{"statistics":{"identical":17,"minorChanges":1,"relatedMeaning":1},"text":{"comparison":{"identical":{"source":{"chars":{"starts":[20147,24304],"lengths":[56,83]},"words":{"starts":[2808,3337],"lengths":[6,9]}},"suspected":{"chars":{"starts":[1125896,1391633],"lengths":[56,83]},"words":{"starts":[171749,213382],"lengths":[6,9]}}},"minorChanges":{"source":{"chars":{"starts":[24388],"lengths":[9]},"words":{"starts":[3347],"lengths":[0]}},"suspected":{"chars":{"starts":[1391717],"lengths":[5]},"words":{"starts":[213392],"lengths":[0]}}},"relatedMeaning":{"source":{"chars":{"starts":[24398],"lengths":[6]},"words":{"starts":[3348],"lengths":[0]}},"suspected":{"chars":{"starts":[1391729],"lengths":[4]},"words":{"starts":[213394],"lengths":[0]}}}},"value":"IS SI\n\nscien\ntome\nrics\n14th International\nSociety of Scientometrics\nand Informetrics Conference\n15th – 19th July 2013\nVienna, Austria\n\nPROCEEDINGS Volume II\n\nPROCEEDINGS OF\nISSI 2013\nVienna\nVOLUME 2\n\n14th International Society of\nScientometrics and Informetrics Conference\nVienna, Austria\n15 to 20th July 2013\nth\n\nEditors\nJuan Gorraiz, Edgar Schiebel, Christian Gumpenberger, Marianne Hörlesberger,\nHenk Moed\nSponsors\nASIS&amp;T, USA\nElsevier B.V.\nEBSCO Information Services, USA\nFederal Ministry for Science and Research, Austria\nFederal Ministry for Transport, Innovation and Technology, Austria\nInformation Assistant, Verein für Informationsmanagement, Vienna\nORCID, Inc.\nScience-Metrix/R&amp;D Reports\nSwets Information Services\nThomson Reuters\nZSI - Centre for Social Innovation, Vienna\n\nAll rights reserved.\n© AIT Austrian Institute of Technology GmbH Vienna 2013\nPrinted by Facultas Verlags- und Buchhandels AG,\nStolbergasse 26, A-1050 Wien\n\nISBN: 978-3-200-03135-7\nISSN: 2175-1935\n\nI NDEX\nKEYNOTE ......................................................................................... 1\nSOCIAL NETWORK ANALYSIS .................................................................... 3\n\nORAL PRESENTATIONS............................................................... 5\nACADEMIC CAREER STRUCTURES – HISTORICAL OVERVIEW\nGERMANY 1850-2013 ..................................................................................... 7\nACADEMIC RESEARCH PERFORMANCE EVALUATION IN BUSINESS\nAND MANAGEMENT USING JOURNAL QUALITY CITING\nMETHODOLOGIES........................................................................................ 22\nACCESS TO UNIVERSITIES’ PUBLIC KNOWLEDGE: WHO’S MORE\nREGIONALIST?.............................................................................................. 36\nADVANTAGES OF EVALUATING JOURNALS THROUGH ACCA - LIS\nJOURNALS (RIP111)........................................................................................ 58\nANALYSIS OF JOURNAL IMPACT FACTOR RESEARCH IN TIME:\nDEVELOPMENT OF A SPECIALTY? .......................................................... 66\nTHE ANALYSIS OF RESEARCH THEMES OF OPEN ACCESS IN CHINA:\nIN THE PERSPECTIVE OF STRATEGIC DIAGRAM (RIP) ....................... 77\nANALYSIS OF THE WEB OF SCIENCE FUNDING\nACKNOWLEDGEMENT INFORMATION FOR THE DESIGN OF\nINDICATORS ON ‘EXTERNAL FUNDING ATTRACTION’ ..................... 84\nANALYZING THE CITATION CHARACTERISTICS OF BOOKS: EDITED\nBOOKS, BOOK SERIES AND TYPES OF PUBLISHERS IN THE BOOK\nCITATION INDEX ......................................................................................... 96\nTHE APPLICATION OF CITATION-BASED PERFORMANCE CLASSES\nTO THE DISCIPLINARY AND MULTIDISCIPLINARY ASSESSMENT IN\nNATIONAL COMPARISON ........................................................................ 109\nAPPROACH TO IDENTIFY SCI COVERED PUBLICATIONS WITHIN\nNON-PATENT REFERENCES IN PATENTS ............................................. 123\nARE CITATIONS A COMPLETE MEASURE FOR THE IMPACT OF ERESEARCH INFRASTRUCTURES?........................................................... 136\nARE LARGER EFFECT SIZES IN EXPERIMENTAL STUDIES GOOD\nPREDICTORS OF HIGHER CITATION RATES? A BAYESIAN\nEXAMINATION. .......................................................................................... 152\n111\n\nResearch in progress paper\n\nARE THERE INTER-GENDER DIFFERENCES IN THE PRESENCE OF\nAUTHORS, COLLABORATION PATTERNS AND IMPACT? (RIP) ...... 167\nASSESSING INTERNATIONAL COOPERATION IN S&amp;T THROUGH\nBIBLIOMETRIC METHODS (RIP) ............................................................. 175\nASSESSING OBLITERATION BY INCORPORATION IN A FULL-TEXT\nDATABASE: JSTOR AND THE CONCEPT OF “BOUNDED\nRATIONALITY.” .......................................................................................... 185\nASSESSING THE MENDELEY READERSHIP OF SOCIAL SCIENCES\nAND HUMANITIES RESEARCH ............................................................... 200\nASSOCIATION BETWEEN QUALITY OF CLINICAL PRACTICE\nGUIDELINES AND CITATIONS GIVEN TO THEIR REFERENCES ...... 215\nAUTHOR NAME CO-MENTION ANALYSIS: TESTING A POOR MAN&#x27;S\nAUTHOR CO-CITATION ANALYSIS METHOD (RIP) ............................ 229\nBIBLIOGRAPHIC COUPLING AND HIERARCHICAL CLUSTERING FOR\nTHE VALIDATION AND IMPROVEMENT OF SUBJECTCLASSIFICATION SCHEMES .................................................................... 237\nBUILDING A MULTI-PERSPECTIVE SCIENTOMETRIC APPROACH ON\nTENTATIVE GOVERNANCE OF EMERGING TECHNOLOGIES .......... 251\nCAREER AGING AND COHORT SUCCESSION IN THE SCHOLARLY\nACTIVITIES OF SOCIOLOGISTS: A PRELIMINARY ANALYSIS (RIP)264\nCITATION IMPACT PREDICTION OF SCIENTIFIC PAPERS BASED ON\nFEATURES ................................................................................................... 272\nCITATION IMPACTS REVISITED: HOW NOVEL IMPACT MEASURES\nREFLECT INTERDISCIPLINARITY AND STRUCTURAL CHANGE AT\nTHE LOCAL AND GLOBAL LEVEL ......................................................... 285\nTHE CITER-SUCCESS-INDEX: AN INDICATOR TO SELECT A SUBSET\nOF ELITE PAPERS, BASED ON CITERS .................................................. 300\nCOLLABORATION IN AFRICA: NETWORKS OR CLUSTERS? ........... 316\nCOLLABORATIVE INNOVATIVE NETWORKS: INFLUENCE AND\nPERFORMANCE .......................................................................................... 328\nCOMPARATIVE STUDY ON STRUCTURE AND CORRELATION\nAMONG BIBLIOMETRICS CO-OCCURRENCE NETWORKS AT\nAUTHOR-LEVEL ......................................................................................... 339\nCOMPARING BOOK CITATIONS IN HUMANITIES JOURNALS TO\nLIBRARY HOLDINGS: SCHOLARLY USE VERSUS &#x27;PERCEIVED\nCULTURAL BENEFIT&#x27; (RIP) ...................................................................... 353\nA COMPARISON OF TWO HIGHLY DETAILED, DYNAMIC, GLOBAL\nMODELS AND MAPS OF SCIENCE .......................................................... 361\n\nA COMPREHENSIVE INDEX TO ASSESS A SINGLE ACADEMIC PAPER\nIN THE CONTEXT OF CITATION NETWORK (RIP) .............................. 377\nTHE CONSTRUCTION OF THE ACADEMIC WORLD-SYSTEM:\nREGRESSION AND SOCIAL NETWORK APPROACHES TO ANALYSIS\nOF INTERNATIONAL ACADEMIC TIES.................................................. 389\nCONSTRUCTION OF TYPOLOGY OF SUB-DISCIPLINES BASED ON\nKNOWLEDGE INTEGRATION .................................................................. 404\nCONTRIBUTION AND INFLUENCE OF PROCEEDINGS PAPERS TO\nCITATION IMPACT IN SEVEN CONFERENCE AND JOURNAL-DRIVEN\nSUB-FIELDS OF ENERGY RESEARCH 2005-11 (RIP) ............................ 418\nCORE-PERIPHERY STRUCTURES IN NATIONAL HIGHER\nEDUCATION SYSTEMS. A CROSS-COUNTRY ANALYSIS USING\nINTERLINKING DATA ............................................................................... 426\nCORRELATION AMONG THE SCIENTIFIC PRODUCTION,\nSUPERVISIONS AND PARTICIPATION IN DEFENSE EXAMINATION\nCOMMITTEES IN THE BRAZILIAN PHYSICISTS COMMUNITY (RIP)\n........................................................................................................................ 447\nCOUNTING PUBLICATIONS AND CITATIONS: IS MORE ALWAYS\nBETTER? ....................................................................................................... 455\nCOVERAGE AND ADOPTION OF ALTMETRICS SOURCES IN THE\nBIBLIOMETRIC COMMUNITY ................................................................. 468\nCROWDSOURCING THE NAMES-GAME: A PROTOTYPE FOR NAME\nDISAMBIGUATION OF AUTHOR-INVENTORS (RIP) ........................... 484\nDETECTING THE HISTORICAL ROOTS OF RESEARCH FIELDS BY\nREFERENCE PUBLICATION YEAR SPECTROSCOPY (RPYS) ............ 493\nDETECTION OF NEXT RESEARCHES USING TIME TRANSITION IN\nFLUORESCENT PROTEINS ....................................................................... 507\nDIFFERENCES AND SIMILARITIES IN USAGE VERSUS CITATION\nBEHAVIOURS OBSERVED FOR FIVE SUBJECT AREAS ..................... 519\nDIFFERENCES IN CITATION IMPACT ACROSS COUNTRIES ............ 536\nDIRECTIONAL RETURNS TO SCALE OF BIOLOGICAL INSTITUTES IN\nCHINESE ACADEMY OF SCIENCES ........................................................ 551\nDISCIPLINARY DIFFERENCES IN TWITTER SCHOLARLY\nCOMMUNICATION ..................................................................................... 567\nTHE DISCOVERY OF ‘THE UBIQUITIN-MEDIATED PROTEOLYTIC\nSYSTEM’: AN EXAMPLE OF REVOLUTIONARY SCIENCE? (RIP)..... 583\nTHE DISTRIBUTION OF REFERENCES IN SCIENTIFIC PAPERS: AN\nANALYSIS OF THE IMRAD STRUCTURE............................................... 591\n\nDO BLOG CITATIONS CORRELATE WITH A HIGHER NUMBER OF\nFUTURE CITATIONS? (RIP) ...................................................................... 604\nDO NON-SOURCE ITEMS MAKE A DIFFERENCE IN THE SOCIAL\nSCIENCES? ................................................................................................... 612\nDOWNLOAD VS. CITATION VS. READERSHIP DATA: THE CASE OF\nAN INFORMATION SYSTEMS JOURNAL ............................................... 626\nDYNAMICS OF SCIENCE AND TECHNOLOGY CATCH-UP BY\nSELECTED ASIAN ECONOMIES: A COMPOSITE ANALYSIS\nCOMBINING SCIENTIFIC PUBLICATIONS AND PATENTING DATA 635\nTHE EFFECT OF BOOMING COUNTRIES ON CHANGES IN THE\nRELATIVE SPECIALIZATION INDEX (RSI) ON COUNTRY LEVEL ... 654\nTHE EFFECT OF FUNDING MODES ON THE QUALITY OF\nKNOWLEDGE PRODUCTION.................................................................... 664\nEFFECTS OF RESEARCH FUNDING, GENDER AND TYPE OF\nPOSITION ON RESEARCH COLLABORATION NETWORKS: A MICROLEVEL STUDY OF CANCER RESEARCH AT LUND UNIVERSITY .... 677\nEVALUATING KNOWLEDGE PRODUCTION SYSTEMS:\nMULTIDISCIPLINARITY AND HETEROGENEITY IN HEALTH\nSCIENCES RESEARCH ............................................................................... 690\nEVALUATING THE WEB RESEARCH DISSEMINATION OF EU\nACADEMICS: A MULTI-DISCIPLINE OUTLINK ANALYSIS OF ONLINE\nCVS ................................................................................................................ 705\nAN EXAMINATION OF THE POSSIBILITIES THAT ALTMETRIC\nMETHODS OFFER IN THE CASE OF THE HUMANITIES (RIP) ........... 720\nEXPLORING QUANTITATIVE CHARACTERISTICS OF PATENTABLE\nAPPLICATIONS USING RANDOM FORESTS ......................................... 728\nEXTENDING AUTHOR CO-CITATION ANALYSIS TO USER\nINTERACTION ANALYSIS: A CASE STUDY ON INSTANT MESSAGING\nGROUPS ........................................................................................................ 742\nEXTENDING CITER-BASED ANALYSIS TO JOURNAL IMPACT\nEVALUATION .............................................................................................. 755\nFIELD-NORMALIZATION OF IMPACT FACTORS: RESCALING VERSUS\nFRACTIONALLY COUNTED ..................................................................... 769\nFUNDING ACKNOWLEDGEMENTS FOR THE GERMAN RESEARCH\nFOUNDATION (DFG). THE DIRTY DATA OF THE WEB OF SCIENCE\nDATABASE AND HOW TO CLEAN IT UP. .............................................. 784\nGENDER AND ACADEMIC ROLES IN GRADUATE PROGRAMS:\nANALYSES OF BRAZILIAN GOVERNMENT DATA ............................. 796\n\nGENDER INEQUALITY IN SCIENTIFIC PRODUCTION (RIP) .............. 811\nGENETICALLY MODIFIED FOOD RESEARCH IN CHINA:\nINTERACTIONS BETWEEN AUTHORS FROM SOCIAL SCIENCES AND\nNATURAL SCIENCES ................................................................................. 819\nA GLOBAL OVERVIEW OF COMPLEX NETWORKS RESEARCH\nACTIVITIES .................................................................................................. 831\nHOW ARE COLLABORATION AND PRODUCTIVITY CORRELATED AT\nVARIOUS CAREER STAGES OF SCIENTISTS? ...................................... 847\nHOW TO COMBINE TERM CLUMPING AND TECHNOLOGY\nROADMAPPING FOR NEWLY EMERGING SCIENCE &amp; TECHNOLOGY\nCOMPETITIVE INTELLIGENCE: THE SEMANTIC TRIZ TOOL AND\nCASE STUDY ............................................................................................... 861\nHOW WELL DEVELOPED ARE ALTMETRICS? CROSS-DISCIPLINARY\nANALYSIS OF THE PRESENCE OF ‘ALTERNATIVE METRICS’ IN\nSCIENTIFIC PUBLICATIONS (RIP)........................................................... 876\nINTERMEDIATE-CLASS UNIVERSITY RANKING SYSTEM:\nAPPLICATION TO MAGHREB UNIVERSITIES (RIP) ............................ 885\nIDENTIFYING EMERGING RESEARCH FIELDS WITH PRACTICAL\nAPPLICATIONS VIA ANALYSIS OF SCIENTIFIC AND TECHNICAL\nDOCUMENTS ............................................................................................... 896\nIDENTIFYING EMERGING TECHNOLOGIES: AN APPLICATION TO\nNANOTECHNOLOGY ................................................................................. 912\nIDENTIFYING EMERGING TOPICS BY COMBINING DIRECT\nCITATION AND CO-CITATION................................................................. 928\nIDENTIFYING LONGITUDINAL DEVELOPMENT AND EMERGING\nTOPICS IN WIND ENERGY FIELD ........................................................... 941\nTHE IMPACT OF CORE DOCUMENTS: A CITATION ANALYSIS OF\nTHE 2003 SCIENCE CITATION INDEX CORE-DOCUMENT\nPOPULATION............................................................................................... 955\nIMPACT OF META-ANALYTICAL STUDIES, STANDARD ARTICLES\nAND REVIEWS: SIMILARITIES AND DIFFERENCES ........................... 966\nTHE IMPACT OF R&amp;D ACTIVITIES ON HOSPITAL OUTCOMES (RIP)\n........................................................................................................................ 978\nINDUSTRY RESEARCH PRODUCTION AND LINKAGES WITH\nACADEMIA: EVIDENCE FROM UK SCIENCE PARKS.......................... 985\nINFLUENCE OF UNIVERSITY MERGERS AND THE NORWEGIAN\nPERFORMANCE INDICATOR ON OVERALL DANISH CITATION\nIMPACT 2000-12 ....................................................................................... 1003\n\nINFORMATION AND LIBRARY SCIENCE, CHANGES THAT\nINFLUENCED IT&#x27;S NEW CHARACTER, DIRECTION AND RESEARCH:\nA BIBLIOMETRIC STUDY, 1985-2006 .................................................... 1019\nAN INFORMETRIC STUDY OF KNOWLEDGE FLOW AMONG\nSCIENTIFIC FIELDS (RIP) ........................................................................ 1030\nINTERACTIVE OVERLAYS OF JOURNALS AND THE MEASUREMENT\nOF INTERDISCIPLINARITY .................................................................... 1037\nINTERDISCIPLINARY RESEARCH AND THE PRODUCTION OF LOCAL\nKNOWLEDGE: EVIDENCE FROM A DEVELOPING COUNTRY........ 1053\nINTERNATIONAL COMPARATIVE STUDY ON NANOFILTRATION\nMEMBRANE TECHNOLOGY BASED ON RELEVANT PUBLICATIONS\nAND PATENTS........................................................................................... 1069\nIN-TEXT AUTHOR CITATION ANALYSIS: AN INITIAL TEST (RIP) 1082\nKNOWLEDGE CAPTURE MECHANISMS IN BIOVENTURE\nCORPORATIONS: A CASE STUDY......................................................... 1090\nLEAD-LAG TOPIC EVOLUTION ANALYSIS: PREPRINTS VS. PAPERS\n(RIP) ............................................................................................................. 1106\nLITERATURE RETRIEVAL BASED ON CITATION CONTEXT .......... 1114\nMAPPING THE EVOLVING PATTERNS OF PATENT ASSIGNEES’\nCOLLABORATION NETWORK AND IDENTIFYING THE\nCOLLABORATION POTENTIAL ............................................................. 1135\nMATCHING BIBLIOGRAPHIC DATA FROM PUBLICATION LISTS\nWITH LARGE DATABASES USING N-GRAMS (RIP) .......................... 1151\nMATHEMATICAL CHARACTERIZATIONS OF THE WU- AND HIRSCHINDICES USING TWO TYPES OF MINIMAL INCREMENTS .............. 1159\nMEASURING INTERNATIONALISATION OF BOOK PUBLISHING IN\nTHE SOCIAL SCIENCES AND HUMANITIES USING THE\nBARYCENTRE METHOD (RIP) ............................................................... 1170\nMEASURING THE ACADEMIC IMPACT OF RESEARCHERS BY\nCOMBINED CITATION AND COLLABORATION IMPACT ................ 1177\nMEASURING THE EXTENT TO WHICH A RESEARCH DOMAIN IS\nSELF-CONTAINED .................................................................................... 1188\nA METHOD FOR TEXT NETWORK ANALYSIS: TESTING,\nDEVELOPMENT AND APPLICATION TO THE INVESTIGATION OF\nPATENT PORTFOLIOS (RIP) ................................................................... 1202\nMISFITS? RESEARCH CLASSIFICATION IN RESEARCH\nEVALUATION: VISUALIZING JOURNAL CONTENT WITHIN FIELDS\nOF RESEARCH CODES ............................................................................. 1210\n\nMODEL TO SUPPORT THE INFORMATION RETRIEVAL PROCESS OF\nTHE SCIENTIFIC PRODUCTION AT DEPARTMENTAL-LEVEL OR\nFACULTY-LEVEL OF UNIVERSITIES ................................................... 1225\nMOST BORROWED IS MOST CITED? LIBRARY LOAN STATISTICS AS\nA PROXY FOR MONOGRAPH SELECTION IN CITATION INDEXES\n(RIP) ............................................................................................................. 1237\nMOTIVATION FOR HYPERLINK CREATION USING INTER-PAGE\nRELATIONSHIPS ....................................................................................... 1253\nMOVING FROM PERIPHERY TO CORE IN SCIENTIFIC NETWORKS:\nEVIDENCE FROM EUROPEAN INTER-REGIONAL COLLABORATIONS,\n1999-2007 (RIP)........................................................................................... 1270\nNANO-ENHANCED DRUG DELIVERY (NEDD) RESEARCH PATTERN\nFOR TWO LEADING COUNTRIES: US AND CHINA ........................... 1278\nNANOTECHNOLOGY AS GENERAL PURPOSE TECHNOLOGY....... 1291\nNEVIEWER: A NEW SOFTWARE FOR ANALYZING THE EVOLUTION\nOF RESEARCH TOPICS ............................................................................ 1307\nTHE NUANCED NATURE OF E-PRINT USE: A CASE STUDY OF ARXIV\n...................................................................................................................... 1321\nON THE DETERMINANTS OF RESEARCH PERFORMANCE: EVIDENCE\nFROM ECONOMIC DEPARTMENTS OF FOUR EUROPEAN COUNTRIES\n(RIP) ............................................................................................................. 1334\nOPEN DATA AND OPEN CODE FOR BIG SCIENCE OF SCIENCE\nSTUDIES ..................................................................................................... 1342\nOPTIMIZING RESEARCH IMPACT BY ALLOCATING FUNDING TO\nRESEARCHER GRANT PORTFOLIOS: SOME EVIDENCE ON A POLICY\nOPTION (RIP) ............................................................................................. 1357\nPATENTS IN NANOTECHNOLOGY: AN ANALYSIS USING MACROINDICATORS AND FORECASTING CURVES ....................................... 1363\nTHE PATTERNS OF INDUSTRY-UNIVERSITY-GOVERNMENT\nCOLLABORATION IN PHOTOVOLTAIC TECHNOLOGY................... 1379\nPERFORMING INFORMETRIC ANALYSIS ON INFORMATION\nRETRIEVAL TEST COLLECTIONS: PRELIMINARY EXPERIMENTS IN\nTHE PHYSICS DOMAIN (RIP) ................................................................. 1392\nPOSSIBILITIES OF FUNDING ACKNOWLEDGEMENT ANALYSIS FOR\nTHE BIBLIOMETRIC STUDY OF RESEARCH FUNDING\nORGANIZATIONS: CASE STUDY OF THE AUSTRIAN SCIENCE FUND\n(FWF) ........................................................................................................... 1401\n\nPREDICTING AND RECOMMENDING POTENTIAL RESEARCH\nCOLLABORATIONS.................................................................................. 1409\nPUBLICATION BIAS IN MEDICAL RESEARCH: ISSUES AND\nCOMMUNITIES.......................................................................................... 1419\nQUANTITATIVE EVALUATION OF ALTERNATIVE FIELD\nNORMALIZATION PROCEDURES ......................................................... 1431\nA RELATION BETWEEN POWER LAW DISTRIBUTIONS AND HEAPS’\nLAW............................................................................................................. 1445\nTHE RELATIONSHIP BETWEEN COLLABORATION AND\nPRODUCTIVITY FOR LONG-TERM INFORMATION SCIENCE\nRESEARCHERS (RIP) ................................................................................ 1461\nRELATIONSHIP BETWEEN DOWNLOADS AND CITATION AND THE\nINFLUENCE OF LANGUAGE .................................................................. 1469\nRELEVANCE AND FOCUS SHIFT: NEW METRICS FOR THE GRANT\nEVALUATION PROCESS PILOT TESTED ON NIH GRANT\nAPPLICATIONS (RIP) ............................................................................... 1485\nRELEVANCE DISTRIBUTIONS ACROSS BRADFORD ZONES: CAN\nBRADFORDIZING IMPROVE SEARCH? ................................................ 1493\nRESEARCH COLLABORATION AND PRODUCTION OF EXCELLENCE:\nFINLAND 1995-2009 .................................................................................. 1506\nRESEARCH PERFORMANCE ASSESSMENT USING NORMALIZATION\nMETHOD BASED ON SCI DATABASE (RIP) ........................................ 1528\nRETHINKING RESEARCH EVALUATION INDICATORS AND\nMETHODS FROM AN ECONOMIC PERSPECTIVE: THE FSS\nINDICATOR AS A PROXY OF PRODUCTIVITY ................................... 1536\nTHE ROLE OF NATIONAL UNIVERSITY RANKINGS IN AN\nINTERNATIONAL CONTEXT: THE CASE OF THE I-UGR RANKINGS\nOF SPANISH UNIVERSITIES ................................................................... 1550\nSCIENCE DYNAMICS: NORMALIZED GROWTH CURVES, SHARPE\nRATIOS, AND SCALING EXPONENTS .................................................. 1566\nSCIENTIFIC POLICY IN BRAZIL: EXPLORATORY ANALYSIS OF\nASSESSMENT CRITERIA (RIP) ............................................................... 1578\n‘SEED+EXPAND’: A VALIDATED METHODOLOGY FOR CREATING\nHIGH QUALITY PUBLICATION OEUVRES OF INDIVIDUAL\nRESEARCHERS.......................................................................................... 1587\nTHE SHORTFALL IN COVERAGE OF COUNTRIES’ PAPERS IN THE\nSOCIAL SCIENCES CITATION INDEX COMPARED WITH THE\nSCIENCE CITATION INDEX .................................................................... 1601\n\nSOCIAL DYNAMICS OF RESEARCH COLLABORATION: NORMS,\nPRACTICES, AND ETHICAL ISSUES IN DETERMINING COAUTHORSHIP RIGHTS (RIP) ................................................................... 1613\nSOFTWARE PATENTING IN ASIA ......................................................... 1622\nSUPPLY AND DEMAND IN SCHOLARLY PUBLISHING: AN ANALYSIS\nOF FACTORS ASSOCIATED WITH JOURNAL ACCEPTANCE RATES\n(RIP) ............................................................................................................. 1640\nA SYSTEMATIC EMPIRICAL COMPARISON OF DIFFERENT\nAPPROACHES FOR NORMALIZING CITATION IMPACT INDICATORS\n...................................................................................................................... 1649\nTHE TIPPING POINT – OPEN ACCESS COMES OF AGE .................... 1665\nTO WHAT EXTENT CAN RESEARCHERS’ INTERNATIONAL\nMOVEMENT BE GRASPED FROM PUBLISHED DATA SOURCES? . 1681\nTO WHAT EXTENT IS THE H-INDEX INCONSISTENT? IS STRICT\nCONSISTENCY A REASONABLE REQUIREMENT FOR A\nSCIENTOMETRIC INDICATOR? ............................................................. 1696\nTOWARD A TIME-SENSITIVE MESOSCOPIC ANALYSIS OF COAUTHOR NETWORKS: A CASE STUDY OF TWO RESEARCH\nSPECIALTIES ............................................................................................. 1711\nTOWARDS THE DEVELOPMENT OF AN INDICATOR OF\nCONFORMITY ........................................................................................... 1726\nTRACING RESEARCH PATHS OF SCIENTISTS BY MEANS OF\nCITATIONS ................................................................................................. 1738\nTRACKING ACADEMIC REGIONAL WORKFORCE RETENTION\nTHROUGH AUTHOR AFFILIATION DATA ........................................... 1746\nTRENDS OF INTELLECTUAL AND COGNITIVE STRUCTURES OF\nSTEM CELL RESEARCH: A STUDY OF BRAZILIAN SCIENTIFIC\nPUBLICATIONS ......................................................................................... 1759\nUSE OF ELECTRONIC JOURNALS IN UNIVERSITY LIBRARIES: AN\nANALYSIS OF OBSOLESCENCE REGARDING CITATIONS AND\nACCESS....................................................................................................... 1772\nUSING MONTE CARLO SIMULATIONS TO ASSESS THE IMPACT OF\nAUTHOR NAME DISAMBIGUATION QUALITY ON DIFFERENT\nBIBLIOMETRIC ANALYSES. .................................................................. 1784\nVISUALIZING AND COMPARING THE DEVELOPMENT OF\nSCIENTIFIC INSTRUMENTATION VS ENGINEERING\nINSTRUMENTATION................................................................................ 1792\n\nWEB BASED IMPACT MEASURES FOR INSTITUTIONAL\nREPOSITORIES .......................................................................................... 1806\nWHAT IS THE IMPACT OF SCALE AND SPECIALIZATION ON THE\nRESEARCH EFFICIENCY OF EUROPEAN UNIVERSITIES? ............... 1817\nWHICH FACTORS HELP TO PRODUCE HIGH IMPACT RESEARCH? A\nCOMBINED STATISTICAL MODELLING APPROACH ....................... 1830\n\nPOSTERS ..................................................................................... 1845\nTHE 2-YEAR MAXIMUM JOURNAL IMPACT FACTOR ..................... 1847\nACCURACY ASSESSMENT FOR BIBLIOGRAPHIC DATA ................ 1850\nANALYSIS OF SEARCH RESULTS FOR THE CLARIFICATION AND\nIDENTIFICATION OF TECHNOLOGY EMERGENCE (AR-CITE) ....... 1854\nAPPLICATIONS AND RESEARCHES OF GIS TECHNOLOGIES IN\nBIBLIOMETRICS ....................................................................................... 1857\nAPPROPRIATE COVERAGE OF SCHOLARLY PUBLISHING IN THE\nSOCIAL SCIENCES AND HUMANITIES - A EUROPEAN OVERVIEW\n...................................................................................................................... 1861\nARE REGISTERED AUTHORS MORE PRODUCTIVE? ........................ 1864\nARE THE BRIC AND MITS COUNTRIES IMPROVING THEIR\nPRESENCE IN THE INTERNATIONAL SCIENCE? ............................... 1868\nJOURNAL IMPACT FACTOR, EIGENFACTOR, JOURNAL INFLUENCE\nAND ARTICLE INFLUENCE .................................................................... 1871\nASEP ANALYTICS. A SOURCE FOR EVALUATION AT THE ACADEMY\nOF SCIENCES OF THE CR........................................................................ 1874\nASSESSING AN INTERVAL OF CONFIDENCE TO COMPILE TIMEDEPENDENT PATENT INDICATORS IN NANOTECHNOLOGY ........ 1877\nBIBLIOMETRIC INDICATORS OF YOUNG AUTHORS IN\nASTROPHYSICS: CAN LATER STARS BE PREDICTED? .................... 1881\nBIOLOGICAL SCIENCES PRODUCTION: A COMPARATIVE STUDY ON\nTHE MODALITIES OF FULL PHD IN BRAZIL OR ABROAD .............. 1884\nA CITATION ANALYSIS ON MONOGRAPHS IN THE FIELD OF\nSCIENTOMETRICS, INFORMETRICS AND BIBLIOMETRICS IN CHINA\n(1987-2010) .................................................................................................. 1887\nCITATION PATTERNS FOR SOCIAL SCIENCES AND HUMANITIES\nPUBLICATIONS ......................................................................................... 1891\nCOLLABORATION IN THE SOCIAL SCIENCES AND HUMANITIES:\nEDITED BOOKS IN ECONOMICS, HISTORY AND LINGUISTICS ..... 1894\n\nTHE COLLECTIVE CONSEQUENCES OF SCIENTIFIC FRAUD: AN\nANALYSIS OF BIOMEDICAL RESEARCH ............................................ 1897\nCOMPARING NATIONAL DISCIPLINARY STRUCTURES: A\nQUANTITATIVE APPROACH .................................................................. 1900\nCOMPREHENSIVENESS AND ACCURACY OF DOCUMENT TYPES:\nCOMPARISON IN WEB OF SCIENCE AND SCOPUS AGAINST\nPUBLISHER’S DEFINITION ..................................................................... 1905\nCONTRIBUTION OF BRAZILIAN SCIENTIFIC PRODUCTION TO\nMAINSTREAM SCIENCE IN THE FIELD OF MATHEMATICS: A\nSCIENTOMETRICS ANALYSIS (2002-2011) .......................................... 1908\nCO-OCCURRENCE BETWEEN AUTHORS’ AFFILIATION AND\nJOURNAL: ANALYSIS BASED ON 2-MODE NETWORK .................... 1912\nCOST ANALYSIS OF E –JOURNALS, BASED ON THE SCIENTIFIC\nCOMMUNITIES USAGE OF SCIENCE DIRECT ONLINE DATABASE\nWITH SPECIAL REFERENCE TO BANARAS HINDU UNIVERSITY\nLIBRARY, INDIA ....................................................................................... 1915\nA COVERAGE OVERLAP STUDY ON CITATION INDEX:\nCOMMERCIAL DATABASES AND OPEN ACCESS SYSTEMS .......... 1918\nFACTORS RELATED TO GENDER DIFFERENCES IN SCIENCE: A COWORD ANALYSIS ..................................................................................... 1922\nTHE CROSSCHECK PLAGIARISM SYSTEM: A BRIEF STUDY FOR\nSIMILARITY ............................................................................................... 1925\nCUMULATIVE CAPABILITIES IN COLOMBIAN UNIVERSITIES: AN\nEVALUATION USING SCIENTIFIC PRODUCTIVITY.......................... 1928\nA DESCRIPTIVE STUDY OF INACCURACY IN ARTICLE TITLES ON\nBIBLIOMETRICS PUBLISHED IN BIOMEDICAL JOURNALS............ 1932\nDIFFUSION OF BRAZILIAN STATISTIC INFORMATION .................. 1935\nDISCOVERING AUTHOR IMPACT: A NOVEL INDICATOR BASED ON\nCITATION IDENTITY ............................................................................... 1938\nDO NEW SCIENTISTS PREFER COLLABORATING WITH OLD\nSCIENTISTS? AND VICE VERSA? .......................................................... 1941\nDO SMALL AND MEDIUM SIZED BUSINESSES CLAIM FOR SMALL\nENTITY STATUS? THE CASE OF MIT AND STANFORD UNIVERSITY\nSPINOFFS ................................................................................................... 1944\nDOES SCIENTIFIC KNOWLEDGE PLAY A ROLE IN PUBLIC POLICIES?\nA CONTRIBUTION OF SCIENTOMETRICS TO POLITICAL SCIENCE:\nTHE CASE OF HTA. .................................................................................. 1947\n\nTHE EARLIEST PRIORITY SELECTOR FOR COMPILING PATENT\nINDICATORS.............................................................................................. 1950\nEFFICIENCIES IN NATIONAL SCIENTIFIC PRODUCTIVITY WITH\nRESPECT TO MANPOWER AND FUNDING IN SCIENCE ................... 1954\nEMERGENCE OF KEYWORDS IN WEB OF SCIENCE VS. WIKIPEDIA\n...................................................................................................................... 1957\nENTROPY-BASED DISCIPLINARITY INDICATOR: ROLE TAXONOMY\nOF JOURNALS IN SCIENTIFIC COMMUNICATION SYSTEMS. ........ 1960\nTHE EPIDEMIC OF RENAL DISEASE –AN EVALUATION OF STATUS\n(2005-2009) .................................................................................................. 1963\nEUROPEAN HIGHLY CITED SCIENTISTS’ PRESENCE IN THE SOCIAL\nWEB ............................................................................................................. 1966\nEVALUATING THE INVENTIVE ACTIVITY OF FOREIGN R&amp;D\nCENTERS IN ISRAEL: LINKING PATSTAT TO FIRM LEVEL DATA 1970\nEVALUATION OF RESEARCH IN SPAIN: BIBLIOMETRIC INDICATORS\nUSED BY MAJOR SPANISH RESEARCH ASSESSMENT AGENCIES 1973\nAN EXPERIENCE OF THE INCLUSION A NEW METHODOLOGY IN\nSELECTING THE REVIEWERS FOR GRANT APPLICATIONS........... 1976\nEXPLORING INTERDISCIPLINARITY IN ECONOMICS THROUGH\nACADEMIC GENEALOGY: AN EXPLORATORY STUDY .................. 1979\nFEATURES OF INDEX TERMS AND NATURAL LANGUAGE WORDS\nFROM THE PERSPECTIVE OF EXTRACTED TOPICS ......................... 1983\nFROM CATEGORICAL TO RELATIONAL DIVERSITY – EXPLORING\nNEW APPROACHES TO MEASURING SCIENTIFIC DIVERSITY ...... 1986\nFULLERENE AND COLD FUSION: BIBLIOMETRIC DISCRIMINATION\nBETWEEN NORMAL AND PATHOLOGICAL SCIENCE ..................... 1989\nGEOGRAPHICAL ORIENTATION AND IMPACT OF FINLAND’S\nINTERNATIONAL CO-PUBLICATIONS ................................................. 1992\nGLOBAL RESEARCH STATUS IN LEADING NUCLEAR SCIENCE AND\nTECHNOLOGY JOURNALS DURING 2001–2010: A BIBLIOMETRIC\nANALYSIS BASED ON ISI WEB OF SCIENCE ...................................... 1995\nGROUPS OF HIGHLY CITED PUBLICATIONS: STABILITY IN\nCONTENT WITH CITATION WINDOW LENGTH ................................ 1998\nHEAPS’ LAW: A DYNAMIC PERSPECTIVE FROM SIMON’S MODEL\n...................................................................................................................... 2001\nHOW EFFECTIVE IS THE KNOWLEDGE TRANSFER OF A PUBLIC\nRESEARCH ORGANIZATION (PRO)? FIRST EMPIRICAL EVIDENCE\nFROM THE SPANISH NATIONAL RESEARCH COUNCIL .................. 2004\n\nHOW MUCH MATHEMATICS IS IN THE BIG TWO AND WHERE IS IT\nLOCATED? ................................................................................................. 2008\nIDENTIFICATION METHOD ON LOW QUALITY PATENTS AND\nAPPLICATION IN CHINA ......................................................................... 2011\nIMPACT AND VISIBILITY OF SA’S RESEARCH JOURNALS:\nASSESSING THE 2008 EXPANSION IN COVERAGE OF THE THOMSON\nREUTERS DATABASES ........................................................................... 2014\nIMPACT OF BRAIN DRAIN ON SCIENCE PRODUCTION: A CASE\nSTUDY OF IRANIAN EDUCATED MIGRANTS IN THE CONTEXT OF\nSCIENCE PRODUCTION IN CANADA ................................................... 2017\nAN INDEX TO QUALIFY HUMAN RESOURCES OF AN ENTERPRISES\nCLUSTER .................................................................................................... 2020\nAN INTERPRETABLE AXIOMATIZATION OF THE HIRSCH-INDEX 2024\nINTERPRETING EPISTEMIC AND SOCIAL CULTURAL IDENTITIES OF\nDISCIPLINES WITH MACHINE LEARNING MODELS OF\nMETADISCOURSE .................................................................................... 2027\nAN INVESTIGATION OF SCIENTIFIC COLLABORATION BETWEEN\nIRAN AND OTHER MENA COUNTRIES AND ITS RELATIONSHIP\nWITH ECONOMIC INDICATORS ............................................................ 2031\nKEYWORD-QUERY EXPANSION USING CITATION CLUSTERS FOR\nPAPER INFORMATION RETRIEVAL ..................................................... 2034\nKNOWLEDGE COMBINATION FORECASTING BETWEEN DIFFERENT\nTECHNOLOGICAL FIELDS...................................................................... 2037\nLANGUAGE PREFERENCE IN SOCIOLOGICAL RESEARCH\nPUBLISHED BY VARIOUS EUROPEAN NATIONALITIES ................. 2040\nLEADERS AND PARTNERS IN INTERNATIONAL COLLABORATION\nAND THEIR INFLUENCE ON RESEARCH IMPACT............................. 2044\nMEASURING INTERDISCIPLINARITY OF RESEARCH GRANT\nAPPLICATIONS. AN INDICATOR DEVELOPED TO MODEL THIS\nSELECTION CRITERION IN THE ERC’S PEER-REVIEW PROCESS .. 2048\nMEASURING THE QUALITY OF ACADEMIC MENTORING ............. 2051\nA MODEL BASED ON BIBLIOMETRIC INDICATORS: THE\nPREDICTIVE POWER ............................................................................... 2054\nMONITORING OF INDIAN RESEARCH PAPERS: ON THE BASIS OF\nMAJOR GLOBAL SECONDARY SERVICES .......................................... 2057\nNANOSCIENCE AND NANOTECHNOLOGY IN SCOPUS: JOURNAL\nIDENTIFICATION AND VISUALIZATION ............................................ 2061\n\nA NEW APPROACH FOR AUTOMATED AUTHOR DISCIPLINE\nCATEGORIZATION AND EVALUATION OF CROSS-DISCIPLINARY\nCOLLABORATIONS FOR GRANT PROGRAMS ................................... 2066\nNORMALIZED INDICATORS OF THE INTERNATIONAL BRAZILIAN\nRESEARCH: A SCIENTOMETRIC STUDY OF THE PERIOD BETWEEN\n1996 AND 2011 ........................................................................................... 2069\nON THE DEFINITION OF A REVIEW, AND DOES IT MATTER? ....... 2072\nAN ONLINE SYSTEM FOR MANAGEMENT AND MONITORING OF\nEXTRAMURAL PROPOSALS FOR FUNDING BY ICMR – A CASE\nSTUDY ........................................................................................................ 2075\nPAPERS PUBLISHED IN PNAS REFLECT THE HIERARCHY OF THE\nSCIENCES ................................................................................................... 2080\nA RESEARCH PROFILE FOR A PROMISING EMERGING INDUSTRY –\nNANO-ENABLED DRUG DELIVERY ..................................................... 2083\nTHE P-INDEX: HIRSCH INDEX OF INDIVIDUAL PUBLICATIONS .. 2086\nPRELIMINARY ANALYSIS OF THE FINANCIAL ASSISTANCE TO\nNON-ICMR BIOMEDICAL SCIENTISTS BY INDIAN COUNCIL OF\nMEDICAL RESEARCH (ICMR) ................................................................ 2089\nTHE PRODUCTIVITY AND IMPACT OF ASTRONOMICAL\nTELESCOPES – A BIBLIOMETRIC STUDY FOR 2007 – 2011 ............. 2092\nPROFILES OF PRODUCTION, IMPACT, VISIBILITY AND\nCOLLABORATION OF THE SPANISH UNIVERSITY SYSTEM IN\nSOCIAL SCIENCES AND HUMANITIES ................................................ 2095\nPROTOTYPICAL STRATEGY FOR HIGH-LEVEL CITATIONANALYSES: A CASE STUDY ON THE RECEPTION OF ENGLISHLANGUAGE JOURNAL ARTICLES FROM PSYCHOLOGY IN THE\nGERMAN-SPEAKING COUNTRIES ........................................................ 2099\nA QUANTITATIVE ANALYSIS OF ANTARCTIC RELATED ARTICLES\nIN HUMANITIES AND SOCIAL SCIENCES APPEARING IN THE\nWORLD CORE JOURNALS ...................................................................... 2102\nTHE RELATIONSHIP BETWEEN A TOPIC’S INTERDISCIPLINARITY\nAND ITS INNOVATIVENESS................................................................... 2105\nHIERARCHICAL CLUSTERING PHRASED IN GRAPH THEORY:\nMINIMUM SPANNING TREES, REGIONS OF INFLUENCE, AND\nDIRECTED TREES. .................................................................................... 2109\nRESEARCH SECTORS INVOLVED IN CUBAN SCIENTIFIC OUTPUT\n2003-2007 .................................................................................................... 2113\n\nRESEARCH TRENDS IN GENETICS: SCIENTOMETRIC PROFILE OF\nSELECTED ASIAN COUNTRIES ............................................................. 2117\nTHE RISE AND FALL OF GREECE’S RESEARCH PUBLICATION\nRECORD: THE LAST 30 YEARS .............................................................. 2120\nTHE ROLE OF COGNITIVE DISTINCTIVENESS ON CO-AUTHOR\nSELECTION AND THE INFLUENCE OF CO-AUTHORING ON\nCOGNITIVE STRUCTURE: A MULTI-AGENT SIMULATION\nAPPROACH ................................................................................................ 2124\nSCIENTIFIC PRODUCTION AND INTERNATIONAL COLLABORATION\nON SOLAR ENERGY IN SPAIN AND GERMANY (1995-2009) ........... 2126\nSCIENTIFIC PRODUCTION OF TOP BRAZILIAN RESEARCHERS IN\nBIOCHEMISTRY, PHYSIOLOGY, PHARMACOLOGY AND BIOPHYSICS\n...................................................................................................................... 2129\nA SIMPLE METHOD TO ASSESS THE QUALITY OF ANY\nUNIFICATION PROCESS .......................................................................... 2132\nSTRUCTURE ANALYSIS OF SMALL PATENT CITATION NETWORK\nAND MAPPING TECHNOLOGICAL TRAJECTORIES .......................... 2136\nSTRUCTURE OF INTERDISCIPLINARY RESEARCH: COMPARING LM\nAND LDA .................................................................................................... 2140\nTHE STUDY AND ASSESSMENT OF RESEARCH PERFORMANCE AT\nTHE MICRO LEVEL: THE AGE PHASE DYNAMICS APPROACH ..... 2143\nTHE SUBJECT CATEGORIES NORMALIZED IMPACT FACTOR ...... 2146\nSUCCESS DETERMINANTS OF FULL-TIME RESEARCHERS AT\nHOSPITALS. A PERCEPTIONS-BASED STUDY ................................... 2149\nSURFING THE SEMANTIC WEB............................................................. 2152\nTEMPORAL EVOLUTION, STRUCTURAL FEATURES AND IMPACT OF\nSTANDARD ARTICLES AND PROCEEDINGS PAPERS. A CASE STUDY\nIN BLENDED LEARNING. ....................................................................... 2156\nTESTING COMPOSITE INDICATORS FOR THE SCIMAGO\nINSTITUTIONS RANKING ....................................................................... 2159\nA TEXT MINING APPROACH EXPLORING ACKNOWLEDGEMENTS\nOF PAPERS ................................................................................................. 2162\nREGULARITY IN THE TIME-DEPENDENT DISTRIBUTION OF THE\nPERCENTAGE OF UNCITED ARTICLES: AN EMPIRICAL PILOT\nSTUDY BASED ON THE SIX JOURNALS .............................................. 2165\nTOPOLOGICAL TOPIC TRACKING – A COMPARATIVE ANALYSIS\n...................................................................................................................... 2168\n\nTOWARDS AN AUTHOR-TOPIC-TERM-MODEL VISUALIZATION OF\n100 YEARS OF GERMAN SOCIOLOGICAL SOCIETY PROCEEDINGS\n...................................................................................................................... 2171\nUSE FREQUENCIES OF NOMINALIZATIONS IN SCIENTIFIC WRITING\nIN BRAZILIAN PORTUGUESE LANGUAGE AS POLITENESS\nSTRATEGIES AND THEIR INDEX ROLE IN THE SUBJECT INDEXING\n...................................................................................................................... 2174\nA VISUALIZATION TOOL FOR TOPIC EVOLUTION AMONG\nRESEARCH FIELDS .................................................................................. 2178\nVISUALIZING THE RESEARCH DOMAIN ON SCIENTOMETRICS (19782012) ............................................................................................................ 2182\nWEB 2.0 TOOLS FOR NETWORK MANAGEMENT AND PATENT\nANALYSIS FOR HEALTH PUBLIC ......................................................... 2185\nWEIGHTING CO-CITATION PROXIMITY BASED ON CITATION\nCONTEXT ................................................................................................... 2189\nWHAT MEANS, IN NUMBERS, A GOLD STANDARD BIOCHEMISTRY\nDEPARTMENT TO NATIONAL AGENCIES OF RESEARCH\nFOMENTATION IN BRAZIL?................................................................... 2193\nWHEN INNOVATION INDICATORS MEET SPIN-OFF COMPANIES: A\nBRIEF REVIEW AND IMPROVEMENT PROPOSAL............................. 2196\nWHERE NATURAL SCIENCES (PHYSICS) MADE IN THE WORLD AND\nIN RUSSIA: 3-DECADES DYNAMICS .................................................... 2200\n\nAUTHOR INDEX .......................................................................2203\n\nMAPPING THE EVOLVING PATTERNS OF\nPATENT ASSIGNEES’ COLLABORATION\nNETWORK AND IDENTIFYING THE\nCOLLABORATION POTENTIAL\nYunwei Chen1,2*, Shu Fang1*\n1\n\n*chenyw@clas.ac.cn; fangsh@clas.ac.cn\n1 Chengdu Library of the Chinese Academy of Sciences, Chengdu, 610041 (China)\n2 University of Chinese Academy of Sciences, Beijing, 100049 (China)\n\nAbstract\n\nThe purpose of this article is to map the evolving patterns of patent assignees’\ncollaboration networks and build a Latent Collaboration Index (LCI) model for evaluating\nthe collaboration probability among patent assignees. The demonstration process was\ncarried on the patents of field of industrial biotechnology (IB) from 2000 to 2010. The\nstudies deployed two different network analysis tools, NWB (NWB Team, 2006) and\nThomson Data Analyzer (TDA), and used ISI Derwent Innovations IndexSM (DII) to\ncollect all the patents of IB. The results shows that the assignees in the field of IB grew\nsteadily while the number of patents had decreased slowly year by year after it reached\npeak in 2002 and 2003. Densification and growth analysis, average degree, density and\ncomponents analysis have showed that the collaboration networks tended to density.\nEspecially from the diameter analysis we might also conclude that the IB field had come\ninto a mature mode after finishing the topological transition occurred in about 2002 or\n2003. The nodes of final network had degrees k followed a power law distribution, which\nimplies a preferential linking feature of the network evolving and thus provided a\nfoundation for link prediction from the aspect of network evolving. Basing on this, two\nnetwork-related parameters had been brought into the LCI model, which were degree and\nnetwork distance. The values of which are positive and negative for link generation\nrespectively. In addition, types of assignees, geographical distance, topic similarity had\nalso been added into the LCI model. Different type of assignees had different probability\nto be linked, such as corporation had been collaborated more frequently, universities\nranked lowest. Assignees from the same country seemed to be likely to collaborate. It\nhave to been noted that the LCI model is flexible that could be adjusted of the factors or\nthe weights of them according to different subjects, time or data. For instance, the topic\nsimilarity factor between assignees would be removed from the LCI model for link\nprediction in the field of IB because of the poor inference from topic similarity to\ncollaboration.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6)\n\n1135\n\nIntroduction\nPatents had been studied for a long time and were regarded as providing valuable\ndata for studies of technology progress, innovative activity (Ernst, 2003),\nidentifying technology trends (Segev &amp; Kantola, 2012), strategies for countries or\ncompanies (Han &amp; Park, 2006), innovation management and policies designing\n(Lee, 2010). Patent documents have also been applied to understand the linkages\nbetween industries, nations, or technologies in terms of technological innovations\nand knowledge flow (Lee, 2010).\nDuring these kinds of works many methods had been used including the method\nof Social Network Analysis (SNA), which just had begun to invade the field of\npatent analysis (Sternitzke, Bartkowski &amp; Schramm, 2008). Basing on patent\ninformation, network nodes could represent inventors, patent assignees or patent\nfiling documents, and so on. For example, cooperation networks between\ninventors and applicants and citation networks of patent families and applicants\nhad been illustrated by using the method of SNA by Sternitzke, Bartkowski &amp;\nSchramm (2008). Inter-industrial knowledge flows had been studied by the patent\nnetwork analysis (Han &amp; Park, 2006).\nWhen the SNA methods were used for patents analysis, most researches had\nfocused on citations networks, collaboration networks and theme maps. For\ninstance, Wartburg, Teichert &amp; Rost (2005) discussed with a methodological\nreflection and application of multi-stage patent citation analysis for the\nmeasurement of inventive progress. Gress (2009) mapped the patent citation\nnetwork based the USPTO data to discuss the information flow directions. Dou &amp;\nBai (2007) analysed the collaboration networks from countries level and applicant\nlevel to find the competition relations and developing strategies. Huang &amp; Wang\n(2010) had examined the small world phenomenon in the patent citation network\nby a case study of the radio frequency identification network. Other patent\nmapping work also included Yang, Akers, Yang, et al. (2010) who made a patent\nlandscape analysis with visualization output by illustrating two case studies:\ntechnology assessment and company assessment.\nSo far, there was few works focusing on mapping the evolution patterns of\ncollaboration networks of the patent assignees. A correlative work was carried by\nHanaki, Nakajima &amp; Ogura (2010), which provided an empirical analysis of\nevolving networks of successful R&amp; D collaborations in the IT industry. The\ncollaboration links in their work was identified between two companies if there\nwas at least one common inventor listed in the patents owned by the companies.\nFirst they showed that the R&amp; D network has become more extensive, more\nclustered, and more unequal in the sense that ‘stars’ have emerged in the network.\nSecond, they analysed the effect of the existing network structure in the process of\nnew R&amp;D collaboration formation. Another related work about link prediction\nwas from Guns (2011). He discussed the function of bipartite for link prediction\nand found that some bipartite predictors form a considerable improvement to their\nunipartite counterparts.\n\n1136\n\nTherefore, this paper utilizes the present techniques to carry out a pilot study that\nwe undertook to map the evolution patterns of the patents assignees collaboration\nnetworks. Furthermore, based on the evolution patterns, this paper also tries to\nbuild a model for evaluating the collaboration probability among patent assignees.\nThe patents of Industrial Biotechnology from 2000 to 2010 had been used for\ndemonstration. The collaboration links in our work are identified between two\ncompanies if their names occurred at least one time in the patents owned by the\nassignees.\nThis paper is organized as follows. Section I is an introduction. Section II\nintroduces the data source &amp; methods. Section III discusses the empirical results\nof the evolving patterns of patent assignees’ collaboration network. Section IV\ndiscusses the collaboration potential model strategy and raised a Latent\nCollaboration Index (LCI) for link prediction. Section V evaluates our findings\nand presents our conclusions.\nData Source &amp; Methods\nWe used ISI Derwent Innovations IndexSM (DII) to collect all the patents in the\nfield of Industrial Biotechnology from 2000 to 2010 according to the patents\ndefinition of Linton, Stone &amp; Wise (2008). Since the publication date of a patent\npublication is generally 18 months later than the application date, in order to make\nexact steady data, we used the basic patent year (defined by DII according to the\nyear of the patent family member that had been collected by DII the earliest) to\ndivide the patent data year by year. The studies deployed two different network\nanalysis tools, NWB (NWB Team, 2006) and Thomson Data Analyzer (TDA).\nThe patents assignees had been cleaned by the following two steps: First, an\nassignee usually has more than one English name because of the different\ntranslation from any other language to English, including different time, different\ntranslation organizations or just spell difference. Therefore all the assignees fields\nhave to be cleaned to integrate the different names of one institute to only one\nunique name. Second, Inventors sometimes would be added to the assignees list at\nsome primary stages of patent applications according to the patent laws of\ndifferent countries. In order to avoiding the interference of the wrong recording\ninformation, this paper deleted all the individual assignees from the assignees list.\nThe assignees that had 50 or more patents were filtered, which contain 450 core\nassignees, 5479 collaborators of the core assignees and 78209 patents (58% of all\npatents from 2000 to 2010). These data were the basic data for our analysis.\nFurthermore, because this paper analyses 11 years evolving networks, many of\nthe 5479 collaborators of the 450 core assignees have few patents were not\nappropriate for evolving analysis, therefore, we selected collaborators only had\nmore than 5 patents (588 collaborators) together with the 450 core assignees as\ncore data (1038 nodes) for network patterns analysis.\nMethodologies deployed in this paper were static in nature, but represent\nsnapshots at certain point of the dynamic investigations, which were used to\nmapping the patterns of patent collaboration network evolution. The basic data\n1137\n\nwere used in the first two sub-sections of section III. The core data were used by\nthe other sections.\nEmpirical results of the evolving patterns of patent assignees’ collaboration\nnetwork\nMapping the Growth of Industrial Biotechnology (IB) from Patents\nThe objectives of this section were to collect the global patent data (basic data) of\nIB from 2000 to 2010, to give a general view of the development of IB at the level\nof applications numbers, annual growth to provide a better understanding of the\npatent activities in the subject of IB these years.\n\n(a)\n\n(b)\n\nFigure 1. Growth of the patents of IB: 2000-2010, annual (a) and cumulative (b)\n\nFigure 1 (a) shows the annual growth of the patents of IB from 2000-2010. From\nthe figure we could see that the patent numbers reached the peak in the year of\n2003, and then decreased slowly year by year.\nThe cumulative number of patents of IB was next investigated and illustrated in\nFigure 1 (b), which shows approximately a linear growth.\nGrowth of Assignees\nIt was to be expected that growth in the number of assignees could show the\npattern as the number of patents applications. One hypothesis is that the assignees\nwould increase steadily along with the development of the number of patents\napplications. However, there were difference in the increasing pattern between\nnumber of patents and number of collaborators. The collaborators could\nrecurrence after it first time occurrence, thus in evolution network we did not\naccount it repeatedly. Therefore, we had to count the cumulative number of\ncollaborators from 2000 to 2010. For instance, the collaborators number from\n2000-2001 and 2000-2010. The collaborators that had already occurred in earlier\nyears would not be counted again when it reoccurred in later years.\nThe annual and cumulative number of the assignees (basic data with more than 50\npatents and their collaborators) from 2000 to 2010 had been showed in Figure 2.\nThe results show that both the annual and cumulative data of assignees had linear\n1138\n\nGrowth Laws. As is vividly betrayed in figure 2 of the cumulative curve, the\nassignees’ number increased rapidly with a compound growth rate of 17.3%. It\nindicated that there were a lot of new assignees emerged in the field of IB.\n\nFigure 2. Numbers of the assignees (&gt;50\npatents) and collaborators:2000-2010\n\nFigure 3. Densification of assignees\ncollaboration networks of IB\n\nDensification and growth\nAs Bettencourt Kaiser and Kaur (2009) pointed that when fields grew, their\nnetworks of collaboration also become denser. This means that the average\nnumber of edges per node tends to increase over time. The relation between\nnumbers of nodes and edges has the following simple scaling law with the scaling\nexponent (α&gt;1) (Bettencourt et al, 2009):\nedges = A(nodes)α,\n(1)\nA and α are constants. The scaling exponent, α, expresses the densification effect\nin a way that was independent of scale (number of nodes).\nIn our work, it is clearly showed in figure 2 that as time gone on, the number of\nassignees grew. Whether in collaborations networks could also show the feature\nof scaling exponent (α&gt;1)? For answer this question, we analysed the relation\nbetween number of nodes and edges in the IB patent collaboration network using\nthe core data, where nodes represented assignees with more than 50 patents and\nits collaborators with more than 5 patents, the data in the curve of Fig. 3 started\nfrom 2000 and ended at 2010.\nWe found that the scaling exponent α=2.46, it suggested that the number of ties\nbetween assignees grew faster than that of assignees.\nDynamics of the Patents Assignees Collaboration networks\nWe study the following network statistics: average degree, density, #components,\net al.\nLet N(i) is the set of assignees collaborating with assignee i. The total number of\ncollaboration assignees with assignee i is the degree of assignee i and is defined as\nη(i) = |N(i)|. The average degree of a network G is defined byη(G)=Σi Nη(i)/n.\nThe density of a network is defined as the number of links divided by the number\nof edges in a complete graph with the same number of nodes. For a network G\nwith N nodes, the density D is defined as:\n1139\n\nD=\n\n2*[#L(G)]\nN(N-1)\n\n(2)\n\nWhere #L(G) represented the number of links of the graph G.\nFor IB assignees collaboration network, the average degree, density and\n#components show that the network became denser and denser, at the same time\nsome individual components had also merged into one bigger component. The\naverage degree of each assignee had also increased year by year, which meant that\nthe assignees had more and more collaborators.\nBuilding on work by Leskovec, Kleinberg, and Faloutsos (2005) which found that\nas networks grow and more nodes and edges are added, their effective diameter\n(as measured by shortest-path length—i.e., the 90th percentile) tends to decrease.\nThey confirmed this for citation and affiliation graphs extracted for patents\nregistered with the United States Patent and Trademark Office. Contrary to this,\nBettencourt, Kaiser, and Kaur (2009) showed that collaboration graphs in several\nscientific and technological fields exhibit initial rapid growth in their diameter,\nwhich then tends to stabilize and stay approximately constant at 12~14. This\nmight be caused by the fact that when a new field emerges, authors are not yet\naware of all relevant experts and works; as the field matures, important\ncollaborations come into existence and lines of research are interlinked via coauthor and citation linkages. The diameter of a collaboration network has major\nimplications for information diffusion—the shorter a pathway of co-author\nlinkages that connects an author pair, the more likely knowledge diffuses.\nIn our work, the collaboration network diameters seemed to stabilize at about 12.\nBased on the theory that a collaboration graph that the density with constant or\ndecreasing diameters suggests that a global topological transition may occur in the\ngraph as a whole as it grows, it could be taken to mean that we could conclude\nthat the global topological transition had happen for the global collaboration\nnetwork of IB.\nTable 1 The evolution of the patents assignees collaboration networks from core data\nNetwork size (# Nodes)\n# Edges\nAverage degree\nDensity (*100)\n# Components\nDiameter\n\n2000\n501\n779\n3.12\n0.62\n36\n17\n\n2001\n670\n1364\n4.07\n0.61\n26\n13\n\n2002\n795\n1919\n4.83\n0.61\n21\n13\n\n2003\n874\n2440\n5.58\n0.64\n21\n13\n\n2004\n933\n2844\n6.10\n0.65\n16\n11\n\n2005\n977\n3247\n6.65\n0.68\n16\n12\n\n2006\n1003\n3700\n7.38\n0.74\n12\n11\n\n2007\n1023\n4099\n8.01\n0.78\n14\n11\n\n2008\n1033\n4428\n8.57\n0.83\n10\n12\n\n2009\n1037\n4701\n9.07\n0.88\n10\n12\n\n2010\n1038\n4893\n9.43\n0.91\n9\n12\n\nDistribution Patterns of Final Global Collaboration Network\nDuring the period of 11 years development, more and more assignees had\nestablished relations with others. We mapped the relation between core nodes and\ntheir degrees in the network of 2000-2010, which was betrayed in Figure 4 (a).\nWe could found that the number of assignees decreased with their degree\nincreased. When nonlinear regression was used to relation between k and P(k), the\n1140\n\nnodes in the collaboration network had degree k (in other words, exactly k links)\nfollowed a power law distribution, except for the nodes degree higher than 50.\nThis probably not only means that the global collaboration network had the scalefree property, but also the preferential linking feature was exceeding the\nregression curve, there were many assignees had been chosen to link much more.\n\na\n\nb\n\nFigure 4. Nodes distribution with k links (2000-2010)\n\nCollaboration potential model strategy: Latent Collaboration Index (LCI)\nThe purpose of this section is to discuss the factors which might determine the\npossibility of patents collaborations and construct a model, Latent Collaboration\nIndex (LCI), to evaluate this possibility. The nodes (assignees) in this paper were\nclassified into three types of corporations, scientific establishments and\nuniversities. Although a link between two assignees could dissolution or\nreformation year by year, in this study we focused only on the newly established\ncollaborations as a new link. That is to say if two assignees had collaborated in a\nyear once before, then the link between them exist forever, no matter there was no\ncollaboration in later years or collaborated off and on. Therefore, the new link in\nthis paper only meant the new collaboration between assignees that have not\ncollaborated before.\nAccording to the results of above analysis on the evolving patterns of assignees\ncollaboration network, the power law distribution of the network had provided the\nfoundation for link prediction from the level of network. This section would\nconstruct a model for predicting link generation of patent assignees collaboration\nnetwork based on network features together with some objective factors that\nmight affect the link generation such as theme similarities, types of assignees,\ngeographical distance or subjects field, etc. However, the model construction\nprocess was so a time-consuming and hard work, the demonstration of link\nprediction in IB was on processing now and will be discussed in later works. This\npaper have only presented the LCI model and discuss the factors might determine\nthe links generation but did not carry out the demonstration process of link\nprediction.\n\n1141\n\nLCI model\nTheoretically, collaborations could be established usually by the following five\nways based on the research interests or technology transfer:\nType I, randomly link occurs between two assignees both of which had no patents\nbefore. This kind of link is impossible to predict.\nType II, new assignee collaborates with the assignees that had already existed.\nType III, two assignees that both have already existed but in different network\nclusters.\nType IV, two assignees that both have already existed and in the same network\ncluster.\nIn the types II, III and IV, collaborations occur on a particular topology of the\nexisting network. At the same time, because we carried out our empirical analysis\non industrial biotechnology based on the patents from 2000 to 2010, there were\nmany links occurred before 2000 and these links were marked as Type V, existing\nlinks.\nWhether the network patterns would affect the choice of one assignee collaborate\nwith others? For instance, whether the idea of preferential linking (Albert &amp;\nBarabasi (2002) and Dorogovtsev &amp; Mendes (2002)) is also appropriate for patent\nassignees collaboration networks? In this study we raised a hypothesis that the\nanswers for the above queries were “yes”. Furthermore, the network-based Latent\nCollaboration Index could be written as follows. We assumed that assignee a and\nb has not collaborated with each other at t-1 year, thus the possibility of a has\nbeen chosen to collaborate with b was named LCI(a,b)t:\nLCI(a,b)t=α+βP[d(a,b)t-1]+γP[k(a)t-1]+δP[simtopic(a,b)t-1]+θω(a,b)+εP[g(a,b)t1]+Φ (3)\nWhere P[d(a,b)t-1] represents the network distance parameter, calculated as the\nshortest path between two nodes in a network.\nP[k(a)t-1] reflects the network preferential linking feature of scale-free network, is\nthe value of degree of assignee a.\nP[simtopic(a,b)t-1] reflects the correlation between the link generation and the topic\nsimilarity of a pair of assignees.\nω(a,b) represents the different collaboration possibility among different types of\nassignees.\nP[g(a,b) t-1] represents the correlation between the link generation and the\ngeographical distance of a pair of assignees.\nΦ represents the different collaboration tendency of different subject fields. To a\ngiven subject, Φ is a constant. This parameter is only useful for multi-subjects\nanalysis. If an analysis is carried for a particular subject, Φ could be removed\nfrom the model, such as we did not discuss it in this paper for only IB, a particular\nsubject had been analysis.α is a random value, which determined by the\nregression process.\n\n1142\n\nRelativities of Factors in LCI model and link generation\n(1) Degree: P[L(a)t]~P[k(a)t-1]\nDuring the period of 2000-2010 there were 431 assignees had patents published\neach year and 607 new assignees. The 431 assignees had been listed descending\norder and divided into 9 groups with 50 assignees per group, the ninth group had\nonly 31 assignees. Then we mapped the relation between Degree (mean) and the\nCompound Annual Growth Rate (mean) of each group in Fig.5. The data in the\nfigure showed that the assignees with higher degree had also got the higher\ncompound annual growth rate. The Pearson correlation was 0.95. It suggested that\nnew links would like to choose assignees with higher degrees. It followed the\n&quot;riches getting richer&quot; phenomenon in the field of complex network. Applying\nlinear regression led to the below equations:\nP[L(a)t]~0.68P[k(a)t-1]\n(4)\nP[L(a)t] represents the possibility of assignee a be chosen to collaborate in year t.\nP[k(a)t-1] represents the degree of assignee a in year t-1.\n\nFigure 5. Degree and compound annual grow rate of assignees\n\nThen therefore, who does became the network centre nodes? We could show them\nin two ways. Firstly, the assignees had been chosen to link by the 607 new\nassignees (table 2). Secondly, the assignees that had the highest compound annual\ngrowth rate who were the targets to be collaborated by the new assignees or the\nexisting assignees choose to link.\nThe data shows that the assignees had been chosen more when the new assignees\nenter the network were also ranked top by degrees. There were 6 assignees in the\nTOP10 assignees ranked also in TOP 10 according to degree.\nAnother way, there were 182 linking pairs of nodes who were already existed in\nthe network before they link to each other. The data in table 3 showed that the\n1143\n\nassignees that had been chosen more when new link generated were also ranked\ntop by degrees. There were 8 assignees in the TOP10 assignees ranked also in\nTOP 10 according to degree.\nTable 2 TOP 10 assignees had been chosen to link by the 607 new assignees\n\nTOP1\nTOP2\nTOP3\nTOP4\nTOP5\nTOP6\nTOP7\nTOP8\nTOP9\nTOP10\n\nAssignees\nJapan Sci &amp; tech Agency\nCnrs Cent Nat Rech Sci\nDokuritsu Gyosei Hojin Sangyo Gijutsu So\nInst Nat Sante &amp; Rech Medicale\nDokuritsu Gyosei Hojin Nogyo Seibutsu Sh\nKyowa Hakko Kogyo Kk\nInra Inst Nat Rech Agronomique\nJapan Min Agaric Forestry &amp; Fisheries\nUniv. California\nBase Corp\n\nTimes be\nDegree\nRank of\nchosen (by the end of 2010) degree\n34\n108\n2\n15\n77\n6\n14\n106\n3\n14\n71\n9\n12\n82\n5\n9\n56\n17\n8\n30\n63\n8\n58\n16\n8\n121\n1\n7\n36\n44\n\nTable 3 TOP 10 assignees had been chosen more when 182 links generation\n\nTOP1\nTOP2\nTOP3\nTOP4\nTOP5\nTOP6\nTOP7\nTOP8\nTOP9\nTOP10\n\nDokuritsu Gyosei Hojin Sangyo Gijutsu So\nJapan Sci &amp; Tech Agency\nCnrs Cent Nat Rech Sci\nDokuritsu Gyosei Hojin Rikagaku Kenkyush\nUs Dept Health &amp; Human Services\nInst Nat Sante &amp; Rech Medicale\nUniv. California\nDokuritsu Gyosei Hojin Nogyo Seibutsu Sh\nDu Pont De Nemours &amp; Co E I\nDaiichi Pharm Co Ltd\n\nTimes be\nDegree\nRank of\nchosen (by the end of 2010) degree\n13\n106\n3\n10\n108\n2\n7\n77\n6\n7\n75\n7\n7\n104\n4\n6\n71\n10\n6\n121\n1\n5\n82\n5\n5\n34\n50\n4\n36\n44\n\n(2) Distance: P[L(a)t]~[d(a, b)t-1]\nAmong these 182 pair assignees, although they had already existed in the network\nbefore their links generation, there were two ways for them to construct links.\nOne was a new link generated in one cluster and there were 169 pairs. Another\nway was between different clusters and two different clusters merged into one\ncluster with the new link generation, there were 13 pairs of new link generated\nfrom this way. These 13 pairs of assignees usually had higher values of\nBetweenness and were very key steps of the network evolving. While those 169\npairs contributed a large part of the new pair generation, the shortest paths of the\n169 pairs before they linked were concluded in table 4. The data illustrates that\nthe probability of link generation grew with the decrease of the shortest distance\nbetween two assignees. The link possibility of assignee a and b P[L(a, b)t] could\nbe reflected by the distance between them as follows:\nP[L(a, b)t]~e-0.929[d(a, b) ]\n(5)\nt-1\n\n1144\n\nTable 4 Distribution of shortest distance of 169 pair before link\nDistance before link d(→1)\n2\n3\n4\n5\n6\n\nLinks number\n115\n23\n22\n7\n2\n\n(3) Types of assignees: P[L(a)t]~ω(a,b)\nω(a,b) represents the different collaboration possibility among different types of\nassignees.\nThis paper divides assignees into three types: corporations, scientific\nestablishments and universities. Table 5 illustrates the types of all the\ncollaboration pairs. We could find that “corporation- corporation” pairs had the\nhighest capabilities of 46.4% and “university-university” pairs collaborated at\nleast. It meant that, for instance, if there was a link generated in the collaboration\nnetwork, which had a chance of 46.6% between two corporations and only 5.4%\nchance between two universities.\nTable 5 Types of pairs of assignees\ncorporation- corporation\ncorporation- scientific establishment\ncorporation- university\nscientific establishment- scientific establishment\nscientific establishment- university\nUniversity- university\n\nNumber of pairs\n294\n87\n57\n96\n66\n34\n\n[ω(a,b)]\n46.4%\n13.7%\n9.0%\n15.1%\n10.4%\n5.4%\n\n(4) Geographical distance: P[L(a)t]~P[g(a,b) t-1]\nTable 6 lists the TOP 10 assignees by degrees and their collaborators’ countries,\nwhich showed that the probability of they collaborated with overseas countries\nwas only 2.1%. A great part of links were among the same countries. Thus, when\nan assignee had a chance to choose a partner to collaborate, the possibility of\nwhich choose an assignee from the same country was about 98%.\nTherefore, the link possibility of assignee a and b P[L(a, b)t] could be reflected by\nthe geographical distance between them as follows:\nP[L(a, b)t]~P[g(a,b)t-1] 97.9% (same countries)\n(6)\n2.1%(different countries)\n\n1145\n\nTable 6 Countries distribution of the collaborators of TOP10 assignees\nAssignees\nUniv. California\nJapan Sci &amp; Tech Agency\nDokuritsu Gyosei Hojin Sangyo\nGijutsu So\nUs Dept. Health &amp; Human\nServices\nDokuritsu Gyosei Hojin Nogyo\nSeibutsu Sh\nCnrs Cent Nat Rech Sci\nDokuritsu Gyosei Hojin\nRikagaku Kenkyush\nUniv. Osaka\nInst Nat Sante &amp; Rech Medicale\nUniv Kyoto\n\n# patents\n237\n344\n362\n\nDegree\n121\n108\n106\n\nCountries\nUSA\nJapan\nJapan\n\nCountries distribution of the collaborators\nUSA\nJapan\nFrance\nGermany\n13\n20\n25\n\n332\n\n104\n\nUSA\n\n16\n\n300\n\n82\n\nJapan\n\n378\n304\n\n77\n75\n\nFrance\nJapan\n\n130\n219\n139\n\n72\n71\n71\n\nJapan\nFrance\nJapan\n\n1\n\n1\n\n14\n1\n\n23\n5\n4\n\n26\n\n14\n\n(5) Topic similarity: P[L(a)t]~P[simtopic(a,b)t-1]\nThrough topic analysis on the pairs of link we found that both assignees of the\nlink pair usually had higher topic similarity, however it could not be reverse\nmapping, that is to say a pair of assignees had higher topic similarity were not\nnecessary to get link to each other. Actually, through our analysis the share of unlink pairs with higher topic similarities was very large. Not only did we discuss\nthis problem in subject IB, a relative narrow field in the scientific world, we had\nalso compared the topic similarities among the sub-institutes of Chinese Academy\nof Sciences (CAS), which had more wide subjects. The same results were found.\nTherefore, it might be very hard to predict the link potential although a link\nusually had higher topic similarity.\nThe methods we had used for count the topic similarities included Pearson\nCorrelation, a common parameter used for count correlation, and two algorithms\ndeveloped by ourselves. One of which is W1, which means the number of IPC\nthat both the pair assignees shared. Another is W2, which represents the similarity\nof the ratios of common IPCs compared to the total IPCs for each assignee.\nW1=count(IPCi∩IPCj)\n(7)\nN i (IPCi\n\nIPC j ) N j (IPCi IPC j )\n\nNi\nNj\nW 2=\nN i (IPCi IPC j ) N j (IPCi IPC j )\n+\nNi\nNj\n\n(8)\n\nLet N be the set of independent assignees in the R&amp;D network for a given year,\nfor two companies i and j (i I,j I), the set of IPCs owned by i and j is\nrepresented as IPCi and IPCj, thus, IPCi∩IPCj represents the set of IPCs have\nbeen shared by i and j.\nNi(IPCi∩IPCj) and Nj(IPCi∩IPCj) represent the patent numbers of i and j belong\nto IPCi∩IPCj, Ni and Nj represent the total patent numbers of i and j.\n1146\n\nBesides these methods, there are more complicated topic models could be used\nfor analysing the topics of assignees, then the results could be applied for count\nP[simtopic(a,b)t-1]. Such representative topic models included LDA (Blei, Ng &amp;\nJordan, 2003) and SAO model (Yoon &amp; Kim, 2011). However, it is uncertain now\nwhether these topic algorithms could be more powerful to distinguish the topics\ndifference which might affect the link generation. More works need to be carried\nto make more comprehensive analysis.\nTo sum up, it must be explained that these factors contributing to the link\ngeneration sometimes intertwine to form an organic whole and thus become more\npowerful than any one of them for link prediction. Without doubt that were some\nother factors had not been mentioned. Even for these discussed factors, sometimes\nare not appropriate and should be removed from the LCI model, such as topic\nfactor would not be used in the model until a better algorithm had been found\nwhich was powerful to identify the topic difference relative to link generation.\nTherefore, in this case of IB, the LCI model could be modified as follows.\nLCI(a,b)t=α+βP[d(a,b)t-1]+γP[k(a)t-1]+θω(a,b)+εP[g(a,b)t-1] (9)\nConclusions &amp; Discussion\nThe goal of the present paper is to show readers that the evolving patterns of\npatent assignees’ collaboration evolution networks, which is the theoretical basis\nof constructing a model of LCI for predicting the collaboration probability\nbetween two assignees. The demonstration process was carried on the patents of\nfield of industrial biotechnology (IB) from 2000 to 2010. The results show that\nduring the period of 11 years development, more and more assignees had begun to\napply patents (cumulative number of assignees curve in figure 2) with an growth\nrate of 17.3%, however the patent numbers of IB had decreased slowly year by\nyear after it reached peak in 2002 and 2003 (figure 1), the same to the annual data\nof assignees in figure 2. It suggested that there were about one fifth assignees\neach year applied patents occasionally or discontinuously, which might be isolates\nor collaborated with other assignees. After 11 years accumulation, these\ndiscontinuous assignees grew to be a huge set, but only acted as the subordinate\nassignees in the whole set of IB assignees. At the network level, these subordinate\nnodes usually had very few patents or single links with other nodes or as isolates\nin the network. Their contributions to the network evolving were feeble.\nTherefore, this paper selected the assignees which had more than 50 patents and\ntheir collaborators with more than 5 patents as core data to analysis the network\nevolving patterns.\nThe scaling exponent (α=2.46) analysis had shown that the collaborations became\nmore frequent with a higher growth rate than the assignees. It reflected more links\nhad generated in the network as a result of the more and more assignees had\nsought collaborations for their research and development activities or transfer of\ntheir patented technologies in the field of IB. This could also be reflected by the\nevolving patterns of network size, average degree, density, number of components\nand diameter, etc. All these parameters had shown that the IB assignees\n1147\n\ncollaboration network had become denser and denser. Especially from the\ndiameter we might also conclude that the IB field had come into a mature mode\nafter finishing the topological transition occurred in about 2002 or 2003. It\nprobably means that the group theory (Whitfield, 2008) does not only suitable for\nauthors but could also be applicable for patents assignees, which also show the\nfeature of increasing collaborations for the need to reinforce their innovation\ncapabilities or to promote the technology transfer of their patents.\nThe final collaboration network had a scale-free pattern that included nine\ncomponents. It implied a preferential linking feature of the network evolving and\nthus provided a foundation for link generation from the aspect of network\nevolving. Basing on this, two network-related parameters had been brought into\nthe LCI model, which were degree and distance. This paper’s analysis has shown\nthe relativity of degree and link generation was positive, while the distance’s\nrelativity was negative. That is to say a link is more likely to generate between\ntwo assignees that with shorter distance and the assignees had more links would\nalso like to be chosen. Beside the degree and distance from the point of network\nevolving, there are some other parameters might contribute for the link\ngeneration, such as types of assignees, geographical distance, topic similarity, etc.\nDifferent type of assignees had different probability to be linked, such as\ncorporation had been collaborated more frequently, universities ranked lowest.\nWhen two assignees from different countries were candidate for another target\nassignee to link, the candidate from the same country had much more possibility\nto be chosen. It has to be explained that although this paper constructed the LCI\nmodel comprised topic similarity factor, it had difficulty to use it for link\nprediction of assignees collaboration networks at present because of the poor\ninference from topic similarity to collaboration.\nActually, link prediction work is impossible to get perfect, the only can we do is\nto increase the accuracy continually. During the improvement process, the factors\nin the model are needed to be adjusted or the weights of each factor need also be\nrevised frequently according to different fields, time or data. For instance, the\ngeographical distance factor could be refined at states or cities level, which might\nbe more powerful. The next step of our study would use the patent data of IB\nfrom 2000 to 2005 as training data to carry the demonstration of LCI to estimate\nthe weights of each factor. Then the validation process would predict the link\ngeneration in the field of IB from 2006 to 2010. After that, we would summarize\nthe limitations of this LCI model and design new improvement measures to\nmodify the LCI model step by step.\nThe present study leads to a necessary thinking that what had made the above\ncharacters? In SNA, although the relationships between nodes become the first\npriority and individual properties were only secondary. However, it should be\npointed out that individual characteristics as well as relational links are necessary\nin order to fully understand social phenomena (Otte, 2002). In future, the node\ncentrality and structural holes should also be analysed. Sternitzke, Bartkowski &amp;\nSchramm (2008) had found that inventors spanning bridges between different\n1148\n\ninventors groups hold patents that were technologically broader, i.e. possess more\nIPC classes. Whether this character could be found in assignees networks?\nWhether the assignees locate in central or had structural holes are more innovative\nor interdisciplinary?\nOn the other hand, our work had analysed the evolution network mainly by\ncumulative data. It was powerful for us to disclose the general pattern of patent\nassignee collaboration networks. However, some collaborators occurred only one\nor limited times, there were very few collaborators were related to each other all\nthe time. Thus, if we want to look into the detail behaviours of collaborations, we\nneed to map the collaboration networks year by year based on the annual data, not\nthe cumulative data.\nReferences\nAlbert, R. &amp; Barabasi, A. L. (2002). Statistical mechanics of complex networks.\nReviews of Modern Physics, 74(1): 47-97.\nBettencourt, L. M. A., Kaiser, D. I., &amp; Kaur, J. (2009). &quot;Scientific discovery and\ntopological transitions in collaboration networks.&quot; Journal of Informetrics.\n3(3): 210-221.\nBlei, D. M., Ng, A. Y. &amp; Jordan, M. I. (2003). Latent Dirichlet allocation. Journal\nof Machine Learning Research. 3(4-5): 993-1022.\nDou, H. &amp; Bai, Y. (2007). A rapid analysis of Avian Influenza patents in the\nEsp@cenet database-R&amp;D strategies and country comparisons. World Patent\nInformation, 29, 26-32.\nDorogovtsev, S. N.&amp; Mendes, J. F. F. (2002). Evolution of networks. Advances in\nPhysics, 51(4): 1079-1187.\nErnst H. (2003). Patent information for strategic technology management. World\nPatent Information, 25(3): 233-242.\nGress B. (2010). Properties of the USPTO patent citation network 1963-2002.\nWorld Patent Information, 32(1): 3-21.\nGuns R. (2011). Bipartite networks for link prediction: Can they improve\nprediction performance? Proceedings of ISSI 2011. 4-7, July, 2011, Durban,\nSouth Africa. - 13TH INTERNATIONAL CONFERENCE OF THE\nINTERNATIONAL SOCIETY FOR SCIENTOMETRICS AND\nINFORMETRICS, VOL1, 2011:249-260.\nHanaki, N., Nakajima, R. &amp; Ogura, Y. (2010). The dynamics of R&amp;D network in\nthe IT industry. Research Policy 39(3): 386-399.\nHan, Y.-J. &amp; Park, Y. (2006). Patent network analysis of inter-industrial\nknowledge flows: The case of Korea between traditional and emerging\nindustries. World Patent Information. 28(3): 235-247.\nHung, S. W. &amp; Wang, A. P. (2010). Examining the small world phenomenon in\nthe patent citation network: a case study of the radio frequency identification\n(RFID) network. Scientometrics. 82(1): 121-134.\nLee, S. &amp; Kim, M.-S. (2010). Inter-technology networks to support innovation\nstrategy: An analysis of Korea&#x27;s new growth engines. Innovation:\n1149\n\nManagement, Policy &amp; Practice, 12(1: Network Analysis Application in\nInnovation Studies): 88-104.\nLeskovec, J., Kleinberg, J. &amp; Faloutsos, C. (2005). “Graphs over Time:\nDensification Laws, Shrinking Diameters and Possible Explanations” ACM\nSIGKDD International Conference on Knowledge Discovery and Data Mining\n(KDD). 177-187.\nLinton K., Stone P. &amp; Wise J. (2008). Patenting trends &amp; innovation in industrial\nbiotechnology. Industrial Biotechnology, 4(4):367-390.\nNWB Team. (2006). “Network Workbench Tool,” Indiana University,\nNortheastern University, and University of Michigan.\nhttp://nwb.slis.indiana.edu/.\nOtte, E. &amp; Rousseau, R. (2002). Social network analysis: a powerful strategy, also\nfor the information sciences. Journal of Information Science, 28(6): 441-453.\nSegev, A. &amp; Kantola, J. (2012). Identification of trends from patents using selforganizing maps. Expert Systems with Applications. 39(18): 13235-13242.\nSternitzke, C., Bartkowski, A. &amp; Schramm, R. (2008). Visualizing patent\nstatistics by means of social network analysis tools. World Patent Information,\n30(2): 115-131.\nWartburg, I., Teichert, T. &amp; Rost, K. (2005). Inventive progress measured by\nmulti-stage patent citation analysis. Research Policy, 2005, 34(10): 15911607.\nWhitfield, J. (2008). Group theory. Nature, 455, 720-723.\nYang, Y. Y., Akers, L., Yang, C. B., et al. (2010). Enhancing patent landscape\nanalysis with visualization output. World Patent Information. 32(3): 203-220.\nYoon, J. &amp; Kim, K. (2011). Identifying rapidly evolving technological trends for\nR&amp;D planning using SAO-based semantic patent networks. Scientometrics.\n88(1): 213-228.\n\n1150\n\nMATCHING BIBLIOGRAPHIC DATA FROM\nPUBLICATION LISTS WITH LARGE DATABASES\nUSING N-GRAMS (RIP)\nMehmet Ali Abdulhayoglu1 and Bart Thijs2\n1\n\nmehmetali.abdulhayoglu@kuleuven.be\nCentre for R&amp;D Monitoring (ECOOM), K.U. Leuven, Waaistraat 6, B-3000 Leuven\n(Belgium)\n2\n\nbart.thijs@kuleuven.be\nCentre for R&amp;D Monitoring (ECOOM), K.U. Leuven, Waaistraat 6, B-3000 Leuven\n(Belgium)\n\nAbstract\n\nThis paper presents a matching method for the identification of publications, extracted\nfrom publications lists provided by authors or research institutes, in large bibliographic\ndatabases. For this purpose, Levenshtein similarities based on N-grams have been used to\nmeasure the closeness between the given publications and the database records. Several\ndifferent similarity scores have been calculated and used as variables in a kernel\ndiscriminant analysis. About 95% accuracy has been achieved by using this method.\n\nConference Topic\n\nManagement and Measurement of Bibliometric Data within Scientific Organizations\n(Topic 9).\n\nIntroduction\nThe application of evaluative bibliometrics at the micro and meso level often\nrequires the use of CVs and publication lists provided by authors, applicants and\ninstitutions as an input of the analysis. The quality of the retrieved data sets is\noften a crucial determinant of the validity of the final results. Therefore, the\nidentification of the authors’ or research teams’ publications in large databases\nlike the Web of Science (WoS) and Scopus usually results in a tremendous\namount of manual effort. Automation of this process of directly linking\npublications provided in lists to publication records indexed in the database could\nessentially simplify this task and free up resources previously assigned to the\nmanual cleaning tasks.\nMost commonly, the problem in finding such matches is caused by incomplete,\nerroneous or censored data in publication lists; but erroneous entries occur in the\ndatabases as well. It is very likely that an author adds a publication to his/her CV\nas soon as a paper is submitted or conditionally accepted but later, the actual\npublication year, but also the title or the number and sequence of co-authors can\nchange during the process of revision and finalization of the publication.\n1151\n\nIn the present paper, a promising method is based on measuring complete string\nsimilarity between the bibliographic references in both publication lists and the\nbibliographic database is presented. In the literature, there are numerous works\nrelated to reference/citation matching for many different purposes (e.g. Giles et al.\n(1998), Lawrence et al. (1999), Larsen (2004)). Depending on implementation, a\nproper similarity measure has been questioning for string comparison. Kondrak\n(2005) introduced a modified Levenshtein distance which is based on N-grams\nthat is applied in this study.\nPossible matches with publications indexed in the database have been examined\nby kernel discriminant analysis (KDA) which uses various similarity scores as\nvariables. In particular, we analyze different components, such as title, journal\nname, co-authors, etc. that constitute the variables in KDA and the accuracy of\nmatches.\nThe objective of this study is not to completely automatize the match or to\ndefinitely decide whether the given publication is indexed in the database but to\nenhance the matching accuracy by trying to obtain various variables to find an\noptimum solution for discriminating existing and non-existing entries. By\nachieving this objective, it is intended to reduce manual work to the possible\nminimum.\nIn order to test the efficiency of the proposed method, a publication list taken\nfrom scientists’ CVs has been matched with papers indexed in the WoS database.\nThe results show that the model proposed by linear discriminant function is\ncapable of matching the publications in our test set with almost 95% accuracy.\nFirst we introduce the concept of N-grams and how that is implemented in this\napplication. We will also describe the classification model that is built. In the\nsubsequent section, the data is described and results are discussed.\nMethodology\nN-gram\nA character N-gram is an adjacent sequence of n characters from a given text. The\nkey benefit of using N-gram is that textual errors can be handled since each string\nis decomposed in small chunks of text. If an error occurs, this is included in only\na minor number of chunks and all others remains intact. Moreover, one needs not\nto deal with stemming since the corresponding forms of a word (e.g. ‘search’,\n‘searching’, ‘searched’) have a lot in common as it is decomposed into their Ngrams (Cavnar and Trenkle, 1994).\nBased on the idea in Kondrak (2005), we have used the ‘NGramDistance’\nimplementation which is part of the LUCENE software for string comparison.\nThis implementation is in fact an N-gram version of the Levenshtein-Edit\ndistance. This distance describes the minimum number of single-character edits\nthat have to be made in order to change one string to another (Levenshtein, 1966).\nFor the N-gram based edit distance between strings x and y, a matrix\nis constructed where\nis the minimum number of edit\n1152\n\noperations needed to match\nto\n. Each matrix element\nis calculated\naccording to Eqs. (1) – (3), where ‘\n’ is the total number of distinct letters\naccording to their positions between the N-grams\nand is the size of the Ngram.\n(1)\n(2)\n\n{\n(\n(\n\n)\n\n)\n(3)\n\nTo see how the N-grams are compared to calculate (\n), we can examine the\nfollowing example. Assume that 3-grams partitions are being used and the\nunderscores indicate the blanks. The ‘\n’ for “_th” and “_th” 3-grams\ncomparison is 0 while it is 3 for “_th” and “dif” since there is no common letter\nat the same position at all. Nevertheless, the ‘\n’ between the portions “ff.” and\n“ffu” is 2 since there are two same letters at the same positions and (\n) is\n2/3.\nHere it should be mentioned that we use 3-grams considering the length of the\ncomponents on CVs. Since such components as author names or publication year\ncontain short texts, there is no need to use N-grams in big sizes to grab a\nstraightforward similarity.\nThe suggested Levenshtein distance has two features. It normalizes the original\ndistance measure by the length of the longer string to avoid length bias. In\naddition, it adds a null-character prefix of size n-1 such that the initial letter is\ncontained in the same number of N-grams and can be exploited more efficiently\nsince the initial characters are very important in word similarity. It should be\nstressed that null-character prefix matches are discounted so that strings with no\nmatching characters will return maximum distance. Finally, distances are\nsubtracted from 1 to get the similarity scores ranging between 0 and 1, where 1 or\n0 means that the specified strings are identical or maximally different,\nrespectively.As we can expect that publication lists provide detailed bibliographic\ninformation about the publications such as its title, the journal title, the names of\nthe author and co-author(s), publication year, volume and first and end page.\nHowever, it is also very likely that records in the lists do not contain complete\ninformation or do not follow the standards of the database. Therefore, it is\nnecessary to compare each entry in the publication lists with a set of variations\nfrom the database records. For each entry in the publication list and the different\nvariations of the database records, the similarity scores are calculated. Table 1\ngives an overview of all eight variations that were used with the order of\ncomponents. The numbers given in the table indicate the order of the components\n1153\n\nto be used to construct the references from the database records. For each\nvariation the corresponding similarity score for the publication in publication list\nis calculated. Finally the maximum of these similarity scores is also assigned to\nSCORE9 variable for our analysis.\nTable 1: Components in Database and corresponding scores\nComponents\nVariables\nSCORE1\nSCORE2\nSCORE3\nSCORE4\nSCORE5\nSCORE6\nSCORE7\nSCORE8\n\nTitle\n\nJournal\n\nCoauthors\n\nVolume\n\nBegin\nPage\n\nPublication\nYear\n\n2\n2\n1\n1\n1\n1\n-\n\n3\n2\n2\n1\n1\n\n1\n1\n2\n2\n-\n\n4\n3\n3\n-\n\n5\n4\n4\n-\n\n6\n5\n5\n-\n\nTable 2 shows an example of 3-gram similarity scores. One entry from a\npublication list is matched with six different versions of the same paper by using\nits components indexed in the Web Of Science database.\nTable 2: CV and Variable Similarity Scores with 3-grams [Data sourced from\nThomson Reuters Web of Knowledge]\nCV\nWOS\nWOS\nWOS\nWOS\nWOS\nWOS\n\nZhang, L., Thijs, B., Glänzel, W., The diffusion of H-related\nliterature. JOI, 2011, 5 (4), 583-593\nZHANG, L, THIJS, B, GLANZEL, W, The diffusion of Hrelated literature, JOURNAL OF INFORMETRICS, 5, 583,\n2011\nZHANG, L, THIJS, B, GLANZEL, W, The diffusion of Hrelated literature, 5, 583, 2011\nThe diffusion of H-related literature, JOURNAL OF\nINFORMETRICS, 5, 583, 2011\nZHANG, L, THIJS, B, GLANZEL, W, The diffusion of Hrelated literature\nThe diffusion of H-related literature\nThe diffusion of H-related literature, JOURNAL OF\nINFORMETRICS\n\n3-Gram\nVariables Score\nSCORE1\n\n0,67\n\nSCORE2\n\n0.73\n\nSCORE3\n\n0.34\n\nSCORE4\nSCORE5\n\n0.65\n0.36\n\nSCORE6\nSCORE9\n\n0.41\n0,73\n\nDiscriminant Analysis (DA)\nA classification model is made by using Discriminant Analysis (DA). This model\nenables us to automatically classify a match between a publication in the CV and\nan entry from the database as being correct on the basis of the set of N-Gram\n1154\n\nscores. DA requires two important assumptions, namely, multivariate normality\nand homogeneity of variances/co-variances. However, it is observed that none of\nthe assumptions are hold. Therefore, we applied the non-parametric discriminant\nanalysis, namely, Kernel Discriminant Analysis (KDA) which is a powerful\nlearning technique (Taylor and Cristianini, 2004). KDA is a method which\nimplements a linear discriminant analysis in a feature space. That is, a non-linear\nmapping in the input space is handled by a linear mapping by means of a kernel\nfunction. It is based on estimating a nonparametric density function for each\ngroup in the training set and present a classification criterion (SAS 9.2 User\nGuide, 2008). As deriving the best classification results, we have decided to use\nnormal kernel (with mean 0 and variance\n), after trying several other kernels\nsuch as Uniform, Epanechnikov, Biweight and Triweight. Here,\nis the\nvariance-covariance matrix for group t and r is the smoothing parameter to\ndetermine the degree of irregularity in the estimate of density function. Withingroup covariance matrixes are used instead of pooled covariance matrixes in the\nanalysis since the variability between groups are significantly different. Here,\ndeciding the r is the most crucial part of the analysis. As stated in Khattree and\nNaik (2000), trying various values of r and choosing the one working best is the\nsolution.\nWe have implemented KDA for the two sets of variables. The first set comprises\nthe variables SCORE1, SCORE2, SCORE3, SCORE4, SCORE5 and SCORE6\nwhile the second set comprises SCORE9, SCORE5 and SCORE8. While the\nformer set is chosen to examine the variables all including “Title” component and\nits variations, the latter one is chosen to analyse as a relatively more independent\nset with “Maximum”, “Title” and “Journal Name”.\nThis resulted in different training models. Based on these models with the\nestimated group-specific densities, the classifiers could be retrieved that assign\npublication pairs in the test set to one of the two groups.\nData\nTwo large samples of entries from a real world application have been collected.\nThe samples were taken from CV’s and matched with publication lists. These\npairs of reference and publication were separated into training and test sets in\norder to be able to validate the classification model. The first set, training set\nconsists of 6525 publications-reference pairs and all these references were\nmatched manually to an entry in the WOS-database. Matching this data manually\ntook several days in manpower. These pairs are labelled as members of Group 1.\nA second group (Group 0) was created by randomly choosing three unmatched\nrecords from the database for each of the 6525 references. Thus 19575 pairs\nbelong to the Group 0. In addition, we have 2570 pairs in a test set to be classified\ninto Group 1 or Group 0 by using the results from the training set. The\npublications in the test set are completely different from those in the training set.\n\n1155\n\nResults\nUsing the normal kernel with the smoothing parameter r=3 for the set2 variables,\nmuch better results are observed than the normal kernels with other r values and\nthan the other kernels. Table 3 presents the percentages of the classification\naccuracies and the errors for the different values of the smoothing parameter\naccording to the set1 and set2 variables when using normal kernel. We define the\npublications assigned to Group 0 incorrectly as false negatives and the ones\nassigned to Group 1 incorrectly as false positives. It is obvious that the percentage\nof false positives (false negatives) is decreasing (increasing) as r increasing. We\ncan infer that there is a trade-off between these errors and the most balanced case\nis observed for the set2 with r=3 as having the highest accuracy. Here, it should\nbe noted that the smaller number of false positives with a high accuracy is more\nimportant for us since we deal with a sample database. That is, a new publication\nmight not be matched with the publications indexed in the database although it\nexists in WoS. Therefore, our proposed model is the normal kernel with r=3 for\nthe second variable set.\nTable 3: Classification accuracy and error percentages for the different values of\nsmoothing parameter according to the variables in Set1 vs. Set2\n[Data sourced from Thomson Reuters Web of Knowledge]\nset1\n\nset2\n\nr\naccuracy\nfalse negatives\nfalse positives\nr\naccuracy\nfalse negatives\nfalse positives\n\n2\n92.96\n4.48\n6.20\n2\n91.13\n2.63\n10.15\n\n3\n90.3\n13.9\n1.20\n3\n94.9\n5.68\n2.23\n\n4\n78.25\n33.31\n0.20\n4\n90.97\n13.33\n0.62\n\n5\n60.62\n60.53\n0\n5\n82.33\n27.03\n0.16\n\nTable 4 summarizes the classification results according to the proposed model for\nthe publications in the test set. The rows present their observed groups while the\ncolumns present their estimated groups. According to the results, 94.3% of the\npublications belong to Group 1 is classified correctly by the proposed model.\nFurthermore, 97.8% of the publications which is estimated as in Group 1 are\nclassified correctly.\nTable 4: Classification results according to the proposed model\n[Data sourced from Thomson Reuters Web of Knowledge]\nObserved 0\nObserved 1\nTotal\n\n1156\n\nEstimated 0\n862\n95\n957\n\nEstimated 1\n36\n1555\n1613\n\nTotal\n898\n1672\n2570\n\nFigure 1 visualizes the classification problem. It contains two diagrams which\npresent the observed matching group values (left panel) and estimated matching\ngroup values (right panel) for the publications from the CV lists in the test set.\nThe diagram (right) shows that the vast majority of the publications in Group1 is\nclassified correctly. However, with the proposed model, false positives remain as\nan issue as it is seen through the figure.\nHere, it is important to note that maximum matching scores below 0.30 have been\nomitted for the test set. Hence, we have aimed to enhance the performance of the\nmodel while implementing it to the whole database.\nAt this point, it should be mentioned that, in principle, it is possible to find some\nfalse positive matches based on high similarity scores, which, in fact, do not cover\nthe same publication. However, in both the training and test sets, such cases did\nnot occur. Therefore this situation requires further investigation.\n\nFigure 1: The Scatter Plots for Observed (Left) and Estimated (Right) Group Values\nin the Test Set According to the Most Powerful Discriminator Variables (SCORE9\nvs. SCORE5) Exist in the Proposed Model [Data sourced from Thomson Reuters\nWeb of Knowledge]\n\nConclusion\nAlmost 95% of the publications collected from a CV’s publication list could be\ncorrectly matched with the Web of Science database using the proposed model.\nHowever, there are some issues that should be mentioned here. Firstly, a\nsufficiently large publication sample of the WoS has been used. Although this\napproach already provides important insight, the aim should be searching for the\npublications in complete database. Secondly, false positives remain as an issue.\nNormally, these CV publications belong to Group 0, yet the model assigns them\nto Group 1.The tolerance of false positives depends on the application. False\npositive or false negative drawbacks could be overcome using regular\nexpressions. Extracting content-relevant information from publication strings,\ncould possibly improve the accuracy of matching. Eventually, the method applied\nin this paper can especially be leveraged for the evaluation purposes such as job\npromotion cases at micro level or as macro assessment studies, that large number\nof CVs are to be dealt with.\n1157\n\nReferences\nCavnar, W.B. &amp; Trenkle, J.M. (1994). N-Gram-Based Text Categorization. In:\nProceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and\nInformation Retrieval, Las Vegas, US, 161–175.\nKhattree , R. &amp; Naik, D.N. (2000). Multivariate Data Reduction and\nDiscrimination With SAS Software. Cary, NC: SAS Institute Inc. Wiley.\nKondrak, G. (2005). N-gram similarity and distance. Proceedings of the Twelfth\nInternational Conference on String Processing and Information Retrieval\n(SPIRE 2005), pp. 115-126, Buenos Aires, Argentina.\nLevenshtein, V.I. (1966). Binary codes capable of correcting deletions, insertions\nand reversals. Soviet Physics-Doklady, 10, 707-710.\nShawe-Taylor, J. &amp; Cristianini, N. (2000). Kernel Methods for Pattern Analysis.\nCambridge Univ. Press.\nSAS Institute Inc. (2008). SAS/STAT 9.2 User’s Guide. Cary, NC: SAS Institute\nInc.\nLawrence, S., Giles, C.L. and Bollacker, K.D. (1999). Autonomous Citation\nMatching. In: Etzioni, O., Muller, J.P. and Bradshaw, J.M. eds. AGENTS ’99.\nProceedings of the Third Annual Conference on Autonomous Agents, May 15, 1999, Seattle, WA, USA. New York: ACM Press, p.392-393.\nLarsen, B. (2004). References and Citations in Automatic Indexing and Retrieval\nSystems - Experiments with the Boomerang Effect. PhD thesis, Royal School\nof Library and Information Science.\nGiles, C.L., Bollacker, K.D., Lawrence, S. (1998).\nCiteSeer: an automatic citation indexing system. Digital 98 Libraries. Third\nACM Conference on Digital Libraries. Pg. 89-98.\n\n1158\n\nMATHEMATICAL CHARACTERIZATIONS OF\nTHE WU- AND HIRSCH-INDICES USING TWO\nTYPES OF MINIMAL INCREMENTS\nLeo Egghe\nleo.egghe@uhasselt.be\nUniversiteit Hasselt, Campus Diepenbeek, Agoralaan, B-3590 Diepenbeek (Belgium)\nUniversiteit Antwerpen, Stadscampus, Venusstraat 35, B-2000 Antwerpen (Belgium)\n\nAbstract\n\nFor a general increasing function f  n   n  1, 2,3,... we can define the most general\nversion of the Hirsch-index being the highest rank n such that all papers on ranks 1,..., n\neach have at least f  n  citations. The minimum configuration to have this value of n is n\npapers each having f  n  citations, hence we have nf  n  citations in total. To increase the\nvalue n by one we hence need (minimally)  n  1 f  n  1 citations, an increment of\nI1  n    n  1 f  n  1  nf  n  citations. Define the increment of second order as\nI 2  n   I1  n  1  I1  n  . We characterize the general Wu-index by requiring specific values\nof I1  n  and I 2  n  , hence also characterizing the Hirsch-index.\n\nConference Topic\n\nScientometrics Indicators (Topic 1)\n\nIntroduction\nThe most general Hirsch-type index can be defined by using a general increasing\nfunction f  n \n\n n  1, 2,3,... . The definition is as follows. Let us have a set of\n\npapers where the ith paper has ci citations (i.e. received ci citations). We assume\nthat papers are arranged in decreasing order of received citations (i.e. ci  c j if\nand only if i  j ). The most general Hirsch-type index can be defined as the\nhighest rank n such that all papers on ranks 1,..., n have at least f  n  citations.\n\nWell-known examples are f  n   n for the classical Hirsch-index (h-index),\nHirsch (2005), f  n   an\nWu (2010) for a  10 ),\n\n a  0 for the general Wu-index (Egghe (2011) and\nf  n   na  a  0  for the general Kosmulski-index\n\n(Egghe (2011) and Kosmulski (2006) for a  2 ). Note that the general Wu- and\nKosmulski-indices reduce to the h-index for a  1 .\n\n1159\n\nIt is important, at least from a theoretical point of view, to know for these h-type\nindices, how (e.g.) an author can increase his/her h-type index value from n to\nn  1 (for any n = 1,2,...). In other words, it is important to know what effort is\nrequired from an author to increase his/her h-type index by one.\nIn general ci  f  n  for i  1,..., n but in many cases we will have ci  f  n  .\nHowever the minimum situation to have an index equal to n is to have n papers\n\nwith exactly f  n  citations each and where the other papers have zero citations.\nIn this case we have a total of nf  n  citations. To have the minimal situation for\nan index equal to n  1 , we need n  1 papers with exactly f  n  1 citations\neach and where the other papers have zero citations. Now we have a total of\n\n n  1 f  n  1\n\nevery n:\n\ncitations. We define the general increment of order 1 as, for\n\nI1  n    n  1 f  n  1  nf  n \n\n(1)\n\nThe general increment of order 2 is defined as\n\nI 2  n   I1  n  1  I1  n \n\n(2)\n\nI 2  n    n  2 f  n  2  2  n  1 f  n  1  nf  n \n\n(3)\n\nwhich is equal to, by (1)\n\nExamples:\n\n1. For the general Wu-index ( f  n   an ) we have\n\nI1  n   a  2n  1\n\n(4)\n\nI 2  n   2a\n\n(5)\n\nfor all n, as is readily seen.\nThis gives for the h-index:\n\nI1  n   2n  1\n\n(6)\n\nI2  n  2\n\n(7)\n\nfor all n.\n2. For the general Kosmulski-index ( f  n   n ) we have\na\n\nI1  n    n  1\nI 2  n    n  2\nfor all n.\n1160\n\na 1\n\na 1\n\n na 1\n\n 2  n  1\n\na 1\n\n(8)\n\n na 1\n\n(9)\n\n3. For the threshold index (obtained for f  n   C , a constant) (called the\n“highly cited publications indicator” in Waltman and van Eck (2012)) we\nhave\n\nI1  n   C\nI2  n  0\n\n(10)\n(11)\n\nfor all n.\nIn the next section we will characterize the functions f  n  for which (4) is valid.\nIt turns out that we obtain a class of functions much wider than f  n   an and\nfrom this we will characterize the general Wu-index. From this we will also\nobtain a characterization of the h-index. The same will be done for the threshold\nindex.\nIn the third section we will characterize the functions f  n  for which (5) is\nvalid. Again it turns out that we obtain a class of functions much wider than\n\nf  n   an and from this we will newly characterize the general Wu-index.\n\nFrom this we will also refind a characterization of the h-index, already proved in\nEgghe (2012).\nThe paper ends with a conclusions section and with suggestions for further\nresearch.\nCharacterization of functions f  n  that satisfy I1  n   a  2n  1 for all n and\ncharacterization of the Wu- and Hirsch-indices and analogue for the threshold\nindex.\nSo we put, for all n,\n\nI1  n    n  1 f  n  1  nf  n    2n  1 a\n\nHence\n\nf  n  1 \n\nn\n2n  1\nf  n  a\nn 1\nn 1\n\n(12)\n\n(13)\n\nThis shows that we can choose one free parameter: f 1  0 . From (13) we now\nhave\n\nf  2 \n\n1\n3\nf 1  a\n2\n2\n\n(14)\n\n1161\n\nf  3 \n\n1\n8\nf 1  a\n3\n3\n\n(15)\n\nf  4 \n\n1\n15\nf 1  a\n4\n4\n\n(16)\n\n(now also using (14))\n\n(now also using (15)).\n\nFrom this mechanism we can formulate and prove the next Theorem.\nTheorem 1:\n\nI1  n   a  2n  1\nfor all n if and only if\n\nf  n \nfor all n.\n\n1\nn2  1\nf 1 \na\nn\nn\n\n(17)\n\nProof:\nThe proof is by complete induction. It is clear that (17) is valid for n  1 and we\nproved (17) for n  2,3, 4 . Now we suppose that (17) is true for n. For n  1 we\nhave by (12) (hence (13))\n\nf  n  1 \nBy (17) we have\n\nf  n  1 \n\nn\n2n  1\nf  n  a\nn 1\nn 1\n\nn 1\nn2  1 \n2n  1\nf 1 \na  a\n\nn 1  n\nn\nn 1\n\n\n1\na\nf 1 \n n2  1  2n  1\nn 1\nn 1\n n  1 2  1 a\n1\nf  n  1 \nf 1 \nn 1\nn 1\n\nf  n  1 \n\nwhich is (17) for n  1 . Hence (17) is valid for all n.\nReversely, if we have (17), we have to show that (12) is valid. Indeed, for all n\n\nI1  n    n  1 f  n  1  nf  n \n\n1162\n\n 1\n n  1 2  1 a   n  1 f 1  n2  1 a \nI1  n    n  1 \nf 1 \n\n n  \n\nn 1\nn\n n 1\n\n\nI1  n    2n  1 a\nHence (12) is valid for all n.\nNote that, for a  1 , we have a characterization of the Hirsch-type increment\n\nI1  n   2n  1 (see (6)).\n\nFrom Theorem 1 we can prove a characterization of the general Wu-index.\nTheorem 2:\nWe have equivalent of\n(i)\n\nI1  n   a  2n  1 for all n and f 1  a\n\n(ii)\n\nf  n   an for all n (i.e. we have the Wu-index)\n\nProof:\n(i) =&gt; (ii)\nBy formula (17) in Theorem 1 we have for all n\n\nf  n \n\na n2  1\n\na\nn\nn\n\nf  n   na\n(ii) =&gt; (i)\nIt was already shown in the introduction that the Wu-index satisfies (12).\nNote that Theorem 2 for a  1 yields a characterization of the Hirsch-index.\nNote that f  n  in (17) increases if a \n\nf &#x27; n \nif and only if\nfor all n. It suffices to require\n\nf 1\n2\n\n:\n\nn2 a  f 1  a\nn2\n\n0\n\n n2  1 a  f 1\n2a  f 1\n1163\n\nor\n\na\n\nf 1\n2\n\nNow we will prove the analogue result for the threshold index. So let\n\nf  n   C  0 for all n (C: a constant). We showed in the introduction that\n\nI1 (n)  C for all n. Let us characterize all functions f  n  that satisfy this. So\n\nI1  n    n  1 f  n  1  nf  n   C\nfor all n. Hence\n\nf  n  1 \n\nn\nC\nf n \nn 1\nn 1\n\n(19)\n\n(20)\n\nAgain we use the general parameter f 1  0 . We have, by (20)\n\n1\nC\nf 1 \n2\n2\n\n(21)\n\nf  3 \n\n1\n2C\nf 1 \n3\n3\n\n(22)\n\nf  4 \n\n1\n3C\nf 1 \n4\n4\n\n(23)\n\nf  2 \n\n(now also using (21))\n\n(now also using (22)). Hence we can formulate and prove Theorem 3\nTheorem 3:\n\nI1  n   C for all n if and only if\nf  n \nfor all n.\n\n1\nn 1\nf 1 \nC\nn\nn\n\n(24)\n\nProof:\nThe proof is by complete induction. We have already (24) for n  1 and proved\n(24) for n  2,3, 4 . Now we suppose (24) is valid for n. For n  1 we have by\n(20)\n\nf  n  1 \n1164\n\nn\nC\nf n \nn 1\nn 1\n\nf  n  1 \n\nn 1\nn 1  C\nf 1 \nC \n\nn 1  n\nn\n n 1\n\nf  n  1 \n\n1\nf 1  C\nn 1\n\nwhich is (24) for n  1 . So (24) is proved for all n.\nReversely, if we have (24) for all n, we have\n\nI1  n    n  1 f  n  1  nf  n \n\nn\nn 1 \n 1\n\n1\nI1  n    n  1 \nf 1 \nC   n  f 1 \nC\nn 1 \nn\n n 1\nn\n\n\nI1  n   C\nfor all n.\nFrom Theorem 3 we can prove a characterization of the threshold index.\nTheorem 4:\nWe have equivalency of\n(i)\n\nI1  n   C for all n and f 1  C\n\nf  n   C for all n (hence the threshold index).\n\n(ii)\nProof:\n(i) =&gt; (ii)\n\nThis is clear from (24), using that f 1  C\n(ii) =&gt; (i)\nThis was already proved in the introduction.\n\nNote that f  n  in (24) increases if and only if C  f 1 . Indeed\n\nf &#x27; n \n\nC  f 1\n\nif and only if\n\nn2\n\n0\n\nC  f 1\n\n.\n\n1165\n\nCharacterization of functions f  n  that satisfy I 2  n   2a for all n and\ncharacterization of the Wu- and Hirsch-indices and analogue for the threshold\nindex\nSo we put, for all n\n\nI 2  n    n  2 f  n  2  2  n  1 f  n  1  nf  n   2a\n\nHence\n\nf  n  2 \n\n2  n  1\nn2\n\nf  n  1 \n\nn\n2a\nf n \nn2\nn2\n\n(25)\n\n(26)\n\nfor all n. Hence we can choose two free parameters: we choose f 1 , f  2  .\nSince we only want to work with increasing functions f  n  we suppose\n\nf  2   f 1 . By (26) we have\n4\n1\n2a\nf  3  f  2   f 1 \n3\n3\n3\n6\n2\n6a\nf  2   f 1 \n4\n4\n4\n\n(28)\n\n8\n3\n12\nf  2   f 1  a\n5\n5\n5\n\n(29)\n\nf  4 \n(now also using (27))\n\nf  5 \n\n(27)\n\n(now also using (28)).\nHence we can formulate and prove Theorem 5.\nTheorem 5:\n\nI 2  n   2a for all n if and only if\n1\nf  n   2  n  1 f  2    n  2  f 1   n  1 n  2  a \nn\n\n(30)\n\nfor all n.\n\nProof:\nThe proof is by complete induction. We already proved (30) for n  3, 4,5 and is\neasy to see for n  1, 2 . Now we suppose that (30) is valid for n and n  1 . For\nn  2 we have , by (25)\n\n1166\n\n2  n  1  2nf  2    n  1 f 1  n  n  1 a \n\n\nn2 \nn 1\n\nn  2  n  1 f  2    n  2  f 1   n  1 n  2  a  2a\n\n\n\nn2\nn\n n2\n\nf  n  2 \n\nf  n  2 \n\n1\n 2  n  1 f  2   nf 1  n  n  1 a \nn2\n\n(31)\n\nafter an elementary calculation. Now (31) is (30) for n  2 .\nReversely, if (30) is valid for all n, it is an elementary calculation, using (25), that\n\nI 2  n   2a for all n.\n\nFrom Theorem 5 we can prove a characterization of the general Wu-index.\nTheorem 6:\nWe have equivalency of\n(i)\n(ii)\n\nI 2  n   2a , for all n and f 1  a and f  2   2a\n\nf  n   na for all n (hence we have the general Wu index).\n\nProof:\n(i) =&gt; (ii)\nIt follows from (30) in Theorem 5 that, for\n\nf 1  a , f  2   2a that\n\nf  n   na for all n.\n(ii) =&gt; (i)\n\nWe proved in the introduction that the Wu-index satisfies I 2  n   2a for all n.\nNote that, for a  1 , Theorem 6 is a characterization of the Hirsch-index, which\nappeared already in Egghe (2012).\nNote: It is easy to see that f  n  in (30) is an increasing function. This can be\n\nshown using (30) by calculating f &#x27;  n  or by (26) using complete induction (and,\nin both cases, using that f 1  f  2  ).\nFor the sake of completeness we also mention the following characterization of\n\nI 2  n   0 for all n and of the threshold index.\n\n1167\n\nTheorem 7 (Egghe (2012)):\n\nI 2  n   0 for all n if and only if\nf  n \n\n2  n  1 f  2    n  2  f 1\n\nfor all n.\n\nn\n\n(32)\n\nTheorem 8 (Egghe (2012)):\nThe following assertions are equivalent:\n(i)\n(ii)\n\nI 2  n   0 for all n, f 1  f  2   C a positive constant.\nf  n   C for all n, i.e. we have the threshold index.\n\nConclusions and suggestions for further research\nIn this paper we characterized functions for which I1  n    2n  1 a for all n.\nAs a consequence we proved a characterization of the general Wu-index, hence\nalso of the h-index.\nWe then characterized functions for which I 2  n   2a for all n. As a\n\nconsequence we proved a new characterization of the general Wu-index, hence\nalso of the h-index.\nFor the threshold index we executed the same exercise leading to\ncharacterizations of the threshold index.\n\nWe invite the reader to elaborate further studies on I1  n  and I 2  n  , hereby\ncharacterizing other known and new impact indices. We stress the importance of\nsuch studies, at least from a theoretical point of view. Characterizing indices\nwhich require a certain increment of citations in order to increase the index with\none unit shows what effort is required from the author to reach this increase.\nReferences\nEgghe L. (2011). Characterizations of the generalized Wu- and Kosmulski-indices\nin Lotkaian systems. Journal of Informetrics, 5(3), 439-445.\nEgghe L. (2012). A mathematical characterization of the Hirsch-index by means\nof minimal increments. Preprint.\nHirsch J.E. (2005). An index to quantify an individual’s scientific research output.\nProceedings of the National Academy of Sciences of the United States of\nAmerica, 102(46), 16569-16572.\nKosmulski M. (2006). A new Hirsch-type index saves time and works equally\nwell as the original h-index. ISSI Newsletter, 2(3), 4-6.\n\n1168\n\nL. Waltman and N.J. van Eck (2012). The inconsistency of the h-index. Journal\nof the American Society for Information Science and Technology 63(2), 406415.\nWu Q. (2010). The w-index: A measure to assess scientific impact by focusing on\nwidely cited papers. Journal of the American Society for Information Science\nand Technology, 61(3), 609-614.\n\n1169\n\nMEASURING INTERNATIONALISATION OF\nBOOK PUBLISHING IN THE SOCIAL SCIENCES\nAND HUMANITIES USING THE BARYCENTRE\nMETHOD (RIP)\nFrederik T. Verleysen and Tim C.E. Engels\nFrederik.Verleysen@ua.ac.be\nCentre for Research &amp; Development Monitoring (ECOOM), University of Antwerp,\nMiddelheimlaan 1, 2020 Antwerp (Belgium)\nTim.Engels@ua.ac.be\nDepartment of Research Affairs and Centre for Research &amp; Development Monitoring\n(ECOOM), University of Antwerp, Middelheimlaan 1, 2020 Antwerp (Belgium);\nAntwerp Maritime Academy, Noordkasteel-Oost 6, 2030 Antwerp, Belgium\n\nAbstract\n\nUsing places-of-publication barycentres this paper measures the internationalisation of\nbook publishing in the Social Sciences and Humanities (SSH) as practiced at Flemish\nuniversities. Over a ten-year timespan, the barycentre for monographs, edited books and\nbook chapters has moved south-westwards slightly, away from Flanders, Belgium. A\ncomparison of 16 SSH disciplines demonstrates how European continental, British,\nAmerican and other publishers carry a different weight depending on the discipline.\n\nIntroduction\nThis paper examines aspects of internationalisation of scholarly book publishing\nby researchers affiliated with Flemish universities in the period 2002-2011. We\napply the concept of barycentre to the place of publication of peer reviewed\nmonographs, edited books and book chapters. A barycentre of book publishing is\ndefined as the imaginary point at which a flat, weightless but stiff map of the\nworld would balance if weights of identical value were placed on it so that each\nweight represented the place of publication of one monograph, edited book or\nbook chapter (Bartlett, 1985; Jin &amp; Rousseau, 2001). Two aspects of\ninternationalisation are analysed in particular. First, it is determined whether the\nplaces-of-publication barycentre for book publications in the Social Sciences and\nHumanities (SSH) has moved during the period under study. Second, the\nbarycentres for 16 SSH disciplines are calculated with a view of visualising\ndifferences in internationalisation. The further away a barycentre is from the\nbarycentre of the five Flemish universities, the more frequent authors have\npublished with a publisher that is not situated in Flanders. Often this is an\nAnglophone, i.e. British or American publisher. The analysis of full coverage data\non peer-reviewed publications in the SSH has previously shown that SSH journal\narticles are increasingly published in English and in the Web of Science\n1170\n\n(Ossenblok, Engels, &amp; Sivertsen, 2012), two major indications of\ninternationalisation of scholarly SSH research. Adding to this, the comparison of\nbarycentres presented in this paper offers information on aspects of\ninternationalisation of book publishing, thereby broadening the picture of\npublication patterns in the SSH (Hicks, 2004). A growing geographical distance\nof the places-of-publication barycentres to the place of affiliation of the scholar(s)\ninvolved (i.e. the Flemish universities), and hence a smaller role for local\npublishers, would in its own right be indicative of growing internationalisation of\nscholarly book publishing.\nFor Flanders, comprehensive data on SSH book publications is available through\nthe Flemish Academic Bibliographic Database for the Social Sciences and\nHumanities (“Vlaams Academisch Bibliografisch Bestand voor de Sociale en\nHumane Wetenschappen” or VABB-SHW, www.ecoom.be/en/vabb). This\ndatabase was established in 2008-2010 in order to include the peer reviewed SSH\npublications in the regional performance-based research funding system (PRFS)\n(Engels, Ossenblok, &amp; Spruyt, 2012). In order to achieve comprehensive coverage\nof academic publications, the Flemish Government entrusted an independent body\nof academics with the task of selecting the peer reviewed outputs published since\n2000 from the whole of the SSH publications submitted by the universities for\ninclusion in the VABB-SHW. This task proved especially difficult for book\npublications (Ghesquière, Van Bendegem, Gillis, Willems, &amp; Cornelissen, 2011).\nAfter considerable debate, it was decided to include all the book publications by a\nlimited number of 82 publishers that had been identified as the most prestigious\nand selective for the SSH in a similar exercise in Norway (Sivertsen, 2010;\nEngels et al., 2012). Three publishers were added in 2011 and another 33 in 2012.\nIn the PRFS this latest selection of 118 publishers is applied to the preceding 10year window, i.e. the period 2002-2011. In addition, in 2010 the Flemish\npublishers’ association introduced the Guaranteed Peer Reviewed Content\n(GPRC) label in order to allow their members to make peer review of individual\nbooks explicit and to facilitate inclusion of these books in the VABB-SHW\n(Verleysen &amp; Engels, 2013).\nData and methodology\nThe analysis presented in this paper is based on a dataset of 5140 book\npublications by academic scholars affiliated with a university in Flanders from the\nperiod 2002-2011. They belong to 16 SSH disciplines and two general categories.\nThis total comprises 401 monographs, 762 edited books and 3.977 book chapters\ncontained in the VABB-SHW. Of course, since the VABB-SHW collects SSH\npublications by scholars affiliated with a Flemish university, not all chapters that\nappeared in the 762 edited books are included. The majority of the book chapters\ndid appear in edited books published by scholars not affiliated with a Flemish\nuniversity. Hence, although some places of publication are included twice or more\nbecause an edited book as well as one or more chapter therein are included in the\nVABB-SHW, all places of publication are included in the analysis. Places of\n1171\n\npublication were used as available in the VABB-SHW database. Whenever the\ndata contained more than one place of publication the first one mentioned was\nused. Missing places of publication were searched for and added.\nFor the total of 5140 places of publication, the geographic coordinates (latitude\nand longitude) were added in decimal notation to their bibliographic description.\nBarycentres were determined for the 5 consecutive 2-year periods (2002-3:\nn=724, 2004-5: n=756, 2006-7: n=860, 2008-9: n=1248, and 2010-11: n=1389\n[excluding places of publication of GPRC-labelled books for reasons of\ncomparability]) by calculating the weighted average of the relevant coordinates.\nWeighting was done according to the number of publications for any given place\nof publication (Jin &amp; Rousseau, 2001; Rousseau, 1989a; Rousseau, 1989b). The\nresulting barycentre coordinates were located on a Google map using the open\nsoftware tool Geocommons.com.\nOne limitation of this approach is that places of publications may be very far apart\n(Rousseau, personal communication). This may complicate the interpretation of\nthe result. Therefore a second set of barycentres was calculated for the 16 SSH\ndisciplines, restricting the places of publication to European locations only. To\nthis end Europe was defined as the EU (including its acceding or candidate\nmembers Croatia, Iceland, Montenegro, Serbia, the FYR of Macedonia and\nTurkey) plus Albania, Belarus, Moldavia, Norway and Switzerland. As Table 1\nshows, a clear majority of 92% of the places of publications are European.\nTable 1. Number of European and non-European places of publication per\ndiscipline.\nDiscipline\nPsychology (1)\nCommunication Studies (2)\nPolitical Science (3)\nSocial Health Sciences (4)\nEducational Studies (5)\nSociology (6)\nEconomics and Business (7)\nPhilosophy (8)\nArt History (9)\nHistory (10)\nLiterature (11)\nCriminology (12)\nLaw (13)\nArcheology (14)\nTheology (15)\nLinguistics (16)\nAll Disciplines\n\n1172\n\n# of European\nlocations\n79\n92\n251\n26\n161\n141\n325\n441\n225\n318\n605\n104\n436\n60\n441\n660\n4365\n\n# of nonEuropean\nlocations\n38\n16\n45\n6\n28\n19\n35\n35\n17\n19\n34\n5\n26\n2\n35\n18\n378\n\nTotal number of\nlocations\n117\n108\n296\n32\n189\n160\n360\n476\n242\n337\n639\n109\n462\n62\n476\n678\n4743\n\nResults and discussion\nThe barycentre for all 5140 book publications from 2002-2011 is located at\n50.08826° latitude and -2.69505° longitude. This corresponds to a location in the\nEnglish Channel, situated some 50km to the South-West of Weymouth in Dorset,\nUnited Kingdom. This location, well outside Flanders or Belgium, demonstrates\nthe importance of non-Flemish publishers for book publications by Flemish\nscholars. As the barycentre is located some 450 km to the West of Flanders, it is\nespecially indicative of the weight of British and American publishers.\nComparing sub-periods\nWhen comparing the barycentres of the five consecutive 2-year periods, it\nbecomes apparent how the geographic centre of weight of scholarly book\npublishing has moved to the South-West marginally. The various locations again\ndemonstrate the considerable and perhaps growing importance of British and\nNorth American publishers, especially in the most recent years.\n\n(source: VABB-SHW; Geocommons.com; Google Maps)\n\nFigure1. Barycentres for the periods A (2002-3); B (2004-5); C (2006-7); D (2008-9);\nE (2010-11), taking into account all publication places; and X (barycentre of the 5\nFlemish universities’ addresses).\n\nComparing disciplines\nBarycentres for the 16 SSH disciplines lie at a varying geographic distance from\nthe barycentre of the 5 Flemish universities (location X, figure 1). The locations\nof the 16 barycentres stretch out from a point near the Belgian-French border\n(Linguistics=16; Lat. 50.34762°, Long. 3.32916°) to the middle of the Atlantic\nOcean between Brittany and Newfoundland (Psychology=1; Lat. 48.00301°,\nLong. -27.8229°). This alignment of the 16 barycentres along an East-West axis\nindicates considerable differences between disciplines regarding the importance\nof, respectively, Flemish, other continental European, British and American\npublishers.\nNotable in Figure 2 is the discrepancy between the locations of the barycentres of\nthe Social Science disciplines (SS) and those of the Humanities disciplines (H).\nThe barycentres of all Humanities disciplines except Communication Studies are\nlocated in or near the Channel, while those of most Social Science disciplines are\nsituated in the Atlantic Ocean to the South-West of Ireland, or, in the case of\nPsychology, even some 500km further to the West. This illustrates that American\n1173\n\npublishers are of greater importance for the Social Sciences than for the\nHumanities.\nWhen looking at the locations of the barycentres based on the European places of\npublication only, a marked contrast is noticeable between the Social Sciences and\nthe Humanities as well.\n\n(source: VABB-SHW; Geocommons.com; Google Maps)\n\nFigure 2: Barycentres for 16 SSH disciplines (1=Psychology (SS); 2=Communication\nStudies (H); 3=Political Science (SS); 4=Social Health Sciences (SS); 5=Educational\nStudies (SS); 6=Sociology (SS); 7=Economics and Business (SS); 8=Philosophy (H);\n9=Art History (H); 10=History (H); 11=Literature (H): 12=Criminology (SS);\n13=Law (H); 14=Archeology (H); 15=Theology (H); 16=Linguistics (H)), taking into\naccount all places of publication.\n\nFigure 3. Barycentres for SSH disciplines (Europe) (1=Psychology (SS);\n2=Communication Studies (H); 3=Political Science (SS); 4=Social Health Sciences\n(SS); 5=Educational Studies (SS); 6=Sociology (SS); 7=Economics and Business (SS);\n8=Philosophy (H); 9=Art History (H); 10=History (H); 11=Literature (H):\n12=Criminology (SS); 13=Law (H); 14=Archeology (H); 15=Theology (H);\n16=Linguistics (H)), taking into account European places of publication only.\n\nThe Social Sciences&#x27; barycentres are mostly located in the United Kingdom or in\nthe North Sea between the UK and the Netherlands, illustrating the weight of\nBritish publishers. The divergent result for Social Health Sciences (4) needs to be\ninterpreted with caution, as data for this discipline is limited to 32 book\npublications (see Table 1). For all Humanties&#x27; disciplines but Law and\nCommunication Studies, the barycentres are located within Flanders, pointing to\nthe greater weight of Flemish and other continental European publishers.\n\n1174\n\nConclusion\nThe places-of-publication barycentre of monographs, edited books and book\nchapters published by scholars affiliated with Flemish universities in the period\n2002-2011 is situated some 450 km to the West of Flanders and seems to be\nmoving westwards slightly. This finding illustrates the importance of British and\nAmerican publishers for SSH scholarly research at Flemish universities. At the\nsame time, there is a marked difference between the Social Sciences and the\nHumanities. For the Social Sciences, British and American publishers are more\nimportant than for the Humanities. Humanities’ researchers rely more on\npublishers situated in Flanders and elsewhere in continental Europe for the\npublication of their books and chapters.\nThe barycentre method thus proves to be very well applicable to book\npublications. As a first exploration of the method, and more in general of a\ngeographic analysis of book publishing in the SSH, barycentres were located on\nan actual map of the world. In our presentation at ISSI, geometric representations\nof barycentres in standardised polygons (Rousseau, 2008) will be added in order\nto provide additional quantitative insight regarding the evolving role of\ncontinental European, British, American and other publishers over time. We\nconclude that the inclusion of book publications in the study of SSH publication\npatterns remains indispensable and that the barycentre method provides a useful\naddition for measuring aspects of research internationalisation.\nAcknowledgments\nWe thank Ronald Rousseau for comments and suggestions during the preparation\nof this paper.\nReference List\nBartlett, A. A. (1985). U.S. population dynamics. American Journal of Physics,\n53, 242-248.\nEngels, T. C. E., Ossenblok, T. L. B., &amp; Spruyt, E. H. J. (2012). Changing\npublication patterns in the social sciences and humanities, 2000-2009.\nScientometrics, 93, 373-390.\nGhesquière, P., Van Bendegem, J.-P., Gillis, S., Willems, D., &amp; Cornelissen, K.\n(2011). Het VABB-SHW: eerste versie klaar, nu verfijnen. In K.Debackere &amp;\nR. Veugelers (Eds.), Vlaams Indicatorenboek 2011 (pp. 260-264). Brussel:\nExpertisecentrum O&amp;O Monitoring.\nHicks, D. (2004). The four literatures of social science. In H.F.Moed, W. Glänzel,\n&amp; U. Schmoch (Eds.), Handbook of quantitative Science and Technology\nResearch: The use of publication and patent statistics in studies of S&amp;T\nsystems (pp. 473-496). Dordrecht: Kluwer Academic.\nJin, B. &amp; Rousseau, R. (2001). An introduction to the Barycentre method with an\napplication to China&#x27;s mean centre of publication. Libri, 51, 225-233.\nOssenblok, T. L. B., Engels, T. C. E., &amp; Sivertsen, G. (2012). The representation\nof the social sciences and humanities in the Web of Science. A comparison of\n1175\n\npublication patterns and incentive structures in Flanders and Norway (2005-9).\nResearch Evaluation, 21, 280-290.\nRousseau, R. (1989a). Kinematical Statistics of scientific output. Part I:\ngeographical approach. Revue Française de bibliométrie, 4, 50-64.\nRousseau, R. (1989b). Kinematical statistics of scientific output. Part II:\nstandardized polygonal approach. Revue Française de bibliométrie, 4, 65-77.\nRousseau, R. (2008). Triad or Tetrad: another representation. ISSI Newsletter, 4,\n5-7.\nSivertsen, G. (2010). A performance indicator based on complete data for the\nscientific publication output at research institutions. ISSI Newsletter, 6, 22-28.\nVerleysen, F. T. &amp; Engels, T. C. E. (2013). A Label for Peer-Reviewed Books.\nJournal of the American Society for Information Science and Technology, 64,\n428-430. Doi: 10.1002/asi.22836.\n\n1176\n\nMEASURING THE ACADEMIC IMPACT OF\nRESEARCHERS BY COMBINED CITATION AND\nCOLLABORATION IMPACT\nJielan Ding 1, Liying Yang 1, Qing Liu 2\n1\n\ndingjielan@mail.las.ac.cn, yangly@mail.las.ac.cn\nNational Science Library of the Chinese Academy of Science\n33 Beisihuan Xilu, Zhongguancun, Beijing, 100190 (P.R.China)\n2\n\nliuqing@mail.whlib.ac.cn\nThe Wuhan Branch of the National Science Library of the Chinese Academy of Science\n25 west of xiaohongshan, Wuchang Dist, Wuhan, 430071 ( P.R.China).\n\nAbstract\n\nTo evaluate the academic impact of researchers in a more comprehensive way, this paper\nutilizes both the citing and collaborating aspects which are the two main forms occurring\nin scientific communication. Three citation-based indicators and three collaboration-based\nindicators are selected and combined into two dimensions by using factor analysis. Then\nbased on the position of the researchers in a two dimensional coordinate system, career\nroles and career paths of researchers can be revealed. Finally, we provide a theoretical\nframework for describing the career roles of researchers by the combination of citation\nimpact and collaboration impact.\n\nIntroduction\nIn bibliometrics many studies focus on exploring the academic impact of\nresearchers. It is well accepted that academic impact is produced during scientific\ncommunication; therefore measuring the academic impact should be based on the\nprocess of scientific communication. Citing and collaboration are the two main\nforms of scientific communication which can be measured by bibliometric\nmethods. Many published results of investigations are related to citing and\ncollaboration impact.\nMost studies concentrated on citation analysis and the indicators used are citationbased, such as total citations, h-index, and citations per publication. This kind of\nstudies stems from the impact in the process of citing, so we refer to this kind of\nresearch as “citation impact studies”(e.g. Garfield,1999; Hirsch,2005;\nEgghe,2006; Jin, Liang&amp;Rousseau,2007; Moed, 2011; Leydesdorff &amp;Bornmann,\n2011; Rousseau, 2012).\nAnother way to detect the impact of researchers, different from using citation\nindicators is collaboration analysis. With the widely application of social network\nanalysis (SNA) in the field of scientometrics, more and more researchers apply\nSNA measures to detect academic impact (e.g., Leydesdorff, 2007; Bollen, Van\nde Sompel, Hagberg &amp;Chute, 2009), especially in collaboration network (e.g.,\n1177\n\nNewman 2001a,b; Liu, Bollen, Nelson, &amp; Van de Sompel, 2005; Rodriguez &amp;\nPepe, 2008). For researchers’ impact study, the micro-level network indicators,\nsuch as degree centrality, closeness centrality, and betweenness centrality, are\nused for measuring researchers’ impact in collaboration networks (Yan &amp; Ding,\n2009). This kind of research studies the impact produced in collaboration, so we\nrefer to it as “collaboration impact studies”.\nThere is no doubt that citation and collaboration can each describe one aspect of\nacademic impact of researchers. To measure the academic impact of researchers\nin a more comprehensive way, the two aspects can be combined, in particular as\nthey have a positive relationship (Yan &amp; Ding, 2009; Levitt, Thelwall &amp; Levitt,\n2011). A researcher’s citation impact is the degree of attention aroused by his\nacademic achievement, so the citation impact represents his academic level to\nsome extent. The collaboration impact reflects one’s importance in a certain\nresearch community. So, we claim that a combined analysis reflects authors’\nstatus in a certain field.\nThis article aims to obtain both the citation impact and collaboration impact of\nresearchers leading to a more comprehensive way of measuring academic impact.\nUsing a set of indicators based on the two dimensions and factor analysis, we\nattempt to describe: (1) the career roles of researchers by a combined analysis of\nthe two dimensions; (2) the career paths of researchers by measuring changes in\nboth dimensions.\nMethodology\nDatasets\n\nFigure 1. The number of authors and papers of SCIENTOMETRICS in 1978-2012.\n(download date:2013.01.08)\n\n1178\n\nWe took the field of scientometrics as an example to apply and test our method.\nThe study focuses on the combined method, and the journal SCIENTOMETRICS\nis the most specialized and typical journal in this field, so the study selected all\nthe papers from SCIENTOMETRICS as dataset, though one journal on its own can\nnever describe the entire career of a scientist.\nWe download the data of SCIENTOMETRICS from the Web of Science on 8\nJanuary, 2013. The time span is from 1978 to 2012. There are 3376 papers and\n3419 different authors after manual data cleaning of authors in the dataset. The\nyearly data of number of authors and papers of SCIENTOMETRICS is shown in\nFigure 1. Because the increase in the number of papers and authors after the year\n2000 is bigger than that before the year 2000, we chose the year 2000 as the cutoff point for detecting the change of impact in the two periods which is the\nreference year for describing the career paths of the authors. The distribution of\nauthors is shown in Table 1, and the data shows that about 10% authors, who\npublished at least four papers in the period 1987-2012 published over 50% of all\npapers.\nTable1. The distribution of authors.\nthreshold of authors\npublished at least 5\npapers\npublished at least 4\npapers\npublished at least 3\npapers\npublished at least 2\npapers\ntotal\n\n1978-2012\n( total dataset )\nauthors\npapers\ncounts\n\n%\n\n1978-1999\n(sub-dataset I )\nauthors\npapers\n\ncounts\n\n%\n\n81\n\n6.9%\n\ncounts\n\n%\n\n2000-2012\n(sub-dataset II )\nauthors\npapers\n\ncounts\n\n%\n\n223\n\n6.5%\n\n1797 53.2%\n\ncounts\n\n325\n\n9.5%\n\n2018 59.8% 119 10.2% 785 54.5% 210\n\n495\n\n14.5% 2271 67.3% 175 14.9% 694 48.2% 340 13.8% 1245 64.3%\n\n982\n\n28.7% 2663 78.9% 342 29.2% 1088 75.5% 688 27.9% 1475 76.2%\n\n677 47.0% 134\n\n%\n\n5.4%\n\ncounts\n\n%\n\n911 47.1%\n\n8.5% 1065 55.0%\n\n3419 100.0% 3376 100% 1172 100% 1441 100% 2470 100% 1935 100%\n\nIndicators for the two dimensions\nA single indicator describes just one aspect of academic impact, but impact is\nmulti-dimensional. Therefore for each dimension we chose a group of indicators\nfrom different perspectives to measure the academic impact of researchers.\nFor the citation impact dimension, total citations, CPP, and h-index were chosen\nto measure the researchers’ citation impact as these are commonly used for\nacademic impact evaluation. We calculated the three indicators based on the\ncitations which the papers published in SCIENTOMETRICS received from all\npapers in WOS.\nFor collaboration impact dimension, closeness centrality, which means one\ndivided by the total geodesic distance from a node to all others, was chosen to\nmeasure the authors’ impact over the entire collaboration network, and degree\ncentrality, which means the number of neighbors of a node, was chosen to\nmeasure the authors’ impact over the local collaboration network. The\n1179\n\ncollaboration ratio, which means the ratio of collaboration papers among all\npapers one published, was chosen to measure the depth of collaboration impact.\nCloseness centrality and degree centrality are network indicators which were\ncalculated in PAJEK based on the SCIENTOMETRICS -collaboration network.\nWe calculated the selected six indicators for each author in the total dataset. These\nindicators form the base for measuring their career roles. Career paths are based\non these six indicators, calculated separately for the sub-dataset I (1978-1999) and\nthe sub-dataset II (2000-2012).\nFactor Analysis\nTable 2. Rotated Component Matrixa.\nThe total dataset of 1978-2012\n(KMO: 0.674)\nComponent\n1\n2\ntotal_cites\nCPP\nh_index\n\nThe sub-dataset of 1980-1999\n(KMO: 0.659)\nComponent\n1\n2\n\n.927 .135 total_cites\n.628 .033 CPP\n\n.936 .166 h_index\ncollaboration ratio -.205 .884 collaboration ratio\n\n.963\n.544\n\nThe sub-dataset of 2000-2012\n(KMO:0.679 )\nComponent\n1\n2\n\n.149 total_cites\n.171 CPP\n\n.928 .104\n.748 -.047\n\n.193 h_index\n.925 .119\n-.022 .906 collaboration ratio -.180 .877\ndegree centrality\n.520 .642 degree centrality\n.392 .750 degree centrality\n.490 .680\ncloseness centrality .359 .622 closeness centrality .332 .764 closeness centrality .518 .422\nExtraction Method: Principal Component Analysis. Rotation Method: Varimax with Kaiser\nNormalization. a. Rotation converged in 3 iterations.\n.928\n\nWe chose factor analysis to reduce the six indicators to two integral indicators in\norder to measure authors’ citation and collaboration impact. We did this for two\nreasons: on the one hand, factor analysis is an objective weighted method of\ndetecting the relationship among a group of indicators; on the other hand, the\nthree citation-based indicators and the three collaboration-based indicators have a\npositive relationship and their interpretation overlaps to some extent. Therefore\nthese indicators can’t be simply added.\nFor the authors who published at least four papers in the total dataset, we took\nfactor analysis based on their six indicator scores to obtain their citation impact\nand collaboration impact to describe their career roles. We did the same thing to\nthe authors who published at least four papers in the sub-dataset I (1978-1999)\nand in the sub-dataset II (2000-2012) in order to detect their career paths.\nAfter factor analysis by SPSS 16.0, the six indicators were reduced to two main\ncomponents for the total dataset and the two sub-datasets. The results are shown\nin table 2. A varimax rotation was applied to measure loadings in order to make\nthe components easier to interpret. For the three datasets (sub-datasets), most\nloadings of the three citation-based indicators are on the first component which\nwe name “citation impact” and most loadings of three collaboration-based\n1180\n\nindicators are on the second component which we refer to as “collaboration\nimpact”. We note that the two components are orthogonal so there is no linear\ndependence between the two.\nMeasuring career roles and career paths for each author\nAfter factor analysis, taking the citation impact component as the abscissa and the\ncollaboration impact component as the ordinate axis, we got each author’s\nlocation in the Cartesian coordinate system. Each author is located in one of the\nfour quadrants in the two dimensional Cartesian coordinate system. As the four\nquadrants represent four different career roles we can describe the career role of\neach author.\nTo some extent, the ascent and descent of a researcher’s citation impact could\nrepresent the change of his academic level while the change of a researcher’s\ncollaboration impact could represent the change of his activity in collaboration.\nSo the change of authors’ impact on the two dimensions can reveal the career\npaths of researchers.\nResults\nThe career roles of researchers in SCIENTOMETRICS\nWe took the 325 authors in Scientometrics who published at least four papers in\nthe period 1978-2012 as examples to describe their career roles by using the two\ndimensional coordinate system. Then we got the location of each author in the\nfour quadrants which represent four different career roles. The results are shown\nin figure 2 and the extraordinarily high citation impact authors whose citation\nimpact scores are higher than two are shown on the map. There are 64 authors\nlocated in the top right quadrant, 50 authors located in the bottom right quadrant,\n139 authors located in the top left quadrant and 72 authors located in the bottom\nleft quadrant.\nThe authors located in the top right quadrants have both high citation impact and\ncollaboration impact. They not only published highly cited papers which appeal to\na lot of people, but also play an important role in scientific collaboration. These\nauthors usually have a very prestige in the field of scientometrics, for example\n“Glänzel, Wolfgang”, “Schubert, Andras”, “Van Raan, AFJ”, “Braun,Tibor”,\n“Moed, Henk F”, “Leydesdorff, Loet”, “Meyer, Martin S”, “van Leeuwen, Thed\nN”, “Rousseau, Ronald”, “Persson, Olle”, etc. These high citation and\ncollaboration impact authors are the excellent and core authors.\n\nThe authors located in the bottom right quadrant have high cited papers but\nthey rarely collaborate or they are located in the periphery of the\ncollaboration community. Taking “Small, Henry”, “Egghe, Leo”, “Vinkler,\nPeter” for example, they are excellent researchers in scientometrics who\nare Derek John de Solla Price award winners, but they seldom collaborate,\nespecially “Vinkler, Peter” who never collaborated in all his 31\n\n1181\n\nSCIENTOMETRICS papers. These authors of high citation impact but low\ncollaboration are the excellent and lonely (like to work alone) authors.\nThe authors located in the top left quadrant are very active in collaboration,\nbut relatively ordinary in academic impact. Most internationally oriented\nChinese authors who have high prestige in China in the field of\nscientometrics are placed in this quadrant. Authors of high collaboration\nimpact but low citation impact are the ordinary and core authors.\nThe authors located in the bottom left quadrant have both low citation and\ncollaboration impact who are the ordinary and lonely authors. They are\nordinary in academic achievement and in the periphery of the collaboration\nnetwork.\n\n(The origin of coordinates is (0,0) which means the average level of the citation and collaboration\nimpact. The authors whose citation impact score are higher than 2 are marked with their names)\n\nFigure 2. The career roles of the 325 authors in SCIENTOMETRICS who published\nno less than 4 papers in year 1978-2012.\n\nThe career paths of researchers in SCIENTOMETRICS\nWe defined seven career paths according to the change of position based on\nimpact score in two periods for each dimension. These are shown in Table 3.\nThere are seven career paths for each dimension; therefore there are 49\ncombinations representing 49 different possibilities of authors’ career status\nshown in table 4. highly characteristic highly characteristic\nWe focused on the career path of top authors, and we took the top 20% authors as\nthe top authors for the sub-dataset of year 1978-1999 (first period) and the subdataset of year 2000-2012 (second period) for each dimension. There are 96 “top\nauthors” who get into the list of the top authors in citation or collaboration\n1182\n\ndimension in at least one period. They form the examples for our career paths\nanalysis. Their career paths are shown in Table 5.\nTable 3. The definition of seven career paths.\nDescription of\nauthors\n\ncareer paths\n\nthe score in first period\n\nPlateau\nNew force\nFall\nRise\nDecline\nGo up\n\n&gt;=A\n—\n&gt;=A\n&lt;A\n&gt;=A\n&lt;A\n\nthe score in second period\n\n&gt;=B\n&gt;=B\n—\n&gt;=B\n&lt;B\nothers\n&lt; B,and higher than the\nscore of former period\nGo down\n&lt;A\n&lt; B,and lower than the\nscore of former period\n(A and B are thresholds for selecting the top 20% authors for each time period which are\nshown in table 4. “—” means the author didn’t have a score because he published less\nthan 4 papers and didn’t occur in sample dataset.)\ntop authors\n\nTable 4. Values of A and B for selecting the top 20% authors.\ndimensions\ncitation impact\ncollaboration impact\n\nA (threshold for first period)\n0.41\n0.95\n\nB (threshold for second period)\n0.47\n0.63\n\nTable 5. The career paths of the 96 top authors (profile).\ncollaboration impact\nplateau new force rise go up go down decline\ncitation impact\nplateau\n2\n3\n6\n4\nnew force\n6\n15\nrise\n1\n2\n2\n2\ngo up\n3\n27\n2\n1\ngo down\n1\ndecline\n1\n1\n1\nfall\n5\n1\n\nfall\n11\n-\n\nThe authors whose career path is “new force” in citation dimension and “going\nup” in collaboration dimension are likely the “new force” who shifted from other\nfields to this field. They are absent in citation impact dimension in this field in the\nfirst period, but jump to be top researcher by publishing some highly cited papers\nin the second period. At the same time they have not yet constructed a broad\npartnership in this field. Porter, Alan L. is such an example (being an expert in\ndata mining and industry-university relations).\n1183\n\nThe authors whose career path is “new force” both in citation dimension and\ncollaboration dimension are likely the new excellent researchers who grow up in\nan excellent community of this field. They didn’t occur in the first period dataset,\nbut jumped to be a top researcher in both dimensions in the second period. Liang,\nLiming is a case in point, collaboration with Rousseau, Ronald.\nThe authors whose career path is “plateau” in the collaboration dimension and\n“going up” or “rising” in the citation dimension are located in the center of the\ncollaboration network work in the two periods and become more excellent in\nacademic achievement in the later period, such as “Noyons, ECM”.\nThe authors whose career path is “plateau” in citation dimension and “rising” or\n“going up” in collaboration dimension are excellent in academic achievement and\nbecome active in collaboration and get to the core position of the collaboration\nnetwork. Taking “Glänzel, Wolfgang”, “Rousseau, Ronald”, “Leydesdorff, Loet”\nfor example, their citation impact was very high in the two periods and in the\nsecond period they get to be located in the central position of the collaboration\nnetwork.\nMost internationally oriented Chinese authors’ career path is “new force” in\ncollaboration dimension and “going up” in citation dimension. Collaboration\nobviously increases their impact.\nThe authors who retired and stopped doing research in scientometrics end up in a\n“going down” or “falling” position. Taking “Narin, Francis” for example, his\ncareer path is “falling” in citation dimension and “going down” in collaboration\ndimension. He established CHI in 1968, an internationally recognized research\nconsultancy company specializing in developing evaluation tools and indicators\nfor science and technology analysis, and obtained the Derek John de Solla Price\naward in 1988. He retired from CHI in 2004.\nConclusion\nSince scientific collaboration becomes more and more popular, it is well accepted\nthat researchers’ citation impact and collaboration impact are equally essential.\nThis investigation took the citing and collaboration dimensions simultaneously\ninto account, leading to a new approach to measure the academic impact of\nresearchers in a more comprehensive way.\nBy combined analysis of citation impact and collaboration impact, we can\ndiscover the detailed information about authors’ career status, such as career roles\nor career paths. Based on empirical results, we provided a framework to\ndescribing the career roles of researchers which is shown in Figure 3. The origin\nof coordinates means the average level. A researcher’s citation impact represents\nhis academic level. We used “excellent” to describe researchers when their\ncitation impact is higher than the average level and used “ordinary” to describe\nresearchers when their citation impact is lower than the average level. The\ncollaboration impact can usually reflect one’s importance in a research\ncommunity. We used “core” to describe researchers when their collaboration\nimpact is higher than the average level and used “lonely”( like to work alone) to\n1184\n\ndescribe when their collaboration impact is lower than the average level. Thus we\ncan describe the researchers by using four career roles. If someone has a high\nscore in both citation impact and collaboration impact, he/she is probably an\nexcellent and core researcher. If someone has a high score in citation impact but a\nlow score in collaboration impact, that person is very likely an excellent and\nlonely researcher in the field. If someone has a high score in collaboration impact\nbut low score in citation impact, he is probably an ordinary and core researcher. If\nsomeone has a low score in both citation impact and collaboration impact, he is\njust an ordinary and lonely researcher (at least at the moment of investigation).\nFor S&amp;T policy makers, identifying researchers in the quadrant we proposed may\nhelp them in finding key researchers, possibly with high collaboration (social)\nskills.\n\nCollaboration impact\n\nexcellent and core\nresearchers\n\nordinary and core\nresearchers\n\nordinary\nresearchers\n\n0\n\nexcellent and\nlonely\nresearchers\n\nCitation impact\nFigure 3: A framework for revealing the career roles of researchers\n\nBy detecting the impact changes in two dimensions in different time windows, we\ncould distinguish various career paths for each researcher. The researchers who\nare top researchers in citation impact for the two periods and become more active\nin collaboration impact are the “evergreen tree” scientists of this field. The “new\nforce” researchers are those who were not main researchers (they published less\nthan 4 papers) in the first period and turned to be top researchers in the second\none. They could perhaps be described as “dark horses” in this field. Finding those\ndifferent types of researchers is also a way to evaluate researchers from different\nperspectives.\nIn empirical study, we detected the career roles and career paths of authors in\nSCIENTOMETRICS. The result may not reflect the real lifetime career roles or\npaths for researchers as the dataset is limited to one journal, but it certainly\nprovides (partial) information of scientists’ profiles active in our field. We use the\n1185\n\ncombined method in the field of scientometrics and we will do further study of\napplying the method in other fields to detect the validity of the method.\nAcknowledgements\nThe study was supported by Knowledge Innovation Program of The Chinese\nAcademy of Sciences (Project NO. 10XZNL9). We thank Ronald Rousseau for\ngiving critically valuable advice and making a lot of linguistic corrections. We\nfurther thank Prof. Alan Porter (Georgia Tech) and Ting Yue (National Science\nLibrary of CAS) for helpful discussions.\nReferences\nGarfield,E. (1999). Journal impact factor: A brief review. Canadian Medical\nAssociation Journal, 161(8),979–980.\nHirsch, J. E.(2005). An index to quantify an individual’s scientific research\noutput. Proceedings of the National Academy of Sciences of the USA,102 (46)\n: 16569- 16572.\nEgghe, L.(2006). Theory and Practise of the g-index. Scientometrics, 69(1):131152.\nJin, B.H.; Liang, L.M. &amp;Rousseau, R.(2007). The R- and AR-indices:\nComplementing the h-index. CHINESE SCIENCE BULLETIN, 52(6): 855863.\nMoed, H.F.(2011). Measuring contextual citation impact of scientific journals.\nJOURNAL OF INFORMETRICS,4(3): 265-277.\nLeydesdorff,L. &amp;Bornmann,L.(2011). Integrated Impact Indicators Compared\nWith Impact Factors: An Alternative Research Design With Policy\nImplications. JOURNAL OF THE AMERICAN SOCIETY FOR\nINFORMATION SCIENCE AND TECHNOLOGY,62(11): 2133-2146.\nRousseau, R.(2012). Basic Properties of Both Percentile Rank Scores and the I3\nIndicator. JOURNAL OF THE AMERICAN SOCIETY FOR\nINFORMATION SCIENCE AND TECHNOLOGY,63(2): 416-420.\nBollen, J. , Van de Sompel, H. , Hagberg, A. &amp; Chute, R. (2009). A principal\ncomponent analysis of 39 scientific impact measures. PLoS ONE ,4(6), e6022.\nLevitt, M.J., Thelwall,M., &amp; Levitt, M. (2011). To what extent does the citation\nadvantage of collaboration depend on the citation counting systems? In: (E.\nNoyons, P. Ngulube &amp; J. Leta, Eds.) Proceedings of ISSI 2011—13th\nInternational Conference of the International Society for Scientometrics and\nInformetrics, pp.398–408. Durban: ISSI, Leiden University and University of\nZululand.\nLeydesdorff, L. (2007).“Betweenness Centrality” as an Indicator of the\n“Interdisciplinarity” of Scientific Journals. Journal of the American Society for\nInformation Science and Technology, 58(9), 1303–1319.\nLiu, X., Bollen, J., Nelson, M.L.,&amp; Van de Sompel, H. (2005). Co-authorship\nnetworks in the digital library research community. Information Processing\nand Management, 41,1462-1480.\n1186\n\nNewman, M.E.J. (2001a). Scientific collaboration networks: I. Network\nconstruction and fundamental results. Physical Review E, 64, 016131.\nNewman, M.E.J. (2001b). The structure of scientific collaboration networks.\nProceedings of the National Academy of Science of the United States of\nAmerica, 98(2), 404-409.\nRodriguez, M.A. &amp; Pepe, A. (2008). On the relationship between the structural\nand socioacademic communities of a coauthorship network. Journal of\nInformetrics, 2(3), 195-201.\nYan, E.J. &amp; Ding, Y. (2009). Applying centrality measures to impact analysis: a\ncoauthorship network analysis. Journal of the American Society for\nInformation Science and Technology, 10, 2107-2018.\n\n1187\n\nMEASURING THE EXTENT TO WHICH A\nRESEARCH DOMAIN IS SELF-CONTAINED\nAlan L. Porter1, David J. Schoeneck2, Stephen J. Carley3\n1\n\nalan.porter@isye.gatech.edu\nTechnology Policy &amp; Assessment Center, Georgia Tech, Atlanta GA, USA 30332-0345,\nand\nSearch Technology, Inc., Norcross GA USA 30092\n2\n\ndaves@searchtech.com\nSearch Technology, Inc., Norcross GA USA 30092\n3\n\nstephen.carley@innovate.gatech.edu\nProgram in Science, Technology &amp; Innovation Policy, Georgia Tech, Atlanta GA, USA\n30332-0345\n\nAbstract\n\nFor several years we have been working to measure cross-disciplinarity, especially trying\nto determine interdisciplinary integration of diverse knowledge. Existing indicators,\nparticularly our own Integration and Diffusion scores, speak to disciplinary engagement,\nbut not directly to whether knowledge is being transferred from areas heretofore not wellconnected to a research domain. This paper introduces simple metrics that gauge 1) the\nextent to which a research domain references papers generated within that domain vs.\noutside publications, and 2) the extent to which a domain’s publications are cited within\nitself vs. outside. We address three emerging technologies as case research domains –\nNano-Enabled Drug Delivery, Hybrid &amp; Electric Vehicles, and Dye-Sensitized Solar\nCells. We first tabulate and map their disciplinary locations based on Web of Science\nCategories. We then calculate the new metrics to offer additional perspectives on\nknowledge diffusion.\n\nConference Topic\n\nScientometrics and Indicators – new developments (Topic 1)\n\nIntroduction\nMeasuring interdisciplinarity is of interest in terms of research planning and\nassessment, and social studies of science. Stirling (2007) presents a compelling\nconceptual basis for considering diversity in terms of variety, balance, and\ndisparity. This fits well with an indicator for the “integration” of disparate\nknowledge (c.f., Porter et al., 2008) and its application (c.f., Porter and Rafols,\n2009). For a comprehensive treatment of measuring interdisciplinarity, see the\nreview of the state of the art by Wagner and colleagues (2011). The Integration\nscore just noted gauges the diversity of the references cited by a given paper or set\nof papers. Conversely, one can address the diversity of document sets that cite a\n1188\n\npaper or set of papers (Zitt &amp; Small, 2008). In this respect, Carley and Porter\n(2012) provide an index to measure forward diversity – called a Diffusion score.\nMany such indicators make use of existing categorizations, especially the Web of\nScience (WoS) Subject Categories (WOSCs)112 that are treated here. Rafols and\nMeyer (2010) point out that diversity in cited WOSCs does not assure true\nintegration of disparate knowledge sources in a given body of research. Our\nmeasures rely on Web of Science categories, and do a reasonable job of depicting\ndisciplinary engagement.\nHowever, they don’t really address whether\npublications and citations reflect knowledge transfer among disparate areas, or\njust that a research domain straddles multiple WOSCs\nInterest in assessing the extent to which a given research area draws upon\n“outside” knowledge prompts the present inquiry. We address three research\ndomains and inquire to what extent they cite research not inherently part of the\ntarget research domain, and to what extent the research they produce interests\nothers (i.e., is cited outside the domain).\nOver the past few years, several of us have been analyzing Dye-Sensitized Solar\nCells (DSSCs) – an emerging photovoltaic technology. We have observed that\nthis research domain seems remarkably cohesive. For instance, in a set of 4,104\nrecords from WoS through 2010, without cleaning to consolidate variations on\ncitations of the same paper, we find one paper cited 2,396 times (i.e., by 58% of\nthe DSSC papers in the whole set). Moreover, 101 papers are cited 100 or more\ntimes, by these 4,104 papers. Social network maps of co-authors, co-cited\nauthors, or such show strong interconnection.\nIn the past months, we have been studying two other R&amp;D domains – Hybrid &amp;\nElectric Vehicles (HEVs) and Nano-Enabled Drug Delivery (NEDD). HEVs\nreflect a more mature technology with multiple sub-systems. NEDD pulls\ntogether materials science with bio-medical research, incorporating a multitude of\nintertwined drug, transport mechanism, and target possibilities. Casual discussion\nsurfaced our sense that these research domains are much less cohesive than\nDSSCs. As a simple indicator, among 61,465 NEDD records from WoS through\n2012, the most cited reference (before consolidating) has only 1,538 hits (so only\n2.5% of the retrieved NEDD papers cite any one reference – in contrast to the\n58% just noted for DSSCs).\n\n112\n\nOne needs to be aware that since late 2011WoS provides this information in the field called\n“WC” that formerly was called “SC”; they provide other, somewhat more aggregated categories\nunder the label, “SC.” This paper consolidates old SC and new WC information -- there are some 8\ncategories unique to the old SCs and some 7 unique to the new WCs, of the set of some 224\ncovering Science Citation Index and Social Sciences Citation Index WOSCs, plus additional ones\nfor the Arts and Humanities Citation Index.\n1189\n\nReflecting on the apparent differences among these three research domains sparks\ntwo research questions that this paper addresses:\n1. Q1: For a given research domain, to what extent is knowledge internal, in\nthe sense that papers cite references within the domain (vs. external\npapers – i.e., those not retrieved by the domain search)?\n2. Q2: Conversely, to what extent is the knowledge generated in that domain\nof external interest, in the sense that papers published receive relatively\nhigh proportion of cites (to them) from outside?\nThis paper sets forth to measure citation patterns for the three research domains\nnoted – DSSCs, HEVs, and NEDD. We believe results will be of interest in our\nstudies of these emerging science &amp; technology areas (these are completely\nseparate analyses). We are also interested in the potential of such citation metrics\nto help in the study of research knowledge diffusion patterns and the forces that\npromote or impede transfer processes. Assessing how “porous” research domains\nare, in terms of citation in and out, would seem to offer potential insight into how\nself-contained research areas are. We are not aware of others having done this.\nOf course, citations are made for multiple motives and have their limitations in\nindicating knowledge transfer at work.\nData and Methods\nVarious colleagues have worked out suitable search strategies for the three\ndatasets under study here (see Appendix). Using those, search sets of WoS full\nrecords, including Cited References (CRs) have been downloaded recently. The\ndate ranges vary somewhat so that is a consideration (e.g., might citation patterns\nbe changing over time?). The basic data include (see Appendix for details):\n DSSCs – 8919 records from 1991 through 2012 (peaking at 1924 records\nin 2012; note that 2012 publications are not completely indexed by WoS\nat the time of search)\n HEVs – 7323 records from 2000 through 2012 (peaking in 2011,with\n2012 incompletely indexed at 1025 records)\n NEDD – 61,465 records from 2000 through 2012 (with 14 in 2013,\npeaking with 9463 in 2011, and 2012 incompletely indexed, with 8120\nrecords downloaded).\nIn each of these WoS abstract record sets, there are multiple document types,\ndominated by journal articles and proceedings papers. The frequency of citation\nis highly skewed, as one would expect, and the overall number of Cited\nReferences (CRs) is large. For instance, for NEDD:\n 1,141,623 CRs are identified with 1 or more cites by the 61,465 papers\n 366,890 CRs with 2 or more cites\n 42,735 CRs with 10 or more cites\n 1045 CRs with 100 or more\n 19 CRs with 500 or more\n1190\n\nWe apply thesauri in VantagePoint [www.theVantagePoint.com], software\ndesigned to facilitate analyses of field-structured records, especially R&amp;D\npublication and patent sets such as these. These thesauri help provide information\non:\n Cited WOSCs, based on extraction of Cited Journal information from the\nCRs, then application of a Find &amp; Replace thesaurus to help standardize\nnomenclature, followed by a thesaurus that links those journals to\nWOSCs\n Macro-Disciplines and Cited Macro-Disciplines, based on analyses of\nWoS journal-to-journal cross-citation, converted to WOSC-to-WOSC\ncross-citation, then factor analysed to group the WOSCs based on their\naffinities (see Leydesdorff and Rafols, 2009; Rafols et al., 2010;\nLeydesdorff et al., 2013). This WOSC citing matrix is also essential for\nthe science overlay mapping coming up.\nFor this study, we encountered a decision about which CRs to examine (i.e., we\ncould not analyze all of them). Table 1 compares alternative selection\npossibilities. The “Top 200” seem to offer a reasonable middle ground for our\npurposes. We expand slightly to take ties – e.g., 212 HEV CRs had 20 or more\ncites. [We note that these are uncleaned counts.]\nTable 1. Highly Cited References\nCriterion\nDSSCs HEVs NEDD\nResearch Domain Set Size (# of papers)\n8,919 7,323 61,465\n100 or more cites by this many papers in the research domain set\n310\n10\n1,045\nTop 200 Cited References are cited at least this many times\n134\n20\n222\n\nWe next take these target ~200 CRs for each research domain and apply fuzzy\nmatching routines to identify additional CRs that likely refer to the same papers.\nThese include two important variations: a) CRs with and without DOI\ninformation; and b) CRs with variant information (e.g., the seminal O’Regan and\nGraetzel DSSC paper, 1991, cited 5,192 times by these 8,919 papers, we find\nfrequent variants -- e.g., O’Reagan or slightly variant page and volume\ninformation).\nFor these top cited ~200 in each dataset, we filtered the CR field text to take first\nauthor’s name, year, and first journal title word (after testing some alternatives).\nWe then made a group in VantagePoint of ~650 CRs, in the NEDD set that match\nthose (similar process used for HEVs &amp; DSSCs). We make that into a thesaurus\nand apply it to consolidate these ~200 CRs. This concentrates the CRs – e.g., the\nmost cited one for NEDD increases from 1,538 to 1,576. This process is not\nperfect, but satisfactory – hand-checking indicates 1,578 (adding one cited only\nby last name, not adding another also published in Nature in 2001 with a different\n1191\n\npage number). The second most cited CR increases from 1,279 to 1,304; handcheck suggests 1,302 (leaving out two in different issues of Nature, same year).\nThe third most cited jumps from 1,090 to 1,352 (hand-check agrees). So, this\nconsolidation helps. After consolidation, further analyses key on these highly\ncited references:\n 190 NEDD CRs, 207 HEV CRs, and 198 DSSC CRs.\nOur design to address the two research questions uses the highly cited CRs to do\n“double-duty.” To address Q1 (looking back to see how much of the cited\nknowledge is internal), we check to see how many of these CR papers are\nthemselves part of the paper set. We limit this inquiry to high CRs published in\nthe time frame of the research domain set (i.e., 2000-2012 for NEDD and HEVs;\n1991-2012 for DSSCs).\nTo address Q2, we study the subset of those high CRs that are included in the\nresearch domain set (just identified in addressing Q1). We search for those\nrecords to capture their current Times Cited in WoS (“TC”), then compare those\nvalues to the # of times each is cited by the respective research domain papers.\nFor the 207 HEV high CRs, we located and downloaded 175 (31 of the 32 not\nfound had no DOI, so apt to be items not indexed by WoS – e.g., books). Of the\n175, 144 were published 2000-2012 (in the time range covered by our HEV paper\nset). Combining information from the HEV papers file with that from the\ndownloaded CR records, we check TC against HEV TC (cites by the HEV papers\nset) for those 144 papers. In 7 of 144 cases, this shows negative, and in 2 it is\nzero, so we recheck and correct. We find many CRs that are hard to classify. In\nchecking these 9, for instance, we have to deal with multiple CRs for that author,\nthat year, and the same first word in the source title. We also find CRs with\ndifferences on some of those fields, but compelling matches on other fields –\nDOI, author, year, volume, and/or page #. We sometimes see differences in\nauthor initials; we see some with a term in front of the typical cited source; and so\nforth. Some CRs without DOI or page # are a judgment call (we manually do so\nby taking into account what other papers show by that first author in the CRs).\nAfter checking, 3 HEV high CRs still show as negative on our best estimates – 1\nshows 1 more citation by the HEV papers than in all of WOS; 2 show 33 more.\nFor purposes of this analysis, we set all of those to be the same (i.e., TC = HEV\nTC) – i.e., all observed cites coming from the HEV records set.\nWe don’t go into such detail for the other two sets. For NEDD, consolidation of\nthe ~200 reduced to 188, of which 148 were published in the period, 2000-2012;\nof those 96 are in the NEDD papers set. For DSSCs, consolidation of the ~200\nreduced to 198, of which 193 were found in WoS. We set aside 3 published prior\nto 1991, leaving 190 for further analyses.\n\n1192\n\nResults\nWe first present descriptive statistics and disciplinary maps to gain a sense of\nwhat these three research domains encompass.\nWe locate the respective bodies of research on science overlay maps (Rafols et\nal., 2010) in Figure 1. These are scaled unequally (because the NEDD dataset is\nso much larger) just to show the relative disciplinary concentrations. The lower\nright map is the base map reflecting all WoS publications in 2010, with the nodes\nindicating 224 WOSCs and the labels showing the 19 Macro-Disciplines. The\nthree research area maps overlay the respective publication intensity (larger node\nsize indicating more publications in journals associated with that WOSC).\n\nFigure 1. Overlaying the 3 Research Domains over a Base Map of Science\n\n\n\n\n\nHEVs show a highly multidisciplinary picture, led by Computer Science\nareas, with notable contributions in Materials Sciences, Environmental\nScience &amp; Technology, and Mechanical Engineering. Note that this\nresearch domain, unlike the others, has considerable activity in\nMathematical Methods, and in Economics, Political Science &amp;\nGeography.\nDSSC research concentrates heavily in Materials Sciences, with notable\ncontributions in Environmental Science &amp; Technology, followed by\nChemistry and Physics.\n1193\n\n\n\nNEDD shows major activity in Biomedical Sciences and Materials\nSciences, followed by notable research publication in Clinical Medicine,\nChemistry, and Infectious Diseases. There is also extensive work\nappearing in Cognitive Sciences, Environmental Science &amp; Technology,\nand Physics.\n\nWe also tabulate the relative frequencies for publication Macro-Disciplines\n(MDs) (using record counts) and Cited Macro-Disciplines (using instances – i.e.,\nif a paper cites 20 Physics papers, we tally those as 20 rather than just counting\nthis as 1 record citing Physics). We then divide by the totals for each dataset and\ntake percentages of the totals. Table 2 compares the 19 MDs and Cited MDs for\neach research domain. These provide MD values that correspond to the research\nconcentrations visualized in Figure 1 in the “MDs (pubs)” columns. The\nprevalence of Materials Sciences is apparent.\nTable 2. Research Domain Publication &amp; Citation Concentrations by MacroDisciplines\nHEVs\nDSSCs\nNEDD\nMDs (pubs) Cited MDs MDs (pubs) Cited MDs MDs (pubs) Cited MDs\n% records % instances % records % instances % records % instances\nAgri Sci\n0.1%\n0.1%\n0.1%\n0.2%\n0.8%\n1.4%\nBiomed Sci\n0.5%\n1.7%\n1.8%\n4.6%\n40.9%\n48.6%\nBusiness &amp; MGT\n0.8%\n1.3%\n0.0%\n0.0%\n0.0%\n0.0%\nChemistry\n0.2%\n0.7%\n6.5%\n5.5%\n6.3%\n4.5%\nClinical Med\n0.2%\n0.2%\n0.2%\n0.2%\n8.8%\n7.4%\nCognitive Sci\n0.1%\n0.4%\n0.1%\n0.1%\n2.8%\n2.7%\nComputer Sci\n41.4%\n29.5%\n2.3%\n0.3%\n0.3%\n0.2%\nEcol Sci\n0.3%\n0.3%\n0.1%\n0.1%\n0.2%\n0.1%\nEcon Polit &amp; Geog\n2.2%\n2.4%\n0.0%\n0.0%\n0.0%\n0.0%\nEnviron Sci &amp; Tech\n16.3%\n17.7%\n12.6%\n6.7%\n1.3%\n0.9%\nGeosciences\n0.9%\n0.6%\n0.1%\n0.1%\n0.1%\n0.1%\nHealth &amp; Social Issues\n1.4%\n1.1%\n0.0%\n0.0%\n0.2%\n0.2%\nInfectious Diseases\n0.0%\n0.1%\n0.1%\n0.1%\n4.4%\n4.9%\nMaterials Sci\n17.1%\n32.8%\n71.1%\n78.8%\n32.1%\n27.2%\nMath Methods\n4.9%\n2.6%\n0.4%\n1.4%\n0.2%\n0.7%\nMech Eng\n12.3%\n7.4%\n0.8%\n0.6%\n0.4%\n0.4%\nPhysics\n1.1%\n1.1%\n3.9%\n1.2%\n1.2%\n0.6%\nPsychology\n0.1%\n0.0%\n0.0%\n0.0%\n0.0%\n0.0%\nSocial Studies\n0.1%\n0.1%\n0.0%\n0.0%\n0.0%\n0.0%\n\nMacro-Disciplines\n\nHowever, the main interest is to get a coarse view of the degree to which these\nresearch domains draw upon knowledge concentrated in the same, or other,\ndisciplines in which they publish. Some observations:\n HEVs: Publish considerably more heavily in, than they cite, journals that\naggregate to the Computer Sciences, Mechanical Engineering, and Math\n1194\n\n\n\n\n\n\nMethods. Conversely, they draw more heavily than they publish in\nMaterials Sciences and several less central MDs (e.g., Biomedical\nSciences, Chemistry). This suggests research knowledge diffusion from\nthe sciences toward engineering applications.\nDSSCs: Publish relatively more than they cite Environmental Science &amp;\nTechnology, Physics, and Computer Sciences; cite relatively more\nheavily Biomedical Science and Math Methods. This is a different\ndistribution than the HEVs show, but also suggests knowledge transfer\nfrom fundamental science and math toward application considerations\n(e.g.,environmental).\nNEDD: Publications generally track citations.\nThe above notes point to interesting differences, but also note the\ndominant tendency to publish where you cite – e.g., DSSCs in Materials\nSciences; NEDD in Biomedical Sciences and Materials Sciences.\n\nTo address research question Q1, we investigate the “~200” heavily cited\nreferences of each dataset, leaving out those published prior to our search year\nrange. We check whether those CRs are themselves included in the dataset.\nResults show:\n NEDD: 96 of 148 = 65% “internal” (i.e., high CRs themselves in the\nNEDD\npapers\nset)\nand in number of cites by the NEDD paper set to these 148 papers –\n34,982 are to those 96 internal papers and 18,807 are to the other 54\n“external” papers = 65% internal also\n HEV: 114 of 144 = 79% internal\nand in number of cites by the HEV paper set to those 144 papers – 5,062\nare to those 114 internal papers and 885 are to the other 30 external\npapers = 85% internal\n DSSCs: 172 of 190 = 91% internal\nand in number of cites by the DSSC paper set to the 190 papers – 50,470\nare to the 172 internal papers and 4,981 to the other 18 external papers =\n91% internal.\nTo address Q2, we are interested only in papers in the target research set to see\nhow many of the cites to them (TCs) are by papers also within the target domain.\nFor this study, we analyze just the highly cited (high CR) subset that are also\nidentified as being in the research domain search set (e.g., 96 for NEDD, after researching WoS for TCs; recall our cleaning combined some CRs that should have\nbeen separate). This yields:\n NEDD: 96 papers cited 64,519 times in WoS, of which 34,982 are cites\nby our NEDD papers set (54% internal)\n HEV: 114 papers cited 8,522 times in WoS, of which 5,062 are cites by\nour HEV papers set (59% internal)\n\n1195\n\n\n\nDSSCs: 172 papers cited 73,752 times in WoS, of which 50,470 are cites\nby our DSSC papers set (68% internal).\n\nA sidenote – these “Q2” analyses focus on the highly cited CRs in our target\npaper sets. In the search process, we gathered data on other of those highly cited\nCRs that are NOT in our target paper sets. For HEVs, for example, we note that\nsome of those “external” CRs are very heavily cited outside the HEV paper set.\nNamely, of those 30 external CRs, 6 are cited over 1,000 times in WoS, in\ncontrast to 20-51 cites by the HEV paper set. Five of those 6 were published in\nNature or Nature Materials. For the DSSCs, one external paper stands way out\nwith 38,255 cites in WoS vs. 288 by our DSSC paper set.\nDiscussion\nThe extent to which research domains stand apart – as proverbial “silos” – is\nimportant in terms of structures and processes to facilitate R&amp;D productivity,\ncreativity (i.e., through interdisciplinary exchange), and innovation [transferring\nknowledge toward technological development and applications (consider\n“translational” research to contribute to clinical practice in the biomedical arena)].\nThis study offers some new measures to offer new perspectives on such\nknowledge interchange, in addition to presenting some established tallies and\nmaps.\nThe measures presented offer multiple perspectives. It is useful to see the subject\ncategories (WOSCs) and Macro-Disciplines represented in a research domain\n(Figure 1). Comparing citation to publication behaviour helps see how these align\nfor research domains (Table 2). We note that the journal is a more precise unit of\nanalysis when compared with the journal grouping using WOS Categories (Rafols\net al., 2010; Leydesdorff &amp; Rafols, 2012; Leydesdorff, Carley &amp; Rafols, in press).\nSo, overlay maps based on journals promise more precise location of research\nactivity.\nBut, such aggregations do not let us know to what extent a research endeavor is\ninterdisciplinary in drawing together previously disparate knowledge. That is – is\nthe research actually “integrative” (National Academies Committee, 2005) – in\nthe sense of combining formerly separate knowledge (Rafols and Meyer, 2010)?\nThat issue prompts exploration of the measures pursued here to distinguish\namalgams of relatively separate research from novel interchanges of knowledge.\nThe current measures devised address the two research questions reasonably\neffectively. Regarding Q1 -- to what extent does the research domain reference\nexternal research? -- results indicate an ordering for our three sample sets, from\nDSSCs most internally oriented, to HEV research, to NEDD research, which\nappears most avaricious in drawing upon external research. Regarding Q2 -- to\nwhat extent do other fields cite the work of the research domain relative to its\n1196\n\nself-citing? -- we find a similar progression, with DSSC (highly cited) papers\nreceiving the most cites from within the field, to HEV research, to NEDD,\nreceiving the highest proportion of cites by external papers. The ordering for the\nthree sample cases fits our field knowledge gained in studying these emerging\ntechnologies. On the other hand, we recognize that changes in the search\nalgorithms would alter the nature of the areas and the resulting scores – e.g., much\nNEDD research targets cancer and our search deliberately does not search on\ncancer terms per se; were such publications to be included, the self-containedness\nwould surely change. Also, we focused on ~200 highly cited records in these\nanalyses; again, a more or less inclusive set would alter the measures. Further\nresearch on sensitivity to such attributes would add considerable value to the\nmeasures.\nThese simple citation counting measures offer promise, but are no means\nsufficiently tested or refined for general adoption. We note that tabulation is not\nautomatic because CRs are not reported completely consistently. The clumping\nalgorithm we used worked pretty well at consolidating CR variations, but\nwarrants further exploration. We believe clumping errors, on balance, tend to\noverestimate the within-domain counts. “Giants” (papers with huge numbers of\ncites received) pose an additional challenge in deciding how best to treat them in\narriving at measures of central tendency. We report means (averages) here as the\ntarget sets were not unduly sensitive to such papers, but would look for a more\nrobust strategy (perhaps focusing on something like the 10-90th percentile range),\nbut alternatives remain to be compared.\nThe measures introduced here could certainly be “translated” to other scales. Of\nspecial interest might be to explore how these score for research threads – much\nsmaller, more discrete research area characterizations (Boyack et al., 2012). And\nconversely, Boyack et al. (2009) have mapped citation “flows” into and out of\nlarger aggregations (namely, chemistry and related subject categories, in that\npaper) and how those have changed over time. In between, examination of the\nknowledge flows (indicated by citations in and out) among sub-fields within a\nresearch domain could prove informative in better managing R&amp;D. For instance,\nmight a hypothetical case be made that DSSC researchers could benefit by being\nmore attentive to dye research from outside their field? Going further, one\nreviewer noted that it would be interesting to examine how self-containedness\nrelates to expansibility and sustainability of research domains. One could\nimagine studying such phenomena at various scales, from research threads on up.\nMany factors could affect self-containedness. Emerging research areas would\nseem apt to transition from “nothingness” to a degree of awareness of others’\nresearch as relevant, and, perhaps, beyond -- to phases in which specialization\nwithin the area grows and sub-fields branch off. Thinking about DSSCs, HEVs,\nand NEDD – differences in research norms as one spans different domains would\n1197\n\nseem a factor. These three emerging technologies also seem inherently different\nin the degree to which they would focus externally or not – NEDD addresses\nmanifold applications of multiple technologies, whereas DSSCs all address one\nfamily of related means to achieve a singular end of effective solar energy\nconversion. HEVs are embedded in innovation processes engaging complex\ntransportation systems and policies that seem wider in scope than DSSC research\nissues at this time. We offer our simple self-containedness measures as tools to\nstudy such factors.\nMultiple perspectives are highly desirable in characterizing the “selfcontainedness” of a research domain. We offer the present simple calculations as\neasy-to-understand indicators. We see nice potential in multiple mappings, noting\nthe journal-based overlay possibilities to locate research domains in science, and\nalso in terms of core journals and their relatedness (Leydesdorff and Rafols, 2012;\nLeydesdorff et al., to appear). We see promise in mapping the respective\ngenerations. For instance, take NEDD. We intend to generate co-citation maps to\nhelp characterize the “knowledge source” domain – separately for the internal and\nexternal CR sets. Given that we have gathered their WoS records, we can try\nthese based on first or all authors, and/or individual papers, and/or on institutions.\nConversely, we also want to examine the co-citing patterns, but those pose greater\nchallenge in data gathering.\nAnother extension would be to compare these self-containedness metrics with\nother indicators for given research areas. For instance, one could compare these\nthree areas in terms of co-author or co-citation network densities. Bibliographic\ncoupling comparisons would also be quite interesting. Furthermore, it could be\nfruitful to pursue bibliographic coupling maps and measures to see if those\ndistinguish sub-systems within a given research domain (e.g., who cites different\nsegments of the CR space?).\nWe offer the present simple measures and early results to stimulate consideration\nof such possible indicators of research domain “porosity.” We see these as\ndialogue and experimentation starters, not finished products.\nAcknowledgements\nThis research was undertaken at Georgia Tech drawing on support from the\nNational Science Foundation (NSF) Science of Science Policy Program -“Revealing Innovation Pathways” (Award No. 1064146). The findings and\nobservations contained in this paper are those of the authors and do not\nnecessarily reflect the views of the National Science Foundation.\n\n1198\n\nReferences\nArora, S.K., Porter, A.L., Youtie, J. &amp; Shapira, P. (2013). Capturing new\ndevelopments in an emerging technology: An updated search strategy for\nidentifying nanotechnology research outputs, Scientometrics, 95 (1), 351-270.\nBoyack, K. W., Borner, K. &amp; Klavans, R. (2009). Mapping the structure and\nevolution of chemistry research. Scientometrics, 79, 45-60.\nBoyack, K.W., Klavans,R., Small, H.,&amp; Ungar, L. (2012). Characterizing\nemergence using a detailed micro-model of science: Investigating two hot\ntopics in nanotechnology, Portland International Conference on Management\nand Engineering Technology (PICMET), Vancouver.\nCarley, S. &amp; Porter, A.L.(2012). A forward diversity index, Scientometrics, 90 (2), 407–\n27.\nLeydesdorff, L., Carley, S. &amp; Rafols, I. (2013). Global maps of science based on the new\nWeb-of-Science categories, Scientometrics, 94 (2), 589-593.\n\nLeydesdorff, L. &amp; Rafols, I. (2009). A Global map of science based on the ISI\nSubject Categories. Journal of the American Society for Information Science\nand Technology, 60 (2), 348-362.\nLeydesdorff, L. &amp; Rafols, I. (2012). Interactive overlays: A new method for\ngenerating global journal maps from Web-of-Science data, Journal of\nInformetrics, 6 (2), 318-332.\nLeydesdorff, L., Rafols, I. &amp; Chen, C. (to appear). Interactive overlays of journals\nand the measurement of interdisciplinarity on the basis of aggregated journaljournal citations. Journal of the American Society for Information Science and\nTechnology.\nMa, T., Porter, A.L., Ready, J. Xu, C., Gao, L., Wang, W. &amp; Guo, Y. (under\nrevision). A technology opportunities analysis model: applied to DyeSensitized Solar Cells for China, Technology Analysis and Strategic\nManagement.\nNational Academies Committee on Facilitating Interdisciplinary Research,\nCommittee on Science, Engineering and Public Policy (COSEPUP) (2005).\nFacilitating interdisciplinary research. (National Academies Press,\nWashington, DC).\nPorter, A.L., Cunningham, S.W. &amp; Sanz, A. (to appear). Extending the FIP\n(Forecasting Innovation Pathways) approach through an automotive case\nanalysis, Portland International Conference on Management and Engineering\nTechnology (PICMET), San Jose, California, 2013.\nPorter, A.L. &amp; Rafols, I. (2009). Is science becoming more Interdisciplinary?\nMeasuring and mapping six research fields over time, Scientometrics, 81(3),\n719-745.\nPorter, A.L., Roessner, J.D. &amp; Heberger, A.E. (2008), How interdisciplinary is a\ngiven body of research?, Research Evaluation, 17 (4), 273-282.\nRafols, I. &amp; Meyer, M. (2010). Diversity and network coherence as indicators of\ninterdisciplinarity: case studies in bionanoscience. Scientometrics, 82(2), 263287.\n1199\n\nRafols, I., Porter, A.L. &amp; Leydesdorff, L. (2010). Science overlay maps: A new\ntool for research policy and library management. Journal of the American\nSociety for Information Science and Technology, 61 (9), 1871–1887.\nStirling, A. (2007). A general framework for analysing diversity in science,\ntechnology and society. Journal of The Royal Society Interface, 4 (15), 707719.\nWagner, C.S., Roessner, J.D., Bobb, K., Klein, J.T., Boyack, K.W., Keyton, J.,\nRafols, I. &amp; Borner, K. (2011),. Approaches to understanding and measuring\ninterdisciplinary scientific research (IDR): A review of the literature, Journal\nof Informetrics, 5165, 14-26.\nZhou, X., Porter, A.L., Robinson, D.K.R. &amp; Guo, Y. (to appear), Analyzing\nResearch Publication Patterns to Gauge Future Innovation Pathways for NanoEnabled Drug Delivery, Portland International Conference on Management\nand Engineering Technology (PICMET), San Jose, California, 2013.\nZhou, X., Porter, A.L., Robinson, D.K.R. &amp; Guo, Y. (to appear), Patent and\nPublication Comparison for One Emerging Industries -- Nano-Enabled Drug\nDelivery, 14th International Society of Scientometrics and Informetrics (ISSI)\nConference, Vienna, 2013.\nZitt, M. &amp; Small, H. (2008). Modifying the journal impact factor by fractional\ncitation weighting: The audience factor, Journal of the American Society for\nInformation Science and Technology, 59 (11), 1856-1860.\nAppendix\nThe DSSC search has been developed by Ying Guo and Tingting Ma through a\nseries of analyses over the past few years (Ma et al., under review). It was rerun\nfor the present study on 22 Jan., 2013, for 1991-2012 in WoS (including SCIexpanded, SSCI, CPCI-S &amp; SPCI-SSH) The main search phrase is:\n\n\nTS= (((dye-sensiti*) or (dye* same sensiti*) or (pigment-sensiti*) or (pigment\nsame sensiti*) or (dye* adj sense)) same ((solar or Photovoltaic or photoelectr*\nor (photo-electr*)) same (cell or cells or batter* or pool*)))\n\nAdditional phrases used:\n\n\n\n\n\nTS= (((dye- Photosensiti*) or (dye same Photosensiti*) or (pigmentPhotosensiti*) or (pigment same Photosensiti*)) same ((solar or Photovoltaic or\nphotoelectr* or (photo-electr*)) same (cell or cells or batter* or pool*)))\nTS= (((dye- optoelectri*) or (dye same optoelectri*) or (pigment- optoelectri*) or\n(pigment same optoelectri*) or (dye- opto-electri*) or (dye same opto-electri*) or\n(pigment- opto-electri*) or (pigment same opto-electri*)) same ((solar or\nPhotovoltaic or photoelectr* or (photo-electr*)) same (cell or cells or batter* or\npool*)))\nTS = (((dye and (conduct* or semiconduct*)) same electrode*) and electrolyte*)\n\nThis yielded 8919 records.\n\n1200\n\nSearch for HEVs was conducted as part of an exercise in “FIP” -- Forecasting\nInnovation Pathways (Porter et al., to appear). The search used here was run on\n22 Jan., 2013 for 2000-2012 in WoS (including SCI-expanded, SSCI, CPCI-S &amp;\nSPCI-SSH) for:\nts= ((electric or hybrid) near/2 (vehicle or vehicles or automobile or\nautomobiles or car or cars))\nIt yielded 7720 records, from which articles (3496) and proceedings papers\n(4384), for a total of 7323 records were downloaded. The HEV search used in the\nFIP exercise was iteratively devised and incorporated many subsystem search\nmodules (e.g., on mechanical energy recovery, thermal management, batteries,\nelectric motors for EVs, fuel cells for cars, electromagnetic brakes, flywheels,\nhydrogen storage, lightweight materials &amp; vehicles, etc.\nThe NEDD search in WoS was based on an earlier search strategy from 2009,\niteratively revised with expert review over about 9 months in 2012 (Zhou et al., to\nappear). The basic strategy is to combine Delivery terms AND Nanotechnology\nterms AND (Pharma terms or highly selective Target terms). In the 2009 search,\na major component concerned the Target of cancer; this was not explicitly\nincluded here. This search included 7 modules. The following were addressed to\na Nano subset of WoS (Arora et al., 2013) OR to records containing alternative\nterms – (viral* OR colloid* OR dendrimer*):\n\n\n\n\n\nTS=((deliver* or vehicle* or carrier* or vector* or &quot;control* releas*&quot;) Near/4\n(Drug* or pharmacy)\nTS=((deliver* or vehicle* or carrier* or vector* or &quot;control* releas*&quot; or\ntransduct* or transfect* or transport* or translocat*) Near/4 agent*)\nTS=((deliver* or vehicle* or carrier* or vector* or &quot;control* releas*&quot; or\ntransfect*) Near/4 formulation*)\nTS= (deliver* or vehicle* or carrier* or vector* or treat* or therap* or &quot;control*\nreleas*&quot; or transduct* or transfect* or transport* or translocat*) Near/4 (DNA or\ngene)\n\nThe following were addressed to WoS:\n\n\n\n\nTS=((deliver* or vehicle* or carrier* or vector* or treat* or therap* or &quot;control*\nreleas*&quot; or transduct* or transfect* or transport* or translocat*) Near/4 (siRNA\nor &quot;short interfering RNA&quot;))\nTS= (deliver* or vehicle* or carrier* or vector* or treat* or therap* or &quot;control*\nreleas*&quot; or transduct* or transfect* or transport* or translocat*) Near/4 (Dox or\nDoxorubicin*)\nTS=((deliver* or vehicle* or carrier* or vector* or treat* or therap* or &quot;control*\nreleas*&quot;or transfect*) Near/4 (&quot;RNA interference&quot; or RNAi))\n\nThis yielded 61,465 records.\n\n1201\n\nA METHOD FOR TEXT NETWORK ANALYSIS:\nTESTING, DEVELOPMENT AND APPLICATION\nTO THE INVESTIGATION OF PATENT\nPORTFOLIOS (RIP)\nLuciano Kay1\n1\n\nluciano@cns.ucsb.edu\nCenter for Nanotechnology in Society (CNS), University of California Santa Barbara,\nSanta Barbara, CA (USA)\nGeorgia Tech Program in Science, Technology and Innovation Policy (STIP), Georgia\nInstitute of Technology, Atlanta, GA (USA)\n\nAbstract\n\nThis research explores Text Network Analysis (TNA) as an alternative method to analyze\nscientific and patent literature. This paper introduces the TNA method and presents some\nresults of algorithm testing, development and implementation. We exemplify the practical\nimplementation of the method with the analysis of a set of patent records by Japanese\ncompanies in the field of nanotechnology applied to energy storage solutions between\n2000 and 2009. Although this is a research in progress paper, we are able to identify some\nfeatures and potential issues in the use of the TNA method to investigate science,\ntechnology and innovation topics using scientific publication and patent data.\nImprovements and calibration of this method are under development.\n\nConference Topic\n\nVisualisation and Science Mapping: Tools, Methods and Applications (Topic 8) and\nTechnology and Innovation Including Patent Analysis (Topic 5).\n\nIntroduction\nA number of approaches have been developed to analyze scientific publication\nand patent document data and investigate a broad range of phenomena related to\nscience, technology and innovation topics. Those approaches involve, for\nexample, metrics to identify most frequent or relevant terms found in the\nacademic and patent literature (e.g. word frequencies and term frequency–inverse\ndocument frequency TF-IDF) and term clumping and identification of concepts\nusing “topic modelling” and clustering techniques such as Principal Component\nAnalysis (Porter et al., 2012).\nThis research explores Text Network Analysis (TNA) as an alternative method to\nanalyze scientific and patent literature. TNA is a set of methods to extract\nmeaning and identify pathways for meaning circulation from text corpora based\nupon conceptual linkages (Paranyushkin, 2011). The TNA analysis draws on the\nanalysis of co-occurrence of words-phrases in the text and the application of\n1202\n\nsocial network analysis techniques. It has been applied, for example, to the\nanalysis of transcripts (Broniatowski, 2012) or rhetoric in scientific publications\n(Long, 2012) (this is generally not academic literature.) Among the alleged\nadvantages of this approach there are the ability to effectively identify the most\ninfluential concepts that produce meaning and the possibility of performing\ncomparative analysis of different kinds of texts.\nA method for Text Network Analysis\nIn this paper we present some results of the testing, development and\nimplementation of TNA analysis applied to patent literature. This process follows\nfour main steps which are further developed in the rest of the paper:\nData extraction. This step involves the identification of “terms” or sets of wordsphrases from the source text. Herein, we start with a set of patent application\nrecords, we merge both title and abstract fields and extract “NLP phrases” using\nthe Natural Language Processing (NLP) routine available in VantagePoint textmining software. Then we extract word-phrases (hereafter, simply “terms”) using\nanother automation macro developed by the author that further cleans up the list\nof NLP phrases and discards irrelevant terms.\nText network creation. TNA requires representing the source text in an\nadjacency matrix format to identify concepts and develop metrics. We do this\nusing the co-occurrence matrix creation routine available in VantagePoint. The\nresulting undirected, weighted matrix is the adjacency matrix used as an input for\nthe next steps.\nClustering. The terms are clustered to form more or less homogeneous groups,\ni.e. clusters of terms that are better connected among them than with the rest of\nthe co-occurrence network formed by the terms. We apply the Markov Cluster\n(MCL) algorithm to cluster terms according to their co-occurrence in titles and\nabstracts of patent documents. The MCL algorithm is a scalable unsupervised\ncluster algorithm for networks based on simulation of stochastic flow in graphs\n(more information on MCL is at http://micans.org/mcl/).\nConcept analysis. We apply a measure of betweenness centrality to the clusters\nfound in previous steps to identify key concepts or themes within each set.\nAlgorithm testing and development\nTo test and develop this method we use data from EPO Patstat on patent\napplications in the nanotechnology for energy storage field. Energy storage\ntechnologies are those defined by the OCDE patent search strategy in terms of\nIPC classes and ECLA codes. We use the keyword-based definition of\nnanotechnology described in Porter et al. (2008). We use a subset of patents from\nall patent authorities filed by Japanese companies between 2000 and 2009. This\ndataset comprises 262 patent applications (only patent documents in English\nlanguage are included.) The VantagePoint NLP phrases creation routine applied\nto titles and abstracts and further automated work to clean up terms yield 304\nwords/phrases (Table 1).\n1203\n\nTable 1. Top-15 terms in the Japanese corporate nanotechnology for energy storage\npatent applications dataset (2000-2009)\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\nTerms\nCarbon Nanotubes\nDye-Sensitized Solar Cell\nLithium Ion Battery\nElectrolyte\nFuel Cell\nFullerene\nNon-Aqueous Electrolyte\nCarbon Nanofibers\nCarbon Fibers\nSecondary Battery\nElectrodes\nCounter Electrode\nElectrochemical Capacitors\nElectrode Substrate\nHexagonal Carbon\n\nPatent records\n45\n40\n34\n27\n21\n21\n21\n20\n17\n15\n14\n9\n9\n8\n8\n\nUsing the co-occurrence matrix creation routine available in VantagePoint, we\ncreate an undirected, weighted adjacency matrix (i.e. cell values contain the\nnumber of records in which two given terms appear together.) Visual inspection\nof this matrix already suggests the concentration of linkages (i.e. co-occurrences)\nbetween the most frequent terms rather than their more homogeneous distribution\nacross the whole set of terms, which is likely the result of a set of terms focused\non a very specific topic.\nWe cluster terms using the MCL algorithm and test different parameters using a\nsub-sample of the dataset with only the top-50 words/phrases in terms of patent\nrecords (to speed up processing.) Three main parameters are set: expansion,\ninflation, and iterations (Macropol, 2009). We found that the MCL process\nconverges before 10 iterations (sooner than suggested by the algorithm author)\nand the variation of this parameter above this level does not affect the clustering\nresults. Expansion and inflation do influence more importantly (and in opposite\ndirections) clustering outputs (Table 2a and Table 2b).113 We find that setting\nexpansion=2 and inflation=2—their minimum value—lead to more satisfactory\nresults (i.e. not too much granularity and overlap between clusters not significant.)\nWe verify that the use of weighted matrices (rather than Boolean matrices) leads\nto less overlap between clusters. While the original implementation of the MCL\nalgorithm (Macropol, 2009) suggests adding self loops in adjacency matrices to\navoid the strong effect of odd powers of expansion, we purposely exclude self\nloops. The result of this is slightly more homogeneous clusters with less\nconcentration of terms in the biggest cluster.\n113\n\nThis sensitivity analysis is performed using the top-50 terms according to the number of patent\nrecords they relate to. Total vertices=number of terms; when clustered vertices is larger than total\nvertices, cluster overlap.\n1204\n\nTable 2a. Sensitivity of MCL algorithm to expansion parameter\nExpansion\n\nInflation\n\n2\n3\n4\n5\n\n2\n2\n2\n2\n\nTotal\nTotal\nTotal\nvertices clusters clustered\nvertices\n50\n12\n85\n50\n3\n50\n50\n3\n50\n50\n3\n50\n\nMedian\ncluster\nsize\n4.5\n4\n4\n4\n\nTable 2b. Sensitivity of MCL algorithm to inflation parameter\nExpansion\n\nInflation\n\n2\n2\n2\n2\n\n2\n3\n4\n5\n\nTotal\nTotal\nTotal\nvertices clusters clustered\nvertices\n50\n12\n85\n50\n15\n51\n50\n19\n50\n50\n22\n50\n\nMedian\ncluster\nsize\n4.5\n3\n2\n1\n\nWe then compute the normalized betweenness centrality (Brandes, 2001) for\nterms within each cluster to identify to most relevant concepts. This measure\nindicates how often a node appears between any two random nodes in the\nnetwork. The higher the betweenness score of a term, the more influential it is\nbecause it functions as a junction for communication within the network\n(Paranyushkin, 2011). We find however that this measure tends to be zero or near\nzero for most of the terms within each cluster as they are only linked with a small,\nwell-connected set of terms within the cluster (we think this is likely a datasetspecific phenomenon.) The measure still helps to identify the most influential\nterms within each cluster.\nImplementation results\nWe applied the TNA to titles and abstracts of a set of 262 patent applications by\nJapanese companies between 2000 and 2009. The analysis yields 32 clusters or\ngroups of terms (6 of them contain only one term.) A cursory inspection of the\nterms in each cluster indicates that some groups are somewhat heterogeneous,\nwhich may be evidence of more complex relationships between different\ntechnology concepts that cannot be appreciated by an inexpert observer. We also\nidentify words/phrases that need further clean up—the data creation preprocessing step is automated—and may affect the clustering process to some\nextent.\nWe observe that terms tend to be clustered into few main groups (or often, one\nmain group) which is more likely the result of the focus of the original dataset\n(i.e. the dataset covers a specific topic, nanotechnology applied to energy\nstorage.) Using a dataset with a specific focus is still interesting from the point of\n1205\n\nview of development and testing as the author is able to better interpret results\nrelated to data and topic he is familiar with.\nThe top-10 clusters represent about 80% of the co-occurrence linkages and almost\nthe same proportion (79%) of patent records in the dataset (Table 3). In this case,\nthe most densely connected clusters are those linked to technologies such as Solar\ncells and Battery components. These account for about 40% of linkages between\nterms. Also the proportion of patent records in clusters such as Solar cells and\nLithium Ion Batteries suggests more activity in those areas.\nTable 3. Top-10 clusters of related concepts in the application of TNA analysis to a\npatent portfolio of Japanese companies\nClustera\n\n# terms\n\nSolar cells\n\n62\n\n% total\nedges\n19.09\n\n% total\nrecordsb\n26.52\n\nBattery\ncomponents\n\n37\n\n17.71\n\n13.66\n\nNanomaterials\n\n40\n\n9.94\n\n18.08\n\nFuel cells\n\n32\n\n9.83\n\n12.05\n\nLithium Ion\nBatteries\n\n34\n\n9.37\n\n20.09\n\nHydrogen\ncells\nCarbon\ncomposites\n\n25\n\n8.11\n\n8.84\n\n9\n\n2.06\n\n7.23\n\nNickel alloys\n\n6\n\n1.71\n\n1.21\n\nEquipment\n\n6\n\n1.71\n\n0.8\n\nSecondary\nbatteries\n\n9\n\n1.49\n\n7.63\n\nTop-3 terms (norm. betweenness in\nparenthesis)\nDye-Sensitized Solar Cell (0.49),\nElectrolyte (0.37), Electrochemical\nCapacitors (0.06)\nCarbon Nanofibers (0.40), NonAqueous Electrolyte (0.38), Electrodes\n(0.04)\nCarbon Nanotubes (0.93), Long-Chain\nCarbon Nanotubes (0.01), Electrical\nConductivity (0.00)\nFuel Cell (0.83), Electrochemical\nCapacitors (0.13), Polymer Electrolyte\n(0.02)\nLithium Ion Battery (0.65),\nNanoparticles (0.19), Carbon Atoms\n(0.06)\nFullerene (0.82), Hydrogen Atoms\n(0.00), Hydrogen Molecules (0.00)\nCarbon Fibers (0.46), Carbon\nComposite (0.25), Carbon Particles\n(0.00)\nElectrochemical Electrode (0.00),\nNanostructures (0.00), Nickel\nNanocrystal (0.00)\nElectrolyzers (0.00), Flowmeter (0.00),\nHydrogen Generator (0.00)\nSecondary Battery (0.75), Hexagonal\nCarbon (0.18), Truncated Conical\nTubular Graphene (0.18)\n\nNotes: a. cluster name assigned by the researcher. b.percentage of total records exceed 100% due to\nterms that appear in more than one records and clusters that overlap. Table shows only the top-10\nclusters in terms of share of total network edges.\n\n1206\n\nThe calculation of the normalized betweenness score helps to identify those terms\nthat are the most central in each group. Their interconnectedness with several\nother peripheral terms within each cluster suggests a role for them in the\nconceptual interpretation of the groups of terms. Cluster names can be created\nbased on these most central terms. We find, however, that most of the terms have\nvery low betweenness centrality scores, indicating the existence of weakly\nconnected groups that do not have a distinctive central term.\nNetwork graph visualization is also helpful in this regard. We use the software\nGephi to visualize the network of all clusters discovered in this dataset (Figure 1).\nThe graph shows closer connections between technologies related with Solar\nCells, Lithium Ion Batteries, and Nanomaterials (particularly, “carbon\nnanotubes”). This focus of the patenting activity of Japanese companies in this\nfield coincides in general terms with the results of the analysis of leading\ncountries as investigated with other methods (Kay &amp; Appelbaum, 2012).\n\nFigure 1. Network graph visualization of terms and clusters discovered using TNA\napproach in nanotechnology energy storage patent applications by Japanese\ncompanies (2000-2009)114\n\n114\n\nThe graph shows labels for top-10 clusters only. The size of labels represents the number of\npatent records associated with the cluster. Node colour represents the cluster each term is associated\nwith. We use Gephi and OpenOrd layout algorithm.\n1207\n\nConclusions and next steps\nThis paper introduces a method for Text Network Analysis and presents some\nresults of algorithm testing, development and implementation. Preliminary\nfindings show some interesting features of this method. Most importantly, it\noffers a number of parameters that can be calibrated to improve the method and\nmake it more effective to investigate scientific and patent literature. It also allows\nthe creation of both quantitative indicators and visualizations that may help to\ninterpret results and discover themes and conceptual relationships. Regarding the\nspecific application of the method to patent portfolio analysis, TNA may\ncomplement other analysis that draw on more conventional categories such as IPC\nclasses. We find that the interpretation of TNA results, however, is not\nstraightforward, particularly when there are an increasing number of terms and\noverlapping clusters. In this regard, the existence of groups of terms that are\nweakly connected or a number of single-element clusters suggests that some\npruning may be beneficial before applying this routine to focus only on the most\nimportant terms.\nImprovements and calibration of this method are under development. Although\nthere are only a few parameters to calibrate the MCL algorithm, its\nimplementation demands significant hardware resources when analyzing big\ndatasets. This results in increased testing and calibration time. Next steps should\ninclude algorithm improvement to increase speed of analysis; application to\ndatasets that do not focus on specific topics (an example would be all patent\napplications by Japanese companies during a certain time period;) direct\napplication to patent document text instead of application to either titles and\nabstracts or their NLP phrases; and, comparison with other methods for topic\ndiscovery such as Principal Component Analysis.\nAcknowledgments\nThis work has been supported by the National Science Foundation (Grant No.\nSES 0938099 and SES 0531184). Any opinions, findings, conclusions or\nrecommendations expressed are ours and do not necessarily reflect those of the\nNational Science Foundation. We conducted our research under the auspices of\nthe UCSB’s Center for Nanotechnology in Society (www.cns.ucsb.edu).\nReferences\nBrandes, A. (2001). Faster Algorithm for Betweenness Centrality. Journal of\nMathematical Sociology 25(2):163-177.\nBroniatowski, Magee (2012). Studying Group Behaviors. A tutorial on text and\nnetwork analysis methods. IEEE Signal Processing Magazine, 22-32.\nKay, L. &amp; Appelbaum, R. (2012). How do companies embrace emerging\ntechnologies? The case of nanotechnology and energy storage applications in\nChina. 2012 Conference on Patent Statistics for Decision Makers (PSDM).\nParis, France, November 28-29.\n\n1208\n\nLong, Seth (2012). Concept clusters in Rhetoric Society Quarterly. Retrieved\nJanuary 25, 2013 from: http://technaverbascripta.wordpress.com/2012/10/08/\ntext-network-analysis-1-concept-clusters-in-rhetoric-society-quarterly/\nMacropol, Kathy (2009). Clustering on Graphs: The Markov Cluster Algorithm\n(MCL)\nParanyushkin, Dmitry (2011). Identifying the Pathways for Meaning Circulation\nusing Text Network Analysis. Retrieved January 25, 2013 from:\nhttp://noduslabs.com/publications/Pathways-Meaning-Text-NetworkAnalysis.pdf\nPorter, Alan L.; Newman, David; Newman, Nils C. (2012). Text Mining to\nIdentify Topical Emergence: Case Study on Management of Technology.\nPorter, A. L., Youtie, J., Shapira, P., &amp; Schoeneck, D. J. (2008). Refining search\nterms for nanotechnology. Journal of Nanoparticle Research, 10, 715-728.\n\n1209\n\nMISFITS? RESEARCH CLASSIFICATION IN\nRESEARCH EVALUATION: VISUALIZING\nJOURNAL CONTENT WITHIN FIELDS OF\nRESEARCH CODES\nGaby Haddow1 and Ed Noyons2\n1\n\ng.haddow@curtin.edu.au\nCurtin University, Dept of Information Studies, GPO Box U1987, 6845 Perth (Australia)\n2\n\nnoyons@cwts.leidenuniv.nl\nLeiden University, Centre for Science and Technology Studies (CWTS), PO Box 905,\n2300 AX Leiden (The Netherlands)\n\nAbstract\n\nThe Australian research evaluation model uses a classification scheme to assign Fields of\nResearch (FoRs) to individual researchers and journals, and to define assessment panels.\nEligible journals for assessment are listed and assigned between one and three FoR codes.\nA high proportion of journals in the list of over 22,000 titles are assigned a single FoR\ncode only. This paper explores the implications of classifying research outputs using the\nFoR code mechanisms. Eight datasets of title and abstract data from journals assigned a\nsingle FoR were mapped using VOSviewer. Four of the datasets were in science fields\nand the other four were humanities and social sciences fields. The maps and extracted\nterms for each journal set were examined for overlap with other FoRs. Sizeable overlaps\nwith other FoR codes were observed in the content of three of the sciences fields’ datasets.\nWeaker overlaps with other FoR codes were found in the humanities and social sciences\ndatasets. The findings suggest that the assignment of FoR codes to journals has the\npotential to disadvantage researchers and their organisational units.\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3) and Visualisation and Science Mapping: Tools, Methods and Applications (Topic 8).\n\nIntroduction\nResearch evaluation serves a variety of purposes. At the macro level of countries\nand institutions, it can encourage higher quality and quantity of research output;\nidentify areas of strength, weakness and duplication; and provide an accountable\nand transparent method of supporting research activity (Box, 2010; Butler, 2010;\nEuropean Science Foundation, 2012). At the micro level, research evaluation\nprovides an opportunity for organisational units and individuals to prove their\nvalue and contribution to their institution. Ideally, the mechanisms applied in\nresearch evaluation deliver outcomes that enable macro level decision making\nwhile recognising the efforts of those at the micro level.\n1210\n\nAn important factor in achieving a match between macro and micro level needs is\nthe method used to classify research by field. Most national research evaluation\nframeworks appoint panels of experts that assess research outputs submitted by\nparticipating institutions. In the United Kingdom (Higher Education Funding\nCouncil for England, 2005) and New Zealand (Tertiary Education Commission,\n2012) these submissions are based on selecting outputs that align with defined\nparameters of expert disciplinary panels. If a panel deems a submission out of\nscope or a submitting institution requests it, then referral to another assessor may\noccur. This mechanism allows for cross-disciplinary research to be assessed by\nthe most appropriate panel or expert, while retaining a connection between an\nindividual or group submission and their research. The Australian research\nevaluation framework, Excellence in Research for Australia (ERA), also uses\npanels. Unlike the models described above, these panels are defined by a\nclassification scheme, the Australian and New Zealand Standard Research\nClassification (ANZSRC) (Australian Bureau of Statistics, 2008). In addition,\nclassification is extended to the assignment of Fields of Research (FoR) codes to\nresearchers and research outputs (Australian Research Council, 2011). Over\n22,000 journals (the ERA 2012 Journal List), deemed eligible outputs, are\nassigned between one and three FoR codes. Some allowance for\nmultidisciplinarity is built into the ERA with an MD code and broader two-digit\ncodes, however journals assigned four digit FoR codes comprise the vast majority\n(85%) and over 50% of all journals in the ERA list are assigned a single code. By\nusing FoR codes to classify researchers, research outputs and assessment panels,\nthe Australian research evaluation model has created a system in which a\nclassification scheme is the overarching structure. In effect, it has the potential to\nseparate researchers from their research output.\nBackground\nClassification schemes, such as the Universal Decimal Classification and the\nextensive Medical Subject Headings (MeSH), are well known and well\nresearched. Schemes applied specifically to research activities are more recent\nand, as a result, research into their impact in research evaluation is limited. The\ngrowth of research evaluation activities internationally (ESF, 2012; Goldfinch &amp;\nYamamoto, 2012) is raising the profile research classification, however. A\nEuropean Science Foundation (ESF) forum discussed several schemes to identify\nkey issues which might improve the capacity to compare research between\norganisations and countries. An ESF working document (2011) stressed the\nimportance of consistent coding and mapping between different classification\nschemes to provide “a powerful tool, particularly when applied to national\nportfolios to plan to address gaps and new opportunities” (p. 17). The potential for\ntext mining using title and abstract data was also discussed as a means to classify\nresearch. Drawing on the working document, a later ESF report notes “one of the\ngreatest challenges in research evaluation is to connect information to a\nresearcher, a grant, an output” (2012, p. 10).\n1211\n\nAccurate classification is vital to achieve a primary objective of evaluation\nactivities: “to provide tools in decision making processes about the allocation of\nresearch funds” (Moed, 2005). In many national systems, research is informally\nclassified by the researcher through selection of an assessment panel to submit\ntheir work for peer review, based on a judgment that the subject content of their\nresearch corresponds with a panel’s expertise. This is the process for research\nevaluation in the United Kingdom and New Zealand, and both limit the number of\nresearch outputs that can be submitted by a researcher (Goldfinch &amp; Yamamoto,\n2012). In contrast, submissions to the ERA include all eligible research outputs\nover a specified period, individual researchers must select between one and three\nFoR codes to represent their research activities, and journal article outputs are\nbound by a pre-determined classification. That is, articles are assigned the same\nFoR code or codes as the journal in which they are published, unless a researcher\ncan argue that over 66% of the content relates to a different FoR. Discussing the\nFoR code mechanism for ERA journals, it has been noted: “accuracy at the article\nlevel will only be achieved if a) the FoRs are allocated to journals accurately and\nconsistently, and b) individual articles conform to the subject focus of a journal as\nit is expressed in the FoRs” (Bennett, Genoni &amp; Haddow, 2011, p. 89). These\nresearchers found 46.8% of codes assigned by authors to their articles did not\nalign with the journals’ codes as assigned in the ERA.\nBasically there are three types of problems with a journal classification: resolution\nof the scheme, inter-disciplinarity and scope of journals. The first type refers to\nthe struggle to describe a proper structure of science. Clearly, ‘natural sciences’ is\ntoo broad to be a meaningful class, but how about ‘physics’. In many cases that is\nstill too broad, but what is an appropriate level. There is no real reference to the\n‘real world’, no definite scheme. The second type is the one we address in this\npaper. Journals may act at the interface of one ‘field’ to the other but should the\noutput and impact of such journals be divided equally over the two fields at stake?\nAs long as we use journals as the entity to classify we will need to answer this.\nFinally, the third type relates to the problem of multi-disciplinary journals but also\nto journals that have a broader scope than specialized journals. Journals like ‘The\nLancet’ are general medicine journals and as such matching a scheme where\n‘medicine’ is the highest resolution reached. But when a higher resolution is\nneeded, such journals are problematic.\nClassification schemes, such as the ANZSRC, are designed to create clearly\ndefined categories, enabling consistency in their application. For the ERA model\nof research evaluation to operate accurately and equitably, a researcher and their\nresearch outputs need to be classified under the same FoR codes. A difference\nbetween a researcher’s selected FoR codes and the codes assigned to their journal\narticle outputs may result in the researcher’s work being assessed under codes that\nrepresent a different field, and possibly a different organisational unit (Kwok,\n2013).\n1212\n\nThis preliminary study explored the implications of classifying journal articles\nusing the FoR code mechanisms of the ERA. It mapped the content of journals\nassigned a single FoR code and analysed the primary clusters and terms evident in\nthe content. By examining this content against FoR code definitions and exclusion\ncriteria, it is possible to assess the correspondence between assigned codes and\njournal content. The results are then considered in relation to the implications for\nresearchers and organisational units.\nMethods\nThe data required for the study were article titles and abstracts from journals\nassigned a single four-digit FoR code in the ERA 2012 Journal List (Australian\nResearch Council, 2012). In order to gather sufficient content for analysis, the\nstudy identifed large journals sets with the highest proportion of titles assigned\none four-digit FoR code only. Codes with less than 200 journals assigned the code\nas their first FoR were excluded to ensure large journal sets formed the base data\nfor the next stage. The large journal sets were then examined to identify those\nwith 60% or more titles assigned the single code and an ISSN search of the\nCWTS Web of Science database was performed to ensure title and abstract\ncontent for the journals was available. Journal sets with coverage by the CWTS\ndatabase of around 40% or more for science fields and over 20% for humanities\nand social science (HSS) fields comprised the final sample. This resulted in eight\nFoR code journal sets for analysis, equally divided between sciences and HSS\nfields. Table 1 data presents these data for the selected journal sets.\nTable 1. Selected journal sets for analysis\nField of Research\n\nFoR\ncode\n\nPure Mathematics\nZoology\nNursing\nPharmacology &amp; Pharmaceutical\nSciences\nPerforming Arts &amp; Creative Writing\nLiterary Studies\nArchaeology\nHistorical Studies\n\n0101\n0608\n1110\n1115\n\nJournals\nassigned\ncode\n(No.)\n502\n355\n270\n418\n\n1904\n2005\n2101\n2103\n\n366\n1070\n362\n1077\n\nJournals\nassigned\nsingle code\n(No.) (%)\n371 73.9\n247 69.6\n163 60.4\n288 68.9\n\nCWTS\ncoverage\nsingle code\n(No.) (%)\n206 55.5\n143 57.9\n64 39.3\n152 52.8\n\n226\n661\n244\n656\n\n59\n166\n53\n180\n\n61.7\n61.8\n67.4\n60.9\n\n26.1\n25.1\n21.7\n27.4\n\nTitle and abstract data for articles in the eight journal sets, published between\n2008 and 2010, were downloaded from the CWTS database. Due to variations in\nthe number of journals in a set and the availability of abstract data, the datasets\ndiffered substantially in size. For example, Pure Mathematics and Historical\nStudies produced datasets with over 40,000 items, while Archaeology had around\n1213\n\n5,000. Exceeding all others was the dataset for Pharmacology, with over 79,000\nitems. These data were analysed for content using the VOSviewer software\n(version 1.5.3). The VOSviewer is an open source application to analyze and\nvisualize network data. The application is able to identify groups within network\ndata using a modularity-based clustering technique. More details about the\nmethod and technique are in Waltman, Van Eck and Noyons (2010) and Van Eck\n&amp; Waltman (2010). To allow for dataset size variations and aiming to produce\nmaps with clearly defined clusters, different term occurrence thresholds were\napplied in the VOSviewer analyses. A thesaurus file for VOSviewer was created\nfor each dataset to eliminate publishers’ names and to ensure consistency for\ndifferent spelling (eg. theatre/theater) and for synonyms (eg. sixteenth\ncentury/16th century). The software enabled visualization of the journal sets’\ncontent and provided a list of the main terms and noun phrases used by authors in\ntheir titles and abstracts. The most relevant terms are selected by an algorithm\n(Van Eck et al., 2010) taking the discriminative strength of terms into account.\nTogether the selected terms do not cover the entire set of publications but always\na representative part. The main clusters in the VOSviewer map and the list of\nextracted terms were examined against the ANZSRC definitions and exclusions\nfor the FoR codes. Additional resources about a field’s coverage and parameters,\nsuch as subject dictionaries, were consulted to aid the analysis.\nFindings\nPure Mathematics 0101\nThe VOSviewer map for Pure Mathematics used a threshold of 25 term\noccurrences, from which the software generated 1527 relevant terms. The dataset\nwas drawn from 206 journals and comprised around 43,000 items. Five clusters\nare evident in the map (Figure 1) and represent content relating to algebra,\nequations and components, number theory, functional analysis and mathematical\nanalysis, and geometry. These clusters appear to conform to the definitions of the\nFoR code. However, a number of terms that occur in the map are closely related\nto mathematical physics, which is classified with a different FoR code and\nspecifically excluded from the 0101 code. A particularly high occurrence of the\nnoun phrase ‘Hilbert space’ (398) and occurrences of variants on the phrase were\nobserved in the central cluster. The terms, ‘Schrodinger operators’ and\n‘Hamiltonian’ (with variant noun phrases), were also found in the map with\nrelatively high occurrences (163 and 188, respectively).\n\n1214\n\nFigure 1. VOSviewer map of journal content for Pure Mathematics (FoR code 0101)\n\nFigure 2. VOSviewer map of journal content for Zoology (FoR code 0608)\n\nZoology 0608\nUsing a threshold of 25 term occurrences, VOSviewer generated 2078 relevant\nterms to map in the Zoology journal set of over 28,000 items from 143 journals.\nThe map (Figure 2) displays a tightly connected field comprising four major\nclusters: physiology, the mechanics of research, subjects of field research, and lab\nresearch, survival and outcomes. In the large ‘species’ cluster, several terms occur\n(eg. systematics, taxonomy, and phylogeny) which the ANZSRC classifies in the\nFoR code Evolutionary Biology (0603). In addition, ‘fossil record’ (66 times) and\n‘fossil’ (82 times) occur in the ‘species’ cluster. These terms are associated with\npalaeontology (an exclusion from Zoology) and are classified by the code 0403\nfor Geology. A close relationship is also evident with ecology (FoR code 0602) in\nthe occurrence of the terms ‘conservation concern’ (68), ‘conservation status’\n1215\n\n(104) and ‘agroecosystem’ (76) in the ‘bird’ dominated cluster. Animal\nphysiology is excluded from Zoology by the ANZSRC, belonging instead to\nPhysiology (0606). Although the results are inconclusive, the occurrence of terms\nrelating to physiology (eg. gene, dna, kidneys, and gland) in the ‘cell’ cluster\nsuggests that a substantial amount of content includes references to animal\nphysiology.\nNursing 1110\nThe Nursing journals dataset consisted of 15,000 items, drawn from 64 journals.\nThe threshold for term occurrence was set at 15, from which the VOSviewer\nsoftware generated 1561 relevant terms. One of the five clusters, seen in Figure 3,\nsuggests there is high level of content about nursing education. Visible terms on\nthe map include: student, learning, lecturer, and academic. Other terms, not\nvisible on the map but included in the cluster are: clinical placement, nurse\neducation, teaching, and curriculum. The ANZSRC does not list nursing\neducation as an exclusion from the Nursing FoR code, however within the code\n1302 for Curriculum and Pedagogy is 130209 for Medicine, Nursing and Health\nCurriculum and Pedagogy. ‘Public health’ is among the terms extracted, as is\n‘nursing home resident’, both of which are specified exclusions in the Nursing\nFoR.\n\nFigure 3. VOSviewer map of journal content for Nursing (FoR code 1110)\n\nPharmacology and Pharmaceutical Sciences 1115\nThe largest dataset, with 79,000 items, was the content of 152 journals from the\nPharmacology and Pharmaceutical Sciences FoR. A threshold of 80 was used for\nterm occurrences and 2,015 relevant terms were generated by VOSviewer. The\nmap (Figure 4) displays three strong clusters, representing: aspects of trials; drug\nrelease; and discovery, as well as two smaller clusters relating to\npharmacokinetics and drug responses. Medicinal chemistry, which includes\n1216\n\nproteins and peptides, is a stated exclusion from the 1115 code, yet the term\nprotein occurs over 6,000 times and is central to the cluster dominated by ‘cell’.\nProteins are, however, an important aspect of pharmacology and no conclusion\ncan be reached as to whether the journals’ content is focussed on pharmacology or\nextends into Medicinal Chemistry (FoR code 0304).\n\nFigure 4. VOSviewer map of journal content for Pharmacology and Pharmaceutical\nSciences (FoR code 1115)\n\nFigure 5. VOSviewer map of journal content for Performing Arts and Creative\nWriting (FoR code 1904)\n\nPerforming Arts and Creative Writing 1904\nA threshold of 10 term occurrences was used to create the map (Figure 5) for the\nPerforming Arts and Creative Writing journal set, which consisted of 9,000 items\nfrom 59 journals. Even with the low threshold, only 594 relevant terms were\n1217\n\ngenerated by the software. Less defined clusters are evident in the map, which\nshows five large and one smaller cluster, with extensive scattering and overlap.\nClassical music is represented by a strong cluster, as is theatre. The term ‘theatre’\noccurs 418 times, far exceeding any other terms. One cluster relates to education\nand research, including the terms: dance education; education; pedagogy and\nmusic education. Combined, these terms occur over 120 times. The ANZSRC\nclassifies ‘Creative Arts, Media and Communication Curriculum and Pedagogy’\nin FoR 1302, however, like Nursing, education is not a stipulated exclusion from\nthe 1904 code. Creative writing is evident in the theatre cluster, but does not\nappear to be represented by a cluster of its own. ‘Biography’ (67 occurrences),\nwhich is specifically listed in 2103 Historical Studies, appears in the classical\nmusic cluster. With fewer occurrences, ‘television’, ‘cinema’ and ‘film’ are all\nexclusions from 1904 and are classified with the 1902 code for Film, Television\nand Digital Media. The term ‘visual art’ (14 occurrences), which has a specified\ncode in the ANZSRC, also appears in the map within the central, scattered\nmodern music cluster.\n\nFigure 6. VOSviewer map of journal content for Literary Studies (FoR code 2005)\n\nLiterary Studies 2005\nWith 166 journals and over 30,000 items, the Literary Studies dataset was\nmapped using a threshold of 20 term occurrences. VOSviewer generated 589\nrelevant terms. The threshold was set lower than the similarly sized Zoology\ndataset (threshold of 25) to ensure a sufficient number of relevant terms were\nselected. Although several clusters can been seen in the map (Figure 6), extensive\noverlap exists between them. Poetry dominates in the most frequently occurring\nterms and is clearly depicted in a relatively defined cluster. Centrally located, but\nnot visible, is ‘theatre’ which occurs 197 times. The ANZSRC does not stipulate\n‘theatre’ as an exclusion from Literary Studies, however performing arts is\nclassified by the FoR 1904. Similarly, ‘film’ and ‘cinema’ (occurring 155 and 109\n1218\n\ntimes) are not stated exclusions, yet these terms are associated with the 1902\ncode. A stated exclusion is ‘biography’ (occurring 132 times in the poetry\ncluster), which should be classified under FoR 2103. Terms associated with\neducation (classified by 1302), such as ‘education’, ‘teacher’ and ‘student’, also\nappear in the map, with over 220 occurrences combined.\nArchaeology 2101\nThe Archaeology dataset was small, comprising 53 journals which produced over\n5,000 items. For this reason a low threshold of 10 was set, with VOSviewer\ngenerating 583 terms as relevant to map (Figure 7). There was a high level of\nuniformity in occurrence of extracted terms; the highest being 157 followed by\nother terms occurring at regularly decreasing rates. Although some scatter of\nclusters is evident in the map, the field has four relatively defined clusters. These\nrelate to burial sites and finds, representation and collections, administration and\ninterpretation, and social and environmental aspects. Very few terms associated\nwith other fields were extracted from the dataset. ‘Anthropology’ (classified by\nthe code 1601), which occurred 27 times is a stipulated exclusion from\nArchaeology. ‘Biography’ (classified by the Historical Studies code 2103)\noccurred 21 times, and ‘education’ occurred 16 times.\n\nFigure 7. VOSviewer map of journal content for Archaeology (FoR code 2101)\n\nHistorical Studies 2103\nThe Historical Studies journals (180) produced a large dataset of over 48,000\nitems. A threshold of 25 was used to map the field, resulting in 1,050 relevant\nterms being generated. Despite the field’s broad subject coverage, ANZSRC\ndefines it as “history of peoples, nations or geographic regions”, the map (Figure\n8) shows four relatively strong clusters, with a fifth scattered cluster. The main\nclusters represent: war; American history; sources, interpretation, and social\npursuits; and monarchy and church. The scattered cluster relates to colonisation\n1219\n\nand migration. Several important overlaps are evident in the terms and partial\nclusters in the map. It is possible that these are due to sources consulted in\nhistorical research. For example, the ANZSRC stipulates that art history, history\nof architecture, and “history of specific concepts or fields of study which defy\ngeographical classification” are excluded from the 2103 code. Each of these areas\nis represented by extracted terms. ‘Art’ occurs 588 times and ‘architecture’ 144\ntimes. ‘Environmental history’ and ‘philosophy’ (classified by FoR 2202 ‘History\nand Philosophy of Specific Fields) occur 75 and 210 times, respectively. In\naddition, the occurrence of ‘archaeology’ (112), ‘anthropology’ (64), ‘novel’\n(166), ‘fiction’ (171), ‘poetry’ (157), and ‘shakespeare’ (87) indicates there is\nsubstantial overlap with other FoR codes.\n\nFigure 8. VOSviewer map of journal content for Historical Studies (FoR code 2103)\n\nOverlapping Fields of Research codes\nThe matrix in Table 2, presents the findings for journal content that indicated\noverlapping FoR codes and includes the full range of codes identified in the\nanalysis. Correspondence within a FoR code (eg. 0101 and 0101) is not displayed.\nA symbol in a grey cell indicates overlap, a large symbol in a black cell indicates\na high level of overlap, either through clearly visible clusters of terms or a high\noccurrence of terms. For the latter, the number of occurrences of a term or similar\nterms combined, such as ‘art’ and ‘artist’, was calculated as a percentage of the\nhighest term occurrence in the map. Terms that occurred more than 50% of the\nhighest term’s occurrence were deemed to illustrate stronger overlap. Strong\noverlaps can be observed in three of the science FoRs: Zoology, Nursing and\nPharmacology. Journal content in the HSS fields presented a high degree of\noverlap with each other and with the education FoR, but there was not the same\nlevel of strength (assessed by term occurrence) as observed in the science fields.\n\n1220\n\nTable 2. Matrix of overlap between Field of Research codes’ journal sets\n01\n03 04 06\n11\n13 16 19\nFoR 01 05 04 03 02 03 06 08 10 15 17 02 01 02 04\n0101\nx\n05 x\n0304\nX\n0403\nx\n0602\nx\n03\nX\n06\nX\n08\nx x X X\n1110\nx X\n15\nX\n17\nx\n1302\nx\nX\n1601\n1902\nx\n04\nx\nx\n05\nx\n2005\nx\nx x\n2101\nx x\n03\nx\nx\n2202\n\n20\n05 05\n\nx\nx\n\nx\nx\n\nx\n\n21\n22\n01 03 02\n\nx\nx\n\nx\nx\n\nx\n\nx\nx\nx\n\nx\n\nDiscussion\nThe analysis of terms extracted from the articles and titles in journals assigned a\nsingle FoR code indicates the assignment of one code is likely to be an inadequate\nrepresentation of their content. In particular, overlaps with the education field\nwere seen in a number of the journal sets. This is evident in the Nursing and, to a\nlesser extent, the Performing Arts and Creative Writing maps and matrix.\nPotentially, there are strong overlaps with other fields of research in\nPharmacology and Zoology, but additional context for the frequently occurring\nterms is needed in order to reach conclusive findings.\nIt is interesting to note the difference in the interplay of FoR codes within science\njournal content compared with the content of HSS journals. Overall, there\nappeared to be fewer overlapping FoRs in the content of science journals, whereas\nthe HSS display higher frequency of overlapping fields, with the exception of\nArchaeology which presented as a self-contained field. This may be a function of\nthe language used in the fields, in that the sciences lexicon tends to be precise and\nbased on well-defined terminology, while the language of HSS lacks the\nspecificity of the sciences. Some of the overlaps observed in the HSS journal\ncontent were shared across the different fields, such as for the term ‘biography’\nwhich occurred in all datasets despite being a stipulated exclusion from three of\nthe FoR codes examined.\n\n1221\n\nA classification scheme such as the ANZSRC is artificial by nature, whereas\njournal content comprises the natural language used by authors. This study did not\nseek to test the classification scheme per se. It instead sought to determine if its\napplication to journals is likely to disadvantage individual researchers. As an\nexercise in the study of classification these observations are interesting, but\ntransferred to research evaluation activities and the impact on researchers, they\nare more concerning. Article content with stipulated exclusions in a FoR has the\npotential to disconnect both the researcher and their organisational unit from the\nresearch output. For a researcher in a productive unit the impact of losing a few\nresearch outputs to another FoR code will be minor. For smaller and less\nproductive units, the loss could mean their field is not assessed in the ERA if they\ndo not meet the threshold required to make a submission. This scenario is possible\nin all the fields analysed in this study and is a direct result of the FoR code\nmechanisms used to create a structure for the ERA. Introduced relatively recently\n(2009), the ERA’s use of FoR codes to classify journal article outputs has not\nbeen explored widely and the full impact this mechanism is yet to be realised.\nHowever, research to date (Bennett, Genoni &amp; Haddow, 2011; Kwok, 2013)\nsuggests that the way in which FoR codes are applied in the Australian research\nassessment model is flawed.\nWhile there is correspondence between the FoR code assigned to the journals\nexamined in this study and their content, there is also substantial overlap with\nother fields. The evidence of multidisciplinary research found in the journal sets\nsuggests the assignment of FoR codes, particularly a single code, is not an\naccurate or consistent method to classify article content. Further research is\nneeded to understand the implications of an overarching classification scheme in\nresearch evaluation and several aspects of this study raised questions that could be\npursued, such as the effect of a field’s language use on the selection of relevant\nterms from abstract and title data. Both the number of terms and the nature of\nterms extracted from the datasets suggest that future studies need to consider\napproaches that will enable a more precise understanding of the context of\nimportant terms, particularly in HSS. In this regard, a sensitivity analysis is\nanticipated for the full version of the current paper. It will involve multiple\nthresholds and creating sub-samples of the publications in each FoR.\nConclusion\nWhen a researcher selects a journal for publishing they do so based on a number\nof factors relating to audience, perceptions of quality and publishing processes.\nThe FoR classification of journals introduces another consideration that may have\nlittle relevance to these. However, in the ERA the assignment of FoR codes to\njournals is not an insignificant issue. Given the importance of aligning\nresearchers’ FoR codes with the publishing journals’ codes, the overlap between\nfields identified in this study indicate there is the potential for researchers to be\ndisadvantaged if their contribution is assessed and aligned with a different\n1222\n\norganisational unit. In a higher education environment where accountability and\nvalue for money are imperatives at senior management and policy-making levels,\na poor assessment (or no assessment) in the ERA can affect an organisational\nunit’s survival.\nThe findings of this study suggest that the assignment of FoR codes to journals,\nwhile serving the purpose of effortless classification at the macro level, are\ninadequate for the purpose of valuing contribution at the micro level. If, as the\nESF (2012) asserts, connecting information about a researcher to their outputs is\none of the primary challenges of research evaluation, then the assignment of FoR\ncodes to outputs and researchers in the ERA is failing to address this challenge.\nReferences\nAustralian Bureau of Statistics. (2008). Australian and New Zealand Standard\nResearch Classification (ANZSRC). Retrieved November 6, 2012 from:\nhttp://www.abs.gov.au/ausstats/abs@.nsf/0/6BB427AB9696C225CA2574180\n004463E\nAustralian Research Council. (2012). ERA 2012 Journal List. Retrieved\nNovember 6, 2012 from:\nhttp://www.arc.gov.au/era/era_2012/era_journal_list.htm\nAustralian Research Council. (2011). ERA 2012 Submission Guidelines.\nRetrieved November 6, 2012 from:\nhttp://www.arc.gov.au/pdf/era12/ERA2012_SubmissionGuidelines.pdf\nBennett, D., Genoni, P. &amp; Haddow, G. (2011). FoR codes pendulum: Publishing\nchoices within Australian research assessment. Australian Universities’\nReview, 53, 2, 88-98.\nBox, S. (2010), Performance-based funding for public research in tertiary\neducation institutions: Country experiences. In OECD, Performance-based\nFunding for Public Research in Tertiary Education Institutions: Workshop\nProceedings. OECD Publishing. http://dx.doi.org/10.1787/9789264094611-6en\nButler, L. (2010). Impacts of performance-based research funding systems: A\nreview of the concerns and the evidence. In OECD, Performance-based\nFunding for Public Research in Tertiary Education Institutions: Workshop\nProceedings. OECD Publishing. http://dx.doi.org/10.1787/9789264094611-7en\nEuropean Science Foundation. (2012). Evaluation in Research and Research\nFunding Organisations: European Practices. A report by the ESF Member\nOrganisation Forum on Evaluation of Publicly Funded Research. Retrieved\nNovember 6, 2012 from:\nhttp://www.esf.org/index.php?eID=tx_nawsecuredl&amp;u=0&amp;file=fileadmin/be_u\nser/CEO_Unit/MO_FORA/MOFORUM_Eval_PFR__II_/Publications/mof_ev\naluation_final.pdf&amp;t=1357886978&amp;hash=281487d267f2bbbcd1d07ad475d31a\n0567e58a79\n1223\n\nEuropean Science Foundation. (2011). The Classification of Research Portfolios.\nMember Organisation Forum on Publicly Funded Research, Working Group\non “Comparative Research Portfolios”. Retrieved November 6, 2012 from:\nhttp://www.esf.org/index.php?eID=tx_nawsecuredl&amp;u=0&amp;file=fileadmin/be_u\nser/CEO_Unit/MO_FORA/MOFORUM_Eval_PFR__II_/3rd_Workshop/Clas\nsification.pdf&amp;t=1357886978&amp;hash=596e8e371eba8cb8cdfefcb998d550e946\n9b6493\nGoldfinch, S. &amp; Yamamoto, K. (2012). Prometheus Assessed? Research\nMeasurement, Peer Review and Citation Analysis. Oxford: Chandos.\nHigher Education Funding Council for England. (2005). RAE 2008: Guidance on\nSubmissions. Retrieved November 6, 2012 from:\nhttp://www.rae.ac.uk/pubs/2005/03/rae0305.pdf\nKwok, J.T. (2013). Impact of ERA Research Assessment on University Behaviour\nand their Staff. NTEU National Policy and Research Unit. Retrieved April 24,\n2013 from: http://www.erawatch.org.au\nMoed, H.F. (2005). Citation Analysis in Research Evaluation. Dordrecht:\nSpringer.\nOECD. (2007). Revised Field of Science and Technology (FOS) Classification in\nthe Frascati Manual. Retrieved November 6, 2012 from:\nhttp://www.oecd.org/science/innovationinsciencetechnologyandindustry/3823\n5147.pdf\nTertiary Education Commission. (2012). Performance-based Research Fund:\nQuality Evaluation Guidelines 2012. Retrieved December 2, 2012 from:\nhttp://www.tec.govt.nz/Documents/Forms%20Templates%20and%20Guides/P\nBRF-2012-Guidelines-Sept12.pdf\nVan Eck, N.J., Waltman, L., Noyons, E.C.M., &amp; Buter, R.K. (2010). Automatic\nterm identification for bibliometric mapping. Scientometrics, 82(3), 581-596\nVan Eck, N.J., &amp; Waltman, L. (2010). Software survey: VOSviewer, a computer\nprogram for bibliometric mapping. Scientometrics, 84(2), 523-538\nWaltman, L., Van Eck, N.J., &amp; Noyons, E.C.M. (2010). A unified approach to\nmapping and clustering of bibliometric networks. Journal of Informetrics,\n4(4), 629-635\n\n1224\n\nMODEL TO SUPPORT THE INFORMATION\nRETRIEVAL PROCESS OF THE SCIENTIFIC\nPRODUCTION AT DEPARTMENTAL-LEVEL OR\nFACULTY-LEVEL OF UNIVERSITIES\nVíctor Bucheli1, Juan Pablo Calderón2, Fabio González3, Bopaya Bidanda4, Juan\nAlejandro Valdivia4 and Roberto Zarama5\n1 vbucheli@uniandes.edu.co\nDepartamento de Ingeniería Industrial, Universidad de los Andes, Cr 1 No 18A-12,\n111711, Bogotá (Colombia) - Ceiba, Complex Systems Research Center, Bogotá\n(Colombia)\n2 ju-cald1@uniandes.edu.co\nDepartamento de Ingeniería Industrial, Universidad de los Andes, Cr 1 No 18A-12,\n111711, Bogotá (Colombia) - Ceiba, Complex Systems Research Center, Bogotá\n(Colombia)\n3 fagonzalezo@unal.edu.co\nMindLab, Departamento de Ingeniería de Sistemas e Industrial,\nUniversidad Nacional de Colombia, Bogotá (Colombia).\n4 bidanda@engr.pitt.edu\nDepartment of Industrial Engineering, University of Pittsburgh, Pittsburgh, PA 15261,\n(USA).\n5 alejo@macul.ciencias.uchile.cl\nDepartamento de Física, Facultad de Ciencias, Universidad de Chile.\nCeiba, Complex Systems Research Center, Bogotá (Colombia)\n6 rzarama@uniandes.edu.co\nDepartamento de Ingeniería Industrial, Universidad de los Andes, Cr 1 No 18A-12,\n111711, Bogotá (Colombia) - Ceiba, Complex Systems Research Center, Bogotá\n(Colombia)\n\nAbstract\n\nBibliographic databases such as Thomson Reuters&#x27; Web of Science (WoS) or Elsevier&#x27;s\nScopus support search filtering by country or institution. However, the study of the\nscientific production at internal levels of organizations (universities) such as departments\nor faculties is error prone. In this paper, it shows common errors to retrieve papers in WoS\nat departmental-level or at faculty-level. We propose a method to support the information\nretrieval process at internal level of universities. The method is composed by an\nexhaustive search strategy and a Bayesian model to estimate the attribution of universities&#x27;\npapers that belong to a given department or faculty. The method was validated on two real\ncases with promising results. This work is a research in progress; the contrast with other\n1225\n\nmethods and other cases of evaluation are proposed as future work. Nevertheless, it could\nopen new opportunities to scientometric studies and research policy.\n\nConference Topic\n\nManagement and Measurement of Bibliometric Data within Scientific Organizations\n(Topic 9) and Old and New Data Sources for Scientometric Studies: Coverage, Accuracy\nand Reliability (Topic 2).\n\nIntroduction\nLiterature reports that indexed documents between 1980 and 2009 in systems such\nas WoS Web of Science —Thomson Reuters system— or Scopus —Elsevier\nsystem— exceeds 32 millon (WoS) and 37 millon (Scopus) publications,\nrespectively (Jacsó P., 2009). The large data sizes of publication databases\nillustrate the information overload in academic organizations (Allen &amp; T. D.\nWilson 2003); in addition, the papers retrieved from the listed systems are the\ninput to scientometrics studies, research performance evaluation, and research\npolicy. These bibliographic databases search filtering by country or institution.\nGarg K.C. (2003) shows that several number of studies have drawn from these\nnew disciplines to evaluate scientific activity by country, research area, and\ninstitution. Furthermore, the study of the scientific production at internal levels of\norganizations (universities) is not efficient; in addition, the information retrieval\nprocess is identity uncertainty—the identity uncertainty refers to how the objects\nin a data base are not labelled with unique identifiers (Hanna P., 2003).\nThe process of information retrieval from publications databases for a specific\ndepartment or faculty is ambiguous. This is because of name variations: a\ndepartment or a faculty may have multiple names and multiple departments or\nfaculties may share the same name. Such name ambiguity affects the performance\nof document retrieval and may cause improper document attribution to\ndepartments or faculties. In addition, due to name misspellings, translation,\ntransliteration, and inconsistent inclusion of initials and pseudonyms affect the\nperformance of document retrieval process. These factors affect the correct\ndepartment-level or faculty-level attribution and it is a challenge for bibliometric\nand scientometric analysis. Thus, the incorrect document attribution to internal\nentities of universities is not conducive to document retrieval of a single\ndepartment or faculty.\nWe propose a method based on a priori information about the previous intellectual\nproduction of department or faculty. It is used to develop a search strategy and a\nBayesian model. The proposed search strategy is exhaustive; it means, it retrieves\nfull and relevant publications. To improve the scalability, accuracy, precision, and\nrecall of the search strategy, we develop a classification model (probabilistic\nBayesian model-PBM) that estimates the probability of a given document\nbelonging to a particular department or faculty. Using one specific case, The\n1226\n\nDepartment of Industrial Engineering of the University of Pittsburgh (DUP), we\nreport the data search strategy and the classifier PBM. We describe the quality of\ndata obtained through machine learning standard performance measurements.\nThis paper is organized as follows, section two presents a brief literature review\nand the problem of retrieving the intellectual production of department-level or\nfaculty-level. Section three outlines the method to support the document retrieval\nprocess. Section four highlights the results of the method applied on: Department\nof Industrial Engineering – University of Pittsburgh (DUP) and Faculty of\nEngineering – Universidad de los Andes (Colombia) (FUA). Finally, in the last\nsection, we discuss possible applications and future work.\n2. The intellectual production of departments or faculties.\n2.1. Related work.\nThe name disambiguation methods are one approach to support the document\n(scientific publications) retrieval process at departmental-level or faculty-level of\nuniversities. Specifically, the authorship uncertainty and the affiliation\ndisambiguation are challenges for Bibliometrics and Scientometrics arenas. It is a\nproblem since 1969 (Garfield E., 1969) and author name disambiguation within\nbibliographic databases is a very active research area in computer science. Here,\ndisambiguation approaches are based on machine learning paradigms, for a\nreview of author name disambiguation procedures and algorithms, see\n(Smalheiser N. &amp; Torvik V., 2009; Tang L. &amp; Walsh J. P., 2010; Koppel M. &amp;\nSchler J., 2009 and Stamatatos E., 2009). In the last two years, new procedures\nand algorithms of author disambiguation have been proposed (Gurney T.,\nHorlings E. &amp; Besselaar P., 2012; Morillo F. &amp; Santabárbara I., 2013; Jiang W. &amp;\nDing X., 2013) .\nOn the other hand, universities could have information systems to track their\npublication outputs or information retrieval systems such as ResearcherID.\nHowever, researchers could not input all relevant information on a timely basis or\nthey could enter erroneous information, which end up corrupting restricted data\nsets. Thus, these data sets need to be constantly checked and refined. Dervos et all\n(2006) show a pilot version of the Universal Author Identifier system, codenamed\nUAI_Sys and describe the critical non functional requirements, for example: user\nauthorization policies, flexibility, durability and ensuring the data integrity.\nSmalheiser N. and Torvik V. (2009) show that this solution can not be reliable.\nBibliometric studies about the affiliation disambiguation in WoS say: the retrieves\ninformation on affiliation is diverse and it may generate some degree of\nuncertainty. (García-Zorita C. et all, 2005). Few studies have focused on\ninstitutional affiliation, where the problems encountered are related to the lack of\nstandardization in the institutional addresses of author affiliation (Hood W &amp;\n1227\n\nWilson C, 2003). In general, the need for standards in scientometrics studies has\nbeen reported in the literature (Glänzel W., 1996; Raan A.F.,1997; Hood &amp;\nWilson 2003). Jiang Yong, et all (2011) present a clustering method based on\nnormalized compression distance for the purpose of affiliation disambiguation.\nThe method exposed in this paper was tested in WoS and it allowed us to compare\nand benchmark the productivity by departments or faculties of different\nuniversities.\n2.2. The document retrieval process of intellectual production of departments or\nfaculties.\nThe information and indicators about scientific publications are basic elements for\nknowledge management (Phillipswren G. &amp; Forgionne G., 2006; Allen D. &amp;\nWilson T. D., 2003). The universities have gained interest in this kind of\ninformation. This has become more relevant because the number of publications\nand citations are inputs of the academic rankings, the allocation of resources, and\nscientific recognition (Geiger 2004; Enserink 2007).\nWe describe a data search strategy for retrieve the intellectual production of a\nsingle department-level or faculty-level. It is delineated by filtering problems in\nWoS—it can be extended to other systems such as Scopus or Scholar google. In\nWoS, the field tags AD Address, OG Organization and SG sub-organization are\nused to retrieve documents related to one organization: department-level or\nfaculty-level. These are defined as searches for the institution and/or place names\nin the Addresses field within a record. (Thomson Reuters, 2011).\nIn this paper, we propose a document retrieval method to identify the documents\nthat belong to a single academic organization within universities. The correct\nattribution represents an unsolved problem for information science. This is due to\nname variations; for instance, departments or faculties may have multiple names\nand multiple departments or faculties may share the same name. The name\nambiguity affects the performance of document retrieval and may cause improper\ndocument attribution to departments or faculties. In addition, the name\nmisspellings, translation, transliteration, and inconsistent inclusion of initials and\npseudonyms affect the performance of document retrieval process. The proposed\nmethod take into account these issues, however, other cases are not consider, such\nas joint appointment affiliation.\n2.2.1. Common errors.\nIn this work, we build search statements with the following field tags: AD and\nOG and non-relevant documents are retrieved, for instance, we search the\npublications of La Universidad Nacional de Colombia from WoS and this\nuniversity appears with multiple name labels: univ nacl colombia, natl univ\ncolombia, univ nacl or natl univ. In other case, The Department of Industrial\n1228\n\nEngineering of the University of Pittsburgh appears as: Ind Engn Dept,\nPittsburgh; Dept Ind Engn, Pittsburgh; or Univ Pittsburgh, Swanson Sch Engn,\nDept Ind Engn, Pittsburgh. On the other hand, The University of Pittsburgh and\nthe city of Pittsburgh share the same name label in WoS. We use the search\nstatement ad=(&quot;univ pittsburgh&quot;), and it retrieves documents from both name\nlabels: the university of Pittsburgh and the Carnegie Mellon University allocated\nin Pittsburgh—labelled as Carnegie Mellon Univ, Pittsburgh. In the case\nOG=(&quot;univ pittsburgh&quot;), this also retrieves non-relevant documents.\n\n2. Description of a method to retrieve the intellectual production\nIn order to illustrate the proposed method, we use The Industrial Engineering\nDepartment of the University of Pittsburgh, see Appendix 1.\n2.1 Data search strategy to retrieve the intellectual production\nIn order to retrieve the corpus data, we search the documents published by\nuniversity— WoS search strategy ad=(university name). According to the\nsupervised learning methods, the corpus data will split in two data sets: training\ndata set and test data set. Here, the data search strategy is the base line to\nconstruct the training data set, thus, the data search strategy is composed of two\nsteps.\nFirst, the initial search strategy is configured based on a priori information about\nthe intellectual production of department or faculty and it is characterized into\nfour sets: staff, journals, socio-semantic and explicit information about the\nacademic unit in the address field. Second, we retrieve a list of papers based on\nthe initial search strategy. Here, each document is classified as relevant and nonrelevant depending if the paper belongs to the faculty (or department) or not. This\nlist and the classification are validated by an expert group; a professor committee\nor the dean of the academic unit. Their recommendations and suggestions are\ntaken into account and they are integrated into the new search strategy. Additional\nrestrictions to filter out documents are also integrated.\nIn the following section we explain the configuration of the initial search strategy\nand the final search strategy. We use boolean notation to explain the configuration\nof the data search strategies. Finally, the PBM is presented.\n2.1.1. Configuration of the initial search strategy\nThe search strategy retrieves the publications of the university and it construct the\ncorpus data in the proposed method; thus, the university set (U) is the group of\ndocuments in which the name of the university appears in the address of at least\none of the authors. The initial set (I) or initial search strategy is composed by the\nunion of the following groups: staff set (S), socio-semantic network set (O),\njournals set (J), and the name of the internal unit set (A). Hence, I = S OR O OR\nJ OR A.\n1229\n\nThe staff set (S) is related to the documents authored by the faculty members. In\nthis way, the set (S) is the group of documents written by one member of the\nfaculty, whereby the name of the university appears in the institutional affiliation\naddress.\nThe socio-semantic set (O): in this context represents the combination of semantic\nand author information—Roth C. and Cointet J. (2010) present a similar\nrepresentation. In this paper, the socio-semantic information represents a network\nwhere concepts and authors appears together. Each document is represented by a\nspecific semantic category. Thus, set (C) contains the group of documents in\nwhich one concept appears in the title or abstract. The list of concepts can be\nprovided by the academic unit or extracted automatically from previous\npublications. In this work, we process title and abstract textual information and\nbuild up a subset of n-grams115 (Croft 2010). Then, we automatically create a\nconcept lists. On the other hand, the set (O) is also related to the documents\nauthored by the faculty members, hence, O=C AND S.\nThe journals, set (J), is the group of documents published in the same journals as\nprevious publications by the faculty, in which the name of the university appears\nin the address. We build a list of journals in which the unit has published before\nand this is the input to build the set J.\nThe explicit academic unit, set (A), is the group of documents in which the name\nof the academic unit appears in the address of one of the authors; for instance, the\nengineering school refers to as ENG, the physics schools refers to as PHY.\n2.1.2 Expert validation\nThe search statement for the initial set is applied to retrieve a list of papers. Each\npaper is validated by experts as explained above, then, the non-relevant papers are\nremoved from the list and a new list of the paper&#x27;s titles of non-relevant\ndocuments are included into the restriction, set (T). This is used as input for the\nnew search strategy. We use another group of restrictions in the address field, set\n(Q). This set is similar to set (A), but it contains other academic units that not\nhave been taken into account. The final search strategy or retrieved set (R) is the\ngroup of documents of (I) that do not belong to sets (T) and (Q). The intellectual\nproduction of department-level or faculty level is retrieved through the final\nsearch strategy or retrieved set (R). Then, R = I NOT ( T OR Q).\n2.1.3 A classification model for academic units tracking\nThe information retrieved by the final search strategy is the input to the\nProbabilistic Bayesian Model (PBM), which is based on a Naive Bayesian Model.\nThe information retrieved can be separated into relevant and non-relevant. Thus,\n115\n1230\n\nWe used Tinasoft software http://tina.csregistry.org/\n\nthe information retrieval methods and classifier models have a similar purpose\n(Croft 2010).\nThe proposed classifier is Naive Bayes, which follows the Bayesian Theorem.\nThe basic assumption of the Naive Bayesian Model, called class conditional\nindependence, is the independence of features. It is made to simplify the\ncomputation (it is considered to be naive). This kind of classifier is commonly\nused in spam classification, email sorting, routing filtering, and document\nclassification (Baeza-Yates R., 1999; Manning C., 2008).\nThe aim of this model is to classify the university documents into two classes:\ndocuments that belong to the department-level or faculty-level (relevant) and\ndocuments that do not belong (non-relevant). The variables are related to each set\ndefined in the search strategy: staff, journal, socio-semantic, explicit address and\nclass (relevant and non-relevant). We built a corpus data with the final search\nstrategy of the faculty and each document is marked as relevant or non-relevant.\nThe complete corpus data is split into two sets (training data set and test data set).\nThe Probabilistic Bayesian Model (PBM) was build with the first data set\n(training set). We use Weka cross-validation 10 folds and percentage split to train\nthe model (Hall M, et all 2009). This set is used to estimates the posterior\nprobability of a new document belonging to the given unit as a function of the\nfour variables listed below. We defined the model as:\n\nTo simplify the computations:\n\nThis probability model is trained through a supervised learning method (training\ndata set). The m-stimate (equation 3) is a method to estimate the probability of a\nnew paper belonging to the relevant category; for instance, the probability of J\ngiven that R:\n\nWhere, nj is the number of relevant documents in J; nr is the number of relevant\ndocuments; and p is a priori estimate for p(R|J). With this information, for each\ndocument defined as (4), the new paper is classified in the respective set given\nthat (5).\n1231\n\n3. Experimental evaluation and results\nThe proposed data search strategy had better performance than the common\nsearch statements (AD or OG in WoS), in the case of DUP, the retrieve records\nwere from 117 to 145, these values are taken into account as base line to evaluate\nthe retrieval performance, as well as, standard measurements: error instances\nclassified, precision, recall and the area under the receiver operating characteristic\ncurve (ROC) (Witten I., 2005; Baeza-Yates R., 1999).\n3.1. Experimental evaluation\n\nWe apply the proposed search strategy for DUP and 173 documents were\n\nretrieved. This highlight shows the correct attribution and how the proposed\nmethod support the document retrieval process at faculty-level. The proposed\nmethod retrieves more publications than the common search statements. The\ncommon search statements presented an average of lost of papers from 24% to\n29%. Thus, the proposed search strategy is exhaustive. These results has been\nconfirmed with the Faculty of Engineering – Universidad de los Andes\n(Colombia) (FUA) and the method is consistent.\n3.2 Results\nTable 1. shows the results in the case of Department of Industrial Engineering –\nUniversity of Pittsburgh and Faculty of Engineering – Universidad de los Andes\n(Colombia). This shows the performance and the predictiveness of the model.\nTable 1. Performance measurements of the proposed model.\n\nDepartment of Industrial Engineering –\nUniversity of Pittsburgh\nFaculty of Engineering – Universidad de\nlos Andes (Colombia)\n\nInstances wrongly Precision Recall Area under\nclassified\nthe ROC\n0.16%\n0.997\n0.494\n0.984\n0.48%\n\n0.954\n\n0.992\n\n0.965\n\n4. Discussion and future work\nThe identity uncertainty in the paper&#x27;s institutional affiliation affects the\nperformance of document retrieval process at department-level or faculty-level\nand may cause improper document attribution to departments or faculties.\n1232\n\nWe report a method to support the information retrieval process of the scientific\nproduction at departmental-level or faculty-level. We describe the quality of data\nobtained through standard performance measurements. The results show that it\ncan effectively identify the correct attribution. This paper is a research in\nprogress; as future work, the contrast with other methods and other cases of\nevaluation will be considered.\nIn order to apply the proposed method the search strategies and the PBM can be\nused as an integrated system, where, the search strategy can be implemented\nthrough RSS alerts (Rich Site Summary) from WoS and the RSS retrieves the\npublications periodically. On the other hand, the PBM can be implemented in\nWeka (Java application), which allows an automatic classification of departmental\nor faculty documents.\nThe proposed method allows to develop scientometrics studies at the different\nlevels within universities and to compare and benchmark the research productivity\nby departments or faculties of different universities. The presented method shows\nthe potential to evaluate and track knowledge production and support the research\npolicies within universities.\nAs future work, this method can be extended to include research groups or\nresearch networks, as well as, other systems such as Scopus or Google Scholar.\nReferences\nAllen, D. &amp; Wilson, T.D., 2003. Information overload: context and causes. New\nReview of Information Behaviour Research, 4(1), pp.31-44.\nBaeza-Yates, R., 1999. Modern information retrieval, New York ;Harlow\nEngland: ACM Press ;;Addison-Wesley c1999.\nCroft, W., 2010. Search engines : information retrieval in practice, Boston:\nAddison-Wesley.\nDervos, D. A., Samaras, N., Evangelidis, G., Hyvärinen, J., and Asmanidis, Y.,\n2006. The Universal Author Identifier System (UAI_Sys). Proceedings of the\n1st International Scientific Conference, eRA: The Contribution of Information\nTechnology in Science, Economy, Society and Education. Retrieved January\n12, 2008, from dlist.sir.arizona.edu/1716\nEnserink, M., 2007. EDUCATION: Who Ranks the University Rankers? Science,\n317(5841), pp.1026-1028.\nGarcía Zorita, C., Martín Moreno, C., Lascurain Sánchez, M. L., &amp; Sanz Casado,\nE., 2006. Institutional addresses in the Web of Science: the effects on scientific\nevaluation. Journal of Information Science, 32(4), pp. 378–383.\nGarfield, E., 1969. British quest for uniqueness versus American egocentrism.\nNature, 223(5207), pp. 763.\n\n1233\n\nGarg K.C., 2003. An overview of cross-national, national, and institutional\nassessment as\nreflected in the international journal Scientometrics,\nScientometrics, 56 (2), pp.169–\n99.\nGeiger, R., 2004. Knowledge and money : research universities and the paradox\nof the marketplace, Stanford Calif. Stanford University Press.\nGlänzel, W., 1996. The need for standards in bibliometric research and\ntechnology. Scientometrics, 35(2), pp.167-176.\nGurney T., Horlings E., and Besselaar P, 2012. Author disambiguation using\nmulti-aspect similarity indicators. Scientometrics, 91(2),pp. 435-449\nHall M, et al, 2009, The WEKA Data Mining Software: An Update; SIGKDD\nExplorations, Volume 11, Issue 1.\nHanna P., et al., 2003, Identity Uncertainty and Citation Matching, In NIPS,\nMIT Press.\nHood, W.W. &amp; Wilson, C.S., 2003. Informetric studies using databases:\nOpportunities and challenges. Scientometrics, 58(3), pp.587-608.\nJiang Wu &amp; Xiu-Hao D., 2013. Author name disambiguation in scientific\ncollaboration and mobility cases. Scientometrics, pp.1-15.\nKoppel, M., Schler, J. and Argamon, S., 2009. Computational Methods in\nAuthorship Attribution, JASIST, 60 (1), pp. 9-26\nJacsó, P., 2009.Errors of omission and their implications for computing\nscientometric measures in evaluating the publishing productivity and impact of\ncountries. Online Information Review, 33(2), pp.376-385.\nJiang, Y., Zheng, H. T., Wang, X., Lu, B., &amp; Kaihua, Wu., 2011. Affiliation\ndisambiguation for constructing semantic digital libraries. Journal of the\nAmerican Society for Information Science and Technology, 62(6), 1029–1041.\nManning, C., 2008. Introduction to information retrieval, New York: Cambridge\nUniversity Press.\nMorillo F. &amp; Santabárbara I. and Aparicio, J., 2013. The automatic normalization\nchallenge: detailed addresses identification. Scientometrics, 91(1) pp.1-14 ,\nPhillipswren, G. &amp; Forgionne, G., 2006. Aided search strategy enabled by\ndecision support. Information Processing &amp; Management, 42(2), pp.503-518.\nRaan, A.F.J., 1997. Scientometrics: State-of-the-art. Scientometrics, 38(1),\npp.205-218.\nRoth, C. &amp; Cointet, J.-P., 2010. Social and semantic coevolution in knowledge\nnetworks. Social Networks, 32(1), pp.16-29.\nSmalheiser NR, Torvik VI. Author name disambiguation. In: Cronin B, editor.\nAnnual Review of Information Science and Technology. Vol. 43. 2009. pp.\n287–313.\nStamatatos E., 2009. A survey of modern authorship attribution methods. Journal\nof the American Society for Information Science and Technology, 60 (3), pp.\n538-556.\nTang, L et. Al, 2010. Bibliometric fingerprints: name disambiguation based on\napproximate structure equivalence of cognitive maps, Scientometrics, 84 (3),\npp.763-784.\n1234\n\nThomson Reuters, 2011. Web of Knowledge - Science - Thomson Reuters. Web\nof knowledge. Available at: http://www.isiwebofknowledge.com/\nWitten, I., 2005. Data mining : practical machine learning tools and techniques\n2nd ed., Amsterdam ;;Boston MA: Morgan Kaufman.\n\n1235\n\nAppendix 1.\nTable 1: Data search strategy for the Department of Industrial Engineering of the\nUniversity of Pittsburgh\nSET\n\nSearch statement\n\nU\nS\n\nAD=(UNIV PITTSBURGH) OR OG=(UNIV PITTSBURGH)\nau=(Shuman,L*) OR au=(Bidanda,B) OR au=(Rajgopal,J*) OR au=(NORman,BA)\nOR au=(Besterfield-Sacre,M*) OR au=(Kharoufeh,JP) OR au=(Maillart,L*) OR\nau=(Prokopyev,O*) OR au=(Shankar,MR) OR au=(Schaefer,A*) not au=(Schaefer,\nat) AND (ad=(UNIV PITTSBURGH) OR og=(UNIV PITTSBURGH))\nts=(suite of test problems) OR ts=(severe plastic deformation spd) OR ts=(solid\noxide fuel cell) OR ts=(cross wedge rolling cwr) OR ts=(behavior in electricity\nmarkets) OR ts=(stage liver disease) OR ts=(strategic behavior in electricity) OR\nts=(leading cause of death) OR ts=(unequal area facility) OR ts=(several oligopoly\nmodels) OR ts=(set ofintuitive conditions) OR ts=(wedge rolling cwr) OR\nts=(objective tabu search) OR ts=(expected lifetime orquality) OR ts=(power\ngenerating system) OR ts=(imposition of knowledge) OR ts=(optimal policy) OR\nts=(mathematical programming) OR ts=(production costs) OR ts=(decisi on\nprocess) OR ts=(crew schedules) OR ts=(decision maker) OR ts=(control limit) OR\nts=(natural history) OR ts=(stage liver) OR ts=(integer programming) OR\nts=(genetic algorithm) OR ts=(outcome measures) OR ts=(generating system) OR\nts=(numerical example) OR ts=(planned cost) OR ts=(several oligopoly) OR\nts=(expected profit) OR ts=(decision problem) OR ts=(welded structure) OR\nts=(process planning) OR ts=(duration curve) OR ts=(generating unit) OR\nts=(product design) OR ts=(auditing practices) OR ts=(leading cause) OR\nts=(engineering education) OR ts=(sofa scores) OR ts=(crew schedule) OR\nts=(ofintuitive conditions) OR ts=(strategic behavior) OR ts=(expected lifetime)\nOR ts=(stochastic model) OR ts=(petri nets) OR ts=(engineering programs) OR\nts=(plane strain) OR ts=(job rotation) OR ts=(waiting list) OR ts=(process mdp)\nOR ts=(robot arc) OR ts=(optimization problem) OR ts=(intellectual property) OR\nts=(handling costs) OR ts=(rescheduling problem) OR ts=(alternative routings) OR\nts=(planning process) OR ts=(institutional changeand) OR ts=(hollow shafts)\n\nC\n\nO\nJ\n\nA\nI\nQ\nT\nR\n\n1236\n\nC AND S\n\nso=(IIE TRANSACTIONS ) OR so=(EUROPEAN JOURNAL OF\nOPERATIONAL RESEARCH ) OR so=(INTERNATIONAL JOURNAL OF\nPRODUCTION RESEARCH ) OR so=(IEEE TRANSACTIONS ON POWER\nSYSTEMS ) OR so=(JOURNAL OF ENGINEERING EDUCATION ) OR\nso=(MEDICAL DECISION MAKING ) OR so=(OPERATIONS RESEARCH )\nOR so=(ANNALS OF OPERATIONS RESEARCH ) OR so=(NAVAL\nRESEARCH LogISTICS ) OR so=(MANAGEMENT SCIENCE ) OR\nso=(OPERATIONS RESEARCH LETTERS ) AND (ad=(UNIV PITTSBURGH)\nOR og=(UNIV PITTSBURGH))\nad=(UNIV PITTSBURGH SAME Dept Ind Engn) OR og=(UNIV PITTSBURGH\nsame Dept Ind Engn)\n\nS OR O OR J OR A\n\n(ad=(UNIV PITTSBURGH same Business*) OR og=(UNIV PITTSBURGH same\nBusiness*))\nThe recommendations and suggestions of experts are taken account in a restriction\nset T\n\nI NOT ( T OR Q)\n\nNumber of\ndocuments\n61,57\n117\n&gt;100.000\n\n87\n132\n\n145\n216\n295\n17\n173\n\nMOST BORROWED IS MOST CITED? LIBRARY\nLOAN STATISTICS AS A PROXY FOR\nMONOGRAPH SELECTION IN CITATION\nINDEXES (RIP)\nÁlvaro Cabezas-Clavijo1, Nicolás Robinson-García1, Daniel Torres-Salinas2,\nEvaristo Jiménez-Contreras1, Thomas Mikulka3, Christian Gumpenberger3,\nAmbros Wernisch3&amp; Juan Gorraiz3\n1\n\nacabezasclavijo@gmail.com, {elrobin, evaristo} @ugr.es\nEC3: Evaluación de la Ciencia y de la Comunicación Científica, Departamento de\nInformación y Comunicación, Universidad de Granada, Campus de Cartuja s/n E-18071\nGranada (Spain)\n2\n\ntorressalinas@gmail.com\nEC3: Evaluación de la Ciencia y de la Comunicación Científica, Centro de Investigación\nMédica Aplicada, Universidad de Navarra, Pamplona (Spain)\n3\n\n{christian.gumpenberger, ambros.wernisch, thomas.mikulka, juan.gorraiz} @univie.ac.at\nUniversity of Vienna, Vienna University Library, Boltzmanngasse 5, A-1090 Vienna\n(Austria)\n\nAbstract\n\nThis study aims to analyse whether library loan statistics can be used as a measure of\nmonograph use and as a selection criterion for inclusion in citation indexes. For this, we\nconducted an exploratory study based on loan data (1000 most borrowed monographs)\nfrom two non-Anglo-Saxon European university libraries (Granada and Vienna) with\nstrong social sciences and humanities components. Loans to scientists only were also\nanalysed at the University of Vienna. Furthermore, citation counts for the 100 most\nborrowed scientific monographs (SM) and textbooks or manuals (MTB) were retrieved\nfromWeb of Science and Google Scholar.The results show considerable similarities in\nboth libraries: the percentage of loans for books in national languages represents almost\n96% of the total share and SM accounts only for 10%–13%.When considering loans to\nscientists only, the percentage of English books increases to 30%; the percentage of SM\nloans also increases (~ 80%). Furthermore, we found no significant correlations between\nloans and citations. Since loan statistics are currently insufficient for measuring the use of\nmonographs, their suggested use as an applicable selection criterion for book citation\nindexes is not yet feasible. Data improvement and aggregation at different levels is a\nchallenge for modern libraries in order to enable the exploitation of this invaluable\ninformation source for scientometric purposes.\n\nKeywords\n\nLoans, citation, usage metric, citation metric, monographs, books, book citation index\n\n1237\n\nConference Topics\n\nTopic 1: Scientometric Indicators; Topic 2: Old and New Data Sources for Scientometric\nStudies\n\nIntroduction\nBibliometric indicators have increasingly been used for research assessment\npurposes since the 1970s. Among other uses, they have been applied to\nimplement reward mechanisms within academia, exceeding their original purpose\nwhich was to serve as an aid for journal selection in university libraries. In this\nsense, bibliometric studies have rested primarily on two basic metrics: journals’\nimpact factors and citations of papers. However, unlike journal articles for which\nnew indicators have been developed in the last few years (SJR, SNIP,\nEigenscore), monographs, an important scholarly communication channel for the\nhumanities and social sciences fields, have been left behind. The absence of books\nin the main databases with bibliometric data has led evaluation agencies to\nconsider monographs a minor scientific product. This has resulted, in many of\nthese fields, in the devaluation of monographs. In fact, as shown in the UK, many\nresearchers have shifted from books to journal articles as their preferred\ndissemination product due to the pressure exerted by national evaluations\n(Research Information Network, 2009).\nThere has been little exploration of usage indicators within the scientometric\ncommunity as a proxy to measure the use and impact of academic materials. The\nadvent of the digital format in academia has brought the development of new\ntools, such as journal hubs or repositories, which produce new use-derived\nindicators. These metrics represent a potential opportunity for applying alternative\nevaluation methods, aiming to complement or even replace the traditional\nbibliometric indicators based on citations. Projects such as COUNTER (Counting\nOnline Usage of Networked Electronic Resources) or MESUR (Metrics from\nScholarly Usage of Resources) have worked on this line of work, developing the\nnecessary frameworks and standards to achieve such goals.\nLikewise, the adoption of so-called web 2.0 tools by researchers has added a new\ndimension in which usage indicators can also be applied to measure the impact of\nresearch, not only within the academic community but also in society at large.\nThe main characteristics of these indicators, known as Altmetrics (Priem et al,\n2010), are: 1) they work at an item level, and 2) they can be obtained in real time.\nHowever, they also have many shortcomings, such as the evanescence of data or\ncomplexity in terms of apprehending their real meaning. The adoption of these\nindicators by journals such as PLoS One, publishing houses such as Nature\nPublishing Group, or major databases such as Scopus, highlight the level of\nacceptance they are gaining within the scientific community.\n\n1238\n\nDespite the availability of e-books on scientific platforms and in library\ncatalogues, these usage indicators do not perform well in this context such that\nthey might be considered valuable alternatives for research assessment. However,\nthere are other usage indicators that could be used instead. Library loans may\ncapture the impact of books in ways that e-usage and Altmetrics cannot. This is\nparticularly interesting in the fields of the social sciences and humanities, where\nmonographs still play a significant role. This approach is not new as Price (1963)\nremarked that the “amount of usage provides a reasonable measure of the\nscientific importance of a journal or a man’s work”. Following this line of\nthought, loans could not only be used as proxies of dissemination, but also of\nrelevance or importance, detecting books that may be considered top tier research\noutcomes for inclusion in citation indexes. This is as a relevant issue as evaluation\nagencies tend to assess based only the content of these indexes.\nThe launch of the Thomson Reuters’ Book Citation Index (hereafter, BKCI) in\n2010 introduced new elements of study for the bibliometric community. Beyond\nthe citations that each book or book chapter gather from other citation indexes,\nthis product also allows the analysis of publishers or citation patterns within\nbook-oriented areas (Gorraiz et al, 2013; Leydesdorff &amp; Felt, 2012; TorresSalinas et al, 2012). Thomson Reuters states that “there is a need to select those\npublications that will most likely contain significant scholarship” and that\n“priority is given to books and book series that have relatively greater citation\nimpact” (Testa, 2012). Such statements suggest that the mere indexing of\nmonographs within this database is a sign of quality commensurate with that for\njournals and therefore it also suggests that solid methodology must be developed\nto ensure that the materials to be included in the future are chosen fairly.\nCurrently, apart from certain bibliographic requirements and the citation impact,\nthe company does not specify further criteria for inclusion.\nBased on the premise that library statistics are an invaluable and underutilized\nsource of information for assessment purposes, we explore in this paper the extent\nto which library loans might be used as a proxy for the measurement of\nmonograph use. Furthermore, we test the feasibility of using library loans as a\npossible selection criterion for monographs in citation indexes.\nTheoretical Background\nThe influence of monographs in the social sciences, especially in the arts and\nhumanities, as the main communication channel between scholars has\ntraditionally led to serious shortcomings when adopting bibliometric\nmethodologies to analyse and assess research activity in these areas. Indeed, not\nonly they lack sound and consolidated bibliometric measures, but their nature\nposes many limitations that must be overcome in order to apply the correct\nmethodological procedure when employing them. In this sense, there are three\nmain issues that should be resolved as a prior step before any kind of\n1239\n\nmethodological approach is taken: the definition of monograph types, the\nestablishment of significant proxies of quality, and addressing differences across\ndisciplines.\nRegarding the first issue, monographs are extremely heterogeneous as content of a\ndifferent nature can be found in them. According to Testa (2011), in the BKCI the\nfollowing book formats are considered scholarly: dissertations, textbooks, books\nin series, reprinted/reissued content, translations and non-English content,\nbiographies and reference books. However, this classification is of no use for\nbibliometric purposes as the ambiguity in the definition of each of these formats\nprevents us from establishing a relation between citation or usage patterns and\ndocument types as is done with journal articles (reviews, letters, notes, research\narticles, etc.). In relation to this, Torres-Salinas and Moed (2009) also point out\nthe lack of book typologies as a shortcoming when assessing monographs and\nsuggest three possible criteria: a) authorship of the monograph (authored versus\nedited works), b) research intensity (books primarily for teaching versus books\nprimarily for research), and c) research focus (books for a specialized scientific\naudience versus books for broader audiences). However, such classifications\ncannot be found in databases or library catalogues, forcing us either to make no\ndistinction, or use an erroneous classification which may lead to the wrong\nconclusions, or perform a manual classification. An alternative approach would be\nto classify them according to the traditional book categories described in library\ncatalogues (i.e., handbook, manual, report and research work) and analyse them\nseparately, deciding the level of research intensity after the analysis has been\nundertaken.\nThe second issue to take into account is the proxy chosen as a performance\nindicator when evaluating scholarly monographs. Until the launch of the BKCI, it\nremained extremely difficult to assess books using citation data for large sets of\nrecords; in fact, few studies can be found using large citation data sets regarding\nthe evaluation of books (Gorraiz et al, 2012; Leydesdorff &amp; Felt, 2012; TorresSalinas et al, 2013). What is more, the few studies that use citations as a proxy\nwarn that the patterns observed have many peculiarities that must be taken into\naccount when they are used. One of them has to do with the aging of citations, as\nmonographs seem to need much wider citation windows (Cronin, Snyder &amp;\nAtkins, 1997) than two to five years, as is common with journal articles. This may\nbe a good explanation for the findings described by Torres-Salinas et al (2012),\nwho observed that more than 70% of the books and book chapters indexed since\n2005 in the BKCI remained uncited.\nIn order to solve not only these shortcomings but also the issue regarding data\navailability, other proxies have been suggested in the literature for evaluating\nmonographs based on: a) library holdings, such as the number of catalogue entries\nper book title in WorldCat® (Torres-Salinas &amp; Moed, 2009), library bindings\n1240\n\n(Linmans 2010), or even introducing an indicator of perceived cultural benefit\n(White et al,2009); b) document delivery requests (Gorraiz &amp; Schlögl, 2006); c)\npublishers’ prestige (Giménez-Toledo, Tejada-Artigas &amp; Mañana-Rodríguez,\n2012);d) book reviews (Zuccala &amp; van Leeuwen, 2011). However, none of these\nhas been adopted unanimously by the bibliometric community, mainly because\nobtaining the data is difficult and time consuming.\nFinally, the last issue that needs to be resolved has to do with the different\npractices observed across disciplines. This is also observed when analysing\njournal articles, but it may be even more acute with monographs as these are most\ncommonly used in the humanities and social sciences in which practices are more\nfragmented and there is a strong national factor biasing researchers’ behaviour\n(Hicks, 1999). The role played by monographs is especially important in these\nfields as they form one of the main channels for scholarly communication (Hicks,\n2004; Research Information Network, 2009, 2011; Williams et al, 2009).\nData &amp; Methodology\nWe conducted a pilot study to test the extent to which library loans could be used\nas a proxy to measure monographs’ relevance within the scientific community.\nSuch analysis was performed in two non-Anglo-Saxon European university\nlibraries: the library of the University of Granada (Spanish-speaking) and the\nVienna University Library (German-speaking). Both of them are universities with\nseveral centuries of history and both libraries are universal with strong social\nsciences and humanities components.\nBriefbackground of the institutions (structure) and description of their loan\nsystems:\nA) Granada:\nOne of the historic universities of Spain, the University of Granada was founded\nin 1531. Despite its encyclopaedic character, it is a university with strong social\nsciences and humanities components, these being areas to which 47.6% of the\nresearch staff are affiliated (University of Granada, 2011). Its library system\ncomprises 21 libraries which are located within faculties, institutes and research\ncentres, providing services to more than 80,000 students, 3,650 researchers and\n2,000 technical and administrative staff. According to the last library report\n(University of Granada, nd), there are 1,042,575 monographs. The integrated\nlibrary system developed by Innovative was established in 2001 in the library\npremises; the loan system was centralized by means of Millenium software and\naffords a number of different reports concerning loans and renewals of\nmonographs and other materials.\n\n1241\n\nB) Vienna\nFounded in 1365, the Vienna University Library is the oldest university library in\nthe German-speaking countries;116 it is also the largest library in Austria with an\ninventory of over 6.8 million books. It comprises a main central lending library\n(2.6 million volumes) and 40 specialist libraries, providing researchers, teachers\nand students with specialist literature on almost all specific academic subjects. It\nprovides services to approximately 91,000 students and a university staff of 9,400\nemployees, of whom 6,700 are academic. For some disciplines, such as medicine,\nveterinary medicine, economics, agriculture and technical subjects, there are\nadditional universities with corresponding university libraries in the city. Since\nthe winter semester of 1986, loans have been managed electronically; in 1989, an\nelectronic catalogue was also introduced. In 1999, the Aleph integrated library\nsystem replaced the previous software. In 2010, around 4 million book loans and\n65,000 active borrowers were counted.\nData retrieval and processing\nData were gathered from the Universities of Vienna and Granada library systems\nin December 2012 regarding loans from, respectively, 2001 and 2000 onwards.\nFor every monograph copy we recorded the following fields: book title, author,\nlocation, publisher, country and year of edition, language, year of acquisition by\nthe library, ISBN, number of loans, and number of renewals.\nFor the University of Granada, only copies of bibliographic material with more\nthan 50 loans were recorded. Afterwards, loan data for every title were\naggregated, regardless of their publication year or publisher. Books with the same\ntitle but different authors were also detected and considered separately. For the\nVienna sample, loan data were analysed at the level of bibliographical records.\nThus, all copies of a certain edition were automatically aggregated, but different\neditions of one work were covered separately. Also, Granada distinguished book\ntypes according to the library’s classification. For this study, we decided to use\nthree main book types:\n-\n\nREF = reference books,such as dictionaries, etc.\nMTB = manuals, textbooks, handbooks, etc.\nSM= scientific monographs\n\nThese bibliographic types are assigned by librarians at the institution. However,\nsome titles were assigned to two different types (MTB and SM). For those\nmaterials, all the copies were recoded as MTB. We also coded as MTB those\nmonographs with the following words in their titles for Spanish and English\nlanguage books: Course, Encyclopedia, Foundations, Introduction, Methods,\nPrinciples, Treaty, Grammar, Atlas, Compendium, Handbook and Textbook.\n116\n\nhttp://bibliothek.univie.ac.at/english/about_us.html\n\n1242\n\nAdditionally, after carefully checking every SM title, some other books were\nrecoded as MTB. Finally, books with Law, Code or Dictionary in the title were\nrecoded as reference books (REF). As Vienna lacked a classification of materials,\nthis differentiation was manually performed by two librarians in line with the\ncriteria used by the University of Granada and described above. The error ratio\nwas less than 5%.\nFor this first pilot analysis, we retrieved the 1000 most borrowed monographs by\nall types of users since the loan system at each library was implemented (1999–\n2000 for Vienna, 2001 for Granada). At the University of Vienna and in view of\nthe initial results, it was also possible to collect data on the 1000 monographs\nmost borrowed exclusively by scientists and without considering those from the\nFaculty of Law library. We then performed analyses and comparisons between all\nsamples at three different levels: book types, language and publisher.\nFurthermore, for the 100 first most borrowed scientific monographs (SM) and the\n100 first most borrowed manuals and textbooks (MTB) citation counts were\nperformed:1) in Web of Science using the “Cited Reference Search”, and 2) in\nGoogle Scholar using the Publish or Perish software (Harzing, 2007), which\ncalculates various bibliometric indicators based on the data retrieved from this\ndatabase. All citation data were manually disambiguated and aggregated in both\ndata sources.\nTable 1.Loans by document type for the three samples\nTYPE\nMTB\nSM\nGranada\nREF\nTOTAL\nMTB\nSM\nVienna\nREF\nTOTAL\nMTB\nSM\nVienna\nOnly Scientists REF\nTOTAL\n\nTITLES\n%\nLOANS\n%\nLOANS/TITLE MAX MIN\n706 70.6\n290943 81.3\n412\n3922\n110\n245 24.5\n49465 13.8\n202\n844\n110\n49\n4.9\n17300\n4.8\n353\n1751\n113\n1000 100.0\n357708 100.0\n358\n3922\n110\n334 33.4\n166895 27.5\n500\n2372\n207\n200 20.0\n60121\n9.9\n301\n1087\n206\n466 46.6\n380651 62.6\n817\n7090\n207\n1000 100.0\n607667 100.0\n608\n7090\n206\n162 16.2\n1690 15.9\n10\n30\n8\n782 78.2\n8199 77.2\n10\n29\n8\n56\n5.6\n738\n6.9\n13\n33\n8\n1000 100.0\n10627 100.0\n10627\n33\n8\n\nResults\nA) Loans by document type\nThe results for both universities are summarized in Table 1. As already mentioned\nabove, the analyses were performed in both universities at edition level and not at\ntitle level. In the sample from Vienna (Top 1000, all users) only five books (4\nMTB and 1 REF) had the same ISBN and approximately 12% were related to\nmore than one edition (thereof ~ 60% REF). In the second sample (Top 1000,\nonly scientists),only one book (SM/MTB) had the same ISBN twice and only\n1243\n\n1.1% of the titles had multiple editions (thereof ~ 60% REF). For the University\nof Vienna, 119 monographs (~ 10%) comprised both sample 1 and sample 2 (~\n36% SM, ~ 36% REF, ~ 28% MTB). The Pearson correlation between loans to all\nusers and loans to scientists only was rather low (about 0.20).\nIn the sample from Granada, more than 70% of the most borrowed books (706\ntitles) were found to be manuals, textbooks and handbooks (MTB), this\npercentage increasing to 81.3% when taking loans into account. Loans per title for\nthe top MTB were twice the loans per title for top scientific monographs (SM).\nThis category accounts for 24.5% of the loans, while REF books (mainly\ndictionaries) are just 4.9% of the loans for the Spanish library (Table 1).\nThe results show a very similar number of scientific monographs in both\nuniversities (20% vs. 24%) when considering loans to all users. The differences\nbetween the other document types (MTB and REF) can be explained by the large\nnumber of books related to law at the University of Vienna (almost 50%), most\nprobably due to their high prices.When considering the number of loans, the rate\nfor scientific monographs drops to 10% in agreement with a lower loan frequency\nin comparison with the other document types, MTB and REF (see “loans per title”\nin Table 1). When considering loans to scientists only, the amount of SM grows\nabruptly to 78%.\nTable 2.Loans by language for the three samples\n%\n%\nLOANS/\nLANGUAGE TITLES TITLES LOANS LOANS TITLE MAX MIN\nSpanish\n938\n93.8 343935\n96.1\n367 3922 110\nEnglish\n47\n4.7\n10750\n3.0\n229\n675 133\nMultilingual\n7\n0.7\n1344\n0.4\n192\n431 137\nFrench\n3\n0.3\n938\n0.3\n313\n649 111\nGranada\nGerman\n3\n0.3\n420\n0.1\n140\n157 114\nItalian\n2\n0.2\n321\n0.1\n161\n191 130\nTOTAL\n1000\n100.0 357708\n100.0\n358 3922 110\nGerman\n945\n94.5 582559\n95.9\n616 7090 206\nEnglish\n55\n5.5\n25108\n4.1\n457 1221 206\nVienna\nTOTAL\n1000\n100.0 607667\n100.0\n608 7090 206\nGerman\n653\n65.3\n7093\n66.7\n11\n33\n8\nEnglish\n318\n31.8\n3250\n30.6\n10\n30\n8\nFrench\n13\n1.3\n109\n1.0\n8\n13\n8\nItalian\n7\n0.7\n68\n0.6\n10\n10\n8\nSerbian\n3\n0.3\n45\n0.4\n15\n20\n10\nSpanish\n1\n0.1\n9\n0.1\n9\n9\n9\nVienna\nOnly Scientists Lithuanian\n1\n0.1\n9\n0.1\n9\n9\n9\nCroatian\n1\n0.1\n17\n0.2\n17\n17\n17\nRumanian\n1\n0.1\n8\n0.1\n8\n8\n8\nCzech\n1\n0.1\n10\n0.1\n10\n10\n10\nHungarian\n1\n0.1\n9\n0.1\n9\n9\n9\nTOTAL\n1000\n100.0\n10627\n100.0\n11\n33\n8\n1244\n\nB) Loans by language\nThe results for all three samples are represented in Table 2. Granada and Vienna\nshow very similar results when we consider the language distribution of the top\n1000 borrowed books. Almost identical percentage values were reported in both\nuniversities: about 94% of the 1000 most borrowed titles are in each country’s\nlanguage, Spanish and German. The percentage of loans for books in national\nlanguages is even higher (96%). Despite being the scientific “lingua franca”,\nEnglish is not popular within these academic communities as in both universities\nthe percentage of books in English stays at around 5%. For the only scientists\nsample in Vienna, this percentage grows to more than 30%, showing an important\ndifference in comparison to the all users sample.\nC) Loans by publisher\nTables 3–5 show the top publishers according to the number of titles (or editions)\nrespectively for all three samples.\nThe alternation of national (Ariel, Pirámide, Manz, Facultas WUV, etc.) and\ninternational publishers (McGraw Hill, Prentice, Springer, Pearson, etc.) is similar\nin both distributions (see Tables 3 and 4). The highest concentration reported for\nVienna (only two publishers, Manz and Facultas.WUV account for almost half of\nthe most borrowed books while in Granada ten publishers are needed to surpass\n50% of loans) is explained by the predominant role of Manz as the Austrian\npublisher for law and other reference texts related to law (see also results by\ndocument type). In contrast, the names and proportions of the international\npublishers in both rankings are quite different. For example, McGraw-Hill, top in\nGranada, does not appear in the top 20 for Vienna, and Springer, top in Vienna, is\nnot present in Granada’s top ranking.\nWhen comparing both samples, the publisher distribution is considerably less\nconcentrated for only scientists (~340 publishers) than for all users (~140\npublishers for Vienna and ~240 for Granada). Other particularities for the Vienna\nloans to scientists only (see Table 5) are the appearance of new publisher names,\namongst them many foreign university press companies, and the homogeneity of\nthe number of loans per title for all top publishers which fluctuate between nine\nand 13 loans.\n\n1245\n\nTable 3.Distribution of the top 20 publishers in the Granada sample\nPUBLISHER\nMcGraw-Hill\nAriel\nPirámide\nPrentice Hall\nAlianza Editorial\nEdit. Médica Panamericana\nSíntesis\nTecnos\nMasson\nPearson Education\nTirant lo Blanch\nOmega\nElsevier\nComares\nThomson\nUniversidad de Granada\nReverté\nOxford University Press\nAddison Wesley\nDifusión\nAkal\nCátedra\n\nTITLES LOANS % LOANS LOANS/TITLE\n105\n47690\n13.3\n454\n39\n12927\n3.6\n331\n37\n12736\n3.6\n344\n37\n17220\n4.8\n465\n35\n10511\n2.9\n300\n32\n15701\n4.4\n491\n27\n15762\n4.4\n584\n26\n14353\n4.0\n552\n25\n6805\n1.9\n272\n23\n10722\n3.0\n466\n22\n17298\n4.8\n786\n18\n9580\n2.7\n532\n18\n7641\n2.1\n425\n18\n4738\n1.3\n263\n17\n5167\n1.4\n304\n15\n4980\n1.4\n332\n14\n5736\n1.6\n410\n13\n3991\n1.1\n307\n13\n6291\n1.8\n484\n11\n3117\n0.9\n283\n11\n2828\n0.8\n257\n10\n1730\n0.5\n173\n\nTable 4. Distribution of the top 20 publishers for the Vienna sample (all users)\nPUBLISHER\nManz\nFacultas.WUV\nLexisNexis-Verl. ARD Orac\nSpringer\nPearson Prentice-Hall\nLinde\nBeltz\nVS Verl. Für Sozialwiss.\nThieme\nBöhlau\nHogrefe\nOldenbourg\nSpektrumAkad. Verl.\nWestdt. Verl.\nHuber\nVerl. Österreich\nWiley-VCH\nLeske + Budrich\nUVK-Verl.-Ges.\nElsevier, SpektrumAkad. Verl.\n1246\n\nTITLES LOANS % LOANS LOANS/TITLE\n174 177505\n29.2\n1020\n132\n93853\n15.4\n711\n123\n66405\n10.9\n540\n65\n47741\n7.9\n734\n38\n19689\n3.2\n518\n35\n17944\n3.0\n513\n23\n14982\n2.5\n651\n19\n6847\n1.1\n360\n16\n6661\n1.1\n416\n16\n9520\n1.6\n595\n16\n7996\n1.3\n500\n14\n8702\n1.4\n622\n13\n6332\n1.0\n487\n13\n4363\n0.7\n336\n12\n4687\n0.8\n391\n11\n7379\n1.2\n671\n11\n4336\n0.7\n394\n9\n2927\n0.5\n325\n9\n3386\n0.6\n376\n9\n3174\n0.5\n353\n\nTable 5.Top publishers with more than 10 titles for the University of Vienna sample,\nonly scientists\nPUBLISHER\nSuhrkamp\nBöhlau\nOxbow Books\nManz\nCambridge Univ. Press\nCampus-Verl.\nSpringer\nOxford Univ. Press\nBeck\nRoutledge\nFink\nFacultas.WUV\nVS Verl. Für Sozialwiss.\nTranscript\nde Gruyter\nTempus\nMetzler\n\nTITLES\n46\n38\n32\n28\n26\n25\n24\n22\n21\n20\n20\n18\n15\n13\n11\n10\n10\n\nLOANS\n492\n423\n295\n365\n253\n296\n302\n214\n230\n216\n203\n193\n145\n126\n110\n92\n118\n\n% LOANS\n4.6\n4.0\n2.8\n3.4\n2.4\n2.8\n2.8\n2.0\n2.2\n2.0\n1.9\n1.8\n1.4\n1.2\n1.0\n0.9\n1.1\n\nLOANS/TITLE\n11\n11\n9\n13\n10\n12\n13\n10\n11\n11\n10\n11\n10\n10\n10\n9\n12\n\nCorrelations between loans and citations\nThe mean number of loans for the 100 most borrowed scientific monographs\n(SM) and the 100 most borrowed manuals (MTB) was 771.6 (Granada) and 640\n(Vienna) respectively, showing for both samples a much higher number of loans\nfor those books coded as MTB. Regarding citations, the results show a mean\nvalue of 171.5 and 260.7 respectively for Google Scholar, and 25.4 and 53.7\nrespectively when using Web of Science to retrieve citations. The median of\ncitations was 36 and 18 respectively for the GS sample and only two and 7.5\nrespectively for the Web of Science sample. When comparing SM and MTB, the\ndifferences in loans and citations were statistically significant (CI=95%, p&lt; 0.05),\nMTB median values being much higher than the SM values, with the only\nexception being Google Scholar citations for the Vienna sample (see Table 6). It\nis also worth mentioning the sizeable differences between numbers of citations in\nboth databases, with Google Scholar being more exhaustive.\nFinally, we performed a correlation analysis by means of the Spearman\ncoefficient (Rho) to test the extent to which loans and citations gathered by both\nmethods were similar. The results show that for the Granada case, there is no\ncorrelation at all between loans and citations, regardless of the citation source\nused and the type of monograph (Table 7). Only correlations between citations\ngathered from both sources were found to be statistically significant. It is worth\nnoting that this value is higher for scientific monographs (0.765; 0.481 for\nVienna) than for handbooks (0.577; 0.466 for Vienna). A statistically significant\ncorrelation (0.310) between loans and citations as measured by Google Scholar\n1247\n\nwas detected for MTB books in the Vienna sample. However, this correlation is\nso weak that is not appropriate to infer any kind of consistent finding regarding\nloans and citations. Also, the correlation between citations regarding both\ndatabases for MTB and SM books was very weak (less than 0.5).\nTable 6. Loans and citations analyses for the 100 most borrowed SM and MTB titles\nMTB\nSM\nTOTAL\nGRANADA\nloans\n1245,6 ± 575,7 (1061,5) 297,7 ± 132,4 (254,5) 771,6 ± 632,0 (698,0)\ncitations_GS\n173,9 ± 387,7 (58,5)\n169,1 ± 533,1 (25,0) 171,5 ± 465,0 (36,0)\ncitations_WOS\n22,8 ± 66,4 (4,0)\n28,1 ± 167,3 (1,0)\n25,4 ± 127,0 (2,0)\nVIENNA\nloans\n908,1 ± 330,8 (841,5) 371,9 ± 110,8 (336,5) 640,0 ± 364,4 (580,0)\ncitations_GS\n244,7 ± 805,1 (7,0)\n276,6 ± 1475,5 (23,0) 260,7 ± 1185,7 (18,0)\ncitations_WOS\n62,5 ± 200,2 (12,5)\n44,9 ± 138,9 (6,0)\n53,7 ± 172,1 (7,5)\n\nMann-Whitney Test: CI=95%; p&lt;0.05. Results are reported as Mean ± Standard Deviation (median)\n\nTable 7. Spearman correlation coefficients for loans, citations and book type\n\nGRANADA\nloans\nRho\nSig.\ncitations_GS Rho\nSig.\nVIENNA\nloans\nRho\nSig.\ncitations_GS Rho\nSig.\n\nMTB\nSM\ncitations_GS citations_WOS citations_GS citations_WOS\n0.135\n0.181\n\n0.081\n0.421\n0.577*\n0.000\n\n0.099\n0.328\n\n0.115\n0.254\n0.765*\n0.000\n\n0.310*\n0.002\n\n0.189\n0.059\n0.466*\n0.000\n\n0.032\n0.751\n\n0.060\n0.550\n0.481*\n0.000\n\n*Correlation is statistically significant at 0.01 level (2-tailed)\n\nDiscussion and concluding remarks\nIn this paper we analyse whether library loans might be used as a proxy for the\nmeasurement of monograph use and the feasibility of using library loans as a\npossible selection criterion for including monographs in citation indexes. To this\nend, we conducted an exploratory study analysing loan data and citation data from\ntwo university libraries which represent two non-Anglo-Saxon academic\ncommunities, a Spanish-speaking community and a German-speaking\ncommunity.\nMethodologically, this has not been an easy process. A number of technical\nfactors need to be considered before taking loans as a valid measure for the useof\nmonographs and subsequently as a selection criterion for book citation indexes:\n1248\n\nthe publication year is not the acquisition year, extensions, loan times or loan\ncounts, differentiation of the user types and materials, different counts in different\nlibraries, multiple editions and copies, etc. Also, the loan time can differ between\nuniversities and types of users and materials. Finally, some books could be\nclassified as not for loan due to several reasons, so no data could be gathered for\nthem. It is also worth mentioning the presence of library departments which loan\nbooks that may not be within the general automated library system.\nAs shown in our study, different approaches can be taken, such as measuring\nnumbers of copies, editions or titles of monographs. Also, the aggregation of\ncounts from different editions and translations should be considered, as a number\nof the most “popular” books happen to be translations of Anglo-Saxon\nmonographs. Counting only the translations could miss the academic impact of a\nbook as a whole. One additional technical difficulty is the detection of citations\nreferring to different books where the title coincides in various languages, as\nhappens for titles such as Economia (Economy) or Biologia (Biology) in Spanish,\nPortuguese and Italian. Usually handbooks and manuals have a broad coverage,\nso the titles are very short (one or two words in many cases), which makes it\nimpossible to split citations for every language.\nMost of the top books were manuals, handbooks and textbooks, or reference\nbooks such as those for law and dictionaries.This is understandable as the main\nusers of university libraries are students. The results also show that scientific\nmonographs in both universities account for 20%–25% of the most borrowed\nbooks when considering loans for all users. However, this percentage increases to\n78% when analysing loan patterns for scientists only. This fact points to the need\nto differentiate between types of users to assess more precisely the reliability of\nloans as a usage indicator for monographs.\nA second conclusion is that both academic communities (Vienna and Granada)\nprefer to borrow books in their respective languages, regardless of the original\nlanguage of the publication. The outstanding percentage (around 95% for Spanish\nand German) of loans for publications in national languages could be explained\nby the type of users, mainly students. When assessing the loan behaviour of\nscientists only (solely for the Vienna sample), we have found that they are more\nlikely to borrow English monographs than the other user groups. This is not\nsurprising as these monographs are expected to convey more specialized\ninformation which could justify the lack of a translation of such books. However,\nfor the Vienna scientists, German is also the preferred language when looking up\ninformation in scientific monographs, with more than 65% of the most borrowed\nbooks being in German.\nThe rankings of publishers according to the most borrowed books also show the\npresence of both international publishers and local well-known publishing houses.\n1249\n\nBoth of these tend to distribute scientific monographs and handbooks with a\nbroad orientation and these are the materials most borrowed from academic\nlibraries.\nWe also have found important differences in the number of citations retrieved\nusing Web of Science and Google Scholar. Google Scholar has gathered more\ncitations than Web of Science for most of the samples when considering the\nmedian number of citations. The exception is the Vienna sample for MTB where\nWeb of Science retrieves a higher number of mentions with respect to those\nmonographs. Standard deviations for citation statistics suggest that within the\nmost borrowed books, highly cited books coexist with other monographs that are\nnot noticed by the scientific community.\nRegarding citations relating to the most borrowed books, it is important to\nmention the lack of correlation between these two variables in our study for the\nGranada sample and the very weak correlation for Vienna MTB books when\nusing Google Scholar. The fact that the books cover a broad range of topics,\nmainly in languages other than English and of a general nature, may be important\nfor the interpretation of this finding. We also have to consider the different\ncitation behaviours in each discipline and the aging of books, further issues which\nmay affect these results, along with the aforementioned technical difficulties.\nThese considerations also lead us to think that a discipline-focused study could\nshed more light on the validity of loans as a criterion for selecting monographs in\nselective indexes than could a broad study.\nThis study also confirms the need for facilities to aggregate different editions and\ntranslations of a certain book under one record in order to indicate the actual\nrelevance of the overall work. It could be a future task for academic libraries to\nprovide usage data, especially concerning book loans for regular systematic\nanalyses, as they still constitute an important aspect of the scholarly\ncommunication process, though rarely recognized by bibliometric studies to date.\nAcknowledgments\nWe would like to thank the Library of the University of Granada for facilitating\nthe provision of the data for the purposes of this study. Nicolás Robinson-García\nis currently supported by an FPU grant from the Ministerio de Economía y\nCompetitividad of the Spanish Government.\nReferences\nCronin, B., Snyder, H. &amp; Atkins, H. (1997). Comparative citation rankings of\nauthors in monographic and journal literature: a study of sociology. Journal of\nDocumentation, 53(3), 263–273.\n\n1250\n\nGiménez-Toledo, E., Tejada-Artigas, C. &amp; Mañana-Rodríguez, J. (2013).\nEvaluation of scientific books’ publishers in social sciences and humanities:\nresults of a survey. Research Evaluation, 22(1), 64–77.\nGorraiz, J., Purnell, P. &amp; Glänzel, W. (2013).Opportunities and limitations of the\nBook Citation Index. Journal of the American Society of Information Science\nand Technology, in press\nGorraiz, J. &amp; Schlögl, C. (2006). Document delivery as a source for bibliometric\nanalyses: the case of Subito, Journal of Information Science, 32(3), 223–237.\nHarzing, A.W. (2007).Publish or Perish. Available\nat:http://www.harzing.com/pop.htm\nHicks, D. (1999).The difficulty of achieving full coverage of international social\nscience literature and the bibliometric consequences. Scientometrics, 44(2),\n193–215.\nHicks, D. (2004). The four literatures of social science.In Moed, H.F., Glänzel,\nW. &amp;Schmoch, U. (Eds.). Handbook of Quantitative Science and Technology\nResearch: The Use of Publication and Patent Statistics in Studies of S&amp;T\nsystems. Kluwer Academic Publishers, Netherlands, pp. 473–496.\nLeydesdorff, L. &amp; Felt, U. (2012). Edited volumes, monographs and book\nchapters in the Book Citation Index (BKCI) and Science Citation Index (SCI,\nSoSCI, A&amp;HCI). Journal of Scientometric Research,1(1), 28–34.\nLinmans, A.J.M. (2010). Why with bibliometrics the humanities does not need to\nbe the weakest link. Indicators for research evaluation based on citations,\nlibrary bindings and productivity measures. Scientometrics, 83(2), 337–354.\nNederhof, A.J. (2006). Bibliometric monitoring of research performance in the\nsocial sciences and the humanities: areview. Scientometrics, 66(1), 81–100.\nPrice, D. de S. (1963). Little Science, Big Science. New York, Columbia\nUniversity Press.\nPriem, J., Taraborelli, D., Groth, P.&amp;Neylon, C. (2010).Almetrics: a manifesto.\nAvailable at: http://altmetrics.org/manifesto/\nResearch Information Network (2009). Communication knowledge: how and why\nUK researchers publish and disseminate their findings. Joint Information\nSystems Committee.Available at: http://www.rin.ac.uk/communicatingknowledge\nResearch Information Network (2011).Reinventing research? Information\npractices in the humanities. Joint Information Systems Committee.Available\nat:\nhttp://www.rin.ac.uk/system/files/attachments/Humanities_Case_Studies_for_\nscreen_2_0.pdf\nTorres-Salinas, D.&amp;Moed, H.F. (2009).Library Catalog Analysis as a tool in\nstudies of social sciences and humanities: an exploratory study of published\nbook titles in Economics. Journal of Informetrics, 3(1), 9–26.\nTorres-Salinas, D., Robinson-García, N., Jiménez-Contreras, E. &amp; Delgado\nLópez-Cózar, E. (2012).Towards a ‘Book Publishers Citation Reports’. First\n\n1251\n\napproach using the ‘Book Citation Index’.Revista Española de Documentación\nCientífica, 35(4), 615–620.\nTorres-Salinas, D., Rodriguez-Sánchez, R., Robinson-García, N., Fdez-Valdivia,\nJ. &amp; García, J.A. (2013).Mapping citation patterns of book chapters using the\nBook Citation Index. Journal of Informetrics, in press.\nTesta, J. (2011) The book selection process for the Book Citation Index in Web of\nScience. Available at: http://wokinfo.com/media/pdf/BKCISelectionEssay_web.pdf\nUniversity of Granada (2011).Memoria básica de investigación 2011. Granada.\nUniversity of Granada (nd). Anuario de la Biblioteca de la UGR. Año 2011.\nGranada.\nWhite, H., Boell, S.K., Yu, H., Davis, M., Wilson, C.S. &amp; Cole, F.T.H. (2009).\nLibcitations: A measure for comparative assessment of book publications in\nthe humanities and social sciences. Journal of the American Society of\nInformation Science and Technology, 60(6), 1083–1096.\nZuccala, A., &amp; van Leeuwen, T. (2011). Book reviews in humanities research\nevaluations. Journal of the American Society of Information Science and\nTechnology, 62(10), 1979–1991.\n\n1252\n\nMOTIVATION FOR HYPERLINK CREATION\nUSING INTER-PAGE RELATIONSHIPS\nPatrick Kenekayoro1 Kevan Buckley2 Mike Thelwall3\n1\n\nPatrick.Kenekayoro@wlv.ac.uk 2 K.A.Buckley@wlv.ac.uk 3 M.Thelwall@wlv.ac.uk\nStatistical Cybermetrics Research Group, University of Wolverhampton, Wulfruna St\nWolverhampton, West Midlands WV1 1LY (UK)\n\nAbstract\n\nUsing raw hyperlink counts for webometrics research has been shown to be unreliable and\nresearchers have looked for alternatives. One alternative is classifying hyperlinks in a\nwebsite based on the motivation behind the hyperlink creation. The method used for this\ntype of classification involves manually visiting a webpage and then classifying individual\nlinks on the webpage. This is time consuming, making it infeasible for large scale studies.\nThis paper speeds up the classification of hyperlinks in UK academic websites by using a\nmachine learning technique, decision tree induction, to group web pages found in UK\nacademic websites into one of eight categories and then infer the motivation for the\ncreation of a hyperlink in a webpage based on the linking pattern of the category the\nwebpage belongs to.\n\nKeywords:\n\nwebometrics, decision tree induction, link classification, supervised learning\n\nIntroduction\nWebometrics has been defined as “the study of web based content with primarily\nquantitative research methods for social science goals using techniques that are\nnot specific to one field of study” (Thelwall, 2009). Techniques from different\nfields like mathematics and statistics have been applied to study web content for\nwebometrics research. Machine learning is an area in computer science that is\nconcerned with pattern discovery. This technique has not been used extensively in\nwebometrics research, but has been applied in several computing web studies, for\nexample (Chau &amp; Chen, 2008; Luo, Lin, Xiong, Zhao &amp; Shi, 2009; Qi &amp;\nDavison, 2009).\nA particular area where machine learning can be applied to webometrics research\nis in link analysis. Link analysis involves the study of link relationships between a\ngroup of websites or the link structure of a group of websites. It has been\nsuccessfully used as a source of business intelligence (Vaughan &amp; Wu, 2004;\nVaughan, 2005) and used in several studies of academic websites (Thelwall,\n2002c; Thelwall &amp; Wilkinson, 2003). Nevertheless, using raw link counts\nbetween websites can be unreliable and several researchers have attempted to find\nalternatives to raw link counting or tried to understand the meaning of link counts\nbetween websites. Researchers have classified links in the web pages of academic\n1253\n\ninstitutions as research or non-research related (Thelwall, 2001), substantive or\nnon-substantive (Smith, 2003) and shallow or deep (Vaseleiadou &amp; van den\nBesselaar, 2006). Other researchers have tried to identify the reasons why links in\nacademic web pages were created (Bar-Ilan, 2004; Wilkinson, Harries, Thelwall,\n&amp; Price, 2003) but there is no agreement about an effective way to classify the\nreasons for university interlinking on a large scale, which is the goal of this paper.\nThe manual classification of individual links is time consuming, thus it is\ninfeasible for large scale studies. Perhaps this is the reason why there is a dearth\nof literature in link classification. In this paper, the reason for link creation is\ninferred from the relationship between the two pages the hyperlink connects; the\nsource page and the target page. Hyperlinks have been previously classified using\nthe target page (Thelwall, 2001), using both the source and target page can give\nbetter insight to the reason for hyperlink creation and web page classification is a\nsimpler problem than individual link classification.\nTypically, a university’s website has thousands of web pages so an effective\napproach will be to group similar web pages together and then infer why a link is\ncreated based on the link creation motivation of the group that web page belongs\nto. This makes it necessary to identify the types of web pages that can be found in\na university’s website. Page types are identified using the mission of a university\nand the function of its website as a guide.\nStuart, Thelwall and Harries (2007) suggest that methods for automatic\nclassification of hyperlinks should be developed if links are to be fully harnessed\nfor webometrics research. The reason why a link is created, that is the relationship\nbetween the source and target page can form classes of links in a university’s\nwebsite. Machine learning techniques are used to automate the classification\nscheme, there by bringing us a step closer to fully harnessing hyperlinks for\nwebometrics research.\nThe main goal of this study is to identify a method that effectively determines the\nreason why a link in a UK university’s website has been created. This is achieved\nby grouping web pages into categories that are in line with the three missions of\nHigher Education Institutions (HEIs), automating the classification scheme with\nmachine learning techniques and then examining the relationship between page\ncategories. This paper begins with background information on link classification,\nthe supervised learning technique used in this study, then, categories of pages that\ncould be found in UK university’s websites are identified, and the results of\nclassification with a supervised learning technique are shown and the relationship\nbetween a random sample of web pages analysed.\nLink Classification\nWebometrics can be used as a source of business intelligence. Vaughan and Wu\n(2004) showed that a link count to a company’s website positively correlates with\nthe company’s business performance and co-linked web pages were used to\nidentify a company’s competitors (Vaughan, 2005). Webometrics has also been\napplied in the study of academic institutions (Payne &amp; Thelwall, 2004; Thelwall\n1254\n\n&amp; Wilkinson, 2004; Vaughan &amp; Thelwall, 2005) and in the identification of\npolitical trends (Park &amp; Thelwall, 2008; Romero-Frías &amp; Vaughan, 2010;\nRomero-Frías &amp; Vaughan, 2012).\nRaw link counts are unreliable (Thelwall, 2002a; Thelwall, 2002b) because links\nare prone to spamming (Smith, 1999) and there could be different motivations\nbehind the creation of hyperlinks (Wilkinson et al., 2003). There are different\nreasons behind link creation, it can vary according to the function and operational\nrelationship between the different organisations studied (Minguillo &amp; Thelwall,\n2011). Linking between municipalities in Finland is motivated by cooperation\nmade possible because of geographic closeness (Holmberg &amp; Thelwall, 2009) and\nco-linking of business web pages tends to be for business reasons (Vaughan,\nKipp, &amp; Gao, 2007) which is different from co linking of university web pages\nthat could just be as a result of general reference. This difference highlights the\ndisparity between linking patterns in different domains, thus caution should be\nused when applying a method tested in one domain to a different domain.\nSeveral attempts have been made to classify web pages in a University’s website\nbut there is no consensus as to how links can be classified and Thelwall (2006)\nsuggests no single link interpretation is perfect. Two approaches to hyperlink\ninterpretation are (Thelwall, 2006)\n Interviewing a random selection of link creators about why they created a\nlink\n Classification of a random selection of links in a way that is helpful to the\nresearch goals\nAuthor interviewing may give a more accurate result but classification of links is\na more practical approach; it is the most common method for hyperlink\nclassification in the academic web space (Bar-Ilan, 2004; Bar-Ilan, 2005;\nThelwall, 2001; Thelwall, 2003; Wilkinson et al., 2003).\nThelwall (2001) classified hyperlinks in web pages of UK academic institutions\nas research related or not research related based on the content of the target page,\nwhich he noted was a practical step. Although classification of some pages was\nsubjective, a situation similar for all research in this area, some general rules were\ncreated to for the classification process. For example, departments’ homepages,\nstaff research profiles, web pages of research groups were classified as research\nrelated while electronic journal pages were classified as non-research related.\nResults showed that using only research related links increased the correlation\nwith average research rating of UK institutions.\nWilkinson and his colleagues (2003) studied 414 random links between UK\nacademic institutions in order to identify the motivations for hyperlink creation.\nEven though individual links were investigated, the reason from link creation was\ndetermined using the source page and target page. They suggest that this\napproach is difficult as it is impossible to guess the motivation for link creation\nand in some cases there could be several motivations.\n\n1255\n\nThelwall (2003) studied 100 random inter site links from a UK university’s’ web\npage to the homepage of another UK university. He grouped web pages into four\ncategories: navigational: a link created to direct uses to other non-subject specific\ninformation, ownership: links to partners and they were often in the form of a\nclickable image of the university’s crest, social: links to institutions of\ncollaborating research groups and gratuitous: links created without any specific\nmotivation.\nBar-Ilan (2004), in perhaps the most systematic study so far, classified the link,\nsource page and target page from different aspects, link context, link tone and\nseveral other properties, in a case study of eight universities in Israel. This\napproach is difficult as Wilkinson and his colleagues (2003) pointed out problems\nwith guessing author motivations and subjective decisions in the classification\nprocess. It is also impractical to study each link individually because of the sheer\nnumber of links that could be found in a university’s website. A more practical\napproach to link classification is finding the relationship between the two pages a\nhyperlink connects, the source and target page, which reduces the problem of\nhyperlink classification to web page classification. To study the relationship\nbetween web pages, the type of pages that could be found in a university’s\nwebsite must be identified.\nSupervised Learning\nAlthough web page classification is simpler than individual link classification,\nthis process is still infeasible for large scale manual studies because a typical\nuniversity’s website can have thousands of web pages.\nSupervised machine learning is a Computer Science technique concerned with\nteaching machines to predict unseen cases of input data based on patterns\nidentified from previously observed examples, usually called a training set. There\nare several machine learning algorithms, like decision tree induction, support\nvector machines, neural networks and k nearest neighbours’ classifiers. Decision\ntree induction has an advantage over other models in that it is easy for humans to\nunderstand the resulting classifier, because of its high level rules, as opposed to\nother black box models like neural networks whose model is encapsulated in a\ncomplex numerical model. For this reason, decision tree induction was used in\nthis study, but other classification techniques may produces similar or better\nresults.\nDecision tree induction\nDecision tree induction recursively splits data into disjoint sets according to a\ncriterion. Each node is a feature an instance can have, and leaf nodes contain\noutput classes for instances that reach that node. Figure 1 is an example of a\ndecision tree classifier that classifies instances into one of three possible classes.\nClassification of instances start at the root node, then the instances traverse down\nthe tree in the direction that meets several criteria until a leaf node is reached. The\nvalue of the leaf node is then assigned to that instance.\n1256\n\nConstructing optimal binary decision trees is a NP-complete problem (Kotsiantis,\nZaharakis, &amp; Pintelas, 2006), however several techniques like the C4.5 algorithm\n(Quinlan, 1993) and CART, acronym for Classification And Regression Trees\n(Breiman, Friedman, Stone, &amp; Olshen, 1984) can be used to build decision trees.\nCART and C4.5 algorithms are implemented in a machine learning toolkit,\nWEKA (Hall et al., 2009) that is used in this study to automate the classification\nscheme.\nX2\n\nX2 &lt; 10\nYes\n\nNo\n\n10\n\nX1 &lt; 10\n\nX1 &gt; 10\n\n10\n\nX1\n\nFigure 1 A Decision Tree Classifier\n\nTwo major phases of a decision tree induction are the growth phase and the\npruning phase (Kotsiantis, 2011). The growth phase involves splitting the training\ndata into disjoint sets and the pruning phase reduces the size of the decision tree\nto avoid overfitting.\nDecision tree induction Pseudo Code (Kotsiantis, 2007)\n1. Check for base cases\n2. For each attribute a\n3.\nFind the feature that best divides the training\ndata\n4. Let a_best be the attribute that best splits data\n5. Create a decision node that splits on a_best\n6. Recurse on the sub-lists obtained by splitting on\na_best and add nodes as children\nA major difference between the C4.5 and CART algorithms is the way the best\nfeature that separates the training data is selected. The attribute with maximum\ninformation gain is used to split the training set. C4.5 uses entropy to compute the\ninformation gain, while CART uses the Gini index. The entropy is calculated by:\n( )\n(\n\n∑\n\n(\n\n)\n\n(\n\n(\n\n))\n\n) is the relative frequency of instances in class Ci.\n1257\n\nThe Gini index is computed by:\n( )\n\n∑\n\n(\n\n)\n\nAnd information gain is computed by:\n(\n\n)\n\n( )\n\n∑\n\n( )\n\nThe formula above computes the information gain of attribute A in data set S\nwhere\nare possible values of attribute A,\nare partitioned subsets\nof S where attribute A is , ( ) is the entropy in C4.5 algorithm and Gini index in\nCART algorithm.\nTesting and Evaluation\nIt is essential to evaluate the accuracy of a learning algorithm. The fundamental\nassumption of machine learning is that the distribution of training data is identical\nto the distribution of test data and future examples (Liu, 2006). If the learning\nalgorithm generalizes the training set, then the machine learning assumption\nsuggests that it will perform well for future unseen examples. Generalization is\nestimated by the accuracy of the learning algorithm, measured by the equation:\n\nUltimately, the accuracy measure depends on the application which applies the\nlearning model. Precision, recall and F-measure give a more elaborate description\nof the performance of a learning algorithm. They are calculated based on four\nparameters: True Positives (TP), False Negative (FN), False Positive (FP) and\nTrue Negative (TN). Given the test set D, if each instance of the set can be of\n(\n) and ( ) is the function trained to predict future unseen\nclass\ninstances. The parameters TP, FN, FP and TN are:\n True Positives (TP) =\n( ( )\n)\n False Negatives (FN) =\n( ( )\n)\n( ( )\n)\n False Positives (FP) =\n True Negatives (TN) =\n( ( )\n)\nPrecision, recall and F-measure is computed by:\n\nPrecision and recall are used when the interest is on one particular class. In most\ncases, the accuracy formula earlier defined as percentage of correctly classified\ndivided by the total number of instances is used.\n1258\n\nA rule of thumb in machine learning is that the input data should be divided into\ntwo-thirds for training and the remaining one-third for tests/validation. Another\ntechnique, cross validation is also used. In cross validation, the input data is\ndivided into equal disjoint subsets. Each subset is used as the test set, and the\nunion of the others the training set. The accuracy of the classifier is the average\naccuracy of the different subsets. A special case of cross validation is the leave\none out approach, where a single example is used as test and all others for\ntraining. In this case, is the number of training examples, thus this method can\nbe computationally expensive.\nPage Types\nBar-Ilan (2005) created a detailed framework for characterising the uses of links\nin an academic website. The scheme had 31 possible relationships between two\npages and 13 different page types. Using machine learning to automate this\nclassification scheme can be difficult because of the number of variables\ninvolved. Moreover, this study aims to group web pages based on the three\nmissions of Higher Education Institutions (HEI) and the functions of its website.\nBar-Ilan&#x27;s (2005) method does not fit into this classification scheme. For example,\na physical unit can comprise of an administrative unit or a research unit. These\ntwo units serve different purposes in regard to the missions of HEIs so they\nshould not be grouped together. Because of this, this study uses a classification\nscheme that is less detailed than (Bar-Ilan, 2005), but is easier to automate with\nmachine learning, and is more in line with the aims of this paper.\nIf the links in a university’s websites are to be classified based on the relationship\nbetween two pages, it is necessary to identify the types of pages that can be found\nin a university’s website, and then study how these page types interlink.\nIn order to identify the type of pages in a university’s website a random set of web\npages in a university’s domain were visited and manually classified. A custom\nweb crawler was designed to get the link structure of 111 UK universities. The\ncrawler extracted links originating from a UK university to another UK\nuniversity, not visiting all pages in a university’s website. It only covers links that\ncan be reached by following links from a university’s homepage, similar to\nThelwall (2001). An additional constraint was added as this work is only\nconcerned with hyperlinks between UK academic institutions. New web pages\nwere not added to the list of websites to visit when the crawler visited 2000\nconsecutive pages without finding a link to another UK university. 15 link pairs\nbetween universities were randomly selected and then the web pages that these\nlinks direct to were used to identify the page types in a university’s website.\nWebsites of organisations are designed to disseminate the activities and functions\nof that organisation. In some cases the structure of the website replicates the\nphysical structure of that organisation. Nowadays, Higher Education Institutions\n(HEIs) have three main goals, teaching, research and what authors simply refer to\nas the third mission. If websites of universities are designed to channel the\nactivities and functions of that university, which in turn are in-line with the (three)\n1259\n\nmain goals of HEIs then university websites will be similar. From a university’s\nhomepage a general idea about the goals of the university as well as the function\nof its website can be inferred. Thus text from the homepages of UK universities\nwas used to determine the types of pages studied in this work. Text from the\nhomepages of UK universities was extracted, and then the top 20 words when\nstop words were removed were used as a guide to determine preliminary page\ntypes.\nTable 1 Page Type and description\nPage Type\nAbout\nBusiness and\ninnovation\nDiscussion\nSupport\nResearch\nStaff\nStudent Life\nStudy\n\nDescription\nPromotes the school and gives information to staff/students. Examples of\nsuch pages are news, information, university profile, prospectus, events\nConnects the school to non-academic environment. Examples include\nexpert services offered, community projects, partnership with science\nparks\nForums, blogs or web page containing opinions of a user. Comments or\nposts in these pages are for a variety of reasons; research, teaching or\nrecreational.\nContains a repository of learning resources for students/staff support,\nskills for learning, services, counselling. Examples include Archives,\nBooks, Database.\nInvolved with the production of new knowledge. Examples include\nResearch centres, research groups, research projects, academic\nschools/departments, conferences, Abstract, Academic Article\nRelated to a staff in the university. Examples include staff homepage,\nstaff profiles, list of publication, CV\nEnhances the student experience. Examples include student union\nwebsite, student benefits, campus facilities, tourism, recreation\nInvolved with transfer of knowledge. Examples include module learning\nmaterials, module timetables, module page, lectures\n\nFigure 2 Distribution of page types in 2500 random UK university web pages\n\n1260\n\n100 random web pages were given to an independent researcher for classification.\nWhen a page type identified by the independent researcher did not fit into the\npreliminary page types, a new category was created.\nThe page types in Table 1 are largely based on the authors’ opinion; top words\nwere only used to assist in the decision process. These page types however, cover\nthe majority of web pages found in university’s websites. Pages were grouped\ninto one of the eight categories and then the possible reasons for link creation\nwere identified for links originating from one page type to another.\nAutomatic Classification\nDecision trees are constructed using features of the training set. Different features\nmay associate a training instance to a particular page type. In this case, training\ninstances are the web pages to be classified. 2500 web pages were randomly\nselected and manually classified into one of eight categories a UK university’s\nweb page could belong to. Two thirds of the web pages were used for training and\nthe rest for testing.\nThe features of each web page were derived from the web page title and/or web\npage URL pre-processed and then represented as a word vector of TF (term\nfrequencies) or inverse document frequency multiplied by the term frequency\n(TFIDF). In this case, a term frequency representation is similar to a binary\nrepresentation because page titles are short thus words rarely occur more than\nonce.\nPre-processing transforms the text to an information rich representation. Preprocessing steps used are:\nWord Tokenization: Splits attributes (web page title/URL) into word tokens. For\nexample “the quick brown fox jumps over the lazy dog” has 9 (nine) tokens of 8\n(eight) word types. A simple way to achieve tokenization is by assuming [space]\nseparates word tokens. Only words that did not contain any non-alphabetic\ncharacters were used in this study.\nCapitalization: All characters were represented in lower case.\nStop word removal: Removal of the most frequent words that occur in the\nEnglish language. Words like “the, and, a, is ... “ are all removed. WEKA (Hall et\nal., 2009) contains the list of stop words that was used in this study. The 111\nuniversity names as well as www, http and https were added to the list of stop\nwords.\nStemming: Stemming reduces inflected words to their root form or stem. For\nexample jumps and jumping have the same stem, jump. Accuracy may be\nimproved if all words are represented in their root form. The Porter Stemmer is a\ncommonly used stemming algorithm and it is used in this study. Stemming\nalgorithms occasionally make errors. For example, the Porter Stemmer stems both\nuniversity and universe to univers.\nWEKA (Hall et al., 2009) implements decision tree induction in its J48 algorithm.\nAlthough the default settings may give satisfactory results, in some cases\ntweaking the settings may improve the accuracy of the algorithm. Feature\n1261\n\nselection as well as data pre-processing is also an important aspect in supervised\nlearning. Table 2 shows how pre-processing options influence the accuracy of the\nclassifier. Training accuracy is determined using a 10 fold cross validation, while\nverification\nis\ndetermined\nusing\nthe\nformula\n; the data set used in\nverification is different from the set used in training. Verification gives an\nestimate of the out of sample performance of the learning algorithm and is also\nused to identify overfitting. A machine learning algorithm overfits when it\nperforms better in training than in testing.\nTable 2 Training and Verification of top 10 pre-processing options of decision tree\ninduction\nBigrams/\nUnigrams\nUnigrams\nUnigrams\nUnigrams\nUnigrams\nBigrams +\nUnigrams\nBigrams +\nUnigrams\nBigrams +\nUnigrams\nUnigrams\nUnigrams\nUnigrams\n\nTF\n*IDF\nYes\nYes\n\nYes\n\nYes\n\nStem\n\nURL\n\nTraining\n\nVerification\n\nYes\n\nPage\ntitle\nYes\nYes\nYes\nYes\nYes\n\nYes\nYes\nYes\nYes\nYes\n\n72.13\n72.16\n71.15\n71.16\n71.57\n\n71.25\n71.25\n69.9\n69.9\n69.66\n\nYes\n\nYes\n\nYes\n\nYes\n\n72.31\n\n69.66\n\nYes\n\nYes\n\nYes\n\nYes\n\n72.32\n\n69.65\n\nYes\n\nYes\nYes\nYes\n\nYes\nYes\nYes\n\n71.86\n72.66\n72.78\n\n68.92\n68.92\n68.55\n\nYes\nYes\nYes\nYes\n\nStop\nwords\nYes\nYes\n\nSettings of the classifier were tweaked and the best results are shown in Table 2.\nOn average, the top 250 features were used in the construction of the decision\ntree.\nWhen word counts are used as features, the number of features increases as the\ntraining set increases. Too many irrelevant features affect the speed as well as\naccuracy of a learning algorithm, so input features have to be carefully selected.\nThe J48 algorithm uses the information gain to select the best feature that\noptimally splits the training data, so it is logical to use information gain to identify\nrelevant features. Other methods like principal component analysis and entropyweighted genetic algorithm can also be used to reduce the size of the features.\nAnother way to reduce the feature size is by generation an initial decision tree\nusing all features, and then excluding those features not used in the initial tree\nduring subsequent training. In tests, only 7 percent of the features were used in\nthe final decision tree. Excluding features that were not used produced a slight\nimprovement in the accuracy of the decision tree.\n\n1262\n\nFigure 3 Influence of feature size on accuracy of the classifier\n\nFigure 3 shows how the number of features affects the accuracy of the decision\ntree classifier when the best pre-processing setting from Table 2 was tested for\ndifferent number of input features. Initially, as the feature size increases, the\naccuracy of the classifier also increases but at some point the increase in size\ndoesn’t improve the accuracy; it only reduces the speed of the decision tree\nclassifier.\nTable 3 Classification Accuracy of each page type\nClass\nAbout\nBusiness and Innovation\nDiscussion\nResearch\nStaff\nStudent Life\nStudy\nSupport\n\nPrecision\n0.59\n0.00\n0.87\n0.63\n0.78\n0.63\n1.00\n0.78\n\nRecall\n0.46\n0.00\n0.89\n0.80\n0.75\n0.29\n0.33\n0.71\n\nF Measure\n0.52\n0.00\n0.88\n0.70\n0.77\n0.40\n0.50\n0.74\n\nThe overall accuracy of the decision tree classifier is about 71%. However it is\ninteresting to know how accurately the classifier identifies individual page types.\nThis is determined using precision, recall and F measure in Table 3. In summary,\nprecision is the likelihood that the classifier will correctly classify a web page of\ntype X as class X, while recall is the likelihood that the classifier will not classify\na web page that is not of type X as class X. F measure is the accuracy of an\nindividual class computed by a formula that depends on the precision and recall.\nFigure 4 shows a partial decision tree for the classification of the web pages. This\nis not the optimal result that can be achieved. The settings of the classifier were\nadjusted to reduce the size of the tree. If the decision tree in Figure 4 is used to\nclassify university web pages, several page types will always be incorrectly\nclassified. Business and Innovation, Study and Student Life pages do not appear\nin any leaf node so they will always be misclassified. Web pages that do not\n\n1263\n\ncontain any of the keywords will be classified as research pages. The tree in\nFigure 4 has an accuracy of 46.8%.\nThe nodes in the tree above show top terms in the feature set that are associated\nwith a specific page type.\nblog\nprofil\npeopl\nstaff\nlibrari\nrepositori\nunivers\nresearch\n\nstaff\nstaff\n\nsupport\nsupport\n\nPage Type\n\nresearch\nabout\n\ndiscussion\nstaff\n\nresearch\n\nKeyword\n\nFigure 4 Tree view of a decision tree induction classifier\n\nInter-page Relationships\nEach page type was studied to identify the type of pages they link to and possible\nreasons for interlinking. 15 random links were randomly selected but at the time\nof the investigation, some of these pages, either the source or target pages were\nnot available online. Such links were excluded from the study.\nWith eight page categories, if each category has a link to all other categories\nincluding itself there becomes\npage relationships to study. However,\nnot all page types interlink and majority of links are between the same page types.\nSubsequent sections describe results for each page type.\n\nFigure 5 Visual representation of interlinking between page types\n\n1264\n\nTable 4 Page types and reasons for link creation\nPage Type\n\nSize\n\nAdditional Notes\n\nSupport\n\n35%\n\n Rarely link to other page types\n Links to research pages that own or created the resource in the support\npage.\n Links are created to direct users to other relevant information, often to\nother pages that are created to improve learning, research or teaching\nskills.\n\nResearch\n\n28.6%\n\n Links to About pages, usually a clickable logo of a collaborating\nuniversity; organisational links as described by Thelwall (2003).\n Pages about research projects had links to staff pages of its\ncollaborators or homepages of research groups or department.\n Research pages had links to all research groups or departments in the\nsame scientific field.\n\nStaff\n\n14%\n\n Links to about pages (homepages of universities) were often what\nThelwall (2003) refers to a gratuitous links.\n Links to support pages that contain a resource, for example, staffs’\npublications.\n Links to other staff pages because of collaboration in a research project\nor co-authorship in a publication.\n\nAbout\n\n9.7%\n\n Are linked to but rarely link to other universities.\n Largely made up of course prospectus and university homepages.\n Majority of outgoing links are for non-scholarly reasons.\n\nDiscussion\n\n9.4%\n\n Links are created for a variety of reasons, so it is very difficult to\nidentify a general pattern.\n Each blog entry belongs to a particular page type, and reasons for\nlinking are the same as reasons of its corresponding page type.\n\nStudent Life\n(SL)\n\n1.8%\n\n Mainly Link to SL pages in close geographic locations.\n A part of the reason why link analysis research shows that UK\nuniversities links to other universities in close geographic location.\n\nStudy\n\n1.2%\n\n Majority of links are to support pages containing information relevant\nto the course.\n Links to research pages that contained software/ research output used in\nthe course.\n Links to staff pages that authored course material, or a visiting\nprofessor\n Represents only a small set of total pages, perhaps because teaching\nmaterials are located on a protected server, thus inaccessible through\npublic web crawlers.\n\nFigure 5 shows how different page types inter links. Vertices represent page types\nand arcs represent links from a page type to another page type. The size of the\nvertices indicates the number of web pages in that page type, while the colour of\narcs indicates the percentage of link from a page type to another page type.\n1265\n\nThicker arcs mean a large percentage of links from that page types go to the page\ntype on the other end of the arc, while bigger vertices mean a large percentage of\nweb pages belong to this page type.\nRandom links are manually classified in order to identify linking patterns of\ndifferent page types. Table 4 shows linking patterns identified for different page\ntypes.\nConclusion and Further Work\nHyperlink classification based on inter-page relationships is a practical solution\ncompared to other methods that try to classify individual links on web pages.\nThis work used the source and target page to determine the reason for linking.\nThe relationship between the source and target pages was similar for web pages in\nthe same category.\nSupport pages had links to its resource creator or pages that gave additional\ninformation that enhances teaching or learning schools. Staff web pages about a\nresearch project are ideal to identify collaboration or cooperation between\ninstitutions. Other research pages only show the amount of research activity going\non in the university. Web pages about the living experience in the university, even\nif they represent only a small part link to web pages in close geographical regions.\nThese links are for non-scholarly reasons and should be excluded when\nidentifying academic relationships between universities. Other page types,\nbusiness and innovation and study web pages contributes less than 1 percent to\nthe total links to other universities, perhaps because they are situated in an area\nnot accessible by web crawlers or link to other non-academic originations.\nAdministrative pages also contained few links to other universities, and they were\nfor non-scholarly reasons. However, majority of links to administrative pages\nwere either gratuitous or as a result of collaboration.\nEven though classification based on inter page relationship is more practical than\nclassifying individual links, it is still infeasible to manually classify each page.\nWeb pages are fewer than hyperlinks, but they cannot be efficiently classified\nmanually because a typical UK university website contains thousands of web\npages. Classification of page types can be automated using a supervised machine\nlearning technique; decision tree induction was used in this study and results\nshowed moderate accuracy; 71%.\nLinks between two staff pages suggest collaboration, and as supervised learning\nmethods can automatically identify staff pages with decent accuracy; F measure\nof 77 percent, there is a possibility for more in depth analysis of inter linking\nbetween universities staffs so this type of links can be in cooperated to\nbibliometric analysis.\nThere are several other machine learning algorithms which may give more\naccurate results. Further work will aim to compare results of other classification\ntechniques as well as apply natural language processing techniques to improve the\naccuracy of the classifier.\n\n1266\n\nReferences\nBar-Ilan, J. (2004). A microscopic link analysis of academic institutions within a\ncountry ” the case of israel. Scientometrics, 59(3), 391-403. Retrieved from\nhttp://dx.doi.org/10.1023/B:SCIE.0000018540.33706.c1\nBar-Ilan, J. (2005). What do we know about links and linking? A framework for\nstudying links in academic environments. Information Processing &amp;\nManagement, 41(4), 973-986. doi:10.1016/j.ipm.2004.02.005\nBreiman, L., Friedman, J., Stone, C. J., &amp; Olshen, R. A. (1984). Classification\nand regression trees\nWadsforth International Group.\nChau, M., &amp; Chen, H. (2008). A machine learning approach to web page filtering\nusing content and structure analysis. Decision Support Systems, 44(2), 482494. doi:10.1016/j.dss.2007.06.002\nHall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., &amp; Witten, I. H.\n(2009). The WEKA data mining software: An update. SIGKDD Explor.Newsl.,\n11(1), 10-18. doi:10.1145/1656274.1656278\nHolmberg, K., &amp; Thelwall, M. (2009). Local government web sites in finland: A\ngeographic and webometric analysis Scientometrics, 79(1), 157 - 169.\ndoi:10.1007/s11192-009-0410-6\nKotsiantis, S. B. (2007). Supervised machine learning: A review of classification\ntechniques. Paper presented at the Proceedings of the 2007 Conference on\nEmerging Artificial Intelligence Applications in Computer Engineering: Real\nWord AI Systems with Applications in eHealth, HCI, Information Retrieval\nand Pervasive Technologies, pp. 3-24. Retrieved from\nhttp://dl.acm.org/citation.cfm?id=1566770.1566773\nKotsiantis, S. B. (2011). Decision trees: A recent overview. Artificial Intelligence\nReview, , 1-23. doi:10.1007/s10462-011-9272-4\nKotsiantis, S. B., Zaharakis, I. D., &amp; Pintelas, P. E. (2006). Machine learning: A\nreview of classification and combining techniques. Artif.Intell.Rev., 26(3),\n159-190. doi:10.1007/s10462-007-9052-3\nLiu, B. (2006). Web data mining: Exploring hyperlinks, contents, and usage data\n(data-centric systems and applications). Secaucus, NJ, USA: Springer-Verlag\nNew York, Inc.\nLuo, P., Lin, F., Xiong, Y., Zhao, Y., &amp; Shi, Z. (2009). Towards combining web\nclassification and web information extraction: A case study. Paper presented at\nthe Proceedings of the 15th ACM SIGKDD International Conference on\nKnowledge Discovery and Data Mining, Paris, France. pp. 1235-1244.\ndoi:10.1145/1557019.1557152\nMinguillo, D., &amp; Thelwall, M. (2011). The entrepreneurial role of the university:\nA link analysis of york science park. Paper presented at the Proceedings of the\nISSI 2011 Conference - 13th International Conference of the International\nSociety for Scientometrics &amp; Informetrics, Durban, South Africa. pp. 570-583.\n\n1267\n\nPark, H. W., &amp; Thelwall, M. (2008). Link analysis: Hyperlink patterns and social\nstructure on politicians’ web sites in south korea Quality &amp; Quantity, 42(5),\n687 - 697. doi:10.1007/s11135-007-9109-z\nPayne, N., &amp; Thelwall, M. (2004). A statistical analysis of UK academic web\nlinks. International Journal of Scientometrics, Informetrics and Bibliometrics,\n8(1)\nQi, X., &amp; Davison, B. D. (2009). Web page classification: Features and\nalgorithms. ACM Comput. Surv., 41(2), 1-31. doi:10.1145/1459352.1459357\nQuinlan, J. R. (1993). C4.5: Programs for machine learning. San Francisco, CA,\nUSA: Morgan Kaufmann Publishers Inc.\nRomero-Frías, E., &amp; Vaughan, L. (2010). European political trends viewed\nthrough patterns of web linking. Journal of the American Society for\nInformation Science and Technology, 61(10), 2109-2121.\ndoi:10.1002/asi.21375\nRomero-Frías, E., &amp; Vaughan, L. (2012). Exploring the relationships between\nmedia and political parties through web hyperlink analysis: The case of spain.\nJournal of the American Society for Information Science and Technology,\n63(5), 967-976. doi:10.1002/asi.22625\nSmith, A. (1999). A tale of two web spaces: Comparing sites using web impact\nfactors Journal of Documentation, 55(5), 577-592.\nSmith, A. (2003). Classifying links for substantive web impact factors.\nProceedings of the 9th International Conference on Scientometrics and\nInformetrics, Dalian, China,.\nStuart, D., Thelwall, M., &amp; Harries, G. (2007). UK academic web links and\ncollaboration - an exploratory study Journal of Information Science, 33(2),\n231 - 246. doi:10.1177/0165551506075326\nThelwall, M. (2001). A web crawler design for data mining Journal of\nInformation Science, 27(5), 319 - 325. doi:10.1177/016555150102700503\nThelwall, M. (2002a). The top 100 linked-to pages on UK university web sites:\nHigh inlink counts are not usually associated with quality scholarly content\nJournal of Information Science, 28(6), 483 - 491.\ndoi:10.1177/016555150202800604\nThelwall, M. (2002b). Evidence for the existence of geographic trends in\nuniversity web site interlinking. Journal of Documentation, 58(5), 563-574.\nThelwall, M. (2002c). An initial exploration of the link relationship between UK\nuniversity web sites. ASLIB Proceedings, 52(2), 118-126.\nThelwall, M. (2009). Introduction to webometrics: Quantitative web research for\nthe social sciences. Synthesis Lectures on Information Concepts, Retrieval,\nand Services, 1(1), 1-116. doi:10.2200/s00176ed1v01y200903icr004\nThelwall, M. (2001). Extracting macroscopic information from web links. Journal\nof the American Society for Information Science and Technology, 52(13),\n1157-1168. doi:10.1002/asi.1182\n\n1268\n\nThelwall, M. (2003). What is this link doing here? beginning a fine-grained\nprocess of identifying reasons for academic hyperlink creation. Information\nResearch, 8(3)\nThelwall, M. (2006). Interpreting social science link analysis research: A\ntheoretical framework. J.Am.Soc.Inf.Sci.Technol., 57(1), 60-68.\ndoi:10.1002/asi.v57:1\nThelwall, M., &amp; Wilkinson, D. (2003). Graph structure in three national academic\nwebs: Power laws with anomalies. Journal of the American Society for\nInformation Science and Technology, 54(8), 706-712. doi:10.1002/asi.10267\nThelwall, M., &amp; Wilkinson, D. (2004). Finding similar academic web sites with\nlinks, bibliometric couplings and colinks. Information Processing &amp;\nManagement, 40(3), 515-526. doi:10.1016/s0306-4573(03)00042-6\nVaseleiadou, E., &amp; van den Besselaar, P. (2006). Linking shallow, linking deep.\nhow scientific intermediaries use the web for their network of collaborators.\nInternationl Journal of Scientometrics, Informetrics and Bibliometrics, 10(1)\nVaughan, L., Kipp, M., &amp; Gao, Y. (2007). Are co-linked business web sites really\nrelated? A link classification study Online Information Review, 31(4; 31), 440450.\nVaughan, L. (2005). Mining web hyperlink data for business information: The\ncase of telecommunications equipment companies IN PROCEEDINGS OF\nTHE FIRST IEEE INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE\nTECHNOLOGY AND INTERNET-BASED SYSTEMS, , 190; 190-195; -195.\nVaughan, L., &amp; Thelwall, M. (2005). A modeling approach to uncover hyperlink\npatterns: The case of canadian universities. Information Processing &amp;\nManagement, 41(2), 347-359. doi:10.1016/j.ipm.2003.10.001\nVaughan, L., &amp; Wu, G. (2004). Links to commercial websites as a source of\nbusiness information Scientometrics, 60(3), 487 - 496.\ndoi:10.1023/B:SCIE.0000034389.14825.bc\nWilkinson, D., Harries, G., Thelwall, M., &amp; Price, L. (2003). Motivations for\nacademic web site interlinking: Evidence for the web as a novel source of\ninformation on informal scholarly communication. Journal of Information\nScience, 29(1), 49-56. doi:10.1177/016555150302900105\n\n1269\n\nMOVING FROM PERIPHERY TO CORE IN\nSCIENTIFIC NETWORKS: EVIDENCE FROM\nEUROPEAN INTER-REGIONAL\nCOLLABORATIONS, 1999-2007 (RIP)\nLorenzo Cassi, Emilie-Pauline Gallié, Agenor Lahatte, Valérie Merindol\nlorenzo.cassi@univ-paris1.fr\nCES-University of Paris 1 and OST-Paris\nemilie-pauline.gallie@obs-ost.fr\nOST-Paris\nagenor.lahatte@obs-ost.fr\nOST-Paris\nvalerie.merindoli@obs-ost.fr\nESG Management School (Paris) and OST-Paris\n\nAbstract\n\nThis paper provides an original framework for investigating scientific collaboration\nnetworks at European regional level. Is European scientific area an integrated system? Are\nthe European regions organized around a core? Which are the determinants explaining the\ntransition of region from periphery towards a core position? To answer these questions,\nthe evolution of eight different scientific discipline networks from 1999 to 2007 is taken\ninto account. For each of these networks, we perform a core-periphery and, given the\ntransition matrices, we identify those regions which are able to move over time from a\nperipheral position to a more central one. A final exercise investigates the determinants of\nthis transition. We conclude that fostering specialization in some discipline is the main\nexplanation of why a regions is able to reach a more central position; moreover, once\nspecialized in a domain, this could allow the region to benefit of a virtuous circle:\nincreasing the overall number of publication and making a greater effort in science-based\nactivities allow the region to become a core member also in other scientific domains.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6).\n\nIntroduction\n‘Regional disparities’ have been a main concern for European Union and\nconsequently cohesion one of the key aim of its policy. This has been even more\ncentral since the recent enlargement to Eastern countries. These disparities have to\ndo not only with economic income but also with innovation activities. The\nobjectives of 2020 EU agenda in developing a European Research Area, on one\n1270\n\nhand, ask for an increase of R&amp;D expenditure in order to reach the threshold of\nthree per-cent of GNP at the national level and, on the other hand, aim at fostering\ninternational collaboration in order to develop a more integrated research system.\nThis paper provides an original framework for the interpretation of the scientific\ncollaboration between European regions. Its aim is to verify the existence of a\ncore-periphery structure and, if it is the case, to identify the central and peripheral\nregions in eight different scientific disciplines and, finally, to investigate the main\ndeterminants explaining the capacity of a region to move from the periphery of\nthe structure to its core.\nTo achieve this aim, we perform two empirical exercises focused on a subset of\n178 European regions at NUTS 2 level in 21 countries. In the first exercise, we\nbuilt up a network of scientific collaborations for each discipline in three different\nperiods (i.e. 1999-2001, 2002-2004 and 2005-2007) and, for each of these\nnetworks, a core and a periphery are identified. In the second exercise, we\nexamine the transition matrixes analyzing the determinants explaining why a\nregion is able to reach a central position within the network.\nThe paper is organized as follows: the second section presents briefly the\ntheoretical framework, the third one presents the data and discusses the main\nassumptions relate to network construction. The following ones present the two\nempirical exercises and the main results.\nTheoretical background: collaboration network in Europe\nThe literature dealing with research collaboration among European regions is the\nmain reference of our paper. This literature can be easily classified, among other\ncriteria, according to data used as a proxy of collaboration and according to unity\nof analysis. Usually three kinds of data are analysed: research project (e.g.\nFramework Program), co-patent and scientific co-publication (for a review see\nFrenken et al., 2009). Concerning the unity of analysis, the literature focuses, on\none hand, on individual actors (i.e. regions) analysing the position of each of them\nin collaboration networks or their collaboration pattern and, on the other hand, on\nthe overall structure of network. The former is the local scale perspective, the\nlatter the global one. Less studied is the intermediate-scale of EU research\ncollaboration network. In this paper, using publication data, we investigate the\nmeso-scale network feature known as core-periphery structure, which consists of\na partition of network’s nodes in a highly connected core and a sparsely\nconnected periphery (Rombach et al, 2012).\nRegional networks: data and method\nIn order to investigate the European scientific system we focus on the\ncollaboration existing among regions (NUTS2) in eight broad scientific\ndisciplines that are defined by OST (2010) as an aggregation of Thomson\nScientific Categories. Data of co-publications among 248 NUTS2 regions (UE27)\nused and citations associated come from Web of Science (WoS) database, which\ncontains the articles published in most journals covering all scientific fields. We\n1271\n\nretrieve all scientific articles published between 1999 and 2007 and related to\nresearch collaborations among UE regions. A publication is considered to be\nresearch collaboration between regions if it contains at least two different\ninstitutional addresses corresponding to NUTS2 regions. The publications coauthored by intra-regional institutions are excluded. Our study is limited to the\nbilateral and multilateral co-authorship inter-regional and is in fact performed on\nthree sets smoothed data corresponding to 3-years periods 1999-2001, 2002-2004\nand 2005-2007. The analysis sample is otherwise restricted to regions having at\nleast 500 publications all fields on average by period. That reduces our sample to\n178 regions, 21 countries. Using this information, it is possible to build a network\nwhere the nodes are the regions and the links between them are given by the\namount of their co-authored scientific publications. The analysis of this kind of\nnetwork could give information on how the European system is structured.\nFor each region, we have calculated the following variables based on publication:\nthe amount of publications in each discipline, the total amount of publication (all\ndisciplines), a normalised specialisation index.117 Moreover, for each region we\nhave collected some economic data from the Eurostat website. In particular we\ndownloaded for the period 1999-2007 for each region: the population (thousands\nof people); the human resources in Science and Technology, broadly defined\n(thousands of people); the GNP per capita relative to EU27 average, normalised\nto 100. Combing this data we define a new variable, labelled Science-Based, as\nthe number of scientific publications (all disciplines) relative to number of people\nworking in Science and Technology sectors. According to us, this measure of\nproductivity can be also interpreted as a measure of how much the human capital\nof a region is dedicated to science related activities rather than more applied ones.\nCore identification\nThe meso-scale perspective in Social Network Analysis literature has been mainly\ndeveloped around the analysis of community structure (roughly equivalent to\ncluster) rather than the analysis of core-periphery. Core-periphery perspective is\nsurprisingly few developed: the main reference is still the contribution of Borgatti\nand Everett (1999) and this is true both in terms of definition and calculation (to\nour knowledge, the only algorithm available is the one provided initially by\nUCInet).\nAccording to them a “core-periphery model consists of two classes of nodes,\nnamely a cohesive sub-graph (the core) in which actors are connected to each\nother in some maximal sense and a class of actors that are more loosely connected\nto the cohesive sub-graph but lack any maximal cohesion with the core” (Borgatti\nand Everett, 1999, p.377).\n117\n\nThe specialisation index is calculated as the ratio between the share of the region in one\ndiscipline and the share of the publication of the region in all fields. Moreover the index is\nnormalised in the following way: (index2 - 1)/ (index2 + 1). The range of normalized index is\nbetween -1 and 1: the index gets a value equal to 0 if a region has a share of publication in a\ndiscipline equal to its share in all fields.\n1272\n\nA similar concept, that it is possible to find in the literature, is the rich-club\nphenomenon (Zhou and Mondargon, 2003) which consists in partition of\nnetwork’s nodes in a group of actors highly connected and the rest of network\nloosely connected. The main difference between the two definitions concerns who\nis connected with whom. In the core-periphery structure the peripheral ones are\nnot connected (or very few) with each other and partially connected to the core,\nwhile in the rich-club structure there are not a priori assumptions on that but just a\nstructural difference between actors in terms of degree (i.e. number of partners).\nThus, in order to detect a rich-club structure, it is sufficient to analyse the degree\ndistribution, and it is not required to look at the adjacency matrix as in coreperiphery case. If a two-tier structure is identified, i.e. two different power laws\ncharacterising the degree distribution, then it is possible to infer the occurrence of\na rich-club phenomenon. This latter represents a necessary condition in order to\nhave core-periphery structure as defined by Borgatti and Everett.\nFollowing the methodology developed in Zelnio (2012), we define a core and a\nperiphery according to the rich-club phenomenon and, in order to do that, we\njointly analyse the distribution of degree (partner) among regions and the regional\ndistribution of number of article. If a region belongs to the rich-club according to\nboth distributions, then the region is a member of the core (for more details on the\nmethodology, see Zelnio 2012).\nThe following table displays the main results on core-periphery structure.\nTable 1. Core: number of regions and share, by dsciplines\nDisciplines\nFundamental Biology\nMedicine\nApplied Biology/Ecology\nChemistry\nPhysics\nScience of the Universe\nEngineering Sciences\nMathematics\n\n1999-2001\n40 (22.5%)\n44 (24.7%)\n44 (24.7%)\n51 (28.6%)\n52 (29.2%)\n46 (25.8%)\n29 (16.3%)\n44 (24.7%)\n\n2002-2004\n40 (22.5%)\n55 (30.9%)\n51 (28.6%)\n44 (24.7%)\n49 (27.5%)\n47 (26.4%)\n45 (25.3%)\n51 (28.6%)\n\n2005-2007\n47 (26.4%)\n50 (28.1%)\n56 (31.4%)\n55 (30.9%)\n53 (29.8%)\n50 (28.1%)\n50 (28.1%)\n65 (36.5%)\n\nThe size of the core varies across disciplines and overt time. Moreover not all\ndisciplines show the same increasing pattern. Indeed only Applied Biology,\nEngineering Sciences and Mathematics show this kind of pattern over the three\nperiods, other as Fundament Biology and Science of the Universe are stable\nbetween the two first periods and increase later on. The other three disciplines\nreport changes between the three periods of different sign. However for any\ndiscipline, the core of the last period is greater than at the beginning of the period\nunder analysis.\n\n1273\n\nMoving to the core\nAs Table1 shows, the size of core changes over times. This could happen because\nsome regions move from the periphery to the core or the other way round. The\nfollowing table presents the transition matrix which sums up the possible cases\nand reports the number of regions corresponding to each of them, without\ndistinguished by discipline.118\nThe most interesting case concerns the regions which are able to move from the\nperiphery to the core in a stable way, i.e. regions that have moved from the\nperiphery to core between first and second period and that have been able to stay\nin the core over the last period. This latter is a subset of 97 cases listed in previous\ntable, because among them we have 46 observations that corresponding to a\nregion moving toward the core only between the second and third period. We\nprefer to exclude them by the following investigation because it could correspond\nto an “instable case” (i.e. a region moving back to periphery after one period in\nthe core). However in future research we intend to extend the analysis also to\nthese cases.\nTable 2. Transition matrix over three periods for each region/discipline observation\nAfter\nCore\nPeriphery\nCore\n312 (21.9%)\n21 (1.5%)\nBefore\nPeriphery\n97 (6.8%)\n966 (67.8%)\nNote: there are 28 (2%) not corresponding to any listed cases, because instable.\n\nThus, in the following, we investigate the determinants of stable transition, i.e. 51\nobservations. In order to do that, we compare those regions with regions that have\nbeen in the periphery over the three periods (966 observations).119 Table 3 reports\nthe result of logistic regression analysing the probability the transition occurs\naccording to two different specifications, respectively without and with\ninteraction terms.\nTable 3. Estimation of the probability to move form periphery to core (Logistic\nregression)\nVariable\nPopulation (thousands)\nGNP per capita (index)\n\n118\n\nModel 1\n0.000644***\n[0.000134]\n0.0141**\n[0.00520]\n\nModel 2\n0.000677***\n[0.000141]\n0.0165**\n[0.00601]\n\nThat implies we have 1424 observation, i.e. 178 regions multiplied by 8 disciplines.\nSome observations are excluded from the following exercise because some missing information\nin Eurostat data.\n119\n\n1274\n\nScience-Based\nDiscipline specialisation (Spec)\nCore in 1 disc (Icore1)\nCore in 2-5 disc (Icore2)\nCore in 6-7 disc (Icore3)\n\n0.1843***\n[0.0544]\n3.5394***\n[0.5389]\n0.8086*\n[0.3579]\n2.1308***\n[0.3875]\n2.2476***\n[0.5351]\n\n-1.0949*\n[0.4848]\n0.0417\n[0.4016]\n0.1845\n[0.3671]\n-0.7838\n[0.4690]\n-1.6386**\n[0.6247]\n-1.0653*\n[0.4596]\n-0.1495\n[0.3776]\n\n0.1876***\n[0.0561]\n2.1896**\n[0.6700]\n0.1359\n[0.4570]\n1.7953***\n[0.3711]\n3.6710***\n[0.9715]\n2.6338+\n[1.4631]\n2.1204*\n[0.9990]\n8.4114**\n[3.0286]\n-1.6412**\n[0.6184]\n0.0280\n[0.4077]\n0.2734\n[0.3835]\n-0.7853\n[0.4996]\n-1.7229*\n[0.6987]\n-0.9795\n[0.4869]\n-0.2409\n[0.4066]\n\nRef.\n\nRef.\n\n0.0262\n[0.5166]\n0.8341\n[0.5139]\n0.7348\n[0.6265]\n-0.0917\n[0.5723]\n-3.0147\n[233.5]\n\n0.0626\n[0.6161]\n0.8238\n[0.6131]\n0.7564\n[0.7017]\n-0.1089\n[0.6852]\n-2.9876\n[302.0]\n\nRef.\n\nRef.\n\nSpec*Icore11\nSpec*Icore12\nSpec*Icore13\nFundamental Biology\nMedicine\nApplied Biology/Ecology\nChemistry\nPhysics\nScience of the Universe\nEngineering Sciences\nMathematics\nFounding members\nAdhesion between 1953 and 1973\nAdhesion: 1974-1981\nAdhesion: 1982-1986\nAdhesion: 1987-1995\nAdhesion after 96\n\n-6.5688***\n-6.4546***\n[0.9554]\n[1.0615]\nNumber of observations: 918; Standard Errors in brackets; *** p&lt;0.001, ** p&lt;0.01, *\np&lt;0.05, + p&lt;0.1\nIntercept\n\n1275\n\nThe size of the region (captured by the population) matters, as well as the relative\nGNP per capita does. The variable Science-Based (i.e. the number of scientific\npublications divided by to number of people working in Science and Technology\nsectors) affects positively the probability of moving to the core: the investment in\nhuman capital in science activities does pay off. The degree of specialisation in\nthe discipline under analysis matters, as we can expect. A region needs to make an\neffort in a specific discipline in order to become a member of the rich-club\nregions. Moreover, being already a member of a core in other discipline plays a\npositive role. This effect is increasing in the number of core-disciplines as the\nthree dummies Icore show.120 According to the first specification (but results are\nmore or less confirmed in the second one), only some disciplines do matter.\nCompare to the reference discipline (Mathematics), only Fundament Biology,\nScience of the Universe and Physics seem to affect the probability making the\ntransition be less likely. This is not surprising given what we have observed in\nTable1: between the first two periods the size of the core of these three disciplines\nis stable or decrease when, in the same period, the core for Mathematics increases.\nThe dummies relative to the date of adhesion to EU are not significant:\nmembership age does not matter, suggesting that, if there is an effect of EU\nmembership, this does not change as time goes by.\nThe second specification (Model 2) takes into account the interaction terms\nbetween specialisation index and the three dummies for core membership. In this\ncase, the coefficient of specialisation in a discipline should be interpreted as the\neffect to being specialised when a region is not belonging to any core in other\ndiscipline. That means that one should compare the coefficient of the interaction\nterms with this one, in order to investigate the effect of being already a core\nmember in other disciplines given a level of specialisation. What we observe is\nthat this effect is increasing in the number of disciplines a region is already in the\ncore (with exception of Icore2). Higher is the number of disciplines where a\nregion is already core, lesser is the relative effort in a specific discipline that a\nregion should make in order to became a member of the core also in that\ndiscipline. This implies that regions can benefit of a virtuous circle, if they are\nable to become a core region in at least one discipline. This result is partially\nsmoothed if we look at the Icore coefficients (that should interpret as the effect\nwhen region is no specialized, i.e. specialisation index equals to zero). The effect\nis confirmed to be increasing, but for Icore1 that is not significant. This means\nthat there is some mass critic effect: if a region does not make any effort in\nspecialisation, it is not enough to be core in one other discipline in order to\nincrease the probability to move toward a more central position. In order to\nbenefit for spill-overs from other discipline, a region should be a member of the in\nat least two of them.\n120\n\nICore1 means that the region is already in the core of one other discipline, ICore2 means that is\nin the core in at least 2-5 other disciplines, and finally Icore3 means that the region is already in the\ncore of other 6 or 7 disciplines.\n1276\n\nReferences\nBorgatti, S.P. and Everett, M.G. (1999). Models of core/periphery structures.\nSocial Networks, 21, 375-395.\nFrenken, K., Hardeman, S. &amp; Hoekman, J. (2009). Spatial scientometrics: Toward\na cumulative research program. Journal of Informetrics, 3, 222-232.\nOST (2010), Indicateurs de sciences et de technologies, Economica, Paris.\nRombach, M.P., M.A. Porter, J.H. Fowler and P.J. Mucha, (2012). CorePeriphery Structure in Networks, http://arxiv.org/abs/1202.2684\nZelnio, R. (2012). Identifying the global core-periphery structure of science.\nScientometrics, 91, 601-615.\nZhou, S. and Mondragon, R.J. (2003). The Rich-Club Phenomenon in the Internet\nTopology, IEEE Communications Letters.\n\n1277\n\nNANO-ENHANCED DRUG DELIVERY (NEDD)\nRESEARCH PATTERN FOR TWO LEADING\nCOUNTRIES: US AND CHINA\nYing Guo,1 Xiao Zhou,2 Alan L. Porter3 and Doug Robinson4\n1\n\nguoying_bit@163.com\nSchool of Management and Economics, Beijing Institute of Technology, Beijing (China)\n2\n\nbelinda1214@126.com\nSchool of Management and Economics, Beijing Institute of Technology, Beijing (China)\n3\n\nalan.porter@isye.gatech.edu\nSchool of Public Policy, Georgia Institute of Technology, Atlanta (USA), and Search\nTechnology, Inc., Norcross, GA (USA)\n4\n\ndouglas.robinson@teqnode.com\nteQnode Limited, Paris (France)\n\nAbstract\n\nNano-Enabled Drug Delivery (“NEDD”) systems are rapidly emerging as a key nano\napplication area. NEDD offers promise in addressing pharmaceutical industry challenges\nconcerning solubility, cost-reduction, disease &amp; organ targeting, and patent lifecycle\nextension. This study compares NEDD research patterns for the US vs. China by profiling\ndata compiled by a multi-component search strategy in Web of Science. We present a\nrange of analyses to address research activity trends, concentration differences, and\ncollaboration networks corresponding to three characteristics of “New and Emerging\nScience &amp; Technologies,” for which NEDD represents a consequential case. It can help\nresearchers and research managers understand the current status and future prospects of an\nemerging scientific or medical field. Such profiling of database search results can offer\nglobal insights to help discern main research trajectories, key players, and promising new\nshoots.\n\nConference Topic\n\nScientometrics Indicators (Topic 1) and Visualisation and Science Mapping: Tools,\nMethods and Applications (Topic 8).\n\nIntroduction\nNano-enhanced Drug Delivery (NEDD) systems\nNano-enhanced Drug Delivery (NEDD) systems seek to improve the release,\ndistribution, absorption, and elimination of drugs. Traditional methods for\nadministering drugs have relied on absorption in the digestive tract or skin or on\ninjection (with manifold issues). We investigate new delivery methods that use\n1278\n\nnanoparticles (e.g., lipid-based, polymer-based, proteins, dendrimers, etc.) to\ntarget specific organs or cell-types (Allen, 2004). These may increase drug\neffectiveness, both via “technical” and “social” effects – e.g., by controlling\nrelease one can reduce dose frequency and improve patient compliance. NEDD\noffers potential for treating chronic diseases and genetic disorders, and it has also\nbeen considered as a suitable substitute for conventional protein therapy.\nChina is on the rise in the drug delivery technology sector and is becoming an\nincreasingly nimble competitor in the space. Chinese drug delivery companies are\nseeking to expand their opportunities into Europe and the US. One company,\nLepu Medical Technology, uses its nanomaterial technology to make drug-eluting\ncoronary stents, among other interventional cardiology products, and the company\nbooked $120 million in 2011 revenue. Meanwhile, just as for other frontier\ntechnologies, the US has been the dominant leader in the area of biotech. Thus,\nwith this context, it is important to underscore to what extent these two countries\nare progressing in this frontier technology -- NEDD.\nForecast Innovation Pathways (FIP) and Bibliometric Analysis\nThis NEDD study is part of a project seeking to develop methods to Forecast\nInnovation Pathways (FIP) for “New and Emerging Science &amp; Technologies”\n(NESTs) (Porter et al., to appear). NESTs have great potential for innovation, but\nat the same time they are associated with great uncertainties. The nurturing of\nappropriate research avenues is crucial so that NESTs are developed along the\nmost promising pathways, both in technological terms as well as towards\naddressing societal and economic problems or needs.\nThe project aims to develop a methodological framework and associated tools for\nanalyzing NESTs to help policy makers and R&amp;D managers to make betterinformed decisions regarding innovation pathways. It combines empirical and\nexpert knowledge of an emerging technology. The empirical work mainly seeks to\nextract intelligence from database search results about R&amp;D activities,\ntechnological maturation, key players, and promising prospects for applications.\nThis reflects a combination of bibliometrics and text mining (i.e., “Tech Mining”\n– Porter and Cunningham, 2005; Cunningham et al., 2006). The case studies in\nthe project (one is NEDD) will be followed by expert interviews, first\nunstructured, then with q-method, plus a workshop with stakeholders to explore\ninnovation pathways.\nThe development of new profiling and mapping techniques to characterize key\nactors and their interactions is crucial. Our hypothesis supposes that by\nunderstanding the various bodies of knowledge involved in a NEST, the key\norganizations, how they are related, and the visions they have constructed,\nanalysts can grasp the diverse potential innovation pathways. Our approach aims\nto help analysts to identify previously hidden possibilities for connections among\n1279\n\nnew ideas, artifacts and actors relating to NEDD (Rammert, 2002) – hence trying\nto preserve diversity in order to avoid technological lock-in towards undesired\napplications (Stirling, 2007).\nThe content for this paper can be divided into four parts. First comes a general\nintroduction. Contextual Framework and Research Approach follow. The third\nsection presents bibliometric analysis results. The last section sums up and points\nout promising “next” research opportunities to pursue.\nContextual Framework &amp; Research Approach\nData &amp; Search strategy\nOur study of NEDD originates from dissertation research in the Netherlands\n(Robinson, 2010) and from a separate study in support of the North Carolina\nBiotechnology Center’s (“NCBC”) efforts to stimulate innovation by matching\nresearch producers with companies having complementary drug delivery interests\n(Porter, 2010). Commencing in 2008, we devised a modular, Boolean, term-based\nsearch algorithm for NEDD, guided by knowledgeable colleagues in the US and\nEurope. We advanced a conceptual framework to approach NEDD, informed by\n\nvarious reviews and “foresight” pieces. This led us toward categorization\nto frame our current NEDD search (Zhou, 2013a).\n\nFramework &amp; Research questions\nNESTs have some obvious characteristics. First, plenty of scientists believe in the\nfuture of any given NEST and apply themselves to advance it; so such\ntechnologies often show accelerating R&amp;D activity and rapid development.\nSecond, NEST R&amp;D is often multidisciplinary or interdisciplinary, as is the case\nfor nano science and engineering (Porter and Youtie, 2009). Third, because of the\nfirst two characteristics, NEST often calls for cooperative development, which\ncould be among different countries, institutions, or researchers. When we explore\nthe R&amp;D activity for a given NEST, we address these three characteristics as\nindicators. In this paper, we apply them to NEDD.\nAs noted, our analyses of NEDD research activity presented in this paper focus on\nChina and the US. In general, we would like to know, to what extent these two\ncountries have developed competency in this high technology area? Is this\ntechnology providing a “window of opportunity” for these two countries to\ncompete in the near future? Considering the three characteristics of NESTs\nmentioned, the study investigates in detail to what extent China and the US are\nasserting themselves to possibly establish dominance over NEDD applications to\ncome. Specific questions that drive this paper are as follows:\n Research activity trend analysis (Rapid development): Does rapidly\nincreasing publication activity mean “real” development?\n Research concentration difference analysis (Cross-disciplinary): How\n1280\n\nscattered and different are Chinese and American NEDD research\nconcentrations? This could help researchers locate and balance their\nresearch emphases.\n Research cooperation network analysis (Collaboration patterns): What\ndoes the network among countries look like, especially in terms of the\npositions of China and the US? To follow up, can we analyze and\nvisualize the networks within countries to reveal different R&amp;D\nmechanisms at work (and possibly suggest policy initiatives)?\nThe study also intends to demonstrate the importance of integrating bibliometrics\nand text analyses to generate informative innovation indicators, helping to\nconstruct a more informed picture of a country’s performance.\nResults for China and US NEDD Research Performance\nResearch activity trend analysis\nBecause WOS indexing of some 12,000 journals’ content is done with some time\nlag, the data for 2011 and 2012 are incomplete. For trend analyses, we want to\nestimate the full activity for those years. We used total annual publication counts\nin recent years in WOS, expressly for its Science Citation Index (SCI) to\nnormalize the NEDD data. We multiplied these ratios of expected/observed\nvalues to adjust the observed NEDD counts for these two years for each country\nto compare the research activity trend for China and the US.\n\nFigure 1. Activity Trends for the Top 10 NEDD Countries\n\n1281\n\nIt is surprising to observe China emerging as the most prolific in research\npublications in 2012 (although the data for 2012 are incomplete)! The picture has\ndramatically changed since 2001. In 2001, the US accounted for 45.5% of the\nNEDD papers, whereas Germany accounted for 10.4% of papers, and China for\n2.5%. In 2011, China accounted for 23.5% of papers and US researchers authored\nor co-authored 26.2%, whereas Germany was considerably less visible,\naccounting for 5.8% of total papers (Figure 1).\nFor China, a steady rise in publication output has been observable particularly\nsince about 2006. Taking 2001 as the base year, China’s relative growth rate has\nbeen much higher than that of the US. Overall, for the aggregate publications\nfrom 2001 to 2012, China accounts for 10,110 NEDD papers (16.45% of the\nglobal total); the US, for 20,807 papers (33.85% of the total).\nCitation measures provide a view of the reception of papers by the international\ncommunity (Glanzel, 2008). However, any indicator based on citations received is\nstrongly affected by the citation window. The larger volume of US papers leads to\nmore citations than for China, and this is amplified by the fact that the US began\npublishing earlier within the 2000–2012 time period under analysis. The\ndifferences becomes less significant when this is normalized by number of papers\nand the number of years in which the paper is cited. We created Figure 2 to\ncompare the citations/paper/year and the rate of uncited papers with the trend of\ntotal papers for both the US and China. Columns in the figures represent\ncitation/paper/year for both countries and are oriented on the left Y axis; the line\nchart represents # uncited paper/total for each year for both countries and is\noriented on the right Y axis.\nInterestingly, we do not observe much difference in the corpus of papers that\nremain uncited, except for the year 2005. Considering the citations/paper/year,\none important indication is how fast the papers of both countries are received by\nthe international communityExcept for 2011 and 2012, citation for the US\nobviously progresses steadily, while for China, it looks erratic but possibly rising.\nMost tellingly, while China’s citation rate lags behind that of the US, the gap\nseems to be moderate in recent years (note 2010 and 2011 especially). These\nbibliometric indicators imply that China’s research is addressing important\nproblems, advancing knowledge, and making researchers take note of that (Figure\n2).\nAn examination of the top 100 most cited papers sheds further led on reception,\nrevealing papers that attract the most attention. The top 100 highly cited papers\nwield major international impact. These papers may offer significant theoretical\nand/or experimental novelty to draw the attention of the research community. For\nthis analysis, we fully credit a country for any paper on which it appears in one or\nmore of the co-authors’ addresses.\n1282\n\nFigure 2. Citation trends for the US and China\n\nThe most cited papers present a rather different picture than average citation rates\n(Figure 2). We see only 2 Chinese papers among those top 100 highly cited\npapers, while 62 belong to the US. Also, interestingly, some countries appear with\nsignificant frequency in the top 100 highly cited papers – e.g. the Netherlands\nwith 10 such papers (ranking 4th) – but remain absent in the top 10 highly active\ncountries. This possibly means that the Netherlands NEDD community pays more\nattention to quality than quantity of research.\nResearch concentration difference analysis\nWe scan for hot topics within this area for both countries – i.e., topics within the\ndomain that evidence increasing research attention in recent years. We identify\nhot topics by comparing the prevalence of key terms in a very recent period (here\nwe use 2011–on) vs. an earlier period (here, 2000–2010). We examine 424\ninteresting, frequently occurring key terms in both periods. Table 1 lists the 20\ntopics that show the greatest increase in attention these past two years. Overall,\nthe ratio of 2011–on to pre-2011 is 0.43. So, these terms are really “hot.” For both\ncountries, nano-related terms are hot, especially for the US. Also, we highlight 3\nterms that appear in both lists, for China and the US. This illustrates the potential\nto identify respective research concentrations (to be probed further in consultation\nwith several domain experts).\nIn our analyses, Principal Components Analysis (PCA) was applied to the most\ninteresting (about 424) clumped term set (Zhang et al., under submission) to\ncluster these as potentially important factors for sub-systems and research\nconcentration analyses for China and the US. We created a sub-dataset with US\nand China records, then made the factor map in Figure 3. We added the “country”\nfield to each node to look for any big research concentration difference between\nthe US and China. As for overall level, China accounts for 10,110 NEDD papers\n1283\n\n(16.45% of the global total); the US, for 20,807 papers (33.85% of the total). The\nUS publication number is almost double that of China. We have not shown the\npull-down box for topical concentrations with similar ratios, but show those with\ninteresting differences.\nTable 1. Increasingly Popular NEDD Research Topics for US and China\nUS\n\nChina\n\nA:\n#2011\non\n\nB:\n#pre\n2011\n\nRatio:\nA/B\n\n166\n\n102\n\n1.63\n\n24\n\n16\n\n1.50\n\n24\n\n18\n\n1.33\n\nsiRNA delivery\n\n20\n28\n\n16\n23\n\n1.25\n1.22\n\n49\n\n41\n\n1.20\n\nNanoemulsion\n\n27\n\n29\n\n0.93\n\nalginate\nMesoporous silica\nnanoparticles\nPLGA\nnanoparticles\nNanocarriers\nradical\npolymerization\nGold\nnanoparticles\nHydroxyapatite\niron-oxide\nnanoparticles\nOptical-properties\npolymeric\nnanoparticles\nmucoadhesion\nSilica\nnanoparticles\nMetal\nnanoparticles\n\n19\n\n21\n\n40\n\nsiRNA delivery\nLipid\nnanoparticles\nRAFT\npolymerization\nphotosensitizers\ncurcumin\nsilver\nnanoparticles\n\n1284\n\nA:\n#2011\non\n\nB:\n#pre\n2011\n\nRatio:\nA/B\n\n68\n\n11\n\n6.18\n\n32\n\n8\n\n4.00\n\n108\n\n29\n\n3.72\n\n7\n22\n\n2\n9\n\n3.50\n2.44\n\n24\n\n10\n\n2.40\n\n7\n\n3\n\n2.33\n\n0.90\n\ncyclophosphamide\ncurcumin\nresonance energytransfer\nNon-Hodgkinslymphoma\nsignaling pathway\n\n35\n\n16\n\n2.19\n\n45\n\n0.89\n\ntargeted delivery\n\n64\n\n30\n\n2.13\n\n46\n\n54\n\n0.85\n\nGlioblastoma\n\n21\n\n10\n\n2.10\n\n93\n\n110\n\n0.85\n\nIn-vivo evaluation\n\n27\n\n13\n\n2.08\n\n20\n\n24\n\n0.83\n\nCell lung-cancer\n\n37\n\n18\n\n2.06\n\n225\n\n278\n\n0.81\n\nMagnetic-resonance\n\n22\n\n11\n\n2.00\n\n26\n\n33\n\n0.79\n\n26\n\n13\n\n2.00\n\n135\n\n175\n\n0.77\n\n51\n\n26\n\n1.96\n\n45\n\n59\n\n0.76\n\nphotosensitizers\nmagnetic resonance\nimaging\nLiving cells\n\n68\n\n35\n\n1.94\n\n83\n\n110\n\n0.75\n\nin-vitro evaluation\n\n25\n\n13\n\n1.92\n\n6\n\n8\n\n0.75\n\nglioma\n\n42\n\n22\n\n1.91\n\n53\n\n71\n\n0.75\n\nPROTEIN-KINASE\n\n15\n\n8\n\n1.88\n\n29\n\n39\n\n0.74\n\nMRI\n\n46\n\n25\n\n1.84\n\nMesoporous silica\nnanoparticles\ncell-penetrating\npeptides\n\nFactor Map\nTop 424 interesting terms\nFactors:\n21\n% Coverage: 55% (16421)\nTop links shown\n&gt; 0.75\n0 (0)\n0.50 - 0.75 0 (0)\n0.25 - 0.50 0 (0)\n&lt; 0.25\n17 (134)\n\nblock-copolymers\nN-isopropylacrylamide\nCountries (1)\n\n628 USA\n563 China\nalpha-Cyclodextrin\n26 South Ko\n24 Canada\n18 Germany\n\nPAMAM dendrimers\n\nCountries (1)\n\nPolyethylenimine\n\n186\n158\n10\n8\n7\n\nUSA\nChina\nUK\nSingapor\nGermany\n\nCountries (1)\n\n418\n135\n25\nnanosuspensions 13\n11\n\nUSA\nChina\nCanada\nGermany\nJapan\nCardiomyopathy\n\nCountries (1)\n\nDOUBLE-STRANDED-RNA\n\nAngiogenesis\n\n190\n159\n9\n7\n6\n\nChina\nUSA\nIndia\nIceland\nGermany\n\ncyclophosphamide\nsolid lipid nanoparticles\nMULTIDRUG-RESISTANCE\n\nCountries (1)\n\n510\n75\n24\n18\n13\n\nNF-KAPPA-B\nCountries (1)\n\n616\n186\n24\n22\n15\n\nUSA\nChina\nJapan\nCanada\nGermany\n\nUSA\nChina\nUK\nGermany\nCanada\n\nretroviral vectors\nCountries (1)\n\nCountries (1)\n\n1247 USA\n140 China\n52 UK\n35 Germany\n31 Japan\nelectrospinning\n\n365 USA\n123 China\n16 Germany\nJapan\niron-oxide 12\nnanoparticles\nCountries (1)\n9 Canada\n575 USA\nmalignant glioma\nviral vectors\n121 China\n24 Germany\n24 Canada\n23 Japan\nDNA vaccine\n\nFigure 3. Factor map for US and China records\n\nLooking at cardiomyopathy, retroviral vectors, viral vectors, NF-KAPPA-B,\nDNA vaccine and malignant glioma, China lags behind in terms of publications,\nespecially for retroviral vectors and viral vectors. Such a big difference is\nsurprising: viral or retroviral vectors are widely used in gene therapy, since they\ncan directly deliver genetic material into cells. Nanosuspensions, Nisopropylacrylamide and solid lipid nanoparticles are related to easy delivery for\ncertain drugs, using nano-size properties. China could compete with the US on\nnumber of publications. (We will probe further with the aid of experts in NEDD.)\n\n1285\n\nResearch collaboration network analysis\nNEDD research is widely dispersed across different journals due to its\ninterdisciplinary nature. More details of the activities of the two countries are\nhighlighted in Table 2. This indicates some important aspects of these two\ncountries’ publication in journals with “Top 10” records in this field. Table 2 also\nreflects that international collaboration plays an important role in getting papers\npublished in these journals, especially for J. Virol and Mol. Ther, for China.\nChina shows a striking level of international collaboration for those journals. This\nanalysis could also be conducted on the journals with a high impact factor, which\ncould possibly show the publication quantity for each country.\nTable 2. Journal Comparison for the US and China\nJournal\nBiomacromolecules\nBiomaterials\nGene Ther\nInt. J. Nanomed\nInt. J. Pharm\nJ. Control. Release\nJ. Mater. Chem\nJ. Virol\nLangmuir\nMol. Ther\n\n# of\nrecords\n689\n1416\n670\n628\n1447\n1465\n616\n661\n972\n839\n\nChina\ntotal\n\n125\n377\n30\n236\n284\n177\n249\n13\n142\n19\n\nworld\nshare\n0.18\n0.27\n0.04\n0.38\n0.20\n0.12\n0.40\n0.02\n0.15\n0.02\n\ninternational\ncooperation\nshare\n0.26\n0.25\n0.33\n0.16\n0.18\n0.28\n0.20\n0.42\n0.22\n0.63\n\nUS\n\ntotal\n576\n451\n442\n442\n357\n322\n243\n231\n122\n89\n\nworld\nshare\n0.84\n0.32\n0.66\n0.70\n0.25\n0.22\n0.39\n0.35\n0.13\n0.11\n\ninternational\ncooperation\nshare\n0.25\n0.35\n0.30\n0.34\n0.30\n0.36\n0.38\n0.19\n0.20\n0.21\n\nFurther analysis for the top 100 highly-cited papers explores how closely\ncountries cooperate (Figure 4). We also contrast research interests among\ncountries based on these top papers (not shown here). Each node represents a\npaper in this map, and the links among them show how much they have in\ncommon. In Figure 4, the US is shown to collaborate with almost all the countries\nrepresented. We also learn from the research interests map analysis that, for the\nmost part, the US shares interests with all the leading countries. All this uncovers\nthe dominant status of US research in the global academy for NEDD. Further\nanalysis could be made to dig into these papers to group and name them by using\nthis map, with the aim of finding out the research areas that strongly attract\nattention.\n\n1286\n\nAuto-Correlation Map\n\nNew Zealand\n\nCountries (1)\n\nAll links shown\n&gt; 0.75\n0.50 - 0.75\n0.25 - 0.50\n&lt; 0.25\n\nBrazil\n\n6 (0)\n3 (0)\n6 (0)\n32 (0)\n\nAustralia\nFrance\n\nTurkey\n\nGermany\n\nPhilippines\nSouth\nKorea\n\nDenmark\n\nTaiwan\nArgentina\n\nNetherlands\n\nSpain\nCanada\n\nChina\n\nUSA\n\nBelgium\nJapan\n\nSwitzerland\nUK\n\nItaly\n\nFigure 4. Cooperation Among Countries for the Top 100 Highly Cited Papers\n\nFigure 5 highlights the links among the 20 top authors for both countries based on\ntheir co-authored publications. University and research institutes are dominating\nthe network for both countries. Also cluster formation shows strong bearing on\ngeographical location, e.g., the small group for Wuhan Univ., Sichuan Univ. of\nChina. This formation may be due to sharing of capital-intensive instruments that\nare prerequisite for certain NEDD research. But the figure shows far fewer\ncollaborative connections for the top 20 US authors, which is surprising. Some\nkey differences should be noted. Chinese University-research institute linkages\nare very strong as almost all the institutes (majority being university) exhibit\nlinkages with CAS, the Chinese Academy of Sciences (CAS represents over 100\nresearch institutes, and over 400 S&amp;T enterprises have been created by CAS).\n1287\n\nAuto-Correlation Map\n\nAuto-Correlation Map\n\nAuthor Affiliations (Organiza...\n\nAuthors (top 20)\n\nAll links shown\n&gt; 0.75\n0.50 - 0.75\n0.25 - 0.50\n&lt; 0.25\n\n73\n23\n7\n7\n5\n\n1 (0)\n6 (0)\n0 (0)\n22 (0)\n\nZhang, Qiang\nJing, Xiabin\nPeking U\nShandong\nAuthor Affiliations (Organiza...\nShenyang\nAuthor Affiliations (Organiza...\nChina Ph\nChen, Xuesi 58 Chinese\nAuthor\nAffiliations (Organiza...\nSichuan\n63 Chinese\n11 Jilin Un\n12 NE Norma\n5 NE Norma\n9 Chinese\n6 Jilin Un\n2 Drexel U\n8 Nankai U\n4 Shanghai\n2 Changchu\n8 Sichuan\n3 Kyushu U\n6 Peking U\n5 Tianjin\n\nAuthors (top 20)\n\nLanger, Robert\n\nAll links shown\n&gt; 0.75\n0 (0)\n0.50 - 0.75 1 (0)\n0.25 - 0.50 1 (0)\n&lt; 0.25\n2 (0)\n\n103 MIT\n52 Harvard\n15 Brigham\n8 Harvard\n6 Alnylam\n\nFarokhzad, Omid C\nAuthor Affiliations (Organiza...\n40\n39\n12\n4\n2\n\nBaker, James R, Jr\n\nWang, Wei\n\nAuthor Affiliations (Organiza...\n\nMIT\nHarvard\nBrigham\nUniv Cal\nGwangju\n\n51\n8\n7\n5\n5\n\nMIT\nHarvard\nAlnylam\nJohns Ho\nAlnylam\n\nAuthor Affiliations (Organiza...\n\n87 Wuhan Un\n3 Sichuan\n2 Tongji U\n2 Univ S C\n2 Hamhung\n\n50 Univ Mic\n4 Donghua\n2 NanoBio\n2 Univ Geo\n2 Xavier U\n\nLi, Wei\n\nAuthor Affiliations (Organiza...\n12\n8\n7\n6\n4\n\nZhang, Xian-Zheng\n\nChinese\nMil Med\nNatl Eng\nShanghai\nNatl Ctr\n\nAuthor Affiliations (Organiza...\n40\n18\n8\n5\n4\n\nUniv Uta\nHanyang\nKorea Ad\nSungkyun\nInje Uni\n\nKim, Sung Wan\nKaplan, David L\n\nAuthor Affiliations (Organiza...\n\nZhuo, Ren-Xi\n\nAuthor Affiliations (Organiza...\n116 Wuhan Un\n3 Sichuan\n2 Hamhung\n2 Huazhong\n2 Univ S C\nCheng, Si-Xue\n\nWickline, Samuel A\n\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\n\nAuthor Affiliations (Organiza...\n65\n3\n2\n2\n1\n\nAnderson, Daniel G\n\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\n\nWuhan Un\nSichuan\nUniv S C\nHamhung\nTongji U\n\n46\n2\n2\n2\n2\n\nShandong\nUniv Kan\nChina Ph\nSichuan\nShandong\n\nAuthor Affiliations (Organiza...\n47 Chinese\n8 Shenyang\n4 E China\n4 Yangzhou\n3 Fudan Un\n\nZhang, Na\n\n36\n8\n4\n3\n3\n\nWooley, Karen L\n39\n18\n9\n4\n4\n\n40\n4\n2\n2\n2\n\nTufts Un\nSoochow\nGeorgia\nIndian I\nUniv Min\n\nChen, Xiaoyuan\n\nAuthor Affiliations (Organiza...\n23\n20\n13\n6\n5\n\nStanford\nNIBIB\nNatl Ins\nN Sichua\nSungkyun\n\nTan, Weihong\n\nAuthor Affiliations (Organiza...\n\nLi, Yaping\nAuthor Affiliations (Organiza...\n57 Chinese\n14 E China\n12 Fudan Un\n5 Chongqin\n4 Shanghai\n\nWashingt\nPhilips\nSt Thoma\nUniv Mis\nPhilips\n\nAuthor Affiliations (Organiza...\n\nWashingt\nTexas A&amp;\nUniv Cal\nUniv Del\nAssiut U\n\n40\n22\n4\n3\n2\n\nUniv Flo\nHunan Un\nXiamen U\nCent S U\nEli Lill\n\nAuthor Affiliations (Organiza...\n29\n24\n21\n2\n2\n\nShi, Jianlin\n\nUniv Neb\nMoscow M\nUniv Neb\nMcGill U\nTech Uni\n\nKabanov, Alexander V\n\nLee, Robert J\nWang, Jun\nWu, Wei\n\nAuthor Affiliations (Organiza...\n46\n5\n4\n4\n4\n\nAuthor Affiliations (Organiza...\n39\n3\n3\n3\n2\n\nAuthor Affiliations (Organiza...\n\nUniv Sci\nSun Yat\nSoutheas\nXiamen U\nSuzhou G\n\n19 Nanjing\n18 Fudan Un\n7 Zhejiang\n3 Sichuan\n2 Wuhan Un\n\nOhio Sta\nShandong\nWuhan Un\nHuazhong\nSichuan\n\nHuang, Leaf\n\nAuthor Affiliations (Organiza...\n42 Univ N C\n5 Univ Pit\n2 Duke Uni\n2 Univ Del\n1 Xi An Ji\n\nFerrari, Mauro\n\nAuthor Affiliations (Organiza...\n27\n24\n19\n15\n13\n\nAuthor Affiliations (Organiza...\n44\n2\n2\n1\n1\n\nSichuan\nTsinghua\nW China\nGuangdon\nSichuan\nZhao, Xia\n\nQian, ZhiYong\nAuthor Affiliations (Organiza...\n\nAuthor Affiliations (Organiza...\n68 Sichuan\nWei, YuQuan\n5 Zhejiang\n52 Sichuan\n2 Sichuan2 W China\n2 Tsinghua\n2 Chengdu\n2 Third Mi\n2 Tsinghua\n1 Zhejiang\n\nRice Uni\nUniv Tex\nMethodis\nUniv Tex\nUniv Tex\n\nZink, Jeffrey I\n\nAuthor Affiliations (Organiza...\n45\n18\n3\n3\n2\n\nCuriel, DT\n\nUniv Cal\nNorthwes\nIntel La\nKorea Ad\nKing Abd\n\nAuthor Affiliations (Organiza...\n52\n4\n4\n4\n4\n\nJiang, Xinguo\n\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\n53 Fudan Un\n16\n5\n5\n4\n3\n\nSoutheas\nShenyang\nChinese\nFudan Un\nShanghai\n\n46 Zhejiang\n4 Shenyang\n3 China Ph\n2 Jiaxing\n2 Ningbo 2\n\nZhang, Yu\n\n6 Chinese\n6 Fourth M\n6 Mil Med\n5 Jiaxing\n5 Fudan Un\n\nDu, Yong-Zhong Zhang, Wei\n\n14 Shanghai\n12 Minist E\n9 PLA\n7 Shenyang\n\nWilson, JM\n\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\nAuthor Affiliations (Organiza...\n53 Northeas\n\n7 Auburn U\nAuthor Affiliations (Organiza...\n4 Massachu\n42\n7\n4\n4\n3\n\nUniv Pen\nWistar I\nUniv Tex\nWistar I\nChildren\n\nUniv Ala\nVectorLo\nUniv Erl\nUniv Dus\nUniv Hel\n\n3 Nano Ana\n2 Harvard\n\n49\n3\n2\n2\n2\n\nUniv Mas\nMayo Cli\nGeorgia\nUniv Mar\nIndiana\n\nTorchilin, Vladimir P\n\n44\n12\n7\n4\n3\n\nSUNY Buf\nNanyang\nRoswell\nUniv Del\nChangchu\n\nPrasad, Paras N\n\nRotello, Vincent M\n\nFigure 5. Top 20 authors for China and US\n\nDiscussion and conclusions\nNano-enhanced drug delivery (NEDD) systems seek to improve the release,\ndistribution, absorption, and elimination of drugs. NEDD offers potential for\ntreating chronic diseases and genetic disorders and has also been considered as a\nsuitable substitute for conventional protein therapy. This paper conducts a\ncomparative analysis of China vs. the US – two important players in the NEDD\nrace – both to present results on this promising emerging technology and to\nconsider ways to better perform such analyses.\nAfter multiple iterations, we have developed a multi-module search strategy to\nconstruct an NEDD dataset from WOS, using the Georgia Tech (GT) “nano”\n(nanoscience, nanoengineering, nanotechnology, etc.) dataset with additional\nsearches in the full WOS, led by our colleague, Xiao Zhou. Then we conduct\nseveral analyses to address research trends, collaboration pattern differences, and\nsocial network analyses concerning three characteristics of NESTs for which we\naspire to forecast innovation pathways.\nIn the “research activity trend analysis,” we compare both the activity and citation\ntrend for the US and China. China’s citation rate lags behind that of the US, but\nthe gap has narrowed in recent years. Further, the trend has dramatically changed\nsince 2001, as China has advanced notably in NEDD research. We then use “term\n1288\n\nclumping” steps to clean and consolidate topical content in text sources.\nAnalyzing the resulting key term set, we list the “hot” research topics for both\ncountries. Using PCA to group key terms, we identify concentration difference for\nthe two nations. The differences concerning viral or retroviral vectors are striking\nand merit reflection on R&amp;D strategy. But China could compete with the US in\nterms of publication intensity for nanosuspensions, N-isopropylacrylamide and\nsolid lipid nanoparticles, with implications for certain applications. Interestingly,\nthe “research cooperation network analysis” shows that, although the US’s\ninternational network spreads globally, internal collaboration seems somewhat\nlimited.\nThe study strives to integrate bibliometrics and text analyses to generate\ninformative innovation indicators, helping to construct a more informed picture of\na country’s performance. It further can help establish analytical steps to nominate\nand assess future innovation pathways (“FIP”) for NEDD applications. That FIP\nprocess entails combining empirical findings with review and brainstorming by\npersons representing multiple stakeholder perspectives (Robinson et al., 2013).\nFor this paper, we focus on data from WOS. Since we know NEDD is heavily\ninvolved in medical science, we will also retrieve research publications from\nMEDLINE. We will then combine and compare with WOS, expecting about a\n50% increase in R&amp;D information to use in extended analyses. Next, as patenting\nis vital in pharmaceutical technology management, we will transfer and adapt the\nsearch logic to retrieve patent records in Derwent Innovation Index (DII).\nAcknowledgements: This research draws on support from the National Science\nFoundation (NSF) Science of Science Policy Program – “Revealing Innovation\nPathways” (Award No. 1064146) to Georgia Tech and has also been facilitated by\nNSF support through the Center for Nanotechnology in Society (Arizona State\nUniversity; Award No. 0531194). The findings and observations contained in this\npaper are those of the authors and do not necessarily reflect the views of the\nNational Science Foundation.\nReferences\nArora, S.K., Porter, A.L., Youtie, J., and Shapira, P. (2013), Capturing new\ndevelopments in an emerging technology: An updated search strategy for\nidentifying nanotechnology research outputs, Scientometrics, DOI:\n10.1007/s11192-012-0903-6.\nAllen, T. M., Cullis, P.R. (2004) Drug Delivery Systems: Entering the\nMainstream. Science 303, 1818-1822.\nCunningham, S.W., Porter, A.L.; Newman, N.C. (2006): Tech Mining Special\nIssue, Technology Forecasting and Social Change, Vol. 73 (8).\nGlanzel, W. Seven myths in bibliometrics. About facts and fiction in quantitative\nscience studies. In H. Kretschmer, &amp; F. Havemann (Eds.), Proceedings of WIS\n1289\n\n2008, Fourth International Conference on Webometrics, Informetrics and\nScientometrics &amp; Ninth COLLNET Meeting, Berlin: Humboldt University,\n2008.\nPorter, A.L., and Cunningham, S.W.(2005). Tech Mining: Exploiting New\nTechnologies for Competitive Advantage. New York: Wiley.\nPorter, A.L., and Youtie, J., “How Interdisciplinary is Nanotechnology? ” Journal\nof Nanoparticle Research, vol. 11(5), 1023-1041, 2009.\nPorter, A.L., Cunningham, S.W., and Sanz, A. (to appear). Extending the FIP\n(Forecasting Innovation Pathways) approach through an automotive case\nanalysis, Portland International Conference on Management and Engineering\nTechnology (PICMET), San Jose, California, 2013.\nRammert, W. (2002) The cultural shaping of technologies and the politics of\ntechnodiversity. Sorensen, K.H. and Williams, R. (Eds.) Shaping technology,\nguiding policy: concepts, spaces and tools. Cheltenham, UK: Edward Elgar.\nRobinson, D.K.R., Huang, L., Guo, Y., and Porter, A.L. (2013), Forecasting\nInnovation Pathways for New and Emerging Science &amp; Technologies,\nTechnological Forecasting &amp; Social Change, 80 (2), 267-285.\nStirling, A. (2007). A general framework for analysing diversity in science,\ntechnology and society. Journal of The Royal Society Interface, 4(15), 707719.\nZhang, Y., Zhou, X., Porter, A.L., and Gomila, J. (under submission), How to\nCombine Term Clumping and Technology Roadmapping for Newly Emerging\nScience &amp; Technology Competitive Intelligence: The Semantic TRIZ Tool and\nCase Study, 14th International Society of Scientometrics and Informetrics\n(ISSI) Conference Proceedings, Vienna, 2013.\nZhou, X., Porter, A.L., Robinson, D.K.R., and Guo, Y. (to appear, a), Analyzing\nResearch Publication Patterns to Gauge Future Innovation Pathways for NanoEnabled Drug Delivery, Portland International Conference on Management\nand Engineering Technology (PICMET), San Jose, California, 2013.\nZhou, X., Porter, A.L., Robinson, D.K.R., and Guo, Y. (to appear, b), Patent and\nPublication Comparison for One Emerging Industries -- Nano-Enabled Drug\nDelivery, 14th International Society of Scientometrics and Informetrics (ISSI)\nConference, Vienna, 2013.\n\n1290\n\nNANOTECHNOLOGY AS GENERAL PURPOSE\nTECHNOLOGY\nFlorian Kreuchauff1 and Nina Teichert2\n1\n\nflorian.kreuchauff@kit.edu 2 nina.teichert@kit.edu\nKIT Karlsruhe Institute of Technology, Dept of Economics, Chair in Economic Policy,\nKaiserstr. 12, D-76128 Karlsruhe, URL: wipo.econ.kit.edu\n\nAbstract\n\nScientific literature postulates that nanotechnology is to be considered as general purpose\ntechnology (GPT), characterized by pervasiveness, high technological dynamism and the\ninducement of innovations within a variety of applications. We set out to not only further\nsystematize existing approaches investigating nanotechnology’s GPT traits based on\npatent applications, but to extend the analysis to academic publication data, in order to\ncover both knowledge creation and application development. By utilizing well established\nand consolidated indicators of GPT features, such as generality, diffusion, and forward\ncitation rates, as well as contextualized technological coherence as a new weighted\ngenerality measure, we compare nanotechnology’s research output to the ones of ICT as\naccepted GPT and of the combustion engine as a non-GPT, representing an upper and\nlower benchmark, respectively. Moreover, we add the EU27 as new institutional setting.\nOur results indicate that while nanotechnology is not as clearly perceptible a GPT as ICT\nis, the potential to develop as such and hence to become an ‘engine of growth’ is clearly\ngiven.\n\nConference Topic\n\nTechnology and Innovation Including Patent Analysis (Topic 5)\n\nIntroduction\nScholars emphasize that nanotechnology is not only one important but the general\npurpose technology (henceforth GPT) of the coming decade. Nanotechnology’s\nversatile and interdisciplinary nature combines all classic basis technologies,\npromising revolutionary alterations of mankind’s life, work, and perception of\nreality at all levels. GPT’s sustainable economic surplus is created by the\npervasive mutual inducements and complementarities of joint inventions in GPT\nand application sectors, yielding wide, continuously self-enhancing and\naccelerating impacts for the entire economy during whole eras (Bresnahan 2010).\nThere is a vast literature examining whether past technologies are to be called a\nGPT, e.g. Lipsey et al. (1998) review potential candidates, Moser &amp; Nicholas\n(2004) examine whether electricity was a GPT, &amp; Jovanovic &amp; Rousseau (2005)\ncompare the impact of IT and electricity, to name just a few. However, it is\nconsiderably more difficult to investigate whether currently emerging\ntechnologies have the potential to become a GPT. The challenge arises because\nex-ante even an exact definition of emerging technologies is difficult, without\n1291\n\neven talking about ways to measure their impact. Nevertheless, conquering this\nbumpy road is important, because GPT’s inherent innovation processes - though\npromising huge effects for economic growth - are subject to market failures and\nhence innovations are assumed to arrive too late and to a too little extent in terms\nof social welfare (Bresnahan &amp; Trajtenberg 1995). Hence, if nanotechnology can\nbe identified as young, but emerging GPT, sustainable policy implications can be\nderived in order to resolve, at least partly, the occurring market failures that\nhamper positive effects on productivity, enduring growth and prosperity.\nWe thus aim to contribute to the question, if nanotechnology is to be called an\nemerging GPT by validating that it features the three characteristics argued for as\ntypical for general purpose technologies: Pervasiveness of use (1) is ensured by\nthe generality of purpose, stemming from the possibility to arrange nanoscaled\nstructures encompassing new material properties for literally countless\napplications in nanomedicine, atomically precise manufacturing, fuel cell\nelectrocatalysis, organic photovoltaic cells and so on. The scope for improvement\n(2) in nanotechnology is provided by the possible reduction of size and costs, and\nincreasing complexity. For instance, nanoapplications in semiconductor\nmanufacturing technology have resulted in a remarkable reduction of processing\nsize in recent years (Graham &amp; Iacopetta 2009). Hints for nanotechnology to spur\ninnovation (3) in application sectors are given by the existence of a nano-oriented\nvalue chain with basic, intermediate and downstream innovations (Youtie et al.\n2008). Wang &amp; Guan (2012) distinguish four stages within this value chain:\nnanomaterials, nanointermediates, nano-enabled products and nanotools. The\nrelationship between electronic microscopy and nanotechnology sketches such\npossible value chains with inherent feedback loops exemplarily: R&amp;D advances in\ninstruments [e.g. scanning tunneling microscopes (STMs) / atomic force\nmicroscopes (ATMs)] actually opened the opportunity to conduct systematical\nresearch on the nanoscale, while advances in nanotechnology applied in such\nmicroscopes improved their capacities remarkably (Palmberg &amp; Nikulainen 2006,\nYoutie et al. 2008). Thus, quality adjusted prices for ATMs and STMs declined,\ndue to the application of nanotechnology. Moreover, in combination with the\nsignificant drop in scale enhancing the advances in semiconductors, this can also\nbe instanced as evidence for innovational complementarities [combination of (2)\nand (3)]. We hence propose that nanotechnology is a general purpose technology\nand are subsequently testing the following hypotheses:\nHypothesis 1 Nanotechnology is increasingly becoming a widely-used, pervasive\ntechnology.\nHypothesis 2 Nanotechnology exhibits scope for ongoing technological\nimprovement.\nHypothesis 3 Nanotechnology increasingly spurs innovation in applications\nsectors.\n\n1292\n\nMethodology and Data\nPrevious Contributions and Systematic Extensions\nIn recent academic literature, nanotechnology has been progressively analyzed in\norder to identify economic trends attributable to its emerging nature. Various\nauthors have contributed to the assembly of a holistic picture on nanotechnology’s\ndevelopment, including Heinze (2004), who focuses on its worldwide expansion,\nHullmann (2007), who examines data on markets, funding, companies, and\npatents and publications (concluding that nanotechnology easily has the potential\nto reach the level of the ICT’s economic impact), Wong et al. (2007), who\ninvestigate the evolution of application areas, Meyer (2007), who emphasizes the\nintegrating and field-connecting characteristics of instrumentation within\nnanotechnology, and Palmberg et al. (2009), who give a first broad overview on\nthe development of nanotechnology. These lines of research already foreshadow\nnanotechnology being an emerging GPT. However, they neither formalize data\nanalyses nor provide acknowledged measures for GPT traits, and thus lack a\nsystematic investigation on this issue.\nFirst systematized approaches to directly uncover GPTs (using patent data) were\nmade by Hall &amp; Trajtenberg (2006). They suggest measures for GPT attributes,\nsuch as a generality index, number of citations, and patent class growth, for\npatents themselves and for the patents that cite these patents. Alongside, basic\napproaches to investigate whether particularly nanotechnology might be a GPT\nwere made by Palmberg &amp; Nikulainen (2006). However, they do not yet apply\nthose indicators proposed by Hall &amp; Trajtenberg (2006) to test their hypotheses.\nThese were adopted first by Youtie et al. (2008), who tested indicators for\ngenerality and highlighted evidence for nano being as pervasive as GPTs like\nICT. Moreover, they developed new indicators for innovation spawning. Graham\n&amp; Iacopetta (2009) also test for these two features, and Schultz &amp; Joutz (2010)\nfurther deepened the topic, discovering a few very general emerging nano related\nfields with the potential for wide economic impact, and nano-fields that\nexperience a more focused development path. Most recently, Shea et al. (2011)\nanalyzed a sample of USPTO patenting activity of the first 25 nano-years, looking\nfor early evidence that nanotechnology is a general purpose technology, assessing\nall three characteristics. Hence, first approaches to investigate GPT features\nwithin nanotechnology systematically have been developed. However, all of them\nwere limited to patent applications and all investigating USPTO data.\nWe set out to not only further consolidate these existing approaches, particularly\nwith respect to the indicators measuring the three GPT features, but we extend the\nanalysis to publication data, in order to conquer both knowledge creation and\napplication development. Moreover, although nano-activity has been subject to\ninvestigation by the OECD in recent years (Palmberg et al. 2009), to our\nknowledge there have not been any examinations of broadly accepted measures of\nGPT-characteristics within the EU27 yet. And finally, there has not been an\nanswer to the need for distance measures between technology classes (Hall &amp;\n1293\n\nTrajtenberg 2006): Though pervasiveness constitutes the most highlighted GPT\ntrait, the commonly stressed indicator, namely the so called generality index,\nsuffers from the lack of distinction between closely related and very dissimilar\ntechnological fields. We thus not only utilize well-established and consolidated\nindicators of GPT features such as generality, diffusion, and forward citation\nrates, but add contextualized technological coherence as a new weighted\ngenerality measure, which has been demanded by Hall &amp; Trajtenberg (2006), and\nwith which we aim to complete the set of instruments on hand. Within all our\nanalyses, we compare nanotechnology’s research output to the ones of ICT as\naccepted GPT and of the combustion engine (henceforth CE) as a non-GPT,\nrepresenting an upper and lower benchmark respectively.\nDevelopment tracking of GPTs with Patents and Publications\nPatents, despite all difficulties that arise in their use and interpretation [see Porter\net al. (2008) for an overview as well as Hullmann &amp; Meyer (2003) and Huang et\nal. (2010) for a more detailed discussion on bibliometric issues concerned with\nnanotechnology], are widely accepted as proxy for innovative activity (Griliches\n1990). Especially citation structures facilitate tracing knowledge flows [see\nFischer et al. (2009), Bresnahan (2010), Jaffe et al. (1993), OECD (2009),\nThompson (2006)]. Hence for the following analysis, data of nano-patents with\npriority application year between 1980 and 2008 were extracted from the ‘EPO\nWorldwide Patent Statistical Database’ (PATSTAT), version September 2010,\nand divided in samples including worldwide data and solely today’s EU27. To\nidentify relevant nano-patents by their titles and abstracts, a validated\n(evolutionary) lexical search strategy was used, based upon an approach of\nmerging keywords proposed by Mogoutov &amp; Kahane (2007), Glänzel et al.\n(2003) and Porter et al. (2008). CE and ICT patents were identified using search\nterms previously used in the literature: For CE, the IPC (International Patent\nClassification) class ‘F02’ was sufficient (Graham &amp; Iacopetta 2009), whereas for\nICT the search term was based on class definitions the IPC itself proposes. All\npatent queries are available upon request.\nIn addition, the considered nano-related publications are indexed in the\nThomson-ISI WoS database. Again we refer to the period between 1980 and\n2008. As well as with patents, a Boolean search term was used in order to identify\nnano-related publications by searching for certain keywords (and excluding\nothers) in the topic of every paper. The search term is likewise based on the\naforementioned combination of different search queries, but, due to technical\nrestrictions, way shorter than the patent search term. A respective lexical CE\nquery was developed by ourselves. For our GPT-reference ICT, we extracted all\npublications that were allocated in the Thomson ISI Subject Areas (SA)\n‘Computer Science’ and ‘Telecommunications’, since an arguable description via\nkeywords seems to be impossible for this field (Schmoch 2011, personal\ncommunication). As with patents, all queries are available upon request.\n\n1294\n\nResults and interpretation\nPervasiveness (H1)\nFor a technology to be(come) pervasive, it has to be widely applicable already at\nan early stage of its development thereby using different diffusion channels.\nFinding evidence for nanotechnology being a future GPT thus includes finding\nlinkages to a broad variety of different industries and technologies. Examining\ndiffusion rates as one possible indicator of pervasiveness, one might consider the\nshare of nano-patents / publications to total patents / publications in the respective\nportfolios of the most innovative firms and institutes, as diffusion is assumed to\nbe fastest in these. Therefore, we apply this first quantitative measure exemplarily\nto the TOP25 firms in the European R&amp;D Investment Scoreboard 2010 for\npatents and to the TOP25 publishing institutions in Europe (following WoS) for\npublications. In Figure 1, we depict the shares of ICT-, CE-, and nano-patents of\nthe Top25 firms over the past three decades. As the trend indicates, the fraction of\nICT-patents in innovative companies shows only a slight increase over the past 20\nyears (where one should not overrate findings in the last few data points:\nInterpreting patent developments demands caution regarding the last years, since\npatent acceptance takes its time. Due to this lag the last year in our sample is\n2008, even though the database ranges till September 2010). It thus seems that\nthere is a quite constant output rate of new codified applications in information\nand communications technology, so the growth follows a linear pattern. This is\nnot only true for these 25 chosen companies, but for our observations of all\npatents as well.\n\nFigure 1. Patent Diffusion Rates of Top25 Firms in R&amp;D, left axis: ICT and CE,\nright axis: nano\n1295\n\nWhile the share of patents of our non-GPT proxy CE appears constant as well\n(around 7% percent for the last 20 years), the fraction of nano-patents seems to\nrise with a remarkable increase setting in about 1997. Nanotechnology inventions\nthus appear to gain in importance regarding their proportion of R&amp;D-Output. But\neven in the observed companies with higher than average R&amp;D intensity\nnanotechnology is still far away from outmatching the share of countable results\nin CE related research.\nScientific publications, though, are often associated with the more fundamental\nresearch, and nanotechnology evidences this quite clearly, as Figure 2 depicts. For\nthe Top25 publishing institutions worldwide we observe shares of nano-related\nscientific literature around 6.5%, with an unbowed trend pointing to further\ngrowth in years to come. ICT shares of publications linger around 3%, with only a\n1% increase in two decades. Hence ICT in general reveals a focus on applied\nresearch (as marked by patents), while nanotechnology is still primarily a matter\nof the scientific debate. Again, this is almost the same for the whole sample.\n\nFigure 2. Diffusion Rates based upon publications of Top25 publishing institutions.\n\nAlready within their seminal paper, Bresnahan &amp; Trajtenberg (1995) point to the\npossibility of identifying valuable inventions by patents that are cited by a wide\nrange of different industries. To measure this, Trajtenberg et al. (1997) employed\nthe Hirschman-Herfindahl index, which was further developed by Moser &amp;\nNicholas (2004) and Hall &amp; Trajtenberg (2006) as generality index\n∑\nwhere\ndenotes the percentage of citations received by patent i\nassigned to patent class j, out of\ntechnological classes. If a patent benefited\nsubsequent inventions in a wide range of technological fields, its generality index\n1296\n\nwill be close to one, whereas if most of its forward citations are concentrated in a\nsmall number of fields will be close to zero. Correcting for the citation lag bias\n(small forward time windows associated with young and emerging technologies\npose difficulties in calculating sensible generality indices, since not all the\ncitations are yet observed, thus\nis biased downwards) is possible by using\ñ\n, where\ndenotes the total number of observed citations (Hall\n2002). With respect to patents the generality index can not only be applied to IPC\nclasses, but also be computed across technological fields in concordance with the\nInternational Standard Industrial Classification (ISIC) system. Such an\naggregation generates less and broader defined classes, sharpening their\ndistinctness, and yielding more meaningful generality indices. Thus, in our\nanalysis, the underlying classes do not represent 4-digit patent IPC classes, but\n30 technological fields, in which these IPC classes are categorized in [following\nthe NACE/ISIC Concordance developed by Hinze et al. (1997) according to\nOST/INPI/ISI - Observatoire des Sciences et Techniques / Institut Nationale de la\nProprieté\nIndustrielle\n/\nFraunhofer\nInstitut\nfür\nSystemund\nInnovationsforschung]. Calculations based upon IPC classes and their aggregation\nto 44 technological areas as developed by Schmoch et al. (2003) are available\nupon request. Figure 3 shows yearly average forward generality Indices of the\nTop10 cited patents according to the K30 technology classification (World data,\nEU27 available as well). Note that for CE we have calculated values for 5-yearintervals only, as we intended to keep the utilized amount of data at a reasonable\nlevel. Intermediate values are linearly interpolated. However, there is no reason to\nexpect robustness problems by extending the data set.\n\nFigure 3. Forward Average Generalities of Top10 Cited Patents p.a. (K30).\n1297\n\nComparatively low generality indices seen in Figure 3 are explainable considering\nthe fact that a smaller number of classes is taken into account: Less\ndistinguishable classes entail smaller generality values, since all percentages of\ncitations received by a patent are divided in fewer categories before their squares\nare summed up. The higher this sum becomes, the lower is the index. Fewer\nclasses thus provide a higher accuracy of discrimination between pervasive\ntechnologies and those, of which the citation structure refers to a more limited\nnumber of fields. This is clearly to be seen in the figure: The average generality\nvalues of our lower benchmark CE are almost everywhere considerably smaller\nthan those of ICT and nanotechnology. This holds true for the European sample.\nThe generality index is not restricted to patents. Publication data and the\ncorresponding classification system of Subject Areas (SA) in Thomson ISI WoS\ncan be used similarly. However, we do not show the results of our publication\ngeneralities here, since they offer little additional information: Classification\nwithin subject areas is subject to minor objectivity, which results in hardly\ndistinguishable average generality indices.\nThe problem with generalities is best expressed by Hall &amp; Trajtenberg (2006):\n‘[...] all of the generality measures suffer from the fact that they treat\ntechnologies that are closely related but not in the same class in the same way\nthat they treat very distant technologies. This inevitably means that generality\nmay be overestimated in some cases and underestimated in others. One\nsuggestion for future research would be to construct a weighted generality\nmeasure, where the weights are inversely related to the overall probability that\none class cites another class.’\nWe use a measure of technological coherence (TC) to approach this goal, which\nin our context will be defined as the extent to which inventions, i.e. patents, in a\ntechnological area share the same underlying knowledge. TC reflects the average\nrelatedness of those classes, a patent is associated with, either because of being\nsorted in those classes or cited by them. Hence, to calculate the coherence of a\npatent portfolio, the degree of relatedness has to be determined for each pair of\ntechnology classes. Commonly, as e.g. in Breschi et al. (2003) and Leten et al.\n(2007), this is done using co-occurences of technological classes that are jointly\nassociated to a patent. We will not recalculate the required relatedness matrix\n(with elements\n), but use the one constructed by Leten et al. (2007), which uses\nthe OST / INPI / ISI concordance with 30 distinct tech fields. Following their\ncitational approach, two technology classes are considered as technologically\nrelated if patents associated to one technology class often (i.e. more often than\ncould be expected assuming random citation patterns) cite patents classified in the\nother technology class and vice versa. The patent-count weighted average\nrelatedness\n\n∑\n\n∑\n\nof technology to all other technologies relevant\n\nin the considered year then leads to an overall coherence measure of (for example\n1298\n\nnanotechnology) patents as a weighted average of all the\n∑\n\n∑\n\nmeasures:\n\n. We thus calculate the TC of (i) nano-patents applied for, and\n\n(ii) nano-patents citing patents, both within one year. TC can reasonably assumed\nto be higher, the more specialized a technological field is. New inventions in\nspecialized fields are expected to be somewhat more coherent than are inventions\nin the field of a general purpose technology. By definition, GPT related\ninventions can be found in a wide range of application fields, and thus their TC is\nexpected to be considerably smaller. We will employ this measure for the first\ntime in this connection.\n\nFigure 4. Technological Coherence of ICT-, Nano- and CE-Patents (World data).\n\nFigure 4 shows the results for our TC-measure (i) based on world data. The GPT\nproxy ICT and nanotechnology shape a narrow side-by-side course with visible\ndistance to the CE coherence values. To verify the significance of this offset we\nperform a two sample location t-test (available upon request). The results are\nrobust when taking the technology classes of citing patents (ii) instead of the cited\npatents technology classes themselves, as well as when restricting the data to\nEuropean patents (both available upon request). The measure is restricted to\npatents, since it relies on the relatedness matrix by Leten et al. (2007).\nNonetheless, a similar matrix for publications might be constructed in further\nresearch.\nWith this new measure it becomes clear, that pervasiveness is undoubtedly much\nstronger for our ICT and the GPT candidate nanotechnology. Both show a visible\ndistance to the lower benchmark technology CE, ICT with a smoother line due to\n1299\n\nthe clearer basis in the categorization system, nanotechnology with soft swings\nand a slight increase in coherence after 1990, the starting point of a significant\nrise in the number of nanotechnology patents, possibly due to a related small gain\nin concentration among technology classes.\nScope for Improvement (H2)\nGPTs are improved continuously at every level of the value creation chain.\nRegarding nanotechnology and its potential to further reduce cost, size and\nenhance or even redefine material characteristics regarding stability, flexibility,\nabrasiveness, electrical properties and so on, two simple indicators shall illustrate\nthe hitherto manifested scope for improvement.\nWith the first one we follow the suggestion of Palmberg &amp; Nikulainen (2006) by\nobserving the pure number of patents. We do not depict the results here for the\nsake of brevity, but as expectable, the number of nanotechnology patents has\nevolved noticeably over the past decades, though it is still far from reaching that\nof CE (not to mention ICT), a result strongly related to the contemporaneous lack\nof countable applications for the emerging technical feasibilities. As well as for\ndiffusion rates, publications on the other hand again underscore the fundamental\ntheoretical work that has been done for nanotechnology in the past 20 years. With\nthe pure number of publications surpassing those of ICT at around the year 2000,\nnanotechnology has become the object of scientific interest of the new century.\nNanotechnology’s scope for ongoing improvements is thus unbowed, and there is\nlittle reason to expect any attenuation within the next years.\n\nFigure 5. Forward Citation Rates ICT-, Nano- and CE-Patents (World data).\n\n1300\n\nOur second indicator is based upon Schultz &amp; Joutz (2010), who propose a later\npatent citing the original invention as an indicator for continual technological\nimprovements. Following Hypothesis 2, nano-patents are hence expected to have\nmany citations indicating a pattern of cumulative innovation (Hall and\nTrajtenberg 2006), an expectation which can easily be transferred to publications.\nIn fact, we find nanotechnology producing patent citation rates even above those\nof ICT (and all patents worldwide, see Figure 5). A small absolute number of\nnano core patents produces comparably large numbers of references. These core\ntechnology founding patents seem to stem from outside Europe, since those\nnanotechnology patents we find in the European union have considerably smaller\ncitation rates.\nPublications are not affected that much by borderlines, and thus European\npublications again show high nano-related citation rates (due to database\nrestrictions using scientific publications from WoS is considerably more difficult,\nwhich is why we limit ourselves to the European Union regarding publications).\nAgain, visualized results are available upon request.\nInnovation spawning (H3)\nIn the field of nanotechnology, innovation spawning can be found in the existence\nof nanoenhanced value creation chains, consisting of initial, intermediate, and\ndownstream innovations. nanoscale structures (carbon nanotubes, quantum dots,\nfullerenes and so on) embodied in products with nanoscale features (coatings,\noptical components, or memory chips) and finally employed in a variety of final\nproducts (such as airplanes, computers, clothing, or pharmaceuticals) can be\nidentified as such (Lux Research 2006, Youtie et al. 2008). In combination with\ntechnological dynamism, this characteristic is the main driver of innovational\ncomplementarities.\nAn increasing share of nano-inventions in overall patenting activity can be used as\nan indicator for the innovation spawning characteristic of nanotechnology. As for\nour Top25 firm sample, for the most part we find similar trends for the fraction of\nnano-, ICT-, and CE- patents worldwide, which is why we do not visualize them\nhere. On account of this and for the sake of brevity again, we will focus instead on\nanother indicator, namely the growth in nano-citing technological classes. If\nhypothesis 3 can be supported, nano-patents-citing tech classes are subject to a\nburst of innovations because they grow with the number of complementary goods\ndeveloped (Hall &amp; Trajtenberg 2006). A proxy for innovation spawning can hence\nalso be the growth of technology classes (or subject areas with respect to\npublications) that harbour (nano-) citing patents / publications, as proposed by\nHall &amp; Trajtenberg (2006). Therefore we chose ten top citing patent classes\n(available upon request) according to their number of references, and ten subject\nareas according to a score system that accounts for the Top25 cited publications\nand the occurrence of their citations in these different subject areas. In the\nresulting diagram (figure 6) we cut the time before 1988, since we observed just a\nfew classes in the beginning of nanotechnology’s evolution, of which excessive\n1301\n\naverage growth would lead to the false impression that nanotechnology’s trend\nwas decreasing.\n\nFigure 6. Growth of Top Citing Classes, ICT-, Nano- and CE-Patents (World data).\n\nWe cut above 2002 as well, since with declining overall citation rates (remember\nFigure 5) the average class growth becomes much less conclusive. Especially in\nhighly complex technological areas (including undisputably our three compared\ntechnologies ICT, nanotechnology and CE) citations and therefore continual\nadvancements take their time.\nSo while we are not willing to conceal an observed below-average class growth\nfor all of those three technologies after 2002, one has to point out that the choice\nof classes is biased due to the declining observable citations. Thus with time,\nother classes might become more meaningful as predictor for an above-average\nclass growth. Reselection of classes every year would lead to incomparability\nthough, which is why being careful in interpreting the years after around 2000 is\nmostly without alternative.\nFor the remaining observation period nanotechnology and ICT both prove to be\noutstanding in their innovation spawning character. Almost without exception\n(1997 Nano, 1993 ICT) we find citing class growth to be above average.\nAdmittedly, the lower benchmark CE does not perform too badly for this\nindicator as well, which is not surprising however: Though CE is not considered\nas GPT here, its ability to spawn innovation - even above average - within a less\npervasive set of technological classes is unquestionable. Finally, regarding\npublications as supporting indicator, we do not observe significant above average\ngrowth rates. A straightforward explanation is yet to be found, but one might\n\n1302\n\nguess that the method we chose to select the top ten subject areas (with the abovementioned score system) could be responsible for that outcome.\nTable 1 provides an overview of all our hypotheses, the analyzed measures and\nthe corresponding results. Statements within the Support column reflect\nsignificant results from our t-tests regarding the visualized offsets (available upon\nrequest for all our measures) as well as our qualitative assessment with respect to\nlevel and trend. Keep in mind that the overall evaluation of the three GPT traits\npervasiveness, scope for improvement, and innovation spawning ultimately relies\non comparisons to the chosen benchmark technologies. Without these\nacknowledged counterparts and their scale function, any presented measure would\nlack relativization.\nTable 1. Overview of Results Supporting the Hypotheses\nHypothesis\nH1\nPervasiveness\nH2\nScope for\nImprovement\nH3\nInnovation\nSpawning\n\nIndicator\nDiffusion TOP25\n\nResult of nanotechnology\n\nPAT: way below ICT &amp; CE, pos.trend\nPUB: above ICT &amp; CE\nGenerality\nNano roughly between ICT &amp; CE\nTechn. Coherence Nano and ICT way below CE\nIncrease in\nPAT: way below ICT &amp; CE, pos. trend\nInventions\nPUB: way above CE, surpassing ICT\nForward Citation PAT: way above ICT and CE/ALL (W)\nPUB: way above ICT and CE/ALL (EU)\nDiffusion\nPAT: way below ICT, trends tw. CE (W)\nPUB: way above CE, surpassing ICT (EU)\nCiting Class\nPAT: above average, similar to ICT\nGrowth\nPUB: average, below ICT, similar to CE\n\nSupport\nWeak\nStrong\nStrong\nStrong\nMedium\nStrong\nStrong\nStrong\nMedium\nStrong\nStrong\nWeak\n\nConclusion\nStating that nanotechnology is widely considered as the general purpose\ntechnology of coming decades yields huge promises regarding consequent\nimpacts on long term economic growth. GPT’s three constituting characteristics\npervasiveness, high technological dynamism and innovation spawning in various\napplication fields have therefore been object of many studies. We contributed to\nthis research by extending the underlying data to scientific publications, regarding\nEurope as examined region for the very first time, and adding up a new measure\nwith technological coherence as demanded for. With an upper and lower\nbenchmark technology, information and communication technology and the\ncombustion engine, respectively, we provided comprehensive counterparts which\nproved to be useful comparisons.\nThe results indicate that nanotechnology evolves as GPT, as predicted by both\nscholars and practitioners. While it remains unclear if it yields similar potential as\nICT has shown in the past two decades, nanotechnology’s development regarding\nits unbowed continual advancement is undisputably as promising, as far as the\ndata tell. Certainly, the incorporation of R&amp;D expenditures representing the input\n1303\n\nside would enable important insights when combining these two perspectives,\noffering explanations of macroeconomic growth already on the micro-level by\ninvestigating incentives and their interdependencies. This enrichment should\nfacilitate the political discussion regarding emerging GPTs, especially as soon as\ncountry-level data reveals catch-up potentials. Moreover, by adding impact\nmeasures of national (or for instance European) and institutional technological\nleverage capabilities, inference statistics could provide a more holistic view on\nnanotechnology and even more, on GPTs altogether.\nAcknowledgments\nThe authors wish to thank the three anonymous reviewers for their valuable\ncomments and suggestions that have led to the improvement of this article. Parts\nof this work, including all figures and tables, can be found in: Teichert, N. (2012).\nDissertation zur Erlangung des akademischen Grades eines Doktors der\nWirtschaftswissenschaften. Innovation in general purpose technologies: How\nknowledge gains when it is shared. Karlsruhe: KIT Scientific Publishing.\nReferences\nBreschi, S. &amp; Lissoni, F. (2001). Knowledge spillovers and local innovations\nsystems: A critical survey. Industrial and Corporate Change, 10, 975-1005.\nBreschi, S., Lissoni, F. &amp; Malerba, F. (2003). Knowledge-relatedness in firm\ntechnological diversification. Research Policy, 32, 69-87.\nBresnahan, T. (2010). General purpose technologies. In B. Hall &amp; N. Rosenberg\n(Eds.), Handbook of Economics of Innovation, Vol. 2 (pp. 761-791).\nAmsterdam: Elsevier.\nBresnahan, T. &amp; Trajtenberg, M. (1995). General Purpose Technologies: ‘Engines\nof growth’?. Journal of Econometrics, 65, 83-108.\nDavid, P.A. (1991). Computer and dynamo: The modern productivity paradox in\na not-too distant mirror. Technology and Productivity: The Challenge for\nEconomic Policy (pp. 315-347). Paris, OECD.\nFischer, M., Scherngell, T. &amp; Jansenberger, E. (2009). Geographic localisation of\nknowledge spillovers: Evidence from high-tech patent citations in europe.\nAnnals of Regional Science,\n43, 839-858.\nGlänzel, W., Meyer, M., du Plessis, M., Thijs, B., Magerma, T., Schlemmer, K.,\nDebackere, K. &amp; Veugelers, R. (2003). Nanotechnology Analysis of an\nemerging domain of scientific and technological endeavour. Steunpunt O&amp;O\nStatistieken.\nGraham, S. &amp; Iacopetta, M. (2009). Nanotechnology and the emergence of a\nGeneral Purpose Technology. Retrieved January 21, 2013 from:\nhttp://papers.ssrn.com/sol3/papers.cfm?abstract_id=1334376\nGriliches, Z. (1990). Patent statistics as economic indicators: A survey. Journal of\nEconomic Literature, 28, 1661-1707.\n\n1304\n\nHall, B. (2002). A note on the bias in the herfindahl based on count data. In A.\nJaffe and M. Trajtenberg (Eds.), Patents, Citations, and Innovation (pp. 454459). Cambridge, MA: MIT Press.\nHall, B. &amp; Trajtenberg, M. (2006). Uncovering GPTs with patent data. In B. Hall\nand M. Trajtenberg (Eds.), New frontiers in the economics of innovation and\nnew technology: Essays in honor of Paul A. David. Northhampton, MA:\nEdward Elgar.\nHeinze, T. (2004). Nanoscience and nanotechnology in Europe: Analysis of\npublications and patent applications including comparisons with the United\nStates. Nanotechnology Law &amp; Business, 1(4), 427-445.\nHinze, S., Reiss, T. &amp; Schmoch, U. (1997). Statistical analysis on the distance\nbetween fields of Technology. Report for European Commission TSER\nProject.\nHuang, C., Notten, A. &amp; Rasters, N. (2010). Nanoscience and technology\npublications and patents: A review of science studies and search strategies.\nJournal of Technology Transfer, 36, 145-172.\nHullmann, A. (2007). Measuring and assessing the development of\nnanotechnology. Scientometrics, 70(3), 739–758.\nHullmann, A. &amp; Meyer, M. (2003). Publications and patents in nanotechnology.\nAn overview of previous studies and the state of the art. Scientometrics, 58(3),\n507–527.\nJaffe, A., Trajtenberg, M. &amp; Henderson, R. (1993). Geographic localization of\nknowledge spillovers as evidenced by patent citations. The Quarterly Journal\nof Economics, 108(3), 577–598.\nJovanovic, B. &amp; Rousseau, P. (2005). General purpose technologies. In P. Aghion\nand S. Durlauf (Eds.), Handbook of Economic Growth, Vol. 1B (pp. 11811224). Amsterdam: Elsevier.\nLeten, B., Belderbos, R. &amp; van Looy, B. (2007). Technological diversification,\ncoherence and performance of firms. Journal of Product Innovation\nManagement, 24(6), 567-579.\nLipsey, R., Bekar, C. &amp; Carlaw, K. (1998). What requires explanation?. In E.\nHelpman (Ed.), General Purpose Technologies and economic growth (pp. 1554). Cambridge, MA: MIT Press.\nLux Research (2006). The Nanotech Report 2006, 4 edn. New York: Lux\nResearch.\nMeyer, M. (2007). What do we know about innovation in nanotechnology? Some\npropositions about an emerging field between hype and path dependency.\nScientometrics, 70, 779-810.\nMogoutov, A. &amp; Kahane, B. (2007). Data search strategy for science and\ntechnology emergence: A scalable and evolutionary query for nanotechnology\ntracking. Research Policy, 36, 893-903.\nMoser, P. &amp; Nicholas, T. (2004). Was electricity a general purpose technology?\nEvidence from historical patent citations. American Economic Review, Papers\nand Proceedings, 94(2), 388-394.\n1305\n\nOECD (2009). Patents as statistical indicators of science and technology. OECD\nPatent Statistics Manual. Paris: OECD.\nPalmberg, C., Dernis, H. &amp; Miguet, C. (2009). Nanotechnology: An overview\nbased on indicators and statistics. OECD STI Working Paper 2009/7.\nPalmberg, C. &amp; Nikulainen, T. (2006). Nanotechnology as a general purpose\ntechnology of the 21st century? - An overview with focus on Finland. DIME\nWorking Paper Series.\nPorter, A., Youtie, J., Shapira, P. &amp; Schoeneck, D. (2008). Refining search terms\nfor nanotechnology. Journal of Nanoparticle Research, 10, 712-728.\nSchmoch, U., Laville, F., Patel, P. &amp; Frietsch, R. (2003). Linking technology\nareas to industrial Sectors. Final Report to the European Commission, DG\nResearch.\nSchultz, L. &amp; Joutz, F. (2010). Methods for identifying ermerging general\npurpose technologies: A case study. Scientometrics, 85, 155-170.\nShea, C., Grinde, R. &amp; Elmslie, B. (2011). Nanotechnology as general purpose\ntechnology: Empirical evidence and impliations. Technology Analysis &amp;\nStrategic Management, 23(2), 175-192.\nThompson, P. (2006). Patent citations and the geography of knowledge spillovers:\nEvidence from inventor- and examiner-added citations. The Review of\nEconomics and Statistics, 88(2), 383-388.\nTrajtenberg, M., Jaffe, A. &amp; Henderson, R. (1997). University vs. corporate\npatents: A window on the business of innovations. Economics of Innovations\nand New Technology, 5(2), 19-50.\nWang, G., Guan, J. (2012). Value chain of nanotechnology: A comparative study\nof some major players. Journal of Nanoparticle Research, 14(2), 1-14.\nWong, P., Ho, Y. &amp; Chan, C. (2007). Internationalization and evolution of\napplication areas of an emerging technology: The case of nanotechnology.\nScientometrics, 70(3), 715-737.\nYoutie, J., Iacopetta, M. &amp; Graham, S. (2008). Assessing the nature of\nnanotechnology: Can we uncover an emerging general purpose technology?.\nJournal of Technology Transfer, 33, 315-329.\n\n1306\n\nNEVIEWER: A NEW SOFTWARE FOR\nANALYZING THE EVOLUTION OF RESEARCH\nTOPICS\nQikai Cheng1, Xiaoguang Wang1, Wei Lu1, Shuguang Han2\n1{\n\nchengqikai0806@gmail.com, whu_wxg@126.com, reedwhu@gmail.com}\nSchool of Information Management, Wuhan University, Wuhan, China, 430072\n2\n\nshh69@pitt.edu\n135 N Bellefield Avenue, Pittsburgh, PA, United States, 15213\n\nAbstract\n\nThis paper proposes a new research frame for analysing the evolution of research topics in\na discipline based on co-word network analysis. A new software was introduced, i.e. the\nNEViewer, in which we present three key features that are distinct from other science\nmapping tools: (a) a powerful analysing module within a longitudinal framework; (b) the\nuse of several network community evolutions analysing algorithms; (c) revealing the\nmacroscopic shifts and microcosmic details of evolution based on alluvial diagram and\ncolored network. Our experimental analysis using five computer science conferences\ndataset show that the NEViewer is effective and reliable; and the research process using\nco-word network analysis in disciplines is also feasible.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6) and Visualisation and Science\nMapping: Tools, Methods and Applications (Topic 8).\n\n1. Introduction\nMethodologies and techniques developed in complex networks and information\nvisualization fields provided opportunities for researchers in information sciences\nto detect and visualize the latent knowledge structure of research topics. Recently,\nthe knowledge map and knowledge networks (Börner, Chen, &amp; Boyack, 2005;\nBoyack, Klavans, &amp; Börner, 2005; Chen, 2005; Leydesdorff &amp; Rafols, 2008)\nhave gained much attention in academia, in which researchers combined\ntechniques from both two fields and aimed to uncover the latent scientific topic\nstructures. After mapping topics and topic bursts in PNAS (Mane &amp; Börner,\n2004), the authors concludes that the knowledge network structure is particularly\nimportant in discovering hidden human knowledge, detecting hot topics and\nidentifying research trends. As one of the most important knowledge networks,\nco-word network has been identified as one of the most important knowledge map\nand the alternatives of the citation networks or co-citation networks. Comparing\nto traditional method, it is even better in research trend detection because the\n\n1307\n\nformation of citation networks and co-citation networks usually required too\nmuch time (Börner et al., 2005; Chen, 2005; Mane &amp; Börner, 2004).\nCo-word network is one type of networks; therefore, methods and algorithms for\nnetwork analysis can be applied to co-word network. In many real natural/social\nnetworks, the roles of nodes in the networks are not homogenous. One common\ncharacteristic of social network is that it has latent community structure (Ding,\n2011): a group of nodes may have more close relationships with each other than\nwith the rest of nodes. The same phenomena were also detected in the co-word\nnetworks. The latent structure in the co-word networks has certain connections\nwith the existing discipline structure. Keywords in different communities can be\nmapped into different disciplines, research topics. The evolution of co-word\nnetworks actually reveals the topic evolution process (Wang, Jiang, &amp; Li, 2010).\nSoftware packages such as CiteSpace and SciMat have been developed in\ndetecting and visualizing topic evolution and knowledge mapping. However,\nCiteSpace only focused on the citation networks, which cannot provide real time\ntopic evolution analysis because there is a delay in forming the citation networks.\nSciMat cannot provide sufficient details of network evolution, and their\nvisualization was not easy to use. Therefore, we developed the NEViewer, a\nsoftware toolkit that is able to detect and visualize the network evolution and\ntopic evolution, and provide both micro-level and macro-level network analysis.\nIn the following section 2, we will introduce the software architecture and related\nalgorithms which are implemented in our software. Section 3 started with the\nintroduction of the NEViewer, and then we provided a case study in NEViewer\nusing five conferences dataset. The experimental results actually demonstrated the\neffectiveness of using our software. This paper concluded with the summarization\nof the advantages and disadvantages of the NEViewer.\n2. Methodology\nScientific publications are important media for researchers to publish their\nresearch outcomes (Cobo, López-Herrera, Herrera-Viedma, &amp; Herrera, 2010;\nWang et al., 2010). Usually, the authors are required to provide several carefully\nselected keywords to represent the main research topic of the paper. Therefore,\nkeywords are considered as important and controlled vocabularies for research\nand study (Lin, Zhang, Zhao &amp; Buzydlowski, 2012). The co-keyword networks\nare also valuable and are able to reveal the latent relationship among research\ntopics and research domains. By simply adding the temporal information, we will\nbe able to investigate the evolution of co-word networks, and further map the\nevolution to the topic level.\nThe keyword network based topic evolution analysis can be divided into three\nphases: the pre-processing step, the topic identification step and the sequential\ndata construction step. First of all, we need to pre-process the raw data and\nconvert them into a sequence of temporal co-word networks. We assign one time\nstamp for each of those networks based on the publication date. Then, the\n1308\n\ncommunity detection algorithms are adopted to uncover the latent community\nstructures within the co-word networks in each time stamp. Since we are focusing\non the high-level topic evolution, each community is assumed to be a topic and a\nrepresentative keyword will be assigned to represent this topic. The last step is to\nmap the communities (topics) from different time stamps and generate a final\nsequential evolution of those topics. The NEViewer then visualized the sequential\nevolution of those topics.\n\nCORPUS\n\nPreprocess\n\nNetwork\nrepresentatio\nn\n\nTemporal\ndata process\n\nCommunity\ndetection\n\nEvolution\nanalysis\n\nVisualization\n\nCluster\nNaming\n各时间段SFI指标\n90.00%\n80.00%\n70.00%\n60.00%\n50.00%\n40.00%\n30.00%\n20.00%\n10.00%\n0.00%\n\n78.60%\n\n平均\nSFI指标\n\n1995-1998\n\nTopic representation\n\nTopic detection\n\n78.50%\n\n69%\n56.50%\n\n1999-2002\n\n2003-2006\n\n2007-2010\n\nEvolution analysis\n\nVisualization\n\nFigure 1. The framework of NEViewer’s methods\n\n2.1 Community Detection in Co-word Networks\nThere are two main approaches in identifying the latent structures within a given\ndataset: the network topology based approach and the content-based topical\nanalysis approach (Ding, 2011). The first approach is based on existing wellinvestigated theories and methods in Graph Theory. A lot of algorithms were\nproposed in the last decade by computer scientists and physicists. Modularity\nMaximization is a widely adopted algorithm for community detection (Newman,\n2004). Its basic idea is to traverse all possible community divisions and choose\nthe division which can maximize the network modularity. Modularity is a metric\nfor measuring whether the community results far away from the random\nassignments. The high modularity implies networks have dense connections\nwithin communities but sparse connection between communities. Although the\ninitial algorithm was designed for un-weighted networks but it can also be\nextended to weighted networks, as suggested by its author (Newman, 2004). One\nproblem for the Modularity Maximization method is that each node can only\nbelong to one community, which may have conflictions with human’s intuition.\nFor example, one information retrieval (information retrieval community) expert\ncan be the same time a social network (social network community) expert.\nMotivated by this idea, Palla, Derényi, Farkas and Vicsek (2005) proposed a Kcliques algorithm based approach, in which each node was able to be assigned to\nmultiple communities. The authors further built the tool CFinder for visualization.\nBall, Karrer and Newman (2011) proposed another approach based on a well1309\n\nknown topic modelling algorithm: the probabilistic latent semantic analysis\n(PLSA). The output of their algorithm for each node’s community detection result\nwas probability distributions over all communities. By comparing with several\nexisting approaches, Lancichinetti and Fortunato (2009) concluded that both the\ninformation-theory based approach and Blondel’s approach (Blondel, Guillaume,\nLambiotte, &amp; Lefebvre, 2008) are superior in their evaluation. McCain (2008)\nadopted the second approach and find the effectiveness of content-based topical\nanalysis in citation networks. Later, Wallace, Gingras and Duhon (2009) found\nthat applying community detection algorithms in research domain analysis is\nreasonable, and even superior in uncovering more detailed information about the\nknowledge structures.\n2.2 Representative Node Finding\nGiven that the latent community structure has been detected, we still need to find\nthe representative topics for each community, i.e. the representative node finding\nproblem. The nodes in co-word networks are the paper keywords (also the\nresearch topics), identifying the representative topics for each community can be\nconverted into the searching of the most representative nodes. The keywords of\nthose representative nodes can be used to represent the community topics.\nGuimerà, Sales-Pardo and Amaral (2006) classified the roles of nodes into several\ncategories: the provincial node, the connector hub node, the peripheral node, and\netc. They further proposed to use the Z-value for determining the roles. The Zvalue measures the local structural position of each node in the whole network. It\nis defined in the following formula, in which k si represents the number of links\nbetween node i and community s; si indicates the community that node i belongs\nto;\ndenotes the average number of nodes in community s. A higher\nZ-value implies a higher closeness of node i and the other nodes in community si.\nBased on the suggestions in Guimerà, Sales-Pardo and Amaral (2006) and our\nexperiences, each detected community can be represented by one or more nodes\nwho are in the community and whose Z-values ≥ 2.5.\n\nzi \n\nksii   ksji  jsi\n2\n(ksji)\n jsi -  ksji 2 jsi\n\n2.3 Community Evolution Analysis\nThe co-word networks in different timestamps are usually unstable: the network\ndensity, the number of communities and the size of each community are all likely\nto change in different time stamps. The evolution of latent communities contains\nthe evolution of nodes, the evolution of relationships among nodes, the evolution\nof community structures, and the changes of structure positions for each\ncommunity. Since our focus is the evolution of research topics, we adopt six\ndifferent forms of evolution as suggested in Palla, Barabasi and Vicsek (2007).\n1310\n\nThe six forms are Birth, Growth, Merging, Contraction, Splitting and Death.\nEach of them requires analyzing the community structure in both time stamp t and\ntime stamp t+1. As a result, we simplify the evolution analysis as finding the\nappropriate successors and predecessors except the Death of one community in\nwhich there are no successors. Therefore, to detect the relationship between\npredecessors and successors, we should find predecessors of communities from\nbackward to forward.\nSearching the predecessors and successors are essentially the problem of\nmeasuring the similarity between two communities. We assume in this paper that\nif the similarity between two consecutive communities is larger than certain\nthreshold, those two communities have evolution connections. We defined the\npredecessor of community\nas the following formula, in which is the\nthreshold value and d measures the similarity.\n\nThe similarity measurement d can be either based on the overlap of nodes (Palla\net al., 2007) or based on the structure similarity (Berger-Wolf &amp; Saia, 2006). In\nthis paper, we extended the former one and proposed to use FS shown in the\nfollowing Formula as the similarity measure. In this formula,\nmeasures the overlap of nodes,\nmeasures the overlap of core nodes\nand\nmeasures the structure similarity. FS considers the similarity\nfrom all of the three aspects.\n\n2.4 Community Evolution Visualization\nRosvall and Berstrom (2010) learned the idea of alluvial diagram from\nGeographic domain to visualize the evolution of networks. Figure 2 provided an\nexample of alluvial diagram. In this figure, the colored rectangle areas represent\neach community; the colored curve areas between two time stamps denote the\nevolution process: if one colored rectangle area in time stamp t divides into two\nsame colored areas in time stamp t+1, it implies that one community divides into\ntwo communities; if two colored rectangle areas in time stamp t merges into the\nsame colored area in time stamp t+1, it implies that two communities merge into\none large community, or a new community is created.\nLearning from the ideas of alluvial diagram, we develop a colored network\ndiagram (see Figure 3) in visualizing the networks. This diagram is able to\nrepresent more details of the community evolution process by providing the\nsuccessors and predecessors for each node.\nThere are two types of coloring algorithms in our software: the backward\ncoloring algorithm and the forward coloring algorithm. The backward coloring\nhelps uncover the future change of the nodes in each community and the forward\n1311\n\ncoloring helps reveal the source of current community. For example, in the time\nstamp Time 1, Figure 3 has one community A, but in the time stamp Time 2, we\nhave two communities B and C who are the successors of community A. The\nbackward algorithm will assign different colors for the nodes in community A\nbased on their community divisions in time stamp Time 2. Assumed that in the\nfuture in the time stamp Time 3, community B and community C merges into one\nlarge community D. The forward coloring algorithm will assign different colors\nfor nodes in community D based on their community divisions in time stamp\nTime 2.\n\nFigure 2. Example of the alluvial diagram\n\nFigure 3. Backboard Coloring and Forward Coloring\n\nWe formalize the rules of backward coloring and forward coloring as follows: i)\nBackward Coloring algorithm: given the community Mt in time stamp t, for any\nnode (keyword) v in this community, if the same keyword v also occurred in\ncommunity cMt+1,i, we let VColor(v) = AColor(cMt+1,i), in which cMt+1,i represents\nthe ith successor community of community Mt. AColor(M) represents the color of\ncommunity Mt in the alluvial diagram, VColor(v) denotes the color of node v in\n1312\n\ncommunity Mt. ii) Forward Coloring algorithm: given the community Mt+1 in\ntime stamp t+1, for any node (keyword) v in this community, if the same keyword\nv also occurred in community pMt,i, we let VColor(v) = AColor(pMt,i), in which\npMt,i represents the ith predecessors community of community Mt.\nBesides, we adopt the hierarchical layout in the colored network and put the core\nnodes in the centre of the layout, because we need to emphasise the importance of\nthe roles of each node in the evolution process.\n3. The NEViewer\nBased on the previous analysis, we designed and developed a novel network\nevolution analysis and visualization software: the NEViewer (Network Evolution\nViewer). We implement all the algorithms in Java, and we supported the NWB\nfile format (Network Workbench File format)121. The developers can also build\ntheir own plugins and implement their own algorithms in our software.\nNEViewer implement all of the algorithms we mentioned above. For community\ndetection, NEViewer supports Blondel algorithm (Blondel et al., 2008),\nNewman’s Modularity Maximization algorithm (Newman, 2004), Ball’s\nalgorithm on overlap community detection (Ball, Karrer, &amp; Newman, 2011).\nNEViewer also supports different types of community similarity measures such as\nJaccard similarity, Tanimoto similarity, cosine similarity, overlap of core nodes\nand FS measure we mentioned in this paper. NEViewer can visualize the\nevolution in both the alluvial diagram and the colored network diagram. Users can\neven choose the network layout. Some basic metrics are also supported in this\nsoftware such as the PageRank value and the centrality measures.\n\nFigure 4. Main view of NEViewer\n121\n\nhttp://nwb.cns.iu.edu/\n1313\n\n4. NEViewer Case Study\n4.1 Dataset\nIn order to evaluate the effectiveness of NEViewer, we constructed an evaluation\ndataset and conducted a qualitative evaluation on the software. A FIVE-CONF\ndataset was collected, which contains five main conferences in Information\nRetrieval, Data Mining and World Wide Web (i.e. KDD, SIGIR, CIKM, CSCW\nand JCDL). The FIVE-CONF dataset contains 7,234 papers that were published\nbetween 2000 and 2011 in one of the five conferences. We exclude workshop\npapers. Each paper in the dataset includes a title and an abstract. Both stemming\nand stop word removing were applied on the data.\n4.2 Construct Sequential data\nThe dataset is divided into three parts according to publishing time for\nconstructing the sequential datasets: T1= [t2000, t2003], T2= [t2004, t2007] and T3=\n[t2008, t2011]. There are 2480 papers in T1, 4283 papers in T2 and 5517 papers in\nT3. We construct three keyword networks N1, N2 and N3 based on those papers.\nIn total, 1217 nodes (keywords) and 12076 links exist in N1, 2295 nodes\n(keywords) and 25678 links exist in N2 and 2903 nodes (keywords) and 33272\nlinks exist in N3. The basic network measurements are shown in Table 1. After\nconstructing the sequential data, the Blondel’s community detection approach is\nadopted (Blondel, Guillaume, Lambiotte, &amp; Lefebvre, 2008) and the community\ndetection results are shown in Table 2.\nTable 1. Basic Network measures for three datasets\nMeasurements\nNodes\nIsolated Nodes\nEdges\nMean degree\nlargest connected component\nDensity\n\nT1\n1217\n9\n12076\n19.846\n1202\n0.00816\n\nDatasets\nT2\n2295\n16\n25678\n22.377\n2263\n0.00488\n\nT3\n2903\n17\n33272\n22.922\n2850\n0.00395\n\nTable 2. Number of communities and the average number of nodes in each\ncommunity in different datasets\nDatasets\nT1\nT2\nT3\n\n1314\n\nNumber of Communities\n23\n34\n41\n\nAverage number of nodes in each community\n50.71\n65.57\n69.12\n\n4.3 Topic Evolution\nTo visualize the overall keyword networks evolution, we adopt the alluvial\ndiagram proposed by Rosvall and Berstrom (2010) . Figure 5 gives an overall\npicture of the topic evolution of five conferences from 2000 to 2011, in which we\nignore the communities with 10 nodes or less because they usually have little\ninfluence on the whole datasets and only present too much noise. The overall\nevolution provides insights of the evolution of different topics. The major topics\ninvolve Information Retrieval (IR), Computer Supported Cooperative Work\n(CSCW), Social Networks, Visualization, World Wide Web and etc. Those topics\nare within our expectation because the chosen five conferences are majorly\nconcerning on those five domains. The evolution diagram actually show different\ntypes of evolution forms as mentioned in previous study (Palla, Barabasi &amp;\nVicsek ,2007). The “information retrieval” community in 2004-2007 divides into\nseveral small communities in 2008-2011. The “interaction design” community\nand partially “education” community in 2000-2003 merged in 2004-2007 into a\nbig “interaction design” community.\n\nFigure 5. The overall topic evolution on FIVE-CONF dataset\n\nIn order to look into the details of how each topic evolves, we took the\ninformation retrieval domain as an example. By clicking the Information\nRetrieval community in our software, we can acquire Figure 6, in which only we\nonly focus on one community evolution of Information Retrieval from T2 to T3.\nIn T3, there seemed to have five different topics: the machine learning application\nof Information Retrieval (labeled “classification”), the basic Search community,\n\n1315\n\nthe Web Search community, the Social Networks analysis in Information retrieval\nand the Sponsored search community.\nIn order to evaluate whether the community detection results actually revealed\nthe true latent structures of conference topics. We manually collect the program\nsessions SIGIR conference from 2008-2011. The results were shown in Table 3.\nWe found that during 2008 and 2010, there was at least a session about\nclassification, which can be used to explain our detected community label\n“classification”. Similarly, almost every year, there was a session named “Web\nIR” or “Web Search”, which might be corresponding to our detected community\nlabeled “Web IR”. Social media and Web 2.0 became important in recent years,\nand almost every year, there was a session about the “Social Media”. We also\nfound a small community in our detected community named “sponsored search”,\nthere was actually one session in 2010 “Link Analysis &amp; Advertising”. For all of\nthose detected communities, we actually found similar conference sessions in the\nreal conferences, which actually demonstrated the effectiveness of our community\ndetection and evolution algorithms.\nWe further analyze the forward colored network diagram of those five\ncommunities in Figure 7. The green nodes are those who originate from the\nprevious community. The size of nodes reflects the frequency of each node\noccurred in the network. In Figure 7(a), we found the “classification” is only a\nlabel of this community. The corresponding community actually contains\nmachine learning and data mining technologies. Similarly, the Figure 7(e) showed\nthat the “sponsored search” community actually stands for the computation\nadvertisement; the commonly used algorithms are from link analysis and\nPageRank.\n\nFigure 6: Topic evolution of Information Retrieval from T2 to T3\n\n1316\n\n(a) backward colored network for\n“Classification”\n\n(b) backward colored network for “Search”\n\n(c) backward colored network for\n“Classification”\n\n(d) backward colored network for “Search”\n\n(e) backward colored network for “Search”\nFigure 7: Backward colored network diagram for five communities\n\n1317\n\nTable 3. SIGIR Conference sessions from 2008-2011\n2008\nUser Interaction Models\n\nWeb Search\n\n2009\nNovel search features\n\nClassification\nand clustering\n\n2010\n\n2011\n\nClustering\n\nQuery Analysis\n\nUser Model\n\nLearning to Rank\n\nExpansion and feedback\n\nApplications\n\nRetrieval models\n\nCollaborative Filtering\n\nWeb 2.0\n\nSearch Engine Architectures and Scalability\n\nLearning to Rank\n\nRetrieval models\n\nHigh-Performance &amp; High Dimensional\nIndexing\nUser Adaptation &amp; Personalization\nClustering\nMultilingual &amp; Crosslingual Retrieval\n\nSpeech and linguistic\nprocessing\nRecommenders\nQuestion answering\nEfficiency\n\nLink Analysis &amp;\nAdvertising\n\nEvaluation\n\nSocial\nMedia\n\nWeb IR\n\nFiltering and Recommendation\nInformation Retrieval Theory\nLanguage Models &amp; IR Theory\n\nCollaborative\nfiltering\nQuery Analysis\nCommunities\nImage Search\n\nLearning to Rank\n\nRelevance Feedback\n\nWeb retrieval\n\nQuery Representations &amp; Reformulations\n\nWeb Queries\n\nSummarization\n\nLearning to Rank\n\nAutomatic Classification\n\nExploratory Search &amp; Filtering\nMultimedia Retrieval\n\nInformation extraction\nClickthrough models\n\nRetrieval Models and Ranking\nUser Feedback &amp; User Models\n\nCollaborative\nfiltering\nMultimedia IR\nSummarization\n\nQuery Analysis &amp; Models\n\nVertical search\n\nNon-Topicality\n\nInteractive search\n\nProbabilistic Models\n\nMultimedia\nFederated, distributed\nsearch\n\nDocument Structure &amp; Adversarial Information\nRetrieval\nUsers and Interactive IR\nDocument Representation and Content\nAnalysis\n\nQuestion-Answering\n\nIndustry Track speakers\n\nTest-Collections\n\nSocial Tagging\n\nEvaluation and\nmeasurement\nQuery formulation\nSpamming\n\nRecommender\nsystems\n\nQuery Log Analysis\n\nTest collections\n\nAnalysis of Social Networks\n\nContent Analysis\nLearning Models for IR\n\nText Classification\n\nWeb IR and\n\nSearch\n\nSocial Media\n\nQuery suggestions\nLinguistic Analysis\nEffectiveness\nMultilingual IR\n\nSummarization &amp; User Feedback\nQuery Analysis\nEffectiveness Measures\nMultimedia Information Retrieval\nNon-English IR &amp; Evaluation\n\n5. Conclusion and Discussion\nIn order to analyze the evolution of scientific topics, we proposed a novel cokeyword network evolution based method and developed the software, i.e. the\nNEViewer to tackle with the community detection, community mapping,\nrepresentative node finding and evolution visualization. The NEViewer provides\nimplementations of several well-known community analysis algorithms so that\nusers can specify their own preferences.\nThe NEViewer consists of four steps in the real analysis: the topic(community)\nfinding, the representative node selection, the evolution detection and the\nvisualization. We developed each step in different modules so that the developers\ncan implemented their own algorithms to each of our four steps.\nThere are already several topic evolution and knowledge mapping software such\nas CiteSpace, VosViewer, Network Workbench and SciMat. However, comparing\nto those software, the novelty of NEViewer are: (a) we developed four\nindependent steps in analyzing network visualization; (b) we implemented the\nalluvia diagram in order to show the visualization and we also designed and\n\n1318\n\nimplemented the Backward and Forward colored network diagram in helping\nusers make sense of both the macro- and micro- level of network evolution.\nHowever, there are still some limitations on our current approaches. We didn’t\ndistinguish the functional roles of each keyword. Some keywords may represent\nthe methodology while others reflect the research objects. This makes it difficult\nfor us to find the accurate representative nodes in each community. Besides, the\ncommunity mapping is still a big issue because they lacked a firm threshold and\nprinciples of predefining the thresholds.\nAcknowledgement\nThis paper is supported by the National Natural Science Foundation of China\n(Grant No.71003078) and the National Natural Science Foundation of China\n(Grant No. 71173164).\nReferences:\nBall, B., Karrer, B., &amp; Newman, M. (2011). Efficient and principled method for\ndetecting communities in networks. Physical Review E, 84(3), 36103.\nBerger-Wolf, T. Y., &amp; Saia, J. (2006). A framework for analysis of dynamic social\nnetworks.\nBlondel, V. D., Guillaume, J. L., Lambiotte, R., &amp; Lefebvre, E. (2008). Fast\nunfolding of communities in large networks. Journal of Statistical Mechanics:\nTheory and Experiment, 2008(10), P10008.\nBörner, K., Chen, C., &amp; Boyack, K. W. (2005). Visualizing knowledge domains.\nAnnual review of information science and technology, 37(1), 179-255.\nBoyack, K. W., Klavans, R., &amp; Börner, K. (2005). Mapping the backbone of\nscience. Scientometrics, 64(3), 351-374.\nChen, C. (2005). CiteSpace II: Detecting and visualizing emerging trends and\ntransient patterns in scientific literature. Journal of the American Society for\nInformation Science and Technology, 57(3), 359-377.\nCobo, M. J., López-Herrera, A. G., Herrera-Viedma, E., &amp; Herrera, F. (2010). An\napproach for detecting, quantifying, and visualizing the evolution of a research\nfield: A practical application to the fuzzy sets theory field. Journal of\nInformetrics.\nDing, Y. (2011). Community detection: Topological vs. topical. Journal of\nInformetrics, 5(4), 498-514.\nGuimerà, R., Sales-Pardo, M., &amp; Amaral, L. A. N. (2006). Classes of complex\nnetworks defined by role-to-role connectivity profiles. Nature physics, 3(1),\n63-69.\nLancichinetti, A., &amp; Fortunato, S. (2009). Community detection algorithms: A\ncomparative analysis. Physical Review E, 80(5), 56117.\nLeydesdorff, L., &amp; Rafols, I. (2008). A global map of science based on the ISI\nsubject categories. Journal of the American Society for Information Science\nand Technology, 60(2), 348-362.\n\n1319\n\nMane, K. K., &amp; Börner, K. (2004). Mapping topics and topic bursts in PNAS.\nProceedings of the National Academy of Sciences of the United States of\nAmerica, 101(Suppl 1), 5287-5290.\nMcCain, K. W. (2008). Assessing an author&#x27;s influence using time series\nhistoriographic mapping: The oeuvre of Conrad Hal Waddington (1905–1975).\nJournal of the American Society for Information Science and Technology,\n59(4), 510-525.\nNewman, M. E. J. (2004). Fast algorithm for detecting community structure in\nnetworks. Physical Review E, 69(6), 66133.\nPalla, G., Barabasi, A. L., &amp; Vicsek, T. (2007). Quantifying social group\nevolution. Nature, 446(7136), 664-667.\nPalla, G., Derényi, I., Farkas, I., &amp; Vicsek, T. (2005). Uncovering the overlapping\ncommunity structure of complex networks in nature and society. Nature,\n435(7043), 814-818.\nRosvall, M., &amp; Bergstrom, C. T. (2010). Mapping change in large networks. PloS\none, 5(1), e8694.\nWallace, M. L., Gingras, Y., &amp; Duhon, R. (2009). A new approach for detecting\nscientific specialties from raw cocitation networks. Journal of the American\nSociety for Information Science and Technology, 60(2), 240-246.\nWang, X., Jiang, T., &amp; Li, X. (2010). Structures and dynamics of scientific\nknowledge networks: An empirical analysis based on a co-word network.\nChinese Journal of Library and Information Science(3), 19-36.\nLin, X., Zhang, M., Zhao, H., and Buzydlowski, J. 2012. Multi-view of the ACM\nclassification system. Proceedings of the 12th ACM/IEEE-CS joint conference\non Digital Libraries. 397-398.\n\n1320\n\nTHE NUANCED NATURE OF E-PRINT USE: A\nCASE STUDY OF ARXIV\nVincent Larivière1, Benoit Macaluso1, Cassidy R. Sugimoto2, Staša Milojević2,\nBlaise Cronin2, and Mike Thelwall3\n1\n\nvincent.lariviere@umontreal.ca; macaluso.benoit@uqam.ca\nÉcole de bibliothéconomie et des sciences de l’information, Université de Montréal, C.P.\n6128, Succ. Centre-Ville, Montréal, QC. H3C 3J7 (Canada) and\nObservatoire des sciences et des technologies (OST), Centre interuniversitaire de\nrecherche sur la science et la technologie (CIRST), Université du Québec à Montréal, CP\n8888, Succ. Centre-Ville, Montréal, QC. H3C 3P8, (Canada)\n2\n\nsugimoto@indiana.edu; smilojev@indiana.edu; bcronin@indiana.edu\nSchool of Information and Library Science, Indiana University Bloomington\n1320 E. 10th St. Bloomington, IN 47401 (USA)\n3\n\nm.thelwall@wlv.ac.uk\nSchool of Technology, University of Wolverhampton, Wulfruna Street, Wolverhampton\nWV1 1LY (UK).\n\nAbstract\n\nSince its creation in 1991, arXiv has become central to the diffusion of research in a\nnumber of fields. Combining data from the entire arXiv and the Web of Science (WoS),\nthis paper investigates (a) the proportion of papers across all disciplines that are on arXiv,\n(b) Elapsed time between arXiv submission and journal publication, and (c) the aging\ncharacteristics and scientific impact of arXiv e-prints and their published version. It shows\nthat the proportion of WoS papers found on arXiv varies across the specialties of Physics\nand Mathematics, and that only a few specialties make extensive use of the repository.\nElapsed time between arXiv submission and journal publication has also shortened, but\nremains longer in Mathematics than in Physics. In Astronomy and Astrophysics, arXiv\nversions are cited more promptly and decay faster than WoS papers. Unsurprisingly,\narXiv versions of papers—both published and unpublished—have lower citation rates,\nalthough there is almost no difference in the impact of the arXiv versions of both\npublished and unpublished papers.\n\nConference Topic\n\nOpen Access and Scientometrics (Topic 10) and Bibliometrics in Library and Information\nScience (Topic 14).\n\nIntroduction\nPreprints—“temporary documents whose function is to bridge the time-gap\ncreated by publication delays” (Goldschmidt-Clermont, 1965, p. 8)—are a wellestablished mechanism for the exchange of scientific information (Mikhailov,\n1321\n\nChernyi, &amp; Giliarevskii, 1984). This is particularly true in astronomy and physics,\ndisciplines that have long used preprints to communicate research results (Brooks,\n2009; Brown, 2001; Wilson, 1970; Kling, 2005) and establish priority claims,\nthereby effectively reducing the role of the journal to “secondary distribution,\narchiving, and peer review” (Brooks, 2009, p. 92). Advocates of open access view\nsubject repositories, such as arXiv, as heralding the eventual demise of the\nscholarly journal and have outlined ways in which peer review might function on\nthese new platforms (Rodriguez, Bollen, &amp; Van de Sompel, 2006) while others\nlook forward to “the stranglehold journal publishers have over science libraries”\nbeing broken (Carriveau, 2008, p. 73). Hence the question: can or need these two\nforms of scholarly communication co-exist (Morris, 2003)?\nFirst a word of caution: one should not be blinded by enthusiasm for the new.\nPreprints, after all, are far from novel. By way of illustration, the Information\nExchange groups, run by the National Institutes of Health, circulated more than\n1.5 million preprints in 1966 (Confrey, 1996). Moreover, relatively few scholars,\nwith physicists and mathematicians being notable exceptions, use preprints\nextensively (Swan &amp; Brown, 2003). Lastly, what appears to work as a publishing\nmodel in one field may not translate to another (Kling, Spector, &amp; McKim, 2002;\nKling, Spector, &amp; Fortuna, 2004).\nSince its creation by Paul Ginsparg in 1991, arXiv has become central to the\ndiffusion of research in a number of related fields: physics, mathematics, and\ncomputer science in particular (Gentil-Ceccot, Mele, &amp; Brooks, 2009). Previous\nresearch has examined: the use made of arXiv (Brown, 2001); ordering and\ncitation rates (Haque &amp; Ginsparg, 2009); the coexistence of e-prints and journals\n(Henneken et al., 2007); and the effect of arXiv on citation rates (Moed, 2007).\nHowever, data from all of arXiv and the Web of Science (WoS) have yet to be\ncombined for a comparative analysis. This paper combines the entire arXiv with\nthe entire Web of Science in order to better understand the ecology of scholarly\ncommunication. More specifically, we investigate (a) the proportion of papers\nacross all disciplines that are on arXiv, (b) the elapsed time between arXiv\nsubmission and journal publication, and (c) the aging characteristics and scientific\nimpact of arXiv e-prints and their alter egos (the versions published in the journal\nof record). This last analysis is performed on a subset of the dataset comprising\npapers published in Astronomy and astrophysics.\nBackground\narXiv and related platforms\nPaul Ginsparg launched xxx.lanl.gov, the first Internet-based e-print server, in\n1991 to facilitate preprint exchange in the field of theoretical high-energy physics\n(Brown, 2010; Carriveau, 2008; Davis &amp; Fromert, 2007; Ginsparg, 2008). The\nname was changed to arXiv.org in 1998, after it grew in popularity and expanded\n1322\n\nto cover other fields (Ginsparg, 2008). The aim was to create an electronic\nbulletin board “to serve a few hundred friends and colleagues” (Ginsparg, 2011,\np. 145). arXiv was “designed as a way of automating a paper-based process\nalready in existence” (Pre-print culture, Pinfield, 2001, para. 1). Today’s muchenlarged arXiv is strongest in physics, mathematics, and computer science\n(Brody, Harnad, &amp; Carr, 2006), fields in which there is a tradition of preprint use.\nThe number of articles in arXiv has been growing linearly since 1991 (Brody,\nHarnad, &amp; Carr, 2006) and arXiv is now the “largest self-archived centralized eprint archive” (Brody, Harnad, &amp; Carr, 2006, p. 102). Originally hosted at the Los\nAlamos National Laboratory (hence the initial domain name), it was later moved\nto Cornell University, where it is under the aegis of the university library (Hey &amp;\nHey, 2006). In parallel, Ginsparg began a movement to develop a set of technical\nstandards for the establishment of a global preprint archive via the Universal\nPreprint Service Initiative—later known as the Open Archives Initiative (Brown,\n2001; Manuel, 2001). The federated nature of OAI repositories has led to\nproposals for a “repository-centric peer-review model” based on the OAI platform\nand using a social-network algorithm to suggest potential reviewers and weigh\nevaluations (Rodriguez, Bollen, &amp; Van de Sompel, 2006).\nIn 1997, arXiv began collaborating with the Astrophysics Data System (ADS).\nThe ADS created an index for the astrophysics e-prints and made them available\nthrough the ADS abstracts service. In 2002, abstracts of all arXiv categories were\nincluded (Henneken et al., 2007). arXiv also has a relationship with SPIRES, the\nfirst electronic catalogue of grey literature, focused on high-energy physics\npreprints (Bentil-Beccot, Mele, Brooks, 2009). SPIRES counts citations to and\nfrom preprints and directs physicists to arXiv (82% of clicks from SPIRES go to\narXiv) (Bentil-Beccot, Mele, Brooks, 2009). SPIRES is currently being replaced\nwith INSPIRE, which was created to “provide an even more flexible and\nextensible system to allow publishers, repositories, and researchers themselves to\ncontribute and share information” (Brooks, 2009, p. 91). A survey of high-energy\nphysicists found that nearly 90% rely on SPIRES and arXiv as their point of entry\nto the literature. This system is so embedded in the working practice of physicists\nthat Kling, McKim, and King (2003) considered SPIRES, arXiv, and associated\nhuman actors as the embodiment of a functioning socio-technical interaction\nnetwork.\nEmpirical investigations of arXiv\nOver the years, several studies have focused on authors’ practices with respect to\narXiv: Fowler’s (2011) survey of mathematicians found that 81% had posted to\narXiv and that it was a regular sharing mechanism for 30%; Manuel (2001) found\nthat authors were primarily academic (rather than corporate); and Moed (2007)\nshowed that posters tended to be high-impact authors (measured by the citation\nimpact of those of their papers not deposited in arXiv). However, most research\n1323\n\nhas focused on the preprints—specifically on the relationship between preprints\nand their subsequent publication and impact. For example, approximately half of\nall preprints in arXiv are subsequently published in peer-reviewed publications\n(Manuel, 2001; Mine, 2009). Studies have also looked at the inverse, viz., the\nproportion of journal literature in a given field that is also in arXiv. Rates\nincluded almost 100% in high energy physics (Gentil-Beccot, Mele, &amp; Brooks,\n2009), 75% in condensed matter (Moed, 2007), and 18.5% in mathematics (Davis\n&amp; Fromerth, 2007). The number of articles appearing in both arXiv and the\npublished literature is increasing (Gentil-Beccot, Mele, &amp; Brooks, 2009; Davis &amp;\nFromerth, 2007). Peer-reviewed articles that were also preprints receive\nsignificantly more citations than articles not deposited (Davis &amp; Fromerth, 2007;\nGentil-Beccot, Mele, &amp; Brooks, 2009). The reasons suggested are: an early view\neffect, a quality differential, and an open access advantage (Kurtz et al., 2005;\nDavis &amp; Fromerth, 2007).\nSome studies confirm the early view effect (Moed, 2007): “colleagues in the field\nstart the process of reading a paper, processing its information, and citing it in\ntheir own articles earlier if a paper is deposited in arXiv” (Moed, 2007, p. 2053).\nHowever, other studies have found no such effect (Davis &amp; Fromerth, 2007).\nEvidence has also been found to support a ‘quality bias’, that is, better papers and\nhigh impact authors appear in arXiv more than the reverse (Davis &amp; Fromerth,\n2007; Moed, 2007). Little or no support has been found for the open access\nadvantage, however (Moed, 2007; Kurtz et al., 2005; Davis &amp; Fromerth, 2007).\nAs Kurtz et al. (2005, p. 1400-1401) concluded: “This implies that there is no\nsignificant population of astronomers who are both authors of major journal\narticles and who do not have ‘sufficient’ access to the core research literature.”\nHaque and Ginsparg (2009, 2010) found that posts on arXiv at the beginning and\nend of the day receive higher levels of citation and readership than those in the\nmiddle. Other studies have examined the proportion of citations to the e-print\nversion of the paper, with mixed findings (Youngen, 1998; Manuel, 2001).\nReadership has been investigated, too. Using two years of cumulative download\nand citation data from arXiv, Brody, Harnad and Carr (2006) found that download\ncounts at six months provided reliable predictions of citation impact at two years.\nThey concluded that, “the rapid dissemination model of arXiv has accelerated the\nread-cite-read cycle substantially” (Harnad, Brody, &amp; Carr, p. 1062). The\nrelationship between the publisher’s version and the preprint remains unclear:\nDavis and Fromerth (2007) found that arXiv-deposited articles received 23%\nfewer downloads from publishers’ websites. However, Henneken et al. (2007), in\na study of four astronomy journals, found that reads of the arXiv e-print through\nADS dropped to zero (or near zero) immediately following the publication of the\npeer-reviewed article. They also note that the half-life of e-prints is shorter than\nthat of the corresponding journal articles, concluding that, “e-prints have not\n\n1324\n\nundermined journal use in the astrophysics community and thus do not pose a\nthreat to the journal readership” (Henneken et al., 2007, p. 19).\nMethods\nHere we use two data sources: the arXiv database and WoS. All arXiv database\nmetadata from 1990 to March 22, 2012 were downloaded (N = 744,583 e-prints).\nAll standard citation indexes were used for WoS (Science Citation Index\nExpanded, Social Sciences Citation Index and Arts and Humanities Citation\nIndex) for the 1990-2011 period. Data are presented for 1995—2011 (although\ncitations and matching papers were compiled until the first 42 weeks of 2012).\nTwo types of links between the data sources were created: (a) between the arXiv\ne-print and its published version indexed in WoS and (b) between the arXiv eprint and the citations it received in WoS. Several steps were needed to match the\narXiv e-print to its published counterpart (a). First, three sets of links were\nestablished: 1) direct correspondence between the arXiv and WoS titles, 2) fuzzy\nmatching between the arXiv and WoS titles AND fuzzy matching between the\njournal mentioned in the arXiv bibliographical notice and the WoS journal, 3)\nfuzzy matching between the arXiv and WoS titles AND fuzzy matching between\nthe arXiv first author and the WoS paper first author. These links were, in a\nsecond step, automatically validated through the similarity of their abstracts. In\ntotal, 441,018 out of the 744,583 arXiv e-prints (59.2%) were matched with a\nWoS-indexed journal article, note or review.\nFor the second matching (b) we utilized the specific structure of the references to\nthe arXiv e-prints in WoS. For example, a reference to an e-print from the\ncondensed matter section of arXiv will have the string ‘CONDMAT’ followed by\nthe series of seven or eight digits that correspond to its document ID in the online\ne-print database. Given that a paper belonging to more than one arXiv category\ncan be cited using both categories as prefixes, the matching process used the\nseven or eight digits as well as its prefix. For Astronomy and Astrophysics, we\nseparated documents into four distinct categories: 1) arXiv e-prints never\npublished in a WoS-indexed journal, 2) arXiv e-prints published in a WoSindexed journal, 3) WoS-indexed journal articles also published and archived as\nan arXiv e-print, and 4) WoS-indexed journal articles that were never published\nas arXiv e-prints. Finally, the field classification used is that of the U.S. National\nScience Foundation122, developed by The Patent Board.\nResults and discussion\nProportion of WoS papers on arXiv\nAs mentioned in the Methods section, about 60% of all arXiv e-prints are\npublished in a WoS-indexed journal. This percentage is slightly higher than those\n122\n\nhttp://www.nsf.gov/statistics/seind06/c5/c5s3.htm#sb1\n1325\n\nobtained by Manuel (2001) and Mine (2009), which is likely a consequence of the\nincrease in self-archiving in recent years. On the other hand, when taking all WoS\npapers as the denominator, only 3.3% of 2010-2011 WoS papers (all disciplines\ncombined) were submitted to arXiv. Three disciplines account for the vast\nmajority (93%) of arXiv submissions in 2010-2011: Mathematics (with 21% of all\nWoS papers on arXiv), Physics (19% of all WoS papers on arXiv) and Earth and\nSpace (11% of all WoS papers on arXiv). Within these disciplines, a few\nspecialties are using it more intensively. As shown in Figure 1, about two-thirds\nof WoS papers published in Astronomy and Astrophysics and Nuclear and\nParticle Physics are found on arXiv. The Inset of Figure 1 shows that this\npercentage has increased since 1995. While researchers in Nuclear and Particle\nPhysics were quick to adopt arXiv—this percentage was already greater than 60%\nin 2000—those in astronomy gradually made a greater use of it. Since the mid2000s, both specialties have used arXiv to the same extent. In Nuclear and\nParticle Physics, the percentage we obtain is lower than that of Gentil-Beccot,\nMele, and Brooks (2009) for high-energy physics, which is due to the fact that\ntheir definition of the field only included 5 high-impact journals, while ours\ncovered 48 journals. In Mathematics, our percentages are higher than those of\nDavis and Fromerth (2007), which is likely a consequence of the increase of\npapers appearing in both arXiv and in the WoS.\nAstronomy &amp; Astrophysics\nNuclear &amp; Particle Physics\nGeneral Physics\nGeneral Mathematics\nSolid State Physics\nMiscellaneous Mathematics\nMiscellaneous Physics\nProbability &amp; Statistics\nApplied Mathematics\nFluids &amp; Plasmas\nChemical Physics\nAcoustics\nComputers\nApplied Physics\nOptics\n\n80%\n70%\n\nPercentage of articles\n\n60%\n50%\n40%\n30%\n\nNuclear &amp; Particle\nPhysics\n\n20%\n\nAstronomy &amp;\nAstrophysics\n\n10%\n0%\n1995\n\n0%\n\n10%\n\n2000\n\n20%\n30%\n40%\n50%\nPercentage of WoS-papers (2010-2011)\n\n2005\n\n2010\n\n60%\n\n70%\n\nFigure 1. Proportion of WoS papers on arXiv, by specialty (2010-2011). Inset:\nProportion of WoS papers on arXiv, by specialty, 1995-2011.\n\nElapsed time between arXiv submission and journal publication Figure 2 shows\nthat the time between the submission of the manuscript to arXiv and publication\n1326\n\nin a peer-reviewed journal has decreased123. Whereas papers were once published\na year after appearing on arXiv, publication in a journal is now likely to occur in\nthe same year as their appearance on arXiv. There are two possible reasons for\nthis: 1) a higher proportion of researchers are waiting for the paper to be\npublished or accepted for publication before submitting to arXiv, or 2) the\nintroduction of arXiv may have motivated publishers to try to reduce publication\ndelays.\n25000\n\nNumber of papers\n\n20000\n\n15000\n\n10000\n\n5000\n\n0\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n2010\n2009\n2008\n2007\n2006\n2005\n2004\n2003\n2002\n2001\n2000\n1999\n1998\n1997\n1996\n1995\n\nDelay between arXiv submission and publication year\n\nFigure 2. Distribution of the elapsed time between arXiv submission and publication\nyear, by year of submission to arXiv, 1995-2010.\n\nElapsed time between arXiv submission and journal publication varies\ndramatically across specialties of science. Figure 3 presents this interval—\ncompiled as an average—for the 18 specialties with more than 1,000 WoS papers\nfound on arXiv. It globally shows that specialties of physics have very short\ndelays—less than half a year on average—while those of mathematics have\nlonger delays (&gt;1 year). Among the specialties with the shortest time between\narXiv submission and journal publication is Astronomy and Astrophysics, one of\nthe two specialties with the most intensive use of preprints. The appearance of\nGeneral Biomedical Research is due to the fact that “general” journals that\npublish Physics or Mathematics papers, such as Science and Nature, are\ncategorized in this specialty.\n123\n\n11,946 e-prints out of 440,371 that matched to a WoS paper (2.7%) have been submitted on\narXiv after journal publication; those have been removed from this part of the analysis.\n1327\n\nMiscellaneous Mathematics\nGeneral Mathematics\nApplied Mathematics\nComputers\nProbability &amp; Statistics\nElectrical Engineering &amp; Electronics\nMiscellaneous Physics\nFluids &amp; Plasmas\nGeneral Physics\nMaterials Science\nPhysical Chemistry\nApplied Physics\nOptics\nNuclear &amp; Particle Physics\nSolid State Physics\nChemical Physics\nAstronomy &amp; Astrophysics\nGeneral Biomedical Research\nOther specialties (N=91)\n0,0\n\n0,2\n\n0,4\n\n0,6\n0,8\n1,0\n1,2\n1,4\nAverage publication delay (year)\n\n1,6\n\n1,8\n\nFigure 3. Average elapsed time between arXiv submission and journal publication,\nby specialty (with more than 1,000 e-prints matched with a WoS paper), 1995-2011.\n\nAging characteristics and scientific impact\nThis section analyzes the aging characteristics and scientific impact of arXiv eprints and their WoS-published alter egos for the specialty Astronomy and\nAstrophysics. Figure 4 presents (A) the trends in the numbers of papers that have\nappeared on arXiv only, on arXiv and WoS (arXiv version), in WoS only and on\narXiv and WoS (WoS version) and (B) the mean number of citations these\ndocuments have received using a one-year citation window plus publication year.\nWe see a considerable increase in the number of documents published both in\narXiv and in journals, a small increase in the number of papers published only in\narXiv, and a decline in papers published only in journals. In terms of proportion\nof all distinct Astronomy and Astrophysics documents in 2010—obtained by the\ncombination of both arXiv and WoS—19% are found on arXiv only, 54% both on\narXiv and in WoS and 27% in WoS only.\nThe citation rates of the four groups are quite different and vary over time. WoS\nversions of arXiv e-prints obtain the highest citation rates, a finding consistent\nwith the well documented association between arXiv submission and citation\n(Davis &amp; Fromerth, 2007; Gentil-Beccot, Mele, &amp; Brooks, 2009). However, this\nmean impact is decreasing—even when we add to the WoS version the citations\nreceived by the arXiv version—and is approaching that of other WoS papers not\nsubmitted to arXiv, whose mean impact is increasing. arXiv versions—both\n1328\n\npublished and unpublished—obtain lower citation rates. Surprisingly, however,\nthere is almost no difference in the impact of the arXiv versions of both published\nand unpublished papers. One could have expected that these unpublished papers,\nbeing non-refereed, would have a lower impact than comparable arXiv\nsubmissions published in a journal. However, it is possible that researchers prefer\nto cite the published version of an e-print which is likely to reduce published eprint impact and, hence, make the two measures comparable. On the whole, these\nresults are consistent with those of Brooks (2009), who showed that unpublished\narXiv submissions had 5 times less impact than those published in a journal, when\none includes the citations received by the published version of the e-print.\nA\n\n9000\n\nB\n\n3,5\n\n8000\n\nArXiv and\nWoS (WoS\nversion)\n\n3\n\nAverage citation rate\n\nNumber of documents\n\n7000\n6000\n5000\n4000\n3000\n\n2,5\n\nOnly in\nWoS\n\n2\n\nArXiv and\nWoS\n(ArXiv\nversion)\nArXiv Only\n\n1,5\n1\n\n2000\n0,5\n\n1000\n0\n\n0\n1995\n\n2000\n\n2005\n\n2010\n\n1995\n\n2000\n\n2005\n\n2010\n\nFigure 4. A) Number of documents published and B) mean number of citation\nreceived (publication year plus one year), for documents published on arXiv only, on\narXiv and WoS (arXiv version), only in WoS and on arXiv and WoS (WoS version),\n1995-2010\n\nIn terms of aging characteristics, Figure 5 presents the age distribution of citations\nreceived by the four groups of documents. It shows that e-prints and published\npapers follow different patterns. Citations to e-prints peak the year following\nsubmission, while citations to papers are similar during the two years following\nthe publication year. Given the transfer of citations from pre-publication e-prints\nto their published version (Brown, 2001; Henneken et al., 2007), citations to their\ne-print versions decay faster than those received by unpublished e-prints. E-prints\nfound on arXiv only have a slower decay, although it is faster than that of WoS\npapers. These faster citations for arXiv e-prints are consistent with findings of\nHarnad, Brody, and Carr (2006) as well as those of Henneken et al. (2007).\n\n1329\n\n50%\nArXiv and WoS (ArXiv version)\n\n45%\n40%\n\nArXiv Only\n\nPercentaeg of citations\n\n35%\n\nArXiv and WoS (WoS version)\n\n30%\n\nOnly in WoS\n\n25%\n20%\n15%\n10%\n5%\n0%\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n7\n8\n9 10\nYear following publication\n\n11\n\n12\n\n13\n\n14\n\n15\n\n16\n\nFigure 5. Percentage of citations received, for documents published on arXiv only, on\narXiv and WoS (arXiv version), only in WoS and on arXiv and WoS (WoS version),\n1995-2010\n\nConclusion\nThis paper shows that arXiv has changed the scholarly communication patterns of\nphysicists and mathematicians. In some specialties, such as Astronomy and\nAstrophysics and Nuclear and Particle Physics, the vast majority of papers\npublished in WoS-indexed journals are found on arXiv. The role of arXiv in these\ncommunities has moved from the space of sharing pre-prints by minority, to the\nplace for archiving the majority of produced research. However, we also note that,\nin those disciplines, there is still a significant proportion of papers that are not on\narXiv. Previous research on the topic, focusing on high-impact journals\nexclusively, has found a greater proportion of WoS-papers in those specialties to\nbe on arXiv (Gentil-Beccot, Mele, &amp; Brooks, 2009), Our results show that, when\nthe whole discipline is considered—both high-impact and low-impact journals\nalike—the proportion of published papers that are self-archived on arXiv is\nnoticeably lower. Similarly, not all specialties are using it to the same extent: in\nmost specialties of Physics and Mathematics, less than a third of WoS papers are\nfound on arXiv. Along these lines, arXiv is increasingly used outside these two\nfields, but is still quite marginal: 93% of all WoS-published arXiv e-prints are\npublished either in Mathematics, Physics or Earth and Space sciences. Our results\nalso show that the average elapsed time between submission to arXiv and\n1330\n\npublication in a WoS-indexed peer-reviewed journal has decreased over time.\nThis is either due to a higher proportion of researchers waiting for the paper to be\npublished or accepted for publication before submitting to arXiv, or to a reduction\nin publication delays. These time lags are also quite different across fields of\nscience, with Physics specialties having shorter delays than specialties of\nMathematics.\nThe subset of Astronomy and Astrophysics papers analysed shows that arXiv\nversions of papers are cited more promptly and decay faster than WoS papers.\nWoS versions of arXiv e-prints obtain the highest citation rates, but the difference\nwith other WoS papers not submitted to arXiv is decreasing. Unsurprisingly,\narXiv versions of papers—both published and unpublished—obtain lower citation\nrates, although there is almost no difference in the impact of the arXiv versions of\nboth published and unpublished papers. As Harnad, Brody, and Carr (2006) point\nout, the fact that preprints are cited before publication—and, hence, peer review—\nas well as the fact that unpublished e-prints are cited raises the question of the\nfunction of peer-review in those fields. It seems that citing authors either evaluate\npapers themselves, often being reviewers, or trust the results presented—which\nmight be a consequence of the few massive collaborations and large-scale\nscientific infrastructures found in these disciplines.\nAcknowledgments\nThis research was funded by SSHRC (Canada), National Science Foundation\n(U.S.; grant #1208804) AHRC/ESRC/JISC (U.K.) through the Digging into Data\nfunding program.\nReferences\nBrody, T., Harnad, S., &amp; Carr, L. (2006). Earlier web usage statistics as predictors\nof later citation impact. Journal of the American Society for Information\nScience &amp; Technology, 57(8), 1060-1072.\nBrooks, T.C. (2009). Organizing a research community with SPIRES: Where\nrepositories, scientists and publishers meet. Information Services &amp; Use, 29,\n91-96.\nBrown, C. (2001). The e-volution of preprints in the scholarly communication of\nphysicists and astronomers. Journal of the American Society for Information\nScience &amp; Technology, 52(3), 187-200.\nBrown, C. (2010). Communication in the sciences. In B.Cronin (Ed.), Annual\nReview of Information Science &amp; Technology (pp. 287-316). Medford, N.J.:\nInformation Today.\nCarriveau, K.L. (2008). A brief history of e-prints and the opportunities they open\nfor science librarians. Science &amp; Technology Libraries, 20(2-3), 73-82.\nConfrey, E.A. (1996). The Information Exchange Groups experiment. Publishing\nResearch Quarterly. 12(3), 37-39\n\n1331\n\nDavis, P.M., &amp; Fromerth, M.J. (2007). Does the arXiv lead to higher citations and\nreduced publisher downloads for mathematics articles? Scientometrics, 71(2),\n203-215.\nFowler, K.K. (2011). Mathematicians’ views on current publishing issues: A\nsurvey of researchers. Issues in Science and Technology Librarianship, 67.\nRetrieved from: http://www.istl.org/11-fall/refereed4.html\nGentil-Beccot, A., Mele, S., &amp; Brooks, T.C. (2009). Citing and reading\nbehaviours in high-energy physics. How a community stopped worrying about\njournals and learned to love repositories. Retrieved from:\nhttp://arxiv.org/abs/0906.5418\nGinsparg, P. (2008). The global village pioneers. Learned Publishing, 21, 95-100.\nGinsparg, P. (2011). arXiv at 20. Nature, 476, 146-147.\nGoldschmidt-Clermont, L. (1965). Communication patterns in high-energy\nphysics. Retrieved from: http://testing-library.web.cern.ch/testinglibrary/Webzine/6/papers/1\nHaque, A.-u., &amp; Ginsparg, P. (2009). Positional effects on citation and readership\nin arXiv. Journal of the American Society for Information Science &amp;\nTechnology, 60(11), 2203-2218.\nHaque, A.-u., &amp; Ginsparg, P. (2010). Last but not least: Additional positional\neffects on citation and readership in arXiv. Journal of the American Society for\nInformation Science &amp; Technology, 61(12), 2381-2388.\nHenneken, E.A., Kurtz, M.J., Eichhorn, G., Accomazzi, A., Grant, C.S.,\nThompson, D., Bohlen, E., Murray, S.S., Ginsparg, P., &amp; Warner, S. (2007).\nE-prints and journal articles in astronomy: A productive co-existence. Learned\nPublishing, 20, 16-22.\nHey, T., &amp; Hey, J. (2006). e-Science and its implications for the library\ncommunity. Library Hi Tech, 24(4), 515-528.\nKling, R. (2005). The Internet and unfrefereed scholarly publishing. In B.Cronin\n(Ed.), Annual Review of Information Science &amp; Technology (pp. 591-631).\nMedford, N.J.: Information Today.\nKling, R., McKim, G., &amp; King, A. (2003). A bit more to it: Scholarly\ncommunication forums as socio-technical interaction networks. Journal of the\nAmerican Society for Information &amp; Technology, 54(1), 47-67.\nKling, R., Spector, L., &amp; McKim, G. (2002). Locally controlled scholarly\npublishing via the Internet: The Guild model. The Journal of Electronic\nPublishing, 8(1). doi: http://dx.doi.org/10.3998/3336451.0008.101\nKling, R., Spector, L.B., &amp; Fortuna, J. (2004). The real stakes of virtual\npublishing: The transformation of e-biomed into PubMed Central. Journal of\nthe American Society for Information Science &amp; Technology, 55(2), 127-148.\nKurtz, M.J., Eichhorn, G., Accomazzi, A., Grant, C., Demleitner, M., Henneken,\nE., &amp; Murray, S.S. (2005). The effect of use and access on citations.\nInformation Processing &amp; Management, 41, 1395-1402.\nManuel, K. (2001). The place of e-prints in the publication patterns of physical\nscientists. Science &amp; Technology Libraries, 20(1), 59-85.\n1332\n\nMikhailov, A.I., Chernyi, A.I., &amp; Giliarevskii, R. (1984). Scientific\ncommunication and informatics. Arlington: Information Resources.\nMine, S. (2009). The roles and place of arXiv in scholarly communication.\nLibrary and Information Science, 61, 25-58.\nMoed, H.F. (2007). The effect of ‘Open Access’ on citation impact: An analysis\nof arXiv’s condensed matter section. Journal of the American Society for\nInformation Science &amp; Technology, 58(13), 2047-2054.\nMorris, S. (2003). Open publishing. Learned Publishing, 16, 171-176.\nPinfield, S. (2001). How do physicists use an e-print archive? D-Lib Magazine,\n7(12).\nRodriguez, M.A., Bollen, J., &amp; Van de Sompel, H. (2006). The convergence of\ndigital libraries and the peer-review process. Journal of Information Science,\n32(2), 149-159.\nSwan, A., &amp; Brown, S. (2003). Authors and electronic publishing: What authors\nwant from the new technology. Learned Publishing, 16, 28-33.\nWilson, J.H. (1970). International high-energy physics preprint network\nemphasizes institutional exchange. Journal of the American Society for\nInformation Science, 21(1), 95-97.\n\n1333\n\nON THE DETERMINANTS OF RESEARCH\nPERFORMANCE: EVIDENCE FROM ECONOMIC\nDEPARTMENTS OF FOUR EUROPEAN\nCOUNTRIES (RIP)\nStelios Katranidis,1 Theodore Panagiotidis2 and Costas Zontanos3\n1\n\nkatranid@uom.gr\nUniversity of Macedonia, Dept. of Economics, 156 Egnatia Str., 540 06 Thessaloniki\n(Greece)\n2\n\ntpanag@uom.gr\nUniversity of Macedonia, Dept. of Economics, 156 Egnatia Str., 540 06 Thessaloniki\n(Greece)\n3\n\nzontanos@uom.gr\nUniversity of Macedonia, Library &amp; Information Center, 156 Egnatia Str., 540 06\nThessaloniki (Greece)\n\nAbstract\n\nThis paper investigates the research performance of 404 economists working in 17\nEconomics Departments from 4 countries. We compare two countries from the North of\nEurope (Belgium and Denmark) with two countries from the South (Greece and Portugal).\nWe differentiate the research performance of their faculty depending on the country they\ndid their PhD and the country of their current affiliation. Based on these, we rank their\nperformance. Furthermore, we employ regression analysis to identify the factors that drive\nthe research performance taking into account both the research environment they have\nfaced while PhD students and as faculty. The most productive economists have a PhD\nfrom the US and work in the North.\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3) and Management and Measurement of Bibliometric Data within Scientific\nOrganizations (Topic 9).\n\nIntroduction\nThere has been an increasing interest on ranking researchers, faculty members,\ndepartments, universities and scientific journals. This is evident from the increase\nin publications on the topic. This paper evaluates the research work of - 404\neconomists – faculty members of 17 European Economics Departments; 8 of\nthem in Belgium, 2 in Denmark, 3 in Portugal and 4 in Greece. The objectives of\nthis study are: first, by adopting more than one productivity indicators, we\nevaluate the published research work and make comparisons. Second, we\n1334\n\ndemonstrate that the place of doctoral studies (Ph.D. origin) affects research\nperformance. Third, we examine the relation between the place of affiliation and\nresearch productivity.\nReview of the relevant literature\nA number of papers related to research evaluation and academic ranking have\nbeen published recently. The data they employ are based on the number of papers\npublished in international refereed academic journals and their corresponding\ncitations. The former are globally recognized as the main outlet of scientific work\nin economics. Many of these studies assess quality via the journals’ (Combes, &amp;\nLinnemer, 2003; Kalaitzidakis, Mamuneas, &amp; Stengos, 2003; Kalaitzidakis,\nMamuneas, &amp; Stengos, 2011). Attempts of this kind, i.e. evaluation and rankings\nof European economists and economic institutions based on this method, include\nKalaitzidakis, Mamuneas, &amp; Stengos (1999) on Greek university departments,\nGuimaraes (2002) on Portuguese, Bauwens (2003) on Belgian, Çokgezen (2006)\non Turkish faculty and universities and Lubrano, Bauwens, Kirman, &amp;\nProtopopescu (2006) where faculties and research performance was compared for\n18 European countries. On the other hand, more recently published papers, for\nIreland (Ruan, &amp; Tol, 2008; Tol, 2008), for Israel (Ben-David, 2010), for Sweden\n(Henkerson, &amp; Waldenström, 2011) and for Greece (Katranidis, Panagiotidis, &amp;\nZontanos, 2012), rely on bibliometric databases (Web of Science, Google Scholar\nand Scopus) and consider directly the scientific impact of each paper separately,\ni.e. according to the times it has been cited.\nBesides rankings, some of the above papers proceed even further; for example, to\nexamine the differences in research performance between private and state\nuniversities (Çokgezen, 2006), high and low rank academic positions (Ben-David,\n2010) and differences in academic advancements due to the country where the\ndoctoral studies have been carried out (Guimaraes, 2001; Katranidis, Panagiotidis,\n&amp; Zontanos, 2012).\nThe factors that have appeared in the literature as determinants of research\nperformance include (i) the place and especially the university where the doctoral\nstudies were completed, and (ii) the department where the faculty member serves\nas a researcher, and both factors in combination with the time that has elapsed\nsince completing the doctoral studies (academic age) (Long, 1978; Long, Bowers,\nBarnett, &amp; White, 1998).\nOur sample includes 404 faculty members from 17 departments. We have\ndetermined the sample size using two criteria: (a) at the national level the overall\nsample size represents 25% of the RePEc registered economists, (b) within that\ntotal number, we established a hierarchy of departmental affiliation, whereby we\ngave priority to the members of higher ranking departments, until reaching the\ndesignated ceiling. The departments involved are listed in the appendix.\nWe calculate the following bibliometric indices: productivity (number of\npublications per faculty); overall impact (number of citation per faculty) and the\nrational h*-index as it has been initially proposed by Hirsch (2005) and modified\n1335\n\nby Tol (2008), all of them divided by the research age, i.e. the number of years\nafter the completion of their PhD. These indices are lightening several aspects of\nwhat the literature refers to as research performance.\nThe analysis for each faculty member of all the seventeen economics departments\nunder consideration is based on data retrieved form Scopus (March-May 2012).\nThe faculty members have been identified according to the Website of each\ndepartment (only economists have been considered). Data on the research work\nof each faculty member (number of papers, number of citations, and h*-index)\nwere collected from the Scopus citation database.\nDescriptive statistics\nTable 1. Research age and faculty distribution according to the PhD origins in %\nCountry\n\nResearch\nAge\n\nBelgium\nDenmark\nGreece\nPortugal\n\n18.01\n16.05\n20.22\n15.79\n\nDpt. or\nInst.\n50.39\n59.32\n9.75\n45.92\n\nPhD Origins in %\nHome\nEurope\nUK\n19.38\n6.78\n8.54\n3.06\n\n13.18\n18.64\n10.98\n19.39\n\n2.33\n1.69\n39.02\n10.20\n\nOverseas\n\nFaculty\nmembers\n\n14.73\n13.56\n31.71\n21.43\n\n129\n59\n82\n98\n\nTable 2. Bibliometric indices, PhD origins by country of affiliation\nCountry\nBelgium\nDenmark\nGreece\nPortugal\n\nBibliomet.\nIndices\np/f\nc/f\nh*\np/f\nc/f\nh*\np/f\nc/f\nh*\np/f\nc/f\nh*\n\nHome\n0.61\n3.64\n0.23\n0.66\n4.59\n0.27\n0.26\n0.58\n0.12\n0.23\n0.33\n0.09\n\nPhD Origins\nEurope\nUK\n0.95\n5.69\n0.38\n0.66\n5.38\n0.29\n0.25\n0.45\n0.96\n1.67\n0.12\n0.15\n0.25\n0.29\n0.93\n1.32\n0.13\n0.17\n\nOverseas\n0.70\n7.82\n0.30\n0.64\n6.17\n0.32\n0.58\n3.44\n0.24\n0.36\n1.84\n0.17\n\nTotal\n0.66\n4.38\n0.26\n0.67\n4.97\n0.29\n0.41\n1.75\n0.17\n0.27\n0.72\n0.12\n\nNote: p/f: papers per faculty per year, c/f: citations per faculty per year, h* is a rational h-index\ndivided by research age.\n\nTable 1 presents the average research age, the percentage distribution of faculty\nmembers according to the country they completed their PhD and the total number\nof faculty members per country. It is worth mentioning the very low percentage of\nGreek faculty members having completed their PhD studies in their own country.\nMoreover, a large part of Greek faculty, almost like their Portuguese colleagues,\nhas completed their studies abroad, mainly in the UK and overseas (mostly in the\n1336\n\nUS and Canada). These rates, regarding overseas studies for the Belgian and\nDanish faculty members are much lower and almost negligible for PhD studies in\nthe UK.\nTable 2 presents the research performance depending on the place of completing\nthe doctorate studies (PhD origin) and the country of employment (affiliation).\nRegression Results\nAt this section we take the further step to identify the factors that drive the\nresearch performance of an economist. There are two important factors that\nrequire further examination. On the one hand we have the place that his/her PhD\nstudies took place as a proxy of the training and the research culture that the\nresearcher did face (factor one: research training). On the other, we want to\nexamine the impact of the working environment as the latter will influence the\nresearch performance based on the research culture of the department, the\ninteraction with his/her colleagues, the peer pressure and research seminars\namong other factors (factor 2: work environment). The adopted specification\nallows us to make at least two comparisons: (i) compare researchers according to\nwhether they did their PhD studies in the US or the country they currently work\nand (ii) compare researchers that did their PhD in the US and currently are\nemployed in the four different countries under consideration. As a result, we\nemploy the following econometric specification:\nResearch Performance = α1PhDUS*Belgium+ α2PhDUS*Denmark+ α3PhDUS*Greece+\nα4PhDUS*Portugal+β1PhDinternal*Belgium+ β2PhDinternal*Denmark+ β3PhDinternal*Greece\n+ β4PhDinternal*Portugal\n\nwhere Research Performance can be (i) Papers per faculty per year (p/f) or (ii)\ncitations per faculty per year (c/f) and PhDUS is a dummy variable that takes the\nvalue of 1 if the research got his/her PhD from the US. Belgium, Denmark,\nGreece and Portugal are dummy variables for the country that the researcher is\ncurrently employed and PhDinternal if the researcher got his/her PhD from the same\ncountry that he/she is employed.\nThe purpose of this study is twofold; compare α1 to α2, α3 or α4 etc and compare\nα1, with β1, α2 with β2 etc. If α1 + α2 &gt; α3 + α4, the working environment in the\nnorth (Belgium and Denmark) is superior to the one in the south (Greece and\nPortugal) given the researcher has a similar training.\nTable 3 presents the regression outcome for the two alternative specifications (one\nwith p/f as dependent variable and one with c/f). In the former, we observe\nthat all coefficients are statistically significant at the 5% level. The ranking that\nemerges for the US PhD holders is: Belgium, Greece, Denmark and Portugal and\nfor the internal PhD holders: Denmark, Belgium, Portugal and Greece. For the\npapers per year per faculty, it emerges that for someone with a PhD from the US,\nthe average performance per year is 0.957 if currently working in Belgium, 0.889\nin Greece, 0.618 in Denmark and 0.452 in Portugal. For the citations per year:\n1337\n\n11.9 if one holds a US PhD and works in Belgium, 5.12 in Greece, 4.18 in\nDenmark and 3.5 in Portugal. With regard to the comparison between north vs\nsouth: = 0.957+0.618 = 1.575 &gt; 1.341 = 0.889+0.452= ˆ3  ˆ 4 . The latter\nimplies that the working environment in the north stimulates research more\ncompared to the south (although this difference is not statistically significant pvalue 0.6). These results are not qualitatively different when we consider\nalternative measures of research performance (results available upon request).\nTable 3. OLS Coefficients\nDependent Variable\nPhD_US*BE_DUMMY\nPhD_US*DK_DUMMY\nPhD_US*GR_DUMMY\nPhD_US*PT_DUMMY\nPhD_BE*BE_DUMMY\nPhD_DK*DK_DUMMY\nPhD_GR*GR_DUMMY\nPhD_PT*PT_DUMMY\n\nPapers per\nYear\n0.957 ***\n3,229\n0.618 **\n2,402\n0.889 ***\n4,093\n0.452 ***\n5,346\n0.814 ***\n9,648\n0.946 ***\n7,205\n0.454 **\n2,463\n0.513 ***\n2,949\n\nCitations per\nYear\n11.921 **\n2,169\n4.184 **\n2,075\n5.123 ***\n3,578\n3.501 **\n2,505\n6.025 ***\n7,540\n6.928 ***\n6,457\n1.280 **\n2,235\n2.537 **\n2,249\n\nNote: t-statistics below the estimate coefficients, ***, ** and * significance at the 1%, 5% and 10 %\nrespectively.\n\nThe analysis so far focused on the average researcher (mean response). However,\nit might be more useful to look at the median researcher as this is more\nrepresentative. For this, we employ quantile regression (QR) that investigates the\nmedian response rather than the average response (see for instance Koenker, &amp;\nBassett, 1978). The results for the same specification are presented in Table 4.\nThe research productivity as it is measured by the alternative specifications is\nsummarized in the following table where each coefficient is divided by the max\ncoefficient. As it is evident from the relative numbers in Table 5 OLS\noverestimate the research productivity of those who are based in Greece and\nPortugal relative to the best (the best is researchers based in Belgium for US PhD\nholders and Denmark for local PhD holders). The QR coefficients are lower\ncompared to the OLS ones. The latter can be explained by the fact that the median\nresearcher is more representative than the average one given the outliers that exist\nin these countries. The most notable difference emerges when one compares the\nproductivity of the median researcher from Denmark with PhD from the same\n1338\n\ncountry and the respective median researcher from Portugal (or Greece). We\nobserve that the latter has only 4% (or 6% in the case of Greece) of the citations\nof the median researcher from Denmark.\nTable 4. Quantile regression coefficients (median)\nDependent Variable\nPhD_US*BE_DUMMY\nPhD_US*DK_DUMMY\nPhD_US*GR_DUMMY\nPhD_US*PT_DUMMY\nPhD_BE*BE_DUMMY\nPhD_DK*DK_DUMMY\nPhD_GR*GR_DUMMY\nPhD_PT*PT_DUMMY\n\nPapers per\nYear\n0.833 ***\n4,501\n0,250\n1,498\n0.474 ***\n4,399\n0.286 ***\n2,643\n0.643 ***\n4,943\n0.750 ***\n6,049\n0.222 **\n2,525\n0.214 ***\n3,805\n\nCitations per\nYear\n4.629 *\n1,678\n0,500\n2,075\n1.857 **\n2,413\n0,813\n1,354\n2.250 ***\n4,108\n3.500 ***\n4,149\n0,222\n0,388\n0,154\n0,490\n\nTable 5. Relative productivity\nRelative Productivity p/f\nUS PhD\nOLS\nQR\nBE\n1,00\n1,00\nDK\n0,65\n0,30\nGR\n0,93\n0,57\nPT\n0,47\n0,34\nLocal PhD\nDK\n1,00\n1,00\nBE\n0,86\n0,86\nGR\n0,48\n0,30\nPT\n0,54\n0,29\n\nRelative Productivity c/f\nUS PhD\nOLS\nQR\nBE\n1,00\n1,00\nDK\n0,35\n0,11\nGR\n0,43\n0,40\nPT\n0,29\n0,18\nLocal PhD\nDK\n1,00\n1,00\nBE\n0,87\n0,64\nGR\n0,19\n0,06\nPT\n0,37\n0,04\n\nConclusions\nThis paper examines the research performance of 404 economists working in 17\nEconomics Department from 4 European countries. Comparisons are made\nbetween two countries from the North of Europe (Belgium and Denmark) with\ntwo countries from the South (Greece and Portugal).The analysis for the research\nperformance of their faculty takes into account the country they did their PhD on\nthe one hand and their current affiliation on the other. We provide a ranking of\n1339\n\ntheir absolute and relative performance based on these two criteria. Furthermore,\nwe identify the factors that drive the research performance by employing\nregression analysis and quantile regression analysis based on both PhD origins\nand current country affiliation. In terms of productivity (impact) the following\norder emerges: 1 (1) PhD from the US and works in Belgium, 2 (2) PhD from\nDenmark and works in Denmark, 3 (4) PhD from the US and works in Greece, 4\n(3) PhD from Belgium and works in Belgium, 5 (5) PhD from the US and works\nin Denmark, 6 (7) PhD from Portugal and works in Portugal, 7 (8) PhD from\nGreece and works in Greece and 8 (6) PhD from the US and works in Portugal.\nReferences\nBauwens, L. (2003, May 31). Economic research in Belgian universities.\nRetrieved from:\nhttp://www.core.ucl.ac.be/econometrics/Bauwens/rankings/rankings.htm\nBen-David, D. (2010). Ranking Israel’s economists, Scientometrics, 82, 351-364.\nÇokgezen, M. (2006). Publication performance of economists and economics\ndepartments in Turkey (1999-2003). Bulletin of Economic Research, 58, 253265.\nCombes, P.P., &amp; Linnemer, L. (2003). Where are the economists who publish?\nPublication concentration and rankings in Europe based on cumulative\npublications. Journal of the European Economic Association, 1, 1250-1308.\nGuimarães, P. (2002). The state of Portuguese research in economics: An analysis\nbased on publications in international journals. Portuguese Economic Journal,\n1, 3-25.\nHenkerson, M., &amp; Waldenström, D. (2011). How should research performance be\nmeasured? A study of Swedish economists. Manchester School, 79, 11391156.\nHirsch, J.E. (2005). An index to quantify an individual’s scientific research\noutput. Proceedings of the National Academy of Sciences of the United States\nof America, 102, 16569-16572.\nKalaitzidakis, P., Mamuneas, T.P., &amp; Stengos, T. (1999). Ranking of economics\ndepartments among Greek-speaking institutions. Economia, 3, 70-75.\nKalaitzidakis, P., Mamuneas, T.P., &amp; Stengos, T. (2003). Rankings in academic\njournals and institutions in economics. Journal of the European Economic\nAssociation, 1, 1346-1366.\nKalaitzidakis, P., Mamuneas, T.P., &amp; Stengos, T. (2011). An updated ranking of\nacademic journals in economics. Canadian Journal of Economics, 44, 15251538.\nKatranidis, S., Panagiotidis, T., &amp; Zontanos, C. (2012). An evaluation of the\nGreek universities’ economics departments. Bulletin of Economic Research.\nAdvance online publication. doi: 10.1111/j.1467-8586.2012.00434.x\nKoenker, R., &amp; Bassett, G. (1978). Regression quantiles. Econometrica, 46, 3350.\n\n1340\n\nLong, J.S. (1978). Productivity and academic position in the scientific career.\nAmerican Sociological Review, 43, 889-908.\nLong, R.G., Bowers, W.P., Barnett, T., &amp; White, M.C. (1998). Research\nproductivity of graduates in management: Effects of academic origin and\nacademic affiliation. Academy of Management Journal, 41, 704-714.\nLubrano, M., Bauwens, L., Kirman, A., &amp; Protopopescu, C. (2003). Ranking\neconomics departments in Europe: A statistical approach. Journal of the\nEuropean Economic Association, 1, 1367-1401.\nRuan, F., &amp; Tol, R.S.J. (2008). Rational (successive) h-indices: An application to\neconomics in the Republic of Ireland. Scientometrics, 75, 395-405.\nTol, R.S.J. (2008). A rational, successive g-index applied to economics\ndepartments in Ireland. Journal of Informetrics, 2, 149-155.\nAppendix\nBelgium: 1) École des Sciences Économiques de Louvain. Université Catholique de\nLouvain, 2) Department of Economics. Faculteit Economie en Bedrijfswetenschappen.\nKatholieke Universiteit Leuven, 3) European Centre for Advanced Research in\nEconomics and Statistics (ECARES) &amp; Département d&#x27;Économie Appliquée (DULBEA).\nSolvay Brussels School of Economics and Management. Université Libre de Bruxelles, 4)\nEconomics Department. HEC École de Gestion. Université de Liège, 5) Department of\nEconomic Science. Faculté des Sciences Économiques, Sociales et de Gestion (FSESG).\nFacultés Universitaires Notre-Dame de la Paix (Namur), 6) Dpts. General, Financial &amp;\nSocial Economics. Faculteit Economie en Bedrijfskunde. Universiteit Gent, 7) Dpt. Of\nEconomics. Faculteit Toegepaste Economische Wetenschappen. Universiteit Antwerpen,\n8) Centre de Recherche en Économie (CEREC). Facultés Universitaires Saint-Louis\nDenmark: 1) Institut for Økonomi, Aarhus Universitet, 2) Københavns Universitet.\nØkonomisk Institut\nGreece: 1) Dpt. of Economics, Athens University of Economics and Business, 2) Dpt. of\nEconomics, University of Crete, 3) Dpt. of Economics, University of Macedonia, 4) Dpt.\nof Economics, University of Piraeus\nPortugal: 1) Universidade Nova de Lisboa. Faculdade de Economia, 2) Instituto Superior\nde Economia e Gestão (ISEG). Dpt. of Economics. Universidade Técnica de Lisboa, 3)\nGrupo de Economia. Faculdade de Economia. Universidade do Porto\n\n1341\n\nOPEN DATA AND OPEN CODE FOR BIG SCIENCE\nOF SCIENCE STUDIES\nRobert P. Light, David E. Polley, and Katy Börner\nlightr@indiana.edu, dapolley@indiana.edu, katy@indiana.edu\nCyberinfrastructure for Network Science Center, School of Library and Information\nScience, Indiana University, Bloomington, IN, USA\n\nAbstract\n\nHistorically, science of science studies were/are performed by single investigators or\nsmall teams. As the size and complexity of data sets and analyses scales up, a “Big\nScience” approach (Price, 1963) is required that exploits the expertise and resources of\ninterdisciplinary teams spanning academic, government, and industry boundaries. Big\nscience of science studies utilize “big data”, i.e., large, complex, diverse, longitudinal,\nand/or distributed datasets that might be owned by different stakeholders. They apply a\nsystems science approach to uncover hidden patterns, bursts of activity, correlations,\nand laws. They make available open data and open code in support of replication of\nresults, iterative refinement of approaches and tools, and education. This paper introduces\na database-tool infrastructure that was designed to support big science of science studies.\nThe open access Scholarly Database (SDB) (http://sdb.cns.iu.edu) provides easy access to\n26 million paper, patent, grant, and clinical trial records. The open source Science of\nScience (Sci2) tool (http://sci2.cns.iu.edu) supports temporal, geospatial, topical, and\nnetwork studies. The scalability of the infrastructure is examined. Results show that\ntemporal analyses scale linearly with the number of records and file size, while the\ngeospatial algorithm showed quadratic growth. The number of edges rather than nodes\ndetermined performance for network based algorithms.\n\nConference Topic\n\nOld and New Data Sources for Scientometric Studies: Coverage, Accuracy and Reliability\n(Topic 2), Visualisation and Science Mapping: Tools, Methods and Applications (Topic\n8) and Open Access and Scientometrics (Topic 10)\n\nIntroduction &amp; Related Work\nMany science of science studies use heterogeneous datasets and advanced data\nmining and visualization algorithms advance our understanding of the structure\nand dynamics of science. The quality of results depends on the quality and\ncoverage of the data used. Data cleaning and preprocessing can easily consume 80\npercent or more of the overall project effort and budget. As the number of data\nrecords grows, different types of tools and expertise are required to handle the\ndata. MS Excel can load a maximum of 1,048,576 rows of data by 16,384\ncolumns per sheet. MS Access file sizes cap at 2 gigabytes, including indices,\nforms, and macros along with the data. Larger datasets need to be stored in a\ndatabase designed with scalability in mind. As the diversity of datasets increases,\n1342\n\nthe structures of different datasets need to be aligned. As data covers more and\nmore years, dealing with format changes becomes necessary. Many studies\nrequire extensive preprocessing and augmentation of the data, such as\nidentification of unique records or record values, geocoding of records in\npreparation for geospatial analysis, or the extraction of networks for network\nstudies. For many researchers, the effort to compile ready-to-analyze-andvisualize data is extremely time consuming and challenging and sometimes\nsimply insurmountable.\nMany datasets relevant for science of science studies, e.g., papers, patents, grants,\nclinical trials, are freely available by different providers. However, they are stored\nin separate silos with diverse interfaces of varying usability that deliver data in\nmany different formats. Research projects seeking to use one or many of these\ndata sources face major data access, integration, and unification challenges.\nIndiana University’s Scholarly Database (SDB), originally launched in 2005,\nmakes over 26 million scholarly records freely available via a unified interface\nand in data formats that are easy to use and well documented. In the last four\nyears, SDB has answered thousands of queries and delivered millions of records\nto users around the globe. The 2012 update to the SDB improves the quality of\ndata offered and integrates new humanities and clinical trial datasets.\nEquipped with high quality, high coverage data in standard data formats, tools\nthat scale in terms of the number of records that can be read and processed are\nneeded to truly make sense of big data (Robertson, Ebert, Eick et al., 2009).\nWhile most tools work well for micro and meso level studies (up to 100,000\nrecords), few scale to macro level big-data studies with millions or even billions\nof records. Another type of scalability relates to the ease of usage and ease of\ninterpretation of big data visualizations. How to best communicate temporal\ntrends or burst of activity over a 100 year time span? How to depict the geospatial\nlocation of millions of records in a scalable fashion? Can the topical evolution of\nmassive document datasets be communicated to a general audience? Most\nvisualizations of million node networks resemble illegible spaghetti balls—do\nadvanced network analysis algorithms scale and help to derive insights?\nFrequently, different types of analysis have to be applied to truly understand a\nnatural, social, or technological system. Examples are temporal studies that\nanswer WHEN questions, geospatial studies that answer WHERE questions and\ndraw heavily on research in cartography, topical studies that use linguistic\nanalysis to answer WHAT questions, and network studies that employ algorithms\nand techniques developed in social sciences, physics, information science and\nother domains to answer WITH WHOM questions. However, most existing\nsystems support only one general type of analysis and visualization and many\nrequire programming skills. For example, four of the top 20 data visualization\ntools listed by .net in September of 2012 support charts and graphs while six\n1343\n\nsupport geospatial maps exclusively (Suda, 2012). Only the D3 (Data-Driven\nDocuments) and Raphaël JavaScript libraries, the Google Chart API, and R\nsupport a larger array of charts, graphs, and maps yet all three require\nprogramming or scripting skills that most users do not possess. Excel might be the\nonly tool on the list that can be used by a large number of non-programmers. A\nlisting of tools commonly used in science of science studies can be found at\nhttp://sci2.wiki.cns.iu.edu/display/SCI2TUTORIAL/8.2+Network+Analysis+and\n+Other+Tools but most support a very limited range of workflows (Cobo, LópezHerrera, Herrera-Viedma et al., 2011).\nThis paper presents a database-tool infrastructure that applies a divide-andconquer approach to support big science of science studies. It combines an online\ndatabase supporting bulk download of data in easy to process formats with a plugand-play tool to read, clean, interlink, mine, and visualize data using easy to\nmanipulate graphical user interfaces.\nThe remaining paper is organized as follows: The next two sections present the\ndatabase and tool functionalities. Subsequently, we test and discuss their\nscalability. We conclude the paper with a discussion of the presented work and an\noutlook to future work.\nThe Scholarly Database (SDB)\nThe Scholarly Database was created in 2005 to provide researchers and\npractitioners easy access to various datasets offered by different publishers and\nagencies (LaRowe, Ambre, Burgoon et al., 2009). The Scholarly Database is\nimplemented using PostgreSQL 8.4, a free and open source relational database\nmanagement system. Since the introduction of version 8.1, PostgreSQL\ndevelopers have been focused on improving the scalable performance of the\nsystem and this software is now employed by many companies to provide largescale data solutions, including Yahoo!, Sony Online and Skype. Today, the\nScholarly Database provides easy access to paper, patent, grant, and clinical trials\nrecords authored by 13.8 million people in 208 countries (some, such as\nYugoslavia, no longer in existence), interlinked by 58 million patent citation\nlinks, and over 2.5 million links connecting grant awards to publications and\npatents. As of November 2012, the SDB features over 26 million records from\nMEDLINE (19,039,860 records spanning from 1865-2010), USPTO patents\n(4,178,196, 1976-2010), NIH awards (2,490,837, 1972-2012), NSF awards\n(453,687, 1952-2010), NEH awards (47,197, 1970-2012) Clinical Trials (119,144,\n1900-2012).\nUnique features of SDB comprise:\n Open Access: The SDB is composed entirely of open data so there are no\ncopyright or proprietary issues for the researcher to contend with in its\nuse. Data is provided to researchers free of charge.\n1344\n\n\n\n\n\n\n\n\n\n\n\nEase of Use: Simple user interfaces provide a one-stop data access\nexperience making it possible for researchers to focus on answering their\nquestions, rather than spending much time on parsing, searching, and\nformatting data.\nFederated Search: By aggregating the data into a single environment,\nSDB offers a federated search environment powered by a Solr core. Users\ncan search one, some, or all of the available datasets over some or all\nyears using the same set of terms and get a combined set of results that\nare ranked by relevance.\nBulk Download: Most databases do not support downloads and those that\ndo only permit access to a limited number of records. SDB supports bulk\ndownload of data records; data linkages—co-author, patent citations,\ngrant-paper, grant-patent; burst analysis files. Users are granted a base\nnumber of downloads by default to prevent abuse of the system, but this\nnumber can be extended by request without charge.\nUnified File Formats: SDB source data comes in different file formats.\nNIH funding data is stored in flat files; clinical trials are offered in XML,\nwhile patents come in a variety of formats, depending on the year. Old\npatents come in a fixed width data format while newer patents are\nprovided in XML. Much time and effort was spent to normalize this data\ninto easy-to-use file formats, e.g., comma-delimited tables for use in\nspreadsheet programs and common graph formats for network analysis\nand visualization.\nWell-Documented: SDB publishes data dictionaries for every dataset\noffered. Information on data provenance, table structure, data types, and\nindividual field comments are available. In addition, the SDB offers a set\nof small sample files, giving researchers an easily usable test-bed for\nworking out their algorithms before committing to analysis of a larger set.\n\nThe SDB Wiki (http://sdb.wiki.cns.iu.edu) provides more information including a\nuser guide, information on each dataset, and release notes.\nThe Science of Science (Sci2) Tool\nThe Science of Science (Sci2) tool is a modular toolset specifically designed for\nthe study of science. It supports the temporal, geospatial, topical, and network\nanalysis and visualization of scholarly datasets at the micro (individual), meso\n(local), and macro (global) levels, see screenshot in Figure 1, general workflow in\nFigure 2 and specific workflows discussed in the scalability tests section.\nThe tool’s OSGi/CIShell core architecture makes it possible for domain scientists\nto contribute new algorithms written in a variety of programming languages using\na plug-and-play macroscope approach (Börner, 2011).\n\n1345\n\nFigure 1: Sci2 tool user interface with proportional symbol map visualization.\n\nFigure 2: General Sci2-based visualization creation workflow (tool-specific tasks in\ngray).\nCategory\nAcquisition\nData Preparation\nPreprocessing\nAnalysis\nModeling\nR\nVisualization\nTotal\n\nAlgorithms\n5\n13\n22\n47\n4\n4\n17\n112\n\nExamples\nGoogle Citation User ID Search Algorithm\nExtract Co-Occurrence Network\nSlice Table by Time, Extract ZIP Code\nK-Nearest Neighbor, Burst Detection\nWatts-Strogatz Small World, TARL\nCreate an R Instance, Send a Table to R\nChoropleth Map, Bipartite Network Graph\n\nFigure 3: Sci2 algorithm summary tables.\n\n1346\n\nAs of November 2012, the Sci2 tool has 171 algorithms, 112 of which are visible\nto the user (see Figure 3) written in Java, C, C++, and Fortran. In addition, a\nnumber of tools (Gnuplot, Guess, and Cytoscape) were implemented as plugins\nand bridges to R and to Gephi were created, allowing the seamless use of different\ntools. The Sci2 user interface and sample map is shown in Figure 1.\nUnique features of Sci2 comprise:\n Open Source: Anybody can examine the source code and advance it.\n Extensive use of well-defined reference systems: To improve readability\nand to support interpretation, Sci2 uses a number of carefully designed\nreference systems, see Figure 4. Each comes with a title, legend, and a\nbrief “How to read this visualization” section that provides further details,\ne.g., on used geospatial projections.\n Interactivity: While visualizations of small datasets can be explored\ninteractively, visualizations of big data are rendered into Postscript files\nthat can be converted to pdf files and examined using pan and zoom as\nwell as filtered, e.g., by searching for specific text in the display.\n Workflows: All user actions are recorded in a log file to ensure proper\ndocumentation and easy replicability of workflows that might comprise\n15-20 analysis and visualization algorithms with a range of parameter\nsettings.\n Online documentation: All Sci2 plugins as well as major workflows are\ndocumented in the Sci2 Wiki (http://sci2.wiki.cns.iu.edu) together with\nrelease notes.\nScalability Tests\nTo demonstrate the scalability of the database and tool, tests were performed\nusing synthetic datasets with pre-defined properties generated in Python and\ndatasets retrieved from the Scholarly Database. All four types of analysis\nsupported by Sci2 were tested: temporal analysis, geospatial analysis, topical\nanalysis, and network analysis. Initially, we identified workflows indicative of\nthese four main types of analysis. From there, we broke down each workflow into\nthe specific steps (algorithms) involved in the workflow, starting with loading the\ndata and ending in visualization. For each algorithm, e.g., data reader, analysis,\nvisualization, we measured (in seconds) the length of time it took for an algorithm\nto finish processing. We considered the start of the algorithm to be the point at\nwhich the user inputs his or her parameters (where applicable) and then executes\nthe algorithm. We considered all algorithms to be finished when the associated\ndata files appeared in the Data Manager and were displayed as complete in the\nScheduler. For each test, we calculated the average for 10 trials. Between trials,\nwe closed down Sci2 in order to minimize any adverse effects of residual\nmemory. Tests were performed on a common system: an Intel(R) Core(TM) Duo\nCPU E8400 3.00GHz processor and 4.0GB of memory running a 64bit version of\n1347\n\nWindows 7 and a 32bit version of Java 7. Memory allotted to Sci2 was extended\nto 1500 MB.\n\nFigure 4: Exemplary reference systems supported by Sci2 including Temporal Bar\nGraph (top, left), Choropleth map (top, right), UCSD science map (bottom, left),\nbimodal network visualization (bottom, right) Full versions available at\nhttp://wiki.cns.iu.edu/display/SCI2TUTORIAL/1+Introduction\n\nFigure 5: Comparison of load times, measured in seconds, across standardized\ndatasets, tabulated (left) and plotted with quadratic regression line (right).\n\n1348\n\nFile Loading\nSynthetic data was used to measure how file loading times vary in terms of\nnumber of records and length of individual record in bytes. Two series of datasets\nwere generated, one with only two rows, a small integer, and a short string and\none with 25 rows, a small integer and 24 short strings, each with increasing\nnumbers of rows. Average loading times over ten trials are given in Figure 5. The\nthree largest datasets did not load but returned a Java heap space error (-TF*). At\nfirst glance, there seems to exist a direct relationship between file size and loading\ntime (R2 = 0.9384), a closer look at the plot of size versus time reveals that a\nquadratic regression line has a noticeably better fit (R2=0.9889). This is likely a\nresult of the tool having to devote resources to file management that would\notherwise be available for completing functions more efficiently.\nNext, SDB data prepared for usage in science of science workflows was read\ncomprising\n NIH data at 3.4GB, NSF data at 489MB, NIH data at 139MB, and NEH\ndata at 12.1MB data prepared for temporal analysis.\n Data from NIH, NSF, MEDLINE, UPSTO, and Clinical Trials at 11.5\nMB and MEDLINE data at 1GB to be used in geospatial analysis.\n MEDLINE data at 514KB for topical analysis.\n NSF data at 11.9MB and UPSTO data at 1.04GB network analysis.\nAverage load times measured across ten trials are shown in Table 1. The three\nlargest datasets, would not load but returned a Java heap space error (-TF*).\nTable 1: Comparison of load times, measured in seconds, across nine different\ndatasets.\nDataset\nNIH (year, title, abstract)\nUSPTO (patent, citations)\nMEDLINE (geospatial)\nNSF (year, title, abstract)\nNIH (title, year)\nNEH (year, title, abstract)\nNSF (co-author network)\nCombined geo-spatial\nMEDLINE journals\n\nSize\n3.4GB\n1.04GB\n1.0GB\n489MB\n139MB\n12.1MB\n11.9MB\n11.5MB\n0.5MB\n\nNumber of\nRecords\n2,490,837\n57,902,504\n9,646,117\n453,740\n2,490,837\n47,197\n341,110\n11,549\n20,775\n\nMean\n-TF*\n-TF*\n-TF*\n64.54\n83.86\n2.05\n4.52\n1.91\n0.44\n\nStandard Minimum Maximum\nDeviation\n\n0.991\n1.32\n0.070\n0.063\n0.056\n0.096\n\n63.2\n82.3\n1.9\n4.4\n1.8\n0.3\n\n65.9\n85.6\n2.1\n4.6\n2.0\n0.6\n\nTemporal Studies (“When”)\nTo test the scalability of temporal analysis within Sci2 we selected the Burst\nDetection algorithm as described by Kleinberg (2003). To test this in a\nstandardized fashion, we generated a randomized set of years from 1980 to 2000,\nassigning each year a distribution of short strings to test the accuracy of the\n1349\n\nalgorithm. We then calculated the average time, minimum time, and the\nmaximum time it took the Burst Detection algorithm to complete across ten trials.\nIn all cases, the algorithm was able to detect a pre-programmed burst of a word\nover a short time frame.\nA look at the table and graph in Figure 6 shows linear growth with number of\nrecords that holds equally true with file size. It is possible that with larger files,\nthis may begin to show the same quadratic tendency as the file loading, but 2.5\nmillion records was the largest file loaded. The data does illustrate that, barring\nresource exhaustion issues, Sci2 runs this algorithm in a linear timescale.\n\nFigure 6: Comparison of Burst Detection run times, measured in seconds, across\nstandardized datasets, tabulated (left) and plotted (right).\n\nWe then conducted a burst analysis of the title fields for NIH, NSF, and NEH\ngrant data. The NSF and NEH datasets contain three columns: title, abstract, and\nyear. The NIH data contains only two columns: title and year. The NIH grant data\nset is the largest at 139MB and 2,490,837 records, followed by the NSF grant data\nat 489MB and 453,740 records, and finally the NEH grant data at 12.1MB with\n47,197 records. In order to obtain accurate results with the Burst Detection\nalgorithm we had to normalize the title text with the Lowercase, Tokenize, Stem,\nand Stopword Text algorithm prior to running the Burst Detection algorithm, a\nstep not necessary with the synthetic data since it was optimized for burst\nanalysis. Due to the number of records in the NIH dataset, the Lowercase,\nTokenize, Stem, and Stopword Text algorithm failed to terminate and as a result\nthe Burst Detection algorithm was not tested with this dataset (-NT*).\nTable 2: Temporal Analysis Algorithm Run Time in seconds.\nBurst Detection\nDataset\nSize\nNSF\n489 MB\nNIH\n139 MB\nNEH\n12.1 MB\n\n1350\n\nRows\n453,740\n2,490,837\n47,197\n\nMean\n13.64\n-NT*\n1.57\n\nSD\n0.648\n\nMin\n12.9\n\nMax\n14.8\n\n0.094\n\n1.4\n\n1.7\n\nGeospatial Studies (“Where”)\nIn order to test Sci2 performance for geomapping, randomized datasets with lists\nof U.S. cities and associated longitude and latitude, were generated. There was\nonly one distinct step (algorithm) involved in this geospatial workflow:\nvisualizing the geolocated data with the Proportional Symbol Map (Biberstine,\n2012), see U.S. geomap in Figure 2. We projected this on a map of the United\nStates, as this data set only included locations within the U.S. Average run times\nare shown in Figure 7. Like with file loading, the Proportional Symbol Map data\nis better fit by a quadratic model (R2 of 0.997 as opposed to 0.9834 for a linear\nfit).\n\nFigure 7: Comparison of Proportional Symbol Map run times, measured in seconds,\nacross standardized datasets.\n\nNext, 11,848 SDB records related to gene therapy funding (NIH, NSF),\npublications (MEDLINE), patents (USPTO), and clinical trials were loaded and\nthe Proportional Symbol Map was used to display the geocoded data. Exactly 299\nrecords had no or incomplete geolocation data and were removed resulting in\n11,549 rows at 11.5MB. The run time, at 4.37 sec is lower than predicted by the\nmodel (6.11 sec), implying that the quadratic model may not perfectly describe\nthe run time, particularly with smaller sets.\nTable 3: Geospatial Analysis Algorithm Run Time in seconds.\nAlgorithm 1: Proportional Symbol Map\nDataset\nSize\nRows Mean\nSD\nPre-located 11.5 MB 11,549\n4.37 0.125\n\nMin\n4.2\n\nMax\n4.6\n\nTopical Studies (“What”)\nThe Sci2 tool supports the generation of science map overlays. Specifically, it\nuses the UCSD map of science and classification system (Börner, Klavans, Patek\net al., 2012), a visual representation of 554 sub-disciplines within 13 disciplines\nof science and their relationships to one another, see lower left map in Figure\n2. This basemap is then used to show the result of mapping a data set&#x27;s journals to\nthe underlying subdiscipline(s) those journals represent (Biberstine, 2011).\n1351\n\nMapped subdisciplines are shown with node sizes relative to the number of\narticles matching journals and color is based on the discipline as defined in the\nbasemap. To create a standardized dataset, random lists of valid journal names\nwere generated. The number of records and run time results are tabulated in\nplotted in Figure 8. Linear and quadratic models fit about equally well, but both\nshow that the intercept is about 1.5 seconds, more than half of the run time for all\nbut the largest sets. This stands to reason as the lookup tables must be loaded and\naccessed regardless of the size of the dataset being used.\n\nFigure 8: Comparison of UCSD Map of Science Generation run times, measured in\nseconds, across standardized datasets.\n\nNext, MEDLINE data was obtained from SDB including all 20,773 journals\nindexed in MEDLINE and the number of articles published in those journals.\nAverage Map of Science via Journals run times are given in Table 4.\nTable 4: Topical Visualization Algorithm Run Time in seconds.\nAlgorithm 1: Map of Science via Journals\nDataset\nSize\nRows Mean\nMEDLINE journals 514 KB 20,773 7,84\n\nSD\n0.096\n\nMin\n7.7\n\nMax\n8.0\n\nNetwork Studies (“With Whom”)\nSci2 supports the extraction of diverse network types. The Extract Directed\nNetwork algorithm (Alencar, 2010) accepts tabular data and constructs a directed\nnetwork from entities in the specified source column to entities in the specified\ntarget column. Run times across ten trials for networks with different numbers of\nnodes and edges are shown in Figure 9. As to be expected, there is a direct linear\nrelationship between the number of edges and the run time.\nNext we retrieved from the SDB all 6,206 USPTO patents that cite patents with\nnumbers 591 and 592 in the patent number field. We ran the Extract Directed\nNetwork algorithm, creating a network pointing from the patent numbers to the\nnumbers those patents reference in the dataset and results are given in Table 5.\nWhile the scalability of Sci2 third-party visualization tools such as GUESS,\n1352\n\nCytoscape, and Gephi do not pertain to Sci2 in a direct way, we were interested to\nunderstand their scalability. Neither Cytoscape nor GUESS were capable of\nrendering the network in a Fruchterman-Reingold layout, while Gephi loaded the\nnetwork in 2.1 seconds and rendered it in about 40 seconds (the actual process in\nGephi is non-terminating, but this was the time to a reasonably defined network).\nGephi is able to achieve higher performance due to its ability to leverage GPUs in\ncomputing intensive tasks.\nRecords\n500\n500\n500\n500\n500\n\n%\nEdges\nSize\nRun SD\nConn\n(MB) (sec) (sec)\n0.017 1.13\n0.05\n2\n5,000\n0.07\n5\n12,500 0.045 1.44\n0.04\n10\n25,000 0.093 1.92\n0.08\n25\n62,500 0.247 3.46\n0.1\n50\n125,000 0.546 5.89\n\nRecords %\nEdges\nSize\nRun\nSD\nConn\n(MB) (sec)\n(sec)\n0.124\n1.86\n0.05\n250\n50\n31,250\n0.546\n5.89\n0.1\n500\n50\n125,000\n2.28\n20.74 0.12\n1,000\n50\n500,000\n45.28 0.44\n1,500\n50\n1,125,000 5.21\n79.41 0.62\n2,000\n50\n2,000,000 9.33\n\nFigure 9: Average Directed Network Extraction run times, measured in seconds\nversus the number of edges in the dataset, across standardized datasets, tabulated\nwith varying connectivity (left) and number of nodes (right) (top) and plotted\n(below).\nTable 5: Network Analysis Algorithm Run Time in seconds.\nAlgorithm 1: Extract Co-Occurrence Network\nDataset\nSize in MB\nNodes\nU.S. Patent References 0.147\n12,672\n\nEdges Mean SD Min Max\n7,940\n7.88 0.103 7.7\n8.1\n\nDiscussion and Future Work\nThis paper introduced and examined the scalability of a database-tool\ninfrastructure for big science of science studies. SDB relational database\nfunctionality was exploited to store, retrieve, and preprocess datasets.\nSubsequently, the data were processed using the Sci2 Tool. The scalability of\n\nthis approach was tested for exemplary analysis workflows using synthetic\n1353\n\nand SDB data. Techniques used were similar to those employed in testing\nthe performance of web-native information visualizations (Johnson &amp;\nJankun-Kelly, 2008). Most run-times scale linearly or exponentially with\nfile size. The number of records impacts run-time more than file size. Files larger\nthan 1.5 million records (synthetic data) and 500MB (SDB) cannot be loaded and\nhence not be analyzed. Run times for rather large datasets are commonly less than\n10 seconds. Only large datasets combined with complex analysis require more\nthan one minute to execute.\n\nA forthcoming paper will compare the runtime of Sci2 with other tools that have\nsimilar functionality, e.g., TEXTrend or VOSViewer for topical analysis and\nvisualization; CiteSpace, Leydesdorff’s Software, DynaNets, SISOB, Cytoscape,\nand Gephi for network analysis and visualization, see below and (Cobo, LópezHerrera, Herrera-Viedma et al., 2011) for links and references.\nRecent work has added web services to the Sci2 Tool and selected workflows can\nnow be run online. Other efforts aim to expand the adoption of OSGi/CIShell in\nsupport of algorithm and tool plugin implementation and sharing across scientific\nboundaries. Tools that are OSGi/CIShell compatible comprise TEXTrend\n(http://textrend.org) led by George Kampis at Eötvös Loránd University,\nBudapest, Hungary supports natural language processing (NLP),\nclassification/mining, and graph algorithms for the analysis of business and\ngovernmental text corpuses with an inherently temporal component and DynaNets\n(http://www.dynanets.org) coordinated by Peter Sloot at the University of\nAmsterdam for the study of evolving networks, or SISOB (http://sisob.lcc.uma.es)\nan observatory for science in society based in social models.\nMuch of the development time for the SDB for the last year has been focused on\nadding data to the system and refactoring code to make it easier to manage and\nupdate. Going forward, we plan to implement an API to further ease access and\nusage of the SDB and we are exploring an RDF conversion to add SDB to the\nWeb of Linked Open Data (Heath &amp; Bizer, 2011). In addition, we are considering\na visual interface to SDB that uses Sci2 Web services to empower users to\ninteractively explore, analyze, and visualize search results.\nDocumentation and teaching of tool functionality and workflows are important for\nresearch and practice. SDB and Sci2 are used in the Information Visualization\nMOOC (http://ivmooc.cns.iu.edu) which debuted in Spring 2013 to over 1,700\nusers, making existing and new workflows available via video tutorials to a much\nbroader audience.\nAcknowledgements\nThe Scholarly Database is funded by the National Science Foundation under\nGrant No. IIS-0238261. SDB and Sci2 are supported by the National Science\n1354\n\nFoundation under Grants No. IIS-0513650, SBE-0738111, a James S. McDonnell\nFoundation grant, and the Cyberinfrastructure for Network Science center at the\nSchool of Library and Information Science at Indiana University. Any opinions,\nfindings, and conclusions or recommendations expressed in this material are those\nof the author(s) and do not necessarily reflect the views of the National Science\nFoundation.\nReferences\nAlencar, A. (2010). CIShell: Extract Directed Network Retrieved January 24,\n2013, from\nhttp://wiki.cns.iu.edu/display/CISHELL/Extract+Directed+Network\nBelter, C. (2012). Visualizing Networks of Scientific Research. Information\nToday, Inc., 36(3). Retrieved from\nhttp://www.infotoday.com/online/may12/Belter-Visualizing-Networks-ofScientific-Research.shtml\nBiberstine, J. R. (2011). CIShell: Proportional Symbol Map Retrieved January\n24, 2013, from\nhttp://wiki.cns.iu.edu/display/CISHELL/Map+of+Science+via+Journals\nBiberstine, J. R. (2012). CIShell: Proportional Symbol Map Retrieved January\n24, 2013, from\nhttp://wiki.cns.iu.edu/display/CISHELL/Proportional+Symbol+Map\nBörner, K. (2011). Plug-and-Play Macroscopes. Communications of the ACM\n54(3), 60-69.\nBörner, K., Klavans, R., Patek, M., Zoss, A., Biberstine, J. R., Light, R., Boyack,\nK. W. (2012). Design and Update of a Classification System: The UCSD Map\nof Science. PLoS ONE, 7(7), e39464. doi: doi:10.1371/journal.pone.0039464\nCobo, M. J., López-Herrera, A. G., Herrera-Viedma, E., &amp; Herrera, F. (2011).\nScience mapping software tools: Review, analysis, and cooperative study\namong tools. Journal of the American Society for Information Science and\nTechnology, 62(7), 1382-1402.\nHeath, T., &amp; Bizer, C. (2011). Linked Data: Evolving the Web Into a Global Data\nSpace. San Rafael, CA: Morgan &amp; Claypool Publishers.\nJohnson, D. W., &amp; Jankun-Kelly, T. J. (2008). A scalability study of web-native\ninformation visualization. Paper presented at the Graphics Interface\nConference 2008, Windsor, Ontario, Canada.\nKleinberg, J. (2003). Bursty and hierarchical structure in streams. Data Mining\nand Knowledge Discovery, 7(4), 373-397.\nKosecki, S., Shoemaker, R., &amp; Baer, C. K. (2001). Scope, characteristics, and use\nof the U.S. Department of Agriculture intramural research. Scientometrics,\n88(3), 707-728.\nLaRowe, G., Ambre, S., Burgoon, J., Ke, W., &amp; Börner, K. (2009). The scholarly\ndatabase and its utility for Scientometrics research. Scientometrics, 79(2), 219234.\n\n1355\n\nPrice, D. J. d. S. (1963). Little Science, Big Science. New York: Columbia\nUniversity Press.\nRobertson, G., Ebert, D., Eick, S., Keim, D., &amp; Joy, K. (2009). Scale and\ncomplexity in visual analytics. Information Visualization, 8(4), 247-253. doi:\n10.1057/ivs.2009.23\nSuda, B. (2012). The top 20 data visualization tools. .net. Retrieved from\nhttp://www.netmagazine.com/features/top-20-data-visualisation-tools\n\n1356\n\nOPTIMIZING RESEARCH IMPACT BY\nALLOCATING FUNDING TO RESEARCHER\nGRANT PORTFOLIOS: SOME EVIDENCE ON A\nPOLICY OPTION (RIP)\nRigby, John 1*, and Julian, Keith1\n*Corresponding Author\nManchester Institute of Innovation Research, Manchester Business School, University of\nManchester, Oxford Road, United Kingdom, M13 9PL\n\nAbstract\n\nThe attempt to maintain and indeed increase the quality of funded research in an era of\nhuge pressure on the budgets of funding bodies has led, perhaps not surprisingly, to urgent\ndiscussion of how best to use the available financial resources. Despite the fact that\nfunding bodies usually require undertakings from grant applicants not to seek “double\nfunding”, concern remains that duplication of funding may still occur. Moreover, the\nargument has been made that funding bodies should take far more account of the whole\nresearcher portfolio when resources are allocated or even when researchers apply for\ngrants. But attempts at top-down management of research grant allocations by funding\nbodies raise difficult questions. Who is in the best position to implement attempts to target\nresearch funding precisely to research topics? Some researchers might well seek duplicate\nfunds for their work but can funding bodies singly or jointly handle the issue of directing\nresearch resources under conditions of uncertainty more ably than researchers? Analysis\nof the papers funded by two major grant awarding bodies that each support research in the\narea of molecular biology suggests that funding by both of these organisations on a per\npaper basis [our proxy for a discrete knowledge generating activity] leads to research with\nhigher impact. We believe that funding from more than one source may in some\ncircumstances lead to positive interaction rather than waste of resources.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6); Modeling the Science System,\nScience Dynamics and Complex System Science (Topic 11)\n\nIntroduction\nAn issue of perennial interest in science policy is the contribution made by\nfunding organisations through their peer review systems and their grants to the\nprogress of scientific enquiry. While the literature indicates a degree of consensus\nthat funding is essential to research, there remains disagreement about the role of\nfunding bodies’ peer review systems as guarantors of or influencers of the novelty\nand impact and the extent of any interaction of funding provision between them\n(Baldi 1998; Rigby 2012). The provision of grant schemes has, over a long\nperiod, diversified to meet a range of needs of different types of researchers at\n1357\n\ndifferent stages of their careers. However, there remains concern that peer review\nsystems, even of the most respected grant awarding bodies, protect the status quo\n(Nicholson and Ioannidis 2012).\nThere have been a number of recent suggestions in the research policy literature\nof ways to change the allocation of resources so as to ensure greater impact\n(Heinze, Shapira et al. 2009; Luukkonen 2012). An earlier paper by Heinze\n(Heinze 2008) has proposed a number of changes to the processes by which\nresearch grants are awarded to bypass the status quo, including the creation of\nnew agencies and the support of research proposals which are ”high risk”.\nHowever, in addition to using the ”uncertainty” criterion or the perceived risk of a\nresearch proposal, assessed by the extent of disagreement between the peer\nreviews of a proposal, Heinze also suggests that grant awarding bodies should\nmake their awards subject to two principles the first of which is uncontroversial,\ni.e. that the grant application is assessed on the basis of the scientific case\nproposed. But his second principle is however quite radical. It proposes that any\nfunding should be awarded in light of the funding already allocated to the\nresearchers whose proposal is under review: ”Hence, funding agencies should\nconsider better aligning their resources with the existing funding of successful\napplicants” (Heinze 2008 page 315).\nThe belief that greater ”top-down coordination” of research funding will prevent\nduplication and achieve greater scientific impact is beginning to receive more\nweight, partly in light of the discovery of instances of apparent duplication of\nresearch funding (”double funding”), reported in 2012 (Reich 2012) and a more\nrecent Nature editorial (Reich and Myhrvold 2013) based on the research of\nGarner, et al (Garner, McIver et al. 2013). An interesting irony here is that some\nyears ago, Lewison and Dawson (1998) proposed that the count of funding\nacknowledgements generally predicted impact, a desirable outcome, arguing that\nresearch (papers) resulting from such funding would have had more peer review.\nHowever, the suggestion is now emerging that funding from multiple agencies\n(which would lead to multiple funding acknowledgements on papers) might be a\nsign of duplication of resources, a state of affairs which should be avoided.\nThe authors of these recent studies on duplication are however careful to\nacknowledge that their claims of duplication have been limited by the data they\nhave been able to use, and they believe that only when full grant applications,\ngrant summaries and resulting publications are available will it be possible to\nassess the true extent of duplication of funding for research activities.\nNevertheless, this recent evidence suggests there is now a need to examine closely\nthe rules that exist to ensure fair allocation of research funds to research work,\nincluding those procedures that exist to re-allocate research money in the event of\nchanges to the work being carried out.\n1358\n\nHowever, the attempt to optimize scientific outcomes by creating further rules and\nprocesses than already exist to prevent double funding (”double dipping”) and to\nimpose greater oversight of the research priority setting of scientists by\nadministrators is not in our view likely to be easy to implement and may not be\nrealistic policy. As this research in progress paper argues, bibliometric evidence\ndoes show that the support of certain funding bodies may increase the level of\nimpact achieved rather than entailing duplication and waste of resources. Using\nthe data on papers funded by two organisations that operate within the same areas\nof science (molecular biology) and which attempt to achieve similar ground\nbreaking research within this research field, we show that papers with funding\nacknowledgements from both the European Molecular Biology Organisation and\nthe Human Frontier Science Program have greater impact than papers with just\none or other of these organisation’s funding acknowledgements.\nMethods\nMeta-data on papers from the Web of Knowledge published in the period 20082012 which had funding acknowledgements from either the European Molecular\nBiology Organisation or the Human Frontier Science Programme, or from both of\nthese organisations, were downloaded and analysed. Papers were chosen from\n2008 as this is the first year in which there is full coverage of funding\nacknowledgement data within the Thomson Reuters Web of Knowledge citation\nindex.\nPapers were uploaded to VantagePoint and then cleaned to disambiguate funding\nacknowledgement and author address data as this is not standardized and many\ndifferent occurrences of funding body and addresses names are present. A\nthreefold categorization of papers was created: EMBO funding acknowledged,\nHFSPO funding acknowleged, funded by both EMBO and HFSP. In all 21903\nfunding acknowledgements were recorded across the whole data set with 5029\nacknowledgements (23%) from these two organisations. As EMBO operates a\nsignificant number of research laboratories, papers that had been written by\nauthors whose addresses indicated an EMBO laboratory were considered as\nEMBO papers for the purpose of the analysis. Articles and Review papers were\ntreated separately as their funding is a priori different in origin.\nThe papers were compared at the level of the paper, as few papers had more than\none grant number applying to them. Papers were then compared in terms of their\ncitedness, the count of authors, the count of author affiliations, and the count of\nfunding acknowledgements. Articles were analysed separately from reviews.\nBook chapters and other forms of publication of which there were small numbers\nin the data set were not included in the analysis.\n\n1359\n\nResults\nThe Kruskal-Wallis ranks test was used to determine differences between the\nthree groups of papers. The Kruskal-Wallis is a non-parametric test of ranks,\nusing an overall difference in ranks. It is a suitable test where samples are of\ndifferent sizes and distributions of variables cannot be assumed to be normal. Pvalues less than 0.05 imply a statistically significant difference amongst the\nmedians at the 95.0% confidence level. The results of the four sets of tests are\ngiven below. The table shown below displays the results of the Kruskal-Wallis\ntest (ranks, test statistic and p-value) for each of the four comparisons.\nTable 1. Kruskal-Wallis Tests of Group Differences: Citations Per Paper; Authors\nPer Paper; Author Affiliations Per Paper; Funding Acknowledgements Per Paper\nKruskal-Wallis Test for Total Citations\nGroup\nEMBO and HFSP\nEMBO\nHFSP\nTest Statistic\nP Value\nKruskal-Wallis Test for Total Authors\nGroup\nEMBO and HFSP\nEMBO\nHFSP\nTest Statistic\nP Value\nKruskal-Wallis Test for Total Author\nAffiliations (Count of Institutions)\nGroup\nEMBO and HFSP\nEMBO\nHFSP\nTest Statistic\nP Value\nKruskal-Wallis Test for Count of\nFunding Acknowledgements\nGroup\nEMBO and HFSP\nEMBO\nHFSP\nTest Statistic\nP Value\n1360\n\nArticles\nSample\nSize\n245\n1550\n2412\n30.62\n2.23E-07\nArticles\nSample\nSize\n245\n1550\n2412\n134.844\n0.000\nArticles\n\nAverage\nRank\n2463.31\n2148.11\n2039.16\n\nAverage\nRank\n2410.73\n2345.29\n1917.78\n\nReview Papers\nSample\nAverage\nSize\nRank\n30\n268.63\n218\n271.81\n295\n272.4\n0.016\n0.991\nReview Papers\nSample\nAverage\nSize\nRank\n30\n270.567\n218\n290.782\n295\n258.266\n5.91264\n0.05201\nReview Papers\n\nSample\nSize\n245\n1550\n2412\n50.2912\n1.20E-11\nArticles\n\nAverage\nRank\n2292.96\n2247.61\n1992.52\n\nSample\nAverage\nSize\nRank\n30\n294.483\n218\n277.048\n295\n265.983\n1.45241\n0.483741\nReview Papers\n\nSample\nSize\n245\n1550\n2412\n192.342\n0\n\nAverage\nRank\n2908.5\n2261.37\n1921.15\n\nSample\nSize\n30\n218\n295\n29.7076\n3.54E-07\n\nAverage\nRank\n408.783\n281.557\n251.027\n\nArticles (but not review papers) that acknowledged funding from both sources\nwere statistically more likely to have more citations than papers funded\nseparately, more likely to have more institutions involved and more likely to have\nmore authors involved in their production. The greater likelihood of jointly\nfunded papers (EMBO and HFSP) having more funding acknowledgements might\nbe related to their having a priori one more funding acknowledgement than a\npaper funded by only one of the organisations (i.e. either EMBO or HFSP) but the\neffect of this on distributions is work in progress.\nDiscussion\nThe results of the analysis conducted here indicate that where researchers receive\nfunding from EMBO and from HFSP at the same time, rather than separately, (i.e.\nfrom either one or the other of the two organisations), the resulting papers achieve\na higher citation count. This may be attributable in part to the presence of more\norganisations and authors in jointly funded papers. The analysis does not provide\nhard evidence of a net benefit of ”simultaneous funding”. To achieve this, there\nwould need to be control of type of research undertaken to reduce the risk that the\ndifferent categories of funding have chosen different forms of research projects\nwith potentially different levels of impact.\nThis research in progress paper has sought to encourage discussion on the issue of\nwhether research funding bodies might take account of the funding that\nresearchers are already receiving or about to receive in order to reduce duplication\nof funding and to enhance research impact. Steps to take control of, manage, or\ntake account of researcher funding portfolios may appear desirable in an era of\nincreasing austerity as this might promise to reduce redundancy of funding,\nparticularly where certain funding bodies are known to support research in the\nsame or very similar areas. However, the attempt to allocate funding by grant\nawarding bodies to remove or reduce the risk of redunancy and to optimize\nresearch output raises serious questions about effectiveness of outcome, as well as\nabout the confidentiality of the work of researchers.\nPolicy researchers should investigate this area in more detail as the evdience\nsuggests that simultaneous funding may be beneficial, and that is leads to the\nprovision of a level of resources for researchers that gives achieve greater impact\non any given research problem. Funding organisations and researchers should\nbetween them decide on the basis of further examination of this question where\nresponsibility should lie for the allocation of resources to research problems. It is\nin our view premature to assume that funding bodies should control the process of\nresource allocation as it researchers which are more likely to know best how to\nmatch funding to the specific challenges of the work they are undertaking.\n\n1361\n\nReferences\nBaldi, S. (1998). &quot;Normative versus social constructivist processes in the\nallocation of citations: A network-analytic model.&quot; American Sociological\nReview 63(6): 829-846.\nGarner, H. R., L. J. McIver, et al. (2013). &quot;Research funding: Same work, twice\nthe money?&quot; Nature 493(7434): 599-601.\nHeinze, T. (2008). &quot;How to sponsor ground-breaking research: A comparison of\nfunding schemes.&quot; Science and Public Policy 35(5): 302-318.\nHeinze, T., P. Shapira, et al. (2009). &quot;Organizational and institutional influences\non creativity in scientific research.&quot; Research Policy 38(4): 610-623.\nLewison, G. and G. Dawson (1998). &quot;The effect of funding on the outputs of\nbiomedical research.&quot; Scientometrics 41(1-2): 17-27.\nLuukkonen, T. (2012). &quot;Conservatism and risk-taking in peer review: Emerging\nERC practices.&quot; Research Evaluation 21(1): 48-60.\nNicholson, J. M. and J. P. A. Ioannidis (2012). &quot;Research grants: Conform and be\nfunded.&quot; Nature 492(7427): 34-36.\nReich, E., S. and C. Myhrvold, L. (2013). &quot;Funding agencies urged to check for\nduplicate grants: Nature probe reveals lack of oversight of researchers who\nwin two grants for similar projects.&quot; Nature 493\nReich, E. S. (2012). &quot;Duplicate-grant case puts funders under pressure.&quot; Nature\n482(7384): 146-146.\nRigby, J. (2012). &quot;Looking for the impact of peer review: does count of funding\nacknowledgements really predict research impact?&quot; Scientometrics: 1-17.\n\n1362\n\nPATENTS IN NANOTECHNOLOGY: AN\nANALYSIS USING MACRO-INDICATORS AND\nFORECASTING CURVES\nDouglas H. Milanez1, Leandro I. L. Faria2, Roniberto M. do Amaral3 and José A.\nR. Gregolin4\n1\n\ndouglas@nit.ufscar.br\nFederal University of Sao Carlos, Center for Information Technology in Materials, PhD\nstudent from Graduate Program in Materials Science and Engineering , Washington Luis\nHighway, km 235, São Carlos – SP (Brazil)\n2\n\nleandro@nit.ufscar.br\nFederal University of Sao Carlos, Center for Information Technology in Materials,\nprofessor from the Dept of Information Science, Washington Luis Highway, km 235, São\nCarlos – SP (Brazil)\n3\n\nroniberto@nit.ufscar.br\nFederal University of Sao Carlos, Center for Information Technology in Materials,\nprofessor from the Dept of Information Science, Washington Luis Highway, km 235, São\nCarlos – SP (Brazil)\n4\n\ngregolin@nit.ufscar.br\nFederal University of Sao Carlos, Center for Information Technology in Materials,\nprofessor from the Dept of Materials Science, Washington Luis Highway, km 235, São\nCarlos – SP (Brazil)\n\nAbstract\n\nThe aim of this study is to analyze the technological output in nanotechnology using\npatent indicators, which were developed based on a set of 189,481 records recovered from\nthe Derwent Innovation Index database. Future trends of worldwide nanopatenting were\nevaluated using logistic growth curves and annual growth rates from 1995 to 2010, while\nthe patenting activity from the main countries and technological domain and subdomain\nwere assessed from the perspective of worldwide, USPTO, TRIAD and TETRAD patent\ndocuments from 2000 to 2010. Outcomes of nanotechnology patent activity have\ngenerated interesting discussions as they suggest that technological development has\nreached a maturation stage apparently. Although China ́s share of patents is small in some\ncases, it was the only country to constantly increase the number of patents from a\nworldwide perspective. In contrast, the USA and the EU were the most active in the\nUSPTO, TRIAD and TETRAD cases, followed by Japan and Korea. The technological\nsubdomains of main interest from countries/region changed according to the perspective\nadopted, although there was a clear bias towards Semiconductors, Surface Treatments,\nElectrical Components, Macromolecular Chemistry, Materials-Metallurgy, PharmacyCosmetics and Analysis-Measurement-Control subdomains. Finally, monitoring\n\n1363\n\nnanotechnology advances should be constantly reviewed in order to confirm the evidence\nobserved.\n\nConference Topic\n\nTechnology and Innovation Including Patent Analysis (Topic 5)\n\nIntroduction\nRecently, there has been considerable interest in evaluating nanotechnology\nresearch developments due to its high potential to promote significant innovation\nin products, processes, materials and devices and to benefit the society (Milanez,\n2011; Salerno, Landoni, &amp; Verganti, 2008). This has encouraged worldwide\nscientific efforts and governmental programs to fund research in nanotechnology,\nespecially from the United States, Japan, China, Korea and the European\nCommunity. For instance, global public spending has increased from\napproximately US$ 4.5 billion to US$ 10 billion between 2005 and 2010\n(Observatorynano, 2012; Roco, 2005). Only the US National Nanotechnology\nInitiative 2012 budget was estimated at US$ 1.7 billion (United States, 2012). The\ncurrent advances in nanotechnology have been quite striking and evident from\npublications and patent document data (Dang, Zhang, Fan, Chen, &amp; Roco, 2010;\nKostoff, Koytcheff, &amp; Lau, 2007; Porter, Youtie, Shapira, &amp; Schoeneck, 2008)\nTo follow advances in nanotechnology, it is preferable to use quantitative\nmethodologies as they are objective and are able to compare results. However,\nmonitoring and evaluating nanotechnology developments using bibliometric\napproaches is a challenge due to its initial stage of development and\ninterdisciplinarity, which can make retrieving information and establishing\nknowledge boundaries difficult. (Milanez, 2011; Porter et al., 2008; Salerno et al.,\n2008). For instance, nano-related patent classification codes emerged from the\nUnited States Patent and Trademark Office (USPTO), the European Patent Office\n(EPO) and the World Intellectual Property Organization (WIPO) as an effort to\nattempt to precisely describe and monitor this area (Scheu et al., 2006), whereas\nthey alone are not sufficient to retrieve all information (Porter et al., 2008).\nFurthermore, there is still a lack of specific regulatory frameworks describing\nsafety procedures accurately, environmental and health effects and risks of\nmanipulating nanomaterials (Salerno et al., 2008), which make future eventchanges uncertain. Therefore, new research to monitor its development can\nminimize the gaps in knowledge and future uncertainties.\nBibliometric analysis of patent documents is an approach to evaluate trends in\ntechnological developments, as well as country and competitors interests. An\nimportant indicator is the annual number of patents in nanotechnology, but few\nresearchers have forecasted the future developments of this area, for example,\nusing the logistic growth curve method. According to Martino (1993), the logistic\ncurve is an extrapolation method that assumes the past of a time series contains all\n1364\n\nthe information needed to forecast the future growth of a time series up to a limit\nestablished. Cheng and Chen (2008) applied this method to USPTO patent data of\nnanosized ceramic powders from 1970 to 2005 and they observed that ceramic\nnanomaterials were in the initial growth periods of a technological life cycle.\nMilanez, Amaral, Faria &amp; Gregolin (2013) also forecasted nanocellulose scientific\nand technological activities using the logistic growth curve and observed\nemerging stage of nanocellulose. Even though Alencar, Porter and Antunes\n(2007) observed this logistic growth trend in nanotechnology data, they did not\npredict its future development and life cycle stage. Besides the development\nstage, the logistic growth curve may also support planning and future investment\n(Martino, 1993).\nAnother issue addressed in papers is to verify which countries or regions were\nleading or competing in the “nanorace”. Some studies only considered the\nUSPTO or the EPO patents as a reference due to their economical importance\n(Chen, Roco, Li, &amp; Lin, 2008; Cheng &amp; Chen, 2008; Z. Huang et al., 2003; Z.\nHuang, Chen, Chen, &amp; Roco, 2004; Hullmann &amp; Meyer, 2003; Igami, 2008), but\nlimiting these repositories make it difficult to comparatively analyse worldwide\nbecause of emerging developing economies, such as China, Russia, Brazil and\nIndia (Glänzel, Debackere, &amp; Meyer, 2007). Other studies considered data from\nworldwide databases, such as Derwent Innovations Index (Alencar et al., 2007;\nWang &amp; Guan, 2012) and Espacenet (Dang et al., 2010). Dang et al. (2010)\nincluded an assessment of the patent application published at the main patent\noffices, yet their analysis did not consider the economic value of patent filing,\nsuch as those from the tridiac patent families (also known as TRIAD). According\nto the OECD Patent Statistic Manual (2009), the TRIAD is a set of patent\napplications filed at the Japanese Patent Office (JPO), EPO and USPTO (in this\nlast case, patents filed after 2001 as the USPTO did not publish patent files before\n2000). TRIAD statistical analysis has an advantage to improve international\ncomparability and include patent families that are typically of high value as it is\nassumed that the additional cost of protection in different countries is worthwhile\n(OECD, 2009). Recently, Wang and Guan (2012) evaluated the worldwide trend\nof patenting in nanotechnology using a dataset from Derwent Innovations Index.\nThey included the TRIAD patents and observed a strong presence of the United\nStates, the European Union and Japan. By contrast, due to the fact that China is\nchallenging the leading science and technology countries and the Chinese market\nhas become one of the most important in the world, analysis should include the\nTETRAD patent families (Glänzel et al., 2007)\nEvaluating the technological sector performance of nanotechnologies and their\ninvolvement with countries is another task of a wide range of studies. It is\ncommon to measure this key issue by patent classification information, such as\nUS Patent Classification (Z. Huang et al., 2003, 2004) and International Patent\nClassification (IPC) (Alencar et al., 2007; Dang et al., 2010). However, the\n1365\n\ngeneral purpose of patent classifications is to describe the content of the patent\ndocument in detail, including issues about the invention, functionality and\napplication. Consequently, they are too disaggregated to analyse technological\ntendencies because different classifications may be related to the same\ntechnological domain. Moreover, a single patent document may contain many\nclassification codes and belong to one or more sector. In order to overcome this\ngap, patent documents can be aggregated according to their classification code\nand improve the analysis. Wang et al. (2012) classified the patent documents in\nfive industrial areas and 35 fields of applications. They also observed a\nconcentration of nanopatenting, mainly in the Chemical industrial area, followed\nby Instruments and Electrical Engineering areas. Their outcome also showed\ncountries’ fields of application highlighting China in Materials and Metallurgy,\nthe United States in Pharmaceuticals and Semiconductors, Japan in\nMacromolecular Chemistry and Optics, Korea in Semiconductors and the\nEuropean Union in Pharmaceuticals. Nevertheless, they have used only the first\nIPC in the aggregation process, thus relevant information was lost and probably\ncould have benefitted from a specific industrial area or field of application.\nThe aim of this paper is to update and pursue studies analyzing technological\ndevelopment in nanotechnology using bibliometric indicators based on patent\ndocuments. Development in worldwide patenting and future trends was evaluated\nusing logistic growth curves and the annual growth rate, while the behavior of the\nmain countries/region and the technological domain and subdomain were assessed\nby the share of patents. Analyses were also carried out in four aspects of\npatenting: considering the worldwide and patent documents from the USPTO,\nTRIAD and TETRAD.\nMethod and procedures adopted\nProcedures for collecting and analyzing the patent data\nTechnological indicators were developed using the patent data indexed in the\nDerwent Innovations Index (DII) (Thomson – ISI, US). DII has the advantage of\ncovering patent bibliographic information from worldwide main repositories,\nallowing for searches in multiple bibliographic fields, such as the title, abstract,\ninventors, assignees and International Patent Classification (IPC). It also makes\nuse of complex Boolean search expressions. Furthermore, DII records are\naggregated according to their family patent124, which provides an analysis of\ndifferent contexts without duplicating the document.\n\nEndnotes:\n124\nA patent family is a core of published patent documents referring to the same invention and\napplied in different countries by way of the priority or priorities of a particular patent document. A\npatent document can be referred to as an applied or a granted patent.\n1366\n\nNanotechnology patent documents were retrieved by using the modularized\nBoolean search strategy suggested by Porter et al. (2008). Defining a search\nexpression for nanotechnology is a challenge due to its interdisciplinary nature.\nHowever, Huang, Notten and Rasters (2011) comparatively reviewed various\nsearch strategies and they concluded that most of the final rankings are similar\ndue to the fact that these search strategies share a group of key words and terms,\nalthough the quantity of documents retrieved are different. Moreover, the modular\nsearch strategy chosen has some advantages. First, it combines a number of nanorelated terms from earlier studies and others accurately selected by experts.\nSecondly, it can be used in multiple databases retrieving a large-scale core of\nrelevant data (Porter et al., 2008; Wang &amp; Guan, 2012). The search was carried\nout on 23rdJanuary, 2013 and 189,481 records were retrieved considering the time\nspan until 2012. All data were collected and imported to the bibliometric software\nVantagePoint (version 7.0, Search Technology Inc, US). A set of bibliometric\nindicators were developed:\n- Number of patents per year and annual growth rate from 1995 to 2010;\n- Accumulated number of patent documents per year from 1995 to 2010;\n- Forecasting growth curves based on the accumulated patent documents;\n125\n- Share of patent documents by the main patenting country/region from\n2000 to 2010;\n- Share of patent documents by technological domains and subdomains\nfrom 2000 to 2010;\n- Share of patents by the main patenting countries/region according to their\nmost relevant technological subdomain from 2000 to 2010.\nThe period of analyses was limited up to 2010 because of the delay between an\napplication and publication of a patent document, regularly 18 months in most\ncountries (MOGEE, 1997). To evaluate the country performance and determine\nthe year when a patent document was first published, the earliest priority of DII\nrecords was selected in view of the fact that they do not provide the nationality of\ninventors or applicants. It was assumed that the country and the year from the\nearliest priority refer to the place and the period the invention was developed. In\norder to analyze the main technological subdomains related to nanotechnology\npatenting, the data were processed according to the subdomains ́ classification\nsuggested by the Observatorie dês Sciences et dês Techniques (OST, 2010). In the\nprocess, patent documents were grouped into seven technological domain and\nthirty technological subdomains according to their IPC code.\n\n125\n\nThe European Union patent documents included patents from Austria, Belgium, Bulgaria, Czech\nRepublic, Cyprus, Denmark, Estonia, France, Finland, Greece, Germany, Hungary, Ireland, Italy,\nLatvia, Lithuania, Luxemburg, Malta, Netherlands, Poland, Portugal, Romania, Slovenia, Slovakia,\nSpain, Sweden, United Kingdom, and European Patent Office.\n1367\n\nFour different cases were considered in order to assess nanotechnology patenting:\npatent documents from worldwide repositories, and from USPTO126, TRIAD127,\nand TETRAD128.\nAnnual growth rate and share of patent calculations\nThe annual growth rate (Gi) was calculated using equation 1, where Ni is the\nnumber of patent documents in year “i” and Ni-1 is the number of patent\ndocuments in year “i-1”.\n(\n)\n(1)\nThe percentage share (S) of patent documents was calculated using Equation 2,\nwhere Si is the number of patent documents from a country/region or a\ntechnological subdomain (i) and St is the total of patent documents in the context\nof the analysis (t).\n(2)\nLogistic Growth Curves Calculation\nThe increase in the number of accumulated patents in nanotechnology was\npredicted using the logistic growth curve which is calculated according to\nEquation 3. L is the upper limit of the growth of variable y, t is time, a and b are\ncoefficients obtained by fitting the growth curve to the known data, and e is the\nbase of natural logarithms (Martino, 1993).\n(3)\nThree upper limits (L) were tested properly to state the future development of\nnanotechnology patent documents. These upper limits were chosen considering\ntheir best fit to the real annual cumulative data from 1995 to 2010. Furthermore,\ninflection points of the three curves were obtained in order to delimit the\nemerging and maturity stages (Martino, 1993; Cheng &amp; Chen, 2008).\nResults and discussion\nGeneral and future prospects on nanopatenting\nWorldwide patenting boomed from 1995 to 2010, as can be seen in Figure 1. In\nthis period, the number of patents grew 1.447%, from 1.451 documents in 1995 to\n126\n\nRecords with at least one US patent number were considered as files at USPTO.\nFor TRIAD patents, records with at least one US patent number, one EPO patent number and one\nJPO patent number were considered.\n128\nFor TETRAD patents, records with at least one US patent number, one EPO patent number, one\nJPO patent number, and one SIPO (State Intellectual Property Office of the People&#x27;s Republic of\nChina) patent number were considered.\n127\n\n1368\n\n22.442 in 2010. The annual growth rates followed an interesting trend, if the\nvalue from 2001 is ignored: the growth rate rose rapidly until 1998 and then\ngradually declined until 2010. Regarding the 2001 growth rate value, although\nthis is the year after launching the US nanotechnology program (the National\nNanotechnology Initiative), which is one of the most important worldwide\nprograms encouraging other countries’ programs, a detailed analysis of the data\nshowed that the peak is a consequence of non-regular behavior from Chinese\npatenting (see Figure 3). Some facts may have influenced this result from China,\nsuch as the impulse of Chinese research in nanotechnology from two research\nprograms in 1999 (the National Key Basic Research Program and the Applied\nResearch on Nanomaterials Program) (Galembeck &amp; Rippel, 2006; Milanez,\n2011). Another fact was the restructuring of their intellectual property system to\nbecome a member of the Agreement on Trade Related Aspects of Intellectual\nProperty Rights (TRIPS), one of the essential requirements for joining the World\nTrade Organization in 2000. The same sudden increase in the number of patents\nfrom China in 2001 was discussed by Hu and Jefferson (2009).\nAnnual Growth Rate\n\nAnnual Number of Patents\n\n60,0\n\n22000\n\n55,0\n\n20000\n\n50,0\n\n18000\n\n45,0\n\n16000\n\n40,0\n\n14000\n\n35,0\n\n12000\n\n30,0\n\n10000\n\n25,0\n\n8000\n\n20,0\n\n6000\n\n15,0\n\n4000\n\n10,0\n\n2000\n\n5,0\n\n0\n\nRate (%)\n\nNumber of Patent Documents\n\n24000\n\n0,0\n1995199619971998199920002001200220032004200520062007200820092010\n\nFigure 1. Annual number and annual growth rate for patent documents in\nnanotechnology from 1995 to 2010.\n\nInterestingly, the growth rates from 2009 and 2010 suggest that the annual\nnumber of patents will grow slowly in coming years. The accumulated number of\npatent documents also shows a gradual decrease towards logistic growth pattern\nin coming years, as can be seen in Figure 2. The growth curves indicated the\ninflection point, which occurred between 2008 and 2009, indicating the beginning\nof deceleration in nanotechnology patenting. According to Martino (1993) and\nCheng et al (2008), this slowing down might be interpreted as the beginning of\nmaturation from the technological development and new growth cycles may occur\nin the future due to scientific advances. Although the patenting activity might\n1369\n\nhave experienced effects from the recent financial crisis and ongoing economic\nuncertainty, these outcomes generated a rather interesting hypothesis and\nconsiderations to be discussed. First of all, the inflection points were quite near to\nthe present moment, thus no additional data was readily available to confirm this\ntrend. Secondly, as nanotechnology is considered as an emerging interdisciplinary\nfield (Milanez, 2011; Salerno et al, 2008; Porter et al, 2008), new nano-related\nterms might have appeared overtime. Therefore the data used to develop these\nindicators could be incomplete. In this case, Arora, Porter, Youtie &amp; Shapira\n(2012) have updated the nanotechnology modular search strategy used in this\nstudy (from Porter et al., 2008) with 33 new terms, which might change the\noverall picture in Figures 1 and 2. Moreover, due to the fact that nanotechnology\ncan be found in various subfields and each one has their own way of working, the\nforecast of its current state could have been made applying the growth curve\nmodel to the subfields separately and then the combinations of these results could\ndepict an overall picture. Other papers (Cheng &amp; Chen, 2008; Milanez et al.,\n2013) applied the growth curve model to nanocellulose and nanosized ceramics\nand their findings suggested that these nanomaterials were in their emerging\nperiod (before the inflection point). This result corroborates with the hypothetical\nneed to forecast the nanotechnology subfields and nanotechnology as a whole.\nLogistic Growth Curves\n\nCumulative Number of Patents\n\n400000\n\n250000\n\n300000\n\n350000\n\nData\n\n350000\n300000\n250000\n200000\n150000\n100000\n50000\n0\n1995\n\n2000\n\n2005\n\n2010\n\n2015\n\n2020\n\n2025\n\nFigure 2. Accumulated number of patent documents from 1995 to 2010 and\nforecasting growth curves for nanotechnology.\n\nNanotechnology is a multidisciplinary field and seeing it as only one area in the\nfuture is complicated. What could be done is to foresee other subfields and\ncombine them to have a general overview of the development stage of\nnanotechnology. Finally, another issue concerns the close link between scientific\nadvances and technological development in nanotechnology. Scientific\n\n1370\n\nknowledge strongly emerged from 2000 to 2011129, but our outcomes (from\nFigure 1 and 2) suggest they do not lead to technological development, probably\ndue to the challenges regarding industrial scale production and risks of\nnanomaterials to human health and the environment (Salerno et al, 2008).\nThe dynamic of patenting for the main countries/region\nThe United States (US), Japan, Korea, the European Union (EU) and China\nshared 93.5% of the worldwide patents in nanotechnology from 2000 to 2010, as\ncan be seen from Table 2. This result corroborates with others from the literature\n(Dang et al., 2010; Glänzel et al., 2007; Milanez, 2011; Wang et al., 2012),\nalthough some differences may occur due to the search strategy used. China has\nalready accumulated more patent documents than the USA, sharing 27.0% of the\nwhole documents retrieved. According to worldwide trends in Figure 3, China\nwas the only country that showed a steady growth in the period analyzed,\nprobably due to its economical situation. On the other hand, although the USA,\nthe EU, Japan and Korea have large quantities of patent documents, they have\ndeclined in recent years in the period analyzed.\nThe most striking result to emerge from Table 2 is the small number of patent\ndocuments that China had in the USPTO, the TRIAD and the TETRAD, which\nraises an issue as to whether their nanotechnologies are potential economically or\nnot. In spite of the logical fact that they are leaders in patenting in USPTO, the\nUSA was also in first place at TRIAD and TETRAD (45.0% and 44.3%,\nrespectively) followed by the EU (31.3% and 30.9%), Japan (15.1% and 15.4%)\nand Korea (4.78% and 5.20%). This result shows evidence of the economic value\nand their interest to protect their developments in other markets.\nTable 2. Share of nanotechnology patent documents from 2000 to 2010 among the\nmain countries/region at the worldwide, USPTO, TRIAD and TETRAD cases.\nCountry/\nRegion\nUS\nEU\nJapan\nKorea\nChina\n\nWorldwide\nShare (%)\n26.8\n11.3\n17.0\n11.4\n27.0\n\nUSPTO\nShare (%)\n61.9\n14.3\n10.4\n6.82\n2.13\n\nTRIAD\nShare (%)\n45.0\n31.3\n15.1\n4.78\n0.76\n\nTETRAD\nShare (%)\n44.3\n30.9\n15.4\n5.20\n1.19\n\nFigure 3 also provides the annual number of patent documents of the USPTO,\nTRIAD and TETRAD and states the patenting activity of the main\n129\n\nWe performed a quick analysis from scientific publications indexed in the Science Citation Index\nExpanded and Social Science Citation Index (Web of Science) from 2000 to 2010 using the modular\nsearch strategy for nanotechnology (Porter et al., 2008). On average, scientific publications went up\nby 13.09% in the period considered and the annual growth rates of 2008, 2009, 2010 and 2011 were\n15.57%, 7.79%, 8.93% and 13.81%, respectively.\n1371\n\ncountries/region in the period considered. Once more, the US dominated the\nannual number followed by the EU, Japan, Korea and China and, in general, the\nnumber of patent documents increased up to a specific year for each\ncountry/region and then decreased. These trends are similar to the ones observed\nworldwide, except for China. However, there was a sharp fall in 2009 and 2010\nand this could partially be a consequence of delaying processes of indexing due to\nthe lack of patent data because of the Patent Cooperation Treaty (PCT) process or\nthe search expression used. Moreover, the effect of the recent financial crisis\nwould have affected their patent activity.\n\nFigure 3. Worldwide, USPTO, TRIAD and TETRAD annual number of patent\ndocuments for the main countries/region.\n\nThe dynamic of patenting for technological domains and subdomains\nTable 3 compares the shares of patent documents according to technological\ndomains and subdomains in worldwide, USPTO, TRIAD or TETRAD situations.\nTable 3. Share of patent documents according to technological domains and\nsubdomains in worldwide, USPTO, TRIAD or TETRAD situations.\n\n\n\nTechnological\nDomain/Subdomain\nElectronic-Electricity\nElectrical Components\nAudiovisual\nTelecommunications\nData Processing\n1372\n\nWorldwide USPTO\nShare (%) Share (%)\n31.0\n40.5\n14.2\n16.7\n2.11\n3.29\n0.99\n1.57\n2.07\n3.77\n\nTRIAD\nShare (%)\n37.4\n19.6\n3.22\n1.39\n3.44\n\nTETRAD\nShare (%)\n39.0\n21.3\n3.47\n1.38\n3.53\n\nSemiconductors\nInstrumentation\nOptics\nAnalysis-Measurement-Control\nMedical Engineering\nNuclear Techniques\nChemistry-Materials\nOrganic Chemistry\nMacromolecular Chemistry\nBasic Chemistry\nSurface Treatments\nMaterials-Metallurgy\nPharmacy-Biotechnology\nBiotechnology\nPharmacy-Cosmetics\nAgricultural and Food Products\nIndustrial Processes\nTechnical Processes\nGraphical Maintenance\nWork with Materials\nEnvironment-Pollution\nAgriculture and Food Equipment\nMachines-Mechanics-Transp.\nMachine-Tools\nMotor-Pump-Turbines\nThermal Processes\nMechanical Components\nTransport\nSpace-Weapons\nHousehold\nConsumption.Construction\nHousehold Consumption\nConstruction\n\n16.8\n24.6\n8.28\n11.6\n5.35\n1.03\n44.0\n3.98\n13.0\n8.30\n13.5\n16.5\n15.8\n7.04\n10.2\n1.12\n24.1\n12.7\n1.73\n9.89\n2.33\n0.52\n4.59\n1.54\n0.56\n1.00\n0.94\n0.64\n0.23\n\n24.0\n32.3\n11.1\n15.8\n6.82\n1.83\n46.1\n6.81\n13.3\n9.93\n21.7\n13.4\n21.7\n12.0\n13.7\n0.90\n25.1\n13.4\n2.38\n11.6\n1.59\n0.45\n5.10\n2.03\n0.66\n0.87\n0.97\n0.73\n0.34\n\n22.2\n37.7\n12.3\n18.8\n9.57\n2.17\n60.7\n11.8\n22.4\n17.0\n25.1\n20.2\n30.8\n15.6\n22.0\n1.62\n35.5\n19.1\n3.82\n17.6\n1.82\n0.61\n6.32\n2.48\n0.80\n0.93\n1.45\n1.25\n0.16\n\n22.7\n32.1\n11.9\n14.4\n7.68\n1.82\n63.9\n11.0\n25.1\n18.6\n26.6\n22.2\n26.7\n12.4\n19.8\n1.73\n38.0\n19.9\n3.97\n19.8\n2.14\n0.53\n6.96\n2.83\n0.66\n1.12\n1.57\n1.36\n0.15\n\n3.25\n\n2.90\n\n2.81\n\n3.14\n\n2.36\n0.93\n\n2.15\n0.81\n\n2.24\n0.63\n\n2.43\n0.79\n\nAll patent documents were associated with at least one technological domain and\nsubdomain showing evidence of the interdisciplinarity of technological\ndevelopments on a nano-scale. Nonetheless, there was a clear bias towards\nChemistry, Electronic-Electricity, Instrumentation and Industrial Process domains\nand\nSemiconductors,\nSurface\nTreatments,\nElectrical\nComponents,\nMacromolecular Chemistry, Materials-Metallurgy, Pharmacy-Cosmetics and\nAnalysis-Measurement-Control subdomains in the four cases analyzed. On the\nother hand, few developments occurred in the Household ConsumptionConstruction and Machines-Mechanics-Transport domains. Furthermore, even\nthough the share may be slightly different, no technological domain or subdomain\noverlapped other positions with the change of perspective. Considering the\nWorldwide patent share, the Semiconductors subdomain concentrated the highest\nnumber (16.8%) followed closely by Materials-Metallurgy (16.5%). Electrical\n1373\n\nComponents (14.2%), Surface Treatments (13.5%) and Macromolecular\nChemistry (13.0%), which were also relevant subdomains in the period analyzed.\nIn the case of patent documents at the USPTO, besides Semiconductors (24.0%),\nSurface Treatments (21.7%) and Electrical Components (16.7%), another two\nsubdomains were highlighted as important technological contexts, AnalysisMeasurement-Control (15.8%) and Pharmacy-Cosmetics (13.7%). Concerning the\nTRIAD and TETRAD shares, there is a similarity of the main technological\nsubdomain. Technology for Surface Treatments (25.1% and 26.6%, respectively)\npresented the most important subdomain, followed by Macromolecular Chemistry\n(22.4 % and 25.1%) and Semiconductors (22.2% and 22.7%). MaterialsMetallurgy appeared, respectively, in fifth (20.2%) and fourth (22.2%) place\nwhile Pharmacy-Cosmetics stood out from TRIAD (22.0%) and Electrical\nComponents (21.3%) from TETRAD. Additionally, it is important to clarify that\nthe sum of percentage shared in any situation will be more than 100% because a\nsingle patent document can contain a range of different IPC codes and belong to a\ndifferent technological domain or subdomain.\nTable 4. Share of country/region patent documents according to their three most\nrelevant technological subdomains in the worldwide, USPTO, TRIAD or TETRAD 130\nsituations.\nCountry/\nWorldwide\nRegion Subd. Share (%)\nSe\n20.3\nUS\nST\n19.1\nAMC\n16.7\nMC\n17.9\nEU\nST\n17.2\nTP\n17.2\nSe\n22.8\nJapan MM\n22.8\nEC\n21.5\nSe\n23.9\nKorea EC\n16.7\nMM\n11.1\nMM\n21.8\nChina TP\n14.4\nMC\n13.9\n\nUSPTO\nSubd. Share (%)\nSe\n21.1\nST\n20.1\nAMC\n16.6\nST\n24.7\nMC\n21.7\nPC\n21.3\nSe\n35.0\nEC\n25.5\nST\n24.9\nSe\n41.4\nEC\n31.6\nST\n22.7\nEC\n31.6\nMM\n28.6\nST\n26.0\n\nSubd.\nPC\nST\nSe\nST\nPC\nMC\nST\nMM\nSe\nEC\nSe\nST\nTP\nMM\nST\n\nTRIAD\nShare (%)\n25.1\n23.2\n21.6\n26.0\n25.5\n25.3\n28.5\n27.9\n26.6\n38.1\n31.5\n29.0\n33.9\n29.8\n24.0\n\nTETRAD\nSubd. Share (%)\nST\n24.6\nMC\n23.4\nSe\n23.3\nMC\n29.3\nST\n28.0\nMM\n23.0\nMM\n30.8\nST\n29.5\nEC\n29.3\nEC\n39.7\nSe\n30.6\nST\n28.6\nTP\n33.9\nMM\n30.4\nST\n23.5\n\nThe patent share of countries/region in the four situations considered can be\nassessed according to the main technological subdomains that they explore, as\nshown in Table 4. Countries/region focus on different subdomains according to\n130\nIn Table 4, Semiconductors = Se; Surface Treatments = ST; Analysis-Control-Measurement =\nACM; Materials-Metallurgy = MM; Technical Processes = TP; Macromolecular Chemistry = MQ;\nPharmacy-Cosmetics = PC; and Electrical Components = EC.\n\n1374\n\nthe perspective considered, although the subdomains of Korea and China tend to\nbe close. Semiconductors was extensively explored by the US, Japan and Korea\nwhile Electrical Components was the major target for Korea and Japan. The EU\nhad great interest in Macromolecular Chemistry in four cases. Furthermore, the\nEU competed against the USA for the Pharmaceutical-Cosmetics subdomain in\nthe case of TRIAD. It should be mentioned that China has a small number of\npatent documents in the USPTO, TRIAD and TETRAD cases from 2000 to 2010.\nHowever, Technical Processes was a subject of interest mainly for China and\nMaterials-Metallurgy stands out as an important technological subdomain,\nalthough Japan was a great competitor in this last subdomain. A striking result is\nthat all countries/region were interested in the Surface Treatments subdomain,\nbecause it appears in all the evaluated situations and all countries/region, except\nfor the worldwide case where just the USA and EU stand out.\nConclusion\nThis paper investigated the trends of patenting and predicts future development\nbased on growth rates and logistic growth curve. It has also discussed the activity\nof the most relevant countries/region and the main technological domains and\nsubdomains using bibliometric indicators. In the country/region and technological\ndomain and subdomain indicators, four perspectives of patenting were considered\n(the worldwide trend and patent documents from USPTO, TRIAD and TETRAD)\nin order to assess the economic value of patent filing in nanotechnology. The\nfollowing conclusions can be drawn from the present study. The share of patents\nindicated a clear bias towards Chemistry, Electronic-Electricity, Instrumentation\nand Industrial Process domains from 2000 to 2010, regardless of the perspective\nadopted. Considering patent documents from TRIAD and TETRAD, the main\nsubdomains of interests can be outlined for the main countries/region, which\ntogether shared 93.5% of worldwide patenting. Semiconductors, Macromolecular\nChemistry and Pharmacy-Cosmetics subdomains characterized the US\ntechnological development; the EU showed interest in Macromolecular\nChemistry, Materials-Metallurgy and Pharmacy-Cosmetics; Japan stood out in\nSemiconductors, Electrical Components and Materials-Metallurgy; Korea paid\nattention to Electrical Components and Semiconductors; and China had an\nextremely small number of documents in the TRIAD and TETRAD. They could\nbe highlighted in Technical Processes and Materials-Metallurgy. China became\nthe main worldwide patentee in nanotechnology after 2007 and was the only\ncountry to increase the annual number of patents until 2010. China shared a small\nnumber of patent documents in USPTO, TRIAD and TETRAD and raised an\nissue whether their nanotechnologies are relevant economically or not. Other\ncountries/region showed a recent decline in the number of patent documents per\nyear, including the USPTO, TRIAD and TETRAD perspectives and this may be\nrelated to several factors, including the current economic recession, the delay in\nPCT processes and indexing, or even uncompleted data. The annual growth rate\nand the cumulative number of patents from 1995 to 2010 suggested that\n1375\n\nnanotechnology development has achieved its initial stage of maturation.\nHowever, some biases were considered, such as data incompleteness, the need to\nforecast the nanotechnology subfield, and the link between nanoscience and\nnanotechnological development although considering the current paradigms.\nMoreover, changes in the developed forecasting curves or indicators cannot be\npredicted and monitoring the technological activities should be constantly\nreviewed in order to confirm evidence and test hypotheses that emerged.\nAcknowledgements\nThe authors are grateful to the Brazilian National Council for Technological and\nScientific Development (process number 160087/2011-2), the São Paulo Research\nFoundation (process number 2012/16573-7) and the Graduate Program in\nMaterials Science and Engineering at the Federal University of São Carlos for\nsupporting this work.\nReferences\nAlencar, M. S. M., Porter, a. L., &amp; Antunes, a. M. S. (2007). Nanopatenting\npatterns in relation to product life cycle. Technological Forecasting and Social\nChange, 74(9), 1661–1680. doi:10.1016/j.techfore.2007.04.002\nChen, H., Roco, M. C., Li, X., &amp; Lin, Y. (2008). Trends in nanotechnology\npatents. Nature nanotechnology, 3(3), 123–5. doi:10.1038/nnano.2008.51\nCheng, A., &amp; Chen, C. (2008). The technology forecasting of new materials: the\nexample of nanosized ceramic powders. Romanian Journal of Economic\nForecasting, 4, 88–110.\nDang, Y., Zhang, Y., Fan, L., Chen, H., &amp; Roco, M. C. (2010). Trends in\nworldwide nanotechnology patent applications: 1991 to 2008. Journal of\nnanoparticle research, 12(3), 687–706. doi:10.1007/s11051-009-9831-7\nGalembeck, F., &amp; Rippel, M. M. (2006). Nanotecnologia: estratégias\ninstitucionais e de empresas. In Strategic studies: nanotechnology (pp. 6–120).\nBrasília: Secretariat of Strategic Affairs. (Portuguese).\nGlänzel, W., Debackere, K., &amp; Meyer, M. (2007). “Triad” or “Tetrad”? On\nGlobal Changes in a Dynamic World. SSRN Electronic Journal.\ndoi:10.2139/ssrn.1101439\nHu, A. G., &amp; Jefferson, G. H. (2009). A great wall of patents: What is behind\nChina’s recent patent explosion? Journal of Development Economics, 90(1),\n57–68. doi:10.1016/j.jdeveco.2008.11.004\nHuang, C., Notten, A., &amp; Rasters, N. (2011). Nanoscience and technology\npublications and patents: a review of social science studies and search\nstrategies. The Journal of Technology Transfer, 36(2), 145–172.\ndoi:10.1007/s10961-009-9149-8\nHuang, Z., Chen, H., Chen, Z., &amp; Roco, M. C. (2004). International\nnanotechnology development in 2003: Country, institution, and technology\nfield analysis based on USPTO patent database. Journal of Nanoparticle\nResearch, 6(4), 325–354. doi:10.1007/s11051-004-4117-6\n1376\n\nHuang, Z., Chen, H., Yip, A., Ng, G., Guo, F., Chen, Z., &amp; Roco, M. C. (2003).\nLongitudinal patent analysis for nanoscale science and engineering : Country ,\ninstitution and technology field. Journal of Nanoparticle Research, 5, 333–\n363.\nHullmann, A., &amp; Meyer, M. (2003). Publications and patents in nanotechnology\nAn overview of previous studies and the state of the art. Scientometrics, 58(3),\n507–527.\nIgami, M. (2008). Exploration of the evolution of nanotechnology via mapping of\npatent applications. Scientometrics, 77(2), 289–308. doi:10.1007/s11192-0071973-8\nKostoff, R. N., Koytcheff, R. G., &amp; Lau, C. G. Y. (2007). Global nanotechnology\nresearch literature overview. Technological Forecasting and Social Change,\n74(9), 1733–1747. doi:10.1016/j.techfore.2007.04.004\nLv, P. H., Wang, G.-F., Wan, Y., Liu, J., Liu, Q., &amp; Ma, F. (2011). Bibliometric\ntrend analysis on global graphene research. Scientometrics, 88(2), 399–419.\ndoi:10.1007/s11192-011-0386-x\nMartino, J. P. (Ed.). (1993). Technological Forecasting for Decision Making.\nNew York: Mcgraw-Hill.\nMilanez, D. H. (2011). Nanotechnology: technological indicators on advances in\nmaterials based on patent analysis. (Master’s thesis) Federal University of Sao\nCarlos, Sao Carlos. (Portuguese). Retrieved January 28, 2013 from:\nhttp://200.136.241.56/htdocs/tedeSimplificado/tde_busca/arquivo.php?codArq\nuivo=4653\nMilanez, D. H., Amaral, R. M., Faria, L. I. L. &amp; Gregolin, J. A. R. (2013).\nAssessing nanocellulose developments using science and technology\nindicators. Materials Research. Epub March 05, 2013. Retrieved April 19,\n2013, from http://www.scielo.br/scielo.php?script=sci_arttext&amp;pid=S151614392013005000033&amp;lng=en&amp;tlng=en.\nMogee, M. E. (1997). Patents and Technology Intelligence. In Ashton, W. B. &amp;\nKlavans, R. A (Eds.) Keeping abreast of science and technology: technical\nintelligence for business (pp. 295-336). Columbus: Battelle Press.\nObservatorynano. (2012). Public Funding of Nanotechnologies (pp. 1–22).\nRetrieved January 28, 2013 from:\nhttp://www.observatorynano.eu/project/filesystem/files/PublicFundingofNanot\nechnologies_March2012.pdf\nOECD. (2009). OECD Patent Statistics Manual. Retrieved January 28, 2013from:\nhttp://dx.doi.org/ 10.1787/9789264056442-en\nObservatoire des Sciences et des Techniques. (2010). Science &amp; technologie\nindicateurs. Paris: Economica.\nPorter, A. L., Youtie, J., Shapira, P., &amp; Schoeneck, D. J. (2008). Refining search\nterms for nanotechnology. Journal of Nanoparticle Research, 10(5), 715–728.\ndoi:10.1007/s11051-007-9266-y\n\n1377\n\nRoco, M. C. (2005). International Perspective on Government Nanotechnology\nFunding in 2005. Journal of Nanoparticle Research, 7(6), 707–712.\ndoi:10.1007/s11051-005-3141-5\nSalerno, M., Landoni, P., &amp; Verganti, R. (2008). Designing foresight studies for\nNanoscience and Nanotechnology (NST) future developments. Technological\nForecasting and Social Change, 75(8), 1202–1223.\ndoi:10.1016/j.techfore.2007.11.011\nScheu, M., Veefkind, V., Verbandt, Y., Galan, E. M., Absalom, R., &amp; Förster, W.\n(2006). Mapping nanotechnology patents: The EPO approach. World Patent\nInformation, 28(3), 204–211. doi:10.1016/j.wpi.2006.03.005\nUnited States. (2012). The National Nanotechnology Initiative. NNI Supplement\nto the President’s 2013 Budget. Retrieved January 28, 2013 from:\nhttp://www.nano.gov/node/748\nWang, G., &amp; Guan, J. (2012). Value chain of nanotechnology: a comparative\nstudy of some major players. Journal of Nanoparticle Research, 14(2).\ndoi:10.1007/s11051-011-0702-7\n\n1378\n\nTHE PATTERNS OF INDUSTRYUNIVERSITY-GOVERNMENT COLLABORATION\nIN PHOTOVOLTAIC TECHNOLOGY\nHuei-Ru Dong1, Dar-Zen Chen2 and Mu-Hsuan Huang 3*\n1\n\nd99126002@ntu.edu.tw\nDepartment of Library and Information Science, National Taiwan University,\nTaiwan\n2\n\ndzchen@ntu.edu.tw\nDepartment of Mechanical Engineering and Institute of Industrial Engineering,\nNational Taiwan University, Taiwan\n3\n\nCorresponding Author: mhhuang@ntu.edu.tw\nDepartment of Library and Information Science, National Taiwan University,\nTaiwan\n\nAbstract\n\nThis research aims to understand the patterns of the Industry-University-Government\n(IUG) collaboration relationship. The degree of the involvement of the three sections in\nphotovoltaic technology is observed from the co-authored patents on I-U-G collaboration\nretrieved from USPTO database between 2002 and 2011. This study hopes to determine\nthe linkage between technical development and potential matches for institutional\ncollaborations. The researcher first analyses and compares the number of co-authored\npatents and the share of patents contributed by each I-U-G sectors. Next, to understand\nhow the institution, the university and the government participated in the development of\nphotovoltaic technology, the study identifies the number of patents co-authored by two of\nthe I-U-G sectors and the percentages of the co-authored patents over the total. Lastly, the\nmain participants in U-I, U-G, and I-G collaborations are identified through close\nexamination of co-authored patents on photovoltaic technology. The results reveal that\nindustry has the highest shares both in the number of patents and of participating\ninstitutions; however, the percentage in co-authored patents of the industry is the lowest.\nOn the other hand, the university has the highest shares of co-authored patents and of\nparticipating institutions.\n\nConference Topic\n\nTechnology and Innovation Including Patent Analysis (Topic 5) and Collaboration Studies\nand Network Analysis (Topic 6).\n\nIntroduction\nCo-authorship signifies the collaborative relationship in scientific collaboration,\nincluding interaction between theoretical knowledge and technical data (Heffiner,\n1981). Patent collaboration is as one of the key methods used to measure the\n1379\n\noutput of innovation system. Previous studies that investigated patent\ncollaborations in national and regional innovation systems developed a strong\ndependency on foreign knowledge (Gao, Guan, &amp; Rousseau, 2011; Chen &amp; Guan,\n2011). Ortega (2011) examines the collaborative patterns in the networks of\npatents and finds that the national collaboration can strongly and effectively\ntransfer the patents.\nPhotovoltaic technology is a key research topic in the field of energy technology.\nAs energy crisis intensified, governments worldwide have promoted policies of\nclean energy and photovoltaic technology. As a result, the increased academic and\nindustrial sections have devoted to the development of photovoltaic-related\ntechnology as encouraged by the government.\nParticularly, academic circles have proposed several types of innovation models.\nThe triple helix innovation pattern reflects the relationship among academia, the\nindustry and the government in one country (Etzkowitz &amp; Leydesdorff 1995).\nAlso, the triple helix indicates a transformation in the relationship among\nuniversity, the industry and the government. Of the three types of organizations,\nthe industry generally leads the development and relies heavily on R&amp;D and\npatents to a higher extent, which explains why industry cooperates frequently\nwith universities and research organizations. University supports innovative\ndevelopment by providing trained human resources, scientific research results,\nand theoretical knowledge to the industry, enhancing its role of innovation in\nknowledge-based societies (Meyer, Sinilainen, &amp; Utecht 2003). The triple helix\ninnovation system theory emphasizes the interdependent and independent\nrelationship among the university, the industry and the government (Etzkowitz &amp;\nLeydesdorff 2000; Etzkowitz 2003).\nSábato and Mackenzi (1982) noted that triangle model guide the development of\ngovernment policies with its technical research and production. Etzkowitz &amp;\nLeydesdorff (2000) conceptualizes the model as analytical difference from the\nnational systems of innovation approach. There are three typical models of triple\nhelix configurations which reflect different relations among I-U-G. Etzkowitz &amp;\nLeydesdorff (2000) further classified triple helix innovation patterns and find that\nthe national innovation system encompasses academia and industry as well as\ndirects the relations among them.\nThe development of national innovation systems depends on various factors such\nas historical situation, policy guidance, economic development and natural\nresources. Nowadays, most countries and regions are encouraged to attain the\nform of triple helix model. Leydesdorff &amp; Meyer (2003) pointed out that there are\nthree functionally different sub-dynamics in the knowledge-based innovation\nsystem: economic exchanges in the market, geographical variations, and the\norganization of knowledge. Dolfsma &amp; Leydesdorff (2008) discussed the\nknowledge based economy and found that medium-tech industry has a greater\ncontribution than high-tech industry on knowledge creation.\nPatent is an open and available information resources to measure the inventive\nactivities and the collaboration status of the university, the industry and the\n1380\n\ngovernment. Lee (1996) considered patent as an important technology output\nwhich influence the attitude of academia toward the university–industry\ncooperation. Besides, patent data contains standardized information that is related\nto new ideas and technological developments (Pilkington, Dyerson, &amp; Tissier,\n2002; Frietsch &amp; Grupp, 2006).\nMeyer et al. (2003) explored the collaboration relationship between the industry\nand the university by combining patent analysis with an inventor survey. The\nuniversity-industry relation has been changing owing to new technologies\ndeveloped from academic research. Altlan (1987) pointed out that R&amp;D\ncollaboration is an important mode in university-industry relations. ManjarresHenriquez, Gutierrez-Gracia and Vega-Jurado (2008) found that the universityindustry relation showed positive effect on scientific productivity of the\nuniversity. In the context of partnerships between industry and academia, Leroy\nand Doerig (2008) stated that the ownership of intellectual property must also be\nconsidered in addition to scientific activities.\nCollaboration is an inherent aspect of the research activity, as information\nexchange reinforces the discussion and the production of new knowledge (Katz &amp;\nMartin 1997). Collaboration pattern plays an important role in the national\ninnovation system. Though the interconnections among the university, the\nindustry and the government in innovation system have been recognized, to\nmeasure the innovative contribution and collaboration status of the triple helix is\nrather difficult, since relevant technology and R&amp;D input and output information\nare usually immeasurable.\nThus, the objective of this research is to study the Industry-UniversityGovernment (I-U-G) relationship via examining scientific collaboration patterns\nin photovoltaic technology. The photovoltaic technology is collected from\nUSPTO database between 2002 and 2011. This research first analysed the\nnumber of co-authored patents in I-U-G and the amount of co-authored patents\nbetween I-U-G and other technologies. This research then analysed the number of\nco-authored institutions in I-U-G and the amount of co-authored institutions\nbetween I-U-G and other technologies. At last, key institutions among U-I, U-G\nand I-G technology collaborations were analysed to understand institution\nparticipation in the development of photovoltaic technology.\nMethodology\nThis study utilizes patentometric methods to explore the collaboration patterns in\nphotovoltaic technology. Patentometrics use objective statistics to observe\nquantitative and qualitative performance of a research topic. Through analysis\nconducted based on the indicators, one can understand the structure of\ntechnological production capacity, as well as the trends in technological\ndevelopment, which establishes common frames of reference for further research.\n\n1381\n\nData collection\nThe source of patent information used in this study is based on the patents retried\nthrough the database of United States Patents and Trademark Office (USPTO)\nwith the United States Patent Classification System (USPC). Since US patents\nare considered as an epitome of the global technological development, patents\napplication in the United States is a strategic action for most of the inventors and\nauthors worldwide to maintain competitive. Compare with International Patent\nClassification system, the United States Patent Classification System is updated\nmore frequently and provides more detailed information on relevant patents,\nreflecting the advancement and innovation of technologies more accurately.\nTo obtain patents relevant to photovoltaic technology, searches through work\nreports published by OECD, FEEM (Fondazione Eni Enrico Mattei) and WIPO\n(World Intellectual Property Organization), and identifies patents through\nkeyword search and queries through USPC classification numbers were\nconducted to assimilate relevant key words in the field. Keywords such as solar\ncell, photovoltaic, PV, and USPC classification number such as 136/258, 136/252,\n136/262, 136/263 are employed as query in the USPTO patent database, each\npatent checked by the expert. There are a total of 6,840 utility patents on\nphotovoltaic technology between 2002 and 2011.\nAnalysis on the scientific collaboration patterns in photovoltaic technology is\nconducted is grouped into three types: the industry, the university, and the\ngovernment. Based on the triple helix innovation patterns following up on studies\nof Leydesdorff (2003) and Park, Hong &amp; Leydesdorff (2005), who used the\nScience Citation Index for computing the mutual information in three dimensions.\nAll of the photovoltaic patents data set and assignees are compiled and organized\nunder attribution to the industry-university- government relations. The titles of\nassignees containing the abbreviations UNIV or COLL are labelled as the\nuniversity. Then assignees are labelled as the industry if their titles contain any of\nthe following identifiers: CORP, INC, LTD, SA or AG. The assignees are\nidentified as the government if they are the public research institutions with\nabbreviations such as NATL, NACL, NAZL, GOVT, MINIST, ACAD, INST,\nNIH, HOSP, HOP, EUROPEAN, US, CNRS, CERN, INRA, and BUNDES in\ntheir title.\nTable 1 Number and share of patents and institutions in photovoltaic\ntechnology in different sectors\nPatent N\nInstitution N\n\nIndustry\n6,232 (91.11%)\n1,057 (83.36%)\n\nUniversity\n403 (5.89%)\n137 (10.80%)\n\nGovernment\n310 (4.53%)\n74 (5.84%)\n\nTotal\n6,840\n1,268\n\nTable 1 tabulates the number of patents and institutions in the three sectors – the\nindustry, the university, and the government. Among the total of 6,840 patents on\nphotovoltaic technology, 6,232 patents (91.11%) are produced by industry, 403\n1382\n\npatents (5.89%) by the university, and 310 patents (4.53%) by the government.\nAmong the total of 1,268 institutions for photovoltaic technology, 1,057 (83.36%)\nare from the industry, 137 (10.80%) from the university, and 74 (5.84%) from the\ngovernment.\nResult\nNumber and share of I-U-G co-authored collaboration in photovoltaic technology\nThis study first calculates the patent numbers of the four I-U-G collaboration\nforms and the shares of patents produced by the three types of institution. Among\nthe 6,840 photovoltaic-related patents, 103 patents are of I-U-G collaborative\nauthorship (1.51%). As shown in Table 2, among 103 patents collected, 62 are\nfrom University-Industry (U-I) collaboration, 25 Industry-Government (I-G)\ncollaboration, 14 University-Government (U-G) collaboration, and 2 I-U-G\ncollaboration.\nAs listed in Table 2, the categorization of I-U-G collaboration patents further\nshows that among the 6,840 photovoltaic-related patents, 91.11% are produced by\nthe industry, 5.89% and 4.53% are from the university and the government\nrespectively. From the perspective of the industry, the share of I-U-G\ncollaboration patents is relatively low (1.43%). To be specific, while the share of\nU-I collaboration patents of industry is the highest in this section, the\ncollaboration share of patents by the industry is still low at 0.99%.\nTable 2 Number and shares of patents for the four types of I-U-G\ncollaborations in photovoltaic technology\nCollaboration type\nPatent N\nIndustry\n\nU-I\n62\n\nI-G\n25\n\nU-G\n14\n\nI-U-G\n2\n\ntotal\n103\n\n0.99%\n\n0.40%\n\n-\n\n0.03%\n\n1.43%\n\nUniversity\n\n15.38%\n\n-\n\n3.47%\n\n0.50%\n\n19.35%\n\nGovernment\n\n-\n\n8.06%\n\n4.52%\n\n0.65%\n\n13.23%\n\n(91.11%= 6,232/6,840)\n(5.89%= 403/6,840)\n(4.53%= 310/6,840)\n\nNumber and share of I-U-G co-authored collaboration in photovoltaic technology\nin different types of institutions\nTable 3 shows that most of the institutions that obtained patents are from the\nindustry, followed by the university and the government. Within the assignees of\n6,840 patents related to photovoltaic technology, there are 131 institutions\nparticipating in I-U-G collaboration. And among these institutions 60 (45.80%)\nare from the industry, 47 the university (35.88%), and 24 (18.32%) the\ngovernment.\nThough the numbers of institutions from university and government participating\nin I-U-G collaboration are relatively low, one third of the patents produced by the\n1383\n\nuniversity and the government are co-authored. The percentage of the shares of\ninstitutions participating in I-U-G collaboration from the university and the\ngovernment are 34.31% and 32.43% respectively. Among the 1,057 industrial\ninstitutions that produced photovoltaic patents, only 60 institutions produced I-UG co-authored patents, accounting for 5.68% of the overall institutions.\nIn the three types of I-U-G co-authorships, with 69 institutions, U-I collaboration\nranks the highest, including 35 from the industry and 34 from the university.\nForty-two institutions participated in I-G collaboration, including 25 from the\nindustry and 17 from the government. Twenty-two institutions participated in UG collaboration, including 12 from the university and 10 from the government.\nSix institutions participated in I-U-G collaborations, including 2 from the\nindustry, the university and the government for each.\nA further analysis on the types of I-U-G collaboration for different types of\ninstitutions shows that for the industry, the percentage of I-U-G collaboration has\na low rate at 5.68%. The percentage of collaboration with the university is slightly\nhigher at 3.31%, but the percentage of collaboration with government is even\nlower (2.37%). More than one third of the institutions participated in I-U-G\ncollaboration (34.31%), including the main collaboration with the industry\n(24.82%), followed by the collaboration with the government (8.76%) Nearly one\nthird of the institutions from the governments have participated in I-U-G\ncollaboration (32.43%). These institutions of government have worked with the\nindustry (22.97%), followed by collaboration with university (13.51%).\nTable 3 Numbers and shares of patents in photovoltaic technology by three\ntypes of institutions in different types of I-U-G collaboration\nCollaboration\ntype (Patent N)\nInstitution N\nIndustry\n\nU-I (69)\nU\n34\n\nI\n35\n\nI-G (42)\nI\n25\n\nU\n12\n\nG\n10\n\n-\n\n-\n\n-\n\n(83.36%=\n1,057/1,268)\n\n-\n\n(10.80%=\n137/1,268)\n\n24.82%\n\n-\n\n-\n\n-\n\n8.76%\n\n-\n\n(5.84%=\n74/1,268)\n\n-\n\n-\n\n-\n\n22.97%\n\n-\n\n13.51%\n\nUniversity\n\nGovernment\n\n3.31% 2.37%\n\nU-G (22)\n\nG\n17\n\nI-U-G (6)\nI\n2\n\nU\n2\n\nTotal (131)\nG\n2\n\n0.19%\n\nI\n60\n\nU\n47\n\nG\n24\n\n5.68%\n1.46%\n\n34.31%\n2.70%\n\n32.43%\n\nThe number of institutions participating in I-U-G collaboration in photovoltaic\ntechnology by year\nThis study tracks the trends of institutions participating in I-U-G collaboration\nannually. Figure 1 lists the numbers of the three types of photovoltaic institutions\nin I-U-G collaboration between 2002 and 2011. The number of institutions\ninvolved in I-U-G collaboration reached its highest in 2011, showing a growing\ntrend toward I-U-G collaboration for institutions. In regard to the institutions in\ndifferent sections, the number of institutions from the industry maintained the\n1384\n\nhighest among the three, except during 2009-2010. The trend line shows that the\nnumber of institutions from the university exceeds that of institutions from\nindustry in 2010.\nComparison of the trend lines for the three types of institutions shows that the\ngrowth rate for the number of university institutions is the highest (R2=0.7367),\nthe growth rate for the number of industrial institutions is approaching linear\n(R2=0. 5026), and the growth rate for the number of governmental institutions is\nrelatively low (R2=0.4041).\n\nFigure 1 Number of institutions in I-G-U collaboration of photovoltaic patents\nby years\n\nKey institutions in I-U-G collaboration\nThis study further conducts analysis to identify the key institutions participating\nin various types of I-U-G collaboration. The results are detailed as follows.\nKey institutions in U-I collaboration\nTable 4 lists the key institutions in U-I collaboration. Among these institutions,\nTsing Hua University has produced the highest number of U-I co-authored\npatents. Among the 16 patents in photovoltaic technology, 15 belong to U-I\ncollaboration (93.75%). Next, Hon Hai Precision Ind. Co., Ltd. obtained 14\npatents from U-I collaboration (56.00%) out of its 25 patents in photovoltaic\ntechnology. The remained institutions have produced less than 10 patents from UI collaboration.\nAnalysing the institutions in U-I collaboration from the perspective of countries,\nJapan obtained the highest number of institutions in U-I collaboration. Seven of\nthe overall institutions are located in Japan, 6 in United States, 3 in South Korea,\n1385\n\n2 in United Kingdom, and one in China, Taiwan, and France for each country\nrespectively.\nA closer observation on the types of institutions participating in U-I collaboration\nshows that 10 institutions are from the university and 11 are from the industry.\nFrom the perspective of patent number and the share in I-U-G collaboration in\nphotovoltaic technology, universities have produced most patents from U-I\ncollaboration including Tsing Hua University (15/16=93.75%), Kyoto University\n(2/3=66.67%), University Of Southern California (8/18=44.44%), Hanyang\nUniversity, Osaka University, Seoul National University, and St. Andrews\nUniversity (2/2=100%). Institutions from the industry include Hon Hai Precision\nInd. Co., Ltd. (14/25=56%), Universal Display Corporation (8/20=40%), and\nDow Corning Corporation and Isis Innovation Limited (2/2=100%).\nTable 4 Key institutions in U-I collaboration\nNo.\n1\n2\n3\n3\n5\n6\n6\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n\nI-U-G\nCountry Type collaboration patent N\npatent N\nTsing Hua University\nChina\nU\n15\n16\nHon Hai Precision Ind. Co., Ltd.\nTaiwan\nI\n14\n25\nThe University Of Southern California\nUSA\nU\n8\n18\nUniversal Display Corporation\nUSA\nI\n8\n20\nSamsung Electronics Co., Ltd.\nSouth\nI\n4\n189\nKorea\nCalifornia University\nUSA\nU\n3\n29\nPrinceton University\nUSA\nU\n3\n52\nDow Corning Corporation\nUSA\nI\n2\n2\nHanyang University\nSouth\nU\n2\n2\nKorea\nIsis Innovation Limited\nUK\nI\n2\n2\nOsaka University\nJapan\nU\n2\n2\nSeoul National University\nSouth\nU\n2\n2\nKorea\nSt. Andrews University\nUK\nU\n2\n2\nKyoto University\nJapan\nU\n2\n3\nEcole Polytechnique\nFrance\nU\n2\n10\nShin Etsu Chemical Co., Ltd.\nJapan\nI\n2\n11\nRohm Company Limited\nJapan\nI\n2\n16\nPioneer Corporation\nJapan\nI\n2\n17\nIdemitsu Kosan Co., Ltd.\nJapan\nI\n2\n40\nHewlett-Packard Development Company, USA\nI\n2\n51\nL.P.\nSeiko Epson Corporation\nJapan\nI\n2\n86\nInstitution\n\nshare\n93.75%\n56.00%\n44.44%\n40.00%\n2.12%\n10.34%\n5.77%\n100.00%\n100.00%\n100.00%\n100.00%\n100.00%\n100.00%\n66.67%\n20.00%\n18.18%\n12.50%\n11.76%\n5.00%\n3.92%\n2.33%\n\nThe university institution with high number of photovoltaic patents but low\nnumber of U-I collaboration patents is Princeton University (3/52=5.77%).\nSimilar industrial institutions include Samsung Electronics Co., Ltd.\n(4/189=2.12%), Idemitsu Kosan Co., Ltd. (2/40=5%), Hewlett-Packard\n1386\n\nDevelopment Company, L.P. (2/51=3.92%), and Seiko Epson Corporation\n(2/86=2.33%). These figures show that university is more dependent on U-I\ncollaboration than industry in U-I collaboration photovoltaic patent output.\nKey institutions in I-G collaboration\nTable 5 lists the key institutions involved in I-G collaboration. Among these\ninstitutions, Agency of Industrial Science &amp; Technology has produced the most of\nthe patents from I-G collaboration. Out of the 19 photovoltaic patents, 4 are I-G\ncollaboration patents (21.05%). National Research Council of Canada has 3 I-G\ncollaboration patents out of the 10 photovoltaic patents (30%). And the third is\nXerox Corporation, with 3 I-G collaboration patents out of 62 photovoltaic\npatents (4.84%).\nFrom the perspective of countries of which the 11 key institutions of I-G\ncollaboration are located, 3 are located in South Korea, 2 in France and Belgium\nfor each, and one in Japan, Canada, USA, and Germany respectively.\nAs for the types of institutions, 6 are from the government sector and 5 are from\nthe industry. From the perspective of number and percentage of patents in I-U-G\ncollaboration, in the industry, institutions produced higher number of patents from\nI-G collaboration. The institutions include Xerox Corporation (3/62=4.84%) and\nSamsung Electronics Co., Ltd. (2/189=1.06%).\nTable 5 Key institutions in I-G collaboration\nNo.\n1\n2\n2\n4\n4\n4\n4\n4\n4\n4\n4\n\nI-U-G\nCountry Type collaboration patent N\npatent N\nAgency of Industrial Science &amp; Technology Japan\nG\n4\n19\nNational Research Council of Canada\nCanada G\n3\n10\nXerox Corporation\nUSA\nI\n3\n62\nFramatome\nFrance\nI\n2\n2\nOffice National Dapos;Etudes Et De\nFrance G\n2\n2\nRecherches Aerospatiales\nUmicore NV\nBelgium I\n2\n2\nHanwha Chemical Corporation\nSouth\nI\n2\n3\nKorea\nKorea Institute of Science and Technology\nSouth\nG\n2\n6\nKorea\nFraunhofer-Gesellschaft Zur Foerderung der\nGermany G\n2\n13\nAngewandten Forschung E.V.\nImec Vzw\nBelgium G\n2\n13\nSamsung Electronics Co., Ltd.\nSouth\nI\n2\n189\nKorea\nInstitution\n\nshare\n21.05%\n30.00%\n4.84%\n100.00%\n100.00%\n100.00%\n66.67%\n33.33%\n15.38%\n15.38%\n1.06%\n\nInstitutions from the industry that produced high number of photovoltaic patents\nbut low number of patents from I-G collaboration include Hanwha Chemical\nCorporation (2/3=66.67%) and Framatome and Umicore NV (2/2=100%). As for\ninstitutions from the government, Agency of Industrial Science &amp; Technology\n1387\n\n(4/19=21.05%), National Research Council of Canada (3/10=30%), Office\nNational Dapos; Etudes Et De Recherches Aerospatiales (2/2=100%), and Korea\nInstitute of Science and Technology (2/6=33.33%) are included. The trend shows\nthat, for I-G collaboration photovoltaic patent output, governmental institutions\nare more dependent on I-G collaboration than on industrial institutions.\nKey institutions in U-G collaboration\nTable 6 lists the key institutions in U-G collaboration. Centre National de La\nRecherche Scientifique - Cnrs and Imec Vzw are the institutions that have\nproduced the highest number of patents from U-G collaboration. Each of the\ninstitutions has 3 patents. The remaining institutions have produced 2 for each.\nAnd from the perspective of countries where these institutions are located, 2 are\nfrom France and Belgium respectively, and one is from Singapore.\nA closer look at the types of institutions in U-G collaboration shows that, of these\ninstitutions, 3 are from the government, and 2 are from the university. From the\nperspective of the number and percentage of patents in I-U-G collaboration,\nCentre National de La Recherche Scientifique - Cnrs (3/5=60%) and Agency for\nScience, Technology and Research (2/5=40%) have higher number of patents\nfrom U-G collaboration in the government sector. Universite Catholique de\nLouvain and Universite Peirre Et Marie Curie (2/2=100%) have the highest\nnumber of patents from U-G collaboration from the university sector.\nOnly one institution, Imec Vzw, produced high number of photovoltaic patents\nbut low number of patents from U-G collaboration (3/13=23.08%). This shows\nthat in comparison with the government, the output of photovoltaic patent is more\ndependent on U-G collaboration for the university.\nTable 6 Key institutions in U-G collaboration\nNo.\n1\n1\n3\n3\n3\n\nInstitution\nCentre National de La Recherche\nScientifique - Cnrs\nImec Vzw\nUniversite Catholique de Louvain\nUniversite Peirre Et Marie Curie\nAgency for Science, Technology and\nResearch\n\nI-U-G\nCountry Type collaboration patent N\npatent N\nFrance\nG\n3\n5\n\n60.00%\n\nBelgium\nBelgium\nFrance\nSingapore\n\n23.08%\n100.00%\n100.00%\n40.00%\n\nG\nU\nU\nG\n\n3\n2\n2\n2\n\n13\n2\n2\n5\n\nshare\n\nConclusion &amp; Discussion\nThis research studies the scientific collaboration patterns in photovoltaic\ntechnology from USPTO database between 2002 and 2011, in order to examine\nthe scientific collaboration pattern of the I-U-G relationship of photovoltaic\ntechnology. The authors analysed the numbers and the shares of co-authored\npatents between I-U-G, the number of co-authored institutions in I-U-G and the\n1388\n\namount of co-authored institutions between I-U-G. Key institutions among U-I,\nU-G and I-G technology collaborations are then identified to understand which\ninstitutions mainly participate in the development of photovoltaic technology.\nThe results show that the industry has produced the most number of patents, but\nthe industry’s involvement in I-U-G collaboration is the lowest (1.43%). On the\nother hand, though the university and the government have not produced as many\npatents in photovoltaic technology relatively, their involvements in I-U-G\ncollaboration reach higher rates at 19.35% and 13.23% respectively. Moreover,\nthe two have predominantly collaborated with industry. The trends show that I-UG collaboration is an important route for cooperation on technological\ndevelopment for university and government. By contrast, I-U-G collaboration is\nclearly not as importance to the industry.\nMajority of institutions that provide photovoltaic patents are from the industry,\nthough their involvement in I-U-G collaboration is the lowest (5.87%). On the\nother hand, the number of institutions from university and government is\nrelatively small, but these institutions have been further involved in I-U-G\ncollaboration with at the rates of 34.31% and 32.43%. Again, these institutions\nalso collaborated with the industry. A closer look at the number of different types\nof institutions of each year shows that the number of institutions from university\nhas exceeded that of institutions from the industry since 2010.\nFrom the institution’s perspective, about one third of institutions from both\nuniversity and government have been involved in I-U-G collaboration, showing\nthat institutions from university and government are more receptive to I-U-G\ncollaboration, while the willingness for I-U-G collaboration from the industry is\nlow by comparison. The industry’s frequent collaboration with the university or\nthe government in the early stage of research and development may be part of the\nreasons. Also, the industry tends to develop independent technology. However,\nfurther studies are required to find out specific reasons for this phenomenon.\nThe key institutions in photovoltaic technology in I-U-G collaboration can be\ndivided into two types. First, the institution focuses on I-U-G collaboration; the\nphotovoltaic patents produced by these institutions are mostly the results of I-U-G\ncollaboration. The second type is the institutions with high number of\nphotovoltaic patents but low number of patents from I-U-G collaboration. These\ninstitutions may have participated in I-U-G collaboration, but they moved to the\ndevelopment for photovoltaic patents individually. Further analyses such as cited\nperformance on the collaboration partners of these key institutions can help\nunderstand the patterns that encourage I-U-G collaboration, as well as help to gain\nmore in-depth understanding to I-U-G collaboration.\nReferences\nAtlan, T. (1987). Bring Together Industry and University Engineering Schools,\n“In Getting More Out of R&amp;D and Technology”. The Conference Board,\nResearch Report No. 904.\n\n1389\n\nChen, Z., &amp; Guan, J. (2011). Mapping of biotechnology patents of China from\n1995–2008. Scientometrics, 88(1), 73-89.\nDolfsma, W., &amp; Leydesdorff, L. (2008). Medium-tech’ industries may be of\ngreater importance to a local economy than High-tech’ firms: New methods for\nmeasuring the knowledge base of an economic system. Medical Hypotheses,\n71(3), 330-334.\nEtzkowitz, H. &amp; Leydesdorff, L. (2000). The dynamics of innovation: from\nnational systems and “Mode 2” to a Triple Helix of university-- industry-government relations. Research Policy, 29, 109–123.\nEtzkowitz, H. (2003). Innovation in Innovation: The Triple Helix of University-Industry-- Government Relations. Social Science Information, 42(3), 293-337.\nEtzkowitz, H., &amp; Leydesdorff, L. (1995). The triple helix of university-- industry- government relations: A laboratory for knowledge-based economic\ndevelopment. EASST Review, 14(1), 14-19.\nFrietsch, R., &amp; Grupp, H. (2006). There is a new man in town: the paradigm shift\nin optical technology. Technovation, 26(1), 463–472.\nGao, X., Guan, J., &amp; Rousseau, R. (2011). Mapping collaborative knowledge\nproduction in China using patent co-inventorships. Scientometrics, 88(2), 343362.\nHeffner, A. (1981). Funded research, multiple authorship, and subauthorship\ncollaboration in four disciplines. Scientometrics, 3(1), 5-12.\nKatz, J. S., &amp; Martin, B. R. (1997). What is research collaboration? Research\nPolicy, 26(1), 1-18.\nLee, Y. S. (1996). Technology transfer and research university: A search for the\nboundaries of university industry collaboration. Research Policy, 25(6), 843863.\nLeroy, D., &amp; Doerig, C. (2008). Drugging the Plasmodium kinome: the benefits\nof academia-industry synergy. Trends in Pharmacological Sciences, 29(5),\n241-249.\nLeydesdorff, L., &amp; Meyer, M. (2003). The Triple Helix of university-industrygovernment relations. Scientometrics, 58(2), 191–203.\nManjarrés-Henríquez, L., Gutiérrez-Gracia, A., &amp; Vega-Jurado, J. (2008).\nCoexistence of university-industry relations and academic research: Barrier to\nor incentive for scientific productivity. Scientometrics, 76(3), 561-576.\nMeyer, M., Sinilainen, T., &amp; Utecht, J. T. (2003). Towards hybrid Triple Helix\nindicators: A study of university-related patents and a survey of academic\ninventors. Scientometrics, 58(2), 321-350.\nOrtega, J. L. (2011). Collaboration patterns in patent networks and their\nrelationship with the transfer of technology: the case study of the CSIC\npatents. Scientometrics, 87(3), 657-666.\nPark, H. W., Hong, H. D., &amp; Leydesdorff, L. (2005). A comparison of the\nknowledge-based innovation systems in the economies of South Korea and the\nNetherlands using Triple Helix indicators. Scientometrics, 65(1), 3–27.\n\n1390\n\nPilkington, A., Dyerson, R., &amp; Tissier, O. (2002). The electric vehicle: patent data\nas indicators of technological development. World Patent Information, 24(1),\n5–12.\nSábato, J. &amp; Mackenzi, M. (1982). La Producción de Tecnología. Autónoma o\nTransnacional. Maxico: Nueva Imagen.\n\n1391\n\nPERFORMING INFORMETRIC ANALYSIS ON\nINFORMATION RETRIEVAL TEST\nCOLLECTIONS: PRELIMINARY EXPERIMENTS IN\nTHE PHYSICS DOMAIN (RIP)\nTamara Heck1 and Philipp Schaer2\n1\n\ntamara.heck@uni-duesseldorf.de\nHeinrich-Heine-Universität Düsseldorf, Universitätsstr. 1, 40225 Düsseldorf (Germany)\n2\n\nphilipp.schaer@gesis.org\nGESIS – Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, 50667 Köln\n(Germany)\n\nAbstract\n\nThe combination of informetric analysis and information retrieval allows a twofold\napplication. (1) While informetrics analysis is primarily used to gain insights into a\nscientific domain, it can be used to build recommendation or alternative ranking services.\nThey are usually based on methods like co-occurrence or citation analyses. (2)\nInformation retrieval and its decades-long tradition of rigorous evaluation using standard\ndocument corpora, predefined topics and relevance judgements can be used as a test bed\nfor informetric analyses. We show a preliminary experiment on how both domains can be\nconnected using the iSearch test collection, a standard information retrieval test collection\nderived from the open access arXiv.org preprint server. In this paper the aim is to draw a\nconclusion about the appropriateness of iSearch as a test bed for the evaluation of a\nretrieval or recommendation system that applies informetric methods to improve retrieval\nresults for the user. Based on an interview study with physicists, bibliographic coupling\nand author-co-citation analysis, important authors for ten different research questions are\nidentified. The results show that the analysed corpus includes these authors and their\ncorresponding documents. This study is a first step towards a combination of retrieval\nevaluations and the evaluation of informetric analyses methods.\n\nConference Topic\n\nOld and New Data Sources for Scientometric Studies: Coverage, Accuracy and Reliability\n(Topic 2), Research Fronts and Emerging Issues (Topic 4) and Open Access and\nScientometrics (Topic 10).\n\nIntroduction\nInformetric analyses are generally used to gain insights into a scientific domain\nand to better understand scholarly activities. A common approach is the use of\nstatistical modelling or visualization techniques to get a more profound overview\nof a scientific domain or a specific topic. The process of science modelling tries to\ndescribe and formalize these approaches. Examples for methods that are used in\n1392\n\nthe science modelling community are co-occurrence or co-authorship analyses or\nbibliographic coupling (see Scharnhorst, Börner &amp; Besselaar, 2012). While in\nmost cases these models are used to make scientific rankings or to draw so-called\nscience maps, some approaches try to combine science modelling and information\nretrieval (IR) research (Mutschke et al., 2011).\n\nFigure 1. Mutual benefits of IR test collections and informetric analysis methods.\n\nAuthors like Ingwersen (2012) propose a more application-driven view on\ninformetrics. The main idea is that a more profound insight into a science system\ncan be exploited to support the search process in a scholarly information system.\nEntities that are usually observed are authors, topics or publication organs like\njournals, publishers etc. The more we know about the different entities and their\nconnection to each other in the scientific publication system, the more we can use\nthis information to enrich the retrieval process. A classic example of this is the\nBradfordizing method proposed by White (1981), where typical power-law\ndistributions in bibliographic data sets are used to offer a different ranking\nmechanism. Up to then Bradford’s Law was only used to detect core journals in a\nscientific field but this qualitative information was not used in actual retrieval\nsystems. It was clearly shown that highly co-occurring attributes have a strong\nselectivity and can be applied as a ranking weight which can lead to different\nview on the document space (Schaer, 2011).\nWhile in the IR community a decades-long evaluation tradition exists (with\nevaluation campaigns like TREC131 or CLEF132), informetrics lacks this kind of\ntradition. To overcome this gap Mutschke et al. (2011) proposed the use of\nstandard IR evaluation methods as a test-bed and “litmus test” for science models.\n131\n132\n\nhttp://trec.nist.gov\nhttp://www.clef-initiative.eu\n1393\n\nThe interconnection between IR test collections, IR evaluation methodologies and\ninformetrics is shown in figure 1. The overall idea is an informetrics-enhanced IR\nsystem that incorporates all the previous elements to complement existing\napproaches through a deeper understanding of informetric science models.\nThe following paper describes the outcomes of a preliminary experiment on\nanalysing a standard IR evaluation collection. We used the iSearch133 test\ncollection as well as data derived from an earlier experiment and an interview\nseries with physicists. The information from the experiment is used to cross-check\nwhether (a) the specific topics the physicists were interested in and (b) the\nimportant authors identified during the interviews are included in the iSearch\ncorpus. If the results are positive, this standard IR corpus might serve as a basis\nfor further retrieval and science model testing.\nIn the next section we will describe both data sets we want to map: the iSearch\ntest collection and the topics and important authors extracted from social\ninformation and informetric analyses as well as interviews. Thereafter the results\nof the mappings are summarised and we will discuss the outcomes of this\npreliminary experiment in the final section.\nData Sets\nThe iSearch Test Collection\nThe iSearch test collection (Lykke et al., 2010) consists of the three standard parts\nof an IR test collection: (1) a corpus of documents, (2) a set of topics, and (3)\nrelevance assessments. The corpus consists of documents from the physics\ndomain: 18,222 monographic library records, 160,168 scientific papers and\njournal articles in PDF full texts and their corresponding metadata, as well as\n274,749 abstracts with their corresponding metadata. Additionally the data set\nincludes more than 3.7 million extracted internal citations. The monographic\nrecords were extracted from the Danish National Library and the full text and\nmetadata sets were crawled from the arXiv.org open-access/preprint repository.\nThe set of 65 topics and their relevance assessments (~200 per topic) were\nextracted from 23 lecturers, PhD and MSc students from three physics\ndepartments. Up to now this test collection was mainly used in the domain of\ncontextual and task-based IR research because of the rich and realistic search\ntasks that allow an in-depth analysis of user intentions and expectations in the\nretrieval task.\nThe deposition of article preprints at arXiv.org is usually best practice in most\nphysics working groups, and so we see potential in the document corpus itself\nbecause of the size and coverage. This corpus is a rich document set from a\nscientific domain (in contrast to other data sets without the scientific and\ndiscipline relatedness, like the typical TREC data sets) and includes everything\nneeded to carry out an IR evaluation (in contrast to other scientific literature\n133\n\nhttp://itlab.dbit.dk/~isearch/?q=node/1\n\n1394\n\ncorpora like INSPEC, Scopus or the Web of Science). On the other hand an\nauthor who deposits his paper is only supposed to provide a minimal set of\n(unstructured) metadata. In fact there are very few instructions and rules on how\nto enter the metadata. This results in a large but very heterogeneous document set.\nTopics and Important Authors in the Physics Domain\nTo find out which resources are relevant for a user and which are not, user\nfeedback and relevance judgements are needed. iSearch only includes such\njudgements for documents, but since we want to focus on important authors we\nneed additional information. In our approach we obtained this user information\nfrom semi-structured interviews. These evaluations were part of a project to\nrecommend collaboration partners to ten participating scientists (Heck, Peters &amp;\nStock, 2011). The aim was to recommend to a researcher authors who have\nsimilar research interests and thus could be potential collaborators. Therefore the\ninterviewees should state whether the recommended authors are important for\ntheir current research.\nThe author names the physicists should evaluate were extracted using social\ninformation data. In the Web of Science134 author names were gained using\nbibliographic coupling of authors, i.e. authors who have many references in\ncommon with the target researchers (the physicists) are supposed to be similar.\nThus their written papers might be relevant and they might be potential\ncollaboration partners. In Scopus135 those authors who were co-cited many times\nwith our target researchers were extracted (White &amp; Griffith, 1981). In\nCiteULike136 those authors were supposed to be similar whose articles have tags\n(assigned by the service’s users) in common with the target researchers’ articles,\nor whose articles were bookmarked by users, who also bookmarked the target\nscientists’ papers (collaborative filtering, see e.g. Marinho et al., 2011). These\nauthor names were rated by the target scientists on a scale from 1 (not relevant for\ncurrent research) to 10 (highly relevant for current research). Furthermore each\nphysicist described his research interests with specific terms during the interview.\nData Mapping in the iSearch Corpus\nDesign of the Experiment\nTo prove the assumptions formulated in the introduction we first have to test\nwhether the iSearch corpus is an appropriate tool to do such experiments. One\ncriterion is that the set includes articles written by the important authors identified\nin the interviews. If the physicist searches for literature in his research domain, he\nwould expect to find articles that are very relevant for his research topic. Thus the\narticles should be written by those authors the physicist has claimed important for\n134\n\nhttp:/www.webofknowledge.com\nhttp:/www.scopus.com\n136\nhttp://www.citeulike.org/\n135\n\n1395\n\nhis research. For the analysis of the iSearch corpus we use those authors the target\nphysicists claimed important for their current research. We call them important\nauthors. Important authors are those authors who in the evaluation process were\nrated with 5 or higher and who were explicitly named by the physicists. If the\niSearch corpus includes articles from these authors – derived from methods like\nauthor-co-citation and bibliographic coupling – a retrieval system including\ninformation from science models could be evaluated on the basis of this corpus.\nTable 1. Descriptions of research interests and research topics of the 10 physicists\nTopic ID Description of research interest\nsci001\nModelling blood flow processes relating to viscosity and the formation of\ndiseases. Analysing properties of polymers and microswimmers for medical\nobligations.\nsci002\nBiomolecular multiscale simulations concerning Alzheimer disease. Analysing\nprotein aggregation and protein-protein interaction like amyloid ß-peptide.\nsci003\nMultiscale protein modelling and computational simulation. Analysing the\nproperties and dynamics of fluids and polymers.\nsci004\nInterested in polymer catalysis and neutron scattering.\nsci005\nAnalysing polymer-membrane interactions and the diffusion of red blood cells.\nsci006\nSpintronics in carbon nanostructures, carbon nanotubes and the raman\nspectroscopy.\nsci007\nInterested in photoelectron spectroscopy, (ferro) magnetic and electronic\nproperties.\nsci008\nSimulation of crumpled elastic sheets and its mechanical deformation. Buckling\nof capsid proteins.\nsci009\nX-ray and neutron scattering in high-correlated electron systems and the\nbuilding of instruments.\nsci010\nAnalysing dynamics of glass-forming liquids. Interested in inelastic neutron\nscattering, dielectric spectroscopy and rheology. Doing simulations of polymers\nand other amorphous material.\n\nIn the interview each physicist described his research interests and research\nfocuses with appropriate terms (see table 1). Our assumption is: If the physicist\nsearches for literature he would probably use those terms as search terms he used\nto describe his research interest and research focus with. Thus the terms derived\nfrom the descriptions of the physicists’ research focus (further described as topics\nsci001 – sci010) are used as search terms in the iSearch corpus. As some single\nterms would describe a research focus in a very common way, these terms are\nonly used in combination; therefore the actual query composition was done\nmanually based on the outcomes of the interviews to best reflect the physicists’\ninterests. We indexed all available metadata (~453,000) and the full text data sets\n(~160,000) in the Solr137 search engine and applied a standard Porter stemmer and\n137\n\nhttp://lucene.apache.org/solr\n\n1396\n\nan English stop-word list. The search is done using Solr’s standard retrieval\nmethod, which is based on an extended Boolean model that allows the extraction\nof co-occurring entities (facets). We extracted all author names and the number of\ntheir articles from the retrieved documents. We only focused on authors and will\nleave the analysis of journals and references for future work.\nResults\nThe physicists named 18 to 55 authors who are relevant for their current research\n(column 2 in table 2). We searched for those authors in the iSearch corpus. To\nsecure correctness of the important authors and obviate author ambiguity, the\nauthor names were verified manually on the basis of co-authorship, article title\nand journal title. In our results we analysed two aspects, namely the important\nauthors and their articles. We used three different data sets:\n1. The whole iSearch corpus.\n2. One subset per physicist, which was retrieved using the physicist’s topicdescribing terms by searching in title, abstract and full text (see previous\nsection).\n3. The top 50 documents of set number 2 ranked by Solr’s TF*IDF\nimplementation.\nThe left part of table 2 shows the coverage of the authors in the iSearch corpus,\nmeaning at least one document of an important author can be found in the corpus.\n199 of 287 unique important authors (IA) are in the corpus; on average they have\nnearly 19 articles in iSearch. For each topic at least 57% of IA are in the iSearch\ncorpus. Sci006, with 29 named IA, even has 100% coverage. When using the\nterms describing the physicists’ research interests as query terms (the subsets),\nnearly 70% of the previously named IA were included. But under the top 50\nranked articles there are on average only 4.8 IA. Of course the coverage depends\non the time the corpus was created. Some interviewed physicists are rather novice\nresearchers, i.e. they also named novice physicists, who are not in iSearch, as\nimportant for their research.\nIn the right part of table 2 we report on the coverage of the documents authored\nby the important authors (IAD) within the three described document pools. Note\nthat the numbers of IAD in iSearch are approximated as it cannot be proved that\nevery single document is really written by the correct important author. That\nmeans author ambiguity can be eliminated in the top 50 documents and for the\nmost part in the subsets, but not in the corpus. Column 6 in table 2 (total docs in\ntopic subset) shows the number of documents that are found with the topics\nshowed in table 1. In these subsets the number of articles written by IA (column\nIAD in topic subset) ranges from just 11 documents for topic sci002 up to 426 for\ntopic sci006 (avg. of 164.7). Within the top 50 documents on average only 4.8\nIAD were included. For two topics (sci002 and sci007) no single IA or IAD were\nincluded in the top 50 documents.\nConcerning both IA and IAD the coverage under the top 50 articles is weaker than\nin the total iSearch corpus and in the subsets. For example: Sci007 named 18\n1397\n\nimportant authors. 16 of them are in the iSearch corpus. But a search with the\nquery terms derived from the descriptions of the researcher’s interests ranks no\narticles of IA under the top 50. Nevertheless in sci007 207 articles (IAD in topic\nsubset) of 15 important authors (IA in topic subset) are found with the query\nterms determined by the physicist’s research interest descriptions. Moreover, no\ncorrelation could be detected between the size of the topic subsets and the number\nof IA and IAD found within these subsets, i.e. you cannot state that the bigger the\nsubset is, the more IA and IAD are included. E.g. sci003 has over 90,000\ndocuments in the subset. All IA found in the total iSearch corpus are included in\nthis subset, and about 86% of the IAD. But sci004, with only 16,042 documents,\nhas similar results. Here all but one IA are included in the subset as well as 62%\nof the IAD. Sci008, which has more than twice as many documents as sci004,\ncovers only about 65% of IA and about 20% of IAD. To summarize, it can be said\nthat the coverage of IA and IAD is quite high in the iSearch corpus (nearly 70%\nof IA could be found) but in the subsets and especially in the top 50 ranked\ndocuments the coverage is quite low in most cases.\n\nTopic\nsci001\nsci002\nsci003\nsci004\nsci005\nsci006\nsci007\nsci008\nsci009\nsci010\navg.\n\nImportant authors\n\nDocuments of important authors\n\nn\na\nm\ne\nd\nIb\nA\nIy\nR\nA\nie\nn\nis\nin\ne\nT\nS\nta\no\neo\nr\ntIac\np\naA\nrh\ni\nlce\nci\nd\nh\nrs\nn\no\nsu\ntc\nb\nIo\ns\nsA\np\niI\ne5\nD\nn\nA\nt0\ntD\nio\nn\np\ni\nin\nS\ntcI\neo\ns\nA\nap\nu\nD\nrib\nccs\nih\nes\nn\ntu\nt\nb\no\nsp\ne5\nt0\n\nA\n\nTable 2. Overview on the coverage of important authors (IA) and documents of\nimportant authors (IAD) within three different document pools: (1) the whole\niSearch corpus, (2) a topical subset and (3) the top 50 TF*IDF ranked documents.\n\n35\n27\n20\n24\n45\n29\n18\n55\n21\n21\n29.5\n\n20\n17\n12\n17\n28\n29\n16\n34\n20\n14\n20.7\n\n7\n7\n12\n16\n24\n28\n15\n22\n18\n14\n16.3\n\n3\n0\n3\n5\n7\n13\n0\n10\n2\n3\n4.8\n\n3152\n1700\n94205\n16042\n25169\n61132\n80846\n39570\n34814\n57368\n41399.8\n\n291\n147\n142\n214\n299\n928\n283\n590\n723\n223\n384\n\n24\n11\n123\n134\n185\n426\n207\n116\n274\n147\n164.7\n\n3\n0\n2\n4\n12\n10\n0\n11\n1\n5\n4.8\n\nDiscussion and Future Work\nWe presented the outcomes of a preliminary experiment of mapping 10 specific\nscientific research interests onto the iSearch corpus. The statements of the\nphysicists about authors being relevant for their current research are used as\nqualitative criterion to draw conclusions about the appropriateness of iSearch for\nevaluating informetric analyses.\nConcerning the quite high coverage of important authors (nearly 70%), we\nassume that the iSearch corpus is appropriate for an evaluation of a retrieval\napproach that uses informetric methods to improve the retrieval process. In the\nfuture project we would like to use the references of the iSearch corpus and build\n1398\n\na retrieval system that also applies bibliographic coupling and co-citation analyses\nto improve the results for the user. For the evaluation we would use not only the\nexternal feedback by the physicists, but also the relevance feedback of the iSearch\ncorpus. However the physicists’ feedback are beneficial because they include\nconcrete relevance ratings of important authors, which can be used to make\nfurther statements about the retrieval results. The relevance feedback in the\niSearch corpus allow statements about the relevance of articles, but not about\nconcrete authors. Both articles and authors might be important for a user who\nsearches for relevant research literature in a retrieval system.\nConcerning the coverage of important authors in the top 50 subset, we suppose\nthat good retrieval results should rank the articles of the important authors at very\nhigh positions. The TD*IDF ranking alone doesn’t seem to be powerful enough.\nIt is assumed that methods like co-citation analysis and bibliographic coupling\nwill improve both document and also author retrieval. It should be tested at which\nstages and in which processes of a retrieval system these approaches could be\napplied. One idea is to re-rank the documents, which were retrieved by e.g. coword analysis. Depending on the users’ need, informetric methods may also be\napplied before co-word approaches and ranking. The analysis of important\njournals is another method to gain more relevant articles.\nReferences\nHeck, T., Peters, I. &amp; Stock, W.G.(2011). Testing collaborative filtering against\nco-citation analysis and bibliographic coupling for academic author\nrecommendation. Proceedings of the 3rd ACM RecSys’11 Workshop on\nRecommender Systems and the Social Web (pp. 16–23). Chicago: ACM.\nIngwersen, P. (2012). Citations and references as keys to relevance ranking in\ninteractive IR. In Proceedings of the 4th Information Interaction in Context\nSymposium (p. 1). New York: ACM.\nLykke, M., Larsen, B., Lund, H. &amp; Ingwersen, P. (2010). Developing a test\ncollection for the evaluation of integrated search. In C. Gurrin, Y. He, G.\nKazai, U. Kruschwitz, S. Little, T. Roelleke, S. Rüger &amp; K. Rijsbergen (Eds.)\nAdvances in Information Retrieval (pp. 627–630). Berlin/Heidelberg: Springer.\nMarinho, L.B., Nanopoulos, A., Schmidt-Thieme, L., Jäschke, R., Hotho, A.,\nStumme, G. &amp; Symeonidis, P. (2011): Social tagging recommender systems.\nIn F. Ricci, L. Rokach, B. Shapira &amp; P.B. Kantor (Eds.) Recommender\nSystems Handbook (pp. 615–644). Berlin: Springer.\nMutschke, P., Mayr, P., Schaer, P. &amp; Sure, Y. (2011). Science models as valueadded services for scholarly information systems. Scientometrics, 89, 1, 349–\n364.\nSchaer, P. (2011): Using lotkaian informetrics for ranking in digital libraries. In\nC. Hoare &amp; A. O’Riordan (Eds.) Proceedings of the ASIS&amp;T European\nWorkshop 2011. Cork: ASIS&amp;T.\n\n1399\n\nScharnhorst, A., Börner, K. &amp; Besselaar, P. van den (Eds) (2012). Models of\nScience Dynamics Encounters Between Complexity Theory and Information\nSciences. Berlin: Springer.\nWhite, H.D. (1981). “Bradfordizing” search output: how it would help online\nusers. Online Information Review, 5, 1, 47–54.\nWhite, H.D. &amp; Griffith, B.C. (1981). Author cocitation: A literature measure of\nintellectual structure. Journal of the American Society for Information Science,\n32, 3, 163–171.\n\n1400\n\nPOSSIBILITIES OF FUNDING\nACKNOWLEDGEMENT ANALYSIS FOR THE\nBIBLIOMETRIC STUDY OF RESEARCH FUNDING\nORGANIZATIONS: CASE STUDY OF THE\nAUSTRIAN SCIENCE FUND (FWF)\nRodrigo Costas1 and Alfredo Yegros-Yegros2\n1\n\nrcostas@cwts.leidenuniv.nl; 2 a.yegros@cwts.leidenuniv.nl\nCWTS-Centre for Science and Technology Studies, Leiden University, PO Box 905\n2300 AX Leiden (the Netherlands)\n\nAbstract\n\nThis paper presents a case study on the presence of funding acknowledgements among\nAustrian publications with a special focus on Austrian Science Fund (FWF). Scientific\npublications funded by the FWF have been studied by means of the bibliographic records\nmaintained by the funding organization and also by the presence of Funding\nAcknowledgements in the publications (FA analysis). It is observed that more than 50%\nof all publications funded by the FWF are detected only by means of the FA analysis, thus\nreinforcing the role of this type of analysis for bibliometric studies of funding\norganizations. Disciplinary differences have also been found, with the Social and\nEconomic sciences showing the lowest rate of funding, but also the lowest rate of properly\nacknowledging their funding sources.\n\nConference Topic\n\nOld and New Data Sources for Scientometric Studies: Coverage, Accuracy and Reliability\n(Topic 2) and Science Policy and Research Evaluation: Quantitative and Qualitative\nApproaches (Topic 3).\n\nIntroduction\nResearch funding organizations play an important role in scientific development\nand they have a strong interesting in studying their role and influence in the\nscientific landscape, particularly through bibliometric indicators. However, one of\nthe challenges for bibliometric studies of funding organizations is how to collect\nreliable data on publications that reasonably can be linked to funded projects by\nthese organizations, or as Hornbostel (2012) already stated “where data about\nfunding should be collected: from the recipient or at the funding institution?”.\nIn this paper we focus on the combination of two approaches that can help to\nsolve this question, namely: the records maintained by the research funding\ninstitution and the publications where the authors (the recipients) acknowledged\ntheir funding sources. Acknowledgments and particularly funding\nacknowledgements (FA) are a common element in science (Tiew &amp; Sen, 2002), as\n1401\n\nauthors of publications indicate through them the sources of funding or economic\nsupport with the research and the publication was made possible. On the other\nhand, funding organizations frequently demand researchers to inform them about\nthe outputs of their funded projects, particularly publications, and may also keep\nrecords of papers that are assumed to result from their funding (Rigby, 2013).\nIn this paper we focus on the Fonds zur Förderung der wissenschaftlichen\nForschung (FWF), the Austrian Science Fund, with the aim of determining how\nthe authors have identified their funding by this organization, both through the\nbibliographic records maintained by the FWF and also by the FAs given in\nAustrian publications.\nObjectives\nThe main objective of this paper is to study the differences and possibilities of\ntwo methods of data collection for the study of research funding organizations:\nthe use of records detected/maintained by the funding organization and the\nanalysis of the FA of scientific publications.\nMethodology - our case study\nThis is a case study on the Fonds zur Förderung der wissenschaftlichen\nForschung (FWF), the Austrian Science Fund, the central funding organization\nfor basic research in Austria. The Austrian Science Fund (FWF) is Austria’s\ncentral\nfunding\norganization\nfor\nbasic\nresearch\n(http://www.fwf.ac.at/en/index.asp).\nPublication data collection of the FWF\nA bibliometric study has been recently developed at CWTS for the FWF (van\nWijk &amp; Costas-Comesaña, 2012). In that study, FWF provided CWTS with a list\nof publications from their own records (period 2001-2010). The publications\nsupplied by the FWF were matched against the CWTS in-hose Web of Science\ndatabase, based on bibliographic elements such as author names, publication year,\njournal title, etc. matching ~80% of all the publications initially supplied.\nThe van Wijk &amp; Costas-Comesaña (2012) study was focused only on the Sciences\nand Social Sciences fields, excluding the Humanities (category 6 as defined by\nthe OECD138). In this study we build upon that database and consider the same\nfield delineation. The time period covers 2009-2010. For this study a manual\ncheck of the unmatched publications was performed in order to increase the\nquality of this data matching process. In table 1 the main figures related with the\nprocessing of the FWF records and their matching with the Web of Science are\npresented.\n\n138\nhttp://www.oecd.org/science/innovationinsciencetechnologyandindustry/38235147.pdf. For the\nmatching of Web of Science with the OECD categories we used an internal classification of journals\nto OECD fields available at CWTS.\n\n1402\n\nTable 1. Main figures regarding the input data from the FWF records.\nFWF System\nTotal records with publication year 2009-2010 from FWF\nMatched in the WoS database\nNon-matched\nUnique matched records\nUnique records matched in the WoS database\nUnique records matched in the WoS database (2009-2010)\n\nRecords\n3198\n2806\n392\nRecords\n2580\n2437\n\nTable 1 shows that the initial input from the FWF system with publication year\nbetween 2009-2010 was composed by 3198 records. Around 88% of these records\nwere effectively matched against the Web of Science. Considering the records\nmatched, duplicated were removed and also some publications with a mismatch\nbetween the publication year in the FWF database and the Web of Science. The\nfinal set of publications was composed by 2437 unique WoS-covered\npublications.\nDetection of variants of the FWF in the Funding Acknowledgements of\npublications\nA second step was the identification of all the variants of the FWF mentions in the\nfunding acknowledgments of scientific publications. This particular difficulty due\nto the low standardization of the funding bodies names (Rigby, 2011) and for this\nstudy this task has been performed manually. As a result more than 400 variants\nof the FWF were identified in the database.\nIndicators\nFor some of the analysis, particularly citation analysis we have employed the\nCWTS standard methodology and indicators (Waltman et al, 2011a, 2011b). In\nthis sense, the results presented in the citation analysis can be slightly different\nfrom that of the publication analysis (see Results Table 2 and following). The\nmain indicators included in the analysis are: P (number of articles, letters and\nreviews; in the citation analysis letters have been weighted by 0.25), TCS (total\nnumber of citations received up to 2011, self-citations excluded), MCS (mean\ncitation score), MNCS (mean normalized citation score, this is a measure of the\nimpact of publications compared to the world citation average in the WoS subject\ncategories of the publications), MNJS (mean normalized journal score, this is the\nimpact of the journals in which publications are published, compared to the world\ncitation average in the fields covered by these journals).\nResults\nAnalysis of publications\nIn this section we present the main results regarding the analysis of the Austrian\nand FWF publications. Austria presents a total of 30362 publications (considering\n1403\n\nall document types) during the period 2009-2010. However, when limited to the\nsame fields that were considered in the FWF study (van Wijk &amp; Costas, 2012 –\nexcluding the Humanities fields) the final set of publications for the country is\n29883.\nIn Table 2 we present the analysis of the presence of FA across different groups\nof publications, particularly taking into account the role of FWF in them.\nTable 2. Coverage of FWF funded publications within Austrian publications in WoS\nperiod 2009-2010.\nMatching\n\nAustrian WoS records\nFWF records\nNon-FWF\n\nAustrian papers with any FA\n\nRecords\n\n29883\n2347\n27536\n\n12202\n\nAustrian papers with FA to FWF\n\n4146\n\nFWF records\n\n2347\n\n** With FA to FWF\n\n1700\n\n** Without FA to FWF\n\n647\n\nPublications with FA to FWF but not in FWF records\n\n2446\n\nTotal FWF funded publications\n(FWF records without FA + Publications with FA to\nFWF but not in FWF records)\n\n4793\n\n% in FWF records\n% not in FWF records\n\n2347\n2446\n\n% Observations\n\n100\n\n90 records didn’t have an\n8 Austrian address\n92\n\n41\n\n% based on the Austrian\n\n34 papers with FA\n\n% of publications in the FWF\nsystem that include FA to the\n72 FWF\n% of publications in the FWF\nsystem without FA to the\n28 FWF\n\n100\n49\n51\n\nTable 2 shows how FWF has funded ~8% of Austrian publications. Regarding the\npublications included in the FWF records 72% of them have in fact an FA to the\nFWF, while 28% of the publications covered in the FWF records do not hold such\nacknowledgement to the funder (although of course lately acknowledged by the\ninclusion of the publication in the FWF database). It is remarkable that 2446\npublications have acknowledgements to the FWF but they are missing from the\nFWF records. Thus, if we consider all the publications that by any of the two\napproaches (i.e. FWF records or FA) show a funding relationship with the FWF\nwe end up with 4793 publications. This means that ~51% of the funded\npublications by the FWF are missing from FWF records, while ~14% are detected\nonly through their records but not through the FA analysis. This is also an\ninteresting result, the fact that 14% of FWF publications (from the combination of\nFA and FWF records) do not have an acknowledgement suggest that somehow\n1404\n\nthe authors ‘forget’ at the time of publication that they should acknowledge the\nFWF. This would be then the lower bound of what we could consider the “FA\nforgetfulness”, although in this account we would still be missing those\npublications that should have acknowledged some funding by the FWF but they\ndidn’t do it in any way (nor by FA neither reporting the FWF).\nCitation analysis\nIn table 4, we compare the impact of the Austrian publications depending on the\nfact if they have funding or not.\nTable 4. Funded vs. non-funded publications.\nPublications\nNon-funded\nFunded\n\nP\n\n10673.5\n12193.25\n\n% pubs\n46.7\n53.3\n\nTCS\n31416.69\n60816.96\n\n% cits\n34.1\n65.9\n\nMCS\n2.94\n4.99\n\nMNCS\n0.97\n1.51\n\nMNJS\n0.92\n1.35\n\nIn this table the number of funded publications outperforms that of the nonfunded publications. It must be taken into account that some document types have\nbeen excluded for the citation analysis and that letters are weighted by 0.25. This\nmeans, as compared to table 2, that a substantial amount of publications without\nfunding are document types not included in the citation analysis. Regarding the\nimpact of the publications, publications with FA present a higher impact in all\nindicators, which is in line with previous studies (Costas &amp; van Leeuwen, 2012).\nIn table 5 all publications that have detected to be funded by the FWF are\ncompared to the rest of the country.\nTable 5. FWF vs. non FWF publications in Austria\nPublications\nNon FWF\nTotal FWF\n\nP\n18125.75\n4737\n\n% pubs\n79\n21\n\nTCS\n71206\n21009.75\n\n% cits\n77\n23\n\nMCS\n3.93\n4.44\n\nMNCS\n1.23\n1.37\n\nMNJS\n1.10\n1.32\n\nPublications with funding from the FWF present in general a higher impact as\ncompared to that of the rest of Austria. This is in line with the results by van Wijk\n&amp; Costas-Comesaña (2012).\nThe next question is about the impact of the publications that show an FA to the\nFWF but are not recorded in the system of the FWF compared to those that are in\nthe FWF records (table 6).\nTable 6. FWF records vs. Only FA to FWF\nPublications\nOnly FA to FWF\nFWF records\n\nP\n2443\n2294\n\n% pubs\n51.6\n48.4\n\nTCS\n10352.0\n10657.8\n\n%cits\n49.3\n50.7\n\nMCS\n4.24\n4.65\n\nMNCS\n1.39\n1.36\n\nMNJS\n1.32\n1.32\n\n1405\n\nThe publications that are retrieved only through their FAs amount to some more\nthan 51% of all publications funded by the FWF. Again, differences with table 2\nare explained by the limitation of document types that are considered for citation\nanalyses (i.e. articles, reviews and weighted letters). Regarding the number and\nshare of citations to both groups, the publications that are only retrieved through\nFAs attract around 49% of all the citations of the organization. The MNCS\nindicator shows that these publications are slightly more cited than those\npublications that are in the system of the FWF (when normalizing by publication\nyear, document type and fields), although the differences are small.\nDisciplinary analysis\nIn this section we present a distribution of publications across fields. We focus\nagain on all document types with the intention of showing the presence of\npublication with and without funding (also with and without FWF participation)\nacross fields. For the disciplinary classification we have used the Dutch NOWT\n(Dutch Observatory of Science and Technology - http://nowt.merit.unu.edu/)\nclassification (Table 7).\nTable 7. FA analysis by fields (Austria and FWF)\nNOWT Discipline\nMEDICAL SCIENCES\nCHEMISTRY, PHYSICS\nAND ASTRONOMY\nLIFE SCIENCES\nEARTH AND\nENVIRONMENTAL\nSCIENCES\nMATHEMATICS,\nSTATISTICS AND\nCOMPUTER SCIENCE\nENGINEERING\nSCIENCES\nSOCIAL SCIENCES\nECONOMICS,\nMANAGEMENT AND\nPLANNING\nHEALTH SCIENCES\nMULTIDISCIPLINARY\nJOURNALS\n\n(1)\n\nP\n\nP with\nfunding\n(any)\n\nPubs\nPubs\n%pubs\nonly in\n%FA\nonly\nTotal %gene- only\nFWF\n&#x27;forget\nFA to\nFWF ral FA FA to\nsystem\nfulness&#x27;\nFWF\nFWF\n(1)\n757\n460\n127 884\n26.0\n52.0\n14.4\n\nPubs Pubs\nin\nwith\nFWF FA to\nsystem FWF\n\n14203\n\n3686\n\n424\n\n6098\n\n3857\n\n816\n\n1583\n\n981\n\n214 1797\n\n63.3\n\n54.6\n\n11.9\n\n5734\n\n3261\n\n754\n\n1206\n\n599\n\n147 1353\n\n56.9\n\n44.3\n\n10.9\n\n2451\n\n1414\n\n221\n\n422\n\n251\n\n50\n\n472\n\n57.7\n\n53.2\n\n10.6\n\n1830\n\n948\n\n275\n\n518\n\n349\n\n106\n\n624\n\n51.8\n\n55.9\n\n17.0\n\n1826\n\n757\n\n96\n\n171\n\n121\n\n46\n\n217\n\n41.5\n\n55.8\n\n21.2\n\n1067\n\n91\n\n32\n\n24\n\n17\n\n25\n\n49\n\n8.5\n\n34.7\n\n51.0\n\n708\n\n31\n\n34\n\n13\n\n10\n\n31\n\n44\n\n4.4\n\n22.7\n\n70.5\n\n505\n\n115\n\n19\n\n16\n\n7\n\n10\n\n26\n\n22.8\n\n26.9\n\n38.5\n\n237\n\n165\n\n40\n\n66\n\n37\n\n11\n\n77\n\n69.6\n\n48.1\n\n14.3\n\nWithout FA to FWF but in FWF records.\n\nTable 7 shows that the fields with more funding acknowledgements are\nChemistry, Physics and Astronomy, Earth and Environmental Sciences, Life\nSciences and Mathematics, Statistics and Computer Science, all of them with\nmore than 50% of their publications acknowledging some kind of funding. On the\nother hand, the fields with the lowest levels of funding are those of the Social\nSciences and Economics, Management and Planning with less than 10% in both\n1406\n\ncases. Another important aspect is the fields where the FA approach retrieves\nmore publications than the FWF records. These fields are the Medical Sciences,\nChemistry, Physics and Astronomy, Earth and Environmental sciences,\nMathematics, Statistics and Computer Sciences or Engineering Sciences. The\nfields where the FA analysis retrieves fewer publications are particularly Social\nSciences and Economics, Management and Planning where the FA approach\nbrings less than 30% of the publications funded by the FWF. Finally, if we focus\non the percentage of FA ‘forgetfulness’ (i.e. the percentage of publications that\nare in the FWF system but they don’t carry any FA to the FWF), we can see how\nthis is particularly high in the Social and Economic sciences (particularly in the\nsecond) being higher than 50% in both cases. Interestingly, we can see a kind of\nnegative relationship between the share of FA across disciplines and the share of\n‘forgetfulness’ of acknowledgements in the fields, this probably suggesting that in\nthose fields where funding is less frequent, the ‘culture’ and tradition of\nacknowledging funders is less established and therefore the authors ‘forget’ more\nfrequently the acknowledgements of their funders, thus also indicating that the\nlower share of FA observed in this study and in other studies for these fields (e.g.\nCostas &amp; van Leeuwen, 2012) could be relatively underrepresented.\nDiscussion of the results and further research\nThis paper presents a cross-field case study on the presence of funding\nacknowledgements among the publications funded by the Austrian Science\nFoundation – FWF using the new information gathered by Thomson Reuters Web\nof Science from the funding acknowledgements of scientific publications. This\nstudy presents different important novel elements: in the first place, to the best of\nour knowledge there are no other studies that combine the analysis of records\ncollected and verified by a research funding organization, together with an\nextensive FA analysis. Secondly, there are no studies that have checked the\nimpact of these publications and how the results can differ depending on the data\ncollection method; and thirdly, there are no studies that have performed such an\nanalysis across fields as in this case.\nThe development of this study already signals one of the most important\nchallenges that this new FA analysis presents, namely, the great variance in the\nnames of the funding organizations (. Another important result of this study is that\nmore than 50% of the publications funded by the FWF are not included in the\nFWF records. The main explanation for this observation is the situation that the\nFWF gathers the publication information from the final reports of the projects.\nThus, those publications that are published after the finalization of the project are\nlost from these records. Therefore, this result is informative of the important\namount of publications (and citations) that could be lost in the records of funding\nagencies as we can argue that this problem is not only for the FWF but likely for\nmost research funding agencies all around the world. Thus, it can be suggested\nthat the analytical combination of FA analysis with the records maintained in the\nsystems of funding agencies (or in other words, the combination of the recipient\n1407\n\nand funder information) is the best approach in order to grasp the most complete\npicture of the activities and influence of these organizations.\nAs a conclusion, it can be suggested that FA analysis has a strong potential for the\nstudy of funding organizations and how they are shaping and influencing the\nscientific landscape. One open question that however still remains is about the\nshare of publications for which authors should acknowledge funding but they\ndon’t do it at all. This question should be addressed in the future in order to\ndetermine the real scope of FA analysis.\nAcknowledgments\nThe authors acknowledge all the valuable comments and suggestions by Falk\nReckling, Ralph Reimann and Rudi Novak from the Austrian FWF.\nReferences\nCostas, R. &amp; van Leeuwen, T.N. (2012). Approaching the “reward triangle”:\ngeneral analysis of the presence of funding acknowledgments and “peer\ninteractive communication” in scientific publications. Journal of the American\nSociety for Information Science and Technology, 63(8), 1647-1661.\nVan Wijk, E. &amp; Costas-Comesaña, R. (2012). Bibliometric study of FWF Austrian\nScience Fund 2001-2010/11. Leiden: CWTS-Leiden University.\nHornbostel, S. (2001). Third party funding of German Universities. An indication\nof research activity? Scientometrics, 50(3): 523-537.\nRigby, J. (2011). Systematic grant and funding body acknowledgement data for\npublications: new dimensions and new controversies for research policy and\nevaluation. Research Evaluation, 20(5), 365-375.\nRigby, J. (2013). Looking for the impact of peer review: does count of funding\nacknowledgements really predict research impact? Scientometrics, 94, 57-73.\nTiew, W.S. &amp; Sen, B.K. (2002). Acknowledgement patterns in research articles: a\nbibliometric study based on Journal of Natural Rubber Research 1986-1997.\nMalaysian Journal of Library &amp; Information Science, 7(1), 43-56.\nWaltman, L., van Eck, N.J., van Leeuwen, T.N., Visser, M.S. &amp; van Raan, A.F.J.\n(2011a). Towards a new crown indicator: some theoretical considerations.\nJournal of Informetrics, 5(1), 37-47.\nWaltman, L., van Eck, N.J., van Leeuwen, T.N., Visser, M.S. &amp; van Raan, A.F.J.\n(2011b). Towards a new crown indicator: an empirical analysis.\nScientometrics, 87(3), 467-481.\n\n1408\n\nPREDICTING AND RECOMMENDING POTENTIAL\nRESEARCH COLLABORATIONS\nRaf Guns1 and Ronald Rousseau2\n1\n\nraf.guns@ua.ac.be\nUniversity of Antwerp, Institute for Education and Information Sciences, IBW,\nVenusstraat 35, B-2000 Antwerp, Belgium\n2\n\nronald.rousseau@khbo.be\nUniversity of Antwerp, Institute for Education and Information Sciences, IBW,\nVenusstraat 35, B-2000 Antwerp, Belgium\nVIVES (Association KU Leuven), Faculty of Engineering Technology,\nZeedijk 101, B-8400 Oostende, Belgium\nKU Leuven, B-3000 Leuven, Belgium\n\nAbstract\n\nWe study research collaborations between cities in Africa, the Middle East and SouthAsia, focusing on the topics of malaria and tuberculosis. For this investigation we\nintroduce a method to predict or recommend high-potential future (i.e., not yet realized)\ncollaborations. The proposed method is based on link prediction techniques. A weighted\nnetwork of co-authorships at the city level is constructed. Next, we calculate scores for\neach node pair according to three different measures: weighted Katz, rooted PageRank,\nand SimRank. The resulting scores can be interpreted as indicative of the likelihood of\nfuture linkage for the given node pair. A high score for two nodes that are not linked in\nthe network is then treated as a recommendation for future collaboration.\nResults suggest that – of the three measures studied – the weighted Katz method leads to\nthe most accurate predictions. Cities that often take part in new intercity collaborations are\nreferred to as facilitator cities.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6)\n\nIntroduction\nResearch collaboration is an important topic in informetrics. Collaboration has the\npotential of saving costs and diffusing insights and ideas between partners, a point\nalso made in (Liu, Rousseau &amp; Guns, 2013). Hence, the advantages of\ncollaboration are especially attractive to institutes in those regions or countries\nthat do not yet belong to the ‘rich and famous’ in science. While it may seem\nmost attractive to collaborate with wealthier regions, there are several advantages\nwhen collaborating among developing nations, such as the establishment of local\ncentres of excellence and a greater awareness among partners of the needs and\nproblems common to developing nations (Boshoff, 2010).\n\n1409\n\nIn this article, we study research collaboration between cities in Africa, the\nMiddle East, and South-Asia. We construct co-authorship networks among these\ncities within the research fields of malaria and tuberculosis during three\nconsecutive, five-year time periods: 1997–2001, 2002–2006, and 2007–2011. Our\naim is to develop a methodology for recommending potentially fruitful\ncollaborations, using link prediction techniques. By comparing the\nrecommendations for the first period with actual collaborations in the second, and\nrecommendations for the second period with actual collaborations in the third, we\ncan evaluate the quality of our recommendations.\nIn the next section, we discuss how the data has been collected. Subsequently, we\ndiscuss the extraction of the collaboration networks. We then explain our link\nprediction approach and highlight the recommended collaborations. The final\nsection contains the conclusions.\nFramework for data collection\nCities located in the following countries (referred to as the target countries) are\nincluded if they have contributions in the field under study:\n all African countries;\n all countries in the Middle East, except for Israel and Turkey (considered\nto be more European oriented);\n countries in South-Asia, that is, all Asian countries excluding countries\nthat belong to the former Soviet Republic, Mongolia, China, North and\nSouth Korea, Taiwan and Japan.\nAs we are interested in collaborations between African and/or South-Asian cities\non specific topics, we were seeking topics that were not entirely dominated by\nWestern countries on the one hand, and not too specific to a certain country or\nregion (The STIMULATE-6 Group, 2007) on the other. After some\nexperimentation, we settled upon two diseases as topics: malaria and\ntuberculosis.\nThe data were collected from Thomson Reuters’ Web of Science (WoS) on\nOctober 26 and November 21, 2012. We searched for all publications published in\nthe three five-year periods (1997–2001, 2002–2006, 2007–2011) with at least one\naddress in one of the target countries. These sets were then restricted to the two\ntopics. Results are summarized in Table 7.\nTable 7. Numbers of publications for each topic and period\nTopic\nmalaria\ntuberculosis\n\n1410\n\nNumber of publications\n1997–2001\n2,622\n2,369\n\n2002–2006\n4,671\n3,830\n\n2007–2011\n7,901\n7,832\n\nTable 8. Number of cities in the data\nTopic\nmalaria\ntuberculosis\n\nNumber of cities (African and South-Asian / other)\n1997–2001\n2002–2006\n400 / 361\n601 / 587\n351 / 270\n482 / 468\n\n2007–2011\n904 / 883\n831 / 777\n\nMethods\nAfter exporting the search results from the WoS, we extracted a weighted network\nof co-authorship between cities as follows (for both topics and for each time\nperiod). For each publication, the city of each author’s (primary) affiliation was\nrecorded. A script was written to extract the city automatically. However, because\nof the large variety of address formats and inconsistencies in the data, all results\nwere manually checked and corrected where necessary. Table 12 summarizes the\nresults.\nSubsequently a network was created whose node set consists of all cities\nencountered. All cities that co-occur on a single publication are then linked in the\nnetwork. The weight of the link between cities A and B is the number of\npublications with authors from A and B. Because our analysis is on the level of\ncities rather than individuals, we have not taken into account the number of\nauthors from a city on a single publication. For instance, a publication with five\nauthors from city A and three from city B is treated the same as a paper with one\nauthor from A and one from B.\nSome publications in our data have co-authors from cities outside the set of target\ncountries (see ‘other’ in Table 2). Therefore, we decided to create two networks\nfor each topic: a network including these external cities – the full network – and a\nnetwork excluding them – the restricted network. In total, this procedure led to\ntwelve different networks: a full and a restricted network for each of the two\ntopics, and this for each of the three periods.\nCollaboration network structure\nUsing VOSViewer (Van Eck &amp; Waltman, 2007, 2010) we obtained twelve\nvisualizations of our data: one for each network.\nThe malaria networks can be described as follows. In the full view (period 1997–\n2001) we can first see a dense main cluster dominated by Oxford, London and\nBangkok; Indian cities (New Delhi) have a peripheral position. During the period\n2002–2006 the main cluster is dominated by London, Bangkok and Nairobi.\nIndian cities have moved closer to the main cluster. Finally, during the period\n2007–2011 we have a strong main cluster, including Indian cities, and dominated\nby London and Oxford. When considering the restricted networks the 1997–2001\nview is rather scattered with centres in Nairobi and Bangkok, with some\nVietnamese cities between these two centres; Indian cities are situated far away\nfrom these clusters. During the period 2002–2006 the Vietnamese cluster has\nalmost merged with the Thai one. Finally during the period 2007–2011 there is a\nclear African cluster (Nairobi, Dakar, Cape Town) and an Asian one (Bangkok,\n1411\n\nMae Sot, New Delhi) as can be seen in Figure 11. Moreover an Iranian group of\ncities becomes visible on the periphery.\n\nFigure 11. Collaboration network for malaria (restricted view, 2007–2011)\n\nAs to the tuberculosis networks, the 1997–2001 full view shows a group of\ncentres around London, Geneva, Atlanta, Paris and Johannesburg. These are\nsituated rather close to one another. During the period 2002–2006 these groups\nhave formed a main cluster where we see London, Geneva, Paris, New Delhi and\nOxford; Dhaka (Bangladesh) is clearly visible above this main cluster, while\nAntwerp and Brussels (Belgium) are situated in the very centre of this figure\n(Figure 12). In the 2007–2011 view we again have several clusters situated close\nto one another. The largest, central, one contains London, Paris, Geneva, Cape\nTown, Kampala and Liverpool; close to this main cluster we have an Indian\ncluster around New Delhi and Chennai; we further have clusters around Taipei\nand around Tehran. The 1997–2001 restricted network contains several scattered\nclusters around the following centres: South-Africa (Cape Town, Tygerberg,\nJohannesberg), Chennai-Pune, another Indian one around New Delhi, Bangalore\nand including Bangkok, and finally one around Addis Ababa (Ethiopia). The\n2002–2006 view is very linear with centres around New Delhi, Hanoi, Bangkok\nand Cape Town (and other South African cities) including Dakar (Senegal).\nFinally the restricted 2007–2011 view contains a large cluster around Cape Town\n\n1412\n\n(and South African cities) and including Addis Ababa. Moreover we see an Indian\ncluster, a Thai one and an Iranian one on the periphery.\n\nFigure 12. Collaboration network for tuberculosis (full view, 2002–2006)\n\nIn summary, the following observations pertain to both topics. The full networks\nare mainly dominated by Western cities, although some larger African or Asian\ncities are also able to occupy a central position. There appears to be at least a mild\nform of geographical bias – e.g., Asian cities mainly collaborating with other\nAsian cities – but the effect is modest: we also found several cases of intense\ninternational and intercontinental collaboration. Some countries, such as India and\nIran, are more likely to form separate clusters. This observation corresponds with\nthe results of Glänzel and Gupta (2008) who found that India has relatively few\nresearch collaborations with other countries.\nLink prediction for recommendation\nSince we are interested in opportunities for future collaboration, we focus on\ncities that do not yet collaborate in a given time period. There are many possible\nmethods for determining which future collaborations are the most promising.\n1413\n\nHere, we focus on the information that is already present in the city collaboration\nnetwork, without relying on any other data source. We start from the assumption\nthat a collaboration should be recommended if (a) the two cities do not yet\ncollaborate, and (b) the two cities are similar or related. To determine the\nsimilarity or relatedness of cities, we take a link prediction approach. We try to\ndetermine a relatedness score W for each node pair on the basis of the current\nnetwork. Singling out those pairs that are currently unlinked (condition a) and\nsorting them in decreasing order of W (condition b) yields a list of the most\npromising future collaborations.\nA formula that results in a relatedness score W is called a predictor. We have used\nthree predictors that had good performance in previous research (Guns, 2011,\n2012; Liben-Nowell &amp; Kleinberg, 2007): weighted Katz, rooted PageRank, and\nSimRank.\nWeighted Katz predictor\nBefore we define the (weighted) Katz predictor (Katz, 1953) we explain the used\nterminology. A walk is a sequence of nodes\n, such that each node\npair\nin the sequence is connected by a link. There are no further\nrestrictions on walks. A multigraph is a graph allowed to have multiple links\nbetween two nodes. Different links between two nodes also constitute different\nwalks, i.e. the number of walks\nin a multigraph is equal to\n∏\n(\n), where (\n) denotes the number of links between and\n.\nWeighted Katz measure: definition\nThe weighted Katz measure can best be described in the context of a multigraph.\nLet denote the (full) adjacency matrix of the multigraph . The element\nis\nequal to the number of links between\nand\nor 0 if no link is present. Each\n( )\n\nof\n(the -th power of ) has a value equal to the number of\nelement\nwalks in with length from to\n(Wasserman &amp; Faust, 1994, p. 159). The\nweighted Katz predictor is then defined as:\n(\n\n)\n\n∑\n\n( )\n\n(1)\n\nwhere\nis a parameter between 0 and 1. This parameter represents the\n“probability of effectiveness of a single link”. Thus, each path with length has a\nprobability\nof effectiveness. As\nhigher powers become smaller and\nsmaller so that the influence of nodes further away decreases fast.\n\n1414\n\nRooted PageRank\nThe other two predictors are inspired by Google’s PageRank (and hence indirectly\nby the Pinski-Narin citation influence methodology (1976)). The intuition behind\nrooted PageRank (Liben-Nowell &amp; Kleinberg, 2007) is best explained from the\nperspective of a random walker. The random walker starts at a fixed node ,\ncalled the root node. At each step, the walker moves along a link to a neighbour of\nthe current node. Contrary to ordinary PageRank, rooted PageRank does not allow\nrandom ‘teleportation’ but only allows teleportation back to the root node . This\nform of teleportation occurs with probability\n(where\n). High\nvalues tend to favour the well-connected nodes in the network (with high classic\nPageRank scores), especially in relatively small networks such as ours. On the\nother hand, setting too low reduces the advantage of a PageRank-like predictor.\nEssentially, rooted PageRank is a specific form of so-called personalized\nPageRank (Langville &amp; Meyer, 2005). The resulting scores can be interpreted as a\nmeasure of each node’s relatedness to the root node. The highest scoring node is\ntypically the root node itself.\nSimRank\nSimRank is a measure of how similar two nodes in a network are, originally\nproposed by Jeh and Widom (2002) and further elaborated by Antonellis, Molina,\nand Chang (2008). The SimRank thesis can be summarized as: Objects that link\nto similar objects are similar themselves. Note the recursive nature of the thesis, –\nto assess the similarity of a node pair, we need to have an estimate of the\nsimilarity of the nodes that they link to. The starting point of a SimRank\ncomputation is the assumption that an object is maximally similar to itself:\n(\n)\n. One can then calculate the SimRank score of each node pair\niteratively, until the changes drop below a given threshold value. The SimRank\nformula is:\n(\n\n)\n\n∑ ∑\n\n(\n\n)\n\n(2)\n\nwhere\ndenotes the neighbourhood of (the set of nodes adjacent to ), and\nthe number of neighbours of . In case of isolate nodes, the above formula\nwould lead to a division by zero, which can be avoided by adding 1 to the\ndenominator. Since our data contains no isolates, this is not necessary.\nIn (2), (\n) is the ‘decay factor’ that determines how quickly similarities\ndecrease. If, for example, cities x and y both collaborate with z, then determines\nthe certainty with which we can state that x and y are similar. Lower values also\nresult in lower values for ( ).\n\n1415\n\nResults\nWe predicted collaborations between research institutes situated in different cities\nbased on relatedness scores as explained above. The parameters for each predictor\nwere set to the values shown in Table 9.\nSince we are interested in recommending high-potential collaborations, it makes\nsense to restrict our analysis to the top predictions. Concretely, for each method\nwe drew a list of the twenty unlinked node pairs with the highest relatedness\nscore. These can be considered as our recommendations according to that method.\nTo evaluate the quality of the recommendations, we applied this procedure to the\nnetworks from the periods 1997–2001 and 2002–2006. We consider a\nrecommendation successful if it actually took place in the following period. In\nthis way, we determined the success rate, the fraction of realized collaborations.\nResults are shown in Figure 13.\nTable 9. Values chosen for predictor parameters\nPredictor and parameter\nWeighted Katz:\nRooted PageRank:\nSimrank:\n\nValue\n0.001\n0.4\n0.3\n\nFigure 13. Results of three predictors in two medical research fields for two periods.\nThe horizontal axis refers to the success rate\n\nFigure 13 clearly shows that overall the weighted Katz predictor performs best,\nfollowed by SimRank. Rooted PageRank is the weakest predictor in our study.\nPredictions based on the full network are generally (but not always) better than\nthose based on the restricted network. Since the former contains more information\nthan the latter, this is not unexpected. Indeed, if two target cities collaborate with\n1416\n\na Western city, they may eventually end up collaborating directly, but this can\nonly be inferred from the full network.\nPredictions based on the second period are generally better than those based on\nthe first one. This is most likely because the network grew larger and hence\ncontained more information. Successful predictions often involved South-African\nor Thai cities (e.g., Bangkok, Mae Sot, Johannesburg). Such cities could be called\nfacilitator cities. They play a central role in weaving the fabric of international\ncollaboration. In our opinion, two findings in particular bear testimony of the\npotential of our approach. First, we obtained high success rates, especially for the\nweighted Katz predictor. Second, among the correctly predicted collaborations we\nhave several ones involving a city in Asia as well as a city in Africa. This\nillustrates that the method outlined in this paper is capable of making realistic but\nnon-trivial recommendations.\nConclusions\nThis investigation shows that it is possible – at least to some extent – to predict\ncollaborations. Yet, we can also consider our predictions as recommendations for\nfuture research and as long as these recommendations are not actually made and\ntried out, it is possible that some institutes just have missed some excellent\npotential collaborators. Of course, this aspect cannot be evaluated.\nAlthough it seems that the larger the network, the better the predictions, it is\nobvious that there is an upper limit on the size or density of the network. After a\nwhile only highly improbable new collaborations can be predicted.\nBy focussing on cities and regions this article contributes to the emerging subfield\nof spatial or regional scientometrics (Frenken, Hardeman &amp; Hoekman, 2009).\nReferences\nAntonellis, I., Molina, H.G., &amp; Chang, C.C. (2008). Simrank++: query rewriting\nthrough link analysis of the click graph. Proceedings of the VLDB Endowment,\n1(1), 408–421.\nBoshoff, N. (2010). South–South research collaboration of countries in the\nSouthern African Development Community (SADC). Scientometrics, 84(2),\n481–503.\nFrenken, K., Hardeman, S., &amp; Hoekman, J. (2009). Spatial scientometrics.\nTowards a cumulative research program. Journal of Informetrics, 3(3), 222232.\nGlänzel, W., &amp; Gupta, B.M. (2008). Science in India. A bibliometric study of\nnational research performance in 1991-2006. ISSI Newsletter, 4(3), 42–48.\nGuns, R. (2011). Bipartite networks for link prediction: can they improve\nprediction performance? In E. Noyons, P. Ngulube, &amp; J. Leta (Eds.),\nProceedings of the ISSI 2011 Conference (pp. 249–260). Durban: ISSI, Leiden\nUniversity, University of Zululand.\n\n1417\n\nGuns, R. (2012). Missing links: Predicting interactions based on a multirelational network structure with applications in informetrics. Doctoral\ndissertation, Antwerp University.\nJeh, G., &amp; Widom, J. (2002). SimRank: a measure of structural-context similarity.\nIn KDD ’02: Proceedings of the Eighth ACM SIGKDD International\nConference on Knowledge Discovery and Data Mining (pp. 538–543). New\nYork: ACM.\nKatz, L. (1953). A new status index derived from sociometric analysis.\nPsychometrika, 18(1), 39–43.\nLangville, A.N., &amp; Meyer, C.D. (2005). A survey of eigenvector methods for web\ninformation retrieval. SIAM Review, 47(1), 135–161.\nLiben-Nowell, D., &amp; Kleinberg, J. (2007). The link-prediction problem for social\nnetworks. Journal of the American Society for Information Science and\nTechnology, 58(7), 1019–1031.\nLiu, YX., Rousseau, R., &amp; Guns, R. (2013). A layered framework to study\ncollaboration as a form of knowledge sharing and diffusion. Journal of\nInformetrics (to appear).\nPinski, G. &amp; Narin, F. (1976). Citation influence for journal aggregates of\nscientific publications: Theory with application to the literature of physics.\nInformation Processing &amp; Management, 12(5), 297–312.\nThe STIMULATE-6 Group (2007). The Hirsch index applied to topics of interest\nto\ndeveloping\ncountries.\nFirst\nMonday,\n12(2).\nhttp://www.firstmonday.org/issues/issue12_2/stimulate/\nVan Eck, N.J., &amp; Waltman, L. (2007). VOS: a new method for visualizing\nsimilarities between objects. In H.-J. Lenz, &amp; R. Decker (Eds.), Advances in\nData Analysis: Proceedings of the 30th Annual Conference of the German\nClassification Society (pp. 299-306). Springer.\nVan Eck, N.J., &amp; Waltman, L. (2010). Software survey: VOSviewer, a computer\nprogram for bibliometric mapping. Scientometrics, 84(2), 523–538.\nWasserman, S., &amp; Faust, K. (1994). Social Network Analysis: Methods and\nApplications. Cambridge: University Press.\n\n1418\n\nPUBLICATION BIAS IN MEDICAL RESEARCH:\nISSUES AND COMMUNITIES\nEdgar Schiebel1 and Maria-Elisabeth Züger2\n1\n\nedgar.schiebel@ait.ac.at, 2maria-elisabeth.zueger@ait.ac.at\nAIT Austrian Institute of Technology GmbH, Donau City Str 1, A-1220 Vienna (Austria)\n\nAbstract\n\nPublication bias is a broadly discussed phenomenon related to the reporting of the\noutcome of clinical studies. As a part of the UNCOVER project this work aimed at the\nidentification of members of the research community as stakeholders for interviews and\nworkshops how to overcome publication bias.\nFor this objective relevant literature was analysed by the following bibliometric\napproaches: networks of co-authorships and affiliated institutions, co-citation analysis and\nbibliographic coupling over a twenty-year timespan. Research communities were mapped\nand examined and research issues where identified by applying bibliographic coupling\nand co-citation maps.\nThe analysis showed a high dominance of publications from evidence based medicine like\nsystematic reviews and meta-analysis performed for different medical topics. Most\nauthors used and cited previous research, findings and methods how to proceed with\npublications bias. They are to be seen as experienced “users and applicants” stakeholder\ngroup.\nA second dominant group of publications is related to research on publication bias from\ndifferent aspects: publications and data for systematic reviews, adequacy of databases,\npublication of negative results, registration of clinical trials, outcome reporting, protocols\nof clinical trials, sponsorship bias, role of editors, ethic committees, guidelines for\nsystematic reviews, regulation of clinical trials and methods for meta-analysis.\nStakeholders were selected on the basis of research issues and affiliated organizations.\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches –\n(Topic 3); Visualisation and Science Mapping: Tools, Methods and Applications (Topic\n8)\n\nIntroduction\nIt has already been discussed, that non-publication of negative results is a\nchallenge in science (Gumpenberger, C., Gorraiz, J., Wieland, M., Roche, I.,\nSchiebel, E., Besagni, D., Francois, C., 2012 and Roche, I., Francois, C.\nGumpenberger, C., Gorraiz, J., Wieland, M., Schiebel, E., 2012). More efficiency,\nmore progress and more transparency could be achieved, if not only positive\noutcomes but also non successful approaches were published. In evidence based\nmedicine publication bias is a well-known phenomenon (Song F, Parekh S,\n\n1419\n\nHooper L, Loke YK, Ryder J, Sutton AJ, HIng C, Kwok CS, Pang C, Harvey I.,\n2010).\nThe framework for the presented bibliometric analysis is formed by the\nUNCOVER project: Evaluation and development of measures to uncover and\novercome bias due to non-publication of clinical trials –. The UNCOVER project\nis a direct contribution to overcome non-publication of clinical studies that have\nbeen designed and executed as randomized controlled trials (RCTs). The issues of\nthe publication bias are treated with quantitative, qualitative and participatory\nmeans in an interdisciplinary approach (Züger, ME., Holste, D. Schiebel, E.,\n2013). It is framed in terms of evidence-based medicine and system’s theory. The\ncore of the system approach is twofold. First we identify, map and link relevant\nstakeholders and opinion leaders like study registries, researchers, editors of\njournals, funding bodies, regulators, and industry on an international and global\nlevel, and secondly possible measures (law, regulations, policies, practices,\nguidelines, methods, tools) are identified to overcome bias. Current measures\nsubstantiated by own experience (“inside-out”) are identified by a systematic\nreview. Experts from international methods groups (“outside-in”) in the field of\nsystematic reviews and meta-analyses are engaged. Measures in terms of\nexperiences, own strategies and existing conflict of interests are reflected by\npersonal interviews with editors and other stakeholders based on stakeholder\nmapping/analysis. Software solutions for the demonstration and treatment of\nunpublished studies on statistical meta-analyses are developed. Recommendations\nimply the implementation of feasible measures and milestones, as well as open\ngaps addressed by new research, to overcome non-publication.\nUNCOVER thus both provides viable solutions for the publication bias for better\nallocation efficiency of medicinal and health related research funds, and develops\nmethodologies for future bias research efforts.\nIn this paper we present a bibliometric analysis of scientific literature on\npublication bias as a general issue: Do we have a scientific discussion about\npublication bias in science and what are the concerned disciplines; Are scientists\naware and do they mention and examine non-publication of negative results that\nalso plays a role for the quality of published work and have a consequence in\npractical use of research results? We assume that non-publication of negative\nresults or inflation of positive ones has many consequences in medical research,\nespecially in reporting the outcome of clinical trials.\nWe present a literature survey performed by relational bibliometric approaches to\nidentify research groups, issues and disciplines with research on publication bias.\nMethod and Data\nThe bibliometric analysis was aimed at the identification of members of the\nresearch community and research issues in the field of publication bias assisted by\na quantitative bibliometric approach.\nTo this end, bibliographic data (e.g., title, authors, institution, country, abstract,\nkeywords, references) of the relevant literature using the search phrases\n1420\n\n“publication bias”, “citation bias”, “language bias”, “location bias”, “reference\nbias”, and “reporting bias” was obtained from the ISI Web of Knowledge.\nBased on 3,891 publications over the time span 1990 to 2012 (partly),\nbibliometric analysis was conducted on co-authorships, affiliated institutions, and\nbibliographic coupling. Relationships between authors, institutions were mapped\nand examined with a network analysis. Research issues were identified by\napplying bibliographic coupling.\nBibliographic coupling is of growing interest to subdivide research fields in\nresearch issues, sometimes called research fronts. Basic work about the\nidentification of research fronts by bibliographic coupling and knowledge bases\nby co-citation analysis was published by Price (1965), Kessler (1965), Chen &amp;\nMorris (2003) and more actual research was performed by Shibata et al (2009)\nand Boyack &amp; Klavans, (2010) just to cite some of the growing amount of\npublications in this issue. Spring models and multidimensional scaling are used to\nmap publications in a two or more dimensional space, see for example Kopcsa, A.\nand Schiebel, E. (1998). Advantages are the visualisation, the representation in\ntwo or three dimensions maps and the visibility of relative positions of\nagglomerations. Schiebel (2012) introduced a plot of link-weighted local densities\nof publications or references that was used in this work to identify research issues\non publication bias.\nResults\nThe results section consists of different descriptive statistics about titles of\nsources (journals, proceedings, etc.), time series and countries data with regard to\nthe number of publications. It gives information about discipline specific journals,\ntimeliness and geographic engagement.\nTable 1 lists journals as a percentage of all journals for of the 3,891 publications.\nThe first 21 Journals sum up to nineteen percent of all publications.\nWe have a high dominance of publications in the Cochrane Database of\nSystematic Reviews, see The Cochrane Collaboration, (2013). The British\nMedical Journals is the second most important source for publications relevant to\npublication bias. Other journals are the Journal of Clinical Epidemiology, JAMA\nJournal of the American Medical Association and Annals of International\nMedicine just to cite media with more than 50 publications. All sources are from\nthe medical discipline. As the ISI Web of Knowledge database covers all\nscientific disciplines it can be concluded, that publication bias is primarily an\nissue in medical research.\nA small number of publications dates back almost two decades, to the year 1990 –\nthe starting point of our analysis (cf. Table 2). Yet it took more than the first\ndecade (about 14 years) to attain a remarkable increase in the number of\npublications in this field. Since then, the number of publications is monotonically\nincreasing with an approximately constant growth rate. In the last two years there\nare indications for further acceleration of the growth rate (and the numbers for\n2012 tend to rise further). The growth per year is indicative of the increasing\n1421\n\nresearch on publication bias from different perspectives like outcome reporting,\nregistration of trials, ethic issues, role of editors, guidelines for performing\nclinical trials reporting and the increase of the number of systematic reviews and\nmeta-analyzes on different medical topics. It reflects the growing research\nactivities in evidence based medicine and awareness of publication bias.\nTable 1: List of the first 21 journals sorted by descendant number of publications\nSource titles\n1.\n2.\n3.\n4.\n5.\n6.\n7.\n8.\n9.\n10.\n11.\n12.\n13.\n14.\n15.\n16.\n17.\n18.\n19.\n20.\n21.\n\nCOCHRANE DATABASE OF SYSTEMATIC REVIEWS\nBRITISH MEDICAL JOURNAL\nJOURNAL OF CLINICAL EPIDEMIOLOGY\nJAMA JOURNAL OF THE AMERICAN MEDICAL\nASSOCIATION\nANNALS OF INTERNAL MEDICINE\nAMERICAN JOURNAL OF EPIDEMIOLOGY\nLANCET\nSTATISTICS IN MEDICINE\nPLOS ONE\nINTERNATIONAL JOURNAL OF EPIDEMIOLOGY\nEPIDEMIOLOGY\nAMERICAN JOURNAL OF CLINICAL NUTRITION\nPLOS MEDICINE\nSTROKE\nAMERICAN JOURNAL OF GASTROENTEROLOGY\nMOLECULAR BIOLOGY REPORTS\nARCHIVES OF INTERNAL MEDICINE\nCANADIAN MEDICAL ASSOCIATION JOURNAL\nCURRENT MEDICAL RESEARCH AND OPINION\nEUROPEAN JOURNAL OF CANCER\nJOURNAL OF CLINICAL ONCOLOGY\n\nNumber\nof Publ.\n101\n83\n78\n\n% of\n3,891\n2.60\n2.13\n2.01\n\n57\n\n1.47\n\n53\n41\n36\n35\n34\n24\n23\n20\n20\n20\n19\n19\n17\n17\n17\n16\n16\n\n1.36\n1.05\n0.93\n0.90\n0.87\n0.62\n0.59\n0.51\n0.51\n0.51\n0.49\n0.49\n0.44\n0.44\n0.44\n0.41\n0.41\n\nThe field is headed by North America and dominated by the United States (with\n1,480 publications in the whole period), where we have the highest publication\nactivity. A large number of European countries are listed as the address of authors\nand their affiliated institutions. England (with 760 publications) is leading the\nstatistics of European countries. Positioned on the fourth place (with 346\npublications), China plays a key role, too, but is not dominating like it does in\nmany engineering domains.\nKeywords were derived from three record-fields: the publication title (TI); the\nauthor key-words (DE) and the Web of Knowledge keywords (ID). The most\nfrequent terms indicate that publication bias is strongly connected to metaanalysis systematic reviews and clinical trials and not to other areas of science\ndisciplines.\n\n1422\n\nTable 2: Number of publications related to publication bias per year.\nPublication Year\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012 (January-May)\n\nNumber of Publ.\n4\n26\n42\n43\n52\n52\n65\n78\n93\n108\n98\n105\n119\n124\n163\n218\n244\n276\n353\n400\n422\n531\n275\n\n% of 3,891\n0.10\n0.67\n1.08\n1.11\n1.34\n1.34\n1.67\n2.01\n2.39\n2.78\n2.52\n2.70\n3.06\n3.19\n4.19\n5.60\n6.27\n7.09\n9.07\n10.28\n10.85\n13.65\n7.07\n\nTrend line\n\nFigure 1 shows the co-authorship network with more than 3 publications per\nauthor. The top 21 authors (ranked by the number of publications) are marked in\nthe graph. The network is dominated by a giant sub-network, which consists of a\nhighly inter-linked core, with many of the highest active researchers and with\nconnections to various working groups via authors in a network role as brokers\n(central position in a sub-network) or bridges (connecting one or more subnetworks). Almost 60% of authors mapped in the graph belong to this dominant\nnetwork component.\nIn addition, the graph shows a number of smaller components with a size of inbetween 2 to 5 authors with more than 2 publications.\nThe structure of the author network is nothing out of the ordinary compared to\nother re-search fields. Although it is unusual that so many of the top 21 authors\nare linked instead of having their own work groups connected indirectly via\nbrokers and bridges.\nSub-networks were defined as a group of authors which are only connected to\neach other. As shown in figure 1 there is one sub-network of 442 authors. To\nmake further analysis possible this sub-network – with the representative\nIoannidis, JPA – was subdivided into frequently co-operating working groups.\nThis was achieved by hiding weak links which yields in several separated groups\n\n1423\n\nof strongly connected authors. Authors of such a group are co-operating\nfrequently and form a working group. Results are listed in tables 3 and 4.\n\nAuthor\n\n| # Pub\n\nFigure 1: Network of co-authorships. The top 21 authors (ranked by number of\npublications) are marked with flags and listed on the right-hand side; Nodes:\nauthors, the size corresponds to the number of publications; Edges: Jaccard index of\nco-frequencies; Timespan of analysis: 1990 to 2012; Date of research: 06 2012; Total\nnumber of publications: 3,891; each author published at least 3 publications;\nNumber of nodes: 754; Number of edges: 1,505.\n\nThe local density map of bibliographically coupled publications was used to\nidentify research issues and key researchers related to publication bias. Research\nissues were identified by selecting an agglomeration of publications, listing\nkeywords from the publications and reading titles and abstracts. The list of\nkeywords was ranked the term frequency–inverse document frequency (TF-IDF)\nmeasure. The TF-IDF weights how often a keyword occurs in a chosen subgroup\nof the agglomeration relative to the overall occurrence. It achieves that very\ncommon and thus unspecific terms like “publication bias” have a low rank and\nspecific keywords like “clinical trial” have a high rank.\nThe bibliographic coupling reveals two huge agglomerations of research\nactivities.\nThe bigger one is formed by systematic reviews and meta-analyzes about\ndifferent medical subjects like “myocardial infarction”, “blood preasure” or\ndiabetis mellitus”. We called it “meta-studies about clinical topics”. It includes\nsystematic reviews and meta-analyzes.\n1424\n\nResearch Front\n\n| Color\n\nFigure 2: Local density of bibliographically coupled publications: 3D surface map\n[left] and 2D surface map [right]; dots are publications; total number of\npublications: 3.891; Number of edges: 1.177.507.\n\nThe second peak represents publications on research about publication bias.\nPublished work reports on guidelines for clinical trials, mathematic and statistical\nmethods for meta-analysis, registration of studies, reporting and research about\ndifferent issues related to publication bias. The assigned name is: “methodologies\nand guidelines for clinical studies”.\nThe network of authors does not reflect the two clusters that were identified as\nagglomerations of bibliographically coupled publications. Generally spoken we\nhave a sequence of links between authors who work on publication bias and\nauthors who work on meta-analysis and systematic review for clinical subjects.\nThe task to identify stakeholders requires a two-fold interpretation of the author\nnetwork based on the two identified clusters.\nFor each cluster authors were analyzed by using the following indicators: the\nnumber of publications, number of citations and recent publications. In addition to\nlinear indicators, we studied relational information based on co-authorships,\nwhich reveals networks of research groups.\n\n1425\n\nTable 3: Cluster “Meta studies about clinical topics”: highest ranked authors by the\nnumber of publications in the cluster, including author network information and\ntitle of the highest cited publication in this cluster. Due to co-publications, different\nauthors can have the same publication listed. Times cited as from June 2012.\n\n1426\n\nTable4: Cluster: “Methodologies and guidelines for clinical studies”: highest ranked\nauthors by the number of publications in the cluster, including author network\ninformation and title of the highest cited publication in this cluster. Due to copublications, different authors can have the same publication listed. Times cited as\nfrom June 2012.\n\n1427\n\nTables 3 and 4 represent the results of the analysis of the author network for the\ntwo identified research issues. It lists the first 21 authors (ranked by the number of\npublished papers) and includes information on the author network and subnetworks. Additionally we included the publication that is highest cited.\nSummary and Discussion\nThe aim of this work was to identify key researchers about “publication bias”.\nThe task was also aimed at mapping the published research activities in the field\nof publication bias, including thematic clustering.\nIn a first step, the selected set of publications was examined by means of\ndescriptive statistics. As a second step relational maps for an authors network and\nresearch issues were drawn.\nA small number of publications about ‘publication bias’ dates back almost two\ndecades, to the year 1990 – the starting point of our analysis. Yet it took more\nthan the first decade (about 14 years) to attain a remarkable increase in the\nnumber of publications in this field.\nSince then, the number of publications is monotonically increasing with an\napproximately constant growth rate. In the last two years there are indications for\nfurther acceleration of the growth rate. The growth per year is indicative of the\nincreasing research on publication bias from different perspectives like outcome\nreporting, registration of trials, ethic issues, role of editors, guidelines for\nperforming clinical trials reporting and the increase of the number of systematic\nreviews on different medical topics. It reflects the growing research activities in\nevidence based medicine, awareness and methods for meta-analysis and\nsystematic reviews.\nThe field is headed by North America and dominated by the United States (with\n1,480 pub-lications), where we have the highest publication activity. A large\nnumber of European countries are listed as the address of authors and their\naffiliated institutions in the field of publication bias. England is leading the\nstatistics of European countries. Positioned on the fourth place, China plays a key\nrole, too, but is not dominating like it does in many engineering domains.\nThe author network showed a high level of co-publishing in the field of\npublication bias. Ranking authors by the number of publications, rank numbers 1–\n21 (the top 21) formed a large predominant cluster (or subnetwork). Interestingly,\nthis large cluster displayed the network type of “brokers”, i.e. authors within\ngroups through a single or few links between groups. Given the accommodating\ninformation about authors (e.g. institution, country, or topic), network positions\nwere used to optimize the selection of stakeholders for up-coming interviews and\nworkshops in the UNCOVER project.\nThe map of bibliographically coupled publications showed two clusters: The\nbigger one is formed by publications about performed systematic reviews and\nmeta-analysis about different medical subjects like “myocardial infarction”,\n“blood preasure” or diabetis mellitus”. We called it “meta-studies about clinical\ntopics”. It includes systematic reviews and meta-analyzes.\n1428\n\nThe second peak represents publications on research about publication bias.\nPublications are about guidelines for clinical trials, mathematic and statistical\nmethods for meta-analysis, registration of studies, reporting and research about\ndifferent issues related to publication bias. The assigned name was\n“methodologies and guidelines for clinical studies”.\nKey researches were identified by exploiting the network of authors combined\nwith the results of the map of bibliographically coupled publications. We\nidentified research communities and persons as stakeholders for publication bias\nand how to overcome it: improvement of performing clinical trials and reporting\ntheir out-come; study registration; sponsorship bias; editorial bias, statistical\nimprovement of available trial results by meta-studies as well as systematic\nreviews.\nAcknowledgments\nThis work is part of the project UNCOVER - Evaluation and development of\nmeasures to uncover and overcome bias due to non-publication of clinical trials;\nHEALTH.2011.4.1-2: Targeting publication bias; project number: 282574; with\ncontributions from dirk Holste, AIT.\nReferences\nBoyack &amp; Klavans, (2010). Co-Citation Analysis, Bibliographic Coupling, and\nDirect Citation: Which Citation Approach represents the Research Front Most\nAccurately?, JASIST 61(12): 2389-2404.\nChen, C., &amp; Morris, S. (2003). Visualizing evolving networks: Minimum\nspanning trees versus pathfinder networks. Proceedings of IEEE Symposium\non Information Visualization (pp 67-74), Seattle, WA: IEEE Computer Society\nPress\nThe Cochrane Collaboration, (2013), hompage:\nhttp://www.cochrane.org/cochrane-reviews/cochrane-database-systematicreviews-numbers\nGumpenberger, C., Gorraiz, J., Wieland, M., Roche, I., Schiebel, E., Besagni, D.,\nFrancois, C. (2012) Exploring the bibliometric and semantic nature of negative\nresults, Scientometrics 1-21\nKopcsa, A., Schiebel, E. (1998), Science and Technology Mapping: A New\nIteration Model for Representing Multidimensional Relationships. Journal of\nthe American Society for Information Science JASIS (1998), 49, 1, 7-17\nRoche, I., Francois, C. Gumpenberger, C., Gorraiz, J., Wieland, M., Schiebel, E.:\n(2012): Análisis bibliométrico de la literatura secundaria sobre la publicación\nde resultados negativos; Congreso Internacional de Información - INFO 2012,\nLa Habana, Cuba; 16.04.2012 - 20.04.2012.\nPrice, D.D. (1965) Networks of scientific papers. Science, 149, 510-515\nSchiebel, E. (2012) Visualization of Research Fronts and Knowledge Bases by\nThree-Dimensional Areal Densities of Bibliographically Coupled Publications\n\n1429\n\nand Co-Citations. Special Issue Scientometrics, DOI: 10.1007/s11192-0120626-8\nShibata et al, (2009). Comparative Study on Methods of Detecting Research\nFronts Using different Types of Citation. JASIST 60(3):571-580\nSong F, Parekh S, Hooper L, Loke YK, Ryder J, Sutton AJ, HIng C, Kwok CS,\nPang C, Harvey I. (2010). Dissemination and publication of research findings:\nan updated review of related biases. Health Technology Assessment; 14(8): 1220\nZüger, ME., Holste, D. Schiebel, E. (2013). Deliverable D3.1 (Part B) of the\nUNCOVER FP7‐funded project under contract number 282574: Bibliometric\nanalysis on publication bias. Publicly available under http://publicationbias.eu\n\n1430\n\nQUANTITATIVE EVALUATION OF\nALTERNATIVE FIELD NORMALIZATION\nPROCEDURES\nYunrong Li1, Filippo Radicchi2, Claudio Castellano3 and Javier Ruiz-Castillo1\n1\n\nyli@eco.uc3m.es\nUniversidad Carlos III de Madrid, Departamento de Economia, Madrid (Spain)\n2\n\nf.radicchi@gmail.com\nUniversitat Rovira i Virgili, Department d’Enginyeria Quimica, Av. Paisos Catalans 26,\n43007 Tarragona (Spain)\n3\n\nclaudio.castellano@roma1.infn.it\nIstituto dei Sistemi Complessi (ISC-CNR), Via dei Taurini 19, 00185 Roma (Italy)\nand Dipartimento di Fisica, &quot;Sapienza&quot; Universita&#x27; di Roma, P.le A. Moro 2, 00185 Roma\n(Italy)\n\nAbstract\n\nThe use of citation numbers for the assessment of research quality has become highly\nrelevant in modern science. Although it is well known that scientific domains strongly\ndiffer in terms of citation rates, bibliometric indicators currently used in research\nassessment are often based on the sole use of raw citation numbers. This necessarily leads\nto unfair evaluation procedures, especially in cross-disciplinary contexts. For this reason,\nthere is an increasing trend towards the formulation of normalization procedures able to\nsuppress disproportions in citation numbers among scientific domains, and thus to lead to\nmore fair cross-disciplinary evaluation criteria. In this paper, we rigorously test the\nperformance of several field normalization procedures devoted to this purpose. We find\nthat four procedures discussed in the literature do worse than the usual normalization with\nfield averages. The latter drastically reduces citation disproportions among scientific\ndisciplines. Finally, we find that a recently introduced two-parameters normalization\nscheme reduces citation disproportions to a level very close to the best achievable level of\nreduction.\n\nConference Topic\n\nScientometrics Indicators (Topic 1)\n\nIntroduction\nThe number of citations that a scientific paper has accumulated is often\ninterpreted as a proxy of the influence of the same paper within the scientific\ncommunity. Although the relation between citations and effective scientific\ninfluence is still under active debate (MacRoberts and MacRoberts, 1989,\n1431\n\nMacRoberts and MacRoberts, 1986, Adler et al., 2009), and although the\nsignificance of citations is content- and discipline-dependent (Bornmann and\nDaniel 2008), citation numbers are often used in assessment exercises and their\npractical role in modern science is becoming more and more central. In the course\nof the last years, many bibliometric indicators have been developed with the aim\nof assessing the relevance of scientific research activities at different levels:\njournals (Garfield, 2006), scientists (Hirsch, 2005; Egghe, 2006), departments\n(Davis and Papanek, 2004), institutions (Kinney, 2007), etc. These indicators,\nhowever, are generally based on raw citation numbers, and thus have several\nlimitations when used to perform comparisons across different fields of research.\nThe limitation of the use of raw citation numbers appears evident already when\nused comparing two scientific papers. A paper in biochemistry typically\naccumulates more citations than a paper in mathematics but this does not\nnecessarily imply that the former paper is more influential than the latter.\nDifferent scientific disciplines strongly differ in citation practices, and as a\nconsequence the typical number of citations that a paper in a given field receives\nmay strongly differ from the number of citations typical of another field.\nTo overcome this inherent disproportion in citation numbers among scientific\nfields, several approaches have been proposed to normalize citation numbers at\nthe level of the single publication. The proposed schemes can be distinguished in\ntwo conceptually different classes:\n(1) Target-based normalization: citation weights are functions of the cited papers.\nThis class includes many different types of normalization techniques such as:\n(i) Field averages (see inter alia Moed et al., 1985, 1988, 1995, Braun et al.,\n1985, Schubert et al., 1983, 1987, 1988, Schubert and Braun, 1986, 1996,\nand Vinkler 1986, 2003; see also Radicchi et al., 2008).\n(ii) Average-based scalar difference from the mean (Glänzel, 2011).\n(iii) Two-parameters reverse engineering (Radicchi and Castellano, 2012a).\n(iv) Exchange rates (Crespo et al., 2012a, 2012b).\n(2) Source-based normalization: citation weights are functions of the citing\npapers. The main example of this normalization scheme is represented by the socalled “fractional citation counting”, extensively studied by, inter alia, Zitt and\nSmall, 2008, Moed, 2010, and Leydesdorff and Opthof, 2010, Glänzel et al.,\n2011, and Waltman et al., 2012.\nWhile the development of cross-disciplinary citation indicators dates back to the\n1980s, only recently scholars have started to apply them to large sets of empirical\ndata, and statistically test their performances. Three methods have been proposed\nto quantitatively assess the performance of a generic normalization procedure:\n(i) Between-group variance (Leydesdorff and Bormann, 2011).\n(ii) Fairness test based on ranking (Radicchi and Castellano, 2012a).\n1432\n\n(iii) Inequality due to Differences in Citation Practices method (IDCP)\n(Crespo et al., 2012a, 2012b).\nBetween-group variance is the simplest of the three tests, but, by construction, it\nvanishes for indicators normalized by field averages. This makes its applicability\nvery limited. Although based on different principles, both the “fairness” and the\nIDCP tests leverage on strict statistical formalisms that do not require any strong\nassumption (i.e., they are distribution free statistical tests). The “fairness” test has\nalready been applied to test the performance of indicators based on the twoparameters reverse engineering (Radicchi and Castellano, 2012b), field averages\nand fractional citation counts (Radicchi and Castellano, 2012a). It has been used\nalso for testing the performances of normalized Impact Factors of journals.\n(Leydesdorff et al, 2012). The IDCP method has been used for field averages,\nexchange rates, and Glänzel type normalizations (Crespo et al, 2012a, 2012b).\nIn this paper, we perform an extensive analysis of several normalized indicators\nand assess their performance using the IDCP method. The dataset consists of\npublications appeared in different years spanning an interval of more than two\ndecades and this allows also to analyse temporal trends in citation practices. Our\nresults are in line with those already obtained in Radicchi and Castellano, 2012a\nand Radicchi and Castellano, 2012b according to which the reverse engineering\nprocedure (Radicchi and Castellano, 2012b) outperforms other normalization\nmethods.\nData\nFor our analysis, we make use of the same dataset as the one already analyzed in\nRadicchi and Castellano 2012b. This dataset is composed of six subsets, each\nincluding all publications appeared in 8,304 scientific journals in a distinct year of\npublication: 1980,1985,1990,1995, 1999 and 2004. Journal titles have been\ncollected from the Journal of Citation Reports (JCR) database\n(http://science.thomsonreuters.com/cgi-bin/jrnlst/jlsubcatg.cgi?PC=D). For all\npublications we retrieved, from the Web Of Science (WOS, isiknowledge.com)\ndatabase, in the period May 23-31, 2011, the number of citations they have\naccumulated (field “times cited”). We restrict our attention only to documents\nwritten in “English”, and classified as “Article”, “Letter”, “Note” or “Proceedings\nPaper” for a total of 2,906,615 publications. Notice that the citation windows\nduring which the papers in the different subsets have accrued citations are\ndifferent, ranging from 31 years for the 1980 subset to 7 years for the papers\npublished in 2004.\nWe further use the JCR classification of scientific journals in order to divide\narticles in different classes. JCR classification is composed of 172 subjectcategories (also denoted as sub-fields in the following), each of them roughly\nrepresenting a different research domain. As already emphasized by the same\ninventors (Pudovkin and Garfield 2002), the JCR classification is known to have\n1433\n\nseveral weak points. One of them is that publications in the periodical literature\nare assigned to sub-fields via the journal in which they have been published.\nMany journals are assigned to a single sub-field, but many others are assigned to\ntwo, three, or even more sub-fields. For example in the datasets used in this paper,\nless than 2/3 of all articles are assigned to a single sub-field (to be more specific\nthe percentage of articles assigned to a single subject-category varies with time: in\n1980, the percentage of single-category papers was 67%, while only 56% in\n2004).\nTo tackle this problem, two paths can be followed. The first is a fractional\nstrategy, according to which each publication is fractioned into as many equal\npieces as necessary, with each piece assigned to its corresponding sub-field. The\nsecond follows a multiplicative strategy in which each paper is counted as many\ntimes as necessary in the several sub-fields which it is assigned to. In this paper\nwe adopt the multiplicative approach. This leads to a substantial increase in the\ntotal number of “papers”: 42% in 1980, 45% in 1985, 48% in 1990, 56% in 1995,\n58% in 1999 and 61% in 2004. However, we expect that our results will be\ncomparable with those obtained with a fractional strategy, as demonstrated by\nCrespo et al. (2012b) for a dataset similar to the one used here.\nDescriptive statistics\nDescriptive statistics (available upon request) indicate that our yearly data\npresent important differences in two respects: the distribution of documents by\nsub-field and the ratio of sub-field citation means to the overall citation mean do\nvary over the six years we study. However, within each year important\nsimilarities across sub-fields should be emphasized. For this purpose, we use the\nCharacteristic Scores and Scales (CSS hereafter) technique, introduced by\nSchubert et al. (1987) in the analysis of citation distributions. Being scale- and\nsize- invariant, the CSS method allows us to focus on the shape of sub-field\ncitation distributions within each year.\nThe following characteristic scores are determined: 1 = mean citation for the\nentire yearly distribution, and 2 = mean citation for articles with citations above\n1. Consider the partition of the distribution into three broad classes: articles with\nnone or few citations below 1; fairly cited articles, with citations above 1 and\nbelow 2; and articles with a remarkable or outstanding number of citations\nabove 2. In every year, we have computed the average and standard deviation\nover the 172 sub-fields for the percentage of articles in the three classes, as well\nas the corresponding statistics for the percentages of the total number of citations\naccounted by each class in every year. Since the results smoothly evolve during\nthe 1980-2004 period, it suffices to report results in Table 1 for the two polar\ncases.\n1434\n\nThe small standard deviations in Table 1 indicate that sub-field citation\ndistributions within each year share some fundamental characteristics: they are\nboth similar and highly skewed in the sense that a large proportion of articles\ngets none or few citations while a small percentage of them account for a\ndisproportionate amount of all citations. Specifically, for the two years in\nquestion between 69% and 73% of all articles receive citations below the mean\nand only account for, approximately, between 22% and 24% of all citations,\nwhile articles with a remarkable or outstanding number of citations represent\nabout 8% or 10% of the total, and account for, approximately, between 42% and\n47% of all citations. Other intermediate years present percentages comprised\nbetween those for 1980 and 2004. Finally, as can be seen in Table 1, these results\nclosely resemble those concerning the shapes of citation distributions across a\nwide array of 219 sub-fields with a five-year citation window studied in Albarrán\net al. (2011). As has been recently emphasized, this striking similarity between\ncitation distributions paves the way for meaningful comparisons of citation\ncounts across heterogeneous scientific disciplines (Radicchi et al. 2008, 2012a,\n2012b, and Crespo et al. 2012a, 2012b).\nTable 1. The skewness of science. Averages (and standard deviations) over 172 subfield citation distributions in 1980 and 2004 versus previous results for articles\npublished in 1998-2002 with a five-year citation window classified in 219 sub-fields\nPercentage of Articles\nIn Category\n1\n2\n3\nResults from our dataset, selected years:\n73.2 (4.3)\n19.0 (2.6)\n1. 1980\n68.6 (3.5)\n21.7 (2.0)\n2. 2004\n\n7.7 (2.1)\n9.7 (1.7)\n\nPercentage of Total Citations\nAccounted For By Category\n1\n2\n3\n21.1 (5.0)\n24.3 (3.6)\n\n32.1 (2.3)\n33.4 (1.4)\n\n46.9 (5.5)\n42.3 (3.5)\n\n3. Previous results over 219 sub-fields for articles published in 1998-2002 with a five-year\ncitation window. See Table 1, p. 391, in Albarrán et al. (2011, Table 1, p. 391):\n68.6 (3.7)\n10.0 (1.7)\n29.1 (1.6)\n44.9 (4.6)\n\nMethods\nCrespo et al. (2012a) introduced a simple model in which the number of citations\nreceived by an article is a function of two variables: the article’s underlying\nscientific influence, and the field it belongs to. Consequently, the broad\ndistribution of citation numbers for all articles in all fields –the all-sciences case–\nis the result of two components: differences in scientific influence within\nhomogeneous fields, and differences in citation practices across fields.\nIn the implementation of this model using an additively decomposable inequality\nindex, the citation inequality attributed to differences in citation practices is\ncaptured by a between-group inequality term in a certain partition by field and\n\n1435\n\ncitation quantile. We refer to (Crespo et al., 2012a, 2012b) for details. In practice\none uses a citation inequality index I\n\nwhere N is the total number of publications in a yearly dataset, c l is the number of\ncitations received by the l-th paper (l = 1,..., N), and μ is the mean of the\ndistribution of c values. This quantity can be shown to be decomposed into the\nsum of three terms, one of them being the IDCP (Inequality due to Different\nCitation Practices)\n\nwhere π denotes the quantile in the distribution for sub-field f = 1,..., F, νπ,f is the\nshare of total citations in quantile π of sub-field f, and νπ = Σf νπ,f.\nThe IDCP term captures the citation inequality attributable to differences in\ncitation practices in different sub-fields. Thus, independently of the characteristics\nof citation distributions, the impact of any normalization procedure can be\nevaluated by the reduction in the IDCP term before and after normalization. The\nresults of the method are dependent on the number of quantiles used to divide\neach citation distribution. In this paper, we use 100 quantiles (i.e., percentiles) in\nall our analysis. It is important to stress, however, that the quantitative difference\ndue to the choice of the number of quantiles affects only the absolute values of the\nICDP terms and not the comparison of the ICDP terms of different indicators and\nthus the measured level of reduction.\nIDCP bounds\nRaw citations – Raw citations are the basic information of impact that we have at\nour disposal. The IDCP term calculated on raw citation numbers quantifies the\ninequality of citation distributions due to different citation practices among\nscientific fields, and thus represents the term of reference for the computation of\nthe reduction of such disproportion when using a normalized citation indicator. In\nthis sense, the IDCP term calculated for raw citations represents the upper bound\nof the IDCP. Any reasonable normalized citation indicator must measure values\nof the IDCP below this upper bound.\nPerfect normalization – What is the lowest bound for IDCP? In the case of\ninfinite, real valued and identically distributed data, the ICDP term would be\nequal to zero. However, real citation numbers do not satisfy the former\nrequirements and thus the best achievable ICDP term is in general larger than\nzero. When using ICDP to test the performance of normalized indicators, it is\n1436\n\ntherefore useful to compute the lowest value of ICDP that is achievable given the\ndata, and use this value as a term of comparison for assessing the ability of the\nindicators to effectively remove differences between scientific sub-fields. In order\nto reach this goal, we use a very simple procedure. Given a sub-field, we assign to\neach paper with c citations a score sc equal to the fraction of papers, within the\nsame sub-field, that have accumulated a number of citations lower or equal to c.\nAccording to this rule scores have values in the range 0 to 1; scores preserve the\nnatural order (including ties) of the original citation sequence; in each sub-field\nscores have exactly the same distribution, the uniform one. For these reasons, our\nway of assigning scores to papers represents a sort of “perfect normalization”\nscheme, and the ICDP term measured with these scores represents the best\nperformance that can be achieved for a given data set.\nNormalization procedures\nNormalization by field average – We assign to each paper a score equal to cf =\nc/1, where c is the number of citations accumulated by the paper and 1 is the\naverage number of citations received by papers in the same year of publication\nand in the same subject-category that was introduced in the section on descriptive\nstatistics. Thus, cf represents the relative impact, in terms of citations, of the paper\nwithin its field.\nWe additionally consider a slight variation of the former normalization scheme,\nwhere 1 is calculated excluding uncited publications. This different approach has\nbeen used by Radicchi et al. 2008 and later suggested also by Waltman et al. 2011\nand by Abramo et al. 2012 because it is supposed to lead to higher levels of\nreduction of citation disproportions among fields of science.\nNormalization by median value – This represents a simple modification of the\nprevious indicator, where the only difference is that the number of citations c\nreceived by a paper is divided by the median value m of its field (instead of that\nby the average value 1). Since for some categories m=0, we calculate here the\nmedian citation number of each category by excluding uncited publications.\nNormalization by two-parameters reverse engineering – Radicchi and Castellano\n2012b have introduced a normalization scheme based on the use of two\nparameters. These parameters are estimated empirically on data, as the best\nestimates of the prefactor a and the exponent α of a power-law transformation\nable to make different citation distributions collapse on top of each other. This\nmeans that if the score of a paper is computed as\n, with a and α\nparameters of the subject-category which the paper belongs to, then the\ndistribution of c’ is universal and no longer dependent on the specific subjectcategory considered. In particular, when two distributions have the same\nexponent, the transformation necessary for their collapse is linear, and the method\n1437\n\nreduces to normalization by field average. Radicchi and Castellano, 2012b\ndemonstrated that, for the vast majority of the sub-fields, the values of a and α are\nvery similar, and the citation distributions are the same when plotted as a function\nof c’. A limited number of sub-fields, instead, is characterized by widely changing\nvalues of the transformation parameters, and thus have nonuniversal shapes of the\ndistribution of c’.\nGlanzel’s normalization – This normalization involves the transformation of the\nraw data of any citation distribution with N papers, c = (c1,..., cN), by the formula\nci* = ci/(2 – 1), where 1 and 2 are the two characteristic scores defined in the\nDescriptive statistics section.\nExchange rates normalization – Crespo et al. (2011a, b) find that the similarity of\ncitation distributions allows the effect of idiosyncratic citation practices to be\nrather well estimated over a wide range of intermediate quantiles where citation\ndistributions seem to differ by a scale factor. Consequently, a set of average-based\nmeasures, called exchange rates can profitably be estimated over that interval. Of\ncourse, this interval and the corresponding set of exchange rates must be\nestimated for each yearly sample.\nResults\nWe apply the IDCP method to the indicators described above, calculated for the\ndifferent publication years present in our dataset. We first analyze how the total\ncitation inequality I and the IDCP term depend on time for raw citations.\nTable 1. The evolution of total citation inequality and the IDCP term\n1980\n1985\n1990\n1995\n1999\n2004\n\n(1) Total citation Inequality\n1.058\n1.088\n1.030\n0.966\n0.890\n0.790\n\n(2) IDCP\n0.124\n0.143\n0.139\n0.137\n0.120\n0.099\n\n(3) = (2)/(1), in %\n11.7\n13.1\n13.5\n14.2\n13.4\n12.5\n\nTable 1 shows that the absolute values of IDCP and I both tend to decrease over\ntime, while their ratio remains approximately constant. This means that, in spite\nof the differences between the six yearly datasets, the relative importance of the\ndifferences in citation practices across sub-fields is of a similar order of\nmagnitude, representing about 13% of total citation inequality. For articles\npublished in 1998-2003 in 219 sub-fields with a five-year citation window,\nCrespo et al. (2011b) find that this percentage is 18%. For 22 broad fields, whose\nconnection with the 219 or 172 Web of Science categories is unknown, this is\napproximately 14%.\n1438\n\nIn Figure 1, we plot the absolute value of IDCP when the different normalization\nprocedures are applied, while in Table 2 we include the percentage that the IDCP\nterm represents relative to the total citation inequality after normalization by the\ndifferent procedures, excluding the perfect normalization that, understandably,\ndoes not perform well in relative terms because the total citation inequality (see\nFigure 1) is very low indeed.\n\nFigure 1. A comparison of the IDCP term in absolute value after applying the\ndifferent normalization procedures\nTable 2. A comparison of the percentage that the IDCP term represents relative to\ntotal citation inequality after applying the different normalization procedures\n\n1980\n1985\n1990\n1995\n1999\n2004\n\nMedian\nWithout 0s\n\nGlänzel\n\nExchange\nRates\n\n5.6\n4.9\n5.0\n5.6\n4.9\n4.8\n\n6.2\n5.5\n5.3\n4.8\n4.9\n5.2\n\n4.4\n4.0\n4.3\n4.8\n4.2\n3.8\n\nMean\nWithout\n0s\n4.3\n3.7\n3.3\n3.0\n2.9\n2.9\n\nMean\n\nTwo\nParameters\n\n3.6\n3.2\n2.9\n2.7\n2.7\n2.7\n\n1.7\n2.1\n1.3\n0.8\n0.8\n0.9\n\nThe contest offers clear results. Normalization by sub-field mean citations\ndominates four other alternatives. However, the two-parameters scheme is the one\nthat gets closer to the perfect normalization benchmark.\nFurther insight into the origin of the variation of the performance of the best\nnormalization procedures is provided by Figure 2, where the quantity I(),\ncapturing the citation inequality due to differences in citation practices across sub1439\n\nfields in every percentile, is plotted as a function of the percentile  for papers\npublished in 1990 (similar results occurring for other publication years) Because\nI() is too large for many low percentiles and some very high ones, Figure 2 only\nreports results for the interval (50, 96).\n\nFigure 2. The citation inequality due to differences in citation practices across subfields in every percentile, I(), as a function of \nand after the best normalization procedures are applied for the 1990 dataset.\n\nThe following comments are in order. Firstly, as in Crespo et al. (2012a, b), the\nquantity I() for the raw data is relatively constant over a large quantile interval\n(although only for high values of ). This is what allows us to define a set of\naverage-based exchange rates over that interval. Secondly, the reduction of I()\nachieved by the best normalization procedures is well illustrated.\n\nFigure 3. The comparison of the effect on I() caused by the best normalization\nprocedures for the 1990 dataset\n\nFinally, Figure 3 amplifies Figure 2 in order to appreciate the differences between\nthe best two normalization alternatives. At the very upper tail of citation\ndistributions –namely, when it most matters– the mean normalization’s\n1440\n\nperformance clearly worsens. This is also the case with the alternative procedures\nnot included in Figure 4. However, the two-parameters scheme does extremely\nwell in that interval.\nDiscussion and Conclusions\nWhile the use of citation numbers in research assessment exercises is becoming\nmore and more relevant, there is still much room for the improvement of\nbibliometric indicators devoted to the quantification of research impact. In\nparticular, there is a strong necessity to find proper ways of suppressing\ndisproportions in raw bibliometric measures merely due to different citation\npractices in different fields. In this paper we have presented a quantitative\nassessment of the effectiveness of several procedures for normalizing raw citation\nnumbers.\nUsing the recently introduced IDCP method, we have measured the performance\nof the different procedures applied to papers published in different years ranging\nfrom 1980 to 2004 divided in 172 distinct sub-fields. It turns out that:\n For raw citation numbers the total inequality of citation distributions and\nthe inequality to due different citation practices both tend to decrease over\ntime, while their ratio remains approximately constant.\n Among the different normalization procedures, the recently introduced\nreverse engineering transformation based on two-parameters performs\nbetter than the others, but also the normalization by field averages yields\ngood results.\n The two-parameter procedure outperforms other methods (and is close to\nthe perfect normalization benchmark) in particular at the upper tail of the\ncitation distributions, i.e. for highly cited publications.\nThese results clearly indicate that the regularity of the features of citation\ndistributions described in Albarrán et al. (2011a, 2011b), as well as in the\nDescriptive statistics section of this paper, can be fruitfully used for the\nformulation of normalization procedures that are able to drastically reduce the\ndisproportions in raw citation counts among different sub-fields of science. At the\nsame time, however, much work is still needed for this basic but central problem.\nApart from further study of the robustness of the available results, possibly the\nmore important issue is the development of better classification schemes able to\ndefine fields and sub-field of science in a more coherent manner.\nReferences\nAbramo, G., Cicero, T. &amp; D’Angelo, C.A. (2012) How important is choice of the\nscaling factor in standardizing citations? Journal of Informetrics, 6, 645–654.\nAdler, R. Ewing, J. &amp; Taylor P. (2009). Citation statistics. Statistical Science, 24,\n1–14.\n\n1441\n\nAlbarrán, P., &amp; Ruiz-Castillo, J. (2011a) References Made and Citations Received\nBy Scientific Articles. Journal of the American Society for Information\nScience and Technology, 62, 40-49.\nAlbarrán, P., Crespo, J., Ortuño, I., &amp; Ruiz-Castillo, J. (2011b) The Skewness of\nScience In 219 Sub-fields and a Number of Aggregates. Scientometrics, 88,\n385-397.\nBornmann L. &amp; Daniel H.D. (2008). What do citation counts measure? A review\nof studies on citing behavior. Journal of Documentation, 64, 45–80.\nBraun, T., W. Glänzel, &amp; A. Schubert (1985), Scientometrics Indicators. A 32\nCountry Comparison of Publication Productivity and Citation Impact. World\nScientific Publishing Co. Pte. Ltd., Singapore, Philadelphia.\nCrespo, J. A., Li, Yunrong, &amp; Ruiz-Castillo, J. (2012a) Differences in Citation\nImpact Across Scientific Fields. Working Paper 12-06, Universidad Carlos III\n(http://hdl.handle.net/10016/14771).\nCrespo, J. A., Li, Yunrong, Herranz, N., &amp; Ruiz-Castillo, J. (2012b) Field\nNormalization at Different Aggregation Levels, Working Paper 12-022,\nUniversidad Carlos III (htpp:/hdl.handle.net/10016/15344).\nDavis, P. &amp; Papanek, G.F. (1984). Faculty ratings of major economics\ndepartments by citations. American Economical Review, 74, 225–230.\nEgghe, L. (2006). Theory and practise of the g-index. Scientometrics, 69, 131–\n152.\nGarfield, E. (2006). The history and meaning of the journal impact factor. Journal\nof the American Medical Association, 295, 90–93.\nGlänzel, W. (2011) The Application of Characteristic Scores and Scales to the\nEvaluation and ranking of Scientific Journals. Journal of Information Science,\n37, 40-48.\nGlänzel, W., Schubert, A., Thijs, B., &amp; Debackere, K. (2011) A priori vs. a\nposteriori normalization of citation indicators. The case of journal ranking.\nScientometrics, 87, 415-424.\nHirsch, J.E. (2005). An index to quantify an individual’s scientific research\noutput. Proceedings of the National Academy of Science USA, 102, 16569–\n16572.\nKinney, A.L. (2007). National scientific facilities and their science impact on\nnonbiomedical research. Proceedings of the National Academy of Science\nUSA, 104, 17943–17947.\nLeydesdorff, L. &amp; Opthof, T. (2010) Normalization at the Field level: Fractional\nCounting of Citations, Journal of Informetrics, 4, 644-646.\nLeydesdorff, L., Radicchi, F., Bornmann, L., Castellano, C., &amp; de Nooye, W.\n(2012) Field-normalized Impact Factors: A Comparison of Rescaling versus\nFractionally Counted Ifs. in press, Journal of the American Society for\nInformation Science and Technology.\nMacRoberts, M.H. &amp; MacRoberts, B.R. (1989). Problems of citation analysis:\nAcritical review. Journal of the American Society for Information Science and\nTechnology, 40, 342–349.\n1442\n\nMacRoberts, M.H. &amp; MacRoberts, B.R. (1996). Problems of citation analysis.\nScientometrics 36: 435–444.\nMoed, H. F., Burger, W.J. Frankfort, J.G., &amp; van Raan, A.F.J. (1985) The Use of\nBibliometric Data for the Measurement of University Research Performance.\nResearch Policy, 14, 131-149.\nMoed, H. F., &amp; van Raan, AF.J. (1988) Indicators of Research Performance. in A.\nF. J. van Raan (ed.), Handbook of Quantitative Studies of Science and\nTechnology, North Holland: 177-192.\nMoed, H. F., De Bruin, R.E, &amp; van Leeuwen, Th.N. (1995) New Bibliometrics\nTools for the Assessment of national Research Performance: Database\nDescription, Overview of Indicators, and First Applications. Scientometrics,\n33, 381-422.\nPudovkin, A.I. &amp; Garfield, E. (2002). Algorithmic procedure for finding\nsemantically related journals. Journal of the American Society for Information\nScience and Technology, 53, 1113–1119.\nRadicchi, F., Fortunato, S., &amp; Castellano, C. (2008) Universality of Citation\nDistributions: Toward An Objective Measure of Scientific Impact.\nProceedings of the National Academy of Science USA, 105, 17268-17272.\nRadicchi, F., &amp; Castellano, C. (2012a) Testing the fairness of citation indicators\nfor comparisons across scientific domains: The case of fractional citation\ncounts. Journal of Informetrics, 6, 121-130.\nRadicchi, F., &amp; Castellano, C. (2012b) A Reverse Engineering Approach to the\nSuppression of Citation Biases Reveals Universal Properties of Citation\nDistributions. Plos One, 7, e33833.\nSchubert, A., &amp; Braun, C. (1986) Relative Indicators and Relational Charts for\nComparative Assessment of Publication Output and Citation Impact.\nScientometrics, 9, 281-291.\nSchubert, A., &amp; Braun, T. (1996) Cross-field Normalization of Scientometric\nIndicators. Scientometrics, 36, 311-324.\nSchubert, A., Glänzel, W., Braun, T. (1983) Relative Citation Rate: A New\nIndicator for Measuring the Impact of Publications. in D. Tomov and L.\nDimitrova (eds.), Proceedings of the First National Conference with\nInternational Participation in Scientometrics and Linguistics of Scientific Text,\nVarna.\nSchubert, A., Glänzel, W., &amp; Braun, T. (1987) A New Methodology for Ranking\nScientific Institutions. Scientometrics, 12, 267-292.\nSchubert, A., Glänzel, W., &amp; Braun, T. (1988) Against Absolute Methods:\nRelative Scientometric Indicators and Relational Charts as Evaluation Tools.\nin A. F. J. van Raan (ed.), Handbook of Quantitative Studies of Science and\nTechnology: 137-176.\nVinkler, P. (1986) Evaluation of Some Methods For the Relative Assessment of\nScientific Publications. Scientometrics, 10, 157-177.\nVinkler, P. (2003) Relations of Relative Scientometric Indicators. Scientometrics,\n58, 687-694.\n1443\n\nWaltman, L, van Eck, N. J., &amp; Van Raan, A.F.J. (2011) Universality of citation\ndistributions revisited. Journal of the American Society for Information\nScience and Technology, 63, 72-77.\nZitt M., &amp; Small H. (2008) Modifying the journal impact factor by fractional\ncitation weighting: The audience factor. Journal of the American Society for\nInformation Science and Technology, 59, 1856-1860.\n\n1444\n\nA RELATION BETWEEN POWER LAW\nDISTRIBUTIONS AND HEAPS’ LAW\nShi Shan1, DingHua Shi2 and YiFei Zhang3\n1\n\nshanshihill@126.com\nShanghai University, Center for Information Studies, 99 Shangda Road, 200444 Shanghai\n(China)\n2\n\nshidh2001@263.net\nShanghai University, School of Science, 99 Shangda Road, 200444 Shanghai (China)\n2\n\nzhangyifei@shu.edu.cn\nShanghai University, School of Management, 99 Shangda Road, 200444 Shanghai\n(China)\n\nAbstract\n\nThe growth of vocabulary size as a concavely increasing function of the text length (its\nnumber of words) has been described in Heaps’ law. Furthermore, word frequencies in\ntexts can be reasonably described by power law distributions. A particular interesting\nphenomenon is the coexistence of Heaps’ law and power law distributions. In this paper\nwe prove that (under a weak condition) Heaps’ law is equivalent to the power law\ndistribution with exponent 1-θ θ∈(0,1).\n\nConference Topic\n\nBibliometrics in Library and Information Science (Topic 14) and Webometrics (Topic 7).\n\nIntroduction\nHow do actual texts evolve with text length? What are “normal” growth patterns\nin languages and information networks? Two models describing real text\ngeneration are worth mentioning. The first one, a formulation put forward by Zipf\n(Zipf, 1936) and is now widely known as Zipf’s law, establishes that the number\nof words f (k ) that occur exactly k times in a text decays with k as\n\nf (k )  ck (1 ) , where c  0 and   0 . This power law size-frequency\nrelation indicates a power law probability distribution of the size k itself, say\np(k )  ck (1 ) . The second model is due to Heaps (Heaps, 1978), who showed\nthat vocabulary size n(k ) grows in a concave function with text size k , namely\nn(k )  ck 1 with   (0,1) and c  0 . A particular interesting phenomenon is\nthe coexistence of the power law distribution and Heaps’ law. Besides the\nstatistical regularities of text, words contained by web pages resulted from web\nsearching (Lansey and Bukiet, 2009) and keywords for scientific publications also\n1445\n\nsimultaneously display the power law distribution and Heaps’ law. In particular,\nthe power law distribution and Heaps’ law are closely related to the evolving\nnetworks. It is well known that some networks grow in an accelerating manner\n(Lu, Zhang &amp; Zhou, 2010) and have power law structures, in fact, the former\nproperty corresponds to Heaps’ law that the number of nodes grows in a\nconcavely increasing function with the total degree of nodes, while the latter is\nequivalent to the power law distribution.\nBased on a variant of Simon model (Simon, 1955), Zanette and Montemurro\n(Zanette and Montemurro, 2005) showed that Mandelbrot’s law is a result from\nHeaps’ law. By using a more polished approach, Leijenhorst and Weide\n(Leijenhorst and Weide, 2005) provided a formal derivation of Heaps’ law from\nMandelbrot’s law. Using an exact informetric argument on random sampling in\nthe items, Egghe (Egghe, 2007) showed that, in most cases, n(k ) is a concavely\nincreasing function, in accordance with practical examples. Nevertheless, it\nappears that the story of Heaps’ Law is inseparably connected with its\nscientometric application from the very beginnings up to the recent days. Zhang,\nLü, Liu and Zhou (Zhang et al, 2008) found that there is a power law correlation\nbetween the cumulative number of distinct keywords and the cumulative number\nof keyword occurrences. They also monitored the decay trend of most popular\nkeywords. Interestingly, top journals from various subjects share very similar\ndecaying tendency, while journals with low impact indexes exhibit completely\ndifferent behaviour (Zhang et al, 2008). In this paper, we introduce the notion of\ngradual variation for function on N  , which plays a key role in studying power\nlaw distributions. Some necessary and sufficient conditions for power law\ndistribution are obtained. In particular, we show an example that\nG (k ) \np(i)   (k )k  ~ d  0 , but it does not hold that p(k ) ~ ck ( 1) ,\n\n\ni k\n\nwhere c  0 and   0 . Finally, we prove that (under a weak condition) Heaps’\nlaw is equivalent to the power law distribution with exponent 1   (   (0,1) ).\nThe Power Law Distribution\nWe start with definitions and properties of the power law distribution and the\ngradually varying function, the latter plays a key role in our discussion.\nHere and throughout the paper, p(k ) is a positive probability on N   {1,2,} .\n\nF () is a distribution function, i.e., F (k )   p(i) . G(k ) is a complementary\n\ndistribution\n\nG(k )  \n\nik\n\nfunction, (or right cumulative distribution function), i.e.,\np(i) . log() stands for the natural logarithm on the set of positive\n\ni k\n\nreals, i.e., log k \n\n1446\n\n\n\nk\n\n1\n\n1\ndx . ( ) denotes the usual gamma function, i.e.,\nx\n\n\n\n( )   x 1e  x dx for   0 . The relation of asymptotic equivalence between\n0\n\nf (k ) and g (k ) , written by f (k ) ~ g (k ) , means that the ratio of f (k ) to g (k )\ngoes to 1 as k   . To write that f (k )  o( g (k )) means that the ratio of f (k )\nto g (k ) goes to 0 as k   .\nWe shall need the following two properties and an auxiliary result.\n\n1\nk\n\nProperty 2.1 (1  )  1 \nProperty 2.2 If\n\n\n\n1\n o( ) for k  N  .\nk\nk\n\n(2.1)\n\n (k )  o(1) , log(1   (k )) ~  (k ) .\n\n(2.2)\n\nStolz Theorem Let g (k ) and f (k ) be functions on N  . (1) If (i) f (k )  o(1) ;\n(ii) g (k )  o(1) and there exists m  N  such that g (k  1)  g (k ) for all\n\nk  m ; and (iii) the limit\n\nlim\n\nk \n\nf (k  1)  f (k )\ng (k  1)  g (k )\n\nexists; it holds that\n\nf (k )\nf (k  1)  f (k )\n. (2) If (i) g (k )   (as k   ); (ii) there\n lim\nk  g (k )\nk  g (k  1)  g (k )\nexists m  N  such that g (k  1)  g (k ) for all k  m ; and (iii) the limit\nf (k  1)  f (k )\nf (k )\nf (k  1)  f (k )\nexists; it holds that lim\n.\nlim\n lim\nk  g ( k  1)  g ( k )\nk  g (k )\nk  g (k  1)  g (k )\nlim\n\nRefer for the above to (Klambauer, 1975).\n\nDefinition 2.1 A positive probability p(k ) on N  is the power law distribution\nwith exponent  , if p(k )   (k )k ( 1) , where\n 0.\nDefinition 2.2 A positive function\n\n (k )  c  0 (as k   ) and\n\n (k ) on N  varies gradually (at  ) if and\n\nonly if  (k  1) /  (k )  1  o(1 / k ) .\n\nTheorem 2.1 p(k ) is the power law distribution with exponent  if and only if\n\nG(k )   (k )k  ,\n\nwhere\n\nG(k )   p(i) ,\n\n (k )\n\nvaries\n\ngradually\n\nand\n\ni k\n\n (k )  d  0 (as k   ), and   0 .\n\nProof. By G(k )  G(k  1)  p(k )   (k )k ( 1) , where  (k )  c (as k   ),\nwe have\n\n1447\n\nUsing (2.1), we get\n\nG(k )  G(k  1) c(1  o(1))k 1\n.\n\n1 \nk   (k  1) \n1  (1  )\nk\n\nG(k )  G(k  1) c\n~ .\nk   (k  1)  \n\nTherefore, by Stolz Theorem,\n\nG (k ) c\n~ ,\n\nk \n\n(2.3)\n\n(2.4)\n\ni.e., G(k )   (k )k  , where  (k )  d  c /  (as k   ).\nOtherwise, from\n\nG (k  1) G (k )  p(k )\n\nG (k )\nG (k )\nc(1  o(1))k ( 1)\nd (1  o(1))k \n\n1\n 1   o( )\nk\nk\n 1\n\nand  (k )  G(k )k  , we have\n\n (k  1)\n1 G (k  1)\n 1 (1  )\n1\n (k )\nk\nG (k )\n1 \n\n1\n\n (1  ) (1   o( ))  1\nk\nk\nk\n1\n o( ).\nk\n\nThis shows that  (k ) is a gradually varying function.\n\nG(k )\np(k )\n, we have\n1 \nG(k  1)\nG (k )\nG(k )\n\n1\n 1   o( ) ,\nG(k  1)\nk\nk\n\n1\np(k ) (  o( ))G (k  1)\nk\nk\n\n1\n\n1\n (  o( ))(1   o( ))G (k )\nk\nk\nk\nk\n\nConversely, seeing (2.5) and\n\n1448\n\n(2.5)\n\nAnd p(k ) \n\n\nk\n\n(1  o(1)) (k )k  . Noting that  (k )  d  c /  (as k   )\n\n(see(2.4)) and letting  (k ) be equal to\nwith  (k )  c (as k   ).\n\n(k )(1  o(1)) , we get\n\np(k )   (k )k ( 1) ,\n\nCorollary 2.1 Let p(k ) be a positive probability on N  and G(k ) \nThen\n\nk 1 p(k )   (k )  c (as\n\nk  )\n\nif\n\nand\n\n p(i) .\ni k\n\nonly\n\nif\n\nk G(k )   (k )  d  c /  (as k   ) and  (k ) varies gradually, where\n  0 and c  0 .\n\n\nProof. It is easy to check from the proof of Theorem 2.1.\nRemark\n\nk\n\n1\n\n2.1\n\nCorollary 2.1 shows an interesting property that\np(k )   (k )  c and k  G(k )   (k )  c /  as k   . Comparing with\n\nthe continuous power law distribution, the Pareto distribution on [ , ) (   0 ),\nwe have\n\nx 1 f ( x)  c   \n\nand\n\nx G ( x ) \n\nc\n\n\n\n  ,\n\nwhere f (x) is the density function and G( x) \n\n\n\n\n\nx\n\nf ( y)dy .\n\nExample 2.1 For the Waring distribution\n\np(k )  \n\n(   )(   k  1)\n, (   0 ,   0 , k  N )\n (  ) (   k   )\n\nIt follows by induction that\n\nG(k ) \n\n(   )(   k  1)\n.\n(  )(    k  1)\n\nLet  (k )  G(k )k  . From the fact that\n\n( )  (  1) and then\n\n (k  1) G (k  1)\n1\n\n(1  )\n (k )\nG (k )\nk\n\n\n1\n (1 \n)(1   o( )),\n    k 1\nk\nk\n1449\n\nWe get\n\n1\n (k  1)\n\n\n 1   o( ) \n(1  o(1)) ,\nk\nk     k 1\n (k )\n\nWhich means that  (k  1) /  (k )  1  o(1 / k ) . Thus  (k ) is a gradually varying\nfunction. Using Stirling’s formula: (  k ) / (k ) ~ k  (as k   ), we have\nthat\n\n (k )  (   ) / ( ) (as k   ) and  (k ) varies gradually, and\n\nG(k )   (k )k  .\nTheorem 2.1 leads us to the following definition\nDefinition 2.3 Let p(k ) be a positive probability on N  and G(k ) \n\n p(i) .\n\ni k\n\n\np(k ) is the power law distribution with exponent  if G(k )   (k )k , where\n (k )  d  0 (as k   ) and  (k ) varies gradually, and   0 .\nTheorem 2.2 Let p(k ) be a positive probability on N  and F (k ) \n\n1\nk\n\n p(i) .\ni k\n\nThen F (k ) varies gradually if and only if p(k )  o( ) .\nProof. Since\n\nk(\n\nF (k  1)\np(k  1)\n 1)  k\n~ (k  1) p(k  1) ,\nF (k )\nF (k )\n\nIt follows that F (k  1) / F (k )  1  o(1 / k ) if and only if p(k )  o(1 / k ) .\n\np(k ) be the geometric distribution on N  , i.e.,\np(k )   (1   ) k 1 , where   (0,1) . For    log(1   )  0 , it is easy to\ncheck that kp(k )  ke ( k 1)  o(1) and then F (k )  1  (1   ) k 1 is a gradually\n\nExample 2.2 Let\n\nvarying function.\nRemark 2.2 As Example 2.2 shows, being a gradually varying function for\nF (k ) is a weak assumption without involving some strong conditions such as\nheavy tails, thick tails or power law style for distributions.\nTheorem 2.3 p(k ) is the power law distribution with exponent  if and only if\n\n (k ) \n\n1450\n\nkp(k )\n  (as k   ) and G(k )k    (k )  d  0 (as k   ).\nG(k )\n\nProof. Now G(k )k    (k )  d  0 (as k   ) and\n\n(k ) \nThis shows that\n\nkp(k )\nG(k  1)\n k (1 \n)   (as k   ).\nG(k )\nG (k )\nG(k  1)\n\n1\n 1   o( ) .\nG(k )\nk\nk\n\nFrom G(k )   (k )k  , it follows that\n\n (k  1)\n1 G (k  1)\n 1 (1  )\n1\n (k )\nk\nG (k )\n\n1 \n1\n\n (1  ) (1   o( ))  1\nk\nk\nk\n1\n o( )\nk\nand  (k ) varies gradually (at  ).\nConversely, from Corollary 2.1 the fact that\n\nk  1 p(k )   (k )  c (as k   )\n\nimplies k  G(k )   (k )  d  c /  (as k   ). Then (k ) \n\nk   ).\n\n (k )\n  (as\n (k )\n\nProposition 2.1 (1) Both 1 (k ) and 2 (k ) are gradually varying functions, then\n\n (k )  1 (k )2 (k ) varies gradually. (2)  (k ) is the gradually varying function,\n\nthen  (k )  ( (k )) 1 varies gradually.\nProof. (1) From\n\n (k  1)\n (k  1) 2 (k  1)\n 1 1\n1\n (k )\n1 (k ) 2 (k )\n1\n1\n (1  o( ))(1  o( ))  1\nk\nk\n1\n o( ),\nk\n\n (k ) then varies gradually. (2) It is easy to check from the definition of gradual\nvariation.\n\n1451\n\nExtended Heaps’ Law\nThe power law relation between the text length k and the number of different\nwords in a text n(k ) , n(k )  c k 1 ( c  0 ), is usually referred to as Heaps’ Law.\n\nThe sub-linear growth of k with n(k ) is insured if the Heaps exponent is more\nthan zero and less than one. Let e(k ) be the expectation number of occurrences\n\nk\n ck  with\nn( k )\ncc  1 , if Heaps’ law holds. Let X be a random variable, “ X  k ”( k  N  ) the\nevent “a word occurs k times” and E ( X | X  k ) the expectation of X under\nthe condition of the text length being k or a word occurring k times at most\nfrom the above, we have that E ( X | X  k )  ck  , if Heaps’ law holds. By\n\nof a word in a text containing k words, we have that e(k ) \n\nreplacing the constant c in the original form of Heaps’ law with a gradually\nvarying function  (k ) with lim  (k )  c , n(k )   (k )k 1 is an extension of\nHeaps’\n\nlaw,\n\nand\n\nk \n\nthe corresponding conditional expectation becomes\nE ( X | X  k )   (k )k  , where  (k ) (k )  1 ,  (k ) varies gradually (see\n\nProposition 2.1) and  (k )  c \n\nDefinition 3.1 Let N (k ) \n\n1\n(as k   ).\nc\n\nk\n. N (k ) is extended Heaps’ law on N \nE( X | X  k )\n\nN (k )   (k )k 1 , where   (0,1) ,  (k )\n (k )  c  0 as k   .\n\n, if\n\nLet  (k ) \n\nvaries gradually and\n\n ip (i) , then  (k )  F (k )E( X | X  k ) , where F (k )   p(i) .\ni k\n\ni k\n\nLemma 3.1 Let  (k )  F (k ) (k )k  (   (0,1) ), where F (k ) is the gradually\nvarying function,  (k ) is the gradually varying function and  (k )  c as\n\nk   , then G(k )   (k )k (1 ) , where  (k ) varies gradually and\nc\nas k   , i.e., p(k ) is the power law distribution with exponent\n (k ) \n1\n1 .\nProof. Now F (k ) (k ) is the gradually function(from the assumption and\nproposition 2.1), i.e.,\nF (k  1) (k  1)\n1\n 1  o( ) ,\nF (k ) (k )\nk\nand\n1452\n\n (k  1)   (k ) F (k  1) (k  1)(k  1)  F (k ) (k )k \n1\nF (k  1) (k  1)\n F (k ) (k )k  (\n(1  )  1),\nF (k ) (k )\nk\nand\n\n (k  1)   (k )  (k  1) p(k  1) , it follows that\n\nand\n\n\n1\n1\n(k  1) p(k  1) F (k ) (k )k  ((1  o( ))(1   o( ))  1)\nk\nk\nk\n\n1\n F (k ) (k )k  (  o( ))\nk\nk\n(1 )\n F (k ) (k )k\n(1  o(1))\np(k  1)  F (k ) (k )\n\n\nk 1\n\nk (1 ) (1  o(1)) .\n\n1\nk\n\n(3.1)\n\n1\nk\n\nSubstituting F (k  1)  F (k )(1  o( )) and  (k  1)   (k )(1  o( )) into\n(3.1) yields\n\np(k  1)  F (k  1) (k  1)k ( 2 ) (1  o(1)) ,\n\nnamely,\n\np(k )  F (k ) (k ) (1  o(1))k ( 2 ) .\nLet  (k )  F (k ) (k ) (1  o(1)) , then  (k )  c (as k   ). p(k ) is the\npower law distribution with p(k )   (k )k ( 2 ) . Using Theorem 2.2, we have\n\nG(k )   p(i)   (k )k (1 ) , where  (k ) varies gradually and  (k ) \ni k\n\n(as k   ).\n\nc\n1\n\nc\n(as\n1\nk   ),  (k ) varies gradually, then  (k )  F (k ) (k )k  , where F (k ) is the\ngradually varying function,  (k )  c (as k   ) and  (k ) is the gradually\n\nLemma 3.2 Let\n\nG(k )   (k )k (1 ) (   (0,1) ), where  (k ) \n\nvarying function.\nProof. From  (k  1)   (k )  (k  1) p(k  1) , and Theorem 1.1 and Corollary\n1.1, we have\n\n (k  1)   (k ) \n\n (k  1)(1   )\n(k  1)1\n\n(1  o(1)) .\n\n1453\n\nDefine  (k ) \n\n1\n\n\n\n (k )k  , then\n\n1\n1  (k  1)\n (k  1)   (k )  (k )k  ((1  )\n 1)\n\nk\n (k )\n1\n\n1\n  (k )k  (  o( ))\n\nk\nk\n(1 )\n  (k )k\n(1  o(1)).\nThere exists m  N  such that for all k  N  and k  m ,  (k  1)   (k )  0 ,\nand  (k )   (as k   ) (because  (k )  d as k   and from\nProposition 2.1). Now\n\n (k  1)   (k )\n (k  1)\n1 1\n (1  o(1))\n(1 \n) (1   )  (1   ) (as k  \n (k  1)   (k )\n (k )\nk 1\n),\n\nfrom the Stolz theorem, it follows that\n\n (k )\n (1   )(1  o(1))\n (k )\n\nor\n\nDenoting  (k )\n\n (k )  (k )(1   )(1  o(1))\n1\n\n (k )k  (1  o(1)).\n\nby\n\n1\n\n\n\n (k )(1  o(1)) and seeing the condition that\n\nc\n, we conclude that  (k )   (k )k  , where  (k )  c (as k   ).\n1\nNext we will show that  (k ) is the gradually varying function.\nc\nFrom k 1 G(k )   (k ) \n(as k   ) and Corollary 2.1, we have\n1\nk 2 p(k )   (k )  c (as k   ). Let (k )  k  , then\n\n (k ) ~\n\n1454\n\n (k  1)   (k )  (k  1)(k  1)  (1 )\n(k  1)  (k )\n\nObviously,\n\n\n\n(k  1)  k \n (k  1)\n1\n)(1  )\n\n1 \nk\n(k  1)((1  )  1)\nk\n (k  1)\n\n1\n\n(1   o( ))\n\n1\nk\nk\n(k  1)(  o( ))\nk\nk\nk (k  1)\n\n1\n(1   o( ))\n\n (k  1)(1  o(1))\nk\nk\n c(1  o(1)).\n\n(k  1)  (k )  0 , for k  N  , (k )   (as k   ), and\n (k  1)   (k )\nlim\n\n(k  1)  (k )\n\nk \n\nFrom the Stolz theorem,\nTherefore,\n\nk(\n\n (k )\n(k )\n\n c (as k   ) and  (s)  ck  (1  o(1)) .\n\n (k  1)\n (k  1)   (k )\n 1) k\n (k )\n (k )\n\n\n\n (k  1)k (k  1) (1 )\nck  (1  o(1))\n\n (k  1)(k  1)\n\nck \n  (1  o(1))\n\nand\n\nLet\n\n(1  o(1))\n\n (k  1)\n\n 1  (1  o(1)) .\n (k )\nk\n\n (k ) denote\n\nand  (k ) denote\n\n c.\n\n1\n,\n (k )\n\n (k )\n1\n (k )k \n\n\n1455\n\nwe have\n\n (k ) \nand\n\n\n1\n\n (k ) (k )k \n\n(3.2)\n\n (k  1)\n (k  1) (k  1)\n1 \n1 \n(1 \n) 1.\n (k )\n (k ) (k )\nk 1\nFrom Proposition 1.1 we know that  (k ) is the gradually varying function and\nthen\n\n (k  1)\n\n1\n1\n\n1\n 1 (1   o( ))(1  o( ))(1   o( ))  1\n (k )\nk\nk\nk\nk\nk\n\n\n\n1\n1\n1\n\n(1  o(1)  o( ))  (1   o( ))  o( )\nk\nk\nk\nk\nk\n1\n o( ).\nk\n\n\nFrom (3.2),  (k ) \n\n (k ) \n\n1\n\n\n\nk\n\n1\n\n\n\n (k ) (k )k  . Using Corollary 1.1, we conclude that\n\n (k ) (k ) varies gradually.\n\nc\nand  (k ) is the\n1\ngradually varying function implies that k 2 p(k )   (k ) ~ c . This shows that\nFrom Corollary 2.1, the fact that k 1 G(k )   (k ) ~\n\n1\np(k )  o( ) and F (k ) is the gradually varying function (from Theorem 2.2).\nk\nTheorem 3.1  (k )  F (k ) (k )k  (   (0,1) ), where F (k ) and  (k ) are\n\n (k ) ~ c  0 , and k  N  , if and only if\nc\n, and if and only\nG(k )   (k )k (1 ) , where  (k ) varies gradually,  (k ) ~\n1\nif p(k )   (k )k ( 2 ) , where  (k ) ~ c .\ngradually varying functions,\n\nProof. Combining Lemma 3.1, Lemma 3.2, Theorem 2.1 and Corollary 2.1 yields\nthe desired result.\nTheorem 3.2 If F (k ) varies gradually (at  ), then\n\nN (k )   (k )k 1 (   (0,1) , k  N  ),\n\n1456\n\n (s)  c (as k   ), if and only if\n, where  (k )   / c (as k   ).\n\nwhere  (s) varies gradually and\n\np(k )   (k )k\n\n ( 2 )\n\nk\nkF(k )\n\n  (k )k 1 , where F (k ) and  (k ) are\nE ( X | X  k )  (k )\n1\n, then  (k )   (k ) F (k )k  . From\ngradually varying functions. Let  (k ) \n (k )\n\nProof. N (k ) \n\nProposition 2.1,  (k ) varies gradually. Using Theorem 3.1 and noting\n\n1\nc\n\n (k )  c  (as k   ), we conclude that p(k )   (k )k ( 2 ) , where\n\n (k )   / c (as k   ). Conversely, from p(k )   (k )k ( 2 ) with\n (k )   / c , using Theorem 3.1, we get that  (k )  F (k ) (k )k  , where\n (k )\n (k ) ~ c  1 / c .\nvaries\ngradually\nand\nThen\nkF(k )\n1 1\n\nk   (k )k 1 . From Proposition 2.1,  (k ) varies\n (k )  (k )\ngradually and  (k )  c (as k   ).\nN (k ) \n\nConclusions\nThe main results of the paper may be summarized in the followings.\n1. p(k ) is the power law distribution on N  , i.e., p(k )   (k )k ( 1) , where\n\nlim  (k )  c  0 and   0 , if and only if G(k )   p(i)   (k )k  , where\nk \n\n1\n (k  1)\nlim  (k )  and\n 1  o( ) .\nk \n\n (k )\nk\n\nc\n\ni k\n\n2. Let k be the number of word occurrences in a text and N (k ) be the\ntheoretical number of distinct words in the text. Then, N (k )   (k )k 1 , where\n\n  (0,1) ,  (k ) varies gradually and  (k )  c (as k   ), if and only if\np(k )   (k )k ( 2 ) , where  (k )   / c (as k   ).\n\nAcknowledgments\nThis work is supported by NNSFC under Grant No. 61174160. The authors thank\nthree referees for their comments and useful suggestions.\nAppendix: An Illustrative Example\nThis appendix focuses on the importance of the notion of gradual variation in\nstudying power law distributions by showing an illustrative example. It is\ninteresting that we can construct a positive probability p(k )   (k )k ( 1) on\n1457\n\nN  (   0 ) with the properties (1) there exist reals a and b , b  a  0 , such\nthat\nand\nand\n(2)\nlim sup (k )  b\nlim inf  (k )  a ;\nk \n\nG(k )   p(i)   (k )k\n\nk \n\n\n\n~ ck\n\n\n\nbut\n\n (k ) does not satisfy the condition of\n\ni k\n\ngradual variation.\n\n1\n(1) k ) ( k  N  ), then  (k )  0 and  (k )  2 (as\nk 1\nk   ). Let H (k )   (k )k 3 . From\n\nLet  (k )  2(1 \n\n1  (1) k\n33\n 1  2(1) k 1 ,\nk\n\ni.e.,\n\n3\n(k  1  (1) k )  1  2(1) k 1 ,\nk\n\nwe have\n\n3 1  2(1) k 1\n\nk k  1  (1) k\n1\nk\n\n(A.1)\n\n3\nand (A.1) yields\nk\n3\n1\n1  2(1) k 1\n 1  1   (1  )3 .\nk\nk  1  (1)\nk\nk\n\nCombining (1  )3  1 \n\nFrom\n\nand (A.2), we have\n\n(A.2)\n\n (k  1)\n1  2(1) k 1\n1\n)(\n (1 \n 1)\n (k )\nk  2 k  1  (1) k\n\n1\n (k  1)\n (1  )3\nk\n (k )\nand H (k  1)  H (k ) . Let h(k )  H (k )  H (k  1) , then\nk\n\nk\n\ni 1\n\ni 1\n\n h(i)  ( H (i)  H (i  1))\n H (1)  H (k  1).\nBecause\n\nH (1)  1 ,\n\nk\n\n\n\ni 1\n\ni 1\n\nlim  h(i)   h(i)  H (1)  lim H (k  1)  1 ,\nk \n\nk \n\nwe\n\nconclude that h(k ) is the corresponding (right cumulative) distribution function.\nWe replace h(k ) and H (k ) with p(k ) and G(k ) respectively.\n1458\n\nFrom  (k ) ~ 2 and\n\n (k  1)  (k  1)   (k )\n\n (k )\n (k )\n1\n( (k  1)   (k ))\n2\n1\n2k  3\n (1) k 1\n2\n(k  1)(k  2)\n~\n\nit follows that\n\n1, k odd , k  ,\n (k  1)\n 1)  \n (k )\n 1, k even, k  .\n\nk(\nThus,\n\n (k ) is not the gradually varying function and from Definition 2.3 the\n\ncorresponding probability p(k ) is not the power law distribution.\nConsider\n\n (k  1)\n (k  1)   (k )\n 1\n (k )\n (k )\n 1  (1) k 1\n\nand let  (k )  (1) k 1\nwe have\n\n2k  3\n (k )(k  1)(k  2)\n\n2k  3\n,\n (k )(k  1)(k  2)\n\nG (k  1)\n1 3\n (1   (k ))(1 \n)\nG (k )\nk 1\n3\n1\n (1   (k ))(1   o( ))\nk\nk\n3\n3\n1\n 1    (k )(1  )  o( ).\nk\nk\nk\n\n(A.3)\n\nSubstituting (A.3) into p(k )  G(k )  G(k  1)\nyields\n\n1459\n\n3\n3\n1\np(k ) G (k )(   (k )(1  )  o( ))\nk\nk\nk\n3\nk\n G (k )(1   (k )  o(1))\nk\n3\n1\nk\n 6(1 \n(1) k )(1   (k )  o(1))k 4\nk 1\n3\n4\n  (k )k ,\n1\nk\nwhere  (k )  6(1 \n(1) k )(1   (k )  o(1)) . Because\nk 1\n3\n1\n, k odd , k  ,\n\nk\n3\n (k )  \n3\n 1 , k even, k  ,\n\n 3\n\nand\n\n4, k odd , k  ,\n8, k even, k  ,\nwe conclude that the limit lim (k ) does not exist.\n\n (k )  \nk \n\nReferences\nEgghe, L. (2007). Untangling Herdan’s law and Heaps’ law: mathematical and\ninformetric arguments. Journal of the American Society for Information\nScience and Technology, 58, 702-709.\nHeaps, H. S. (1978). Information Retrieval, Computational and Theoretical\nAspects. New York: Academic Press.\nKlambauer, G. (1975). Mathematical analysis. New York: Macel Dekker.\nLansey, J. C. &amp; Bukiet, B. (2009). Internet search result probabilities: Heaps’ law\nand word associativity. Journal of Quantitative Linguistics, 16, 40-66.\nLeijenhorst, D. &amp; Weide, T. (2005). A formal derivation of Heaps’ law.\nInformation Science, 170, 263-272.\nLu, L., Zhang, Z.-K. &amp; Zhou, T. (2010). Zipf&#x27;s Law Leads to Heaps&#x27; Law:\nAnalyzing Their Relation in Finite-Size Systems. PLoS ONE, 5, e14139.\nSimon, H. (1955). On a class of skew distribution functions. Biometrika, 42, 425440.\nZanette, D. &amp; Montemurro M. (2005). Dynamics of text generation with realistic\nZipf’s distribution. Journal of Quantitative Linguistics, 12, 29-40.\nZhang, Z.-K. et al. (2008). Empirical analysis on a keyword-based semantic\nsystem. European Physical Journal B, 66, 557-561.\nZipf, G. K. (1936). The Psycho-Biology of Language. An Introduction to\nDynamic Philology. London: Routledge.\n1460\n\nTHE RELATIONSHIP BETWEEN\nCOLLABORATION AND PRODUCTIVITY FOR\nLONG-TERM INFORMATION SCIENCE\nRESEARCHERS (RIP)\nJonathan M. Levitt1 and Mike Thelwall2\n1\n\nJ.M.Levitt@wlv.ac.uk and J.Levitt@lboro.ac.uk\nStatistical Cybermetrics Research Group, School of Technology, University of\nWolverhampton, Wulfruna Street, WV1 1LY Wolverhampton (UK)\n2\n\nM.Thelwall@wlv.ac.uk\nStatistical Cybermetrics Research Group, School of Technology, University of\nWolverhampton, Wulfruna Street, WV1 1LY Wolverhampton (UK)\n\nAbstract\n\nOver the past decade funding bodies have tended to encourage research collaboration,\nperhaps because articles by smaller groups of researchers tend to be less highly cited than\narticles by larger groups. This does not imply that, in general, researchers in smaller\ngroups are less productive since they may produce more articles and hence may receive\nmore citations altogether. This study investigates the relationship between average coauthorship group size and productivity in 2001-2008 for long term researchers, those who\nauthored at least one information science article in both 1998-2001 and 2008-2011. In\ngeneral the more collaborative researchers were the least productive, supporting previous\nsimilar findings for physics. Nevertheless, the most productive information scientists had\nmean group size of 2-3, suggesting that promoting a small rather than a large degree of\nresearch collaboration may be the best strategy for achieving high productivity.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6) and Science Policy and Research\nEvaluation: Quantitative and Qualitative Approaches (Topic 3).\n\nIntroduction\nFunding bodies typically promote collaborative research with the implicit or\nexplicit assumption that researchers in collaborative groups are more productive.\nThis assumption may partly stem from collaborative articles being, on average,\nmore highly cited than sole authored articles (e.g., Vogel, 1997; Leta &amp;\nChaimovich, 2002; Levitt &amp; Thelwall, 2010). For example, in their investigation\nof Web of Science articles from 2000 to 2009 with at least one author affiliated to\nHarvard University, Gazni and Didegah (2011) found a significant positive\ncorrelation between the number of co-authors and the number of citations and that\nthe mean citation per article was about one for sole author articles, about two for\n2, 3, 4, 5 and 6 co-authors and thereafter rose steadily as the number of co-authors\n1461\n\nincreased. In an investigation of all articles indexed by the Science Citation Index\nin 1992, Persson, Glanzel and Danell (2004) found that the mean citation rate,\nexcluding self-citations, increased, on average, by about .58 citations for each\nadditional author. On the same dataset Glanzel, Debackere, Thijs and Schubert\nfound that the self-citation rate for one author articles was 20% and for each\ncollaborative level from 2 to 10 authors was between 25 and 28%, suggesting that\nself-citations may be partly the cause of the apparent citation advantage of coauthored articles. Glanzel and Danell (2004) also found that for articles published\nin 1988 and 1998 the mean citation rate of internationally collaborative articles\nrose more sharply than that for domestic collaborative articles when the number\nof authors increased. But higher average citation does not imply higher\nproductivity. For example, consider the case of Researcher A who is sole author\nto one article that received four citations and Researcher B who is sole author to\nten articles that in total received thirty citations. Although A has higher average\ncitations than B, A is not more productive than B. Moreover, the productivity of\nA would be even lower if their article was co-authored and credit for its citations\nshared with A’s co-authors.\nA pilot investigation of physics found the relationship between group size and\nproductivity depends on how productivity is measured (Levitt, 2011): when\nproductivity is measured by articles per researcher, productivity decreases as the\nnumber of co-authors increases but when productivity is measured by the number\nof articles per citation band (i.e., clustering articles together with similar citation\nrates), group sizes of one to two were most productive in the lowest citation band\nbut not in the highest citation bands, suggesting that collaboration may increase\nthe chance of producing the most highly cited research. This pilot investigation\ninvestigated research published in a single year and therefore gave an advantage\nto researchers that publish occasionally since occasional researchers not\npublishing in the year studies would be excluded altogether. The current paper\naddresses this limitation by investigating long term researchers and including\nyears in which they did not publish. In addition it investigates the collaboration\nlevel variations to see if researchers vary their collaborative style.\nResearch questions\nThis study investigates the following research questions:\n1. To what extent does the research productivity of long-term researchers\nvary with the number of collaborative partners (Productivity of groups)?\n2. To what extent does the number of collaborative partners of long-term\nresearchers vary (Variation in group size)?\nThe research questions are addressed for the Information Science &amp; Library\nScience (IS&amp;LS) Web of Science category with data from articles published in\nnine years, 2001-2008.\n\n1462\n\nMethod\nIn this study Long-Term researchers are defined as researchers who authored at\nleast one IS&amp;LS article in both 1998-2002 and 2008-11. This study investigates\nthe IS&amp;LS articles by the long-term researchers during 2001-08. The end year of\n2008 provides recent data without reducing the citation window to less than 4\nyears. The set includes not only researchers who published in the start year\n(2001), but also researchers who published in any of the three years before the\nstart year; and not only researchers who published in the end year (2008), but also\nresearchers who published in any of the three years after the end year. This avoids\nbiasing the sample towards authors that publish every year, who are presumably\nthe most productive. The remaining authors that published at least one article in\n2001-2008 are termed ‘Occasional’ researchers; note that this group contains any\nlong term researcher that did not publish after 2007 or who did not publish an\nIS&amp;LS article in both 1998-2001 and 2008-2011, due to a career break or due to\npublishing in a different discipline.\nResearch productivity was measured by calculating the fractional article\ncontribution and fractional citation contribution in the period assessed. Fractional\ncontributions use the fractional counting system, recommended by Price (19981)\nand used in several investigations (e.g., Burrell &amp; Rousseau, 1995; Glänzel &amp; De\nLange, 2002). In the fractional counting system the credit for a sole author article\nis the same as the total credit for a collaborative article, but the authors of\ncollaborative articles share equal fractions of the credit for their articles. We\ndecided against measuring contribution using the whole counting system, in\nwhich the article and citation credit is irrespective of the number of authors,\nbecause the objective is to identify the impact of collaboration on productivity\noverall in the system.\nBibliographic data on IS&amp;LS articles was obtained from the Social Sciences\nCitation Index in autumn 2011 and the names of researchers extracted. For each\nperiod and each researcher name, the collaboration level of the researcher was\nobtained by adding the number of authors in the IS&amp;LS articles authored by the\nresearcher in the period and dividing by the number of IS&amp;LS articles published\nby the researcher in the period. Authors were identified on the basis of their\nsurnames and initials. As the number of Long-Term researchers was less than\n1,800, there would have been few cases of different authors to have had the same\nsurname and initials and these should not systematically bias the results.\nFindings\nProductivity of groups (Question 1)\nTables 1 and 2 compare the productivity of long-term researchers with the\nproductivity of Occasional researchers. In tables 1-4, ‘All’ refers to all levels of\n\n1463\n\nresearchers, ‘1–2’ to the researchers with a collaboration level less than 2, and ‘8–\n9’ to the researchers with a collaboration level of at least 8 but less than 9.\nTable 1: Productivity by collaboration level for Long-Term IS&amp;LS researchers\n(2001-2008) using the whole number counting system.\nCollaboration\nlevel\nNumber of\nresearchers\nMean level of\ncollaboration\nArticles per\nresearcher\nCitations per\narticle\n\nAll\n\n1–2\n\n1,722\n\n2–3\n\n3–4\n\n4–5\n\n5–6\n\n6–7\n\n7– 8\n\n8– 9\n\n20.9% 34.0% 22.6% 10.5% 5.4%\n\n2.2%\n\n2.0%\n\n1.1%\n\n3.03\n\n1.28\n\n2.31\n\n3.21\n\n4.23\n\n5.20\n\n6.28\n\n7.22\n\n8.16\n\n4.81\n\n5.20\n\n5.59\n\n4.62\n\n3.77\n\n3.43\n\n4.55\n\n2.31\n\n2.11\n\n14.65\n\n7.34\n\n16.78\n\n15.09\n\n16.83\n\n15.72\n\n30.04\n\n23.94\n\n23.26\n\nTable 2: Productivity by collaboration level for Occasional IS&amp;LS researchers\n(2001-2008) using the whole number counting system.\nCollaboration\nlevel\nNumber of\nresearchers\nMean level of\ncollaboration\nArticles per\nresearcher\nCitations per\narticle\n\nAll\n\n1–2\n\n2–3\n\n3–4\n\n4–5\n\n5–6\n\n6–7\n\n7– 8\n\n8– 9\n\n21,024 20.3% 26.2% 21.6% 12.4% 6.7%\n\n4.6%\n\n2.6%\n\n1.8%\n\n3.30\n\n1.08\n\n2.09\n\n3.07\n\n4.05\n\n5.06\n\n6.04\n\n7.04\n\n8.03\n\n1.44\n\n1.72\n\n1.49\n\n1.42\n\n1.27\n\n1.30\n\n1.22\n\n1.16\n\n1.17\n\n9.83\n\n3.76\n\n10.41\n\n12.38\n\n11.11\n\n10.87 12.65 15.52 13.53\n\nAgain using the whole number counting system, for Long-Term and Occasional\nresearchers the Spearman correlations between the mean collaboration level and\narticles per researcher were small at 0.016 (p &gt; 0.05, n=1,722) and -0.031 (p &lt;\n0.001, n=21,024) respectively, despite the clear decreasing trends in tables 1 and\n2. For the Long-Term and Occasional researchers the Spearman correlations\nbetween the mean collaboration level and citations per article were moderate at\n0.260 (p &lt; 0.001) and 0.265 (p &lt; 0.001). Amongst the researchers who published\nat least one IS&amp;LS article in 2001-2009, fewer than 7.6% were Long-Term. These\nLong-Term researchers were particularly productive; on average they authored\n3.34 times as many articles as the Occasional researchers and their articles on\naverage received 49% more citations each. For both Long-Term and Occasional\nresearchers, a collaboration level of 2–3 is the most common but Occasional\nresearchers have a slightly higher average group size. For both Long-Term and\nOccasional researchers, for every collaboration level higher than 1–2, the mean\ncitation per article was more than double that for 1–2, although the mean number\n1464\n\nof citations per article varied little as the collaboration level increased from 2–3 to\n5–6. The picture is different when fractional counting is used, however.\nTable 3 indicates that, apart from two years (2004 and 2006), the fractional\ncitation contribution per long-term researcher was lower for the 1–2 collaboration\nlevel than for the 2–3 level and thereafter in all years it decreased steadily as the\ncollaboration level increased.\nTable 3: Fractional citations per researcher by collaboration levels for Long-Term\nresearchers.\nYear\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n\nAll\n11.57\n15.11\n13.33\n12.41\n9.72\n10.38\n6.90\n4.75\n\n1–2\n14.31\n17.79\n10.11\n15.84\n9.98\n16.55\n9.15\n6.42\n\n2–3\n16.16\n18.52\n18.70\n13.63\n13.59\n13.14\n11.49\n6.86\n\n3–4\n9.52\n14.08\n10.87\n13.43\n9.58\n7.13\n4.54\n3.64\n\n4–5\n6.04\n7.30\n17.38\n6.99\n7.43\n5.87\n3.30\n2.95\n\n5–6\n4.85\n6.67\n6.51\n4.98\n3.30\n7.26\n1.99\n2.20\n\n6–9\n3.83\n1.74\n10.27\n5.28\n4.06\n4.33\n4.10\n1.67\n\nIn all apart from two cases (3–4 to 4–5 for 2004; 4–5 to 5–6 for 2002) the\nfractional article contribution decreased as the collaboration level increased from\n1–2 to 4–6 apart from two exceptions (Table 4).\nTable 4: Fractional articles per researcher by collaboration level for Long-Term\nresearchers.\nYear\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n\nAll\n.77\n.95\n.96\n.86\n.82\n.79\n.82\n.75\n\n1–2\n1.48\n1.93\n1.77\n1.67\n1.60\n1.51\n1.63\n1.47\n\n2–3\n.77\n.85\n1.03\n.81\n.90\n.92\n1.02\n.82\n\n3–4\n.51\n.60\n.59\n.48\n.51\n.59\n.53\n.53\n\n4–5\n.36\n.38\n.53\n.48\n.44\n.40\n.38\n.38\n\n5–6\n.29\n.39\n.27\n.30\n.32\n.27\n.29\n.31\n\n6–9\n.22\n.19\n.27\n.27\n.24\n.27\n.25\n.25\n\nTable 5 shows the relationship between collaboration level and number of articles\nauthored. In Table 5, the ‘Sample size’ column presents the number of long-term\nresearchers at the collaboration level, and the remaining columns present the\npercentage of researchers at the collaboration level who authored the number of\narticles in the column heading. For example, the ‘24’ in the in the ‘1–2’ row and\n‘1’ column indicates that 24% of the Long-Term researchers at the collaboration\n1465\n\nlevel of &gt;= 1 and &lt; 2 authored exactly one IS&amp;LS article in 2001-2008. For all\ncollaboration levels in Table 5, over half the researchers authored fewer than 4\narticles. The percentage of researchers who authored one article only was\nsubstantially lower for the 2–3 collaboration level than for other collaboration\nlevels. There is also a suggestion in the table that lower collaboration levels are\nassociated an increased chance of the highest productivity (larger percentages in\nthe &gt;8 articles column).\nTable 5: Percentage of Long-Term researchers by the number of articles published\n(top row).\nCollaboration\nlevel\n1–2\n2–3\n3–4\n4–5\n5–6\n\nSample\nsize\n360\n585\n389\n181\n93\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n&gt;8\n\n24%\n17%\n27%\n26%\n30%\n\n22%\n16%\n17%\n19%\n19%\n\n12%\n18%\n15%\n12%\n15%\n\n11%\n10%\n12%\n13%\n9%\n\n6%\n8%\n5%\n11%\n5%\n\n4%\n6%\n5%\n5%\n7%\n\n4%\n4%\n4%\n4%\n7%\n\n6%\n3%\n2%\n2%\n3%\n\n11%\n16%\n13%\n8%\n5%\n\nVariation in group size (Question 2)\nIn order to gauge variations in group size, for different collaboration levels the\nmaximum and minimum number of authors are listed in Table 6. The minima and\nmaxima are calculated only on researchers that authored more than one article as,\nin order for the researcher’s group size to vary, the researcher needs to have\nauthored more than one article. For example, the ‘31%’ in the in the ‘1–2’ row\nand ‘1’ column indicates that 31% of the multi-author Long-Term researchers at\nthe collaboration level of &gt;= 1 and &lt; 2 authored a maximum of one IS&amp;LS article\nin 2001-2008. Table 5 indicates considerable variation in the level of group size.\nFor example, 9% of the multi-article researchers at the collaboration level of 1–2\nauthored an article that had at least four authors and 31% of the multi-article\nresearchers at the collaboration level of 5–6 authored an article that had fewer\nthan three authors.\nTable 6: Minimum and maximum number of authors expressed as a percentage of\nall multiple-article authors. Shaded cells report maxima and the un-shaded cells\nreport minima.\nCollaboration Sample\nlevel\nsize\n1–2\n274\n2–3\n486\n3–4\n286\n4–5\n134\n5–6\n65\n\n1466\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n&gt;8\n\n31%\n47%\n21%\n9%\n12%\n\n44%\n14%\n47%\n34%\n19%\n\n16%\n45%\n13%\n40%\n25%\n\n4%\n22%\n35%\n5%\n34%\n\n2%\n11%\n27%\n25%\n5%\n\n0%\n3%\n10%\n31%\n22%\n\n0%\n3%\n6%\n17%\n22%\n\n1%\n1%\n2%\n5%\n19%\n\n2%\n2%\n6%\n16%\n39%\n\nLimitations and Discussion\nA major limitation is that only one dataset was investigated and the findings\nmight be different for other subjects or databases with different coverage (e.g.,\nScopus). The findings also depend to some extent on the use of fractional\ncounting. Whilst whole counting would give an unfair advantage to highly\ncollaborative authors, it would have been reasonable to use a counting system that\nallocated fractional credit to scholars based upon their order in the author list.\nMoreover, some of the authors, and particularly those of highly collaborative\npapers, may have been non-scientists, scientists from other fields (e.g., computing\nresearchers constructing software for a project) or even listed for honorary\npurposes (e.g., department heads) and so the categories may mix core and\nperipheral researchers in different proportions. Hence direct comparisons between\ncollaboration levels are likely to be to some extent unfair.\nIn order to obtain some indication of the extent to which the findings depend on\nthe dataset for the same subject, the study was partly repeated with a different\ndataset, researchers who authored at least one IS&amp;LS article in both 2002-2005\nand 2008-2011 (called ‘Medium-Term researchers’). This enabled comparison of\nthe fractional citation and article contribution of long-term researchers with that\nof medium-term researchers. In all cases, apart from two years (2004 and 2006),\nthe fractional citation contribution per Long-Term researcher was lower for the 1–\n2 collaboration level than for the 2–3 level, and thereafter in all years it decreased\nsteadily as the collaboration level increased; in all years the fractional citation\ncontribution per Medium-Term researcher was lower for the 1–2 collaboration\nlevel than for the 2–3 level, but then decreased steadily as the collaboration level\nincreased. In all cases, apart from two cases (3–4 to 4–5 for 2004; 4–5 to 5–6 for\n2002), the fractional article contribution per Long-Term researcher decreased as\nthe collaboration level increased from 1–2 to 4–6, whereas in all cases the\nfractional article contribution per Medium-Term researcher decreased as the\ncollaboration level increased. In conclusion, the similarity in the findings between\nMedium-Term and Long-Term indicates that findings are unlikely to depend\nmuch on the length of period investigated.\nConclusions\nAs has been found previously for many other data sets, Long Term IS&amp;LS\nresearchers’ articles were more highly cited when more collaborative. In\nagreement with one previous study, however, the productivity of Long Term\nIS&amp;LS researchers decreases as their level of collaboration increases, both in\nterms of the number of articles produced and the total number of citations\nreceived (using fractional counting in both cases). This confirms the previous\nfinding for physics and, because of the focus on long term researchers, ensures\nthat the results cannot be attributed to the exclusion of less productive researchers\nthat may not author an article every year. Hence, the main contribution of this\narticle is the increased evidence (now for two disciplines) that research\n1467\n\nproductivity seems to decline overall with the average number of collaborators.\nDespite this, the optimal average collaboration level seems to be 2-3 rather than 12 in IS&amp;LS, suggesting that a small amount of collaboration is the optimal\nstrategy. Finally, there was considerable variation in the sizes of groups in which\nindividual researchers participated so IS&amp;LS researchers are willing to\nexperiment with different styles.\nAcknowledgements\nThis research is supported by the Economic and Social Research Council [grant\nreference: RES-000-22-4415]. We thank Gertrude Levitt for her very helpful\ncomments on the drafts.\nReferences\nBurrell, Q. &amp; Rousseau, R. (1995). Fractional counts for authorship attribution: A\nnumerical study. Journal of the American Society for Information Science\n46(2), 97–102.\nGazni, A. &amp; Didegah, F. (2011). Investigating different types of research\ncollaboration and citation impact: a case study of Harvard University&#x27;s\npublications. Scientometrics 87(2), 251-265.\nGlänzel W. &amp; De Lange C. (2002). A distributional approach to multinationality\nmeasures of international scientific collaboration. Scientometrics 54(1), 75-89.\nGlanzel, W., Debackere, K., Thijs, B. &amp; Schubert, A. (2006). A concise review on\nthe role of author self-citations in information science, bibliometrics and\nscience policy. Scientometrics 67(2) 263-277.\nLeta, J. &amp; Chaimovich, H. (2002). Recognition and international collaboration:\nThe Brazilian case. Scientometrics 53(3), 325–335.\nLevitt J.M. (2011). Preliminary findings on whether it is good value for money to\nfund larger research groups. ISSI Newsletter.\nLevitt J.M. &amp; Thelwall M. (2010). Does the higher citation of collaborative\nresearch differ from region to region? A case study of Economics.\nScientometrics 85 (1), 171–183.\nPersson, O., Glanzel, W., &amp; Danell, R. (2004). Inflationary bibliometric values:\nThe role of scientific collaboration and the need for relative indicators in\nevaluative studies. Scientometrics 60(3), 421–432.\nPrice, D.J. de Solla (1981). Multiple Authorship. Science 212(4498), 986.\nVogel, E.E. (1997). Impact factor and international collaboration in Chilean\nphysics: 1987–1994. Scientometrics 38(2), 253–263.\n\n1468\n\nRELATIONSHIP BETWEEN DOWNLOADS AND\nCITATION AND THE INFLUENCE OF LANGUAGE\nVicente P. Guerrero-Bote1 and Félix Moya-Anegón2\n1\n\nguerrero@unex.es\nGrupo Scimago, Universidad de Extremadura, Departamento de Información y\nComunicación, Plazuela Ibn Marwan, 06071 Badajoz (Spain)\n2\n\nfelix.demoya@cchs.csic.es\nGrupo Scimago, CSIC, CCHS, IPP, C/Albasanz, 26-28, 28037 Madrid (Spain)\n\nAbstract\n\nDownload indicators represent a great potential due to the high amount of download data\nthat can be collected that can provide a great statistical significance. The relationship\nbetween citation and downloads at journal level and the influence of language on it is\nstudied with the data of Scopus (for citation) and ScienceDirect (for downloads).\nThe results show that the use of downloads as prediction of the citation, is limited, as in\nthe early years is when it obtained less significance. The relationship between downloads\nand citations is also different in different areas.\nIn Francophone regions the downloads of English language journals is proportionately\ngreatly reduced with respect to their citation. There seems to be a part of the citation\nimpact of the non-English language journals invisible in Scopus, which make the number\nof downloads proportionally greater than citations. This has its effect on the lack of\ncorrelation between the downloads and citations in the non-English language journals.\n\nConference Topic\n\nScientometrics Indicators: Criticism and new developments (Topic 1) and Old and New\nData Sources for Scientometric Studies: Coverage, Accuracy and Reliability (Topic 2).\n\nIntroduction\nThe bibliometric indicators used for research evaluation not only take into\naccount quantitative but also qualitative aspects. This is based on the citation of\npapers included in the main databases (Thomson Reuters Web of Science and\nScopus principally) and on the idea that in spite of the different motivations\n(Brooks, 1985), citations are recognitions of previous works (Moed, 2005a).\nHowever, frequently, the application of these bibliometric indicators and these\ninternational databases to certain disciplines has been questioned. For some, the\nbibliometric indicators built from these databases are effective normally in basic\nscience contexts in which research is spread mainly thru scientific journals\n(Filippo &amp; Fernández, 2002). Different research fields have varying yearly\naverage citation rates (Lundberg, 2007). Bibliometric indicators are almost always\nlower in areas of Engineering, Social Sciences and Humanities using the ISI data\n\n1469\n\n(Guerrero et al., 2007) and using Scopus data (Lancho-Barrantes, Guerrero-Bote\n&amp; Moya-Anegón, 2010).\nThroughout the scientific literature some authors have pointed out a lack of\nstatistical significance and normalization that could have been originated by a\nseries of causes: the lack of database coverage in certain areas (Braun, Glänzel &amp;\nSchubert, 2000, Grupo SCImago, 2006, Moya-Anegón et al., 2007), both for the\njournals and principally for types of documents, and the referencing habits in the\ndifferent scientific areas (Broadus, 1971; Clemens et al., 1995; Cronin, Snyder &amp;\nAtkins, 1997; Hargens, 2000; Kyvik, 2003; Lewison, 2001; LindholmRomantschuk &amp; Warner, 1996; Nederhof et al., 1989; Nock, 2001; Price, 1970;\nSmall &amp; Crane, 1979; Thompson, 2002).\nSince scientific literature is now mostly published and accessed online, a number\nof initiatives have attempted to measure scientific impact from download log data.\nThe download data allows scientific activity to be observed immediately upon\npublication, rather than to wait for citations to emerge in the published literature\nand to be included in citation databases; a process that with average publication\ndelays can easily take several years. Shepherd (2007) and Bollen et al, (2008)\npropose a Download Impact Factor as journal metrics which consists of average\ndownload rates for the articles published in a journal, similar to the citation-based\nJIF. Bollen et al. (2005, 2008) demonstrate the feasibility of a variety of social\nnetwork metrics calculated on the basis of download networks extracted from the\nclickstream information contained in download log data.\nBollen et al, (2009) performed a principal component analysis of the journal\nrankings produced by 39 measures of scholarly impact that were calculated on the\nbasis of both citation and download log data. Their results indicate that the notion\nof scientific impact is a multi-dimensional construct that cannot be adequately\nmeasured by any single indicator, although some measures are more suitable than\nothers. They observed a greater reliability of download measures possibly caused\nby the high amount of download data that can be collected.\nAlthough Kurtz et al. (2005) shows how the obsolescence function (Egghe &amp;\nRousseau, 2000) of citations and readership follow similar trajectories across\ntime, Schloegl and Gorraiz (2010, 2011) shows that downloads and citations have\ndifferent obsolescence patterns. Darmoni et al. (2002) and Bollen et al. (2009)\nshow that journal download frequency does not correspond very much to the\nImpact Factor, although Schloegl and Gorraiz (2011) computed a high correlation\nat the journal level between citation and download frequencies when using\nabsolute values and a moderate to high correlation when relating usage and\ncitation impact factors. Wan, Hua, Rousseau, and Sun (2010) defined also a\ndownload immediacy index.\nAlthough citation indicators are accepted by the international scientific\ncommunity, they have problems of statistical significance and normalization that\ncould have been originated by the lack of database coverage in certain areas, and\nthe referencing habits in the different scientific areas.\n\n1470\n\nDownload indicators represent a great potential due to the high amount of\ndownload data that can be collected that can provide a great statistical\nsignificance. However, studies indicate that these are only loosely related with\nindicators based on impact. Would it be possible to use downloads as predictors\nof the citation?\nAnd, there is no study about the influence of the language in downloads and in its\nrelationship with citation. Are there differences between downloads and citation\nby language of publication? Is download number by publication languages\nproportional to the citation one? And does the language have influence in the\norigin of the citation and the downloads?\nThus our purpose is to study the relationship between citation and downloads at\njournal level, with the volume of data of ScienceDirect and Scopus, and the\ninfluence of language on it. The origin of download will be also studied.\nMethod and Data\nThe method that we have applied is to relate the downloads of each journal with\nthe citation of that journal so that correlations between them could easily be\nfound. Not to be very rough, and make a finer comparison, we have compared\ndownload counts of downloaded and downloading year with citations to cited\nyear from citing year.\nTo this goal we have used the download data from ScienceDirect and the citation\ndata from Scopus.\nTo set the language differences, we have studied these parameters for non-English\njournals in ScienceDirect. More particularly those having more than 95% of the\npapers in French (15), German (4) or Spanish (4) in the period 2003-2011.\nWe have also defined a control group of English journals in ScienceDirect, so as\nto establish the differences between the non-English and English journals. For\nevery non-English journal, at least one English journal present in both databases,\nbelonging to the same Specific Subject Area and with similar number of papers\npublished was selected as control journal, up to 33 control journals.\nTo go deeper into this, we have compared the geographic origin of both the\ndownload with the citation of both groups.\nNot all journals publish papers every year. There are only 8 non-English journals\n(French) with papers every year and 14 control journals. The rest of journals\nbegin or are incorporated during the period, because of that they have no papers in\nthe first years. However, there are three exceptions, one French journal with no\npaper the last year of the period and two control journals with no papers in the last\ntwo years.\nThe majority of the journals are concentrated in the Subject Area of Medicine,\nwhere all the German and Spanish journals are added and the majority of the\nFrench. Two other French journals are from &quot;Pharmacology, Toxicology and\nPharmaceutics&quot;, and three from Psychology (although one of the latter also is\nassigned to Medicine). The majority of the control journals are included also in\n“Medicine” (27) (2 in &quot;Pharmacology, Toxicology and Pharmaceutics&quot; and 6 in\n1471\n\nPsychology), however, many other subject areas appear because of the addition of\njournals to multiple Subject Areas.\nIn the data from ScienceDirect supplied by Elsevier, each paper, regardless of\ndocumental type, has two dates, the online date and the publishing date. It is usual\nat present to publish a paper online before in the journal issue, a way to take\nadvantage of the “Early View” effect (Moed, 2005b; Craig et al., 2007; Davis et\nal., 2008). We have calculated the difference between these two dates (publication\ndate minus online date expressed in days), and it can be observed (in table 1) that\nin the first part of the period such difference is negative (they were published\nonline some time after they were published in the issue). It can be observed also\nhow during the period the difference closes to cero and becomes positive at the\nend of the period. That may be caused by a retrospective incorporation to\nScienceDirect. For example, Masson journals started in ScienceDirect in\n2010/2011, while they were already quite far in their volume numbering. E.g.,\nMasson published volumes 1-10, and first Elsevier processed issue is volume 11\nin 2010. What ScienceDirect then does is back-capture volumes 1-10 and add\nthose to ScienceDirect. The on-line dates are then the dates the back-captured\narticles are added to ScienceDirect. That means that the publication/cover dates\nare older than the on-line dates, which gives those weird minus figures in the\ntables. This especially happened with Spanish titles, and also with French ones,\nalthough many French journals were already in ScienceDirect for a long time so\nthat the effect is less. German titles from Urban&amp;Fischer show the same patterns,\nalthough less since Elsevier acquired U&amp;F much earlier than the Spanish\npublications.\nThe types of documents of the data provided by Elsevier ScienceDirect that\naccumulate more than 5% of downloads which have more than 500 downloads\nper paper and which accumulate a percentage of downloads superior to its\npercentage of papers are Review Article, Short Survey, Full length article and\nShort Comunication. The other types of documents do not involve major\nscientific contributions. Therefore in this paper we focus on these four document\ntypes from ScienceDirect as primary production.\nIn Scopus, documental typology is slightly different. The three types that\naccumulate more than 2% of the citation and more than 5 citations per paper on\naverage are Reviews, Articles and Conference Papers. However, while this is true\nin this Journal Set, in general in Scopus, the Short Surveys accumulate a citation\nsimilar to the Conference Papers, so that we included it in this study, along with\nthe above three as primary documents.\nThe records from ScienceDirect are 79,363, while the records from Scopus are\n43,914. The divergence is mainly because Scopus covers all items except types:\nconference/meeting abstracts and book reviews. Specifically, the abstracts\nrepresent over 38% of the records of ScienceDirect.\n\n1472\n\nTable 1: Average difference between the online date and the publication date\n(publication date minus online date) expressed in days. They are grouped by the year\nof publication in the issue.\nJournal\nLanguage Ndocc\nAcute Pain\nEnglish\n132\nAddictive Behaviors\nEnglish\n1819\nAlzheimer&#x27;s &amp; Dementia\nEnglish\n290\nAsian Journal of Psychiatry\nEnglish\n137\nBiomedical and Environmental Sciences\nEnglish\n322\nChildren and Youth Services Review\nEnglish\n1150\nClinical Microbiology Newsletter\nEnglish\n341\nContraception\nEnglish\n1337\nDiagnostic Microbiology and Infectious Disease\nEnglish\n1789\nEarly Human Development\nEnglish\n1014\ne-SPEN, the European e-Journal of Clinical Nutrition and Metabolism\nEnglish\n178\nEuropean Journal of Integrative Medicine\nEnglish\n67\nEuropean Journal of Pharmaceutical Sciences\nEnglish\n1368\nEXPLORE: The Journal of Science and Healing\nEnglish\n460\nForensic Science International Supplement Series\nEnglish\n30\nGeneral Hospital Psychiatry\nEnglish\n766\nInternational Journal of Drug Policy\nEnglish\n450\nInternational Journal of Pediatric Otorhinolaryngology Extra\nEnglish\n366\nJapanese Dental Science Review\nEnglish\n49\nJournal of Adolescent Health\nEnglish\n1598\nJournal of Cardiology Cases\nEnglish\n175\nJournal of Hepatology\nEnglish\n2325\nJournal of Medical Colleges of PLA\nEnglish\n259\nJournal of Pediatric Urology\nEnglish\n670\nJournal of the American Academy of Child &amp; Adolescent Psychiatry\nEnglish\n1278\nMental Health and Physical Activity\nEnglish\n50\nMicrobial Pathogenesis\nEnglish\n711\nNanomedicine: Nanotechnology, Biology and Medicine\nEnglish\n403\nProgress in Lipid Research\nEnglish\n208\nResearch in Social and Administrative Pharmacy\nEnglish\n228\nSexologies\nEnglish\n222\nSurgical Pathology Clinics\nEnglish\n131\nTaiwanese Journal of Obstetrics and Gynecology\nEnglish\n598\nActualités Pharmaceutiques\nFrench\n461\nActualités Pharmaceutiques Hospitalières\nFrench\n183\nAnnales Médico-psychologiques, revue psychiatrique\nFrench\n957\nArchives de Pédiatrie\nFrench\n2732\nGynécologie Obstétrique &amp; Fertilité\nFrench\n1206\nJournal de Pédiatrie et de Puériculture\nFrench\n367\nLa Revue de Médecine Interne\nFrench\n1573\nLa Revue de Médecine Légale\nFrench\n29\nL&#x27;Encéphale\nFrench\n968\nMédecine &amp; Droit\nFrench\n224\nNeuropsychiatrie de l&#x27;Enfance et de l&#x27;Adolescence\nFrench\n613\nNutrition Clinique et Métabolisme\nFrench\n273\nPratiques Psychologiques\nFrench\n244\nPsychologie Française\nFrench\n202\nRéanimation\nFrench\n132\nDas Neurophysiologie-Labor\nGerman\n63\nKrankenhaus-Hygiene + Infektionsverhütung\nGerman\n105\nOsteopathische Medizin\nGerman\n70\nPublic Health Forum\nGerman\n282\nCardiocore\nSpanish\n90\nRevista de Psiquiatría y Salud Mental\nSpanish\n69\nRevista Española de Patología\nSpanish\n243\nRevista Internacional de Acupuntura\nSpanish\n171\n\n2003\n15.4\n190.7\n\n2004\n-68.1\n106.9\n\n2005\n21.1\n177.9\n-76.0\n\n2006\n37.1\n235.7\n-5.5\n\n2007\n43.6\n224.1\n2.2\n\n6.9\n-95.6\n-11.5\n50.9\n35.3\n\n71.1\n-16.5\n9.4\n10.4\n44.8\n\n145.1\n-26.5\n39.4\n26.7\n51.7\n\n233.5\n-1.5\n85.5\n78.5\n94.4\n\n111.5\n-1.1\n50.2\n77.9\n170.9\n4.6\n\n10.5\n\n41.4\n\n55.4\n-12.3\n\n97.0\n-15.1\n\n90.0\n-24.9\n\n-17.4\n1.1\n\n-18.3\n49.7\n\n-10.5\n23.2\n\n-2.4\n35.8\n51.5\n\n-4.1\n142.5\n75.7\n\n8.7\n\n13.0\n\n9.4\n\n35.2\n\n53.3\n\n35.3\n\n69.4\n\n90.9\n\n99.3\n\n117.9\n-2327.0 -1970.0 -1595.0\n22.9\n\n42.2\n\n80.9\n\n87.8\n\n13.2\n-53.1\n3.7\n-26.1\n\n-1812.7 -1460.6\n\n-29.3\n-102.0\n-53.3\n-130.2\n-248.9\n\n20.6\n26.4\n19.3\n54.9\n-20.8\n\n-1239.1\n-80.8\n-24.3\n9.1\n9.3\n14.6\n-25.3\n-2.9\n\n-147.5\n-36.2\n-18.6\n\n-1290.0\n37.1\n45.5\n4.5\n30.4\n45.6\n\n2008\n37.2\n140.5\n13.2\n3.8\n-79.5\n178.8\n-1.8\n51.0\n81.4\n137.8\n66.1\n\n2009\n54.7\n129.1\n0.6\n6.2\n-75.4\n153.8\n5.5\n111.6\n43.0\n68.3\n47.9\n11.6\n79.3 72.5\n-3.5 -5.4\n53.6\n22.4 98.6\n214.7 256.9\n123.0 228.9\n33.8 54.3\n84.5 114.8\n\n97.3\n76.2 81.0\n-90.6 -39.3 -70.7\n197.2 200.5 155.6 143.3\n-1238.6 -864.5 -466.4 -94.0\n38.2 109.5\n35.7\n84.0 118.2 70.4\n-13.8\n5.5\n76.4 182.5\n80.3\n80.4 109.2 76.2\n-8.5\n-19.4 25.5 143.2\n-32.3\n16.5\n76.2 38.4\n-5.0 -12.5\n-1089.9 -415.2 -109.1 -48.3\n-238.7 -74.2\n-952.6 -577.7 -260.0 -85.6\n85.5\n104.0 224.9 85.9\n33.6\n17.8\n-7.3 24.7\n-0.8\n-41.8 -3.0 -2.2\n31.5\n15.9\n22.4 29.6\n81.5\n87.0 139.7 144.8\n\n-862.3 -428.0 -127.9 46.5 88.2\n-42.2\n-3.5\n22.1\n4.0\n16.9\n-43.0\n-6.5\n16.8\n66.4 112.4\n17.0\n-62.1 -58.1 -15.9 2.0\n14.9\n36.2\n53.8\n62.1 245.7\n81.6\n80.0\n145.8 115.9 111.0\n-14.1\n-6.7\n-74.4 -39.5 65.5\n-2.6\n5.6 153.5\n-5.1\n19.9\n1.0\n-151.1 -58.2\n23.6\n10.4 44.8\n-20.0 -116.0\n-1448.7 -1081.4 -706.7 -348.1\n-416.8 -197.1 -68.9\n\n2010\n\n2011\n\n127.4\n23.8\n13.8\n-64.3\n139.3\n-2.2\n117.2\n63.1\n18.4\n39.2\n35.4\n68.3\n-7.8\n\n122.8\n13.8\n14.4\n-66.2\n138.8\n5.5\n172.1\n38.4\n53.0\n36.9\n6.3\n51.2\n-4.2\n\n102.0\n195.4\n359.4\n152.4\n121.4\n127.9\n84.6\n-64.5\n212.3\n33.7\n103.2\n100.3\n198.9\n144.4\n213.7\n88.9\n-58.6\n-54.2\n-67.0\n-153.6\n55.2\n-4.5\n2.7\n48.8\n83.2\n-16.8\n108.5\n14.9\n173.7\n9.7\n329.9\n49.0\n-35.7\n58.6\n30.7\n-62.3\n38.1\n-13.0\n-62.0\n-20.8\n-113.4\n\n48.4\n62.0\n309.8\n139.1\n139.5\n70.8\n193.4\n-64.5\n199.6\n32.8\n122.4\n95.5\n194.4\n105.0\n331.3\n83.5\n-4.5\n-43.1\n-112.0\n-135.4\n81.0\n10.3\n14.0\n59.0\n151.0\n8.6\n87.4\n37.8\n201.1\n7.8\n472.2\n33.8\n59.5\n21.0\n-30.4\n38.2\n83.6\n-41.2\n61.3\n-147.5\n\nIt may seem a bit inconsistent that one documental type from Scopus considered\nprimary production are &quot;Conference Papers&quot;, while the type &quot;Conference&quot; from\nScienceDirect has not been considered. However, the percentage involved is quite\nsmall, and the percentage of downloads which accumulates is even lower, which\nmeans that the number of downloads per papers is below average. And at the\nsame time the &quot;Conference Papers&quot; from Scopus are included primarily as &quot;Full\n1473\n\nLength Articles&quot; and only less than 5% of them are listed as &quot;Conference&quot; from\nScienceDirect, because ScienceDirect assign ‘Full Length Article’ to full\nscientific papers in Conference issues. Then, though “Conference Papers” of\nScopus represents the greater part of “Conference” of ScienceDirect, they do not\nget a large number of downloads.\nResults and discussion\nIn Figure 1, the average of citation from primary documents considered have been\nrepresented per Scopus documental types and age. Unlike other similar\nrepresentations in this case they have not been made per calendar year, but the\ntime difference between the citing and cited document has been considered. That\nis, for instance to calculate the citation average in the eighth year, only the papers\nwith a minimum of 8 years have been considered, and the average was calculated\nwith citation aged between 7 and 8 years. As in Scopus only pre-2012 citation can\nbe considered almost complete, to calculate the citation average of 8 years only\npapers published in 2003 were considered since they are the only ones having at\nleast eight full years to receive citations. To calculate the citation average of seven\nyears papers published in 2003 and 2004 were considered since they are the only\nones having at least 7 full years to receive citations. And so on. This means that\nthe data for lesser age are statistically more significant because they have been\ncomputed with larger datasets.\nThe citation maximum for Reviews is obtained at 3 years. For articles, the citation\nfor the third and fourth years is very similar, and the fall is much slower, the\ncitation in the seventh year exceeds even that of the second year.\nAverage of Downloads\n\nAverage of Citations\n\n2.5\n2\n\n1.5\n1\n0.5\n0\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n900\n800\n700\n600\n500\n400\n300\n200\n100\n0\n1\n\n2\n\n3\n\nYears old\n\n4\n\n5\n\n6\n\n7\n\n8\n\nYears Old\n\nReview\n\nArticle\n\nReview article\n\nShort survey\n\nConference Paper\n\nShort Survey\n\nFull length article\n\nShort communication\n\nFigure 1: Average of primary Citations per Scopus document type by age in years of\nthe Journal Set and Averages of Downloads of the main Science Direct document\ntypes per Science Direct paper by years of difference with respect to the online\npublication date.\n\nIn the second part of Figure 1, a similar representation has been made but with\nregard to the downloads. In this case, the online date has been used as reference.\nSimilarly, the number of years shown on the horizontal axis refers to the\ndifference between the date of download and online publication date. To calculate\neach average, only those papers that have the corresponding full annuity to be\n1474\n\ndownloaded have been considered. In 8, only those downloads in which the\ndifference between the download and the online date is between 7 and 8 years\nhave been considered.\nIn this case all the curves are monotonic decreasing, while in the previous figure\nas a result of the time required for citation from the date in which the cited paper\nis published until the citing paper is made and published.\nIn the case of downloads, the diffusion made when the paper is published online\nand the large number of downloads that results from novelty are very evident.\nAlso there is a greater difference between Reviews and Articles.\nFigure 2 shows the citation from primary papers toward primary papers by\nSubject Areas. The way of computation is similar to the previous one. The peak in\nthe seventh year of Pharmacology, Toxicology and Pharmaceutics is striking,\nhowever it is because in 2005 two of the four journals of the subject area enter,\nwhich lower significantly the citation average, except for that incidence the curves\nare quite similar.\nThe second part of Figure 2 similarly shows download averages by Subject areas\nand years. As in the first part, irregularities in the curve of Pharmacology,\nToxicology and Pharmaceutics are observed, following the incorporation of the\nfour journals assigned to it at different times.\nAlso striking is the difference in the order of the Subject Areas, while Medicine is\nthe one with the highest average of citations, it is the one that has the lowest\ndownloads. Psychology while always behind in citations, is always ahead in\ndownloads. This may, once again, be indicative of different patterns in different\nareas.\n600\nAverage of Downloads\n\nAverage of Citations\n\n2\n1.5\n1\n0.5\n0\n\n500\n400\n300\n200\n\n100\n0\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\nYears Old\n\nPharmacology, Toxicology and Pharmaceutics\nPsychology\nMedicine\n\n8\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\nYears Old\n\nPharmacology, Toxicology and Pharmaceutics\nPsychology\nMedicine\n\nFigure 2: Average of primary citation toward primary papers, and average of\ndownloads of primary papers by Subject Area (only the three original Subject\nAreas).\n\nTable 2 shows the correlation between averages of downloads and averages of\ncitations by journals, year of publication and of citation or download “age” using\nthe same calculation method as above. The only difference is that, in order to\nallow both data to be comparable, for download “age”, the date of publication of\nthe paper in the journal has been used instead of online publication date as above.\nIn columns the age of the citation and in rows the age of the downloads. The last\n1475\n\ncolumn and row correspond to the sum of all averages of citation/downloads as an\naverage of citation/downloads of up to 8 years old. There is a certain time delay\nbetween download and citation: if an author downloads an article, he must first\nread it, include it a new paper he is writing, and that paper must be published. All\nthis may take 1-2 years, sometimes even more, depending upon journal and\nperhaps field.\nTable 2: Correlations between averages of downloads and averages of citations by\njournals, year of publication and of citation or download “age”. In columns the age\nof the citation and in rows the age of the downloads. The last column/row correspond\nto the sum of all averages of citation/downloads.\n\nDY\\CY\n1\n2\n3\n4\n5\n6\n7\n8\nΣ\n\n1\n0.77\n0.71\n0.66\n0.63\n0.64\n0.61\n0.73\n0.72\n0.65\n\n2\n0.78\n0.75\n0.71\n0.69\n0.68\n0.66\n0.73\n0.72\n0.71\n\n3\n0.82\n0.79\n0.76\n0.74\n0.73\n0.7\n0.76\n0.74\n0.76\n\n4\n0.85\n0.84\n0.79\n0.77\n0.75\n0.72\n0.77\n0.78\n0.77\n\n5\n0.86\n0.87\n0.83\n0.78\n0.76\n0.75\n0.8\n0.8\n0.79\n\n6\n0.88\n0.89\n0.85\n0.81\n0.75\n0.76\n0.81\n0.8\n0.79\n\n7\n0.93\n0.93\n0.92\n0.86\n0.85\n0.81\n0.82\n0.84\n0.83\n\n8\n0.94\n0.94\n0.93\n0.92\n0.89\n0.9\n0.77\n0.82\n0.82\n\nΣ\n0.51\n0.6\n0.63\n0.67\n0.7\n0.71\n0.78\n0.79\n0.73\n\nTable 2 shows that the highest correlation is between the number of downloads of\none year of difference and the citation 8 years of difference. The average\ncorrelation between the number of downloads and the citation of the same age is\n0.78 (the diagonal), between the number of downloads and the citation of two\nmore years of difference is 0.84 and between the citation and the number of\ndownloads of 2 years more of difference 0.73. These results are consistent with\nthe idea that there is a certain time delay between download and citation.\nTable 3 shows the correlations between downloads and citations of two more\nyears of age separated by groups with levels of statistical significance. The\ncorrelations are significant and positive for the total and for the control set.\nHowever, they are lower (in some cases even they may be slightly negative) and\nof little significance in the case of non-English language journals.\nTable 4 has been made with the same data as table 3, but in this case columns of\ndownloads have been correlated with the column that sums the averages of\ncitation up to 8 years of age. With this you can see which are the most significant\ndownloads when predicting total citations obtained by each journal. In this case\nwe can see that none of the correlations of the non-English language journals are\nstatistically significant at a level of α = 0.05. The most significant is the third year\nwith a correlation below 0.2.\n\n1476\n\nTable 3: Correlations between averages of downloads and averages of citations by\njournals, year of publication and of citation or download “age”. The citation “age” is\ntwo years more than download “age”. The correlations have been separated by\nlanguage of publication.\n\n1-&gt;3 2-&gt;4 3-&gt;5 4-&gt;6 5-&gt;7\nr 0.82 0.84 0.83 0.81 0.85\nTotal\nα &lt;0.01 &lt;0.01 &lt;0.01 &lt;0.01 &lt;0.01\nr 0.80 0.86 0.83 0.82 0.87\nEnglish\nα &lt;0.01 &lt;0.01 &lt;0.01 &lt;0.01 &lt;0.01\nr 0.29 0.33 0.21 -0.03 -0.31\nNon-English\nα 0.01 0.02 0.16 0.89 0.18\n\n6-&gt;8\n0.90\n&lt;0.01\n0.90\n&lt;0.01\n0.36\n0.34\n\nΣ\n0.73\n&lt;0.01\n0.71\n&lt;0.01\n0.43\n&lt;0.01\n\nTable 4: Correlations between averages of downloads and the sum of the averages of\ncitations by journals, year of publication and of citation or download “age”. The\ncorrelations have been separated by language of publication.\n\nr\nα\nr\nEnglish\nα\nr\nNon-English\nα\nTotal\n\n1\n0.51\n&lt;0.01\n0.45\n&lt;0.01\n0.07\n0.46\n\n2\n0.60\n&lt;0.01\n0.56\n&lt;0.01\n0.15\n0.13\n\n3\n0.63\n&lt;0.01\n0.60\n&lt;0.01\n0.20\n0.08\n\n4\n0.67\n&lt;0.01\n0.64\n&lt;0.01\n0.12\n0.34\n\n5\n0.70\n&lt;0.01\n0.68\n&lt;0.01\n0.04\n0.78\n\n6\n0.71\n&lt;0.01\n0.69\n&lt;0.01\n-0.005\n0.98\n\n7\n0.78\n&lt;0.01\n0.77\n&lt;0.01\n-0.09\n0.71\n\n8\n0.79\n&lt;0.01\n0.74\n&lt;0.01\n0.27\n0.48\n\nΣ\n0.73\n&lt;0.01\n0.71\n&lt;0.01\n0.43\n&lt;0.01\n\nThe correlations of the control journals are statistically significant and positive.\nThe highest correlation is obtained in the seventh year.\nHowever, in many cases, only the citation obtained in the first three years is taken\ninto account, which is why we have created Table 5 which shows the correlation\nof the averages of downloads of different ages with the sum of the averages of\ncitation of the first three years. In this case the correlation increases slightly in the\nearly years in cases of non-English journals although the correlation is still quite\nlow. In the case of the control journals, all the correlations have a high level of\nstatistical significance, and the maximum value is obtained in the downloads of\nseven years of “age”, although the first three years rise steeply with respect to the\ncorrelations in Table 4.\nFor the study and comparison of the origin of the downloads and the citation, two\ntables were generated by countries with the number of citations and downloads of\neach country to the control journals of English language in one column, to the\nFrench-language journals in another, to the German language journals in another\nand to the Spanish language journal in the fourth. We have also calculated other\ncolumns with the total number of citations and downloads and with citations and\ndownloads of the three groups of journals to study (the French language journals,\n1477\n\nthe German language journals and Spanish language journals). The countries in\nthis table have been ordered by the scientific production in the period. From them\nwe have kept the data of the 50 most productive countries, which are those with\nmore than 25,000 papers in the period 2003-2011.\nTable 5: Correlations between averages of downloads and the sum of the averages of\ncitations of up to 3 years old by journal, year of publication and of citation or\ndownload “age”. The correlations have been separated by language of publication.\n\nr\nα\nr\nEnglish\nα\nr\nNon-English\nα\nTotal\n\n1\n0.66\n&lt;0.01\n0.61\n&lt;0.01\n0.24\n&lt;0.01\n\n2\n0.74\n&lt;0.01\n0.72\n&lt;0.01\n0.33\n&lt;0.01\n\n3\n0.73\n&lt;0.01\n0.71\n&lt;0.01\n0.33\n&lt;0.01\n\n4\n0.72\n&lt;0.01\n0.70\n&lt;0.01\n0.20\n0.12\n\n5\n0.70\n&lt;0.01\n0.68\n&lt;0.01\n0.12\n0.44\n\n6\n0.68\n&lt;0.01\n0.65\n&lt;0.01\n0.09\n0.63\n\n7\n0.75\n&lt;0.01\n0.73\n&lt;0.01\n-0.01\n0.98\n\n8\n0.74\n&lt;0.01\n0.67\n&lt;0.01\n0.27\n0.49\n\nΣ\n0.75\n&lt;0.01\n0.73\n&lt;0.01\n0.54\n&lt;0.01\n\nBy correlating the columns, correlations higher than 0.98, statistically significant\nat α = 0.01 level were found between downloads and citations to the same type of\njournals. The downloads and citations of the control journals have correlations\nhigher than 0.93, statistically significant at α = 0.01 level with the scientific\nproduction and the total sum of downloads and citations (to the control journals\nand non-English language journals) while downloads and citations of non-English\nlanguage journals do not correlate significantly, either by language or as a set\n(only two correlations are significant at α = 0.01, which are slightly less than 0.5,\nboth with the total sum of downloads in each country, one of them is of the\ncitations to French journals and the other of the citations to non-English language\njournals).\nAs Table 6 shows, the countries with the highest percentage of downloads of\ncontrol journals (relative to the total number of downloads thereof) are USA,\nChina and UK. The following country is Canada, although it has a higher\npercentage of downloads of the French journals. The countries with the highest\npercentage of the French Journals downloads are France, Tunisia, Canada,\nAlgeria and Belgium all Francophones, although Tunisia and Algeria are not\namong the 50 most productive. Germany, Switzerland and Austria are for German\nJournals. Switzerland also has a high percentage of downloads from the French\nJournals. Spain, Brazil, Argentina and Uruguay are for Spanish Journals, the last\ntwo at a great distance, and Brazil not being a Spanish speaking country. If we\ncompare these percentages of downloads with the percentage of total downloads,\nwe see that the three countries with the highest percentage of Control Journals\nhave a slightly higher percentage of them than the total, the ratio is slightly\ngreater than unity. In the case of the French Journals, the ratio becomes slightly\nlarger. Curiously, Tunisia and Algeria have the highest ratio. This ratio continues\n1478\n\nto increase in the case of the German Journals and especially the Spanish Journals\nindicating that these downloads are more concentrated in those countries.\nTable 6: The Highest Percentages of Downloads of the Control (%CD), French\n(%FD), German (%GD) and Spanish (%SD) journal group with respect to the total\nnumber of downloads of each group, ratio of these percentages with respect to the\nDownload percentage of each country (%TD) and similar citation ratios.\n\n1479\n\nIf you calculate a similar ratio to citation, we can see that the control journals\nhave lower ratios (that of downloads) in the case of USA, UK and China and\nhigher in the remaining cases. The French Journals have higher citation ratios in\nmost of the countries shown. The German Journals only in France and Canada.\nThe Spanish Journals only in the case of USA, UK and Belgium.\n1.2\n\nIndia\n1\n\nUnited States\nPoland United Kingdom\nIran\nAustralia\nRussian Federation Israel Austria\nNetherlands Sweden\nTurkey\nGreece\nDenmark\nBrazil\nGermany\nItaly\n\n0.8\n\nJapan\n\nTaiwan\n\nSouth Korea\n\nChina\n\nSpain\nCanada\n\ncRR\n\nSwitzerland\n\n0.6\nBelgium\n\n0.4\n\nFrance\n\n0.2\n\n0\n\n0\n\n1\n\n2\n\n3\n\n4\neRR\n\n5\n\n6\n\n7\n\n8\n\nFigure 3: Ratio of downloads with respect to citations of the journals of control\n(cRR) against the French, German and Spanish language journals (eRR). The size is\nproportional to the number of total national downloads. The 27 countries with the\nhighest scientific production are represented.\n\nSome others relative columns have also been calculated per country, as the ratio\nof downloads with respect to citations:\n\nWhere d are downloads, of a journal group (gd) or in total (td), and c are citations\nto a journal group (gc) or in total (tc). The measurements calculated in this way\nfor each country were: cRR (ratio of downloads of the control journals with\nrespect to its citations ratio), fRR (ratio of downloads of the French journals with\nrespect to its citations ratio), gRR (ratio of downloads of the German journals with\nrespect to its citations ratio), sRR (ratio of downloads of the Spanish journals with\nrespect to its citations ratio), eRR (ratio of downloads of the French, German and\nSpanish journals with respect to its citations ratio).\n\n1480\n\nRegarding download ratios with respect to the citations, we found that the control\njournals (cRR) average in the top 50 countries of 0.93 with a standard deviation of\n0.12. While the group consisting of French, German and Spanish language\njournals (eRR) has an average of 2.35 with a standard deviation of 1.36 (mean\ndifference significant at the α = 0.01). This means that in these countries the\ncontrol journals are cited in greater proportion to the downloading, while the\nFrench, German and Spanish languages journals are downloaded twice with\nrespect to its citation. This can be seen in figure 3.\nAs you can see countries with the lowest downloaded papers of the control\njournals with respect to the citing, have a francophone link. This effect does not\noccur in the case of Spanish or German, but we must take into account that the\nGerman and Spanish journals studied are very few, and some of them seem to\nhave been included on ScienceDirect retrospectively.\nConclusions\nThe number of papers from Scopus and ScienceDirect is different, because the\nfirst includes all items except types: conference/meeting abstracts and book\nreviews. The divergence is mainly because of conference/meeting abstracts.\nThe set of journals in German and Spanish language is not very significant in\norder to find separate conclusions.\nThe citation and download curves with respect to time are different. The time\nrequired for a paper to be cited can be seen in the citation curves and the effect of\nnovelty in download curves. The proportional difference between the downloads\nreceived by the reviews and other types of documents increases with respect to\nthe citation.bi\nThe order of the Subject Areas in average citation does not match the order in\naverage download. This leads to different patterns in different areas i.e.\nresearchers in different areas cite proportionally differently with respect to what\nthey read.\nThere are statistically significant correlations between the downloads and\ncitations for journals and years, but these are greatly reduced in both value and\nstatistical significance in the case of non-English language journals. Some\ninfluence on these results can have the late incorporation of these journals to\nScienceDirect.\nIn the control journals, at first there is a novelty effect that makes many\ndownloads occur that do not result in citations. This may be the reason why the\nfirst year is the one which obtain lower correlations. Interestingly the highest\ncorrelations are those of the sixth or seventh year of age, which may correspond\nto when researchers are looking for a particular paper probably redirected by a\ncitation.\nAll this makes the use of downloads as prediction of the citation, limited, as in the\nearly years is when it obtained less significance. In no case thus does it reach the\ncorrelation between the citation of the first three years with the citation total\n\n1481\n\n(0.91). This circumstance is even greater in the case of non-English language\njournals.\nThe 50 most productive countries download the control journals proportional\nslightly less than they cited them. However the non-English journals to study are\ndownloaded proportionately more than twice what they are cited. This may be due\nto the fact that a part of the citation impact of the non-English journals is invisible\nin Scopus because those who download the papers, also cite them in articles\npublished in journals that are not processed for Scopus.\nIn these 50 most productive countries, there is an association between the\nproportional citation or downloads of control journals with the ratio between\ndownloads and citation of them. This means that those which frequently\nproportionally download or cited the control journals, download them\nproportionately more with respect what they cite them. This same effect does not\noccur in the non-English journals to study.\nIn Francophone regions it is observed how the download of control journals is\nproportionately greatly reduced with respect to their citation. In the case of\nGerman and Spanish language, the study is not very significant because the\nnumber of journals is very small, some of which have been loaded into\nScienceDirect retrospectively.\nDefinitely there seems to be a part of the citation impact of the non-English\nlanguage journals invisible in Scopus, which make the number of downloads\nproportionally greater than citations. This has its effect on the lack of correlation\nbetween the downloads and citations in the non-English journals, which means\nthat the downloads can hardly be used to predict the citation.\nAcknowledgments\nThis work was granted by Elsevier as part of the Elsevier Bibliometric Research\nProgram (EBRP) and financed by the Junta de Extremadura, Consejería de\nEmpleo, Empresa e Innovación and the Fondo Social Europeo as part of the\nresearch group grant GR10019.\nReferences\nBollen, J., Van de Sompel, H. and Rodriguez, M.A. (2008). Towards usage-based\nimpact metrics: First results from the MESUR project. In Joint Conference on\nDigital Libraries (JCDL2006), Pittsburgh, PA, June 2008.\nBollen, J., Van de Sompel, H., Hagberg, A, and Chute, R. (2009). A principal\ncomponent analysis of 39 scientific impact measures. PLoS ONE, 4(6): e6022.\ndoi:10.1371/journal.pone.0006022.\nBollen, J., Van de Sompel, H., Smith, J. and Luce, R. (2005). Toward alternative\nmetrics of journal impact: a comparison of download and citation data.\nInformation Processing and Management, 41(6):1419-1440.\nBraun, T., Glänzel, W., Schubert, A. (2000). How balanced is the Science\nCitation Index’s journal coverage? A preliminary overview of macrolevel\nstatistical data. In: Cronin, B; Barsky Atkins, H (eds.). The Web of knowledge,\n1482\n\na festschrift in honor of Eugene Garfield. Canada: American Society of\nInformation Science, 2000, pp. 251–277.\nBroadus, R. N. (1971). The literature of the social sciences: a survey of citation\nstudies. International Social Sciences Journal, 23: 236–243.\nBrooks, T.A. (1985). Private acts and public objects: an investigation of citer\nmotivations. Journal of the American Society for Information Science, 36(4):\n223-229.\nClemens, E. S., Powell, W. W., Mcilwaine, K., Okamoto, D. (1995). Careers in\nprint: Books, journals, and scholarly reputations. American Journal of\nSociology, 101: 433–494.\nCraig, I., Plume, A., McVeigh, M., Pringle, J., Amin, M. (2007). Do open access\narticles have greater citation impact? A critical review of the literature.\nJournal of Informetrics, 1, 239-48.\nCronin, B., Snyder, H., Atkins, H. (1997). Comparative citation rankings of\nauthors in monographic and journal literature: a study of sociology. Journal of\nDocumentation, 53: 263–273.\nDarmoni, S. J., Roussel, F., Benichou, J., Faure, G. C., Thirion, B., &amp; Pinhas, N.\n(2000). Reading factor as a credible alternative to impact factor: a preliminary\nstudy. Technol. Health Care, 8 (3-4), 174–175.\nDavis, Philip M., Bruce V. Lewenstein, Daniel H. Simon, James G. Booth, and\nMatthew Connolly. (2008). Open Access Publishing, Article Downloads, and\nCitations: Randomized Controlled Trial. British Medical Journal, 337: 331345.\nEgghe, L., &amp; Rousseau, R. (2000). Aging, obsolescence, impact, growth, and\nutilization: Definitions and relations. Journal of the American Society for\nInformation Science, 51 (11), 1004–1017.\nFilippo, D., Fernández, M.T. (2002). Bibliometría: importancia de los\nindicadores bibliométricos. In: El estado de la ciencia. p. 69-76. Red\nIberoamericana de Indicadores de Ciencia y Tecnología (RICYT).\nGrupo SCImago (2006). Análisis de la cobertura de la base de datos Scopus. El\nprofesional de la información, Vol.15, no2: 144-145.\nGuerrero-Bote, V. P., Zapico-Alonso, F., Espinosa-Calvo, M. E., GómezCrisóstomo, R., &amp; Moya-Anegón, F. (2007). The Iceberg Hypothesis: ImportExport of Knowledge between scientific subject categories. Scientometrics,\n71(3): 423-441.\nHargens, L. L. (2000). Using the literature: reference networks, reference\ncontexts, and the social structure of scholarship. American Sociological\nReview, 65 : 846–865.\nKurtz, M. J., Eichhorn, G., Accomazzi, A., Grant, C. S., Demleitner, M., &amp;\nMurray, S. S. (2005). The bibliometric properties of article readership\ninformation. Journal of the American Society for Information Science and\nTechnology, 56: 111-28.\nKyvik, S.(2003). Changing trends in publishing behaviour among university\nfaculty, 1980–2000. Scientometrics, 58: 35–48.\n1483\n\nLancho-Barrantes, B.S., Guerrero-Bote, V.P. , Moya-Anegón, F. (2010). The\nIceberg Hypothesis revisited. Scientometrics, 85: 443-461.\nLewison, G. (2001), Evaluation of books as research outputs in history of\nmedicine. Research Evaluation, 10 : 89–95.\nLindholm-Romantschuk, Y., Warner, J. (1996). The role of monographs in\nscholarly communication: an empirical study of philosophy, sociology and\neconomics. Journal of Documentation, 54 : 389–404.\nLundberg, J. (2007). Lifting the crown—citation z-score. Journal of Informetrics,\n1, 145–154 .\nMoed, H.F. (2005a). Citation Analysis in research evaluation. Dordrecht;\nSpringer, p. 346.\nMoed, H.F. (2005b). Statistical relationships between downloads and citations at\nthe level of individual documents within a single journal. Journal of the\nAmerican Society for Information Science and Technology, 56, 1088-97.\nMoya-Anegón, F., Chinchilla-Rodríguez, Z., Vargas-Quesada, B., CoreraÁlvarez, E., Muñoz-Fernández, F. J., González-Molina, A., et al. (2007).\nCoverage analysis of Scopus: a journal metric approach. Scientometrics, 73,\n(1) , 53-78.\nNederhof, A. J., Zwaan, R. A., De Bruin, R. E., Dekker, P. J. (1989). Assessing\nthe usefulness of bibliometric indicators for the humanities and the social\nsciences. Scientometrics, 15 : 423–435.\nNock, D. A. (2001). Careers in print: Canadian sociological books and their wider\nimpact, 1975–1992. Canadian Journal of Sociology/Cahiers canadiens de\nsociologie, 26: 469–485.\nPrice, D. J. (1970). Citation measures of hard science, soft science, technology,\nand non-science. In: C. E. Nelson, D. Pollack (Eds), Communication Among\nScientists and Engineers. Lexington, Mass., Lexington books.\nSchloegl, C., &amp; Gorraiz, J. (2010). Comparison of citation and usage indicators:\nThe case of oncology journals. Scientometrics, 82(3), 567–580.\nSchloegl, C., &amp; Gorraiz, J. (2011). Global Usage Versus Global Citation Metrics:\nThe Case of Pharmacology Journals. Journal of the American Society for\nInformation Science and Technology, 62(1):161–170.\nShepherd, P.T. (2007). The feasibility of developing and implementing journal\nusage factors: a research project sponsored by UKSG. Serials: The Journal for\nthe Serials Community, 20(2):117-123.\nSmall, H. G., Crane, D. (1979). Specialties and disciplines in science and social\nscience: an examination of their structure using citation indexes.\nScientometrics, 1 : 445–461.\nThompson, J. W. (2002). The death of the scholarly monograph in the\nhumanities? Citation patterns in literary scholarship. Libri, 52 (3) : 121–136.\nWan, J.-K., Hua, P.-H., Rousseau, R., &amp; Sun, X.-K. (2010). The journal download\nimmediacy index (DII): Experiences using a Chinese full-text database.\nScientometrics, 82(3), 555–566.\n\n1484\n\nRELEVANCE AND FOCUS SHIFT: NEW METRICS\nFOR THE GRANT EVALUATION PROCESS PILOT\nTESTED ON NIH GRANT APPLICATIONS (RIP)\nDuane E. Williams1, Leo DiJoseph1, James Corrigan2, Elizabeth Hsu2, Yvette R.\nSeger1, Samantha Finstad2, Emily J. Greenspan3, Jerry S.H. Lee3, Joshua D.\nSchnell1\n1\n\nduane.williams@thomsonreuters.com\nThomson Reuters, Rockville, MD (USA)\n2\n\ncorrigan@mail.nih.gov\nOffice of Science Planning and Assessment, National Cancer Institute, National Institutes\nof Health Bethesda, MD (USA)\n3\n\nemily.greenspan@nih.gov\nCenter for Strategic Scientific Initiatives, National Cancer Institute, National Institutes of\nHealth Bethesda, MD (USA)\n\nAbstract\n\nAmong the challenges faced by program staff in research funding organizations is\nobtaining an early assessment of the suitability of grant applications received in response\nto new funding announcements. Here we present two new metrics that use text mining to\nprovide rapid and objective characterization of grant applications. This pilot study\nassesses the relevance and focus shift of grant applications submitted to the National\nCancer Institute’s (NCI) Provocative Questions (PQ) Initiative (RFA-CA-11-011 and\nRFA-CA-11-012). Relevance is measured by comparing the titles and abstracts of PQ\ngrant applications to the background text on the PQ website summarizing the intent, goals\nand feasibility of each PQ. Focus Shift measures the similarity between PQ applications\nand prior applications submitted to the National Institutes of Health (NIH). Our results\nfound the majority of applications to be relevant, but the relevance scores varied\nsignificantly by topic. Of the applications with very low focus shift scores, manual review\nof a subset found that 25-50% were very similar in scientific approach to previously\nsubmitted grant applications to other funding opportunities. The primary limitations of our\nautomated approach are that similarity measurements are sensitive to the comparison text\nand often unable to distinguish subtle text differences.\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3).\n\nIntroduction\nAutomated assessments of grant portfolios may allow research funding agencies\nto incorporate additional objective and transparent metrics into funding decisions.\n1485\n\nHere we apply automated text similarity calculations in novel ways to aid funding\nagencies in understanding their grant application portfolios. The use of text\nsimilarity algorithms is well established, but most commonly associated with the\nidentification of plagiarized work (Errami, et al., 2010) (Bailey, 2002)(Long,\n2009). In this study, we examine the first round of applications submitted to the\nNational Cancer Institute’s (NCI) Provocative Questions (PQ) Initiative (RFACA-11-011 and RFA-CA-11-012). This initiative sought to challenge the\nscientific community to creatively think about and answer important, but nonobvious or understudied questions in cancer research. To aid program staff in\nassessing the success of the initiative in attracting relevant and novel proposals,\nwe use text similarity to assign numeric values for the relevance and focus shift of\nthe grant applications. The relevance score is intended to assess how well the\napplication responds to the core aspects of the PQ. Focus shift is intended to\nmeasure the extent to which an application represents a distinct approach from\nprior submitted applications. Both measurements are proxies for manual review\naimed at providing program staff with a quick and objective overview of their\ngrant applications. In this study, each application was assessed and assigned a\nsingle relevance score relative to the text used within the public description of the\nfunding opportunity in the Request for Applications (RFA) documents. Two focus\nshift values were calculated for each PQ application. The first was in comparison\nto the investigator’s own prior work (“by-self”), and the second was in\ncomparison to NIH grants received from other investigators (“general”). The\nscheme for calculating these two values is presented below.\nMethods\nCalculating text distances\nText similarity scores were obtained using the FREETEXTTABLE function in\nMicrosoft SQL Server, which is based on the Okapi BM25 algorithm.139 Text\nsimilarity scores were converted to text distances in the range from 0 (similar) to\n1 (dissimilar). The text distance scale from 0 to 1 is illustrated in Figure 1, along\nwith a suggested interpretation of text distance as a measure of relevance and\nfocus shift.\nThe text similarity scores are based on a Term Frequency/Inverse Document\nFrequency calculation (TF/IDF). As such, the values that result depend on the\nselection of pertinent documents that provide a corpus of text. Relevance\nmeasurements were made using a single document corpus of PQ applications and\nother similar grant applications identified as being coincidentally relevant to the\nPQ based on earlier unpublished work. Focus shift measurements were made\nusing a single document corpus of the PQ applications and a comparison cohort of\nNIH applications received prior to the publication of the PQ RFAs. In calculating\n139\n\nMicrosoft Corporation (2008). SQL Server 2008 R2. How Search Query Results Are Ranked\n(Full-Text\nSearch).\nRetrieved\nfrom\nhttp://msdn.microsoft.com/enus/library/ms142524(v=sql.105).aspx.\n1486\n\nfocus shift for each PQ application, the comparison cohort was partitioned into\ntwo subsets based on whether the prior application was submitted by the same\ninvestigator (the “by-self” subset) or by different investigators (the “general”\nsubset).\n\nFigure 14. Text distance scale and suggested interpretation as relevance and focus\nshift. The vertical line at 0.53 denotes the threshold used for a binary classification of\nthe PQ applications.\n\nText distances as scaled texts similarity scores\nThe call to the FREETEXTTABLE function returns a similarity score for each\nordered pair of documents (Score(Left, Right)). The score has a documented\nabsolute range of 0 to 1000, with the highest score corresponding to the most\nsimilar documents. Using the formula below, scores were converted to distance140,\nso that a case with maximal similarity score is converted to a distance of 0, and a\n0 similarity score is converted to a distance of 1 (the maximum distance). We\nexperimented with several ways of defining what represented a maximal\nsimilarity score (e.g., whether to include a document self comparison or allow a\nhypothetical document comparison that would return 1000).\n\nWe defined maximal similarity based on a manual review of a sample of scored\ndocument pairs. For relevance, this value was the highest score for all documents\ncompared to the RFA. For the focus shift by-self measurement, the value was set\nto the highest score obtained in any of the by-self calculations. For the focus shift\nmeasurement relative to the general subset, we expanded the right side corpus to\ninclude the PQ applications, so that the maximal similarity was obtained from\ncomparing a PQ application text to itself.\n\n140\n\nThis is not a distance in the strict sense of a mathematical metric or pseudo-metric. In particular,\ndistance (left, right) is generally not equal to distance (right, left).\n1487\n\nRelevance and focus shift measurement definitions and thresholds\nAfter calculating the scaled text distances, we formally defined relevance as 1relevance text distance, and focus shift (both forms) as the minimum of all focus\nshift distances measured for a given PQ application relative to either the by-self or\ngeneral subsets of prior applications. For the thresholds, rather than attempting to\ncalibrate the text distances (scaled similarity scores) against the results of expert\nmanual comparison, we set the more modest goal of determining a fixed distance\nthreshold value to classify applications as either relevant or not relevant, and as\neither focus shifted or not focus shifted. The thresholds were 0.53 for focus shift\n(both forms) and 0.47 for relevance.\n\nFigure 2. Relevance of PQ application text to RFA text\n\nResults and Discussion\nRelevance\nOf the 754 PQ Applications, 614 (81.4%) were classified as relevant by score.\nBox plots of the measured relevance of all PQ applications are shown in Figure 2\n(Wickham, 2009) (R Development Core Team, 2012). The portion of the\ndistribution to the right of 0.47 represents the applications that were classified as\nrelevant to the background text on the PQ website for each question. The graph\nshows a high degree of variability in relevance among the applications for\nparticular questions and significantly different distributions across the PQs.\nResults from a manual review suggest that our current approach for measuring\nrelevance using text comparisons could be enhanced by a more sophisticated\nmethod that could appropriately account for semantic differences within the text.\nWe are currently working to enhance our model to reflect these subtleties.\nAdditionally, relevance scores were found to be highly influenced by the target\ntext used. The results presented here were limited to the text used publicly to\n\n1488\n\ndescribe the PQs.141 However, this text often has specific references to therapeutic\nagents and methodologies designed to give examples of possible approaches to a\nrespective PQ. When grant applications cite the same examples or even restate the\nproblem, the scores could be inflated. We are currently working to address these\npotential pitfalls by preprocessing the target text used, which might include\naugmenting the text with other more generic descriptions of the problem. We\nshould also note that automated approaches are generally limited in their ability to\ndistinguish subtle differences in language that may indicate to human readers\nsubstantial differences in the content.\nFocus shift\nSince it is expected that investigators will tend to carry over ideas from prior\nresearch, achieving a focus shift classification in comparison to one’s own prior\napplications – the by-self subset – was expected to pose a challenge. Conversely,\nit was expected that finding a very similar scientific approach within a general\nprior application (which excludes the investigator’s own applications) would be\nless likely. Of the 754 PQ Applications, 39 (5.2%) were classified as focus shifted\nrelative to the by-self prior subset score and 271 (35.9 %) were classified as focus\nshifted relative to the general subset score. Box plots of the by-self and general\nforms of the focus shift measurement for all PQ applications are shown in\nFigures 3a and 3b, respectively. The portion of the distribution to the right of\n0.53 represents those applications that were focus shifted relative to the prior\napplications for each question.\n\nFigure 3. Box plots of PQ application focus shift relative to prior (a) by-self\napplications and (b) NIH general applications\n\n141\n\nPQ RFA text used in this analysis can be found online at www.provocativequestions.nci.nih.gov.\n1489\n\nDegree of Scientific Similarity\nTo better understand the correlation of our focus shift measurements with actual\nscientific similarity between two grant applications, we conducted a manual\nreview using subject matter experts with a subset of grant applications with very\nlow focus shift measures (minimum distance &lt;0.05). Using this criterion, 41%\n(311/754) of applications to the PQs were identified as similar, 25% (189/754) of\ngrants were similar to unfunded prior grants submitted by at least one of the\nprincipal investigators on the PQ application, and 12% (88/754) were similar to\nfunded prior grants with publications.\nThe manual review was conducted on 40 applications subdivided into two groups\nbased on the nature of the prior application to which they were most similar:\n1. Applications similar to unfunded prior grants\n2. Applications similar to funded prior grants with publications\nThis review found that PQ applications with low focus shift by-self measures\ncannot be assumed to have been reused from prior grants (see Table 1). Of the\napplications with low focus-shift relative to prior funded grants with publications,\na larger percentage was found to be an extension of the prior work (45%) than the\npercentage with similar scientific approaches to prior grants (25%). PQ\napplications that were similar to prior unfunded grant applications had a greater\nlikelihood of having similar scientific approaches to previously submitted grant\napplications (55%).\nTable 10. Results from manual review of 40 PQ applications with very low novelty\nby-self distances (distances &lt;0.05).\nClassification\nSimilar scientific approach to prior application\nSimilar background/stage setting, scientific\napproach substantially different\nExtensions of prior work\n\nSimilar to\nunfunded grant\napplications\n55%\n30%\n\nSimilar to funded grant\napplications with\nPublications\n25%\n30%\n\n15%\n\n45%\n\nPossible extensions of this work may focus on identifying whether applications\nwith similar scientific approaches were more successful in the review process\nthan applications that represent a true focus shift. We will also investigate\nwhether the trends in scientifically similar applications vary by specific PQ\nquestion to which the application responded. If there is a correlation between\nthese applications and specific questions, it may inform the program staff\nregarding the accessibility of different questions to different audiences.\nRelevance and focus shift quadrants\nFor the 702 PQ applications for which prior by-self applications were found, we\nnow have 2 sets of paired values (focus shift by-self, relevance), and (focus shift\n1490\n\ngeneral, relevance). For the remaining 52 applications we have only the (focus\nshift general, relevance) pair. In this section, we examine the distribution of these\npaired values. As shown below in Figure 4, in Cartesian coordinates of the (focus\nshift, relevance) values, the 2 thresholds define 4 quadrants in which a given\napplication can be found:\n Neither focus shifted nor relevant, lower left quadrant, abbreviated as **\n Focus shifted but not relevant, lower right quadrant, abbreviated as Fs*\n Relevant but not focus shifted, upper left quadrant, abbreviated as *R\n Focus shifted and relevant, upper right quadrant, abbreviated as FsR\n\nFigure 4. Focus shift /relevance quadrants.\n\nOverall distributions of PQ applications over the FsR quadrants\nTable 2 shows the overall distribution of PQ applications across the focus\nshift/relevance quadrants, using the focus shift by-self measurement. This table\nincludes all 754 applications– those with no prior by-self applications were\nclassified into either the (**) or (*R) quadrants depending on whether they were\nrelevant. Table 3 shows the quadrant distribution using the focus shift general\nmeasurement.\nTable 2. Quadrant distribution using focus shift by-self.\nFocus shift by-self\nand relevance\nclassification\nFsR\n*R\nFs*\n**\n\nDescription\nfocus shifted and relevant\nrelevant but not focus shifted\nfocus shifted but not relevant\nneither focus shifted nor relevant\n\nPQ\napplication\ncount\n26\n588\n13\n127\n\nPercentage of\napplications\n3.4%\n78.0%\n1.7%\n16.8%\n\n1491\n\nTable 3. Quadrant distribution using focus shift general.\nFocus shift general\nand relevance\nclassification\nFsR\n*R\nFs*\n**\n\nDescription\nfocus shifted and relevant\nrelevant but not focus shifted\nfocus shifted but not relevant\nneither focus shifted nor relevant\n\nPQ\napplication\ncount\n182\n432\n89\n51\n\nPercentage of\napplications\n24.1%\n57.3%\n11.8%\n6.8%\n\nConclusions\nThis work represents a first step toward the use of automated text mining\nalgorithms to inform the grant evaluation process. The primary limitation of our\ncurrent approach to calculate focus shift and relevance is that when two bodies of\ntext are found to be similar, it may represent a similarity of background and stage\nsetting rather than a similarity of the experimental approach. Generally, focus\nshift measurements were found to be more accurate than relevance in terms of\ntheir agreement with manual assessment of the scientific similarity between\ndocuments. Re-examining the choice of text used for analysis is likely to show\npromise in improving the confidence in the meaning of both focus shift and\nrelevance scores; both measurements may be improved by the inclusion of the\nspecific aims section of grant applications. Another important next step is to use a\nmore sophisticated text mining approach that accounts for semantic relationships\nwithin the documents.\nBibliography\nBailey, B. (2002). Duplicate publication in the field of otolaryngology-head and\nneck. Otolaryngol. Head Neck Surg., 211-216.\nErrami, M., Sun, Z., George, A., Long, T., Skinner, M., Wren, J., et al. (2010).\nIdentifying duplicate content using statistically improbable phrases.\nBioinformatics , 26 (11), 1453-1457.\nLong, T. e. (2009). Responding to possible plagiarism. Science , 323, 1293-1294.\nR Development Core Team. (2012). R: A Language and Environment for.\nVienna: R Foundation for Statistical Computing.\nWickham, H. (2009). ggplot2: elegant graphics for data analysis. New York:\nSpringer.\n\n1492\n\nRELEVANCE DISTRIBUTIONS ACROSS\nBRADFORD ZONES: CAN BRADFORDIZING\nIMPROVE SEARCH?\nPhilipp Mayr1\n1\n\nphilipp.mayr@gesis.org\nGESIS – Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8, 50667\nCologne, Germany\n\nAbstract\n\nThe purpose of this paper is to describe the evaluation of the effectiveness of the\nbibliometric technique Bradfordizing in an information retrieval (IR) scenario.\nBradfordizing is used to re-rank topical document sets from conventional abstracting &amp;\nindexing (A&amp;I) databases into core and more peripheral document zones. Bradfordized\nlists of journal articles and monographs will be tested in a controlled scenario consisting\nof different A&amp;I databases from social and political sciences, economics, psychology and\nmedical science, 164 standardized IR topics and intellectual assessments of the listed\ndocuments. Does Bradfordizing improve the ratio of relevant documents in the first third\n(core) compared to the second and last third (zone 2 and zone 3, respectively)? The IR\ntests show that relevance distributions after re-ranking improve at a significant level if\ndocuments in the core are compared with documents in the succeeding zones. After\nBradfordizing of document pools, the core has a significant better average precision than\nzone 2, zone 3 and baseline. This paper should be seen as an argument in favour of\nalternative non-textual (bibliometric) re-ranking methods which can be simply applied in\ntext-based retrieval systems and in particular in A&amp;I databases.\n\nIntroduction\nThe perceived expectations of users searching the web are that retrieval systems\nshould list the most relevant or valuable documents in the result list first (socalled relevance ranking). More approaches appear that draw on advanced\nmethods to produce relevant results and alternative views on document spaces.\nGoogle PageRank and its derivations (see e.g. Lin, 2008) or Google Scholar’s\ncitation count are just two popular examples for informetric-based rankings\napplied in Internet search engines.\nDistributed search across multiple A&amp;I databases will also generate large and\nheterogeneous document sets with the effect that users are confronted with a\nmassive load of results from different scientific domains, even for specific\nresearch topics. Furthermore, empirical tests with typical A&amp;I databases like\nMedline show that conventional term frequency - inverse document frequency (tfidf) best match models and especially recent web-based ranking methods\nimplemented in search engines (originally for web pages) are not always\nappropriate for search in heterogeneously collected scholarly metadata\ndocuments.\n1493\n\nIn this paper we want to apply and evaluate a non-textual ranking technique,\ncalled Bradfordizing. Introduced by H.D. White (1981), Bradfordizing is a\nbibliometric method to reorganize a search result for a topic. Bradfordizing is set\nup by applying the following procedure:\n“... that is sorting hits (1) by the journal in which they appear, and then\nsorting these journals not alphabetically by title but (2) numerically, high to low,\nby number of hits each journal contains. In effect, this two-step sorting ranks the\nsearch output in the classic Bradford manner, so that the most productive, in terms\nof its yield of hits, is placed first; the second-most productive journal is second;\nand so on, down through the last rank of journals yielding only one hit apiece.”\n(White, 1981: p. 47).\nBradford Law\nJournals play an important role in the scientific communication process. They\nappear periodically, they are topically focused, they have established standards of\nquality control and often they are involved in the academic gratification system.\nMetrics like the famous impact factor are aggregated on the journal level. In some\ndisciplines journals are the main place for a scientific community to communicate\nand discuss new research results. These examples shall illustrate the impact\njournals bear in the context of science models (Börner et al., 2011). Modeling\nscience or understanding the functioning of science has a lot to do with journals\nand journal publication characteristics. These journal publication characteristics\nare the point where Bradford law can contribute to the larger topic of science\nmodels.\nBradford law of scattering bases on literature observations the librarian S.\nBradford has been carried out in 1934. His findings and after that the formulation\nof the bibliometric model stand for the beginning of the modern documentation\n(Bradford, 1948) – a documentation which founds decisions on quantifiable\nmeasures and empirical analyses. The early empirical laws described by Lotka,\nZipf and of course Bradford are landmark publications which still influence\nresearch in scientometrics (Bookstein, 1990), but also in other research\ncommunities like computer science or linguistics. In brief, scientometric and\ninformetric research investigates the mathematical descriptions and models of\nregularities of all observable objects in the library and information science area.\nThese objects include authors, publications, references, citations, all kinds of texts\netc. Bradford’s work bases on analyses with journal publications on different\nsubjects in the sciences.\nFundamentally, Bradford law states that literature on any scientific field or\nsubject-specific topic scatters in a typical way. A core or nucleus with the highest\nconcentration of papers - normally situated in a set of few so-called core journals is followed by zones with loose concentrations of paper frequencies (see Figure 1\nfor a typical Bradford distribution). The last zone covers the so-called periphery\njournals which are located in the model far distant from the core subject and\nnormally contribute just one or two topically relevant papers in a defined period.\n1494\n\nBradford law as a general law in informetrics can successfully be applied to most\nscientific disciplines, and especially in multidisciplinary scenarios (Mayr, 2009).\nBradford describes his model in the following:\n“The whole range of periodicals thus acts as a family of successive\ngenerations of diminishing kinship, each generation being greater in number than\nthe preceding, and each constituent of a generation inversely according to its\ndegree of remoteness.” (Bradford, 1934)\nBradford provides in his publications (1934, 1948) just a graphical and verbal\nexplanation of his law. A mathematical formulation has been added later by early\ninformetric researchers. Bradford`s original verbal formulation of his observation\nhas been refined by Brookes (1977) to\n\na  r \nG(r )  k ln \n\n a \n\n(1)\n\nWhere G(r) is the cumulative distribution function, k and a are constants, and r is\nthe rank 1,2,...n.\nThe result of the application of this formula is often called a rank-order\ndistribution of the items in the samples. In the literature we can find different\nnames for this type of distribution, e.g. “long tail distribution”, “extremely\nskewed”, “law of the vital few” or “power law” which all show the same\nproperties of a self-similar distribution.\n\nFigure 1. A typical Bradford distribution: Core, Zone 2 and Zone 3 (so-called\nperiphery). The cumulative number of journals (x-axis) is displayed on a logarithmic\nscale.\n\n1495\n\nIn the past, Bradford law is often applied in bibliometric analyses of databases\nand collections e.g. as a tool for systematic collection management in library and\ninformation science. This has direct influence on later approaches in information\nscience, namely the development of literature databases. The most common\nknown resource which implements Bradford law is the Web of Science (WoS).\nWoS focuses very strictly on the core of international scientific journals and\nconsequently neglects the majority of publications in successive zones.\nTo conclude this section, Bradford law is relevant for scholarly information\nsystems due to its structuring ability and the possibility to reduce a large\ndocument set into a core and succeeding zones. As a consequence, modeling\nscience into a core (producing something like coreness) and a periphery always\nruns the risk and critic of disregarding important developments outside the core.\nBradfordizing\nBradfordizing, originally described by White (1981), is a simple utilization of the\nBradford law of scattering model which sorts/re-ranks a result set accordingly to\nthe rank a journal gets in a Bradford distribution. The journals in a search result\nare ranked by the frequency of their listing in the result set (number of articles in a\ncertain journal). If a search result is bradfordized, articles of core journals are\nranked ahead of the journals which contain an average number (Zone 2) or only\nfew articles (Zone 3) on a topic (compare the example in Figure 1). This reranking method is interesting because it is a robust and quick way of sorting the\ncentral publication sources for any query to the top positions of a result set.\nBradfordizing shows the following advantages: a) a structured view on a result set\nwhich is ordered by journals; b) an alternative view on publication sources in an\ninformation space which is intuitively closer at the research process than\nstatistical methods (e.g. best match ranking) or traditional methods (e.g. exact\nmatch sorting); c) an approach to switch between the search modus e.g. starting\nwith directed term searching and changing to a browsing mode (Bates, 2002) an\nimprovement of relevance distribution between the journal zones, recently\ninvestigated (Mayr, 2009).\nIn principle, the ranking technique Bradfordizing can be applied to any search\nresult with a minimum of 100 documents from one specific document type (e.g.\njournal articles). Generally Bradfordizing needs 100 or more documents because\nsmaller document sets show too little scattering to divide the result into\nmeaningful zones.\nBates’ paper (2002) is interesting in our context because it brings together\nBradford’s Law (1934), information seeking behavior and IR (compare Wolfram,\n2003, Garfield, 1996). Bates postulates “... the key point is that the distribution\ntells us that information is neither randomly scattered, nor handily concentrated in\na single location. Instead, information scatters in a characteristic pattern, a pattern\nthat should have obvious implications for how that information can most\nsuccessfully and efficiently be sought.”\n\n1496\n\nThe main task of this paper is to evaluate the effect when applying Bradfordizing\nto topical document sets from A&amp;I databases. We want to answer the following\nquestion: Does Bradfordizing improve the ratio of relevant documents in the first\nthird (core) compared to the second and last third (zone 2 and zone 3,\nrespectively)?\nThe implementation of Bradfordizing in a typical digital library (DL) should be an\nalternative ranking option used to re-build and structure a result set. The intention\nis to list more relevant documents for a topic in the first third of a re-ranked result\nset. The re-ranking should be interpreted by users as a value-added due to the new\nstructure and the relevance concentration of the listed documents after\nBradfordizing. Furthermore Bradfordizing can be a helpful service to positively\ninfluence the search process. The opening up of new access paths and possibilities\nto explore document spaces for academic search questions can be a plausible\nvalue-added for users.\nIn the following section we will describe the research questions and methods used\nin our study (see Mayr, 2009).\nMethods\nIn this paper we seek to answer the following research questions:\n1.\nIs a re-ranking of documents according to Bradfordizing (ranking journal\nproductivity or core journals first) a measurable added value for\nsearchers?\nThe re-ranking of content to the most frequent sources (extracting the nucleus)\ncan, for example, be a helpful access mechanism for browsing and initial search\nstages, especially for novice researchers in a discipline. Evaluation of the utility of\nsuch a simple re-ranking mechanism is still a desideratum.\n2.\nAre the documents in the nucleus (core journals) of a bradfordized list\nmore often relevant for a topic than items in succeeding zones with lower\nproductivity?\nCompared to traditional text-based ranking mechanisms, the bibliometric reranking technique Bradfordizing offers a completely new view on result sets,\nwhich have not been implemented and tested in heterogeneous database scenarios\nwith multiple collections to date. This requires proving on a larger scale via\nintellectual assessments.\n3.\nCan Bradfordizing be applied to document sources other than journal\narticles?\nFew analyses show that monograph literature can be successfully bradfordized.\nBut is this a utility for searchers? Other document types (proceedings, grey\nliterature etc.) have to be equally proven.\nIn our study we focus on document sets from conventional subject-specific A&amp;I\ndatabases. We have decided for a laboratory-based IR approach. Intellectual\nassessments of document relevance were performed following the classical IR\nevaluation experiments at TREC (e.g. Voorhees, 2007) and Cross-Language\nEvaluation Forum (CLEF). First of all, the organizers of a retrieval conference\n1497\n\nlike CLEF provide a test collection and a set of topics adequate to this test\ndocument corpus. Afterwards, participants apply their individual retrieval\nalgorithms and systems while retrieving these topics (25 different topics each year\nin CLEF) in the test collection. Each participating retrieval system produces one\nor more ranked lists (called run) and sends these results back to the organizers.\nThe organizers pool the documents from the retrieval runs for each topic and give\nthe merged document pools away for objective intellectual relevance assessment.\nAll documents in the document pools undergo binary assessment (relevant or\nirrelevant for a topic) by trained jurors (normally relevance is not binary (see\nSaracevic, 1975, Mizzaro, 1997 or White, 2007). The jurors perform the\nassessments on the basis of a short guideline.\nWe can hypothesize for our experiment: If the ratio of relevant documents,\nmeasured in precision (p), is the same in all three equally sized zones, then\nBradfordizing has no effect on the distribution of relevant documents in the whole\ndocument pool. If the relevance ratio p in the first zone after re-ranking (core) is\nlower than p in the succeeding zones (zone 2 and zone 3), then Bradfordizing\nproduced a falloff in precision. But if the ratio p of relevant documents in the core\nis higher than in other zones, and that is what we expect, then Bradfordizing\nimproves the search result (measured in p) and consequently has a positive effect\non search.\nFor this study, topics, documents and intellectual assessments from two\nevaluation initiatives have been analyzed: document pools from the GIRT-corpus\nin CLEF and the KoMoHe evaluation project (see Mayr &amp; Petras, 2008). Our\nstudy analyzed scientific literature (journal articles and monographs) from social\nand political sciences, economics, psychology and medical science databases (see\nTable 1). Documents from the following database were included: SOLIS, SoLit,\nUSB Köln Opac, World Affairs Online, Psyndex and Medline.\nTable 1. Overview of the analyzed topics and documents in the IR experiments.\nProject period\nNumber of topics\nDomain, discipline\nAssessed documents total\nJournal articles bradfordized\nMonographs bradfordized\nDatabases\n\nCLEF\n2003-2007\n125\nSocial and\npolitical\nsciences\n65,297\n18,112\n11,045\n2 (1)\n\nKoMoHe\n2007\n39\nSocial sciences, political sciences,\neconomics, psychology and medical\nscience\n31,155\n17,432\n4,900\n6\n\nWe retrieved, analyzed and intellectually assessed 164 different standardized\ntopics which yielded more than 96,000 documents from all the above domains.\nMore than 51,000 assessed documents could be bradfordized.\nThe analysis of the data sets can be divided into three steps.\n1498\n\n1.\n\nThe document types journal articles and monographs are extracted from\nthe document pool. Each document type and topic is analysed separately.\n2.\nEach document set for a topic will be re-ranked according to\nBradfordizing and divided into equally sized zones (core, z2 and z3).\n3.\nThe relevance assessments of the documents in the three zones are\nmatched and aggregated zone by zone.\nAverage precision for each topic and zone can be calculated afterwards. We\ndefine the precision as the ratio of relevant documents out of all documents.\nWe calculate the average precision for each zone (core, zone 2 and zone 3) and\nbaseline precision for the whole document pool (see Table 2 for an example).\nTable 2. Example of the applied precision calculation for the CLEF-topic no. 171\n“Computers in everyday life”.\nCore\nZone 2\nZone 3\nTotal\n\nRetrieved\n73\n65\n70\n208\n\nRelevant\n41\n25\n14\n80\n\nPrecision\n0.56 (P core)\n0.38 (P z2)\n0.20 (P z3)\n0.38 (P baseline)\n\nResults\nThe average precision for 164 tested topics from the projects CLEF and KoMoHe\nincreases significantly after Bradfordizing (compare Table 3-6). So we can clearly\nverify research question 1. In this paper we show only precision values from\nanalyses with journal articles. The largest precision benefit in both datasets is\nachieved between core and the last zone (zone 3). The improvements in Tables 4\nand 6 marked with (*) are statistically significant based on the Wilcoxon signedrank test and the paired T-Test. The improvements in the KoMoHe tests (see\nTables 5, 6) are less significant, but average precision in the core outperforms\nprecision in zone 3 impressively in all test series. Following this result we can\nclearly verify research question 2.\nTable 3. Average precision for journal articles after re-ranking for five CLEF\nperiods (N=125 topics). Core, Zone 2 (Z2), Zone 3 (Z3) and baseline.\nCLEF\narticles\n2003\n2004\n2005\n2006\n2007\n\nTopics P core P Z2\n\nP Z3 P baseline\n\n25\n25\n25\n25\n25\n\n0.157\n0.134\n0.174\n0.244\n0.217\n\n0.294\n0.226\n0.310\n0.288\n0.278\n\n0.218\n0.185\n0.240\n0.267\n0.256\n\n0.221\n0.179\n0.239\n0.265\n0.248\n\n1499\n\nTable 4. Average precision improvements for journal articles for five CLEF periods\n(N=125 topics). Core, Zone 2 (Z2), Zone 3 (Z3) and baseline.\nCLEF\narticles\n2003\n2004\n2005\n2006\n2007\nAverage\n2003-2007\n\nP@Core against\nP@Z3 in %\n86.56 (*)\n69.23 (*)\n78.03 (*)\n17.63\n28.18 (*)\n\nP@Core against\nP@Z2 in %\n34.57 (*)\n22.45\n29.05 (*)\n7.66\n8.31\n\nP@Z2 against\nP@Z3 in %\n38.63 (*)\n38.20\n37.95 (*)\n9.27\n18.35\n\nP@core against\nbaseline in %\n32.65 (*)\n26.25 (*)\n29.52 (*)\n8.46\n11.77\n\n55.93 (*)\n\n20.41 (*)\n\n28.48 (*)\n\n21.73 (*)\n\nTable 5. Average precision for journal articles after re-ranking for three KoMoHe\ntests (N=39 topics). Core, Zone 2 (Z2), Zone 3 (Z3) and baseline.\nKoMoHe\narticles\nTest1\nTest2\nTest3\n\nTopics\n15\n12\n12\n\nP core\n\nP Z2\n\nP Z3\n\n0.292\n0.215\n0.700\n\n0.261\n0.202\n0.644\n\n0.245\n0.192\n0.587\n\nP baseline\n0.265\n0.202\n0.642\n\nTable 6. Average precision improvements for journal articles for three KoMoHe\ntests (N=39 topics). Core, Zone 2 (Z2), Zone 3 (Z3) and baseline.\nKoMoHe\narticles\nTest1\nTest2\nTest3\nAverage\nTest1-3\n\nP@Core against\nP@Z3 in %\n18.82\n11.58\n19.32 (*)\n\nP@Core against\nP@Z2 in %\n11.75\n6.16\n8.67 (*)\n\nP@Z2 against\nP@Z3 in %\n6.32\n5.11\n9.80 (*)\n\nP@Core against\nbaseline in %\n9.84\n6.12\n9.00 (*)\n\n16.57 (*)\n\n8.86\n\n7.08 (*)\n\n8.32 (*)\n\nIn general, the precision analyses with monographs in our tests show very similar\nresults. The precision improvements after Bradfordizing (Bradfordizing of\npublishers) between zones are also positive but less significant than\nimprovements with the journal articles (see research question 3).\nImplementation\nThe proposed re-ranking service addresses the problem of oversized result sets by\nusing the bibliometric method Bradfordizing. Bradfordizing re-ranks a result set\nof journal articles according to the frequency of journals in the result set such that\narticles of core journals are ranked ahead (see example in Figure 2). This reranking method is interesting for retrieval systems because it is a robust and quick\nway of sorting the central publication sources for any query to the top positions of\na result set.\n1500\n\nFigure 2. A bradfordized search for the search term “luhmann”. ISSN numbers of\njournals and their productivity (article counts) are displayed on the left side of the\nscreen. See research prototype under http://multiweb.gesis.org/irsa/IRMPrototype\n\nThe Bradfordizing procedure is implemented in the IRM prototype as a Solr\nplugin (see Figure 2 and a description of the prototype in Mayr et al., 2011). In a\nfirst step the search results are filtered with their ISSN numbers. The next step\naggregates all results with an ISSN number. For this step we use a build-in\nfunctionality of our prototype engine Solr, the Solr faceting mechanism. Facets in\nSolr can be defined on any metadata field, in our case the “source” field of our\ndatabases. The journal with the highest ISSN count gets the top position in the\nresult. The second journal gets the next position, and so on (see example in Figure\n2). This procedure is an exact implementation of the original Bradfordizing\napproach. In the last step, the document ranking step, our current implementation\nworks with a simple boosting mechanism. The frequency counts of the journals\nare used as boosting factors for documents in these journals. The numerical\nranking value from the original tf-idf ranking of each document is multiplied with\nthe frequency count of the journal (see Schaer, 2011). The result of this\nmultiplication will be taken as ranking value for the final document ranking.\nIn principle, this ranking technique can be applied to any search result providing\nqualitative metadata (e.g. journal articles in literature databases). Generally,\nBradfordizing needs 100 or more documents because smaller document sets often\nshow too little scattering to divide the result into meaningful zones. Bradfordizing\ncan be applied to document types other than journal article, e.g. monographs (cf.\nWorthen, 1975; Mayr, 2008, 2009). Monographs e.g. provide ISBN numbers\nwhich are also good identifiers for the Bradfordizing analysis.\nTo conclude, our implementation of re-ranking by Bradfordizing is a simple\napproach which is generic, adaptable to various document types and quickly\nimplementable with build-in functionality. The only precondition for the\napplication is the existence of qualitative metadata to assure precise identification\nand access to the documents. An evaluation of the value-added services of\n1501\n\nBradfordizing and other approaches has been published recently by Mutschke et\nal. (2011).\nDiscussion\nThe discussion of the re-ranking method Bradfordizing will focus on possible\nadded-values and the positive and negative effects of this method. Some addedvalues appear very clearly. On an abstract level, re-ranking by Bradfordizing can\nbe used as a compensation mechanism for enlarged search spaces with\ninterdisciplinary document sets. Bradfordizing can be used in favor of its\nstructuring and filtering facility. Our analyses show that the hierarchy of the result\nset after Bradfordizing is a completely different one compared to the original\nranking. The user gets a new result cutout with other relevant documents which\nare not listed in the first section (in our experiment the top 10 documents) of the\noriginal list. Furthermore, Bradfordizing can be a helpful information service to\npositively influence the search process, especially for searchers who are new on a\nresearch topic and don’t know the main publication sources in a research field.\nThe opening up of new access paths and possibilities to explore document spaces\ncan be a very valuable facility. Additionally, re-ranking via bradfordized\ndocuments sets offer an opportunity to switch between term-based search and the\nsearch mode browsing. It is clear that the approach will be provided as an\nalternative ranking option, as one additional way or stratagem to access topical\ndocuments (cf. Bates, 2002).\nInteresting in this context is a statement by Bradford where he explains the utility\nof the typical three zones. The core and zone 2 journals are in his words\n“obviously and a priori relevant to the subjects”, whereas the last zone (zone 3) is\na very “mixed” zone, with some relevant journals, but also journals of “very\ngeneral scope” (Bradford, 1934). Pontigo and Lancaster (1986) come to a slightly\ndifferent conclusion of their qualitative study. They investigated that experts on a\ntopic always find a certain significant amount of relevant items in the last zone.\nThis is in agreement with quantitative analyses of relevance assessments in the\nBradford zones (Mayr, 2009). The study shows that the last zone covers\nsignificantly less often relevant documents than the core or zone 2. The highest\nprecision can very constantly be found in the core.\nTo conclude, modeling science into a core and a periphery – the Bradford\napproach – always runs the risk and critic of disregarding important developments\noutside the core. Hjorland and Nicolaisen (2005) recently started a first\nexploration of possible side effects and biases of the Bradford methods. They\ncriticized that Bradfordizing favours majority views and mainstream journals and\nignores minority standpoints. This is a serious argument, because by definition,\njournals which publish few papers on specific topics have very little chance to get\ninto the core of a more general topic. A counter-argument could be that the\nBradfordizing approach is just an application which is working on existing\ndocument sets. The real problem is situated before, in the development of a data\nset, especially in the policy of a database producer.\n1502\n\nConclusions\nAn evaluation of the method and its effects was carried out in two laboratorybased information retrieval experiments (CLEF and KoMoHe) using a controlled\ndocument corpus and human relevance assessments (see Ingwersen &amp; Järvelin,\n2005 for pros and cons of this methodology). The results show that Bradfordizing\nis a very robust and promising method for re-ranking the main document types\n(journal articles and monographs) in today’s digital libraries (DL). The IR tests\nshow that relevance distributions after re-ranking improve at a significant level if\narticles in the core are compared with articles in the succeeding zones. The items\nin the core are significantly more often assessed as relevant, than are items in\nzone 2 or zone 3. The largest increase in precision can typically be observed\nbetween core and zone 3. This has been called the Bradfordizing effect.\nThe results of our study can also be seen as a coalescence of Bradford Law in so\nfar as Bradford did not postulate or observe a relevance advantage in the core. In\nBradford’s eyes all documents in his bibliographies were “relevant to a subject”.\nHis focus was the scattering of documents across journals, not the relevance\ndistribution between document zones. According to Saracevic (1975), Bradford\n(1934) was one of the first persons to use the term relevant in our context\n(“relevant to a subject”). The results in this study show that articles in core\njournals are valued more often relevant than articles in succeeding zones\n(compare Garfield, 1996). This is an extension to the original conception of\nrelevance distribution in the zones by Bradford. As we can empirically see,\nbibliometric distributions like Bradford distributions can also be described as\n“relevance related distributions” (Saracevic, 1975). The examination of relevance\nconcentrations in our test series (CLEF and KoMoHe) show that there is not a\nmassive concentration of relevant articles in the core, rather it is more a\ncontinuously decreasing of average precision from core to zone 3.\nThe relevance advantage in the core can probably be explained in that a) core\njournals publish more state-of-the-art articles, b) core journals are more often\nreviewed by peers in a certain field and c) core journals cover more aspects of the\nsearched topic than journals in the peripheral zones. Further research is needed to\nclarify these questions.\nFurther research\nAfter evaluating the positive relevance effect of Bradfordizing, our next goal is to\ngo automatically from directed searching into a browsing mode. Starting with a\nsubject-specific descriptor search, we will treat the query with our heterogeneity\nmodules (Mayr &amp; Petras, 2008) to transfer descriptor terms into a multi-database\nscenario. In a second step, the result lists from the distributed databases are\ncombined, merged and re-ranked by users e.g. according to Bradfordizing. Step 3\ncould be the extraction of a result set of documents in the Bradford nucleus which\ncan be delivered for browsing or other search stratagems. This browsing modus,\nbased on automatically bradfordized lists, can be compared to the search\ntechnique which Bates terms “journal run.”\n1503\n\nThe exploration of possible side effects and bias (see e.g. Nicolaisen &amp; Hjorland,\n2007) of this promising re-ranking method will be a next step. Recently\nNicolaisen &amp; Hjorland have criticized Bradfordizing: “Bradford analyses function\ndiscriminatorily against minority views ... Bradford analysis can no longer be\nregarded as an objective and neutral method.” This has to be proven on a larger\nempirical basis.\nA comparison with other ranking and re-ranking methods would be highly\ndesired. Techniques like bibliometric re-ranking (e.g. Bradfordizing described in\nthis paper) or the application of social-network analysis techniques (e.g. coauthorship relationships in Mutschke, 2003) or other combinations of value-added\nservices can and should be applied in digital libraries (DL) to improve IR (White\n2005, 2007). Further research will focus on the implementation and evaluation of\nthe method in a live system with different modules for improving retrieval (see\nMutschke et al, 2011).\nAcknowledgement\nThe KoMoHe project at GESIS (“Competence Center Modeling and Treatment of\nSemantic Heterogeneity”) was the starting point and background of this study.\nThe KoMoHe project was funded by the German Federal Ministry for Education\nand Research (BMBF) grant number 523-40001-01C5953. The retrieval prototype\nhas been developed in the DFG project “Value-Added Services for Information\nRetrieval” (IRM) under project number: INST 658/6-1.\nReferences\nBates, M. J. (2002). Speculations on Browsing, Directed Searching, and Linking\nin Relation to the Bradford Distribution. Paper presented at the Fourth\nInternational Conference on Conceptions of Library and Information Science\n(CoLIS 4).\nBörner, K., Glänzel, W., Scharnhorst, A., &amp; van den Besselaar. P. (2011).\nModeling science: Studying the structure and dynamics of science.”\nScientometrics 89, 347–348.\nBradford, S. C. (1934). Sources of information on specific subjects. Engineering,\n137(3550), 85-86.\nGarfield, E. (1996). The Significant Scientific Literature Appears In A Small Core\nOf Journals. The Scientist, 10(17), 13.\nIngwersen, P., &amp; Järvelin, K. (2005). The Turn - Integration of Information\nSeeking and Retrieval in Context. Dordrecht: Springer.\nLin, J. (2008). PageRank without hyperlinks: Reranking with PubMed related\narticle networks for biomedical text retrieval. BMC Bioinformatics, 9.\nMayr, P. (2009). Re-Ranking auf Basis von Bradfordizing für die verteilte Suche\nin Digitalen Bibliotheken. Humboldt-Universität zu Berlin, Dissertation.\nMayr, P., Mutschke, P., &amp; Petras, V. (2008). Reducing semantic complexity in\ndistributed digital libraries: Treatment of term vagueness and document reranking. Library Review, 57(3), 213-224.\n1504\n\nMayr, P., Mutschke, P., Petras, V., Schaer, P., &amp; Sure, Y. (2011). Applying\nScience Models for Search. In J. Griesbaum, T. Mandl, &amp; C. Wormser-Hacker\n(Eds.), 12. Internationales Symposium für Informationswissenschaft (ISI\n2011) (pp. 184–196). Hildesheim: vwh Verlag Werner Hülsbusch.\nMayr, P., &amp; Petras, V. (2008). Cross-concordances: terminology mapping and its\neffectiveness for information retrieval. In 74th IFLA World Library and\nInformation Congress. Québec, Canada.\nMizzaro, S. (1997). Relevance: The whole history. Journal of the American\nSociety for Information Science, 48(9), 810-832.\nMutschke, P., Mayr, P., Schaer, P., &amp; Sure, Y. (2011). Science models as valueadded services for scholarly information systems. Scientometrics, 89(1), 349–\n364. doi:10.1007/s11192-011-0430-x\nMutschke, P. (2003). Mining Networks and Central Entities in Digital Libraries: a\nGraph Theoretic Approach Applied to Co-Author Networks. Paper presented\nat the Advances in Intelligent Data Analysis 5. Proceedings of the 5th\nInternational Symposium on Intelligent Data Analysis (IDA 2003), Berlin.\nNicolaisen, J., &amp; Hjørland, B. (2007). Practical potentials of Bradford&#x27;s law: A\ncritical examination of the received view. Journal of Documentation, 63.\nSaracevic, T. (1975). Relevance: A review of and a framework for the thinking on\nthe notion in information science. Journal of the American Society for\nInformation Science, 26(6), 321-343.\nSchaer, P. (2011). Using Lotkaian informetrics for ranking in digital libraries. In\nC. Hoare &amp; A. O’Riordan (Eds.), Proceedings of the ASIS&amp;T European\nWorkshop 2011 (AEW 2011). Cork, Ireland: ASIS&amp;T.\nVoorhees, E. M. (2007). TREC: Continuing information retrieval&#x27;s tradition of\nexperimentation. Communications of the ACM, 50(11), 51-54.\nWhite, H. D. (1981). &#x27;Bradfordizing&#x27; search output: how it would help online\nusers. Online Review, 5(1), 47-54.\nWhite, H. D. (2005). On Extending Informetrics: An Opinion Paper. In\nProceedings of the 10th International Conference of the International Society\nfor Scientometrics and Informetrics (pp. 442-449). Stockholm, Sweden:\nKarolinska University Press.\nWhite, H. D. (2007). Combining bibliometrics, information retrieval, and\nrelevance theory, Part 1: First examples of a synthesis. JASIST, 58(4), 536559.\nWolfram, D. (2003). Applied informetrics for information retrieval research.\nWestport, CT: Libraries Unlimited.\n\n1505\n\nRESEARCH COLLABORATION AND\nPRODUCTION OF EXCELLENCE: FINLAND 19952009\nHannes Toivanen1 and Arho Suominen2\n1\n\nhannes.toivanen@vtt.fi\nVTT Technical Research Centre of Finland, Innovation and Knowledge Economy,\nP.O.Box 1000, 02044 Espoo, Finland\n2\n\narho.suominen@vtt.fi\nVTT Technical Research Centre of Finland, Innovation and Knowledge Economy, Itäinen\nPitkäkatu 4, Turku, P.O. Box 106, 20521 Turku, Finland\n\nAbstract\n\nThis study uses complete-normalized counting in assessing credit for authorship and\ncitations received, and argues that conventional bibliometric assessments used for policy\ndevelopment lead to misguided conclusions about how best research is created, and what\ntype policies may promote research excellence. Exploring Finnish research 1995-2009\nbased on ISI data, we demonstrate that the nature of the Finnish “hot papers” (papers that\nreceive most citations within two years after publication) doesn’t correspond with the\nidealized vision of “high quality research” by being highly national and created by\nrelatively small author teams. As such, it also resembles closely research with no impact,\ni.e. the non-cited papers. These two differ from the “other cited papers”, which are\nauthored by larger and highly international teams. While we describe the author team\nstructure and national nature for different cohorts of scientific excellence, our central\nresult is the observation that in terms production of excellence, whole citations created per\nauthor, small Finnish author teams are slightly more productive than large international\nauthor teams. We discuss at some length the methodological and policy implications of\nour results, especially as far as they give rise to the suspicion that conventional (Finnish)\npolicy efforts to foster research excellence target the middle-tier papers and target poorly\nthe best papers that resemble closely the worst ones. We also demonstrate how results and\nconclusions are highly dependent whether research excellence assessment focuses on\npapers or alternatively researchers. Finally, we consider how “scientific excellence”\nshould be defined and measured in national contexts.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6); Research Fronts and Emerging\nIssues (Topic 4); Science Policy and Research Evaluation: Quantitative and Qualitative\nApproaches (Topic 3).\n\nIntroduction\nWhat type of research collaboration fosters excellence in knowledge creation?\nThis remains a central challenge for sociology of science as well as research\n1506\n\npolicy. By using the complete-normalized counting in assessing credit for\nauthorship and excellence with Finnish data for 1995-2009, this paper questions if\nconventional bibliometric assessments lead to misguided conclusions about what\nkind of research collaboration and what type policies may promote research\nexcellence within national context.\nIn this context, we explore the relationship between research collaboration and\nscientific excellence. Our approach is based on differentiation three layers of\nscience in Finnish research: The national ”hot papers” consisting of the most\nvisible and high-impact research, whereas the two other sets consist of other cited\nresearch and research without any citations. Methodologically, we demonstrate\nthat bibliometric measures of research collaboration that do not recognize at\narticle level the geographic locations of co-authorship (fractional counting), or\nrelate papers’ received citations to number of authors and their geographic\nlocation, are bound to provide incorrect assessments of the impact of research\ncollaboration on excellence of science. Consequently, much of research indicators\nfocus on papers, instead of actual researchers and research communities,\nundermining the credibility and effectiveness of policy incentives for research\nexcellence. We use a method to credit citations received based on the share of\ninstitutional authorship, and demonstrate that results derived with such a method\nprovide accuracy new frame for the assessment of the impact of research\ncollaboration on research excellence.\nThis paper demonstrates the amount of “noise” included in conventional\n(uncalibrated) bibliometric measures by contrasting at article level the\ninternational and national perspective, count of citations per author, and\ngeographic location of authorship. Besides of providing accurate and more\nrealistic description of co-authorship, our basic policy concern is whether policy\nefforts to boost excellence through internationalism are really viable in the\ncontext of recent doubts on existing funding award criteria (Nicholson &amp;\nIoannidis, 2012).\nOur results suggest that highly domestic and relatively small collaborative teams\nare most effective in producing of high-impact and most visible (as measured\nthrough citations) science in Finland. Large international author teams produce in\nabsolute terms more citations, but Finnish participation in such teams is relatively\nmarginal, weakening their impact on Finnish science community. Furthermore,\nsmaller teams have more efficient ratio of received citations per author. Finally,\nwe demonstrate that the Finnish “hot papers” science, (derived with our methods)\nresembles in terms of co-authorship structure that part of Finnish science that\ndoesn’t receive citations at all, raising questions about how to focus research\npolicies fostering excellence.\n\n1507\n\nResearch collaboration, productivity, and excellence\nOne of the major changes in the university research environment is the\nintroduction of a plethora of performance-based research funding systems. These\nsystems are a research policy tool often directed implicitly or explicitly towards\ncreating research excellence. Reviewed in detail by Hicks (2012), the various\nmethods of using performance-based measures are in many countries indicator\nbased, measuring the number of publications or publications and citations. The\nexisting policy regime assumes that the international collaboration is a route\ntowards increased citation and publication counts, thus to indicator based research\nexcellence.\nAlthough there can be little doubt that research collaboration is today the norm in\npractically all fields of science (Beaver, 2001), our understanding of the dynamics\nand impacts of research collaboration are much more murky. Indeed, Bozeman et\nal. (2012) note in their recent extensive review of research collaboration research\nthat the existing literature doesn’t really answer whether research collaboration\nreally pays off, or under what conditions it would do so. In parts this might be due\nto a lack of valid indicators that would enable policy decisions (Edler &amp; Flanagan,\n2011)\nClearly one problem is the choice of right perspective to assess the productivity of\nresearch collaboration. Although on a global scale teams increasingly author most\nand the best papers (Jones, Wuchty, &amp; Uzzi, 2008), there is increasingly literature\nthat demonstrates that research collaboration is actually highly nuanced and\ndiffers by the field of inquiry, as well as by the size or level of development of\ncountry.\nIndeed, the existing literature about the benefits of research collaboration is\ninconclusive. A series of studies have demonstrated the benefits of international\ncollaboration. Looking at UK science, Katz and Hicks (1997) demonstrated that\ninternational co-authorship increased received citations much more than domestic\ncollaboration. In case of chemistry, Glänzel and Schubert (2001) showed that\nwhereas international co-authorship produced higher citation rates than purely\ndomestic papers, it didn’t contribute to the citation eminence. Also, the intensity\nof participation in research collaboration enhances quality. (Liao, 2011)\nIn contrast, a number of studies have cast doubts whether research collaboration\nreally is an efficient way of fostering excellence. Ionnadis (2008) argued that\nfractional count of citations received reveals that large author team papers are less\nefficient in attracting citations than smaller teams. Lee and Bozeman (2005)\ndemonstrated that collaboration is not a good predictor of publishing productivity\nor high citation rates, and identified the nature of the collaboration relationship as\nmore significant factor than the author team size.\n\n1508\n\nReflecting the complexity of research collaboration as a phenomenon, Schmoch\nand Schubert (2008a) speculated that the increasing specialization in science\ncould cause internationally co-authored papers to receive less citations: If\nincreased specialization decreases the size of scientific fields, then the increasing\nabsence of potential domestic collaboration partners would push scientists\nincreasingly to international collaboration, and the overall shrinking of the field\nwould result in smaller citation rates. Other identified drivers of international\ncollaboration are the increasingly important role of instruments for knowledge\nproduction and access to high-cost research equipment. Finally, funding has been\nidentified as one of the key drivers of international research collaboration, not\nleast because science policies often assume that this is key instrument to improve\nthe quality of science. (Defazio, Lockett, &amp; Wright, 2009; Fraunhofer ISI, Idea\nConsult, &amp; SPRU, 2009)\nAlthough scientometric literature and evidence maintains that the relationships\nbetween research collaboration, productivity, and excellence is an fragmented and\ncomplex phenomenon, there are plenty of examples of national policy makers\nmaking blanket assumptions that international research collaboration fosters\nresearch excellence. (e.g. in Finnish context: Muhonen, Leino, &amp; Puuska, 2012;\nTreudthardt &amp; Nuutinen, 2012)\nAuthorship and citation impact\nAlthough there certainly is some kind of relationship between research\ncollaboration and citation impact, this “is a complex phenomenon that does not fit\nsimple patterns,” as Schmoch and Schubert (2008b) have noted. Reviewing\nmethods to measure research collaboration and its impacts, Persson et al. (2004)\nargued that the uncritical use of basic indicators could easily lead to wrong\nconclusions, and recommended the use of normalization measures and relative\nindicators to strengthen validity of conclusions.\nHere we focus on two well-known challenges of using citations to identify highimpact papers or research fields. The first one involves how to credit authorship\nand citations correctly for co-authored papers, and whether whole counting or\nfractional counting would provide significantly different results. (Gauffriau,\nLarsen, Maye, Roulin-Perriard, &amp; Von Ins, 2007; Gauffriau, Larsen, Maye,\nRoulin-Perriard, &amp; von Ins, 2008; Huang, Lin, &amp; Chen, 2011; Wagner &amp;\nLeydesdorff, 2005, 2012). This problem basically requires one to choose to focus\non high impact papers or authors. The issue of fractional counting is repeated if\none wants to analyze impacts in national contexts, which requires that credit for\ncitations is allocated according to the geographical location of authors. (Toivanen,\n2012a.)\nThe second challenge emerges from the highly differing citation traditions (i.e.\nfrequencies) of different fields (Leydesdorff &amp; Opthof, 2010; Waltman, van Eck,\n1509\n\nvan Leeuwen, Visser, &amp; van Raan, 2011). If one employs citations as criteria to\nidentify high-impact papers or authors, or successful fields, this easily skews\nselection if not controlled.\nResearch frontier\nThe notion of research frontiers implies the most advanced, path-breaking new\nscientific knowledge, and its measurement and identification has been a key\ntheme of scientometrics (Garfield &amp; Merton, 1979; Garfield &amp; Small, 1989;\nGarfield, 2006). “Hot” science and technology research are research frontiers that\nhave immediate, or concentrated, high impact on other research or technology.\n“Hot research” is typically defined as papers that receive the largest share of\ncitations within certain time frame. Garfield and Small (1989) identified as “hot\nfields” clusters of papers that generated most citations within three years from\npublication.\nThere is relatively little research on analysing research frontiers in national\ncontexts (Toivanen, 2012a), it’s identification and measurement in such a context\nsuffers from several of the difficulties associated with the assessment of research\ncollaboration. Here we imply with research frontier the best and most visible\nresearch when measured as citations received. Towards this end, we use two\nmethods to calculate received citations, explained in detail below. The point of\nseparating Finnish research frontier from the rest of the research is to allow us to\ncontrast the nature, structure, and dynamics of research collaboration among\ndifferent research paper populations ranked among citation based “excellence”.\nData and Methods\nThe study focuses on the research frontier, by limiting the data used to a relatively\nshort citation windows. Excellence is looked through a proxy of citations\naccumulated in the selected narrow frontier citation window. Citations credited to\nauthors based on a fractional (complete-normalized) counting scheme. The\nmethodological selections are described in detail the following sub-sections.\nData\nWe use Web of Science data articles including at least one Finnish affiliated\nauthor from 1995 to 2009, provided in XML format on article level by Thomson\nReuters in August 2012, including all WOS indexed fields. The data was\nprocessed with Vantagepoint software. For this research, we have restricted data\nto types Article, Proceedings paper, Meeting abstracts, and Reviews, totaling 141\n554 papers. The data appears uniform for all other years except 2009, which has a\ndrop in the share of Proceedings papers, lowering significantly the number of\nreceived citations and skewing the overall composition of document types. We\nlook forward to fix this by re-calculating 2009 data with new data later.\n\n1510\n\nFor each year, we have also received all papers awarding citations to Finnish\npublications (totaling approximately two million records). Using this latter set and\nunique article level identifier, we estimated how many times each Finnish\npublication, published between 1995-2009, was cited during a 4-year citation\nwindow stretching from one year before the publishing year to two full years\nafter. Naturally, we are able to record only WOS indexed citations.\nCounting methods\nIn a perfect situation, the credit from a publication or its received citations would\nbe accredited based on the effort the authors or resources an organization has put\ninto the work. Bibliometrics is, however, limited by the meta information\navailable in the bibliometric databases. This does not contain any knowledge on\nthe actual work carried out by the authors or the nature of the authors’ affiliations.\nWith the limited data available, scholars should focus on understanding the\nlimitations of different methods and describing explicitly the methodological\nselection made, thus creating reproducible results of which the limitations are\nclearly described.\nEvaluating bibliometric results is dependent on the quantities and scoring\nmethods used to calculate the results. Not to go as far as arguing that the varying\nuse of terminologies and methods have created a crisis (Glänzel &amp; Schoepflin,\n1994) but the lack of consistency in describing results has significantly limited the\nreproducibility of results. Illustrated by an practical example by Chao et al.\n(2007), Seymour et al. (2007) and Liu et al. (2012) and the discussion that\nfollowed (Ho, 2009, 2012; P. Larsen, 2008; Seymour, 2008), being able to use a\ncommon shared vocabulary in describing the methodological options used to gain\nresults is an credibility issue. This does not only challenge authors less familiar\nwith bibliometrics who try to apply it, but also to scholars active in the field of\nscientometrics as pointed out by Larsen (2008).\nIn the case of directly policy focused bibliometric studies, credit for authorship is\nfrequently obfuscated, leading to wrong-headed policy conclusions, priorities,\nstrategies and whole-sale perceptions about the state of research. Reports\npublished (Karlsson &amp; Persson, 2012; Opetus- ja kulttuuriministeriö, 2011a,\n2011b) often describe in lose detail the methodological options made and discuss\nlittle or none the limitations set by methodological decision made during the\nprocess – even though the underlying methodological selections would be sound.\nThis sets significant practical implications if research funding is interconnected\nwith studies where possible bias created through methodologies.\nDiscussion on the standardization of scientometric ‘methods’ was taken up by\nseveral researcher in a workshop in 1995, discussion subsequently published in\n1996 (Scientometrics Vol 35 Issue 2). Much of the more recent literature on\nbibliometric counting methods (Gauffriau et al., 2007, 2008; Vinkler, 2001) is\n1511\n\ndrawn from the work published in 1996 (Bourke &amp; Butler, 1996; McGrath, 1996;\nVinkler, 1996). Recent efforts on creating a systematic approach on the measures\nof scientific publications counting was done by Gauffriau et.al (Gauffriau et al.,\n2007, 2008). The authors took a set theory approach to creating the foundation for\nstandardized measures in scientific research by consistently defining four\ncounting methods; complete counting (C), complete-normalized counting (CN),\nstraight counting (S), whole counting (W) and whole-normalized counting (WN).\nIn addition, Gauffriau et.al (2007, 2008) defined two notations basic unit of\nanalysis (B) and object of study (O), which with the counting method enables an\nauthor to explicitly define the method of attributing a score in a bibliometric\nstudy.\nGauffriau et.al (2007, 2008) define three values of B and O, author, country, and\ninstitution, which should be selected for a study independently depending on the\nresearch objective. This selection should be complemented with an understanding\nof the limitations of the selected counting method. The selection of the previously\nmentioned counting method, unit of analysis and object of study create context\nand limitations for the results of the calculation made.\nLooking at the counting methods in more detail, complete counting attributes\neach unit of analysis one credit. If for example setting the object of the study and\nbasic unit to countries an article with two affiliations from Finland, one from\nSweden and one from Denmark, Finland would receive two credits and Sweden\nand Denmark both one. In this, it is important to note the notation credit, to be\ndistinguished from counting publications. In Huang et al. (2011)the authors do\nnot consider complete counting as a “...reasonable approach” as they claim that\nthe previous example would resulted in Finland producing two publications. This\nis of course not the case, and it is important note the difference between\nattributing credit and the number of publications. In CN counting all of the basic\nunits share one credit based on the number of times each basic unit of analysis is\nmentioned in the publication. This method is also referred to as fractional\ncounting (for example Aksnes, Schneider, &amp; Gunnarsson, 2012)\nIn straight counting the first basic unit of analysis mentioned receives full credit\nof the publication that is one credit. First basic unit thus often refers to the first\naffiliation mentioned in the paper or the country of that affiliation. Studies have\nargued, although against logic, that straight counting results would correlate\nstrongly with the results of other counting measures (see Lange, 2001). This has\nlater been questioned by Zhao (2006), who discussed in detail the differences and\npossible biases of the straight counting approach.\nIn literature whole counting (W) has been described by several different names,\nsuch as full counting, normal counting and integer counting. The before\nmentioned describe a crediting method where if a basic unit (B) appears more\n1512\n\nthan one time it will still receive only one credit. Whole counting is often used\nwhen calculating citation indexes, and Moed (2005) argues that whole counting is\na valid measure of participation. With whole-normalized counting (WN) each\nunique basic unit will share one credit, thus serving as a means of normalization.\nThe above mentioned methodological option, described in detail by Gauffriau et\nal. (2007, 2008), are summarised in Table 1.\nTable 1. Scores for different counting methods for a publication with one author\nfrom Denmark, two authors from Finland, and on author from Sweden, where one\nof the Finnish authors has the first affiliation mentioned in the document. (for details\nrefer to Gauffriau et al., 2007, 2008)\nComplete\ncounting\nDenmark\nFinland\nSweden\nSum\n\nC\n1\n2\n1\n4\n\nCompletenormalized\ncounting\nCN\n1/4\n2/4\n1/4\n1\n\nStraight\ncounting\n\nWhole\ncounting\n\nS\n0\n1\n0\n1\n\nW\n1\n1\n1\n3\n\nWholenormalized\ncounting\nWN\n1/3\n1/3\n1/3\n1\n\nAltogether, we should notice that often the selection of a method is not a question\nof right or wrong, but more a practical question of does the indicator measure\nwhat we think it measures? Using similar terminology and focusing the discussion\non what we expect that a counting method actually measures would be valuable.\nFor example, when looking at a smaller portion of the whole population of\npublications, such as focusing on research excellence and thus looking at a\nperceived top segment of the publications, we should be aware that the known\nlimitations of bibliometric indicators are amplified when focusing on a smaller\nsample. In addition, in the case of research excellence we are forced to question if\nbibliometric measures have the ability to distinguish excellence from “very good”\n- as excellence might be defined by a number of capacities falling outside the\ngrasp of bibliometric indicators (Rons &amp; Amez, 2009).\nThe complexity of assigning credit is multiplied with accrediting citations to\ndifferent basic units. (Gauffriau et al., 2007) Logically, when moving from\nassigning credit from one publication to dividing citation credits we increase the\ncomplexity of the problem. When assigning publication credits, the differences\nbetween counting methods are controlled by the relatively low deviation and\nmean value of an average number of basic units in a publication. With citations\nwe are faced with a larger variation from publication to publication. This\nultimately changes the dynamics of giving credit.\nCitation counting methods are challenged by the difference in the patterns and\ntraditions of publishing in different fields of science - resulting in a long-standing\n1513\n\ndebate on the use of normalization methods, such as a crown indicator (Moed, De\nBruin, &amp; Van Leeuwen, 1995) or normalisation at a publication level\n(Leydesdorff &amp; Opthof, 2010), and the use of either whole counting or completenormalized counting for country level research impact (Aksnes et al., 2012).\nCounting methods applied in the study\nThe counting method applied in the study is complete-normalized counting. By\nusing the research address field as a proxy for how work has been divided at a\ncountry level, we calculated for each article the share of domestic and foreign\ninstitutional authors. This allowed us to calculate Finnish institutional author\nshare, i.e. complete-normalized count, (hereafter FI Auth) of all institutional\nauthorship. More importantly, the “FI Auth share” share of citations received for\neach article (hereafter FI FRC Citations), measuring the what share of citations\nreceived can be credited to Finnish institutional authors. Taking the example from\nTable 1, the FI Auth is 2/4, and assuming that the article has received 12 citations\nthe FI FRC Citations is 6.\nFor each year, we created two data sets according to total number of citations\nreceived during the citation window used. First data set is based on the whole,\nabsolute, citations received (ABS Citations). Second data set is based on using the\nFI FRC Citations as a classifying factor. We have divided these two sets of\nannual publications 1995-2009 in to three echelons of research: First, the best and\nmost visible research, or “Hot papers” or the “research front”, defined here as the\nmost cited 10% of publications that receive citations within the citation window.\nSecond, the “Other cited papers” that receive citations less than the “Hot papers”\nwithin citation window, and, third, the “Non-cited papers”.\nThe “Hot papers” consists of the roughly 10% of most cited papers among all\npapers that have received citations during the citation window. If it was not\npossible to apply the threshold directly, we included in “Hot papers” all papers\nreceiving exactly the same number of citations as the paper at 10% threshold or\nnearest it. The “Other cited papers” (both “FI FRC Citations” and “ABS\nCitations”) versions for each year) consist of all the papers that have received\ncitations and that fell below the “Hot papers” citation threshold. “Non-cited\npapers” consists of annual sets of papers that have not received single citations,\nand is – obviously- the same for “FI FRC Citations” and “ABS Citations” data.\nThe approach used is based on several assumptions and limitations. First, citations\nare used as a measure of excellence. This is of course limited, as research\nexcellence, not to mention personal excellence, is a sum of several factors to\nwhich the number of citations is a mere – and even a bad – proxy. Second, the\nmethod applied does not use any field or publication type normalization. The\nstudy does not endeavour to compare different scientific fields, but answer the\ncore question of analysing the impact of research collaboration to the production\n1514\n\nof excellence to the extent it is measured by citations. We do not sample data or\nattempt to introduce measures that would “correct” the biased or skewed nature of\nthe whole population – rather we discuss the eventuality that latent variables\nimpacting the results do exist.\nResults\nThe overall volume of Finnish authored papers has increased substantially in the\nlate 1990s, when the government increased national R&amp;D funding, but has\nsaturated to an average 3% growth subsequently. The average Finnish publication\ncount growth in the 2000s is similar to that of the average growth of world\nscientific publications of 2% (Veugelers, 2010). Interestingly, this has had little or\nno impact on the percentage of cited papers, which has remained fairly constant\nthroughout the time frame of this study (Table 1.). The concentration of citations\nto on average 62 % of publications is also in line with earlier findings and the\noverall decline in the concentration of citations (Larivière, Gingras, &amp;\nArchambault, 2009).\nTable 1. Summary of data used in the study.\n\nYear\n\nCited\nHot\nAll\npapers % papers %\npapers\nof all\nfrom all\npapers\npapers\n\nOther cited\npapers %\nfrom all\npapers\n\nNon-cited\npapers %\nfrom all\npapers\n\n6,33 %\n52,01 %\n41,66 %\n1995 4693 58,34 %\n6,15 %\n56,61 %\n37,23 %\n1996 5119 62,77 %\n6,22 %\n53,02 %\n40,75 %\n1997 6041 59,25 %\n6,26 %\n52,30 %\n41,44 %\n1998 8800 58,56 %\n6,03 %\n55,55 %\n38,41 %\n1999 8867 61,59 %\n5,99 %\n53,78 %\n40,22 %\n2000 9477 59,78 %\n6,19 %\n56,56 %\n37,25 %\n2001 9353 62,75 %\n6,29 %\n54,85 %\n38,86 %\n2002 9608 61,14 %\n6,35 %\n57,13 %\n36,52 %\n2003 9972 63,48 %\n6,07 %\n54,41 %\n39,51 %\n2004 10705 60,49 %\n6,62 %\n57,24 %\n36,14 %\n2005 10615 63,86 %\n6,30 %\n56,61 %\n37,09 %\n2006 11480 62,91 %\n6,16 %\n55,23 %\n38,61 %\n2007 11999 61,39 %\n6,47 %\n57,97 %\n35,56 %\n2008 12341 64,44 %\n6,71 %\n58,43 %\n34,86 %\n2009 12484 65,14 %\nNOTE: Hot papers selection based on FI FRC Citations.\n\nHot\npapers %\nof cited\npapers\n\nCitation\nthreshold\nfor hot\npapers\n(FI FRC)\n\n10,85 %\n9,80 %\n10,51 %\n10,69 %\n9,80 %\n10,03 %\n9,87 %\n10,28 %\n10,00 %\n10,05 %\n10,37 %\n10,01 %\n10,03 %\n10.05%\n10,31 %\n\n10\n9,33\n10\n10\n9,14\n9,33\n9,14\n10\n9,2\n10\n10\n9,67\n9,75\n10\n9\n\nHot\npapers&#x27;\nshare of\nall\ncitations\nreceived\n(FI FRC)\n44,93 %\n43,45 %\n44,89 %\n43,28 %\n41,15 %\n41,15 %\n42,65 %\n41,30 %\n40,10 %\n40,72 %\n41,12 %\n40,76 %\n40,87 %\n41,85 %\n42,49 %\n\nThe structure and nature of scientific excellence changes substantially when the\ncitations received by papers are weighted with the share of institutional Finnish\nauthors as opposed of using simply the whole count of citations. The average\nshare of Finnish institutional authors in “Hot papers” based on “FI FRC\nCitations” is 87% between 1995 and 2009, whereas respective share for “Hot\n1515\n\npapers” based on “ABS Citations” is 57%. During the period, the share of Finnish\ninstitutional authors declines about 10 percentage units in both datasets, but the\ndifference persists throughout the period.\nThe fractional counting scheme used in this paper approaches authorship equally\ndividing the fractions to all authors as a simple division citations by the number of\nauthors. A more elaborate method, based on for example a Hunt-type (Hunt,\n1991) valuation of authorship, could yield different results. However, this is not in\nthe scope of this study.\nThe features of “Hot papers” based on “FI FRC Citations” are relatively\nconstant throughout the period. The citation threshold for the most cited 10% of\nall cited papers within the 4-year citation window doesn’t move significantly, and\nthe share that “Hot papers” capture from all citations remains relatively stable,\nbeing roughly 40%. (Table 1.) The most cited 1% of all cited papers capture\naround 10% of all “FI FRC Citations” received. The excellence is significantly\nmore concentrated when “Hot papers” are selected by using “ABS Citations”,\nwhen the best 1% would capture around 15% of all citations received, but the\n“Hot papers” combined 45%.\nThe comparison of the basic features of “FI Hot papers” and “ABS Hot papers”\nalone confirms that if one doesn’t control of the geographic location of\ninstitutional authors, assessments of research excellence based on citations are\nbound to include considerable amount of noise, blurring the focus of targeted\npolicy instruments. This essentially because the Finnish research excellence\nwould be considerably less “Finnish”, and, secondly, excellence would\nconcentrate more strongly in the most cited papers.\nStructure and nature of research teams\nThe size of author teams is an essential factor when assessing the productivity\n(e.g. published papers or received citations). From the perspective of national\nresearch systems and policies, the nationality, and more accurately domestic and\nforeign authorship, are alike significant. Here we investigate how the average\nnumber of authors and the share of Finnish institutional authors evolve in the\nthree data sets created with “FI FRC Citations”. (Figure 1.)\nThe average number of authors in “Hot papers” and “Non-cited papers” is\nrelative stable in 1995-2009 and not very different, being on average about 6 and\n4, respectively. In contrast, “Other cited papers” shows a more challenging trend,\nwith significant variance in the average number of authors, suggesting structural\nsystem-level transitions in the structure or focus of research, such as annual\nvariation in participation to international big science. This is supported by the\nsignificantly smaller author count standard deviation of 9,4 in 2002 in comparison\nto the average of 45,7. Outliers in the data offer a reasonable explanation to the\n1516\n\nbehaviour, as when calculated as a median value the “Other cited papers” remains\nat a stable median of 4 authors until 2004. From 2005 onward, the median value\nof the group increases to 5 authors. This suggests that the upward trend from 2004\nin the “Other cited papers” is an actual increase in group size. Disciplinary\norientation could explain these differences too, but is beyond this paper. (Figure\n1.)\n\nFigure 1. Average number of authors in the publications in the three groups (FI FRC\nHot papers, FI FRC Other cited papers and Non-cited papers) during 1995 to 2009.\n\nThe share of Finnish institutional authors in “Hot papers” and “Non-cited\npapers” is almost equal throughout the period, being around 90% and, thus,\nhighly “Finnish”. In contrast, author teams for ”Other cited papers” more and\nincreasingly international, with the share of Finnish institutional authors declining\nsteadily from about 80% in 1995 to around 65% in 2009. (Figure 2.)\nWhen investigated from national research system perspective, the structure and\nnature of research teams in the three different quality groups of Finnish research\nis somewhat counter intuitive if one subscribes to the idea that large international\nteams author the most cited papers. The assumed best papers, “Hot papers”, are\non average relatively small (6 authors) and have a very low degree of\ninternational collaboration (10% of institutional authors are non-Finnish). As\nsuch, they resemble closely the “Non-cited papers” that have about 4 authors on\naverage and almost identically low degree of international collaboration. The\nauthor structure and national composition of these two groups remains also\nrelatively stable between 1995 and 2009.\n\n1517\n\nFigure 2. Average share of Finnish authors in the publications in the three groups\n(FI FRC Hot papers, FI FRC Other cited papers and Non-cited papers) during 1995\nto 2009.\n\nFigure 3. Median authors and share of Finnish authors in the “Other cited papers”.\n\nRemarkably, the “Other cited papers” shows very different qualities and trends.\nIts average author share is, for the most years, significantly higher than in the two\nother groups, and varies greatly. Furthermore, its author teams are significantly\nmore and increasingly international, with the share of non-Finnish institutional\n1518\n\nauthors increasing from about 20% to 35%. This is further illustrated by the more\nstable median value, in Figure 3, where we see that as the author count increases\nthe share of non-Finnish authors increase. While the selection criteria applied\nhere, “FI FRC Citations”, explains these differences to some degree, as could the\ndisciplinary orientation not afforded to study here.\nCitation based excellence and productivity\nTo assess the overall citation-based quality and author productivity in the context\nof excellence, we compare the citations received by papers and author teams’\nproductivity in attracting citations across the different data sets.\n\nFigure 4. Average and median number of absolute citations (AVG/MEDIAN\nCITATIONS), average and median share of citations per author (AVG/MEDINA\nFRC CITATION) and average and median share of Finnish institutional authors\nfrom citations (AVG/MEDIAN FI FRC CITATION) within the two citation groups\n(“Hot papers” and “Other cited papers”).\n\nThe different citation averages of “Hot papers”, and ”Other cited papers”\n(selected with the “FI FRC Citation”) remain relatively stable throughout the\nperiod, yet the two groups have sharply contrasting features. As illustrated in\nFigure 4, the average (whole) citation value of “Hot papers” between 1995-2009\ninches somewhat upwards, being on average 25 for the period, of which on\n1519\n\naverage about 17 can be credited to Finnish institutional authors - though this\nlatter share declines somewhat during the period. (Note that 2009 citation count\ndrops because the share of conference proceedings drops – something we will fix\nwith data augmentation later).\nIn case of “Other cited papers” the average (whole) citation inches slightly up,\nbeing on average little below 5 between 1995 and 2009, of which Finnish\ninstitutional authors capture on average 2.7 citations. However, the “FI Auth\nshare” declines from almost 80% to 65%.\nThus, the ratio of average citations and the share of Finnish institutional authors\nremain higher for the “Hot papers” than “Other cited papers” within the time\nperiod. It is noteworthy, that although the average number of authors in ”Other\ncited papers” experiences a U-shaped curve, the average citation values remain as\na constant throughout the period. This might be explained by the significantly\nsmaller variance and the median being stable – the average paper performs\nsimilarly and the fluctuation in the number of authors does not change this. This\nhowever suggests that the so called “big science” papers, with an extremely large\nnumber of authors, perform near to average.\nFigure 4. also includes the median value as a measure of central tendency.\nAlthough Aksnes and Sivertsen (2004) question the usefulness of median values\nin describing citations, even though the distribution of citations is prone to\noutliers and skewness, median values as a more stable measure of central\ntendency give useful insight to the average based measures. Looking at the\nmedian values, we see the same order of variables. In addition, the comparison\nbetween median and average values show that each of the variables have a\nsimilarly skewed distribution containing data points that are significantly larger\nthan the central tendency of the distribution – e.g. all of the cohort are\nindependently skewed.\nTo contrast the differences in results obtained by using national fractional citation\ncounting and whole citation counting, we compare “FI Hot papers” and “ABS\nHot papers” datasets to examine how they differ in terms of production of\nexcellence. (Figure 5.)\nThe Figure 5. illustrates the fundamental problem addressed in our paper.\nWhereas “ABS Hot papers” receive by whole count more citations than “FI Hot\npapers”, and is by that definition more “hot”, the relationship is turned upside\ndown when we use national fractional citation count. Indeed, with the “FI FRC\ncitation” count, “FI Hot papers” is “hotter” than “ABS Hot papers”. This notion\nholds true in both average or median based metrics. With median values we even\nsee that the gap between the “FI Hot papers” and “ABS Hot papers” has increased\nfrom a near equal.\n1520\n\nFigure 5. Comparison of citation profile between the “FI Hot papers” and “ABS Hot\npapers”. Average whole count of citations (AVG/MEDIAN CITATIONS), average\ncitations per author (AVG/MEDIAN FRC CITATION) and average share of\ncitations of Finnish institutional authors from citations (AVG/MEDIAN FI FRC\nCITATION)\n\nPerhaps the most important observation relates to the author productivity in terms\nof attracting citations. The fractional count of citations per author in “FI Hot\npapers” and “ABS Hot papers” is practically the same throughout 1995-2009,\nbeing roughly 5 (average 5.5 or median 3.5 and 5.3 or median 3.5, respectively).\nThis despite the fact that the two groups differ greatly in terms of author team\nstructure and the extent of international collaboration (and probably disciplinary\norientation).\nThis last result raises the question what kind of excellence is important in the\ncontext of national research systems, and how excellence can be fostered with\ntargeted policy instruments. Basically, our result contrasts here the assessment of\nexcellence of papers with that of researchers, and our results show that highly\nnational and relative small author teams are just as productive (and actually\nslightly more) in terms of scientific excellence as large international teams.\n\n1521\n\nDiscussion\nBy exploring the nature of Finnish research 1995-2009, we have demonstrated\nthat the nature of the “FI Hot papers” or research frontiers doesn’t correspond\nwith the idealized vision of “high quality research”. It is created by relatively\nsmall author teams (on average 6 co-authors) and is highly national (on average\n85% of authors are Finnish), and that as such it resembles closely research with\nno impact, i.e. the “Non-cited papers” (4 authors; 86% Finnish, respectively).\nThese two groups differ dramatically from the “Other cited papers” (10 authors,\n73% Finnish, respectively).\nMore importantly, we have demonstrated that the “Hot papers” selected with “FI\nFRC citation” count are equally productive in terms of citations received per\nauthor as “Hot papers” selected with absolute citation count. This despite the fact\nthat these two groups differ starkly, as the latter group has much larger author\ngroups, and involve international collaboration to the extent that implies a\nmarginal author role for Finnish contributors. In contrast, “FI Hot papers” are\ncreated by relatively small teams that are about 90% of Finnish, suggesting a\nleading and controlling role of Finnish contributors.\nMethods developed here and our results raise fundamental questions about how to\ndefine scientific excellence in national research system context, and how to device\npolicy strategies and targeted instruments in support of excellent researchers.\nBasically, which science is more valuable and potential from national perspective:\nThe one created through participation in marginal role in international large\ncollaborative author teams, or the one authored through participation in central\nleadership role in relatively small and highly national author teams?\nWhile it is beyond this paper to address fully these questions, our results alone\ngive rise to the suspicion that conventional (Finnish) policy efforts to foster\nresearch excellence target the middle-tier papers, and target poorly the best papers\nthat resemble closely the worst ones, but is compounded when we show that the\n“ABS Hot papers” – the assumed crème of Finnish science - has less than half of\nFinnish institutional authorship.\nAs such, our results have immediate bearing upon public policies and institutional\nstrategies trying to foster excellence in science, up to the point of suggesting that\nmany of the existing approaches may be wrong-headed and target wrong\n(mediocre) researcher populations. This especially, if they are underpinned by\nsimplistic assumptions that large and international author teams lead to scientific\nexcellence, or are based on assessments of research that are blind to geographic\nsources of authorship. While our results may be a Finnish idiosyncry, the\nbibliometric assessment method and some literature (Toivanen, 2012b) suggests\notherwise, as the fractional accounting of geographic locations shows great\n\n1522\n\nvariance in the share of domestic authorship. Naturally more comparative work is\nneeded, as well as to develop further policy implications.\nReferences\nAksnes, D., Schneider, J. W., &amp; Gunnarsson, M. (2012). Ranking national\nresearch systems by citation indicators. A comparative analysis using whole\nand fractionalised counting methods. Journal of Informetrics, 6(1), 36–43.\ndoi:10.1016/j.joi.2011.08.002\nAksnes, D., &amp; Sivertsen, G. (2004). The effect of highly cited papers on national\ncitation indicators. Scientometrics, 59(2), 213–224. Retrieved from\nhttp://www.akademiai.com/index/N167344L22728752.pdf\nBeaver, D. D. B. (2001). Reflections on scientific collaboration (and its study):\npast, present, and future. Scientometrics, 52(3), 365–377. Retrieved from\nhttp://www.akademiai.com/index/FA5LNKLHDKGD7X77.pdf\nBourke, P., &amp; Butler, L. (1996). Standards issues in a national bibliometric\ndatabase: The Australian case. Scientometrics, 35(2), 199–207.\ndoi:10.1007/BF02018478\nBozeman, B., Fay, D., &amp; Slade, C. P. (2012). Research collaboration in\nuniversities and academic entrepreneurship: the-state-of-the-art. The Journal\nof Technology Transfer (Vol. 38, pp. 1–67). doi:10.1007/s10961-012-9281-8\nChao, C.-C., Yang, J.-M., &amp; Jen, W.-Y. (2007). Determining technology trends\nand forecasts of RFID by a historical review and bibliometric analysis from\n1991 to 2005. Technovation, 27(5), 268–279.\ndoi:10.1016/j.technovation.2006.09.003\nDefazio, D., Lockett, A., &amp; Wright, M. (2009). Funding incentives, collaborative\ndynamics and scientific productivity: Evidence from the EU framework\nprogram. Research Policy, 38(2), 293–305. Retrieved from\nhttp://www.sciencedirect.com/science/article/pii/S0048733308002709\nEdler, J., &amp; Flanagan, K. (2011). Indicator needs for the internationalisation of\nscience policies. Research Evaluation, 20(1), 7–17.\nFraunhofer ISI, Idea Consult, &amp; SPRU. (2009). The Impact of Collaboration on\nEurope ́s Scientific and Technological Performance, Final Report. Karlsruhe,\nBrussels, Brighton.\nGarfield, E. (2006). The history and meaning of the journal impact factor. JAMA:\nthe journal of the American Medical Association, 295(1), 90–93. Retrieved\nfrom http://jama.ama-assn.org/content/295/1/90.short\nGarfield, E., &amp; Merton, R. K. (1979). Citation indexing: Its theory and\napplication in science, technology, and humanities (Vol. 8). Wiley New York.\nRetrieved from http://www.garfield.library.upenn.edu/cifwd.html\nGarfield, E., &amp; Small, H. (1989). Identifying the changing frontiers of science.\nevolution, 1(182), 1431. Retrieved from\nhttp://www.garfield.library.upenn.edu/papers/362/362.html\n\n1523\n\nGauffriau, M., Larsen, P. O., Maye, I., Roulin-Perriard, A., &amp; Von Ins, M. (2007).\nPublication, cooperation and productivity measures in scientific research.\nScientometrics, 73(2), 175–214.\nGauffriau, M., Larsen, P. O., Maye, I., Roulin-Perriard, A., &amp; Von Ins, M. (2008).\nComparisons of results of publication counting using different methods.\nScientometrics, 77(1), 147–176.\nGlänzel, W., &amp; Schoepflin, U. (1994). Discussion Paper LITTLE\nSCIENTOMETRICS , BIG SCIENTOMETRICS ... AND BEYOND ?*.\nScientometrics, 30, 375–384.\nGlänzel, W., &amp; Schubert, A. (2001). Double effort= double impact? A critical\nview at international co-authorship in chemistry. Scientometrics, 50(2), 199–\n214. Retrieved from\nhttp://www.akademiai.com/index/T2PQ1372401V27V8.pdf\nHicks, D. (2012). Performance-based university research funding systems.\nResearch Policy, 41(2), 251–261. doi:10.1016/j.respol.2011.09.007\nHo, Y.-S. (2009). Comments on “Determining technology trends and forecasts of\nRFID by a historical review and bibliometric analysis from 1991 to 2005”.\nTechnovation, 29(10), 725–727. doi:10.1016/j.technovation.2009.01.002\nHo, Y.-S. (2012). Comments on “a bibliometric study of earthquake research:\n1900–2010”. Scientometrics, (500), 2010–2012. doi:10.1007/s11192-0120915-2\nHuang, M. H., Lin, C. S., &amp; Chen, D. Z. (2011). Counting methods, country rank\nchanges, and counting inflation in the assessment of national research\nproductivity and impact. Journal of the American Society for Information\nScience and Technology, 62(12), 2427–2436.\nHunt, R. (1991). Trying an authorship index. Nature, 352(6332), 187–187.\nRetrieved from http://old.imber.info/DM_WG/DM_portal/authorship.pdf\nIoannidis, J. P. A. (2008). Measuring co-authorship and networking-adjusted\nscientific impact. PLoS One, 3(7), e2778. Retrieved from\nhttp://dx.plos.org/10.1371/journal.pone.0002778\nJones, B. F., Wuchty, S., &amp; Uzzi, B. (2008). Multi-university research teams:\nshifting impact, geography, and stratification in science. science, 322(5905),\n1259–1262. Retrieved from\nhttp://www.sciencemag.org/content/322/5905/1259.short\nKarlsson, S., &amp; Persson, O. (2012). The Swedish Production of Highly Cited\nPapers. Vetenskapsrådet, Stockholm\nKatz, J. S., &amp; Hicks, D. (1997). How much is a collaboration worth? A calibrated\nbibliometric model. Scientometrics, 40(3), 541–554. Retrieved from\nhttp://www.springerlink.com/index/M06J2871281PR764.pdf\nLange, L. (2001). Citation Counts of Multi-Authored Papers—First-named\nAuthors and Further Authors. Scientometrics, 52(3), 457–470. Retrieved from\nhttp://www.akademiai.com/index/Y5DM8J5A4Q90VMGA.pdf\nLarivière, V., Gingras, Y., &amp; Archambault, É. (2009). The decline in the\nconcentration of citations, 1900–2007. Journal of the American Society for\n1524\n\nInformation Science and Technology, 60(4), 858–862. Retrieved from\nhttp://onlinelibrary.wiley.com/doi/10.1002/asi.21011/full\nLarsen, P. (2008). Commentary on: “Indicators of European public research in\nhydrogen and fuel cells—an input–output analysis”. International Journal of\nHydrogen Energy, 33(4), 1455–1456. doi:10.1016/j.ijhydene.2007.12.003\nLarsen, P. O. (2008). The state of the art in publication counting. Scientometrics,\n77(2), 235–251. doi:10.1007/s11192-007-1991-6\nLee, S., &amp; Bozeman, B. (2005). The Impact of Research Collaboration on\nScientific Productivity. Social Studies of Science, 35(5), 673–702.\ndoi:10.2307/25046667\nLeydesdorff, L., &amp; Opthof, T. (2010). Normalization at the field level: Fractional\ncounting of citations. arXiv preprint arXiv:1006.2896. Retrieved from\nhttp://arxiv.org/abs/1006.2896\nLiao, C. H. (2011). How to improve research quality? Examining the impacts of\ncollaboration intensity and member diversity in collaboration networks.\nScientometrics, 86(3), 747–761. Retrieved from\nhttp://www.akademiai.com/index/X1724TP767401812.pdf\nLiu, X., Zhan, F. B., Hong, S., Niu, B., &amp; Liu, Y. (2012). A bibliometric study of\nearthquake research: 1900–2010. Scientometrics, 92(3), 747–765.\ndoi:10.1007/s11192-011-0599-z\nMcGrath, W. (1996). The unit of analysis (objects of study) in bibliometrics and\nscientometrics. Scientometrics, 35(2), 257–264. Retrieved from\nhttp://www.springerlink.com/index/KN81081G526100LK.pdf\nMoed, H. F. (2005). Citation analysis in research evaluation (Vol. 9). Springer.\nRetrieved from\nhttp://www.google.com/books?hl=en&amp;lr=&amp;id=D9SaJ6awy4gC&amp;oi=fnd&amp;pg=\nPR9&amp;dq=Citation+analysis+in+research+evaluation&amp;ots=FFnVIt3Rk_&amp;sig=0\nm5FKrBb1wBHc9dnpddEoxu_NYI\nMoed, H. F., De Bruin, R. E., &amp; Van Leeuwen, T. N. (1995). New bibliometric\ntools for the assessment of national research performance: Database\ndescription, overview of indicators and first applications. Scientometrics,\n33(3), 381–422. Retrieved from\nhttp://www.akademiai.com/index/N0683864614TN345.pdf\nMuhonen, R., Leino, Y., &amp; Puuska, H.-M. (2012). Suomen kansainvälinen\nyhteisjulkaiseminen. Helsinki: Opetus- ja kulttuuriministeriö.\nNicholson, J. M., &amp; Ioannidis, J. P. A. (2012). Research grants: Conform and be\nfunded. Nature, 492(7427), 34–36. doi:10.1038/492034a\nOpetus- ja kulttuuriministeriö. (2011a). Sitaatioindeksityöryhmä II : n raportti.\nOpetus- ja kulttuuriministeriön julkaisuja 2011:34 (The Ministry of Education\nand Culture publications in Finnish), Helsinki\nOpetus- ja kulttuuriministeriö. (2011b). Sitaatioindeksityöryhmän raportti.\nOpetus- ja kulttuuriministeriön julkaisuja 2011:12 (The Ministry of Education\nand Culture publications in Finnish), Helsinki\n\n1525\n\nPersson, O., Glänzel, W., &amp; Danell, R. (2004). Inflationary bibliometric values:\nThe role of scientific collaboration and the need for relative indicators in\nevaluative studies. Scientometrics, 60(3), 421–432. Retrieved from\nhttp://www.akademiai.com/index/h880j22v8t145572.pdf\nRons, N., &amp; Amez, L. (2009). Impact vitality: an indicator based on citing\npublications in search of excellent scientists. Research Evaluation, 18(3), 233–\n241. doi:10.3152/095820209X470563\nSchmoch, U., &amp; Schubert, T. (2008a). Are international co-publications an\nindicator for quality of scientific research? Scientometrics, 74(3), 361–377.\nRetrieved from http://www.springerlink.com/index/8475PP504667561U.pdf\nSchmoch, U., &amp; Schubert, T. (2008b). Are international co-publications an\nindicator for quality of scientific research? Scientometrics, 74(3), 361–377.\nSeymour, E. H. (2008). Rebuttal to commentary. International Journal of\nHydrogen Energy, 33(4), 1457–1458. doi:10.1016/j.ijhydene.2007.12.004\nSeymour, E. H., Borges, F. C., &amp; Fernandes, R. (2007). Indicators of European\npublic research in hydrogen and fuel cells—An input–output analysis.\nInternational Journal of Hydrogen Energy, 32(15), 3212–3222.\ndoi:10.1016/j.ijhydene.2007.02.031\nToivanen, H. (2012a). Identifying hot Brazilian science and technology: Tech\nmining methods for relating sources of knowledge and emerging research\nareas. Karlsruhe, Germany.\nToivanen, H. (2012b). Does the knowledge trap exist? The diverging roles of\ndomestic and foreign capacities for the evolution of knowledge creation in\nChina, India, Brazil, and Northern and Sub-Saharan Africa. Hangzhou, China.\nTreudthardt, L., &amp; Nuutinen, A. (Eds.). (2012). Suomen tieteen tila. Helsinki:\nSuomen Akatemia.\nWagner, C. S., &amp; Leydesdorff, L. (2005). Mapping the network of global science:\ncomparing international co-authorships from 1990 to 2000. International\nJournal of Technology and Globalisation, 1(2), 185–208. Retrieved from\nhttp://inderscience.metapress.com/index/q8x345099crntewm.pdf\nWagner, C. S., &amp; Leydesdorff, L. (2012). An Integrated Impact Indicator: A new\ndefinition of “Impact”with policy relevance. Research Evaluation, 21(3), 183–\n188. Retrieved from http://rev.oxfordjournals.org/content/21/3/183.short\nWaltman, L., Van Eck, N. J., Van Leeuwen, T. N., Visser, M. S., &amp; Van Raan, A.\nF. J. (2011). Towards a new crown indicator: Some theoretical considerations.\nJournal of Informetrics, 5(1), 37–47. Retrieved from\nhttp://www.sciencedirect.com/science/article/pii/S1751157710000817\nVeugelers, R. (2010). Towards a multipolar science world: trends and impact.\nScientometrics, 82(2), 439–456. Retrieved from\nhttp://www.akademiai.com/index/b60146401036v185.pdf\nVinkler, P. (1996). Some practical aspects of the standardization of scientometric\nindicators. Scientometrics, 35(2), 237–245. doi:10.1007/BF02018481\nVinkler, P. (2001). An attempt for defining some basic categories of\nscientometrics and classifying the indicators of evaluative scientometrics.\n1526\n\nScientometrics, 50(3), 539–544. Retrieved from\nhttp://www.springerlink.com/index/q31h04230660123p.pdf\nZhao, D. (2006). Dispelling the Myths Behind First-author Citation Counts.\nProceedings of the American Society for Information ..., 43(1), 1–16.\nRetrieved from\nhttp://onlinelibrary.wiley.com/doi/10.1002/meet.14504301194/full\n\n1527\n\nRESEARCH PERFORMANCE ASSESSMENT\nUSING NORMALIZATION METHOD BASED ON\nSCI DATABASE (RIP)\nLing Zhang1, Juan Wang2, Yanan Zhang3, Xin Tan4, Qing Du5\n1\n\nlingzhang@tju.edu.cn\nTianjin University, 92 Weijin Road, Nankai District, Tianjin (China)\n2\n\nrscwangjuan@tju.edu.cn\nTianjin University, 92 Weijin Road, Nankai District, Tianjin (China)\n3\n\nzhangnanmiao@gmail.com\nTianjin Polytechnic University, extension line, BinshuiXi Road, Xiqing District, Tianjin\n(China)\n4\n\ntanx@tju.edu.cn\nTianjin University, 92 Weijin Road, Nankai District, Tianjin (China)\n5\n\nduqing@tju.edu.cn\nTianjin University, 92 Weijin Road, Nankai District, Tianjin (China)\n\nAbstract\n\nTo correct differences among fields, a derivative indicator of Crown Indicator - Tindicator - was proposed as an effective supplement of established Article Assessment\nSystem of Tianjin University. Based on normalized citation counts, T-indicator could give\nthe order of research performance of researchers or groups in different disciplines. A\ngiven example was used to thoroughly discuss this evaluation method, via the application\nof derivative indices using SCI database.\n\nConference Topic\n\nScientometrics Indicators (Topic 1) and Science Policy and Research Evaluation:\nQuantitative and Qualitative Approaches (Topic 3)\n\nIntroduction\nResearch performance assessment (RPA) plays important roles in universities and\nresearch institutions, especially in the process of recruitment, academic\npromotion, offering tenure, granting, etc. The general indices of RPA include\npublications, patents, awards, and grants. It is hard to evaluate the quality level of\npatents, awards, and grants among different institutions and countries as there is\nno same standard. However, journal publication, mostly published after peer\nreviews, is a good and unique index for internal and external comparison.\n\n1528\n\nNowadays, journal publication has been widely used officially or subconsciously\nin the process of RPA.\nAn article assessment system has been successfully established based on both\nTianjin University and nine key Chinese Universities’ academic disciplinary\nbenchmarks (Zhanga, 2010). With this scientific benchmarking system, the quality\nof a researcher’s papers could be easily located in a percentile scale in\ncorresponding field and within certain groups. Several factors, including total\nnumber of papers, order of authors, impact factor of journals, citation count, hindex (Hirsch, 2005), e-index (Zhangb, 2009), a-index (Jin, 2006), m-quotient\n(Hirsch, 2005), as well as weighted citation analysis (Zhangc, 2009), were also\nutilized for both quantity and quality analysis.\nThis article assessment system has played a significant role as an important part\nof RPA in Tianjin University. However, with unique advantages in comparing\nresearchers or groups in a same field, it is hard to tell their RPA in different fields.\nTo improve this article assessment system, referring to Crown Indicator proposed\nby CWTS, a derivative indicator, named after Tianjin University - T-indicator was applied, where citation counts were normalized for correcting differences\namong fields. (Zhangd, 2012) However, in this early study of T-indicator, the\napplied disciplines were only 25 categories defined in the Scopus database, which\nare very broad for building subject-specific indicators and reference standards. In\nthis paper, 169 disciplines based on SCI database were applied. The modified\ncitation-based article assessment system could easily and specifically give the\norder of research performance of researchers or groups even in different\ndisciplines.\nMethod\nThe average number of citation count of all TJU publications from SCI citation\ndatabase are obtained for each discipline and for each year from the year of 2001\nto the year of 2011, based on the accumulation of citations from the year of\npublication to the current year. (Equation 1)\n\nAC y j\n\n1\n\nnj\n\nnj\n\nC\ni 1\n\ni, j\n\n(1)\nwhere Ci,j are the citations received by the ith paper in the year j, and nj is number\nof papers published in the year j. On the left hand of equation (1), ACyj represents\nthe average number of citations received in the period from year j to 2011 by\npapers published in the year j.\nTo obtain the total T–indicator (Ttotal), annual T–indicator (Tyear) are required to be\ncalculated firstly: the sum of a researcher or group’s actual number of citations of\nall publications is divided by the above average number for each year in the same\ndiscipline (Equation 2).\n\n1529\n\nmj\n\nCi , j\n1 \ni 1\nTy j \nm j AC y j\n\n(2)\n\nwhere mj is the number of papers published by an individual researcher or a group\nof researchers in the year j, and Tyi is the ratio of the average citations received for\nan individual researcher or a group of researchers in the year j, over the average\nnumber of citations received in the year j of the whole university, both in the in\nthe same discipline.\nThe average number of Tyear is the T-indicator (Equation 3)\n\nTtotal \n\n1\n( y2  y1  1)\n\ny2\n\n TJ\nj  y1\n\nyj\n\n(3)\n\nWhere y1 is the first year of the period in which the research performance of an\nindividual researcher or a group of researchers are required to be analyzed, and y2\nis last year of this period required to be analyzed.\nResults and Discussion\nTable of Mean of Citation Count of all TJU Publications is prepared (Table 1) for\n169 disciplines from the year of 2001 to the year of 2011. Total number of TJU\npublications over 11 years and of each year, as well as the annual mean citation\ncount were all included for every category in this table. For example, in category\nof “ENGINEERING CHEMICAL”, total number of TJU publication is 1587; the\nnumber of publications in the year of 2001 and the mean citation count is 41 and\n9.8, respectively.\nTable 1. The Mean of Citation Count of all TJU Publications. The data were\ncollected from SCI citation database at Oct.2012. (The table is too big to present\nentirely.)\nNo.\n\nSubject\n\nMATERIALS SCIENCE\nMULTIDISCIPLINARY\nENGINEERING\n2\nCHEMICAL\n3\nCHEMISTRY PHYSICAL\nCHEMISTRY\n4\nMULTIDISCIPLINARY\n5\nPHYSICS APPLIED\n...\n...\n169 UROLOGY NEPHROLOGY\n1\n\n1530\n\nTotal\nPub.\n\n2001\nPub. Mean\n\n2002\nPub. Mean\n\n2003\nPub. Mean\n\n1731\n\n36\n\n4.0\n\n57\n\n7.8\n\n71\n\n8.4\n\n1587\n\n41\n\n9.8\n\n91\n\n9.5\n\n96\n\n11.0\n\n1356\n\n44\n\n15.9\n\n58\n\n9.5\n\n72\n\n9.0\n\n1164\n\n31\n\n5.3\n\n37\n\n8.1\n\n64\n\n6.9\n\n1009\n...\n1\n\n12\n...\n0\n\n14.1\n...\n0\n\n21\n...\n0\n\n8.9\n...\n0\n\n32\n...\n0\n\n20.2\n...\n0\n\nThe following example is taken to discuss the application of T-indicator. Tianjin\nUniversity announced the competition for an award funding for research\nperformance, and there are 8 candidates. In the process of research publication\nassessment, as shown in Table 2, all of them are excellent in their research fields,\nand some of them have similar number of publications (Candidate 5 and\nCandidate 6), total citation count (Candidate 1 and Candidate 6), and average\ncitation count (Candidate 2 and Candidate 3) as well. Furthermore, considering\nthe property of citation frequency in different research areas, it is very hard to\nsimply compare them via the common indices, including citation count, h-index,\ne-index, etc., as mentioned above. However, T-indicator, based on normalized\ncitation count, could be conveniently used here to give the order of research\nperformance as a helpful reference to the award funding committee.\nTable 2. Publication details of 8 candidates for the award funding for research\nperformance. The data were collected from SCI citation database at Oct.2012.\nNo.\n\nCollege\n\n1\n2\n3\n\nCollege of Science\nCollege of Science\nCollege of Science\nCollege of Precision Instrument and\nOpto-electronics Engineering\nCollege of Precision Instrument and\nOpto-electronics Engineering\nCollege of Material Science and\nEngineering\nCollege of Chemical Engineering and\nTechnology\nCollege of Environment Science and\nTechnology\n\n4\n5\n6\n7\n8\n\nTotal\npub.\n130\n344\n54\n\nTotal\ncitation count\n1079\n5564\n924\n\nAverage citation\ncount\n8.3\n16.2\n17.1\n\n57\n\n368\n\n6.5\n\n101\n\n891\n\n8.8\n\n111\n\n1051\n\n9.5\n\n69\n\n979\n\n14.2\n\n159\n\n2999\n\n18.9\n\nIn SCI citation database, collected journals are categorized into 169 disciplines;\nhowever, due to the relativity among certain fields, publications of some journals\nare subjected to 2 or even more disciplines. In such case, the average of Tindicators of different disciplines could be used instead, due to the normalized\nnative of T-indicator. For example, Candidate 1 has published 130 articles, which\nare categorized to 12 disciplines by SCI, including “Physics Applied” (65),\n“Physics Condensed Matter” (48), “Materials Science Multidisciplinary” (34),\nand so on. Apparently some of the publications are classified to several\ndisciplines by SCI, instead of only one category.\nAs shown in Table 3, in Discipline 1 - the category of “Physics Applied”,\naverages of citation count of different year were calculated firstly (Row 3), which\nwere then divided by the corresponding average number of citation count of all\nTJU publications for each year in Table 1, and the quotients—obtained (Row 4)\nwere Tyear-indicator. T1 (0.77) of “Discipline 1” was subsequently calculated. The\n1531\n\nsame method was also used to calculate the T2 (0.51) of publications in Discipline\n2 of “Physics Condensed Matter”. With this method, T indicator could be\nobtained respectively for the next 10 disciplines. Finally T total (0.42) was achieved\nby computing the mean value of them in different subjects.\nTable 3. T-indicator of publication of Candidate 1. The data were collected from SCI\ncitation database at Oct. 2012.\nCandidate 1\nDiscipline 1: Physics Applied\nYear\n2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011\nNo. of Pub.\n2\n3\n6\n5\n5\n10\n8\n9\n7\n7\n3\nNo. of citation count 49\n7\n104\n68\n44\n55\n42\n61\n23\n18\n2\nAver. of citation\n24.5 2.3 17.3 13.6 8.8\n5.5\n5.2\n6.8\n3.3\n2.6\n0.7\ncount\nTyear\n1.74 0.26 0.86 1.27 0.83 0.54 0.63 0.60 0.55 0.69 0.49\nT1=0.77\nDiscipline 2: Physics Condensed Matter\nYear\n2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011\nNo. of Pub.\n3\n4\n5\n7\n3\n7\n7\n3\n6\n2\n1\nNo. of citation count\n4\n131\n15\n49\n14\n42\n32\n3\n20\n1\n0\nAver. of citation\n1.3 32.8 3.0\n7.0\n4.7\n6.0\n4.6\n1.0\n3.3\n0.5\n0.0\ncount\nTyear\n0.35 1.95 0.27 0.86 0.39 0.57 0.48 0.07 0.47 0.17 0.00\nT2=0.51\nDiscipline ... ...\n......\nDiscipline 12: Metallurgy Metallurgical Engineering\nYear\n2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011\nNo. of Pub.\n1\n1\n2\n1\n2\n1\n3\n2\n0\n1\n0\nNo. of citation count\n0\n0\n13\n16\n33\n0\n25\n5\n0\n2\n0\nAver. of citation\n0.0\n0.0\n6.5 16.0 16.5 0.0\n8.3\n2.5\n0.0\n2.0\n0.0\ncount\nTyear\n0.00 0.00 3.20 5.90 3.57 0.00 2.28 0.77 0.00 0.63 0.00\nT12=1.49\nTtotal=0.42\n\nTtotal could also show an individual annual research performance as shown in\nFigure 1. For example, Ttotal of Candidate 1 hit the peak (1.47) in the year of 2004,\nand reached the bottom after the year of 2008, presenting a decreasing research\nperformance. However, Ttotal of Candidate 2 has gradually climbed up since the\nyear of 2003, and a sudden jump to the peak of 1.22 appeared in the Year of 2004,\nafter that a stable trend was shown, demonstrating an increasing research\nperformance. A conclusion could be drawn that both Candidate 1 and 2 are very\nexcellent in their own research field as their Ttotal are almost over 1, but Candidate\n2 showed higher potential in research.\nWhen comparing the research performance among more scholars in different\ndisciplines, Ttotal displays unique advantages. As shown in Table 4, Ttotal of each\n1532\n\ncandidate was calculated, and from these data, Candidate 8 showed the best\nresearch performance with the highest Ttotal of 1.69, followed by Candidate 5 and\nCandidate 4, with 1.13 and 0.94, respectively, and the poorest performance in this\ngroup is Candidate 1, showing the lowest Ttotal of 0.42.\n\nFigure 1. Ttotal vs. year of Candidate 1 and Candidate 2. (The data were collected\nfrom SCI citation database at Oct. 2012.)\n\nFor further analysis when considering candidates’ contributions to publications,\nweighted T is introduced based on weighted citation analysis. The use of\nweighted citation analysis has been thoroughly discussed elsewhere (Zhangc,\n2009; Zhanga, 2010), which is a quantitative scheme to describe the contribution\nof co-authors via weight coefficient. Basically weight coefficients for the first and\ncorresponding authors are 1 for both, and the correspondence of the second, third,\nand the other authors are decreased sequentially. Weighted T of each candidate\nwas obtained in Table 5. The weighted T-indicator was very similar to the normal\nT-indicator of both Candidates 3 (0.34 and 0.33, respectively), showing his/her\nhigh research contributions to all publications; however, the big difference of\nthese two indicators of Candidate 4 (0.94 and 0.26, respectively) demonstrated\nhis/her un-ideal contribution to all publications. Consequently, the order of\nresearch performance of these candidates based on weighted T-indicator could be\nlisted as Candidate 8, Candidate 2, Candidate 7, Candidate 5, Candidate 3,\nCandidate 6, Candidate 4, and Candidate 1, without the consideration of\ndifferences among disciplines.\nAs described above, the research performance of these 8 candidates was\nquantitatively analyzed via this assessment method, which could give helpful\nreference to the award funding committee but still need the comprehensive\nqualitative evaluation via peer reviews, to get a final reasonable evaluation result\nof research performance of these candidates.\n\n1533\n\nTable 4. Ttotal of publication of 8 candidates. The data were collected from SCI\ncitation database at Oct. 2012.\nNo.\n1\n2\n3\n4\n5\n6\n7\n8\n\nField No.\n12\n26\n22\n15\n8\n17\n13\n19\n\nTtotal\n0.42\n0.91\n0.34\n0.94\n1.13\n0.48\n0.93\n1.69\n\nTable 5. Weighted Ttotal of publication of 8 candidates. The data were collected from\nSCI citation database at Oct. 2012.\nNo.\n1\n2\n3\n4\n5\n6\n7\n8\n\nField No.\n12\n26\n22\n15\n8\n17\n13\n19\n\nTtotal\n0.12\n0.57\n0.33\n0.26\n0.42\n0.28\n0.53\n1.16\n\nConclusions\nThe application of T-indicators has successfully corrected differences among\ndisciplines during research performance assessment using SCI database. An\nexample was given to describe this whole assessment procedure which could not\nonly give the research performance curve with year of candidate, but also provide\nthe order of their research performance. Last but not least, because of the\nincreasing citation times with time, the Table of the Mean of Citation Count of all\nTJU Publications is required to be updated at least twice annually.\nAcknowledgments\nWe thank Prof. Chun-Ting Zhang and Prof. Qiushi Li of Tianjin University for\nhelpful discussions and revisions. Ling Zhang thanks the financial support from\nThe Ministry of education of Humanities and Social Science Research Fund\nPlan/Youth Fund/Self-financing project (11YJC870036) as well as Open Fund\nIT2012006 of the ISTIC-Thomson Reuters Joint Lab for Scientometrics Research.\n\n1534\n\nReferences and Citations\nZhanga, L., Zhao, H., Li, Q., Wang, J. &amp; Tan, X. (2010) Establishment of Paper\nassessment system based on acadmic disciplinary benchmarks. Scientometrics,\n84, 421-429.\nHirsch, J.E. (2005) An index to quantify an individual&#x27;s scientific research output.\nProceedings of the National Academy of Sciences of the United States of\nAmerica, 102, 16569-16572.\nZhangb, C.T. (2009) The e-index, complementing the h-index for excess citations.\nPLoS (Public Library of Science) ONE, 4, e5429.\nJin, B. (2006) h-index: an evaluation indicator proposed by scientist. Science\nFocus, 1, 8–9.\nZhangc, C.T. (2009) A proposal for calculating weighted citations based on author\nrank. EMBO (European Molecular Biology Organization) Reports, 10, 416417.\nZhangd, L., Tan, X., Du, Q., Wang,J. (2012) Research Performance Assessment\nbased on T-indicator. Open Journal of Statistics, 2, 46-351.\n\n1535\n\nRETHINKING RESEARCH EVALUATION\nINDICATORS AND METHODS FROM AN\nECONOMIC PERSPECTIVE: THE FSS INDICATOR\nAS A PROXY OF PRODUCTIVITY\nGiovanni Abramoa, *, Ciriaco Andrea D’Angeloa,b\na\n\nLaboratory for Studies of Research and Technology Transfer\nInstitute for System Analysis and Computer Science (IASI-CNR)\nNational Research Council of Italy\nViale Manzoni, 30; 00185 Roma - Italy\nb\n\nSchool of Engineering, Department of Management\nUniversity of Rome “Tor Vergata”\n\nAbstract\n\nThe current bibliometric indicators and methods for evaluation of research performance\nare generally inappropriate in the light of economic theory of production. World ranking\nlists, including those by noted research agencies, seem based on what can be easily\ncounted rather than “what really counts”. In this work we operationalize the economic\nconcept of productivity for the specific context of research activity and propose a\nmeasurable form of productivity. From an economic perspective, we demonstrate the\nlimits of the most commonly-used performance indicators and we present the indicator\n“Fractional Scientific Strength (FSS)”, which better approximates the measure of research\nproductivity. We present the methodology for measure of FSS at various levels of\nanalysis: individual, field, discipline, department, institution, region and nation.\n\nConference Topic\n\nTopic 1 - Scientometrics Indicators: Criticism and new developments\n\nIntroduction\nIn 2010, Opthof &amp; Leydesdorff criticized the statistical normalization of the\nLeiden CWTS “crown indicator”. A year later, bibliometricians from the CWTS\ngroup (Waltman et al., 2011) admitted that the “old crown indicator” was\nmathematically inconsistent and adopted the normalization method suggested by\nthe above authors, leading to a “new crown indicator”: the mean normalized\ncitation score, or MNCS. A counter-reply from Leydesdorff &amp; Opthof (2011) was\nnot long in arriving: although agreeing with the new statistical normalization, they\nthen further recommended using the mean rather than the median to field\nnormalize citations.\n\n1536\n\nIn a parallel story, since the original introduction of the h-index in 2005 by\nphysicist Jorge E. Hirsch, over 1,300 articles have been written illustrating its\nmerits and defects and proposing one variant after another, to the extent even the\nmost devoted historian of bibliometrics would despair of tracing them all.\nBut is it possible that these two indicators really merited all this attention, or is it a\ncase of “Much ado about nothing”? These particular indicators have only been the\nmost popular among a myriad of others proposed over recent years by scholars\nand practitioners. While bibliometricians undoubtedly intended to provide useful\nindicators and ever more accurate and reliable methods, they have actually been\nthe cause of increasing confusion. The proliferation of proposals has actually\ngenerated a type of disorientation among decision makers, no longer able to\ndiscriminate the pros and cons of the various indicators for planning an actual\nevaluation exercise. The proof of this is the increasing number of expert\ncommissions and working groups at institutional, national and supranational\nlevels, formed to deliberate and recommend on this indicator, that set of\nindicators, and this or that measure of performance. Performance ranking lists at\nnational and international levels are published with media fanfare, influencing\nopinion and practical choices. The impression of the current authors is that these\nrankings of scientific performance, produced by “non-bibliometricians” (THES,\n2012; ARWU, 2011; QS, 2011; etc.) and even by bibliometricians (University of\nLeiden, SCImago, etc.), are largely based on what can easily be counted rather\nthan “what really counts”. It is also our impression that the large part of the\nperformance evaluation indicators proposed in the literature arise from a primarily\nmathematical school of thought. While knowledge in this area is fundamental in\nthe methodology for application, our personal conviction is that research\nevaluation indicators must necessarily derive from economic theory. Since\nresearch activity is a production process, it should be analyzed from the\nperspective of microeconomic theory of production. Performance, or the ability to\nperform, should be evaluated with respect to the specific goals and objectives to\nbe achieved. The objectives must therefore be stated in measurable terms\nrepresenting the desired outcome of production activity. The principal\nperformance indicator of a production unit (whether this an individual, research\ngroup, department, institution, field, discipline, region or country) is its\nproductivity, or simply speaking the ratio of the value of the production output to\nthe value of the inputs required to produce it. From this point of view, we will see\nthat the renowned crown indicator and h-index, with its innumerable variants, and\na wide variety of other publication-based and citation-based indicators, are\ninadequate to measure research productivity. As a consequence, all the research\nevaluations based on these indicators and their relative rankings are at best of\nlittle or no value, and are otherwise actually dangerous, due to the distortions\nembedded in the information provided to the decision-makers. For the large part\nof the objectives and contexts where evaluation of research performance is\nconducted, productivity is either the most important or the only indicator that\nshould inform policy, strategy and operational decisions. We thus issue a two-fold\n1537\n\ncall to the scholars in the subject: first, to focus their knowledge and skills on\nfurther refining the measurement of this indicator in contexts of real use; second,\nto refrain from distribution of institutions’ performance ranking lists based on\ninvalid indicators, which could have negative consequences when used by policymakers and research administrators.\nIn this work we intend to operationalize the concept of productivity for the\nspecific context of research activity and propose a measurable form of\nproductivity. We will then present an indicator, Fractional Scientific Strength\n(FSS), which in our view is thus far the best in approximating the measure of\nproductivity. We will also illustrate the methodology for measuring FSS in the\nevaluation of performance at various levels of analysis: individual, field,\ndiscipline, department, institution, region and nation.\nProductivity in research activities\nIn this section, our intention is to operationalize the concept of research\nproductivity in simple terms and propose a proxy to measure it.\nGenerally speaking, the objective of research activity is to produce new\nknowledge. Research activity is a production process in which the inputs consist\nof human, tangible (scientific instruments, materials, etc.) and intangible\n(accumulated knowledge, social networks, economic rents, etc.) resources, and\nwhere output, the new knowledge, has a complex character of both tangible nature\n(publications, patents, conference presentations, databases, etc.) and intangible\nnature (tacit knowledge, consulting activity, etc.). The new-knowledge production\nfunction has therefore a multi-input and multi-output character. The principal\nefficiency indicator of any production unit (individual, research group,\ndepartment, institution, field, country) is productivity, i.e. the ratio of the value of\noutput produced in a given period to the value of production factors used to\nproduce it. To calculate research productivity one needs adopt a few\nsimplifications and assumptions.\nOn the output side, a first approximation arrives from the imposition of not being\nable to measure any new knowledge that is not codified. Second, where new\nknowledge is indeed codified, we are faced with the problem of identifying and\nmeasuring its various forms. It has been shown (Moed, 2005) that in the so-called\nhard sciences, the prevalent form of codification for research output is publication\nin scientific journals. Such databases as Scopus and Web of Science (WoS) have\nbeen extensively used and tested in bibliometric analyses, and are sufficiently\ntransparent in terms of their content and coverage. As a proxy of total output in\nthe hard sciences, we can thus simply consider publications indexed in either\nWoS or Scopus142. With this proxy, those publications that are not censused will\ninevitably be ignored. This approximation is considered acceptable in the hard\n142\n\nAlthough the overall coverage of the two databases does differ significantly, evidence suggests\nthat, with respect to comparisons at large scale level in the hard sciences, the use of either source\nyields similar results (Archambault et al., 2009).\n1538\n\nsciences, although not for the arts, humanities and a good part of the social\nscience fields. Other forms of output, particularly patents, can be identified in\ncommercial or free databases such as Derwent and Espacenet. Patents are often\nfollowed by publications that describe their content in the scientific arena, so the\nanalysis of publications alone may actually avoid in many cases a potential double\ncounting.\nResearch projects frequently involve a team of researchers, which shows in coauthorship of publications. Productivity measures then need to account for the\nfractional contributions of single units to outputs. The contributions of the\nindividual co-authors to the achievement of the publication are not necessarily\nequal, and in some fields the authors signal the different contributions through\ntheir order in the byline. The conventions on the ordering of authors for scientific\npapers differ across fields (Pontille, 2004; RIN, 2009), thus the fractional\ncontribution of the individuals must be weighted accordingly. Following these\nlines of logic, all performance indicators based on full counting or “straight”\ncounting (where only the first author or the corresponding author receive full\ncredit and all others receive none) are invalid measures of productivity. The same\ninvalidity applies to all indicators based on equal fractional counting in fields\nwhere co-author order has recognized meaning.\nFurthermore, because the intensity of publications varies across fields (Garfield,\n1979; Moed et al., 1985; Butler, 2007), in order to avoid distortions in\nproductivity rankings (Abramo, D’Angelo &amp; Di Costa, 2008), we must compare\norganizational units within the same field. A prerequisite of any productivity\nassessment free of distortions is then a classification of each individual researcher\nin one and only one field. An immediate corollary is that the productivity of units\nthat are heterogeneous for fields of research of their staff cannot be directly\nmeasured at the aggregate level, and that there must be a two-step procedure: first\nmeasuring the productivity of the individual researchers in their field, and then\nappropriately aggregating this data.\nIn bibliometrics we have seen the evolution of language where the term\n“productivity” measures refers to those based on publication counts while\n“impact” measures are those based on citation counts. In a microeconomic\nperspective, the first operational definition would actually make sense only if we\nthen compare units that produce output of the same value. In reality this does not\noccur, because the publications embedding the new knowledge produced have\ndifferent values. Their value is measured by their impact on scientific\nadvancements. As proxy of impact bibliometricians adopt the number of citations\nfor the units’ publications, in spite of the limits of this indicator (negative\ncitations, network citations, etc.) (Glänzel, 2008). Citations do in fact demonstrate\nthe dissemination of knowledge, creating conditions for knowledge spillover\nbenefits. Citations thus represent a proxy measure of the value of output.\nComparing units’ productivity by field is not enough to avoid distortions in\nrankings. In fact citation behavior too varies across fields, and is not unlikely that\nresearchers belonging to a particular scientific field may also publish outside that\n1539\n\nfield (a typical example is statisticians, who may apply statistics to medicine,\nphysics, social sciences, etc.). For this reason we need to standardize the citations\nof each publication with respect to a scaling factor stemming from the distribution\nof citations for all publications of the same year and the same subject category. 143\nDifferent scaling factors have been suggested and adopted to field normalize\ncitations (average, median, z-score of normalized distributions, etc.).\nOn the side of production factors, there are again difficulties in measure that lead\nto inevitable approximations. The identification of production factors other than\nlabor and the calculation of their value and share by fields is not always easy\n(consider quantifying value of accumulated knowledge or scientific instruments\nshared among units). Furthermore, depending on the objectives of the assessment\nexercise, it could sometimes be useful to isolate and examine the contribution to\noutput of factors, that are independent of the capacities of the staff for the units\nunder examination (for example returns to scale, returns to scope, available\ncapital, etc.).\nLabor productivity in research activity and the FSS\nThe productivity of the total production factors is therefore not easily measurable.\nThere are two traditional approaches used by scholars to measure the total factor\nproductivity: parametric and non-parametric techniques. Parametric\nmethodologies are based on the a priori definition of the function that can most\neffectively represent the relationship between input and output of a particular\nproduction unit. The purpose of non-parametric methods, on the other hand, is to\ncompare empirically measured performances of production units (commonly\nknown as Decision Making Units, DMUs), in order to define an “efficient”\nproduction frontier, comprising the most productive DMUs. The reconstruction of\nthat frontier is useful to assess the inefficiency of the other DMUs, based on\nminimum distance from the frontier.\nThe measure of total factor productivity requires information on the different\nproduction factors by unit of analysis. Instead of total factor research productivity,\nmost often research administrators are interested in measuring and comparing\nsimply labor productivity, i.e. the value of output per unit value of labor, all other\nproduction factors being equal. In measuring labor productivity then, if there are\ndifferences of production factors available to each unit, one should normalize for\nthese. Unfortunately, relevant data are not easily available, especially at the\nindividual level. Thus an often-necessary assumption is that the resources\navailable to units within the same field are the same. A further assumption, again\nunless specific data are available, is that the hours devoted to research are more or\nless the same for each individual. Finally, the cost of labor is likely to vary among\nresearch staff, both within and between units. In a study of Italian universities,\nAbramo, D’Angelo &amp; Di Costa (2011) demonstrated that productivity of full,\n143\n\nThe subject category of a publication corresponds to that of the journal where it is published. For\npublications in multidisciplinary journals the scaling factor is generally calculated as the average of\nthe standardized values for each subject category.\n\n1540\n\nassociate and assistant professors is different. Because academic rank determines\ndifferentiation in salaries, if information on individual salaries in unavailable then\none can still reduce the distortion in productivity measures by differentiating\nperformance rankings by academic rank.\nNext we propose our best proxy for the measurement of the average yearly labor\nproductivity at various unit levels (individual, field, discipline, department, entire\norganization, region and country). The indicator is named “Fractional Scientific\nStrength” (FSS), and we have previously applied it to the Italian higher education\ncontext, where most of its embedded approximations and assumption are\nlegitimate.\nAs noted above, for any productivity ranking concerning units that are nonhomogenous for their research fields, it is necessary to start from the measure of\nproductivity of the individual researchers or fields. Without these two building\nblocks, any measure at aggregate level presents strong distortions (Abramo,\nD’Angelo &amp; Di Costa, 2008). In their measures of this data, the authors gain\nadvantage from a characteristic that seems unique to the Italian higher education\nsystem, in which each professor is classified as belonging to a single research\nfield. These formally-defined fields are called “Scientific Disciplinary Sectors”\n(SDSs): there are 370 SDSs, grouped into 14 “University Disciplinary Areas”\n(UDAs). In the hard sciences, there are 205 such fields144 grouped into in nine\nUDAs.145\nWhen measuring research productivity, the specifications for the exercise must\nalso include the publication period and the “citation window” to be observed. The\nchoice of the publication period has to address often contrasting needs: ensuring\nthe reliability of the results issuing from the evaluation, but also permitting\nconduct of frequent assessments. For the most appropriate publication period to\nbe observed see Abramo, D’Angelo &amp; Cicero (2012a), while for the citation\nwindow that optimizes the tradeoff between accuracy of rankings and timeliness\nof the evaluation exercise, see Abramo, D’Angelo &amp; Cicero (2012b).\nLabor productivity at the individual level\nAt micro-unit level (the individual researcher level, R) we measure Fractional\nScientific Strength (FSSR), a proxy of the average yearly productivity over a\nperiod of time, accounting for the cost of labor. In formula:\n∑\n̅\n\n[1]\n\nWhere:\ns = average yearly salary of the researcher\nt = number of years of work of the researcher in the period of observation;\nN = number of publications of the researcher in the period of observation;\n144\n\nThe complete list is accessible on http://attiministeriali.miur.it/UserFiles/115.htm\nMathematics and computer sciences; physics; chemistry; earth sciences; biology; medicine;\nagricultural and veterinary sciences; civil engineering; industrial and information engineering.\n\n145\n\n1541\n\n= citations received by publication i;\n̅ = average of the distribution of citations received for all cited publications146 of\nthe same year and subject category of publication i;\n= fractional contribution of the researcher to publication i.\nFractional contribution equals the inverse of the number of authors, in those fields\nwhere the practice is to place the authors in simple alphabetical order, but\nassumes different weights in other cases. For the life sciences, widespread\npractice in Italy and abroad is for the authors to indicate the various contributions\nto the published research by the order of the names in the byline. For these areas,\nwe give different weights to each co-author according to their order in the byline\nand the character of the co-authorship (intra-mural or extra-mural). If first and last\nauthors belong to the same university, 40% of citations are attributed to each of\nthem; the remaining 20% are divided among all other authors. If the first two and\nlast two authors belong to different universities, 30% of citations are attributed to\nfirst and last authors; 15% of citations are attributed to second and last author but\none; the remaining 10% are divided among all others147.\nTo calculate productivity accounting for the cost of labor, requires knowledge of\nthe cost of each researcher, information that is usually unavailable for reasons of\nprivacy. In the Italian case we have resorted to a proxy. In the Italian university\nsystem, salaries are established at the national level and fixed by academic rank\nand seniority. Thus all professors of the same academic rank and seniority receive\nthe same salary, regardless of the university that employs them. The information\non individual salaries is unavailable but the salaries ranges for rank and seniority\nare published. Thus we have approximated the salary for each individual as the\naverage of their academic rank.\nIf information on salary is not available at all, one should at least compare\nresearch performance of individuals of the same academic rank.\nThe productivity of each scientist is calculated in each SDS and expressed on a\npercentile scale of 0-100 (worst to best) for comparison with the performance of\nall Italian colleagues of the same SDS; or as the ratio to the average performance\nof all Italian colleagues of the same SDS with productivity above zero 148. In\ngeneral we can exclude, for the Italian case, that productivity ranking lists may be\ndistorted by variable returns to scale, due to different sizes of universities\n(Abramo, D’Angelo &amp; Cicero, 2012d) or by returns to scope of research fields\n(Abramo, D’Angelo &amp; Di Costa, 2012e).\n\n146\n\nA preceding article by the same authors demonstrated that the average of the distribution of\ncitations received for all cited publications of the same year and subject category is the most reliable\nscaling factor (Abramo, D’Angelo &amp; Cicero, 2012c).\n147\nThe weighting values were assigned following advice from senior Italian professors in the life\nsciences. The values could be changed to suit different practices in other national contexts.\n148\nIn a preceding article the authors demonstrated that the average of the productivity distribution of\nresearchers with productivity above 0 is the most effective scaling factor to compare the\nperformance of researchers of different fields (Abramo, D’Angelo &amp; Cicero, 2012f).\n1542\n\nLabor productivity in a specific field\nAt field level, the yearly average productivity\nover a certain period for\nresearchers in a university (region, country, etc.) in a particular SDS149 is:\n∑\n̅\n\n[2]\n\nWhere:\n= total salary of the research staff of the university in the SDS, in the\nobserved period;\nN = number of publications of the research staff in the SDS of the university, in\nthe period of observation;\n= citations received by publication i;\n̅ = average citations received by all cited publications of the same year and\nsubject category of publication i;\n= fractional contribution of researchers in the SDS of the university, to\npublication i, calculated as described above.\nFor each SDS we can construct a university (region, country, etc.) productivity\nranking list by FSSS expressed in percentiles or as the FSSS ratio to average FSSS\nof all universities with productivity above zero in the SDS.\nThe measures of productivity at field level permit identification of field strengths\nand weaknesses and thus correctly inform research policies and strategies.\nLabor productivity of multi-fields units\nIn multi-field organizational units (i.e. disciplines, departments, universities,\nregions, nations), where there are researchers that belong to different fields, we\nare presented with the problem of how to aggregate productivity measures for\nresearchers from the various fields. Two methods are possible, based on either the\nperformance of individual researchers (FSSR), or of the SDSs (FSSS) present in the\nunit under examination. The appropriate choice depends on the objective for the\nmeasure. The first method emphasizes individual performance and the second\nemphasizes field performance, which we note is a “virtual” unit, since the\nmembers of the SDS at a university do not necessarily work together on a\nstructured basis. The research administrator will perhaps be more interested in the\nperformance results derived under the first method, determined from the average\n149\nWe note again that a field is not an organizational unit, rather a classification of researchers by\ntheir scientific qualifications. This does not mean that all the researchers in the same field and\norganization will necessarily form a single research group that works together. As an example, we\nquote the SDS description for FIS/03-Materials physics: “The sector includes the competencies\nnecessary for dealing with theory and experimentation in the state of atomic and molecular\naggregates, as well as competencies suited to dealing with properties of propagation and interaction\nof photons in fields and with material. Competencies in this sector also concern research in fields of\natomic and molecular physics, liquid and solid states, semiconductors and metallic element\ncomposites, dilute and plasma states, as well as photonics, optics, optical electronics and quantum\nelectronics”. In the Italian academic system it is quite common to find “Materials physics”\nresearchers working in two different departments (physics and engineering) at the same university.\n\n1543\n\nof individual productivities. On the other hand the policy-maker, not being\nparticularly interested in the performance variability within the organizational\nunits but rather in comparison of the overall productivity of the various research\ninstitutions, could prefer the performance measure calculated by the second\nmethod. In the following subsections we present the two measurement\nprocedures.\nLabor productivity of multi-fields units based on FSSR\nWe have seen that the performance of the individual researchers in a unit can be\nexpressed in percentile rank or standardized to the field average. Thus the\nproductivity of multi-field units can be expressed by the simple average of the\npercentile ranks of the researchers. It should be noted that the resort to percentile\nrank for the performance measure in multi-filed units or for simple comparison of\nperformance for researchers in different fields is subject to obvious limitations,\nthe first being compression of the performance differences between one position\nand the next. Thompson (1993) warns that percentile ranks should not be added\nor averaged, because percentile is a numeral that does not represent equalinterval measurement. Further, percentile rank is also sensitive to the size of the\nfields and to the performance distribution. For example, consider a unit composed\nof two researchers in two different SDSs (A and B, each with a national total of\n10 researchers), who both rank in third place, but both with productivity only\nslightly below that of the first-ranked researchers in their respective SDSs: the\naverage rank percentile for the unit will be 70. Then consider another unit with\ntwo researchers belonging to another two SDSs (C and D, each with 100\nresearchers), where both of the individuals place third but now with a greater gap\nto the top scientists of their SDSs (potentially much greater): their percentile rank\nwill be 97. In this particular example, a comparison of the two units using\npercentile rank would certainly penalize the former unit.\nHowever the second approach, involving standardization of productivity by field\naverage, takes account of the extent of difference between productivities of the\nindividuals. In formula, the productivity\nover a certain period for\ndepartment D, composed of researchers that belong to different SDSs:\n∑\n\n̅̅̅̅̅̅̅̅\n\n[3]\n\nWhere:\n= research staff of the department, in the observed period;\n= productivity of researcher i in the department;\n̅̅̅̅̅̅̅= average productivity of all productive researchers in the same SDS of\nresearcher i.\nLabor productivity of multi-fields units based on FSSS\nThe second method for measurement of research unit productivity involves\nidentifying all the SDSs present in the unit and assigning each one a relative\n1544\n\nweight depending on size (full time equivalent research personnel). As an\nexample, for measurement of productivity of a university (region, nation) in a\ndiscipline (UDA), beginning from the productivity of the individual SDSs (FSSs),\nthe productivity\nof a university in a specific UDA U, is:\n∑\n\n̅̅̅̅̅̅̅̅\n\n[4]\n\nWith:\n= total salary of the research staff of the university in the SDS i, in the\nobserved period;\n= total salary of the research staff of the university in the UDA U, in the\nobserved period;\n= number of SDSs of the university in the UDA U;\n̅̅̅̅̅̅̅ = national FSSS in the SDS i.\nFor the measure of the productivity of a department (or university, region,\ncountry), the procedure is exactly the same: the only thing that changes is the size\nweight of the SDS, which is no longer with respect to the other SDSs of the UDA,\nbut rather to all the SDSs of the department (university, region, country).\nAs noted, the appropriate choice between the two methods of measure for\nperformance of a multi-field unit depends on the aims of the evaluation. The first\nmethod, based on productivity of individual researchers, interprets the\nperformance of the unit as the average of the individual performances, meaning\nthat the emphasis is on the individual. The other method, based on productivity of\nfields, interprets the field as a unique group (even though a virtual group),\nmeaning that emphasis is on the overall product of the researchers that belong to\nthe field, independently of the variability of the individual contributions. The two\nmethods lead to performance results that are quite similar. In a future work we\nwill provide a comparative in-depth analysis of the two methods.\nConclusions and recommendation\nUntil now, bibliometrics has proposed indicators and methods for measuring\nresearch performance that are largely inappropriate from a microeconomics\nperspective. The h-index and most of its variants, for example, inevitably ignore\nthe impact of works with a number of citations below h and all citations above h\nof the h-core works. The h-index fails to field-normalize citations, to account for\nthe number of co-authors and their order in the byline, Last but not least, because\nof the different intensity of publications across fields, productivity rankings need\nto be carried out by field (Abramo &amp; D’Angelo, 2007), when in reality there is a\nhuman tendency to compare h-indexes for researchers across different fields.\nEach one of the proposed h-variant indicators tackles one of the many drawbacks\nof the h-index while leaving the others unsolved, so none can be considered\ncompletely satisfactory.\n\n1545\n\nThe new crown indicator, on the other hand, measures the average standardized\ncitations of a set of publications, which cannot provide any indication of unit\nproductivity. In fact a unit with double the MNCS value of another unit could\nactually have half the productivity, if the second unit produced four times as many\npublications. Whatever the CWTS research group (Waltman et al., 2012) might\nclaim for them, the annual world university rankings by MNCS are not\n“performance” rankings - unless someone abnormally views performance as\naverage impact of product, rather than impact per unit of cost. Applying the\nCWTS method, a unit that produces only one article with 10 citations has better\nperformance than a unit producing 100, where each but one of these gets 10\ncitations and the last one gets nine citations. Further, the methodology reported\nfor producing the ranking lists does not describe any weighting for co-authorship\non the basis of byline order. Similar drawbacks are embedded is the SCImago\nInstitutions Ranking by their main indicator, the Normalized Impact, measuring\nthe ratio between the average scientific impact of an institution and the world\naverage impact of publications of the same time frame, document type and subject\narea. We do not further consider any of the many annual world institutional\nrankings that are severely size dependent: the SJTU Shanghai Jiao Tong\nUniversity, THES Times Higher Education Supplement and QS Quacquarelli\nSymonds rankings, among others. These seem to represent skilled\ncommunications and marketing operations, with the actual rankings resulting\nmore from improvisation than scientifically-reasoned indicators and methods.\nThe great majority of the bibliometric indicators and the rankings based on their\nuse present two fundamental limits: lack of normalization of the output value to\nthe input value, and absence of classification of scientists by field of research.\nWithout normalization there cannot be any measure of productivity, which is the\nquintessential indicator of performance in any production unit; without providing\nfield classification of scientists, the rankings of multi-field research units will\ninevitably be distorted, due to the different intensity of publication across fields.\nAn immediate corollary is that it is impossible to correctly compare productivity\nat international levels. In fact there is no international standard for classification\nof scientists and, we are further unaware of any nations that classify their\nscientists by field at domestic level, apart from Italy. This obstacle can in part be\novercome by indirectly classifying researchers according to the classification of\ntheir scientific production into WoS or Scopus categories, and then identifying the\npredominant category. Fractional Scientific Strength (FSS) is a proxy indicator of\nproductivity permitting measurement at different organizational levels. Both the\nindicator and the related methods can certainly be improved, however they do\nmake sense according to economic theory of production. Other indicators and\nrelated rankings, such as the simple number (or fractional counting) of\npublications per research unit, or the average normalized impact, cannot alone\nprovide evaluation of performance - however they could assume meaning if\nassociated with a true measure of productivity. In fact if a research unit achieves\naverage levels of productivity this could result from average production and\n1546\n\naverage impact, but also from high production and low impact, or the inverse. In\nthis case, knowing the performance in terms of number of publications and\naverage normalized impact would provide useful information on which aspect\n(quantity or impact) of scientific production to strengthen for betterment of\nproduction efficiency.\nAside from having an indicator of research unit productivity, the decision-maker\ncould also find others useful, such as ones informing on unproductive researchers,\non top researchers (10%, 5%, 1%, etc.), top publications, dispersion of\nperformance within and between research units, etc.\nBased on the analyses above, we issue an appeal and recommendation. Our appeal\nto scholars is to concentrate their efforts on the formulation of productivity\nindicators more or less resembling the one we propose, and on the relative\nmethods of measurement, aiming at truly robust and meaningful international\ncomparisons. Our recommendation is to avoid producing research performance\nrankings by invalid indicators and methods, which under the best of\ncircumstances serve no effective purpose, and when used to inform policy and\nadministrative decisions can actually be dangerous. Our undertaking, as soon as\npossible, should be to develop a roadmap of actions that will achieve international\nperformance rankings that are meaningful and useful to the research administrator\nand policy-maker.\nReferences\nAbramo, G., Cicero, T. &amp; D’Angelo, C.A. (2012a). A sensitivity analysis of\nresearchers’ productivity rankings to the time of citation observation. Journal\nof Informetrics, 6(2), 192–201.\nAbramo, G., Cicero, T. &amp; D’Angelo, C.A. (2012b). What is the appropriate length\nof the publication period over which to assess research performance?\nScientometrics, 93(3), 1005-1017.\nAbramo, G., Cicero, T. &amp; D’Angelo, C.A. (2012c). Revisiting the scaling of\ncitations for research assessment. Journal of Informetrics, 6(4), 470–479.\nAbramo, G., Cicero, T. &amp; D’Angelo, C.A. (2012d). Revisiting size effects in\nhigher education research productivity. Higher Education, 63(6), 701-717.\nAbramo, G., D’Angelo, C.A. &amp; Di Costa, F. (2012e). Investigating returns to\nscope of research fields in universities. Working paper LabRTT. A short\nabstract available at\nhttp://www.disp.uniroma2.it/laboratoriortt/TESTI/Working%20paper/Returns_\nto_scope.pdf\nAbramo, G., Cicero, T. &amp; D’Angelo, C.A. (2013). Individual research\nperformance: a proposal for comparing apples to oranges. Journal of\nInformetrics, 7(2), 528-529.\nAbramo, G., D’Angelo, C.A. &amp; Di Costa, F. (2011). Research productivity: are\nhigher academic ranks more productive than lower ones? Scientometrics,\n88(3), 915-928.\n\n1547\n\nAbramo, G., D’Angelo, C.A. &amp; Di Costa, F. (2008). Assessment of sectoral\naggregation distortion in research productivity measurements. Research\nEvaluation, 17(2), 111-121.\nAbramo, G. &amp; D’Angelo, C.A. (2007). Measuring science: irresistible\ntemptations, easy shortcuts and dangerous consequences. Current Science,\n93(6), 762-766.\nArchambault, É., Campbell, D., Gingras, Y. &amp; Larivière, V. (2009). Comparing\nbibliometric statistics obtained from the Web of Science and Scopus. Journal\nof the American Society for Information Science and Technology, 60(7), 13201326.\nButler, L. (2007). Assessing university research: A plea for a balanced approach.\nScience and Public Policy, 34(8), 565-574.\nGarfield, E. (1979). Is citation analysis a legitimate evaluation tool?\nScientometrics,1(4), 359-375.\nGlänzel, W. (2008). Seven myths in bibliometrics. About facts and fiction in\nquantitative science studies. Kretschmer &amp; F. Havemann (Eds): Proceedings\nof WIS Fourth International Conference on Webometrics, Informetrics and\nScientometrics &amp; Ninth COLLNET Meeting, Berlin, Germany.\nHirsch, J.E. (2005). An index to quantify an individual’s scientific research\noutput. Proceedings of the National Academy of Sciences, 102(46), 1656916572.\nLeydesdorff, L. &amp; Opthof, T. (2011) Remaining problems with the “New Crown\nIndicator” (MNCS) of the CWTS, Journal of Informetrics, 5(1), 224-225.\nMoed, H.F. (2005). Citation Analysis in Research Evaluation. Springer, ISBN:\n978-1-4020-3713-9\nMoed, H.F., Burger, W.J M., Frankfort, J.G. &amp; Van Raan, A.F.J. (1985). The\napplication of bibliometric indicators: Important field- and time-dependent\nfactors to be considered. Scientometrics, 8(3-4), 177-203.\nOpthof, T. &amp; Leydesdorff, L. (2010). Caveats for the journal and field\nnormalizations in the CWTS (“Leiden”) evaluations of research performance.\nJournal of Informetrics, 4(3), 423–430.\nPontille, D. (2004). La Signature Scientifique: Une Sociologie Pragmatique de\nl’Attribution. CNRS ÉDITIONS, Paris, 2004.\nQS-Quacquarelli Symonds (2011). World University Rankings. Retrieved January\n16, 2013 from: http://www.topuniversities.com/university-rankings/worlduniversity-rankings.\nRIN (Research Information Network) (2009). Communicating Knowledge: How\nand Why Researchers Publish and Disseminate Their Findings. London, UK:\nRIN. Retrieved January 16, 2013 from:\nhttp://www.jisc.ac.uk/publications/research/2009/communicatingknowledgere\nport.aspx.\nSJTU-Shanghai Jiao Tong University (2011). Academic Ranking of World\nUniversities. Retrieved January 16, 2013 from:\nhttp://www.shanghairanking.com/ARWU2011.html.\n1548\n\nTHES-Times Higher Education Supplement (2012). World Academic Ranking\n2011-2012. Retrieved January 16, 2013 from:\nhttp://www.timeshighereducation.co.uk/world-university-rankings/20112012/top-400.html.\nThompson, B. (1993). GRE Percentile Ranks Cannot Be Added or Averaged: A\nPosition Paper Exploring the Scaling Characteristics of Percentile Ranks, and\nthe Ethical and Legal Culpabilities Created by Adding Percentile Ranks in\nMaking “High-Stakes” Admission Decisions. Paper presented at the Annual\nMeeting of the Mid-South Educational Research Association, New Orleans,\nLA, November 12, 1993.\nWaltman, L., Van Eck, N.J., Van Leeuwen, T.N., Visser, M.S. &amp; Van Raan,\nA.F.J. (2011). Towards a new crown indicator: Some theoretical\nconsiderations. Journal of Informetrics, 5(1), 37–47.\nWaltman, L., Calero-Medina, C., Kosten, J., Noyons, E. C. M., Tijssen, R. J. W.,\nVan Eck, N. J., ... &amp; Wouters, P. (2012). The leiden ranking 2011/2012: Data\ncollection, indicators, and interpretation. Journal of the American Society for\nInformation Science and Technology, 63(12), 2419-243.\n\n1549\n\nTHE ROLE OF NATIONAL UNIVERSITY\nRANKINGS IN AN INTERNATIONAL CONTEXT:\nTHE CASE OF THE I-UGR RANKINGS OF\nSPANISH UNIVERSITIES\nNicolás Robinson-García1, Jose Garcia Moreno-Torres2, Daniel Torres-Salinas3,\nEmilio Delgado López-Cózar1 and Francisco Herrera4\n1\n\n{elrobin, edelgado}@ugr.es\nEC3: Evaluación de la Ciencia y de la Comunicación Científica, Departamento de\nBiblioteconomía y Documentación, Universidad de Granada (Spain)\n2\n\njose.garcia.mt@gmail.com\nDepartment of Computer Science and Artificial Intelligence, Universidad de Granada\n(Spain)\n3\n\ntorressalinas@gmail.com\nEC3: Evaluación de la Ciencia y de la Comunicación Científica, Centro de Investigación\nBiomédica Aplicada, Universidad de Navarra (Spain)\n4 herrera@decsai.ugr.es\nDepartment of Computer Science and Artificial Intelligence, Universidad de Granada\n(Spain)\n\nAbstract\n\nThe great importance international rankings have in the research policy arena calls for\ncaution as they present many flaws and shortcomings. One of them has to do with the\ninability to accurately represent national university systems as their original purpose is\nonly to rank world-class universities. Another one has to do with the lack of\nrepresentativeness of universities’ disciplinary profiles as they usually provide a unique\ntable. Although some rankings offer a great coverage and others offer league tables by\nfields, no international ranking does both. In order to surpass such limitation from a\nresearch policy viewpoint, this paper analyzes the possibility of using national rankings in\norder to complement international rankings. For this, we describe the Spanish university\nsystem as a study case presenting the I-UGR Rankings for Spanish universities by fields\nand subfields. Then, we compare their results with those obtained by the Shanghai\nRanking, the QS Ranking and the NTU Ranking, as they all have basic common grounds\nwhich allow such comparison. We conclude that it is advisable to use national rankings in\norder to complement international rankings, however we observe that this must be done\nwith certain caution as they differ on the methodology employed as well as on the\nconstruction of the fields.\n\n1550\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3) and Management and Measurement of Bibliometric Data within Scientific\nOrganizations (Topic 9).\n\n1. Introduction\nSince the launch of the first edition of the Shanghai Ranking in 2003, interest has\ngrown on the development of tools for benchmarking and comparing academic\nand research institutions. As a result of the massification of higher education, the\nrace for excellence and a fierce battle for research funding, universities now strive\nfor positioning themselves in these international rankings (Hazelkorn 2011).\nThese tools have gain an undisputable position in the research managers ‘toolkit’\nfor measuring the state of health of higher education institutions and the main\nresource for many universities and countries when taking decisions in a research\npolicy context (Marginson &amp; van der Wende, 2007). The great effect they have, not only in the media and the public but also for research managers, politicians\nand decision makers, - relies on the perception that highly ranked institutions are\nusually more productive, produce higher quality research and teaching and\ncontribute best to society than the rest of universities (Shin &amp; Toutkoushian,\n2011).\nHowever, despite their advantages as easy-to-read tools, they also have many\ninconsistencies and shortcomings that warn against a careless use (Delgado\nLópez-Cózar, 2012). In this sense, we can identify five major issues which must\nbe addressed: 1) methodological and technical errors and difficulties such as the\nrecollection of reliable and standardized data (Toutkoushian &amp; Webber, 2011), 2)\nthe criteria for selecting the indicators are not scientifically supported (Van Raan,\n2005), 3) the multidimensional nature of universities (Orduña-Malea, 2012;\nWaltman et al., 2012) leads to a wide heterogeneity among institutions (Collini\n2011), 4) using a unique table to rank universities neglects their disciplinary focus\n(Visser et al., 2007), and 5) international rankings cannot reflect the state of\nnational higher education systems as they usually cover just the top universities of\neach country (Torres-Salinas et al., 2011a).\nWhile the issue of data reliability still remains a major shortcoming and there is\nno consensus yet over which indicators represent better the nature and quality of\nuniversities, the other issues have been somehow surpassed using approaches\nwhich do not solve completely their dangers but at least, diminishes the flaws. For\ninstance, rankings such as the Leiden Ranking (Waltman et al., 2012) or the\nScimago Institutions Rankings (henceforth SIR) have emerged focusing uniquely\non the research dimension of universities to the neglect of other aspects such as\ninnovation, transference of knowledge or teaching. Others, such as the Shanghai\nRanking, the Times Higher Education World University Rankings (henceforth\nTHE Ranking), the QS Rankings or the National Taiwan University Ranking\n1551\n\n(henceforth NTU Ranking, previously produced by the Higher Education\nEvaluation and Accreditation Council of Taiwan) now publish, along with a\nglobal ranking, rankings by subjects and fields, which offer a better picture of\nuniversities&#x27; performance (García et al., 2012). Also, some rankings such as the\nSIR or the Ranking Web of World Universities cover now not just top-class\nuniversities but the former includes more than 3,000 research institutions and the\nlatter, more than 19,000.\nRankings have not been fully developed and still draw serious shortcomings (van\nRaan, 2005). But their dominance as decisive factors in research policy\n(Hazelkorn, 2011) at national and supranational level puts them in the spotlight.\nOne of the most important threats rankings entail is that they ignore universities&#x27;\ndiversity, which can affect seriously the health of higher education systems and\nlead to dangerous and simplistic conclusions when interpreting and developing\nranking systems (e.g., Moed et al., 2011). These differences affect institutions at\ntwo levels, at their organizational structure, and in the national configuration of\nhigher education systems, affecting their multidisciplinary nature and diversity\n(Orduña, 2012). The phenomenon of university rankings has influenced deeply all\nuniversity systems, even those that were not conceived at first to establish a\ncompetitive framework. Therefore, in order to analyze the success or failure of\ndifferent countries in their research policy, university systems should be assessed\nas a whole, and not considering each university as an individual and autonomous\nunit. Such approach was applied by Docampo (2011) using the Shanghai Ranking\nin order to analyze the university systems of the countries represented.\nDespite its limitations, this study offers a glimpse of the global scenario regarding\nthe research excellence of different countries&#x27; university systems. In Table 1 we\nshow the clusters emerged from the study carried out by Docampo (2011) and the\nnumber of universities by country in different intervals according to the 2012\nedition of the Shanghai Ranking. Therefore we observe a dominance of the\nUnited States and the United Kingdom which alone, represent more than a third\nof the universities included in the ranking (37.6%), followed by Germany and\nCanada as the next with the highest number of universities included. However,\ndespite the numbers, except Japan, which in this new edition includes a university\nin the top20, none of the others have a university positioned within this interval.\nIn this context, the truth is that the high visibility Anglo-Saxon universities have\nin rankings leaves little space for others, blurring the state of other countries\nwhich are working towards a successful university model. In fact, it clearly shows\nthe incapability of the ranking to represent national university systems with\nexhaustiveness.\nThus, these rankings do not offer a complete view of national higher education\nsystems, preventing research managers and decision makers to have an accurate\npicture of the state of each country&#x27;s university system. For this reason, in 2010\n1552\n\nwe developed the Rankings I-UGR of Spanish Universities according to Fields\nand Scientific Disciplines150 (henceforth I-UGR Rankings) available at\nhttp://rankinguniversidades.es. This website offers 49 rankings for Spanish\nuniversities divided in 12 fields and 37 disciplines, according to their international\nresearch performance. Spain is a good example of a misrepresented higher\neducation system. For instance, in the 2012 edition of the Shanghai Ranking only\n11 universities out of 74 met the criteria for inclusion in the global ranking. In\nfact, none made it to the top 100 and only three were included in the 201-300\ninterval. Also, as it occurs with other countries such as Italy (Abramo, Cicero &amp;\nD&#x27;Angelo, 2011), it is a non-competitive higher education system, which means\nthat universities do not act as individual units but within a national framework,\ntherefore decisions should not be taken relying in such a poor sample.\nTable 1. University systems by country considering the results in Docampo (2011)\nand the 2012 Shanghai Ranking edition. Leaders, Fast followers and followers\nNr of\n\nNr of\n\nNr of\n\nNr of\n\nTop20\n\nTop100\n\nTop300\n\nTop500\n\nFollowers\n\nFast followers Leaders\n\nCountries Universities Universities Universities Universities\nUnited States\nUnited Kingdom\nSwitzerland\nAustralia\nCanada\nSweden\nIsrael\nNetherlands\nDenmark\nGermany\nFrance\nBelgium\nNorway\nFinland\n\n17\n2\n-------------------------\n\n53\n9\n4\n5\n4\n3\n3\n2\n2\n4\n3\n1\n1\n1\n\n109\n30\n7\n9\n17\n7\n4\n10\n4\n24\n13\n6\n3\n1\n\n150\n38\n7\n19\n22\n11\n6\n13\n4\n37\n20\n7\n4\n5\n\nThe main goal of the present paper is to justify that national rankings are\nnecessary in order to complement international rankings. For this we will use the\nI-UGR Rankings analyzing:\n1) Levels of agreement with international rankings: are the top Spanish\nuniversities the ones visible in international rankings?\n2) Disciplinary concordance: do the different classifications by fields and\nsubjects allow an analysis by areas?\n\n150\n\nI-UGR stands for Institutions - University of Granada.\n1553\n\nThe paper is structured as follows. First we present the Spanish case analyzing its\ncurrent state and we introduce the I-UGR Rankings, we contextualize its creation\nand we describe the methodology employed for their development. Next, we\naddress the main issue of this paper: we compare the results of the main\ninternational rankings and the I-UGR Rankings for Spanish universities. To do so,\nwe selected the Shanghai Ranking, the QS Ranking and the NTU Ranking.\nFinally, in Section 4 we resume our main findings and their consequences in a\nresearch policy scenario.\n2. Spain as a case study: introduction to the I-UGR Rankings\nThe Spanish university system is formed by 74 universities: 48 public and 26\nprivate. However in the 2012 edition of the Shanghai Ranking only 11 met the\nminimum requirements to be included. It is a country poorly represented in the\nmain international rankings due to the scarce number of universities considered as\nWorld-Class universities. But the impact these rankings have in research policy\nthreatens a good governance and sensible decision making as they do not offer a\ncomplete picture of the university system (Docampo, 2011). In fact, as observed\nin Table 2, only 20 universities (19 public and 1 private universities) are included\nin three of the most important rankings; that is, 27.03% of the whole system. For\nthis reason, other tools are needed in order to complete this fragmented picture of\nthe Spanish higher education scenario.\nTable 2. Spanish universities represented in the 2012 edition of the Shanghai\nRanking, the QS Ranking and the NTU Ranking\nPosition of Spanish\nUniversities in\nShanghai Ranking\n\nBarcelona\nAutónoma de Madrid\nComplutense de Madrid\nValencia\nAutónoma de Barcelona\nPolitécnica de Valencia\nPaís Vasco\nGranada\nPompeu Fabra\nZaragoza\nVigo\n\n1554\n\nPosition of Spanish\nUniversities in\nQS Ranking\n\n201-300 Autónoma de Barcelona\n201-300 Barcelona\n201-300 Autónoma de Madrid\n301-400 Complutense de Madrid\n301-400 Pompeu Fabra\n301-400 Carlos III de Madrid\n301-400 Politécnica de Cataluña\n401-500 Navarra\n401-500 Politécnica de Valencia\n401-500 Politécnica de Madrid\n401-500 Granada\nSalamanca\nSantiago de Compostela\nValencia\nZaragoza\nSevilla\nAlcalá de Henares\nMurcia\n\nPosition of Spanish\nUniversities in\nNTU Ranking\n\n176 Barcelona\n187 Autónoma de Barcelona\n206 Autónoma de Madrid\n226 Valencia\n266 Complutense de Madrid\n343 Santiago de Compostela\n350 Granada\n359 Zaragoza\n401-450 Pompeu Fabra\n401-450 País Vasco\n451-500 Oviedo\n451-500 Politécnica de Valencia\n451-500 Sevilla\n451-500\n501-550\n551-600\n601+\n601+\n\n115\n191\n231\n253\n259\n330\n335\n382\n408\n420\n461\n471\n483\n\nThe first edition of the I-UGR Rankings was launched on 2010. Its development\nwas motivated by the scarce visibility Spanish universities have in international\nrankings, which leads to a fragmented picture of the Spanish university system.\nThough other national rankings had already been developed, these were\nconsidered insufficient due to the limitations they presented which made them\nunsuitable as research policy tools. Among other limitations we address the\nfollowing: lack of continuity over time, exclusion of private institutions, disregard\nof disciplinary focus, use of rudimentary bibliometric indicators, selection of\nunsuitable time periods or election of databases with dubious selection criteria of\nsources (Torres-Salinas et al., 2011a).\nData is retrieved from the Thomson Reuters Web of Science database. In its first\nedition 12 rankings were offered for 12 broad fields. These fields were later\nexpanded with 19 subfields or disciplines in the second edition (Torres-Salinas et\nal., 2011b) and finally, 37 disciplines in the 2012 edition. The fields and\ndisciplines were constructed by aggregating the subject categories to which\nrecords from the Science Citation Index and Social Science Citation Index are\nassigned. Aggregating subject categories is a classical perspective followed in\nmany bibliometric studies when adopting a macro-level approach (e.g., Moed,\n2005; Leydesdorff &amp; Rafols, 2009). For further information on the coverage on\nthe I-UGR Rankings and the development of the fields and subfields the reader is\nreferred to the Methodology section of the rankings&#x27; website available at\nhttp://rankinguniversidades.es. Once the data is compiled into a relational\ndatabase, the indicators defined in Table 3 are computed and normalized in [0, 1],\nand the index for rating each university is calculated. To rank universities we use\nthe IFQ2A Index (Torres-Salinas et al., 2011c). This indicator measures the\nquantitative and qualitative dimensions of the research outcome of a group of\ninstitutions in a given field. It is based on six primary bibliometric indicators,\nthree focused on the quantitative dimension (QNIF) and the other three focused\non the qualitative dimension (QLIF). In Table 3 we summarize the methodology\nemployed for calculating the IFQ2A Index. For a detailed explanation on the\nIFQ2A Index the reader is referred to Torres-Salinas et al. (2011c).\nTable 3. Calculation of the IFQ2A Index and definition of indicators.\n\nQNIF  3 NDOC  NCIT  H\nNDOC\nNCIT\nH\n\nNumber of citable papers\npublished in scientific journals\nNumber of citations received by\nall citable papers\nH-Index as proposed by Hirsch\n(2005), over all the publications\nof the institution\n\nQLIF  3 %1Q  ACIT  TOPCIT\n%1Q\nACIT\nTOPCIT\n\nRatio of papers published in\njournals in the top JCR quartile\nAverage number of citations\nreceived by all citable papers\nRatio of papers belonging to the\ntop 10% most cited papers\ncalculated within all institutions\n\nIFQ 2 A  QNIF  QLIF\n1555\n\nThe selection of the indicators as well as the conceptualization of the index, are\nbased on the following criteria:\n1) The indicators chosen must not be restrictive. That is, they should be\napplied to all institutions. For instance, the Shanghai Ranking uses the\nnumber of Nobel Prizes as an indicator to measure research excellence. In\nthe Spanish case only one university is affected by it (Complutense de\nMadrid).\n2) Rankings must be size-independent. This leads to the use of a\nbidimensional index which takes into account research outcome but also\nexcellence, benefiting equally: small and large institutions.\n3) Rankings must take into account the disciplinary focus of universities. For\nthis, a unique list cannot be provided. Contrarily one most offer rankings by\nfield of specialization in order to provide useful tools for research\nmanagers.\n4) Seniority must not be rewarded. For this fixed time periods must be used.\nAlso, when calculating the H-Index, this must be considering the time\nframe used. In this sense, the I-UGR Rankings offer a five-year window\nand a ten-year window.\n5) Stability must be assured. This means that the fixed time frame must be\nwide enough to offer stable results. A five-year time frame allows results to\nbe consistent and significant.\nIn Figure 1 we show the distribution of universities according to the QNIF and\nQLIF in the field of Medicine and Pharmacology for the 2007-2011 time period.\nThe dashed lines show the average values of each dimension. Universities\npositioned at the top right hand of the figure are those which outstand in both\ndimensions. Those positioned on the bottom right outstand on the quantitative\ndimension but not on the qualitative dimension. At the top left, we observe\nuniversity with small research output but high quality research. Lastly, in the\nbottom left, universities which do not outstand in any dimension are represented.\nAs we can observe, although top universities outstand in both dimensions, many\nuniversities outstand in the qualitative dimension but do not do so in the\nquantitative dimension. Due to the bidimensional nature of the IFQ2A index, these\nsmall institutions are reflected in the rankings.\n\n1556\n\n1,0\n\nBarcelona\nNavarra\nAutónoma de\nMadrid\nAutónoma de\nBarcelona\nValencia\nAVERAGE QLIF\n\n0,6\n\n0,4\n\nAVERAGE QNIF\n\nQUALITATIVE DIMENSION\n\n0,8\n\n0,2\n\n0,0\n0,0\n\n0,2\n\n0,4\n\n0,6\n\n0,8\n\n1,0\n\nQUANTITATIVE DIMENSION\n\nFigure 1. Distribution of universities according to their qualitative and quantitative\ndimensions in the field of Medicine and Pharmacology. 2007-2011.\n\n3. Comparison by fields of the main international rankings and the I-UGR\nfor Spanish universities\nIn this section we analyze the state of the Spanish university system using\ninternational and national rankings. For this, we first establish in Section 3.1 a set\nof criteria for the selection of the rankings we will use in order to set some basic\ncommon grounds which will allow a fair comparison between them. Then, in\nSection 3.2 we match rankings by fields between the international and national\nrankings and finally, we analyze the level of agreement between them. For this we\nuse two indicators. On the one hand, we calculate the Spearman&#x27;s rank correlation\ncoefficient or Spearman&#x27;s rho, which will indicate to what extent are the different\nrankings coherent between them. On the other hand, we show the level of\nagreement between rankings, which indicates if universities included in an\ninternational ranking coincide with those which occupy the top positions of the\nnational ranking.\n3.1 Selection of rankings\nThe aim is to use international and national rankings as complementary tools to\noffer on the one hand, a global perspective of the position of Spanish universities\nand, on the other hand, a complete picture of the Spanish university system. For\n\n1557\n\nthis, we first need to establish a set of criteria for choosing the most relevant\nrankings for our purposes. These are the following:\n1) As we are analyzing the research dimension of universities, rankings must\nbe based on the research performance of universities, at least partially.\n2) Data retrieved for the construction of the rankings must come from a\nreliable bibliometric database or information resource, at least partially.\n3) They must offer rankings by fields, as we have considered that only this\nway we can provide an accurate image of universities’ research\nperformance.\nBased on these criteria we selected the I-UGR Rankings as national rankings and\nthe following international rankings. The methodology of each ranking is\navailable at its website, due to space limitations it has not been included in this\npaper:\n1) Shanghai Ranking (http://www.shanghairanking.com/). It was not only the\nfirst international ranking launched (Liu &amp; Cheng, 2005) but it is used as\nyardstick to measure the research excellence of universities worldwide\n(Docampo, 2011). It is based on six indicators, two of them (40% of the\ntotal rating) are based on data retrieved from the Web of Science (for more\ninformation on this ranking the reader is referred to Liu &amp; Cheng, 2005;\nvan Raan, 2005; Docampo 2011; Aguillo et al., 2010). Since 2007 it offers\nfive rankings by field and since 2009, five ranking by subject.\n2) QS Ranking (http://www.topuniversities.com/). The first edition of this\nranking was launched in 2004. Until 2009 it was produced in partnership\nwith the Times Higher Education, however, since then each company\ndevelops its own ranking (for more information on this ranking the reader\nis referred to Aguillo et al., 2010; Usher &amp; Savino, 2007). 20% of the total\nrating assigned to each university is based on data retrieved from the\ndatabase Scopus. It offers along with the global league table, 29 rankings\nby discipline classified into five major fields.\n3) NTU Ranking (http://nturanking.lis.ntu.edu.tw). This ranking was first\nlaunched in 2007. It aims at measuring solely the quality of universities&#x27;\nresearch. It is based on 8 indicators all of them supported by bibliometric\ndata from the Web of Science and the Thomson Reuters Essential Science\nIndicators (for more information on this ranking the reader is referred to\ne.g., Aguillo et al., 2010). Along with the global table league, it offers\nrankings by field and subject in a similar structure to that of the Shanghai\nRanking. In this case, it offers 6 rankings by field and 14 rankings by\nsubject.\n1558\n\n3.2 Concordance between international and national rankings and levels of\nagreement\nIn order to establish fair comparisons and provide a global picture of the state of\nSpanish universities using national and international rankings, we first need to\nensure that the classification of fields of national and international rankings is\nsomehow similar and therefore, compatible. For this, we would need to analyze\nthe way these fields are constructed for the four rankings used in this study and\ndetermine to which grade the methodology employed by each of them allows fair\ncomparisons. As mentioned before, the I-UGR Rankings construct fields and\ndisciplines by aggregating the Thomson Reuters subject categories. The NTU\nRanking uses the same approach, and the construction of fields and subjects is\ndeclared at their website (http://nturanking.lis.ntu.edu.tw). However, this does not\noccur for the other two rankings, which do not declare the methodology employed\nfor establishing such fields. This lack of transparency is a shortcoming that must\nbe taken into account when using these rankings for research policy.\nTable 4. Matching of fields and disciplines between the Shanghai Ranking and the IUGR Rankings\nSHANGHAI RANKING I-UGR RANKINGS\nNatural Sciences &amp;\nMathematics\nEngineering/Technology &amp;\nComputer Sciences\nLife &amp; Agricultural Sciences\n\nClinical Medicine &amp; Pharmacy\nSocial Science\nMathematics\nPhysics\nChemistry\nComputer Science\nEconomics &amp; Business\n\nRHO\n\nA\n\n*\n\n1/3; 2/3\n\n1,00; 1,00\n\n1/2; 2/2\n\n1,00\n*\n\n2/2\n0/2; 0/2; 2/2\n\n-0,23\n0,72\n0,26\n0,41\n*\n\n4/8\n5/5\n8/10\n3/6\n2/2\n\nMathematics / Physics / Chemistry -0,50; -0,50; 0,50 0/3; 3/3; 2/3\nEngineering / Information &amp;\nCommunication Technology\nAgricultural Sciences / Biological\nSciences\nMedicine &amp; Pharmacy\nOther Social Sciences /\nPsychology &amp; Education /\nEconomics, Finance &amp; Business\nMathematics\nPhysics\nChemistry\nComputer Science\nEconomics, Finance &amp; Business\n\nNote: Rho indicates the Spearman&#x27;s coefficient. A indicates the level of agreement between rankings, that is, the\nnumber of universities present in both rankings.\n*Insufficient values to calculate the indicator\n\nWe analyzed the fields and subjects of the selected international rankings and we\nestablished the homologous field or discipline according to the I-UGR Rankings.\nIn Tables 4-6 we show the matching of fields per ranking. In general terms, we\nobserve that it is possible to match most of the fields between the three\ninternational rankings selected and the I-UGR Rankings, although some\nexceptions are noted. The areas misrepresented in the I-UGR Rankings were\nMechanical Engineering (QS Ranking and NTU Ranking), Law (QS Ranking)\nand all of the areas considered of the Arts &amp; Humanities fields by the QS\n1559\n\nRanking. This is due to the way the I-UGR Rankings are constructed, as they rely\non the JCR and these lack journal rankings for these fields. Also, we observe that\nsome fields of the international rankings (i.e., the Shanghai Ranking and the field\nof Social Science) include more than one of the tables by field of the I-UGR\nRankings. Finally, the classification of fields and subfields does not always match\nbetween rankings. Although this issue has no relevance for the purposes of this\nanalysis, we must point out that subjects considered as major areas in one ranking\nare considered in the other as subfields or disciplines.\nTable 5. Matching of fields and disciplines between the QS Ranking and the I-UGR\nRankings\n\nSocial Sciences &amp;\nManagement\n\nLife\nEngineering &amp;\nNatural Sciences Sciences &amp;\nArts &amp; Humanities\nTechnology\nMedicine\n\nQS RANKING\n\nPhilosophy\nModern Languages\nGeography\nHistory\nLinguistics\nEnglish Language &amp; Literature\nComputer Science &amp; Information Systems\nChemical Engineering\nCivil Engineering\nElectrical Engineering\nMechanical Engineering\nMedicine\nBiological Sciences\nPsychology\nPharmacy &amp; Pharmacology\nPhysics &amp; Astronomy\nMathematics\nEnvironmental Sciences\nEarth &amp; Marine Sciences\nChemistry\nMaterials Science\nStatistics &amp; Operational Research\nSociology\nPolitics &amp; International Studies\nLaw\nEconomics &amp; Econometrics\nAccount &amp; Finance\nCommunication &amp; Media\nEducation\n\nRH\nO\n\nA\n\nGeography &amp; City Planning\n\n0,68\n\n2/6\n\nComputer Science\nChemical Engineering\nCivil Engineering\nElectric &amp; Electronic Engineering\n\n-0,87\n0,84\n-0,5\n-0,43\n\n1/3\n4/7\n1/3\n4/7\n\nMedicine\nBiological Sciences\nPsychology\nPharmacy &amp; Toxicology\nPhysics\nMathematics\nEarth &amp; Environmental Sciences\nEarth &amp; Environmental Sciences\nChemistry\nMaterials Science\nStatistics\nSociology\nPolitical Science\n\n0,50\n0,87\n0,26\n0,74\n0,67\n0,21\n0,87\n1,00\n0,80\n0,83\n-0,62\n-1,00\n**\n\n3/3\n3/3\n6/7\n3/5\n4/5\n2/4\n2/3\n1/2\n3/4\n3/6\n3/6\n1/2\n0/1\n\nEconomics\nBusiness\nCommunication\nEducation\n\n0,50\n0,87\n0,00\n0,29\n\n4/6\n2/3\n0/3\n1/5\n\nI-UGR RANKINGS\n\nNote: Rho indicates the Spearman&#x27;s coefficient. A indicates the level of agreement, that is, the number of\nuniversities present in both rankings.\n*Insufficient values to calculate the indicator\n\nThe three selected rankings included a total of 30 Spanish universities dispersed\nin 40 different fields and subfields. In Tables 4-6 we show the levels of agreement\nbetween international and national rankings according to the assignment of areas.\n1560\n\nFor each area we calculate the Spearman coefficient to analyze the consistency\nbetween both rankings and the number of universities included in international\nrankings which take up the top positions of the national ranking. That is, if 6\nSpanish universities are included in an international ranking but only two occupy\npositions between 1 and 6, the coincidence will be 2/6.\nTable 6. Matching of fields and disciplines between the NTU Ranking and the I-UGR\nRankings\nNTU RANKING I-UGR RANKINGS\nAgriculture\nClinical Medicine\nEngineering\nLife Sciences\nNatural Sciences\nSocial Sciences\nAgricultural Sciences\nEnvironment/Ecology\nPlant &amp; Animal Science\nComputer Science\nChemical Engineering\nCivil Engineering\nElectrical Engineering\nMechanical Engineering\nMaterials Science\nPharmacology &amp; Toxicology\nChemistry\nGeosciences\nMathematics\nPhysics\n\nRHO\n\nA\n\n1,00\n0,6\n0,84\n0,89\n0,88\n0,89\n\n4/5\n5/5\n14/15\n5/6\n11/12\n6/7\n\nAgriculture\n0,34\n10/13\nMedicine\n1,00\n2/3\nEngineering\n0,19\n9/11\nBiological Sciences\n0,77\n6/6\nMathematics / Physics /\n0,14; 0,94; 0,75 7/10; 8/10; 9/10\nChemistry &amp; Chemical\nEngineering\nOther Social Sciences /\n0,36; -0,69; 0,95\n3/4; 3/4; 2/4\nPsychology &amp; Education /\nEconomics...\nAgricultural Sciences\n0,38\n17/21\nEarth &amp; Environmental Sciences\n0,53\n6/9\nBiological Sciences\n0,55\n6/10\nComputer Science\n0,754\n8/13\nChemical Engineering\n0,55\n8/11\nCivil Engineering\n0,47\n8/12\nElectrical &amp; Electronic\n0,58\n8/11\nEngineering\nMaterials Science\nPharmacy &amp; Toxicology\nChemistry\nGeosciences\nMathematics\nPhysics\n\nNote: Rho indicates the Spearman&#x27;s coefficient. A indicates the level of agreement. *Insufficient values to\ncalculate the indicator\n\nThe Shanghai Ranking is the less consistent with the I-UGR Rankings as only two\nfields have significant correlations (Life &amp; Agricultural Sciences and Physics),\nwhile the NTU Ranking shows high correlations in 11 out of 20 fields (Table 6)\nand the QS Ranking correlates in 7 out of 21( Table 5). The three fields with the\nhighest correlations between the NTU Ranking and the I-UGR Rankings are\nClinical Medicine (1,00), Materials Sciences (1,00) and Natural Sciences (0,94\nwith Physics). In the case of the QS Ranking, these three fields are Earth &amp;\nMarine Sciences (1,00) and, Biological Sciences, Environmental Sciences and\nAccount&amp; Finance, all of them with a value of 0,87. The fields with high\ncorrelation belong in most cases to the fields of Biomedicine, Life Sciences and\n1561\n\nExact Sciences, and the ones with least correlation belong to the Social Sciences.\nOnly one exception is noted in the field of Social Science for the NTU Ranking,\nwhich has a high correlation with the field of Economics of the I-UGR Rankings.\n4. Conclusions\nIn this paper we explore the possibility of using national rankings to complement\ninternational rankings, as the latter usually offer a poor representation of national\nuniversity systems. We insist on the importance of rankings by fields (García et\nal., 2012) as these do not neglect universities&#x27; disciplinary focus and offer a\ncomplete picture of universities&#x27; research performance. For this we use Spain as a\nstudy case and we introduce the I-UGR Rankings for Spanish universities. This\nranking uses the IFQ2A Index, an indicator which measures the qualitative as well\nas the quantitative dimension of research (Torres-Salinas, 2011c). Then, we select\nthree international rankings (Shanghai Ranking, QS Ranking and NTU Ranking)\naccording to a given set of criteria; we analyze the concordance between the fields\nthese rankings offer and the ones given by the I-UGR Rankings in order to\nestablish equivalences between them. Finally, we calculate the Spearman&#x27;s\ncoefficient and we analyze the levels of agreement between the universities\nincluded in the international rankings and the top positions of the national\nrankings. From this analysis we conclude that national rankings can complement\ninternational rankings in order to provide a complete picture of university systems\ndespite the methodological differences aroused from the comparisons by fields.\nAlthough there are differences between the methodologies employed by the\nvarious rankings, it is possible to use both and combine them in a research policy\ncontext. The coherence between them is especially significant for the fields of\nBiomedicine, Life Sciences and Exact Sciences. This does not occur in the Social\nSciences where the only exception noted is Economics. In general terms, the NTU\nRanking is the one which seems to be more consistent with the I-UGR Rankings.\nThis is not surprising as it is the only one which measures solely the research\ndimension and fully based on the Web of Science, as it occurs with the I-UGR\nRankings. Also, the confection of the fields and subfields is similar as both\nrankings aggregate subject categories to construct the fields, while in the other\ntwo cases this is not explained. Another issue which affects the correlation\nbetween rankings has to do with the way results are presented in the Shanghai\nRanking and the QS Ranking, as they only show the intervals in which each\nuniversity is positioned after they surpass certain threshold. Although the QS\nRanking provides the rating of each university, allowing the user to rank\nuniversities, this those not occur with the Shanghai Ranking. Having said this and\ndespite of the shortcomings mentioned, we observe coherent results between\nrankings leading us to assure that it is possible to use national rankings as\ncomplement to international rankings in order to offer a complete picture of\nnational university systems in a research policy context.\n\n1562\n\nAcknowledgments\nNicolás Robinson-García and Jose G. Moreno-Torres are currently supported by a\nFPU grant from the Ministerio de Educación y Ciencia of the Spanish\nGovernment.\nReferences\nAguillo, I., Bar-Ilan, J., Levene, M. &amp; Ortega, J.L. (2010). Comparing University\nRankings. Scientometrics, 85(1), 243-256.\nAbramo, G., Cicero, T. &amp; D&#x27;Angelo, C.A. (2011). The Dangers of Performance based Research Funding in Non-competitive Higher Education Systems.\nScientometrics, 87(3), 641-654.\nAghion, P., Dewatripoint, M., Hoxby, C., Mas-Colell, A. &amp; Sapir, A. (2010). The\ngovernance and performance of universities: Evidence from Europe and the\nUS. Economic Policy, 25(61), 7-59.\nCollini, S. (2011). What are universities for? London, UK: Penguin Books.\nDelgado López-Cózar, E. (2012). Cómo se cocinan los rankings universitarios.\nDendra Médica. Revista de Humanidades, 11(1), 43-58.\nDill, D.D. &amp; Soo, M. (2005). Academic quality, league tables and public policy: a\ncross-national analysis of university ranking systems. Higher Education,\n49(4),494-533.\nDobbins, M., Knill, C. &amp; Vögtle, E.M. (2011). An Analytical Framework for the\ncross-country Comparison of Higher Education Governance. Higher\nEducation, 62(5), 665-683.\nDocampo, D. (2011). On the use of the Shanghai Ranking to assess the research\nperformance of university systems. Scientometrics, 86(1), 77-92.\nGarcía, J.A., Rodríguez-Sánchez, R., Fdez-Valdivia, J., Robinson-García, N. &amp;\nTorres-Salinas, D. (2012). Mapping Institutions According to their Journal\nPublication Profile: Spanish Universities as a Case Study. Journal of the\nAmerican Society for Information Science and Technology, 63(11), 2328-2340.\nHazelkorn, E. (2011). Rankings and the Reshaping of Higher Education. The\nBattle for World-Class Excellence. Houndmills, UK: Palgrave MacMillan.\nHirsch, J.E. (2005). An index to quantify an individual’s scientific research\noutput. Proceedings of the National Academy of Sciences USA, 102(46),\n16569–16572.\nLabaree, D.F. Understanding the Rise of American Higher Education: How\nComplexity Breeds Autonomy. http://www.stanford.edu/~dlabaree/selectedpapers.html.\nLeydesdorff, L. &amp; Rafols, I. (2009). A global map of science based on the ISI\nsubject categories. Journal of the Americna Society for Information Science\nand Technology, 63(11), 2239-2253.\nLiu, N.C. &amp; Cheng, Y. (2005).The Academic Ranking of World Universities.\nHigher Education in Europe, 30(2), 127-136.\n\n1563\n\nMarginson, S. &amp; van der Wende, M. (2007). To Rank or to be Ranked: The\nImpact of Global Rankings in Higher Education. Journal of Studies in\nInternational Education, 11(3-4), 306-329.\nMoed, H.F. (2005). Citation Analysis in Research Evaluation. Dordrecht:\nSpringer.\nMoed, H.F., Moya-Anegón, F., López-Illescas, C. &amp; Visser, M. (2011). Is\nconcentration of university research associated with better research\nperformance? Journal of Informetrics, 5(4), 649-658.\nOrduña-Malea, E. (2012). Propuesta de un modelo de análisis redinformétrico\nmultinivel para el estudio sistémico de las universidades [Doctoral Thesis].\nValencia, Spain: Universidad Politécnica de Valencia.\nThe Research Universities Consortium (2012). The Current Health and Future\nWell-being of the American Research University.\nhttp://www.researchuniversitiesfutures.org/RIM_Report_Research%20Future&#x27;s\n%20Consortium%20.pdf\nShin, J. C. &amp; Toutkoushian, R.K. (2011). The Past, Present, and Future of\nUniversity Rankings. In: Shin, J.C., Toutkoushian, R.K. &amp; Teichler, U. (eds.).\nUniversity Rankings. Theoretical Basis, Methodology and Impacts on Global\nHigher Education (pp. 1-18). Dordrecht, Netherlands: Springer.\nTorres-Salinas, D., Delgado López-Cózar, E., Moreno-Torres, J.G. &amp; Herrera, F.\n(2011a). Rankings ISI de las Universidades Españolas según Campos\nCientíficos: Descripción y Resultados. El Profesional de la Información,\n20(1), 111-118.\nTorres-Salinas, D., Moreno-Torres, J.G., Robinson-García, N., Delgado LópezCózar, E. &amp; Herrera, F. (2011b). Rankings ISI de las Universidades Españolas\nsegún Campos y Disciplinas Científicas (2a ed. 2011). El Profesional de la\nInformación, 20(6), 701-709.\nTorres-Salinas, D., Moreno-Torres, J.G., Delgado López-Cózar, E. &amp; Herrera, F.\n(2011c). A methodology for Institution-Field ranking based on a\nbidimensional analysis: the IFQ2A index. Scientometrics, 88(3), 771-786.\nToutkoushian, R.K. &amp; Webber, K. (2011). Measuring the Research Performance\nof Postsecondary Institutions. In: Shin, J.C., Toutkoushian, R.K. &amp; Teichler,\nU. (eds.). University Rankings. Theoretical Basis, Methodology and Impacts\non Global Higher Education (pp. 123-144). Dordrecht, Netherlands: Springer.\nUsher, A. &amp; Savino, M. (2007). A Global Survey of University Rankings and\nLeague Tables. Higher Education in Europe, 32(1), 5-15.\nVan Raan, A.F.J. (2005). Fatal Attraction: Conceptual and Methodological\nProblems in the Ranking of Universities in the Global Scientific\nCommunication System. Scientometrics, 62(1), 133-143.\nVisser, M.S., Calero-Medina, C.M. &amp; Moed, H.F. (2007). Beyond Rankings: The\nRole of Large Research Universities in the Global Scientific Communication\nSystem. In: Torres-Salinas, D. &amp; Moed, H.F. Proceedings of 11th Conference\nof the International Society for Scientometrics and Informetrics (pp. 761-765).\nMadrid, Spain: CINDOC-CSIC.\n1564\n\nWaltman, L., Calero-Medina, C., Kosten, J., Noyons, E.C.M., Tijssen, R.J., van\nEck, N.J., et al. (2012). The Leiden Ranking 2011/2012: Data Collection,\nIndicators and Interpretation. In: Archambault, É., Gingras, Y. &amp; Larivière, V.\nProceedings of 17th International Conference on Science and Technology\nIndicators (791-802). Montreal, Canada: Science-Metrix and OST.\n\n1565\n\nSCIENCE DYNAMICS: NORMALIZED GROWTH\nCURVES, SHARPE RATIOS, AND SCALING\nEXPONENTS\nHaiko Lietz1 and Mathias Riechert2\n1\n\nhaiko.lietz@gesis.org\niFQ – Institute for Research Information and Quality Assurance, Schützenstraße 6a,\n10177 Berlin (Germany);\nGESIS – Leibnitz Institute for the Social Sciences, Unter Sachsenhausen 6-8, D-50667\nKöln (Germany)\n2\n\nriechert@forschungsinfo.de\niFQ – Institute for Research Information and Quality Assurance, Schützenstraße 6a,\n10177 Berlin (Germany)\n\nAbstract\n\nMany indicators exist that measure different aspects of scientific productivity, impact, and\ncollaboration. Longitudinal analyses are commonly used to identify developments and\nchanges. However, indicators to quantify dynamics are largely missing and scholarly\narticles documenting the use of a dynamics indicator are rare. This paper aims at\ncontributing to their development and application. Using Scopus, time series of four\noutput indicators in 13 years are observed for 27 disciplines. One qualitative way and two\nquantitative ways to study dynamics are discussed. The qualitative way is to visualize the\ndata. The first quantitative method to measure growth, the Sharpe Ratio, is imported from\nportfolio management. The second method is the application of scaling analysis, a way to\ndescribe how two properties of a system, like authors and publications, relate to each other\nas the system undergoes size changes in time. We show that the database is a source of\nartificial growth, confirming earlier results. Visualizations are an important step to get to\nknow the data, identify potential problems, and generally help interpret quantitative\nresults. The two dynamics indicators reveal different perspectives of growth, but results\nare correlated with a Pearson coefficient of at least 0.67.\n\nConference Topic\n\nScientometrics Indicators - Criticism and new developments (Topic 1), Old and New Data\nSources for Scientometric Studies: Coverage, Accuracy and Reliability (Topic 2), and\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3).\n\nIntroduction\nAt the same time that the science system experiences growth, globalization, and\nan increase of interdisciplinary, team, and project work, scientometrics are\nbecoming effectively available. To keep track of developments and analyze its\nactions, science policy is increasingly interested in scientometric analyses. Many\n1566\n\nindicators have been developed and continue to be developed that quantify\ndifferent aspects of scientific productivity, impact, and collaboration.\nLongitudinal analyses are commonly used to identify developments and changes.\nHowever, indicators to measure dynamics are largely missing. Scholarly articles\ndocumenting the use of a dynamics indicator are rare (Grupp et al., 2009). This\npaper aims at contributing to their development and application.\nUsing Scopus, time series of four output indicators in 13 years are observed for 27\ndisciplines. One qualitative way and two quantitative ways to study dynamics are\ndiscussed. The qualitative way is to visualize the data. Normalizations can be\napplied to enable comparisons. The first method to quantify growth, the Sharpe\nRatio, is imported from portfolio management (Sharpe, 1994). There, it is\nimportant to monitor stocks in a portfolio against changes in the whole stock\nmarket––a task not so different from science evaluation where database growth\nmust be taken into account. The second method is the application of scaling\nanalysis (Katz, 2000; Lane et al., 2009). The goal is to describe how two\nproperties of a system, like authors and publications, relate to each other as the\nsystem undergoes size changes in time. We proceed like Bettencourt et al. who\napplied scaling analysis to measure the dynamics of publications per author\n(2008).\nWe start by describing the data and indicators in use. Visualizations are presented\nas an important step to get to know the data, identify potential problems, and\ngenerally help interpret quantitative results. Characteristics, applications, and\nlimitations of the quantitative methods are discussed.\nData and Indicators\nWe are studying 27 scientific disciplines using the Scopus custom database of the\nGerman Competence Centre for Bibliometrics. Disciplines are delineated through\nthe All Science Journal Classification (ASJC) provided by Scopus. The analysis is\nrestricted to the document type “article” and the source type “journal.”\nPublication years 1996 to 2008 are subject to analysis, resulting in 13 years. To\navoid the problem of author deflation through homonyms (Strotmann and Zhao,\n2012), the author identifier delivered by Scopus was used. While this identifier is\nnot sufficiently accurate if authors are the objects of study we deem it accurate\nenough for macro studies such as ours. We are using disciplines as objects but the\ninstruments to be discussed are applicable to other objects such as fields,\ncountries, or organizations as well.\nIndicators are the\n- number of publications ( ),\n- cumulative number of authors (\n),\n- authors per publication (\n), and\n- publications per author (\n).\nand\nare two measures for the size of a discipline. The assumption behind\ncounting authors cumulatively is that scientists stay in the discipline once they\nhave entered it.\nare calculated on the basis of items, i.e., the number of\n1567\n\ndistinct author identifiers per paper are averaged.\nis the indicator for\nproductivity. It is the quotient of distinct author identifiers and distinct\npublications.151\nVisualizing Growth\nThe first possibility to study growth is to visualize the data. Figure 1 depicts\nand\ngrowth curves of seven selected disciplines and total database content.\nOn the level of disciplines, smooth exponential or sigmoid growth is expected\n(Bettencourt et al., 2008). Instead, in terms of , we are seeing jumps and dents.\nThe Arts and Humanities jump from 4,000-5,000 publications in 1996-2001 to\n7,000-8,000 in 2002-2006. This is because in 2009 the database producer\nincluded many new journals that went back as far as 2002.152 Neuroscience is the\nonly discipline with a publication increase in every year. Almost all disciplines\nshow a decrease of\naround the years 2002-2003. The dent is strongly\npronounced in the Social Sciences and is clearly visible for the total. This can be\nexplained historically, and reflects the different phases in the creation of\nScopus.153\nIn general, this fact will need to be dealt with if Scopus and the selection of\npublications through the ASJC are used to measure dynamics. For the purpose of\nthis paper, this complication is instructive. At this point it is clear that database\ncontent is a biased estimator of scientific growth.\nFor the purpose of comparisons it is desirable to show multiple curves in one\nfigure. In practice it is hardly possible to combine more than ten curves without\nlosing comprehensiveness. In addition, it is problematic to combine curves which\nreside at different scales because the inclusion of curves at a large scale tends to\ndisguise details of curves at small scale. Logarithmic ordinates enable such a\ncombination but also compress the curves and hide details.\nFigure 2 (top row) combines growth curves for seven disciplines. Details are\nalready much less visible than in the individual curves of Figure 1. Normalizing\ngrowth reintroduces detail (bottom row). To do so, all year values are divided by\nthe initial (1996) value. It is now more easily visible that, in terms of the number\nof publications, Computer Science, Energy, also the Social Sciences, and\nEngineering grow stronger in the more recent years than the total which is shown\nas a solid black line.\nTo look at productivity (\n) we must first look at collaboration (\n). Teams\nare increasingly important in the production of knowledge, most strongly in\nScience &amp; Engineering, but also in the Social Sciences and the Arts &amp; Humanities\n(Wuchty et al., 2007). In principle,\nand\ncan grow simultaneously.\nConsider a field with one publication (having authors X and Y) in one year and\n151\n\nThe quotient of maximum author position and distinct publications gives similar results.\nPrivate message from the database producer Elsevier, 14 January 2013.\n153\nDocument and source types grow differently in Scopus. Elsevier recommends including reviews\nand conference proceedings articles to arrive at persistent positive growth at the discipline level.\nPrivate message from Elsevier, 17 January 2013.\n152\n\n1568\n\nFigure 1. Growth of the number of publications (continuous lines) and the\ncumulative number of authors (dotted lines) for seven disciplines and total database\ncontent in separate figures.\n\n1569\n\ntwo publications (the first having authors X and Y, the second having authors X,\nY, and Z) in the following year.\nincreases from 2 to 2.5,\nincreases from\n1/2 to 2/3. Instead, Figure 2 shows that\nand\nare inversely proportional\nwhen all 13 years are looked at. The increasing dominance of teams prevents a\ngrowth of productivity.\n\nFigure 2. Growth and normalized growth curves of the number of publications,\nnumber of authors per publication, and publications per author for seven disciplines\nand total database content.\nTable 1. Sharpe Ratios of the four indicators and scaling exponents of productivity\nfor the whole timespan and the last five years (ranks in brackets).\nDiscipline\nGeneral\nAgricultural and\nBiological\nSciences\nArts and\nHumanities\nBiochemistry,\nGenetics and\nMolecular\n1570\n\nS(P)\n13yrs 5yrs\n-0.10\n(20)\n\n-0.48\n(22)\n\n0.33\n(11)\n\nS(Acum)\n13yrs 5yrs\n0.84\n(18)\n\n2.58\n(19)\n\n1.58\n(9)\n\n0.96\n(12)\n\n0.22\n(15)\n\n-0.62\n(24)\n\n-0.20\n(22)\n\n-0.40\n(21)\n\nS(APP)\n13yrs 5yrs\n0.25\n(13)\n\n0.20\n(20)\n\n4.08\n(9)\n\n1.51\n(1)\n\n1.03\n(11)\n\n3.23\n(12)\n\n0.92\n(14)\n\n9.46\n(3)\n\nS(PPA)\n13yrs 5yrs\n\n13yrs\n0.43\n(27)\n\nβ\n\n5yrs\n\n-0.37\n(14)\n\n-0.35\n(10)\n\n0.52\n(26)\n\n4.16\n(1)\n\n-0.76\n(22)\n\n-0.73\n(15)\n\n0.61\n(18)\n\n0.78\n(17)\n\n-0.16\n(22)\n\n0.71\n(11)\n\n0.10\n(3)\n\n-1.26\n(20)\n\n0.91\n(1)\n\n0.48\n(27)\n\n0.69\n(7)\n\n0.43\n(16)\n\n-1.63\n(27)\n\n-1.53\n(23)\n\n0.55\n(22)\n\n0.69\n(19)\n\nBiology\nBusiness,\nManagement and\nAccounting\nChemical\nEngineering\nChemistry\nComputer\nScience\nDecision\nSciences\nDentistry\nEarth and\nPlanetary\nSciences\nEconomics,\nEconometrics\nand Finance\nEnergy\nEngineering\nEnvironmental\nScience\nHealth\nProfessions\nImmunology and\nMicrobiology\nMaterials\nScience\nMathematics\nMedicine\nNeuroscience\nNursing\nPharmacology,\nToxicology and\nPharmaceutics\nPhysics and\nAstronomy\nPsychology\nSocial Sciences\nVeterinary\nTotal\n\n0.36\n(9)\n\n1.41\n(12)\n\n0.88\n(16)\n\n11.48\n(2)\n\n-0.28\n(24)\n\n-2.18\n(27)\n\n0.06\n(4)\n\n0.95\n(1)\n\n0.87\n(2)\n\n1.09\n(1)\n\n0.64\n(2)\n0.21\n(16)\n0.96\n(1)\n0.34\n(10)\n0.32\n(12)\n\n0.98\n(14)\n0.31\n(18)\n4.25\n(2)\n2.94\n(4)\n0.47\n(16)\n\n1.28\n(1)\n1.24\n(3)\n1.04\n(10)\n0.75\n(22)\n1.27\n(2)\n\n2.58\n(18)\n1.34\n(25)\n7.42\n(5)\n1.83\n(22)\n5.12\n(7)\n\n0.42\n(11)\n-0.16\n(21)\n0.54\n(10)\n-0.46\n(27)\n0.72\n(6)\n\n1.46\n(4)\n0.96\n(9)\n0.97\n(8)\n-0.05\n(23)\n0.59\n(13)\n\n-0.40\n(17)\n-0.07\n(9)\n-0.26\n(11)\n0.02\n(6)\n-0.76\n(23)\n\n-0.90\n(17)\n-0.44\n(12)\n-0.22\n(7)\n0.02\n(4)\n-1.06\n(19)\n\n0.77\n(8)\n0.71\n(14)\n0.81\n(7)\n0.82\n(6)\n0.57\n(21)\n\n0.81\n(14)\n0.79\n(16)\n0.91\n(6)\n0.95\n(3)\n0.76\n(18)\n\n-0.15\n(21)\n\n-0.76\n(27)\n\n0.38\n(26)\n\n0.41\n(27)\n\n1.14\n(2)\n\n1.13\n(5)\n\n-0.38\n(15)\n\n-0.51\n(13)\n\n0.63\n(17)\n\n0.69\n(21)\n\n0.45\n(7)\n\n1.89\n(7)\n\n0.75\n(21)\n\n2.36\n(20)\n\n-0.40\n(25)\n\n0.32\n(18)\n\n-0.11\n(10)\n\n-0.25\n(8)\n\n0.76\n(9)\n\n0.89\n(9)\n\n0.62\n(3)\n0.50\n(4)\n0.10\n(17)\n-0.27\n(25)\n-0.30\n(26)\n0.46\n(6)\n0.42\n(8)\n0.30\n(14)\n-0.22\n(24)\n0.49\n(5)\n\n1.84\n(8)\n1.57\n(10)\n1.46\n(11)\n-0.65\n(25)\n-0.53\n(23)\n1.15\n(13)\n2.73\n(6)\n3.32\n(3)\n-0.71\n(26)\n10.61\n(1)\n\n1.08\n(6)\n0.82\n(19)\n0.70\n(24)\n0.91\n(15)\n0.94\n(13)\n0.70\n(23)\n0.69\n(25)\n1.07\n(7)\n1.07\n(8)\n1.08\n(5)\n\n2.31\n(21)\n2.59\n(17)\n7.46\n(4)\n2.93\n(14)\n3.93\n(10)\n1.53\n(24)\n1.62\n(23)\n3.08\n(13)\n6.05\n(6)\n2.73\n(16)\n\n-0.03\n(19)\n0.06\n(17)\n0.88\n(4)\n-0.41\n(26)\n0.59\n(9)\n-0.06\n(20)\n0.24\n(14)\n0.18\n(15)\n0.60\n(8)\n0.83\n(5)\n\n0.27\n(19)\n0.64\n(12)\n3.84\n(2)\n-1.49\n(26)\n0.54\n(14)\n0.99\n(7)\n0.32\n(17)\n-0.15\n(24)\n0.13\n(22)\n0.52\n(15)\n\n0.03\n(5)\n0.12\n(2)\n-0.62\n(19)\n-0.38\n(16)\n-1.44\n(26)\n0.21\n(1)\n-0.56\n(18)\n-0.36\n(13)\n-1.36\n(25)\n-0.73\n(21)\n\n-0.02\n(5)\n-0.78\n(16)\n-1.27\n(21)\n-1.60\n(24)\n-1.82\n(26)\n-0.15\n(6)\n-1.30\n(22)\n0.18\n(3)\n-2.56\n(27)\n-0.91\n(18)\n\n0.87\n(3)\n0.84\n(5)\n0.72\n(12)\n0.57\n(20)\n0.48\n(25)\n0.85\n(4)\n0.61\n(19)\n0.66\n(16)\n0.51\n(23)\n0.68\n(15)\n\n0.94\n(4)\n0.84\n(12)\n0.84\n(13)\n0.80\n(15)\n0.66\n(25)\n0.90\n(7)\n0.68\n(23)\n0.92\n(5)\n0.69\n(20)\n0.89\n(10)\n\n-0.42\n(27)\n\n-0.17\n(20)\n\n1.06\n(9)\n\n12.98\n(1)\n\n0.25\n(12)\n\n2.50\n(3)\n\n-0.72\n(20)\n\n-0.61\n(14)\n\n0.47\n(26)\n\n0.69\n(22)\n\n-0.07\n(19)\n0.08\n(18)\n0.32\n(13)\n-0.20\n(23)\n\n0.46\n(17)\n0.84\n(15)\n2.77\n(5)\n-0.17\n(19)\n\n-0.71\n(27)\n0.86\n(17)\n0.78\n(20)\n1.11\n(4)\n\n0.49\n(26)\n3.37\n(11)\n2.92\n(15)\n4.73\n(8)\n\n-0.24\n(23)\n0.06\n(18)\n0.17\n(16)\n0.94\n(3)\n\n0.19\n(21)\n-0.40\n(25)\n0.95\n(10)\n1.07\n(6)\n\n-0.03\n(7)\n-0.03\n(8)\n-0.29\n(12)\n-0.83\n(24)\n\n-0.27\n(9)\n0.38\n(2)\n-0.43\n(11)\n-1.63\n(25)\n\n0.75\n(10)\n0.71\n(13)\n0.74\n(11)\n0.48\n(24)\n\n0.85\n(11)\n1.03\n(2)\n0.90\n(8)\n0.67\n(24)\n\n––\n\n––\n\n––\n\n––\n\n––\n\n––\n\n––\n\n––\n\n0.71\n\n0.88\n\nWhile figures of normalized variables obscure dimensions, they are capable of\ndelivering basic growth messages in a qualitative way. When quantifying growth\ntwo things should be kept in mind. First, because database content is itself\n1571\n\ndynamic indicators should correct for that. Second, due to changes in growth it\nmay be necessary to compute growth indicators for different time regimes. In our\ncase, because of the dynamics of the Scopus database itself, we will study\nindicators for all 13 years and just the last five years where dynamics are more\nstable.\nThe Sharpe Ratio\nThe Sharpe Ratio is a metric from financial portfolio management, a measure of\naverage annual growth (Sharpe, 1994). It has been applied in science policy\ncontexts to identify key institutions (Schmoch et al., 2006) and dynamic research\nfields (Grupp et al., 2009). Although in these and other studies the metric is\napplied to raw publication counts, in principle it can be applied to describe the\ndynamics of all indicators. The (historic) Sharpe Ratio of a quantity\nin\ndiscipline is defined as\n( )\n\n̅̅̅̅̅̅̅\n( )\n\n(1)\n\n( )\n\nwith\n( )\n\n(\n\n)\n( )\n\n( )\n\n(\n\n)\n\n( )\n( )\n\n(2)\n\nwhere ̅̅̅̅̅̅̅\n( ) is the average of ( ) and\n( ) is its standard deviation. In words,\nfirst, the annual growth rate of the desired quantity in discipline is calculated for\neach year. Second, to normalize for database growth the annual growth rate of the\ntotal is subtracted, giving the normalized annual growth rate. Third, the\nnormalized annual growth rate is averaged over all years, giving the average\nnormalized growth rate. Fourth, the average normalized growth rate is divided by\nthe standard deviation of the normalized annual growth rates. Since the standard\ndeviation is small when the normalized annual growth rates do not vary much,\nsteady growth is rewarded and erratic growth is punished.\nTable 1 gives the Sharpe Ratios for all 13 years and just the last five years. is\nnot intuitively interpretable. A negative value does not imply negative growth, it\nmeans that a discipline grows less than the total. The indicator confirms the\nimpressions from Figure 2. Computer Science, Energy, and Engineering have the\nstrongest publication growth. Pharmacology, Toxicology and Pharmaceutics has a\nnegative Sharpe Ratio and occupies the last rank position. Because the Arts and\nHumanities hardly grow except for the artificial jump, they take almost last rank\nwhen just the last five years are considered. The top rank for Nursing is because\nthe number of publications more than doubled in the last five years which again is\nan artifact of database production.\n\n1572\n\nRegarding productivity, the three top curves of Figure 2, Engineering (0.12), Arts\nand Humanities (0.10), and Energy (0.03) are among the disciplines with the\nhighest Sharpe Ratios. Pharmacology, Toxicology and Pharmaceutics (-0.72) as\nwell as Neuroscience (-1.36) grow much less than the total, as can be seen in the\nfigure. When just the last five years are considered, the Arts and Humanities fall\n17 rank positions, reflecting that the artifact does not influence the score anymore.\nIt may be surprising that only six scientific disciplines exhibit a growth of\nproductivity. Again, we look at its relation to cooperation, now in a quantitative\nway. Engineering is the only discipline with both cooperation and productivity\ngrowth. The average growth of cooperation in all 27 disciplines over 13 years is\n0.29 while average productivity growth is -0.43. The Pearson correlation\ncoefficient of both quantities is -0.64. This confirms the impression from Figure 2\nthat, overall, the increasing dominance of teams indeed prevents a growth of\nproductivity. And teams do become more important. Cooperation growth is even\nbigger (0.69) when just the last five years are studied. Recent 5 year average\ncooperation growth is 137% bigger than overall 13 year growth. Productivity, on\nthe other hand, does not decrease as drastically. Recent 5 year average\nproductivity growth (-0.71) is just 65% bigger than 13 year growth. In the 5 year\nwindow, correlation of both quantities gets lost (the Pearson coefficient is -0.24).\nThis may indicate that science is entering a phase where productivity grows\ndespite growing cooperation, but confidence in this statement is muddled due to\nthe database artifact we have found.\nScaling Analysis\nAnother way to quantify dynamics is scaling analysis, a method to study the\nbehaviour of a complex system across spatial or temporal scales (Lane et al.,\n2009). Scaling analysis belongs to modeling but can also be used for evaluation\npurposes. A system is said to scale when two properties\nand\nare related\nthrough a power law\n. The scaling exponent is then a system-specific\ndescriptor of the average relative change in with . If\n, ⁄ increases\nwith\n(increasing returns). On the contrary, if\n, ⁄ decreases in an\neconomy of scale. For\n, ⁄ is constant.\nOriginating in biology, astrophysics, and urban studies, scaling analysis was later\napplied to science and innovation systems and it was demonstrated that different\nscientific disciplines all share the property of scale invariance, making the method\napplicable to systems with different publication behaviors (Katz, 1999, 2000).\nBettencourt et al. (2008) have applied scaling analysis to model science system\ndynamics. If\nis the number of authors\nat time and is the number of\npublications\nat that time,\n(\n) characterizes a research field with\nincreasing (decreasing) individual productivity (\n):\n( )\n\n( )\n\n(3)\n\n1573\n\nFigure 3. Scaling analysis (productivity) of seven disciplines and total database\ncontent (the continuous line is a fit to all data points, the dotted line to just the last 5\nyears).\n\n1574\n\nWe have used standardized major axis analysis, implemented in R, to estimate the\nscaling exponent because the method is scale invariant and we are not interested\nin inference (Warton et al., 2006, 2012).\nResults are given in Figure 3 and Table 1. Each data point in a figure corresponds\nto a year. Grayscales are used to mark years. If both\nand\nincrease\nmonotonously from year to year data points monotonously move from the bottom\nleft to the upper right corner as time passes. This is only the case for\nNeuroscience. But even there different growth regimes are visible as non-parallel\nlines. Continuous lines are fits to all 13 years, dotted lines just to the last five\nyears. The artifact caused by database growth is visible in most disciplines, also\nfor the total database content. In the Social Sciences the second regime starts at a\nscale way below of what had been reached in the first regime. In the Arts and\nHumanities it is now clearly visible that in the last five years growth is much\nsmaller than for the system as a whole.\nExponents for all disciplines are smaller than 1, saying that productivity decreases\nas size increases. Top disciplines are those with largest exponents. Again, the Arts\nand Humanities (0.90), Energy (0.87), and Engineering (0.84) have top scores\nwhile Pharmacology, Toxicology and Pharmaceutics (0.47) and Neuroscience\n(0.51) are at the lower end of productivity. When just considering the last five\nyears, the Arts and Humanities are punished more than if the Sharpe Ratio is\nused. They drop from first to last rank position.\nEven though and are different perspectives on growth, the two indicators are\nquite strongly correlated. Pearson correlation coefficients are 0.77 for the whole\ntimespan and 0.67 for the last five years. This is because is mathematically\nrelated to changes in ⁄ , the annual growth rate, that is based on.\nDiscussion and Conclusion\nStarting from a need for metrics of dynamics in the science system, visual growth\ncurves, the Sharpe Ratio, and scaling exponents were discussed. Curves can\nunveil essential meanings in a qualitative way. Comparison of objects of study is\nmade easier by normalizing curves. In our case, the visualization revealed\ndifferent growth regimes where just one regime was expected, showing that the\ndatabase is a source of artificial growth, confirming earlier results (Larsen and\nIns, 2010; Michels and Schmoch, 2012). Knowing the data is thus imperative and\nactually looking at it should be a first step before growth is quantified.\nTwo metrics, the Sharpe Ratio and scaling exponent , were discussed and\napplied to whole and partial timespans to cope with the presence of different\ngrowth regimes. The Sharpe Ratio is based on the average annual growth rate and\naims to remove artifacts by subtracting overall database growth. On the level of\nthis study, this subtraction may be criticized because overall database content is\ndominated by the hard sciences but is also used to normalize the soft sciences. But\nonce objects in a coherent field are studied, like countries in a discipline, such a\nnormalization immediately makes sense. In addition, the Sharpe Ratio addresses\n\n1575\n\nthe stability of growth by dividing by the standard deviation of the normalized\nannual growth rates.\nIn scaling analysis, visualizations also proved to be important as they made\ndifferent regimes very transparent and stressed the need to fit different functions\nto them (Bettencourt et al., 2008). A spontaneous reaction is to criticize fits to just\nfive data points. Of course, the fewer data points there are, the more each one\ninfluences the result. But this is also true for the average growth rate which is\nfrequently used also for small numbers. Scaling exponents are not normalized for\ndatabase dynamics, but a way to normalize would be to divide by the exponent of\nthe total.\nThe Sharpe Ratio can be applied to all possible time series, not just to publication\ncounts, as common in the literature. If one does not feel comfortable with dividing\nby the standard deviation, this can easily be left out. Scaling analysis is only\napplicable to bivariate data. Besides productivity another natural application is to\nquantify impact dynamics (Katz, 2000).\n\nFigure 4. Growth dynamics of an hypothetical system with\n\n.\n\nScale only corresponds to time if annual growth rates are constantly positive. In\nother words, time does not move backwards when variables decrease. Consider\nthe system depicted in Figure 4. It has the typical dynamics of an emerging, then\npersisting, and finally dying field with\n. If all years are subject to scaling\nanalysis, the exponent will still be 1.2. If scaling analysis is done like it is done\nhere, the only sign that the field is actually shrinking is that the data points\nbecome darker as they move from the upper right corner to the lower left. Most\nobvious applications of scaling analysis may be the identification and\ncharacterization of emerging science (Guo et al., 2011).\nTo conclude, the Sharpe Ratio and scaling exponents are different perspectives on\ngrowth with different areas of applicability. They should be used in combination\nwith growth visualizations which help get a feeling for the data and which can\nreveal intricacies of the system under study. A result of this technical discussion\nthat requires further scrutiny is that the increasing dominance of teams in the\nproduction of knowledge actually prevents a growth of productivity, less so in the\nlast five than in the last 13 years.\n\n1576\n\nAcknowledgments\nThanks to Almuth Lietz (iFQ) for help with the figures.\nReferences\nBettencourt, L.M.A., Kaiser, D.I., Kaur, J., Castillo-Chávez, C. &amp; Wojick, D.E.\n(2008). Population modeling of the emergence and development of scientific\nfields. Scientometrics, 75, 495-518.\nGrupp, H., Hinze, S., Breitschopf, B. (2009). Defining regional research\npriorities: a new approach. Science and Public Policy, 36, 549-559.\nGuo, H., Weingart, S. &amp; Börner, K. (2011). Mixed-indicators model for\nidentifying emerging research areas. Scientometrics, 89, 421-435.\nKatz, J.S. (1999). The self-similar science system. Research Policy, 28, 501-517.\nKatz, J.S. (2000). Scale-independent indicators and research evaluation. Science\nand Public Policy, 27, 23-36.\nLane, D., Pumain, D. &amp; Leeuw, S. van der (Eds.) (2009). Complexity Perspectives\nin Innovation and Social Change. Dordrecht: Springer.\nLarsen, P.O. &amp; Ins, M. von (2010). The rate of growth in scientific publication\nand the decline in coverage provided by Science Citation Index.\nScientometrics, 84, 575-603.\nMichels, C. &amp; Schmoch, U. (2012). The growth of science and database coverage.\nScientometrics, 93, 831-846.\nSchmoch, U., Wang, J. &amp; Stoica, R. (2006). Research and Development in the\nTurkish Landscape of Science: Identification of Key Institutions. Report to the\nFederal Ministry of Education and Research (BMBF), Fraunhofer Institute for\nSystems and Innovation Research.\nSharpe, W.F. (1994). The Sharpe Ratio. The Journal of Portfolio Management,\n21, 49-58.\nStrotmann, A. &amp; Zhao, D. (2012). Author name disambiguation: What difference\ndoes it make in author-based citation analysis? Journal of the American\nSociety for Information Science and Technology, 63, 1820-1833.\nWarton, D.I., Duursma, R.A., Falster, D.S. &amp; Taskinen, S. (2012). smatr 3- an R\npackage for estimation and inference about allometric lines. Methods in\nEcology and Evolution, 3, 257-259.\nWarton, D.I., Wright, I.J., Falster, D.S. &amp; Westoby, M. (2006). Bivariate linefitting methods for allometry. Biological Reviews, 81, 259-291.\nWuchty, S., Jones, B.F. &amp; Uzzi, B. (2007). The increasing dominance of teams in\nproduction of knowledge. Science, 316, 1036-1039.\n\n1577\n\nSCIENTIFIC POLICY IN BRAZIL: EXPLORATORY\nANALYSIS OF ASSESSMENT CRITERIA (RIP)\nElaine Cristina Pinto de Miranda1, Rogério Mugnaini1,2,\n1\n\nelainecpm@hotmail.com\nUniversidade de São Paulo, Escola de Comunicações e Artes, Depto. de Ciência da\nInformação, Av. Prof. Lúcio Martins Rodrigues, 443, CEP 05508-020, São Paulo, SP,\nBrazil\n2\n\nmugnaini@usp.br\nUniversidade de São Paulo, Escola de Artes, Ciências e Humanidades, Av. Arlindo Bettio,\n1000, CEP 03828-000,São Paulo, SP, Brazil\n\nAbstract\n\nBrazilian scientific evaluation process involves nowadays 3,000 postgraduate programs\nand almost 1,000 of ad hoc consultants from educational institutions of all regions of the\ncountry. Each triennial cycle, produces a lot of information, part of it qualitative, derived\nfrom the decisions of the committees of the 46 assessment areas. Our study proposes a\ndocumentary analysis of this documentation, in order to express contextual aspects of\nscientific communication process in each area. We aimed to compare the different\nscientific fields, due to the importance given to publication in scientific journals as well as\nits contrast to books and national journals importance. The results here presented show\ngroups of Assessment Areas at different stages of the scientific communication process.\nWe found that there are areas in which publications occurs primarily in indexed\ninternational journals, otherwise there are areas proposing specific criteria to evaluate the\nquality of national journals. There are also areas that are in the process of establishing\ntheir journals, and others are being forced to change the practice of publishing books and\nstart publishing on journals.\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3)\n\nIntroduction\nSince 1976, the Coordination of Higher Education Personnel Improvement\n(CAPES) is developing a national wide evaluation process of Brazilian\npostgraduate programs, which has been significantly improved between 1996 and\n1997, in order to establish a triennial evaluation cycle since 1998. This is a huge\neffort considering that Brazil presents nowadays around 3,000 postgraduate\nprograms. The evaluation process involves almost 1,000 of ad hoc consultants\nfrom educational institutions of all regions of the country, composing committees\nin 46 assessment areas of the different scientific fields154. Between the different\n154\n\nhttp://www.capes.gov.br/avaliacao/tabela-de-areas-de-conhecimento\n\n1578\n\naspects evaluated, scientific production is the one that most influence and\ndetermine the level of the postgraduate program (Souza &amp; Paula, 2002).\nFollow up evaluations are done annually, and the final one, at the end of each\ntriennial cycle, producing a lot of information published in the Coordination’s\nwebsite: documents, tables and even raw bibliographic data. The information can\nbe found in different levels of aggregation (researcher, postgraduate program,\ninstitution, assessment area and broad scientific area).\nSignificant part of the information gathered by CAPES comes directly from\nLattes Platform155 – the curriculum database maintained by the National Council\nfor Scientific and Technological Development (CNPq). The reliability of this\nprocess is based on policies that guarantee that the researchers will maintain their\ncurriculum up-to-date periodically. It will refer about all information related to the\nscientific production, research projects, academic career, and any information\ninserted in the curriculum. The objective character of this type of information has\nserved a diversity of scientometric analysis that has been widely published in\nimportant specialized information sources (Leite et al., 2011).\nThe other part consists mainly of qualitative information, which composes the\ndocumentation derived from the decisions of the committees (CAPES, 2011), in\norder to define specific criteria to each assessment area. These committees are\ncomposed by the Area Representative at CAPES and ad hoc consultants, who are\nresponsible for setting criteria for qualifying vehicles and their classification for\nsubsequent use as an input to postgraduate program evaluation (Souza &amp; Paula,\n2002). This rich information reflects the consensus among the researchers,\nbringing in itself, the capability of express contextual aspects of scientific\ncommunication process in each area.\nHicks (2004) argues that, although journal articles have its importance, in Social\nSciences and Humanities, books publishing predominates, and due to its\ncharacteristics an ideal evaluation should consider what she calls the four\nliteratures: journals, books, national and non-scholarly literature – being &quot;national\nliterature&quot; the one developed in local context and &quot;non-scholarly literature&quot; the\nknowledge reaching out to application.\nThese concerns are contemplated in CAPES documentation, which requires each\narea decide about setting specific criteria based in: (1) a book classification form,\nand; (2) a national citation index to infer quality of national journals.\nThis study aims to compare the difference between the scientific communication\nprocess in the 46 areas of CAPES national assessment, based in the\ndocumentation derived from the decisions of the committees of each assessment\narea. More specifically it analyses the importance given to publication in\nscientific journals as well as its contrast to books and national journals\nimportance. The next stage of this ongoing project aims to evaluate the whole\nBrazilian Scientific Community, including the scientific indicators derived from\nthe Lattes Platform.\n155\n\nhttp://www.capes.gov.br/avaliacao/coleta-de-dados\n1579\n\nAGRIC\nAN-SCI, FISH\nFOOD S&amp;T\nVET-MED\n\nMethodology\nAn exploratory research was carried out, applying documentary analysis to the\ndocuments proposed by the committees of the 46 assessment areas, classified into\nnine broad subject areas, that are described on Figure 1. These documents are part\nof the Qualis, a set of procedures used by CAPES to realize a more systematic\ntreatment and quality of scientific intellectual output of postgraduate programs\naiming to improve the indicators that support the evaluation of these programs\n(Souza &amp; Paula, 2002).\nAgricultural Sciences\nAGRICULTURAL SCIENCES\nANIMAL SCIENCE / FISHING RESOURCES\nFOOD SCIENCE AND TECHNOLOGY\nVETERINARY MEDICINE\nApplied Social Sciences\nAPPLIED SOCIAL SCIENCES\nARCHITECTURE, URBAN PLANNING AND DESIGN\nBUSINESS, ACCOUNTING (SCIENCES ) AND TOURISM\nECONOMICS\nLAW\nSOCIAL SERVICES / DOMESTIC ECONOMY\nURBAN AND REGIONAL PLANNING / DEMOGRAPHICS\nBiological Sciences\nBIOLOGICAL SCIENCES I\nBIOLOGICAL SCIENCES II\nBIOLOGICAL SCIENCES III\nECOLOGY AND ENVIRONMENT\n\nEngineering\nENGINEERING I\nENGINEERING II\nENGINEERING III\nENGINEERING IV\n\nENG 1\nENG 2\nENG 3\nENG 4\nExact and Earth Sciences\nAPP-SOC-SCI\nASTRONOMY / PHYSICS\nASTR, PHYS\nARCHT, URB, DESN\nCHEMISTRY\nCHEM\nBUS, ACC, TOUR\nCOMPUTER SCIENCE\nCOMP\nECON\nGEOSCIENCES\nGEOSC\nLAW\nMATH / PROBABILITY AND STATISTICS MATH, PROB, STAT\nHealth Sciences\nSOC-SERV, DOM-ECON\nURB-REG-PLAN, DEMOG DENTISTRY\nDENT\nMEDICINE I\nMED 1\nBIO 1\nMEDICINE II\nMED 2\nBIO2\nMEDICINE III\nMED 3\nBIO 3\nNURSING\nNURS\nECOL, ENV\nPHARMACY\nPHARM\nPHYSICAL EDUCATION\nPHYS-EDUC\nPUBLIC HEALTH\nPUB-HEAL\n\nEngineering\nAGRIC\nAN-SCI, FISH\nFOOD S&amp;T\nVET-MED\n\nENGINEERING I\nENGINEERING II\nENGINEERING III\nENGINEERING IV\n\nENG 1\nENG 2\nENG 3\nENG 4\nExact and Earth Sciences\nAPP-SOC-SCI\nASTRONOMY / PHYSICS\nASTR, PHYS\nARCHT, URB, DESN\nCHEMISTRY\nCHEM\nBUS, ACC, TOUR\nCOMPUTER SCIENCE\nCOMP\nECON\nGEOSCIENCES\nGEOSC\nLAW\nMATH / PROBABILITY AND STATISTICS MATH, PRO\nHealth Sciences\nSOC-SERV, DOM-ECON\nURB-REG-PLAN, DEMOG DENTISTRY\nDENT\nMEDICINE I\nMED 1\nBIO 1\nMEDICINE II\nMED 2\nBIO2\nMEDICINE III\nMED 3\nBIO 3\nNURSING\nNURS\nECOL, ENV\nPHARMACY\nPHARM\nPHYSICAL EDUCATION\nPHYS-EDUC\nPUBLIC HEALTH\nPUB-HEAL\n\nHuman Sciences\nANTHROPOLOGY / ARCHAEOLOGY\nEDUCATION\nGEOGRAPHY\nHISTORY\nPHILOSOPHY / THEOLOGY\nPOLITICAL SCIENCE AND INTERNATIONAL RELATIONS\nPSYCHOLOGY\nSOCIOLOGY\nLinguistics, Letters and Arts\nARTS / MUSIC\nLETTERS / LINGUISTICS\nMultidisciplinar\nBIOTECHNOLOGY\nINTERDISCIPLINARY\nMATERIALS\nSCIENCE AND MATH TEACHING\n\nANTR, ARCH\nEDUC\nGEOGR\nHIST\nPHIL, THEOL\nPOL-SCI, INT-REL\nPSYCH\nSOCIOL\nART, MUSC\nLETT. LING\nBIOTECH\nINTERD\nMATER-SCI\nSCI&amp;MATH -TEACH\n\nFigure 1: List of acronyms of Assessment Areas and respective Broad Areas\n\nQualis consists of the classification of vehicles in which the scholars of\npostgraduate programs publish their findings. Titles are analyzed and ranked\naccording to criteria established by committees of area. According to Capes\n(2004), &quot;is at the discretion of each area to decide on the category of vehicle used\n1580\n\nby it: there are areas that rank only journals, as there are those who classify other\ntypes of vehicles such as: annals, newspapers and magazines”. As one might\nexpect, the relative importance of journals, against books and proceedings is a\nconstant discussion of the committees of different assessment areas, that develops\nits own document based on the main guidelines from CAPES Board of\nAssessment. These documents are reviewed and approved by the Scientific\nTechnical Council (CTC).\nThe CAPES document is structured into six parts: a) Identification (Assessment\nArea, area coordinator, area assistant coordinator, modality); b) I. General\nconsiderations on the current stage of area; c) II. General considerations on the\nevaluation form for the respective triennium; d) III. General Considerations for\nQualis journals, books classification form and criteria for usage and stratification\nof these documents in the assessment; IV. General Evaluation Form for the\nrespective triennium; e) V. Considerations and definitions about assigning grades\n6 and 7 (maximum) – international insertion.\nAs this study intent to study the specific criteria to evaluate books and national\njournals, it considered the sections III and IV that are described below, from the\nlast completed triennial assessment (2007 - 2009).\nSection III: consists in the defined criteria to (1) journals classification (A1, A2,\nB1, B2, B3, B4, B5 – where A1 and A2 are the core journals of each area, and C\nmeans &quot;no value&quot;). At one hand, the majority of the areas consider the journal\nImpact Factor from the Journal Citation Reports (JCR IF) as the main and unique\nindicator to define the core journals, while other areas value national journals\nindexed at SciELO (Scientific Electronic Library Online) database. On the other\nhand, some areas consider the book in its evaluation and also describe the books\nclassification in a detailed (complex and controversial) way, defining the book\nclassification form. A couple of areas still classify conference proceedings, even\ncalculating specific indicators to do so - that is the case of Computer Science.\nSection IV: shows the general Evaluation Form. It is composed by five items and\nsub items that receive a weight for the whole evaluation, for example, in a specific\narea: 1. Proposal of the postgraduate program (0%); 2. Docent staff (20%); 3.\nStudents Thesis and Dissertations (35%); 4. Intellectual Production (35%); 5.\nSocial Inclusion (10%). Each area has the autonomy to set the weight of the items\nand sub items, in a weight range established at the main guidelines from CAPES\nBoard of Assessment.\nIn order to map the diverse attribution of relevance of scientific journals and\nbooks between the different assessment areas, the respective weights were\nanalyzed (information gathered from item 4. Intellectual Production of Evaluation\nForm). The documents were obtained from CAPES Board of Assessment that\nsent the material on December 2012.\nInformation of interest were: Broad Area (BA), Assessment Area (AA), the\ndefinition or not, by the AA of a detailed book classification form and the\nconsideration about the presence of a journal at SciELO database as a quality\ncriteria. As response variables were selected the JCR IF and the weight attributed\n1581\n\nto publication on scientific journal (that multiplied by the weight associated to\nIntellectual Production, gives the importance of publication in journal articles\nagainst all the other aspects of the general Evaluation Form).\nFindings and discussion\nThe first variable analyzed concerns to the percentual weight of the publication on\njournals in relation to all aspects considered in the general Evaluation Form.\nObserving Figure 2 it is possible to see that the average weight assigned by the\nAAs of each BA is more significant (&gt; 22%) for EXA and AGR, followed by\nSOC, ENG, MULT and HLTH (around 18%), and HUM e BIO (around 17.5%)\nand LLA (16%). The BAs showing more AAs (8) are HLTH and HUM.\nThe data shows (figure not presented) that most AAs (58.6%) use books\nclassification criteria and, contrarily, the majority (63,6%) do not consider being\nindexed in SciELO as a criteria for the journal classification on the highest\nstratum. But is interesting to note that SciELO is more used in areas that classify\nbooks (41.4%) than in areas that don’t classify (29.4%).\nExact and Earth Sciences\n(EXA) - 5\nLinguistics, Letters and\nArts (LLA) - 2\n\n25,0\n\n20,0\n\nAgricultural Sciences\n(AGR) - 4\n\n15,0\n10,0\n\nBiological Sciences (BIO)\n-4\n\nHuman Sciences (HUM) 8\nHealth Sciences (HLTH) 8\n\n5,0\n0,0\n\nApplied Social Sciences\n(SOC) - 7\n\nEngineering (ENG) - 4\nMultidisciplinar (MULT) 4\n\nFigure 2. Broad Areas (and respective number of Assessment Areas) distributed by\ndescendent average weight attributed to journal in the postgraduate program\nassessment.\n\nAnother aspect to be mentioned is that the 17 AAs that do not classify books are\nmostly the so called hard sciences, assigning an average weight to journals in\n20.3%. However, when considering the 29 AAs that classify books, the 5 Social\nSciences areas attribute the highest average weight to journals (18.6%), followed\nby 9 hard sciences areas (18.0%) and finally by 3 Arts and Humanities areas\n(15.1%).\nTable 1 show areas that don’t use books classification criteria or SciELO indexing\nto classify journals on the highest stratum (Group 2) are those with highest weight\nfor journal publications. This group concentrates 60% of EXA AAs and 50% of\n1582\n\nHLTH. It is the second group that requires higher average value of JCR IF to be\nat the highest stratum, presenting the largest JCR IF on BIO (BIO 3, with 4.9) and\nAGR (VET-MED, with 2.6).\nAreas that do not value books but consider indexing in SciELO as criteria for\nevaluating journals (Group 1) are those that require higher JCR IF as evaluation\ncriteria of journals on the top stratum. We highlight the ASTR, PHYS require JCR\nIF 6.0 (the highest of EXA) and ENG 4 (IF 1.0) with the higher requirement\nacross the ENG fields. The group concentrates 40% of EXA AAs and 50% of\nENG. It should be emphasized that the presence ENG and COMP on this group is\nbecause they are areas that use mostly conference proceedings to disseminate\ntheir results, not considering either national journals or books – as consequence\nthey require low JCR IF to classify journals.\nGroup 3 shows AAs that classify books but do not consider SciELO indexing as\nevaluation criteria. It is possible to see that it is the most heterogeneous group and\ncontains the majority of the AAs. Displays the BIOTECH area which requires\nJCR IF 5.0 (the highest into MULT).\nAnd Group 4 concentrates the most part of AAs in HUM (75%) and SOC (57%),\nand classifies books and considers indexing in SciELO as evaluation criteria.\nThese areas do not often use the JCR IF as journals evaluation criteria on the\nhighest stratum, except in GEOGR areas (IF of 0.5) and PUB-HEAL (IF of 4.0,\nthe highest of HLTH).\nThe evaluation of scientific production nationwide should consider the existing\npolicy model as well as add the scientific communication specificities expressed\nin the practices of communities of different knowledge areas. The evaluation\ncriteria should be appropriate to the different areas, and also to the national\ncontext, in order to give subsidies to a coherent science policy, in which the\nBrazilian scientific community has played an important role.\nAs explains Trigueiro (2001), the scientific community, together with the state,\ncontributed significantly to the establishment and consolidation of scientific and\ntechnological national base through scientific societies that now use the policy\nweapons, establishing: the institutions that support research, postgraduate\nprograms, national plans and the current evaluation system itself. Already Guédon\nidentifies the emergence of a power structure formed at the scientific field, whose\ncomponents are institutions, associations and journals - that is involved in a dense\nand complex web of interactions and influences, characterizing the scientific field.\n&quot;Institutions, associations and journals will also be relevant to any study of power\nand competition in the social sciences and the humanities, but they will not work\nin the same way as in science. Together, they form a national system of science&quot;\n(Guédon, 2010, p. 26).\nAt this context Qualis evaluation process is being developed, while it is always\ntrying to adjust the criteria to the specificities of each area, but always seeking to\nestablish a high standard of excellence, aiming to lead scientific production to\nmost qualified vehicles.\n\n1583\n\nTable 2. Distribution of Assessment Areas (and respective Broad Area) by journal\nweight and Impact Factor (JCR) required to get the highest stratum classification,\ngrouped by usage or not of book classification form and/or national journal SciELO\nindexing\nGroup 1: No books |\n\nYes SciELO\n\nBroad Area\nJournal\nAssessment Area\n%\nArea\nweight (%)\n14\nBIO 25% BIO2\nASTR, PHYS\n17.5\nEXA 40%\nCOMP\n26\nENG 4\n17.5\nENG 50%\nENG 3\n17.5\n18.5\nAvarage\n\nGroup 3: Yes books |\n\nGroup 2: No books |\n\nIF JCR\n4.7\n6\n1.4\n1\n3.3\n\nBroad Area\n%\nArea\nBIO\n25%\nHLTH\n\n50%\n\nEXA\n\n60%\n\nAGR\n\n50%\n\nMULT\nENG\n\n25%\n25%\n\nNo SciELO\n\nBroad Area\nJournal\nAssessment Area\n%\nArea\nweight (%)\nBIOTECH\n16\nMULT 50%\nSCI&amp;MATH -TEACH\n17.5\nBIO 1\n15.8\nBIO 50%\nECOL, ENV\n20\nFOOD S&amp;T\n22\nAGR 50%\nAN-SCI, FISH\n22\nPHARM\n16\n16\nHLTH 38% PHYS-EDUC\nNURS\n16\nENG 25% ENG 1\n17.5\nBUS, ACC, TOUR\n22.8\n22.8\nSOC 43% ECON\nARCHT, URB, DESN\n16\nPHIL, THEOL\n17.5\nHUM 25%\nEDUC\n17.5\nLETT. LING\n20\nLLA 100%\nART, MUSC\n12\n18.1\nAvarage\n\nJournal\nweight (%)\nBIO 3\n20\nMED 2\n20\nMED 1\n20\nDENT\n20\nMED 3\n20\nCHEM\n21\nGEOSC\n24\nMATH, PROB, STAT\n26\nVET-MED\n22\nAGRIC\n22\nMATER-SCI\n17.5\nENG 2\n20\n21.0\nAvarage\nAssessment Area\n\nGroup 4: Yes books |\n\nIF JCR\n5\n4.1\n3\n2.6\n2\n3\n1.9\n0.8\n0.8\n0.5\n2.4\n\nBroad Area\n%\nArea\nHLTH 13%\n\nHUM\n\n75%\n\nSOC\n\n57%\n\nMULT\n\n25%\n\nNo SciELO\n4.9\n3.8\n3.8\n3.1\n3\n4\n2.8\n1\n2.6\n2\n1\n1\n2.7\n\nYes SciELO\n\nJournal\nweight (%)\nPUB-HEAL\n16\nGEOGR\n14\nPSYCH\n17.5\nPOL-SCI, INT-REL\n24\nSOCIOL\n20\nANTR, ARCH\n16\nHIST\n14\nURB&amp;REG-PLAN, DEMOG\n17.5\nSOC-SERV, DOM-ECON\n16\nAPP-SOC-SCI\n16\nLAW\n16\nINTERD\n21\n17.3\nAvarage\nAssessment Area\n\nIF JCR\n\nIF JCR\n4\n0.5\n2.3\n\nCurrently it is required that the higher stratum of the journals (A1 and A2) must\ncontain no more than 25% of the journals classified by the area and the number of\njournals comprising the stratum A1 must be smaller than those classified as A2.\nThis restriction was promptly opposed by several areas - taking as an example the\nPublic Health, because two very important national journals that are doomed to\nsecond stratum (A2), what is a problem in one area in which large percentage of\nthe production is directed to the national reality and has no significant\ninternational impact (ABRASCO, 2008). However the last triennial evaluation\ndocument (2007-2009) shows a remarkable advance by considering national\njournals indexed in SciELO, as we observed on this study, mostly on Group 4.\n1584\n\nThe outcome is in line with the evaluation studies carried out in some countries\nwhere there is also a preoccupation with differences between the areas and the\ndifferent forms of communication. Among then we highlight Larivière et al\n(2006) who claim that &quot;while the validity and appropriateness of bibliometric\nmethods are largely accepted in the natural sciences, the situation is more\ncomplex in the case of the social sciences and humanities&quot;. To the authors,\n&quot;evaluations based only on measures obtained from journal databases are more\nlikely to be less than adequate for disciplines in which less than 50% of references\nare made to journal articles than for those in which these references account for\nmore than 50%”.\nFinal remarks\nThe results here presented show groups of AAs at different stages of the scientific\ncommunication process. There are areas in which publications occurs primarily\non indexed international journals, otherwise there are areas proposing specific\ncriteria to evaluate the quality of national journals. There are also areas that are in\nthe process of establishing their journals, and others being forced to publish on\njournals.\nVarious adjustments can be observed in passing periods, and a longitudinal\napproach of this analysis will be undertaken soon.\nAcknowledgments\nWe acknowledge FAPESP, that supports the Young Investigators Awards project,\nintitled Scientific assessment in Brazil: study of scientific communication in\nscientific areas - Grant number 2012/00255-6156.\nReferences\nABRASCO (2008). Nota do fórum de coordenadores de Programas de PósGraduação em saúde coletiva sobre o novo Qualis Periódicos. Saúde e\nSociedade, 17 (4).\nCAPES - Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (2004).\nQUALIS: Concepção e diretrizes básicas. Revista Brasileira de PósGraduação, 1 (1), 149-151. Retrieved January 14, 2013 from:\nhttp://www2.capes.gov.br/rbpg/images/stories/downloads/RBPG/Vol.1_1_jul2\n004_/Qualis_ConcepcaoDiretrizes.pdf.\nCAPES - Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (2011).\nCritérios de avaliação. Retrieved December 7, 2011 from:\nhttp://www.capes.gov.br/avaliacao/criterios-de-avaliacao.\nGuédon, J. C. (2010). Acesso Aberto e a divisão entre ciência predominante e\nciência periférica. In: Ferreira, S.M.S.P. &amp; Targino, M.G. (Orgs).\nAcessibilidade e visibilidade de revistas científicas eletrônicas (pp. 21-77).\nSão Paulo: Senac/CENGAGE Learning.\n156\n\nhttp://www.bv.fapesp.br/en/auxilios/48066/scientific-assessment-brazil-study-scientific/\n1585\n\nHicks, D. (2004). The four literatures of Social Science. Retrieved January 12,\n2013 from: http://works.bepress.com/diana_hicks/16.\nLarivière, V. et al. (2006). The Place of Serials in Referencing Practices:\nComparing Natural Sciences and Engineering with Social Sciences and\nHumanities. Journal of the American Society for Information Science and\nTechnology, 57 (8), 997–1004.\nLeite, P.; Mugnaini, R.; Leta, J. (2011). A new indicator for international\nvisibility: exploring Brazilian scientific community. Scientometrics. 88: 311319.\nSouza E. P.; Paula M. C. S. (2002). QUALIS: a base de qualificação dos\nperiódicos científicos utilizada na avaliação CAPES. INFOCAPES – Boletim\nInformativo da CAPES, 10 (2), 7-25. Retrieved August 1, 2011 from:\nhttp://www.capes.gov.br/images/stories/download/bolsas/Infocapes10_2_2002\n.pdf.\nTrigueiro, M. G. S. (2001). A comunidade científica, o Estado e as universidades,\nno atual estágio de desenvolvimento científico tecnológico. Sociologias, 6, 3050.\n\n1586\n\n‘SEED+EXPAND’: A VALIDATED\nMETHODOLOGY FOR CREATING HIGH\nQUALITY PUBLICATION OEUVRES OF\nINDIVIDUAL RESEARCHERS\nLinda Reijnhoudt1, Rodrigo Costas2, Ed Noyons2, Katy Börner1,3, Andrea\nScharnhorst1\n1\n\nlinda.reijnhoudt@dans.knaw.nl, andrea.scharnhorst@dans.knaw.nl\nDANS, Royal Netherlands Academy of Arts and Sciences (KNAW), the Hague, the\nNetherlands\n2\n\nrcostas@cwts.leidenuniv.nl, noyons@cwts.leidenuniv.nl\nCenter for Science and Technology Studies (CWTS)-Leiden University, Leiden, the\nNetherlands\n3\n\nkaty@indiana.edu\nCyberinfrastructure for Network Science Center, School of Library and Information\nScience, Indiana University, Bloomington, Indiana, United States of America\n\nAbstract\n\nThe study of science at the individual micro-level frequently requires the disambiguation\nof author names. The creation of author’s publication oeuvres involves matching the list\nof unique author names to names used in publication databases. Despite recent progress in\nthe development of unique author identifiers, e.g., ORCID, VIVO, or DAI, author\ndisambiguation remains a key problem when it comes to large-scale bibliometric analysis\nusing data from multiple databases. This study introduces and validates a new\nmethodology called seed+expand for semi-automatic bibliographic data collection for a\ngiven set of individual authors. Specifically, we identify the oeuvre of a set of Dutch full\nprofessors during the period 1980-2011. In particular, we combine author records from the\nNational Research Information System (NARCIS) with publication records from the Web\nof Science. Starting with an initial list of 8,378 names, we identify ‘seed publications’ for\neach author using five different approaches. Subsequently, we ‘expand’ the set of\npublications in three different approaches. The different approaches are compared and\nresulting oeuvres are evaluated on precision and recall using a ‘gold standard’ dataset of\nauthors for which verified publications in the period 2001-2010 are available.\n\nConference Topic\n\nOld and New Data Sources for Scientometric Studies: Coverage, Accuracy and Reliability\n(Topic 2) and Management and Measurement of Bibliometric Data within Scientific\nOrganizations (Topic 9)\n\n1587\n\nIntroduction\nCreating correct linkages between a unique scholar authoring a work and her or\nhis (possibly many) author name(s) is complex and unresolved. Authors might\nuse anonymous and alias author names, names might be misspelled or change\nover time, e.g., due to marriage, and multiple scholars might have the very same\nname. Yet, science is driven by scholars, and the identification and attribution of\nworks to individual scholars is important for understanding the emergence of new\nideas, to measure the creative human capital of institutions and nations, to model\nthe relationships and networks of researchers, and to forecast new scientific fields\n(Scharnhorst et al. 2012). With the ‘return of the author’ in bibliometrics\n(Scharnhorst &amp; Garfield 2011); bibliometric indicators on the individual level\n(Hirsch, 2005; Costas et al, 2010; Lariviere, 2010; Vieira &amp; Gomes, 2011); and\ninstitutional evaluation based on the individual publication output of authors over\nlonger time periods (van Leeuwen, 2007; Zuccala et al, 2010), the ambiguity\nproblems in allocating publications to authors have become more pressing (Costas\net al, 2005, 2010). Different approaches to data collection at the individual level\nhave been proposed in the literature (see the review by Smalheiser &amp; Torvik,\n2009), although in many cases these approaches focus on the disambiguation of\nauthor in one single database (e.g. PubMED). Recently, systems of unique author\nidentifiers offer a practical solution, e.g. ORCID. However, they are not yet fully\nstandardized and often rely on authors to register their own bibliographic profiles.\nThus, the problem of automatically linking author names across publication,\npatent, or funding databases still persists.\nIn this paper, we present a general methodology that combines information from\ndifferent data sources157 to retrieve scientific publications covered in the Web of\nScience (WoS) for a given list of authors. Specifically, we trace the publications\nfor 8,378 professors affiliated with at least one of the Dutch universities, as\nincluded in the Nederlandse Onderzoek Databank (NOD, Dutch Research\nDatabase) and displayed in the web portal NARCIS (National Academic Research\nand Collaborations Information System). The approach differs from prior work by\nthe usage of an initial set of ‘seed publications’ for each author; and the expansion\nof this seed to cover the whole oeuvre of each author as represented in a large\nbibliographic database using an automated process. This automatic process is\napplied in parallel to each of the authors in the initial set. At the end, an ensemble\nof authors and their publications is build from the individual oeuvres. We\ncompare five different approaches to create ‘seed publications’ and three\napproaches to ‘expand’ the seed. Last but not least, we assess and validate the\nproposed methodology against a ‘gold standard’ dataset of Dutch authors and\ntheir publications that was compiled by Centre for Science and Technology\nStudies (CWTS) and verified by the authors themselves.\n157\n\nThe idea of combining different data sources with the objective of collecting data at the\nindividual level is not completely new (see for example D’Angelo et al, 2011) and has shown\nalready interesting results.\n\n1588\n\nThe proposed methodology is able to account for different kinds of author\nambiguity such as different ways of spelling a name, different ways to store a\nname (initials, first and last name, etc.) in different database systems, and\nmisspellings. Homonyms, i.e., different authors with the same name, can be\npartially resolved using additional information about authors such as address and\ninstitution information yet, two authors might work at the same institution and on\nsimilar topics and be merged. Note that each new information source likely offers\nnew challenges. Plus, there is much human error that is hard or impossible to\ndetect: Mail addresses can be wrongly noted or allocated, even publications\nverified by the authors themselves can be wrong. Because we aim for a scalable\nmethodology of automatic oeuvre detection we counter these ambiguities by\ndifferent means:\n manual cleaning of initial sets for automatic retrieval\n manual inspection of multiple links in automatically produced mappings\n applying similarity measures (as Levenshtein distance) for string\ncomparison\n elimination of most common names and\n elimination of publications when more than one professor from the\nsample with similar names are matched to the same author in a given\npaper (e.g. Ad de Jong and Albert de Jong assigned to the same paper\nwith the author “A. de Jong”).\nThe rest of the paper is organized as follows. First, a description of the different\ndatasets is given, followed by an overview of the ‘seed creation’ approach\napplied. Second, the ‘expansion of the seed’ and the results and issues of\nperformance are presented. Finally, we discuss the key results of the proposed\nmethodology, draw conclusions, and discuss planned work.\nData\nThe datasets used in this study are under active development at DANS (Data\nArchiving and Networked Services), an institute of the Royal Netherlands\nAcademy of Arts and Sciences (KNAW) and the Centre for Science and\nTechnology Studies (CWTS). DANS promotes sustained access to digital\nresearch data and also provides access, via NARCIS.nl, to thousands of scientific\ndatasets, e-publications and other research information in the Netherlands. In\naddition, the institute provides training and advice, and performs research into\nsustained access to digital information. CWTS is a centre of excellence in\nbibliometric analysis. It has conducted numerous bibliometric studies both for\nresearch and for evaluation, and compiled extensive data about Dutch researchers.\nNARCIS/NOD database: The Dutch full professor seed\nKNAW serves the NARCIS Dutch research information system (Baars et al,\n2008) a web portal for a set of databases. One of them is the so-called NOD\n(Dutch research database) which contains information about forty thousand plus\n1589\n\npersonnel employed at Dutch research institutions (universities and other\nacademic institutions). The person database contains metadata such as names, email addresses, but also—for some scholars among them—the Dutch Digital\nAuthor Identifier (DAI). Introduced in 2008 in the Netherlands, the DAI assigns a\nunique identifier to every employee of a Dutch university, university of applied\nsciences (HBO-Hoger beroepsonderwijs) or research institute. Since 2006,\nNARCIS also harvests publications from Dutch scientific repositories. These are\nmatched to the scholars on their DAI. A complete dump of the NARCIS database\nwas made on April 3, 2012 and is used in this paper (Reijnhoudt et al, 2012).\nSpecifically, we will use the set of 8,378 hoogleraren, or full professors, and their\n105,128 papers to exemplify the proposed methodology. 75% of the full\nprofessors have a known DAI.\nCWTS Web of Science database: High quality publication data\nThe in-house CWTS version of the Thomson Reuters Web of Science (WoS)\nconsists of nearly 35 million scientific publications and hundreds of millions of\ncitations, from 1980 up to 2012, covering all fields of science. It comprises the\nScience Citation Index Expanded (SCIE) as well as different enhancements made\nduring the scientific and commercial activities of CWTS over more than 20 years.\nEnhancements include among others: The standardization of different fields,\nnamely addresses, journal names, references and citation matching, and a new\ndisciplinary classification at the paper level (Waltman &amp; van Eck, 2012). The\nmethodology proposed here uses the standardized address information and the\nnew classification.\nCWTS SCOPUS database: Scopus Author Identifier\nScopus is one of the largest abstract and citation databases of peer-reviewed\nliterature. The database contains 47 million records, 70% with abstracts from\nmore than 19,500 titles from 5,000 publishers worldwide covering the years 1996\n– 2012 (http://www.info.sciverse.com/ scopus/about). Of particular interest for\nthis study is the newly introduced ‘Scopus Author Identifier’ that is based on an\nassignment of documents to authors determined by their similarity in affiliation,\npublication history, subject, and co-authors (Scopus, 2009). It has been discussed\nthat articles assigned to a particular Scopus Author Identifier tend to be articles of\nthe author represented by that identifier, but the set of articles might be\nincomplete, or articles by the same author might be assigned to multiple\nidentifiers (see Moed et al, 2012).\nCWTS Gold Standard dataset: High quality publication oeuvres\nFrequently CWTS’ studies at the individual author level require a manual\nverification process in which the individual researchers check and verify their\nown lists of publications - for more details on this verification process see (van\nLeeuwen, 2007). This verification process has been applied to different sets of\nresearchers in the Netherlands on publications from 2001 to 2010. From this\n1590\n\ndataset of verified author-publication oeuvres we retrieve a ‘gold standard’ dataset\nby manual matching on initials, last names and organisations. This dataset\nconsists of 1400 full professors captured in NARCIS to evaluate different author\ndisambiguation methods. The use of a gold standard set is a common approach in\nbibliometric and information retrieval research (Costas &amp; Bordons, 2008; Sladek\net al, 2006).\nMethodology\nThe main objective of this study is to develop and validate a general\nmethodology, called seed+expand, for automatic oeuvre detection at the\nindividual author level. Given a set of author names, we are interested to detect\ntheir publications, as many (high recall) and as correctly (high precision) as\npossible combining data from different databases. To exemplify and evaluate the\nmethodology, we use the set of all 8,378 full professors included in the NARCIS\ndatabase. Figure 1 shows an overview of the workflow comprising:\n1. Seed Creation: Starting with an initial list of 8,378 full professors, we\ncollect information on their name, affiliation, and e-mail addresses from\nthe NOD. Next, we identify ‘seed publications’ in the WoS for each\nauthor using five different approaches.\n2. Seed Expansion: Retrieval of additional papers for seed authors based on\ncharacteristics of the papers. Three different approaches are compared.\n3. Evaluation: Results of the different seed expansion approaches are\nvalidated using standard measures for precision and recall and the CWTS\n‘gold standard’ dataset of authors for which verified publications in the\nperiod 2001-2010 are available.\nAll three parts are detailed subsequently.\nSeed Creation\nThe first step of the methodology consists of the creation of a reliable ‘seed’ of\npublications for the 8,378 target professors. An element of this set consists of a\ntriplet of elements (publication identifier, person identifier and author position in\nthe paper). The identifiers come from different databases; and the author position\nindicates if the scholar is first, second, or nth author for that publication. The\naccuracy of the seed is very important as the precision and recall of the final\noeuvre detection will be significantly higher if the precision of the seed is high. It\nis important to bear in mind that during the expansion phase of the methodology it\nwill not be possible to add papers for those professors that are not already in the\nseed. So, for this phase in the methodology it is not the recall on papers but the\nrecall on authors that matters. Five different approaches of creating ‘accurate’\nseeds are explored here:\n E-mail seed (EM): A seed based on the matching of the e-mail of the\nprofessor with the publications in Web of Science.\n\n1591\n\n\n\n\nThree author-address approaches (RP, DL, AL): These seeds are based on\ndifferent combinations of the name of the professors and the affiliation(s)\nof that professor matched with the Web of Science.\nDAI seed (DAI): This approach builds upon the publications in NARCIS\nthat have been attached to the professors through the Dutch Author\nIdentifier.\n\nFigure 1. General workflow and relevant data sources\n\nE-mail Seed (EM)\nIn the NOD system, e-mail addresses are attached to scholars directly or via their\naffiliations. Hereby, e-mail addresses of the target professors are simply matched\nagainst e-mail addresses of authors found in the papers in Web of Science. This\napproach produced a seed for 4,786 different authors (57% of the professors from\nour list) with at least one paper found in WoS, see also Table 1. As e-mail\naddresses are uniquely attached to one scholar158 and are seldom transferred to\nother scholars159, this approach is assumed to be most accurate.\n158\n159\n\nExceptions exist with addresses like info@ or dep@\nWe expect sometimes an e-mail is transferred to another researcher with the same (or very\nsimilar) name in the same organization when the previous e-mail holder has left the\norganization.\n\n1592\n\nThree Author-Address approaches\nThree approaches combine author names and affiliation data in the NOD system\nand match them to WoS affiliation data to retrieve relevant publications. This\napproach was only feasible thanks to standardization of WoS affiliations and\naddresses by CWTS. However, some parts of this task also required manual\nhandling and checking. As a result of this, 92% of the papers with a Dutch\norganization in the WoS have a matched counterpart in the NOD organizations.\nThese are the only 652,978 papers that can be considered for the Author-Address\napproach seeds as described in the following paragraphs.\nReprint author (RP): In scientific publications, the reprint address refers to the\naddress of the corresponding author in charge of managing requests that a\npublication may generate. In the WoS database this reprint address appears\ndirectly linked to the author, thus offering a direct and “safe” connection between\nan author and an organization that can be directly extracted from the publication.\nThus, the creation of this seed consists of the matching of the name of the\nprofessor and his/her affiliation as is recorded in the NOD with the reprint author\nname and the reprint affiliation.\nDirect linkage author-addresses (DL): 69% of publications WoS include data on\nthe linkage between the authors and their organizations as they appear in the\noriginal publications. For instance, if the original publication featured three\nauthors and two organizations this linkage of authors and organizations is\nindicated as follows (Figure 2):\n\nAuthor A(1)(2), Author B(2), Author C(1)\nOrganization G, Organization H\nFigure 2. Example of direct author organization linkage\n\nIndicating that Author A is linked to Organization G and H; Author B is linked to\nOrganization H, and Author C is linked to Organization G. As in the RP-based\napproach, the names and the affiliations of the professors are matched with the\nauthor-affiliation linkages of the publications, detecting those publications that,\nbased on this author-affiliation linkage, could belong to the target professors.\nApproximate linkage author-addresses (AL): The other 31% of publications did\nnot have a direct linkage recorded in the database. Thus, authors and affiliations\nof the publications were recorded, but there was no way to tell which author is\naffiliated with what organization. This approach detects as seed publications of\nthe target professor those publications that share the same name and affiliation as\nthe professor in the same record. The AL approach has the potential problem of\nwrongly attributing a publication to a target professor if the name of the author\n1593\n\nand the institute both appear on a paper. For instance, referring back to Figure 2,\nif a homonym of ‘Author B’ (i.e., another scholar with the same name) appears in\na paper where ‘Organization H’ also appears, the real ‘Author B’ might get this\npaper wrongly attributed to him/her.\nDAI Seed (DAI)\nThis seed creation approach starts with publications that are in the NARCIS\ndatabase attributed by means of the DAI to the target professors. However, these\npublications are not necessarily WoS publications (there may be books, theses, or\njournal articles not covered in the WoS). For this reason, it was necessary to\nperform a matching process between the bibliographic records for the professors\nwith a DAI extracted from NARCIS and the WoS database. The NARCIS papers\nwere matched with the WoS publications on journal, year, title, and first page.\nThis way, we were able to create a new seed, based on the publications covered in\nthe Web of Science that were also in the NARCIS database for the target\nprofessors.\nCombining the seeds\nTable 1 shows the resulting numbers of publications and professors created by the\nfive different seed creation approaches. Publications are counted once per seed,\neven if they appear several times for different professors. The last column shows\nthe number of professors that were found exclusively by this particular seed\nmethod. So, if the AL approach would not be used, the number of professors\nfound would drop only by 76, whereas not using the EM approach would result in\na drop of 790 professors. At the end, all seed results are combined (added) and\ncleaned for duplicates leaving us with 6,989 unique professors and corresponding\n174,568 publications.\nTable 1. Result sets obtained by different seeds\nSeed Method\n\nCWTS Publications\n\nEM\nRP\nDL\nAL\nDAI\nTotal unique in\ncombined seed\n\n40,826\n81,079\n79,515\n28,837\n30,322\n\nNARCIS Full\nProfessors\n4,786\n5,819\n5,749\n5,018\n2,742\n\n174,568\n\n6,989\n\nFull Professors\nUnique to This Seed\n790\n149\n158\n76\n162\n\nTo further improve seed quality, we remove multiple assignments and common\nnames. Multiple assignments refer to the cases where more than one professor is\nmatched to the same paper, with the same author position number. Clearly this is\nwrong, as only one researcher should be matched to one author. In order to keep\n1594\n\nthe seed as precise as possible and thus sacrificing some recall for precision, all\nthese records have been removed (see Table 2, ‘remove multiple assignments’).\nThe top 5% most common author names (first initial-last name pairs) from the\nformer two seed-approaches (RP and DL) and the top 10% from the least precise\napproach (AL), thus trying to keep the level of ‘noise’ (i.e., false positives) in the\nseed to a minimum. (See Table 2, column ‘remove common names’).\nThe resulting seed comprises 6,753 professors (80% of initial set of 8,378) with\n157,343 unique papers.\nTable 2. Pruning the seeds to increase precision\nSeed Method\nEM\nRP\nDL\nAL\nDAI\nTotal unique in\ncombined seed\n\nNumber of Found\nProfessors\n4,786\n5,819\n5,749\n5,018\n2,742\n\nRemove Multiple\nAssignments\n4,786\n5,696\n5,629\n4,864\n2,742\n\nRemove Common\nNames\n4,786\n4,648\n4,675\n3,147\n2,740\n\n6,989\n\n6,947\n\n6,753\n\nSeed Expansion\nIn this second phase, we use the 6,753 author profiles and associated papers in the\nseed to identify additional publications by these authors in the WoS database.\nThree approaches have been explored and are detailed subsequently.\nTwo CWTS Paper-Based Classifications (Meso and Micro)\nThese two approaches use a new paper-based classification that has been\ndeveloped at CWTS (Waltman &amp; van Eck, 2012) based on the citation\nrelationships of individual publications. It has been applied to publications\nbetween 2001 and 2011, excluding the Arts and Humanities. The hierarchical\nclassification has three levels, with a medium-level classification that comprises\n672 ‘meso-disciplines’, and a lower-level classification that includes more than\n20,000 different ‘micro-disciplines.’ We assume that within small disciplinary\nclusters (meso and micro) there is a rather low probability that two professors\nshare the same name. Hence, we assign all papers within a meso/micro-discipline\nthat have the same author names to one professor. Incorrect assignments might\noccur when two persons with the same name work in the same subfield.\nPerforming assignments at the meso-discipline level results in an increase of 34%\nto 211,202 unique papers, the micro-disciplines yield a subset thereof with\n194,257 unique papers, an increase of 23%.\n\n1595\n\nScopus Author Identifier Approach\nA third approach to expand the publications of professors is to use one of the\nalready existing author identifiers. We choose the Scopus Author Identifier\nbecause it has been introduced for all authors in the Scopus database. Here, the\n157,343 WoS publications from our initial seed were matched to Scopus\npublications and their 6,753 authors were matched with Scopus authors to derive\ntheir Scopus author identifier. As shown in Figure 3, 614 WoS seed authors had\nno Scopus author identifier; 2,977 authors had exactly one Scopus author\nidentifier; and all others had more than one. All Scopus author identifiers were\nused to retrieve additional Scopus publications that were traced back to WoS\npublications via bibliographic matching on journal, title, etc. The resulting set has\n266,105 unique papers, an increase by 69%—the largest number of all three\napproaches.\n\nFigure 3. Number of authors (y-axis) from the seed with a given number of matched\nScopus author identifiers (x-axis). The 47 authors with more than 10 were ultimately\ndiscarded.\n\nEvaluation\nTo evaluate the three seed expansion approaches, their result sets are compared to\nthe CWTS gold standard dataset introduced in section 2.4. The expansion of the\nseed by the different approaches has been performed on the whole WoS (from\n1980 to 2011). But to evaluate the approaches we restrain the result of the\nexpansion to publications published between 2001 and 2010, the same time\nperiod as the gold standard set. Exactly 1,400 of the 6,753 authors (21%) are in\nthe gold standard dataset - only 63 professors are not accounted for. These 1,400\nauthors and their 57,775 associated papers will be used to measure precision and\nrecall achieved by the different approaches.\n\n1596\n\nFigure 4. Gold standard set (A) versus the result of the expansion (B)\n\nPrecision and recall are widely used to measure how well an information retrieval\nprocess performs. Precision is defined as the retrieved relevant records (true\npositives) divided by all retrieved records (both true and false positives). Recall\non the other hand is the number of retrieved relevant records divided by the\nnumber of records that should have been retrieved (the true positives and the false\nnegatives). Thus, we can score the performance of our different approaches\naccording to these two parameters, see Table 3\nColumn 2-4 in Table 3 present the three approaches individually. In general, the\nvalues for recall are equally high for the three approaches. Regarding the\nprecision there is a slight difference. As expected, the micro-discipline set has a\nhigher precision and lower recall than the meso-disciplines approach. The Scopus\nauthor identifier approach, with 63,460 professor-paper combinations and a\nprecision of 87.3, ends up exactly in between.\nTable 3. Performance of the three expansion approaches - individually and combined\n\nTrue pos. (AB)\nFalse pos. (AB)\nFalse neg. (AB)\nPrecision\nRecall\n\nScopus\nIdentifier\n55,405\n8,055\n2,370\n87.3\n95.9\n\nMeso\n55,459\n10,430\n2,316\n84.2\n96.0\n\nMicro\n55,394\n7,212\n2,381\n88.5\n95.9\n\nScopusI\n&amp; Meso\n55,509\n13,200\n2,260\n80.8\n96.1\n\nScopusI\n&amp; Micro\n55,460\n10,260\n2,315\n84.4\n96.0\n\nThe last two columns show the combination of two approaches: Scopus author id\nplus meso-disciplines and Scopus author id plus micro-disciplines. As can be\nexpected, the recall increases, whereas the precision declines. The increase in the\nrecall is rather small, and the number of false negatives is high. This indicates that\nboth approaches miss roughly the same papers. Apparently there are some\n\n1597\n\npublications in the oeuvres of some researchers that are hard to find using the kind\nof approaches presented in this paper.\nConclusions\nOf the 8,378 professors in our target list we identified at least one publication for\n6,753 (80%) professors, which gave us a seed into their oeuvre (as far as covered\nby the WoS). Combining all publications of all professors we started with a set of\n6,753 authors and 157,343 unique publications. After the expansion of the\nindividual publication seeds with the Scopus author id approach and the microdisciplines approach we find the same recall on the gold standard dataset, and a\ncomparable precision, as shown in Table 3. The Scopus author id approach finds\nmore unique papers (266,105 vs. 194,257). This can be attributed to the\nrestrictions on the disciplines classification on period (2001-2011) and subject,\ne.g., the Arts and Humanities WoS publications are not included (Waltman &amp; van\nEck, 2012).\nThe gold standard dataset used for evaluation covers 1,400 (or 21%) of the 6,753\nprofessors and we assume the precision and recall results can be extrapolated to\nthe entire data collection. It is important to remark that the results of precision are\nslightly conservative due to the fact that for some authors some publications were\nstill missing in their verified set of publications. This happens particularly with\nauthors with high numbers of publications, in fact Smalheiser &amp; Torvik (2009)\nindicated that this happens when authors have more than 300 publications. In\nother words, although the precision of our gold standard set is 100% (basically we\ncan assume that all are correct publications, as verified by their authors) it seems\nthat the recall of the golden standard set is not necessary 100%. Thus, the values\nof ‘wrong’ publications obtained through our methodologies might not be as high\nin reality, and thus we can consider this measure to be the upper bound of false\npositives that we could expect for the whole analysis, because true values will\nlikely be smaller. The methodology developed in this paper will be further applied\nin an impact study of the set of Dutch full professors, retrieving citations to all\ntheir publications. We would like to point out that our methodology, relying on\ndomain specific scholarly communication, is sensitive towards the disciplinary\ncomposition of the author set, e.g., authors that publish mostly books are\nunderrepresented. This will be explored in further analysis.\nNote that the success of cross-database retrieval and author disambiguation\nheavily depends on access policies of the hosting institutions, and the quality of\nthe databases involved. Even if access is given, extensive institutional\ncollaboration is required to interlink and harmonize databases. Initiatives such as\nORCID (Foley &amp; Kochalk, 2010) with the idea of a central registry of unique\nidentifiers for individual researchers or bottom-up networked approaches such as\nthe VIVO international researcher network (Börner et al, 2012) that assigns\nunique VIVO identifiers to each scholar, aim to provide processes and data\nstructures to assign and keep track of unique scholars and their continuously\nevolving oeuvres. The data collected by ORCID and VIVO can be used as\n1598\n\nadditional ‘gold standards’ in future evaluation studies. The methodology\npresented here can be applied to retrieve publications for scholars with a valid\nORCID and VIVO from the existing commercial and public data sources.\nUltimately, unique author identifiers are required for the comprehensive analysis\nof science, e.g., using altmetrics (Wouters &amp; Costas, 2012), and also for models\nof science (Scharnhorst et al. 2012) using data from multiple databases.\nAcknowledgements\nThe authors acknowledge detailed comments and suggestions provided by\nVincent Lariviere and Kevin W. Boyak for an early version of this manuscript.\nPart of this work was funded by the NoE European InterNet Science (EINS) (EC\nGrant 288021) and the National Institutes of Health under award U01 GM098959.\nReferences\nBaars, C.; Dijk, E.; Hogenaar, A.; van Meel, M. (2008). Creating an Academic\nInformation Domain: A Dutch Example. In: Bosnjak A., Stempfhuber M.\n(Eds.) Get the Good Current Research Information System (CRIS) Going:\nEnsuring Quality of Service for the User in the European Research Area.\nProceedings of the 9th International Conference on Current Research\nInformation Systems, Maribor, Slovenia, June 05-07, pages 77-87 (Online at\nhttp://depot.knaw.nl/5628/).\nBörner, K.; Ding, Y.; Conlon, M.; Corson-Rikert, J. (2012). VIVO: A Semantic\nApproach to Scholarly Networking and Discovery. San Rafael, Calif.: Morgan\n&amp; Claypool Publishers.\nCostas, R.; Bordons, M. (2005). Bibliometric indicators at the micro-level: some\nresults in the area of natural resources at the Spanish CSIC. Research\nEvaluation, 14(2): 110-120.\nCostas, R.; Bordons, M. (2008). Development of a thematic filter for the\nbibliometric delimitation on interdisciplinary area: The case of Marine\nScience. Revista Española de Documentación Científica. 31(2): 261-272.\nCostas, R.; van Leeuwen, T.N.; Bordons, M. (2010). A bibliometric classificatory\napproach for the study and assessment of research performance at the\nindividual level: The effects of age on productivity and impact. Journal of the\nAmerican Society for Information Science and Technology, 61(8): 1564-1581.\nD’Angelo, C.A.; Guiffrida, C.; Abramo, G. (2011). A heuristic approach to author\nname disambiguation in bibliometrics databases for large-scale research\nassessments. Journal of the American Society for Information Science and\nTechnology, 62(2): 257-269.\nFoley, M.J.; Kochalk, D.L. (2010). Open Researcher and Contributor\nIdentification (ORCID). Proceedings of the Charleston Library Conference\n&lt;http://dx.doi.org/10.5703/1288284314850&gt;.\nMoed, H.F.; Aisati, M.; Plume, A. (2012). Studying scientific migration in\nScopus. Scientometrics, Online at\nhttp://link.springer.com/content/pdf/10.1007%2Fs11192-012-0783-9\n1599\n\nLariviere, V. (2010). A bibliometric analysis of Quebec’s PhD\nstudents’contribution to the advancement of knowledge. PhD Thesis.\nMontreal: McGill University.\nReijnhoudt, L.; Stamper, M.J.; Börner, K.; Baars, C.; Scharnhorst, A. (2012)\nNARCIS: Network of Experts and Knowledge Organizations in the\nNetherlands. Poster presented at the Third annual VIVO conference, August\n22 - 24, 2012 Florida, USA, http://vivoweb.org/conference2012. Online at\nhttp://cns.iu.edu/research/2012_NARCIS.pdf\nScharnhorst, A., Garfield, E. (2011) Tracing Scientific Influence. Dynamics of\nSocio-Economic Systems, 2 (11): 1–31. Preprint online at\nhttp://arxiv.org/abs/1010.3525\nScharnhorst, A.; Börner, K. and Van den Besselaar, P. eds. (2012) Models of\nScience Dynamics. Berlin, Heidelberg: Springer Berlin Heidelberg.\ndoi:10.1007/978-3-642-23068-4.\nScopus (2009). Frequently Asked Questions – Author Identifier. Online at\nhttp://www.info.sciverse.com/documents/files/scopustraining/resourcelibrary/pdf/FAQ_Author_Identifier_09.pdf\nSladek, R.; Tieman, J.; Fazekas, B.S.; Abernethy, A.P.; Currow, D.C. (2006).\nDevelopment of a subject search filter to find information relevant to palliative\ncare in the general medical literature. Journal of the Medical Library\nAssociation. 94(4): 394-401.\nSmalheiser, N.R., Torvik, V.I. (2009). Author name disambiguation. Annual\nReview of Information Science and Technology. 43: 287-313.\nVan Leeuwen, T.N. (2007). Modelling of bibliometric approaches and importance\nof output verification in research performance assessment. Research\nEvaluation, 16 (2): 93-105.\nVieira, E.S.; Gomes, J.A.N.F. (2011). An impact indicator for researchers.\nScientometrics, 89 (2): 607-629.\nWaltman, L.; van Eck, N.J. (2012). A new methodology for constructing a\npublication-level classification system of science. Journal of the American\nSociety for Information Science and Technology, 63(12): 2378-2392.\nZuccala, A.; Costas, R.; van Leeuwen, T.N. (2010). Evaluating research\ndepartments using individual level bibliometrics. Eleventh International\nConference on Science and Technology Indicators. Leiden: CWTS-Leiden\nUniversity.\n\n1600\n\nTHE SHORTFALL IN COVERAGE OF\nCOUNTRIES’ PAPERS IN THE SOCIAL SCIENCES\nCITATION INDEX COMPARED WITH THE\nSCIENCE CITATION INDEX\nGrant Lewison1 and Philip Roe2\n1\n\ngrantlewison@aol.co.uk\nKing’s College London: Research Oncology, Guy’s Hospital, Great Maze Pond, London\nSE1 6RT (UK)\n2\n\nphilip@evaluametrics.co.uk\nEvaluametrics Ltd, 157 Verulam Road, St Albans, AL3 4DW (UK)\n\nAbstract\n\nMost physical science research papers are universal in their interest and are published in\ninternational journals in English. However much social sciences research is of primary\ninterest to readers in the authors’ country and so is often published in the national\nlanguage and in journals not processed for the SSCI. We wondered if it was possible to\nestimate the shortfall in coverage of this research by the SSCI by comparing the ratio of\npapers from a given country in the SSCI only to the numbers in both the SCI and SSCI\nwith the corresponding ratio for the USA, with account taken of the relative expenditures\non social sciences and medical research. For this purpose, we examined sets of papers\nwith each of a selected title word chosen from one of four subject categories, and found,\nas expected, that Anglophone countries showed much less shortfall than the large\ncontinental European ones (France, Germany, Italy, Spain) or those in east Asia (China,\nJapan, South Korea). The data in the paper can be used to estimate how many social\nsciences papers are likely to be “missing” from the SSCI for the leading countries.\n\nConference Topics\n\nScientometric Indicators: Relevance to Social Sciences (Topic 1); Old and New Data\nSources for Scientometric Studies: Coverage, Accuracy and Reliability (Topic 2)\n\nIntroduction\nMuch bibliometric work is concerned to describe the evolution of scientific\nsubject areas and to identify the leading actors – countries, institutions and\nindividuals. In the physical sciences, this task has been made easier in recent\nyears with the advent of the Web of Science (WoS) and SCOPUS, which provide\nnearly comprehensive coverage of journals in all fields of science, most of which\nare in English. The WoS in particular has increased its coverage recently of\njournals published other than in western Europe or north America. For example,\nIndian cancer research coverage in the WoS included only 9 Indian journals in\n1995 but as many as 35 in 2010 (Lewison and Roe, 2012) The decline in\n1601\n\ncoverage of Indian journals in the 1990s by the Science Citation Index (SCI) was\nthe main reason for the apparent decline in output of Indian scientists (Basu,\n1999). Relatively small increases or declines in national scientific output can be\nimportant matters for politicians in government or opposition, respectively. So,\nsince these indicators may depend critically on the coverage of national journals\nby the WoS, it is important to investigate any shortfall in coverage.\nWhat do we mean by “shortfall”? This means that the number of papers from a\ncountry in the SSCI is less than its total output in peer-reviewed social sciences\njournals because the database coverage is less comprehensive than it is for social\nsciences journals that are mainly used by US scientists, i.e. that there is a national\nbias in the journal selection process used by Thomson Reuters. This process may\nnot be value-free: Klein and Chang (2004) suggested that there was “a variety of\nevidence of bias in favor of journals of a social democratic orientation and against\njournals of a classical liberal orientation”. In particular, journals not in English\nare poorly represented in the SSCI compared with their abundance in Ulrich’s\nPeriodicals Directory, a list of over 300,000 periodicals first compiled in 1932 by\nCarolyn Ulrich, the head of periodicals at the New York Public Library (Wiegand,\n1990). This is now a commercial database, and is coupled with the Ulrich’s\nSerials Analysis System (Jacsó, 2012). Between 1992 and the present, on average\nmore than 94% of the SSCI papers (all document types) were in English.\nTo investigate the extent of the shortfall in representation, we made the initial\nassumption that the SSCI coverage of US output would be reasonably\ncomprehensive, and therefore that its ratio of papers in the SSCI only to papers in\nboth databases would be a value that would be the norm for the given subject\narea. (This may well be conservative because, as we shall see, the USA spends\nrather less on social science research relative to that on medical research\ncompared with other countries.) We then determined this ratio for some 30\nleading countries, and divided it by the ratio for the USA to give a “shortfall\nratio” (SR) which would depend on the country and also on the subject matter.\nFor example, Table 1 gives the data for a title word (properly, stem) “adolescen”\nfor the USA and two other countries, one of which (Australia) has a much smaller\nshortfall than does France, i.e., the SR is closer to unity. The numbers are the\ninteger counts of papers from the respective countries.\nTable 1. Example of calculation of shortfall ratio for Australia and for France for the\ntitle stem, “adolescen”.\nCountry\nUnited States\nAustralia\nFrance\n\nISO\nUS\nAU\nFR\n\nSCI+SSCI\n7388\n825\n416\n\nSSCI only\n2948\n239\n59\n\nSSCI/both, %\n39.9\n29.0\n14.2\n\nShortfall ratio\n0.73\n0.36\n\nThere are likely to be two reasons for a shortfall in papers in the SSCI – in the\nabove table, 27% for Australia and 64% for France. One is the paucity of SSCI\ncoverage of the journals from a given country that might be thought worthy of\n1602\n\ninclusion, but the second may be more important, namely that the country actually\ndoes less social sciences research in comparison with its physical sciences\nresearch than the USA does in the same subject areas. If this is so, then the real\nshortfall in SSCI coverage is correspondingly less than would appear from\ncalculations such as those whose results are shown in Table 1. Effectively, the\nmeasured shortfall above is the product of two factors: the under-representation of\na country’s social sciences journals and the under-performance of its social\nsciences research. We can readily determine the value of SR for a given subject\narea, but we need to calculate the under-representation of social sciences journals\nfrom data on social sciences research expenditures compared with physical\nsciences ones.\nTable 2. Title words selected for the study, with the numbers of Canadian SSCI\npapers containing each of them in 2009-11 (articles and reviews only, and not in\nSCI). HUM = human behaviour, MED = medical, ORG = organisational, PSY =\npsychological.\nHUM words\nadolescen\nadult\nchildren\ncommunity\nfamily\nhealth\nhuman\nolder\npopulation\nrisk\nwomen\nyoung\n\nCA\n331\n290\n865\n421\n297\n735\n186\n244\n141\n426\n453\n200\n\nMean:\n\n382\n\nMED words\ncancer\nclinical\ndisorder\ninjury\nmedical\nnursing\npain\npatients\nrandomized\ntreatment\ntrial\n\nCA\n104\n106\n363\n81\n48\n53\n59\n116\n52\n208\n82\n\n116\n\nORG words\nactivity\nassessment\ndecision\neducation\nevaluation\nevidence\nimpact\ninformation\nknowledge\nmanagement\noutcomes\nperformance\nquality\nsurvey\n\nCA\n234\n212\n188\n309\n217\n466\n390\n227\n225\n277\n195\n320\n184\n306\n268\n\nPSY words\nbrain\ncognitive\ndement\ndepression\nlearning\nmemory\nmental\nphobia\npsycholog\nschizophrenia\nstress\nvisual\n\nCA\n233\n207\n31\n92\n387\n167\n192\n12\n256\n21\n103\n82\n149\n\nMethodology\nSelection of subject areas.\nWe chose four main areas: human behaviour (designated HUM), medical (MED),\norganisational (ORG) and psychological (PSY). For each of these, we selected\nabout a dozen different title words (or stems, such as “adolescen” in Table 1 to\ncover both adolescence and adolescent(s)). They were chosen from the list of the\ntitle words most frequently used in Canadian social sciences papers in the three\nyears 2009-11 that were in the SSCI but not in the SCI. Canada was chosen\nbecause it was expected that its social sciences papers would be well covered in\nthe SSCI and that they would encompass a wide range of topics. The selected\n1603\n\nwords and stems were as listed in Table 2, with the numbers of Canadian papers\nin the SSCI only that contained them in their titles. It appears that there were\nmany more papers in human behaviour (HUM) and organisational studies (ORG)\nthan in psychology (PSY) and medicine (MED) – the latter papers would have\nbeen largely in the SCI.\nSearches on the Web of Science and analysis of SR values\nFor each title word, we counted the numbers of papers in the SCI plus the SSCI,\nand in the SSCI only, excluding papers in the SCI. We then calculated, for each\ncountry and for each word in the above table, the ratio of these two numbers, and\ndivided this by the corresponding ratio for the USA to give a nominal shortfall\nvalue. For each country, we then calculated the mean of this value for each of the\nfour sets of title words, together with its standard deviation, from which we\ndetermined the standard error of the mean (s.e.m.). For this purpose we used the\nstandard WoS software, supplemented by some of our own.\nOECD data on expenditures on social sciences research and R&amp;D personnel\nWe obtained data on research expenditures and numbers of research scientists in\nmajor fields from the Science and Technology Indicators published annually by\nthe Organisation for Economic Co-operation and Development (OECD) in Paris.\nIt was difficult to make standard comparisons for all the 31 countries (including\nthe USA) as many countries did not provide the OECD with statistics for each\nyear, and some gave no breakdown by field. We selected expenditures (in\nmillions of constant 2005 US dollars) and numbers of research personnel for\nmedical &amp; health and for social sciences. However, for some countries and/or\nyears, social sciences were combined with humanities, and we had to estimate the\nshare of this total that represented social sciences. The intention of this datagathering exercise was to estimate the effort (expenditure and personnel) devoted\nby the individual countries to social sciences research relative to that given to\nmedical &amp; health research. However, the years of the data inevitably varied from\ncountry to country, and we needed to assume that this ratio was reasonably\nconstant. We attempted to obtain data for 2006, on the grounds that expenditures\nthen would be likely to generate research papers three or four years later, but such\ndata were not available for all countries. If they were not, we used data from the\nlatest year for which they were published.\nData from Ulrich’s Periodicals Directory\nThe purpose of this exercise was to obtain data on the numbers of social science\njournals in the individual countries that claimed to use peer-review for\ncomparison with the numbers that were covered in the SSCI. (For the latter\ncount, we excluded journals in other subject areas that had a few social science\npapers.) However, Ulrich’s does not distinguish between social sciences and\nhumanities, so we needed to inspect the titles of all the journals in this category in\norder to count the number that corresponded in their apparent coverage to the\n1604\n\njournals processed for the SSCI. These included archaeology, economics and\nbusiness, education, international relations, law and sociology, but not history\n(except for the history of science and medicine). Allocation of Ulrich’s journals\neither to social sciences or to humanities was a nice decision in many instances,\nand was carried out by PR. The intention was to use these data as a simple check\non the results of the calculation of SSCI shortfall, which would be based on the\napparent shortfall and the difference between the ratio of social sciences research\nto medical &amp; health research in the country and in the USA. Because the SSCI\nselects journals on the basis of their contribution to the international literature, the\nshortfall based purely on the numbers of journals in the Ulrich’s directory might\nbe quite inaccurate, but at least the value based on the Ulrich’s data should bear\nsome resemblance to the truth, and it would serve to give some credibility to the\ncalculated value of the shortfall of SSCI papers.\nIn order to see if these shortfall data agreed with those in the Ulrich&#x27;s Periodicals\nDirectory, we first determined the identity and country of publication of all the\njournals covered in the SSCI during 2009-11. Of course, the shortfall will depend\nnot only on the number of journals covered in the SSCI but also the number of\narticles in each one. Also, researchers from a given country may publish their\nsocial science papers in journals published in other countries – and indeed, the\ncountry of publication may not be obvious to intending authors who may only be\naware of the nationality of the editor(s) and will probably submit their mss\nelectronically. However, we have assumed that there will be a tendency for social\nscientists to seek a national readership for their research, and so may publish some\npapers in national journals listed in Ulrich but not processed for the SSCI. A\nfurther complicating factor is that many non-Anglophone countries (notably the\nNetherlands and Germany) publish many of their journals in English in order to\nattract a wider range of contributors and readers.\nThe listing of all the SSCI journals, with their countries of publication and\nlanguages, is a non-trivial task, even with the excellent search facilities available\non the WoS160. Individual papers have the publisher’s address and language, but\nit is not possible currently to search the WoS by country of publication. This\nmeans that the bibliographic details of large numbers of selected papers have to\nbe downloaded and analysed in order to list journals with their countries of\npublication. We compared these data with the numbers of peer-reviewed social\nscience journals covered by Ulrich from the different countries.\n\n160\n\nIt is possible to list the names of all the journals whose papers are included in a given search, but\nthe names do not always correspond to the correct names of the journals – hyphens are replaced by\nspaces, and ampersands are omitted, which makes matching difficult. Moreover, many journals are\nnot published from the country that is given in their title.\n1605\n\nResults\nApparent shortfall of papers in SSCI.\nThe primary results of the study are shown in Table 3 for the 30 leading countries\n(the USA is omitted as the values are unity, by definition). In the table, SR values\nwith an s.e.m. of less than 10% are printed in bold, ones with s.e.m. less than 20%\nprinted in normal type, and ones with s.e.m &gt; 20% printed in italics.\nTable 3. Apparent shortfall in papers in SSCI only (SR), based on ratio of SSCI-only\npapers to ones in both SCI and SSCI compared with corresponding ratio for the\nUSA, 2009-11. HUM = human behaviour, MED = medical, ORG = organisational,\nPSY = psychological.\nCountry\nIsrael\nNew Zealand\nAustralia\nNorway\nCanada\nEngland\nScotland\nSweden\nSpain\nRomania\nNetherlands\nFinland\nIreland\nMalaysia\nGermany\nSingapore\nBelgium\nSwitzerland\nDenmark\nTaiwan\nBrazil\nRussia\nGreece\nFrance\nChina\nSouth Korea\nItaly\nHungary\nJapan\nPoland\nMean Values\n\n1606\n\nISO\nIL\nNZ\nAU\nNO\nCA\nEN\nSC\nSE\nES\nRO\nNL\nFI\nIE\nMY\nDE\nSG\nBE\nCH\nDK\nTW\nBR\nRU\nGR\nFR\nCN\nKR\nIT\nHU\nJP\nPL\n\nALL\n0.96\n0.96\n0.95\n0.93\n0.90\n0.88\n0.77\n0.76\n0.75\n0.75\n0.74\n0.71\n0.68\n0.65\n0.64\n0.63\n0.61\n0.57\n0.57\n0.55\n0.55\n0.44\n0.44\n0.40\n0.37\n0.36\n0.35\n0.34\n0.27\n0.23\n\nHUM\n0.93\n0.89\n0.90\n0.74\n0.92\n0.91\n0.83\n0.56\n0.64\n0.69\n0.70\n0.49\n0.80\n0.56\n0.53\n0.65\n0.56\n0.45\n0.36\n0.47\n0.52\n0.47\n0.34\n0.33\n0.35\n0.29\n0.30\n0.33\n0.22\n0.21\n0.57\n\nMED\n0.85\n0.72\n0.91\n1.03\n0.91\n0.81\n0.65\n0.88\n0.64\n0.99\n0.58\n0.86\n0.60\n0.27\n0.55\n0.56\n0.46\n0.50\n0.64\n0.31\n0.58\n0.30\n0.39\n0.40\n0.37\n0.33\n0.32\n0.26\n0.33\n0.19\n0.57\n\nORG\n1.03\n1.08\n0.98\n0.89\n0.81\n0.94\n0.73\n0.66\n0.75\n0.56\n0.84\n0.78\n0.78\n0.96\n0.60\n0.82\n0.59\n0.54\n0.59\n0.91\n0.55\n0.48\n0.50\n0.37\n0.47\n0.47\n0.34\n0.41\n0.28\n0.25\n0.66\n\nPSY\n1.03\n1.14\n0.99\n1.07\n0.96\n0.89\n0.88\n0.95\n0.95\n0.76\n0.83\n0.71\n0.52\n0.82\n0.87\n0.50\n0.83\n0.80\n0.68\n0.52\n0.54\n0.50\n0.52\n0.48\n0.27\n0.36\n0.45\n0.34\n0.23\n0.28\n0.69\n\nThe countries are ordered on the basis of apparent shortfall, with those countries\nshowing the least difference from the USA at the top, and the ones showing the\ngreatest difference at the bottom. It is not surprising that the countries at the top\nare, in the main, Anglophone, whose papers are most likely to be published in\ninternational journals and in English, i.e., the ones that stand the best chance of\nbeing selected for inclusion in the SSCI. However, there are a few anomalous\nplacings – Norway is very high, but Ireland, Malaysia and Singapore are only in\nthe middle of the table. The shortfall appears to be greater for human behaviour\nand medicine (mean value of SR = 0.57) than for organisational matters (SR =\n0.66) and for psychology (SR = 0.69). A few of the SR values exceed unity: this\ndoes not necessarily mean that the shortfall is negative, but rather that the country\ninvolved devotes relatively more effort to social sciences research compared with\nthe type of work that also appears in the SCI than the USA does. The amount of\nrelative effort on different science fields is discussed in the next section.\nRelative effort on social science research and on medical &amp; health research.\nThe results taken from the OECD science &amp; technology indicators are shown in\nTables 4 and 5. The first of these shows the financial expenditures on medical &amp;\nhealth research and for social sciences research in the given year (data for some of\nthe countries listed in Table 3 are not available), and the ratio between them. This\nvaries from 0.82 (Russia, where there is very little biomedical research) to 0.17\n(USA and China, which appear to do little social sciences research in comparison\nwith their biomedical work, Sarewitz, 2013). The data for the USA are quite old\n(1998 is the latest year for which they are available), and in the quinquennium\nafter that year the budget of the National Institutes of Health (NIH) doubled in\nreal terms (Greenberg, 1999; Check, 2002), so it is unlikely that the ratio has\nbecome larger. However, since 2003, the NIH budget has barely increased\nbecause of US budgetary difficulties (Rosbach, 2011).\nTable 4. Expenditures on medical &amp; health research and on social sciences research\nin 23 leading countries in the given year, USD2005 million, constant prices and PPP.\nRatio is soc sci / (medical &amp; health + soc sci)\nCode\nRU\nIL\nES\nPL\nFI\nIE\nJP\nDK\nNO\nTW\nAU\n\nYear\n2007\n1999\n2007\n2006\n2006\n2006\n2001\n2006\n2007\n2006\n2006\n\nM&amp;H\n43\n189\n623\n117\n265\n104\n4483\n369\n427\n399\n1322\n\nSoc sci Ratio\n200 0.82\n347 0.65\n992 0.61\n136 0.54\n231 0.47\n88 0.46\n3645 0.45\n217 0.37\n250 0.37\n233 0.37\n768 0.37\n\nCode\nBE\nCA\nNL\nKR\nSE\nIT\nCH\nDE\nSG\nUS\nCN\n\nYear\n2006\n2005\n2001\n1998\n2007\n1987\n2000\n2000\n2005\n1998\n2000\n\nM&amp;H\n410\n1822\n739\n313\n777\n799\n263\n2463\n421\n8731\n170\n\nSoc sci\n238\n987\n397\n155\n329\n324\n106\n863\n96\n1841\n34\n\nRatio\n0.37\n0.35\n0.35\n0.33\n0.30\n0.29\n0.29\n0.26\n0.19\n0.17\n0.17\n1607\n\nThe second table shows the numbers of research personnel. Far fewer countries\nreport these numbers; most of the totals given here are the sum of the numbers in\nthree sectors: government, higher education and private-non-profit. The\ncorrelation between the ratios obtained from expenditure and personnel data is\njust positive but very modest, see Figure 1. However, if the spot for the most\nextreme outlier (PL, Poland) is removed, then the correlation for a linear trendline improves from r2 = 0.09 to 0.27, and if the spot for IT, Italy, is also removed\nthen r2 = 0.41.\nTable 5. Numbers of research personnel in medical &amp; health research and in social\nsciences research in 11 leading countries in the given year. Ratio is soc sci / (medical\n&amp; health + soc sci)\nCode\nIL\nIE\nIT\nAU\nES\nSE\n\nYear\n2008\n2006\n2009\n2006\n2009\n2003\n\nM&amp;H\n661\n1042\n23175\n18012\n28646\n5327\n\nSoc sci\n1524\n1121\n21786\n16211\n22660\n3634\n\nRatio\n0.70\n0.52\n0.48\n0.47\n0.44\n0.41\n\nCode\nNL\nCH\nJP\nDK\nPL\n\nYear\n2009\n2000\n2003\n2006\n2006\n\nM&amp;H\n12668\n2650\n78688\n4996\n3323\n\nSoc sci\n7884\n1494\n41343\n2463\n834\n\nRatio\n0.38\n0.36\n0.34\n0.33\n0.20\n\n1\n\nExpenditure ratio\n\n0.8\n\nIL\n\nES\n\n0.6\nPL\n\nIE\n\nJP\n0.4\n\nDK\n\nNL\nSE\n\nCH\n\nAU\nIT\n\n0.2\n\n0\n0\n\n0.2\n\n0.4\n\nPeople ratio\n\n0.6\n\n0.8\n\n1\n\nFigure 1. Ratio of social science to medical &amp; health plus social science expenditures\ncompared to the ratio for people, for 11 OECD countries, various dates.\n1608\n\nIt is not clear which of the two data sets is the more reliable, so for countries\nwhere both indicators are available, a mean value has been taken to be applied to\nthe SR values in Table 3. Because the USA does relatively little social sciences\nresearch in comparison with its activity in medical &amp; health research, most other\ncountries have a higher ratio, and would therefore be expected to generate\nrelatively more papers in the SSCI than they appear to do in Table 3. This means\nthat the shortfall in SSCI coverage is even greater than suggested by this table,\nand the best estimates for the shortfall, based on multiplication of the SR values\nby the ratio of the ratio for the country to the ratio for the USA, are those shown\nin Table 6, where the calculations are displayed. Values are only available for the\n27 countries for which an estimate of relative effort on social sciences to (medical\n&amp; health plus social sciences) is available; this excludes France, New Zealand and\nthe UK.\nThis last table shows that the shortfall in SSCI coverage is slightly more than half\nfor Canada and Norway, around two thirds for some northern European countries\n(Germany, Sweden, Netherlands) and Australia, about three quarters for some\nothers (Switzerland, Denmark, Finland, Ireland, Belgium), and more than 90% for\nPoland and Russia.\nTable 6. Calculated shortfall in papers in SSCI only (SR), based on ratio of SSCIonly papers to ones in both SCI and SSCI compared with corresponding ratio for the\nUSA, 2009-11, and corrected for difference in relative effort on social science\nresearch compared with medical &amp; health research from OECD S&amp;T data.\nCountry\nCanada\nNorway\nAustralia\nChina\nGermany\nSweden\nNetherlands\nSwitzerland\nDenmark\nFinland\nIreland\nBelgium\nIsrael\nSpain\nTaiwan\nSouth Korea\nItaly\nJapan\nPoland\nRussia\n\nISO\nCA\nNO\nAU\nCN\nDE\nSE\nNL\nCH\nDK\nFI\nIE\nBE\nIL\nES\nTW\nKR\nIT\nJP\nPL\nRU\n\nHUM\n0.92\n0.74\n0.90\n0.35\n0.53\n0.56\n0.70\n0.45\n0.36\n0.49\n0.80\n0.56\n0.93\n0.64\n0.47\n0.29\n0.30\n0.22\n0.21\n0.47\n\nMED\n0.91\n1.03\n0.91\n0.37\n0.55\n0.88\n0.58\n0.50\n0.64\n0.86\n0.60\n0.46\n0.85\n0.64\n0.31\n0.33\n0.32\n0.33\n0.19\n0.30\n\nSS/(M&amp;H+SS)\n0.35\n0.37\n0.42\n0.17\n0.26\n0.35\n0.37\n0.32\n0.35\n0.47\n0.49\n0.37\n0.67\n0.53\n0.37\n0.33\n0.39\n0.40\n0.37\n0.82\n\nSR* HUM\n0.45\n0.34\n0.37\n0.35\n0.35\n0.27\n0.32\n0.24\n0.18\n0.18\n0.28\n0.26\n0.24\n0.21\n0.22\n0.15\n0.13\n0.09\n0.10\n0.10\n\nSR* MED\n0.44\n0.47\n0.37\n0.37\n0.36\n0.43\n0.27\n0.26\n0.31\n0.31\n0.21\n0.21\n0.22\n0.21\n0.14\n0.17\n0.14\n0.14\n0.09\n0.06\n1609\n\nTable 7 lists the numbers of journals published by the top ten countries that we\nwere able to identify in the SSCI; it is clear that the distribution is highly skewed,\nwith 47% coming from Canada and the USA and 46% from Europe.\nTable 7. Numbers of SSCI journals published in 10 leading countries present in\n2009-11\nCountry\nUnited States\nUnited Kingdom\nNetherlands\nGermany\nSpain\n\nISO\nUS\nUK\nNL\nDE\nES\n\nNumber\n1211\n744\n159\n110\n48\n\n%\n46.6\n28.6\n6.1\n4.2\n1.8\n\nCountry\nAustralia\nFrance\nBrazil\nCanada\nSwitzerland\n\nISO\nAU\nFR\nBR\nCA\nCH\n\nNumber\n35\n21\n20\n19\n18\n\n%\n1.3\n0.8\n0.8\n0.7\n0.7\n\nIt proved difficult to list the journals in the Ulrich list that mapped clearly onto the\nfields covered by the SSCI journals so that a comparison could be made. For\nseveral countries, the number of “relevant” Ulrich journals was actually smaller\nthan the number of journals processed for the SSCI. For example, there were 110\nSSCI journals published in Germany (68 in English, 40 in German) but the tally\nof “relevant” journals in Ulrich was only 62: 43 in German and 29 in English.\nThis suggests that almost all the German-language journals were covered in the\nSSCI, so there should have been relatively little shortfall for German authors, but\nthis is unlikely to be the case.\nTable 8. Numbers of papers (articles and reviews) in the SSCI but not in the SCI,\n2009-11, with the number in own country language(s) and percentage.\nISO\nBR\nRU\nES\nDE\nFR\nPL\nCH\nHU\nJP\nBE\nIT\n\nSSCI x SCI\n4361\n1396\n10450\n14755\n6987\n1214\n3945\n622\n3492\n4093\n5683\n\nOwn lang.\n2655\n765\n3627\n3403\n1337\n217\n433\n58\n186\n183\n178\n\n% OL\n60.9\n54.8\n34.7\n23.1\n19.1\n17.9\n11.0\n9.3\n5.3\n4.5\n3.1\n\nISO\nNO\nNL\nSE\nTW\nCN\nDK\nIL\nRO\nFI\nGR\nKR\n\nSSCI x SCI\n3404\n10707\n4939\n4549\n7450\n2518\n3653\n990\n2509\n1418\n3285\n\nOwn lang.\n54\n166\n60\n15\n10\n1\n0\n0\n0\n0\n0\n\n% OL\n1.6\n1.6\n1.2\n0.3\n0.1\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\nFinally, we give data on the numbers and percentages of papers from the nonAnglophone countries that appeared in the SSCI but not the SCI and were in the\nnational language(s). This gives some indication of the possibilities for social\nscientists to publish in national journals, despite the pressures in many countries\nfor publications in English in order to gain a wider readership. The list is, perhaps\nsurprisingly, headed by Brazil (Portuguese) and Russia. Some countries have no\n1610\n\nnational-language journals in the SSCI, and this may account for their relatively\nsmaller shortfall seen in Table 3 – for example, Israel, Romania and Finland.\nDiscussion\nIt was clear that something was amiss with those countries for which the number\nof “relevant” Ulrich journals was smaller than or only slightly above the number\nof SSCI journals: this was the case for Germany, Italy, Poland, Spain and\nSwitzerland within Europe, and also South Korea and Taiwan. But for the other\nnine countries, there was a positive correlation between the SR values in Table 6\nand the ratio between SSCI journal numbers and Ulrich “relevant” numbers, see\nFigure 2.\n0.5\nCA\n\nCalculated shortfall\n\n0.4\n\n2\n\nR\n\n0.3\nDK\n\nIE\n\n11\n.50\n0\n=\n\nNO\nAU\nSE\n\nBE\n\n0.2\n\nJP\n\n0.1\n\nRU\n\n0\n0\n\n0.1\n\n0.2\n\n0.3\n\n0.4\n\n0.5\n\nSSCI/Ulrich relevant jnls\nFigure 2. Scatter plot of the calculated shortfall values for social science papers\n(from Table 6) for nine countries compared with the ratio of numbers of their\njournals in the SSCI compared with those in Ulrich’s Periodicals Directory for social\nscience peer-reviewed academic journals.\n\n1611\n\nThe correlation is moderate, and would be better except for two outliers: Canada,\nwhose calculated shortfall value is greater than expected, and Japan, whose value\nis smaller. It is possible that Ulrich’s directory does not adequately cover all the\nJapanese journals: there were only 17 social science ones listed, half the number\npublished in Brazil.\nThe results presented here can only be regarded as rather approximate, and\nadditional work is clearly needed to refine them. However, it is apparent that the\nshortfall is real and quite large, and biggest for Russia, Poland and Japan;\nsomewhat smaller for Italy, Spain and Belgium; less again for the Scandinavian\ncountries; and least for the Anglophone countries (Australia, Canada, the UK), as\nwould be expected.\nAcknowledgments\nThe authors gratefully acknowledge the assistance of Lauren Hutchinson with the\ndownloading of the data from the WoS on country outputs.\nReferences\nBasu, A. (1999) Science publication indicators for India: Questions of\ninterpretation. Scientometrics, 44, 347-360.\nCheck, E (2002) Bush’s budget boost puts NIH on target for doubled figures\nNature, 415, 459.\nGreenberg, DS (1999) Washington – a big budget and big changes on the way for\nUS NIH The Lancet, 354, 1621.\nJacsó P (2012) Analysis of the Ulrich’s Serials Analysis System from the\nperspective of journal coverage by academic databases Online Information\nReview, 36, 307-319\nKlein DB &amp; Chiang E (2004) The Social Science Citation Index: A black box –\nwith an ideological bias? Econ Journal Watch, 1, 134-165\nLewison, G. &amp; Roe, P. (2012) The evaluation of Indian cancer research.\nScientometrics, 93, 167-181.\nRosbash, M (2011) A threat to medical innovation Science 333, 136.\nSarewitz, D (2013) Science must be seen to bridge the political divide. Nature,\n493, 7.\nWiegand WA (1990) Carolyn Ulrich Supplement to the Dictionary of American\nLibrary Biography. Libraries Unlimited, Englewood, Colorado, 136-168.\n\n1612\n\nSOCIAL DYNAMICS OF RESEARCH\nCOLLABORATION: NORMS, PRACTICES, AND\nETHICAL ISSUES IN DETERMINING COAUTHORSHIP RIGHTS (RIP)\nBarry Bozeman1, Monica Gaughan2 and Jan Youtie3\n1\n\nbbozeman@uga.edu;\nUniversity of Georgia, Department of Public Administration and Policy, 201 Baldwin\nHall, Athens, Georgia 30602-1615 (USA)\n2\n\ngaughan@uga.edu\nUniversity of Georgia, Department of Health Policy and Management, College of Public\nHealth, Athens, Georgia 30602 (USA)\n3\n\njan.youtie@innovate.gatech.edu\nGeorgia Institute of Technology, Enterprise Innovation Institute, 75 Fifth Street, Suite\n300, Atlanta, Georgia 30308 (USA)\n\nAbstract\n\nAs co-authorship has become common practice in most science and engineering\ndisciplines and, with the growth of co-authoring has come a fragmentation of norms and\npractices, some of them discipline-based, some institution-based. It becomes increasingly\nimportant to understand the practices, in part to reduce the likelihood of misunderstanding\nin collaborations among authors from different disciplines and fields. Moreover, there is\nalso evidence of widespread satisfaction with collaborative and co-authoring experience.\nIn some cases the dissatisfactions are more in the realm of bruised feelings and\nmiscommunication but in others there is clear exploitation and even legal disputes about,\nfor example, intellectual property. Our paper is part of a multiyear study funded by the\nU.S. National Science Foundation and draws its data from a representative national survey\nof academic scientists working in Carnegie Extensive (“Research I”) universities (n=641).\nThe paper tests hypotheses about the determinants of collaboration effectiveness.\n\nConference Topic\n\nCollaboration Studies and Network Analysis (Topic 6) and Sociological and Philosophical\nIssues and Applications (Topic 13).\n\nIntroduction\nOf late there has been a growing concern about “contributorship” and,\nparticularly, that authors may be included as co-authors in research in which they\nhad no research role and, worse, may not even understand. Contributorship is\ndefined as authors declaring in detail, in advance of publication, their individual\ncontributions to scholarly papers (Rennie 2000, p. 1274). Contributorship\n1613\n\npolicies and norms are viewed as increasing transparency and fairness; The\nimpact of institutionalized standards is a timely aspect of the proposed work.\nIncreasingly, journals and professional associations are adopting rules and\nguidelines about “contributorship” (Rennie, 1998).\nWhile journals and\nprofessional associations continue to make much needed contributorship policies,\nit remains the case that these policies are based more on anecdotal information\nand even rumours than on empirical research. Our paper seeks to provide such an\nempirical basis.\nRelated Studies of Research Collaboration Dynamics\nDuring the past decade or so, researchers, especially those in the biomedical\nsciences (e.g. Rennie et al., 2000; Cohen 2004), have begun to focus on ethical\nissues and the “dark side” of collaboration. Lagnado (2003) argues that trust in\nthe meaning of co-authorship has eroded. Levsky and colleagues (2007) describe\npotentially troubling trends in authorship in medical journals between 1995 to\n2005, including honorary authorship, ghost authorship, duplicate and redundant\npublications and most important, authors’ refusal to accept responsibility for their\narticles despite their readiness to accept credit for professional purposes. They\nnote that causes of the trends continue to be unknown but that the relationship\nbetween authorship and career pressures on academic physicians are clear.\nOutside of biomedical fields, research on the ethics and socio-political dynamics\nof scientific collaboration (Shrum, et al., 2001, 2007) remains scarce. Perhaps\nthis scarcity is owing to the view (we think mistaken) that such problems are\nneither as pervasive nor as troublesome in other STEM fields. To be sure,\nbiomedical research is different. In most fields of science, technology,\nengineering and mathematics (STEM) there is little potential for unethical\nbehavior to affect clinical trials (Devine 2005; Klingensmith and Anderson 2006)\nand there are no pharmaceutical industry representatives providing services as\n“phantom” co-authors. Nonetheless, our preliminary studies (Bozeman, et al.,\n2012) show that many of the same ethical threats and problems documented in\nbiomedical fields occur in other STEM fields, albeit with somewhat different\ncauses and impacts.\nFar from being restricted to biomedical fields, problems in scientific collaboration\nare ubiquitous in science. Some of these problems are ethical (Shrum et al.,\n2001), others practical (Bozeman and Corley, 2004; Lee and Bozeman, 2005),\nsome pertain to collaboration among individuals (Katz and Martin, 1997;\nBozeman and Corley, 2004), and some to collaboration among institutions\n(Chompalov and Shrum, 1999). The literature on scientific collaboration not only\nidentifies problems in collaboration but also possible solutions. For example,\nMarusic (2004) and Pichini (2005) describe the many international Uniform\nRequirements for coauthorship information and the complex but poorly\nunderstood relationship between contributorship and grants, promotion, and\nadmittance to professional associations. Most work is case-based or anecdotal\nand, as a result, neither the scientific community nor policy-makers have much\n1614\n\nsystematic, empirically based evidence of the possible pitfalls of collaboration\nand contributorship.\nOur study draws from the abundant literature on scientific collaboration (see Katz\nand Martin, 1997 and Bozeman, Fay and Slade, 2013 for overviews), especially\nquestions associated with scholarly manuscript authorship (Tulandi et al. 2008;\nChompalov, et al., 2002) to analyze the ethical challenges for participants in\ncollaborative STEM research. By developing from the authors themselves\ninformation about collaboration dynamics, norms and social and ethical\ndilemmas, this work provides insights into the potential of new public policies\nand designs that will promote effective collaboration. Using a web-based survey,\nwe seek to develop strong empirical knowledge of STEM researchers’ norms,\nbehaviours, and perceptions about collaboration and co-authoring, especially the\nassigning of credit.\nThe foundation of STEM research-based knowledge is peer-reviewed publication\nof research findings. Due to increasingly interdisciplinary work and large-scale,\nthe assignment of authorship for publication is complex and sometimes confusing.\nAllocation of credit and responsibility for authorship is an important issue and it\nmust be resolved if STEM research results are to be managed effectively (Devine\n2005).\nWhile there are many problems with co-authoring credit and contributorship,\nsome are well known and familiar. One problem is that scientific fields and even\nwork groups within fields vary substantially in their practices for assigning coauthoring credit. In some cases first authorship means that the individual made the\nmost significant scientific and intellectual contributions to the research, but in\nother cases it means that the individual was the lab director or the principle\ninvestigator and may have had little or no direct involvement in the research\n(Mowatt et al. 2002). An alternative practice – alphabetizing authorship order –\nwould presume to reflect more “fairness” but it also lacks explicit information as\nto which author is primarily responsible for the work. The decision about\nassigning credit is highly varied and often provides only an oblique signal as to\nwho has done what. But a decision prior to co-authorship status (who is a coauthor and what it means) is the problem of how co-authorship issues are decided.\nAs decision analysts have known for years, often process is the primary\ndeterminant of outcome (Brockner and Wiesenfeld, 1996). While there is\nremarkably little evidence about collaboration and co-authorship decision\nprocesses and norms, most agree that these vital processes affect not only\nscientific career trajectories and advancement but very course of science (Katz\nand Martin, 1999; Melin, 2000). The choice of scientific topics and the\nconfiguration of research teams depend in part on collaborative and co-authorship\nnorms. Researchers have considerable autonomy in their collaboration choices\nand collaboration strategies are based in part of judgments about the conferring of\nco-authorship and status (Heffner, 1981; Bozeman and Corley, 2004). The issue is\nwho decides.\n\n1615\n\nSome attribute problems with sorting out contributorship to the explosion in\nresearch and the funding imperatives driving collaboration among investigators\nfrom multiple sites and numerous disciplines (Devine et al. 2005, Drenth 1998).\nUltimately the system of scientific authorship is built on trust that the published\nwork reflects the data and analysis of the authors (Lagnado 2003). We contend\nthat co-authorship choices and perceptions relate closely to the integrity of the\nresearch. Specifically, the integrity of the research can be undermined in (at least)\nthe following ways. In cases where authors, especially lead or corresponding\nauthors, make no substantial contribution to the research, authorship claims are\nessentially scientific fraud. Control of authorship award and credit can in some\ninstances be a “weapon” that the powerful use to obtain resources, knowledge or\nobedience from the less powerful. Since grants and contracts and other important\nresearch-related resources are provided in part on the basis of scientific reputation\nand apparent productivity, measured in terms of quantitative and quality of\npublication, misattribution of co-author credit undermines the effective allocation\nof science resources. In cases where “legitimate” collaborators are not included as\nco-authors and not provided their due, there is a possibility that data privileges\nand other resource controls can act as, essentially, a restraint of trade. Conflicts\nof interest in STEM research, often revealed in authorship of scholarly literature,\nare problematic for obvious reasons (McCrary et al. 2000). While our study\ncannot deal with the full range of ethical problems and implications flowing from\nco-authorship and collaboration issues, we can begin to prepare the empirical\nbasis for understanding these problems. Absent more detailed knowledge of\nnorms, practices and perceptions about collaboration, it is difficult to even begin\nto understand the extent of ethical hazard. According to Rennie (2000, p. 91),\n“the general consensus appears to be that identifying and publishing specific\ncontributions of authors is a venture that shows promise. But its utility must be\ndemonstrated.” Our study seeks to assess the processes, dynamics, and utility of\nvarious approaches to contributorship decisionmaking.\nThe Research Focus and Hypotheses\nThe focus of this work is on data from a web survey. This paper examines\ndeterminants of predictors of collaboration experiences in the “most recent coauthored research publication.” We used this wording approach in the survey to\nprevent the respondents from having to provide a specific citation, thereby\nthreatening their anonymity. Here we examine difficulties related to (1) persons\nnot being credited whom are perceived as deserving credit, (2) persons being\ncredited who were perceived as not deserving, (3) gender-based conflict. Our\ncentral hypothesis is that undesirable collaboration outcomes are associated with\ncollaborations in which co-authorship credit is never discussed explicitly. Other\nhypotheses associate undesirable collaboration outcomes with large\ncollaborations, author collaboration motivations, negative past experiences, mixed\ngender co-author groups, and collaborator geographic distance. Controls for\nauthor’s PhD award year and gender were included.\n1616\n\nData\nThe analysis is based on a web survey of 641 non-medical academic researchers\nin science and technology disciplines in US doctoral research universities\n(Carnegie Doctoral/Research Universities—High). A sampling frame of science\nand technology fields was developed using NSF’s categories in its Survey of\nEarned Doctorates. Health sciences was excluded (because of its medical\norientation) while economics was added to incorporate social science practices\ninto the survey. The resulting frame was based on 14 disciplines in biology,\nchemistry, computer science, mathematics, engineering, and economics. The\nsampling frame called for one male and one female faculty member from each\nrandomly selected department at a given university because qualitative interviews\nsuggested that gender would be a significant factor; in the event that no female\nfaculty members were affiliated with the department, two male researchers were\nselected. The target sampling frame, which assumed a 50% response rate, resulted\nin 2,996 faculty and another 216 postdocs. We were able to collect contact\ninformation for 2,574 individuals in the sampling frame; of these 2,189 were of\nsufficient quality as indicated by an electronic mail verification software program.\nPilot surveys performed in April and May of 2012 used 400 of these, leaving\n1,789 for the final survey. Six waves of survey invitations and reminders were\nsent in October and November of 2012. One percent were not at their office\nlocation, while another 5% explicitly opted-out of participation. In all, we\nreceived 641 completed or mostly completed online questionnaires, for a 36%\nresponse rate. Respondents were very similar to the population in terms of gender,\nrank and departmental discipline. Given that we oversampled females and certain\ndepartments, results are re-weighted to reflect the population distribution as\nindicated in the NSF Survey of Doctorate Recipients 2006 (the most recently\navailable survey).\nResults\nUndesirable collaboration outcomes are measured with respect to the most recent\nco-authored research publication. A logit model (Table 1) is based on a variable\n“problems,” indicating lack of disagreement with statements about denial of\ndeserved co-authorship, receipt of undeserved co-authorship, and gender-based\nconflict based on responses to a 10-point scale from strongly agree to strongly\ndisagree. The number of co-authors in the recent paper is logged\n(“lnrecent_numcoauth”). Whether this publication involved explicit discussions\nabout co-authoring credit (“creditdis_yesno”) addresses the main hypothesis.\nDescriptive statistics indicate that 40% of respondents engaged in explicit\ndiscussions about co-authoring credit. We captured the percentage of co-authors\nof the paper that are male “permale” and the percent at other universities than\nthose of the respondent “perothuniv.” Importance of motivations for\ncollaborations to increase research productivity and help a co-author’s career\n(“mov_productivity” and “mov_helpcoauthor”) are represented in responses to a\n10-point scale ranging from not important at all to extremely important. The\n1617\n\nexistence of past negative behaviors in terms of a co-author having made no\ncontribution to the research is included as well (“careerbad_undeservedcoaur”).\nControls for the year of the author’s PhD (“yearphdr”) and whether or not the\nauthor is male or female (male2) are included.\nExplicit discussion of co-authorship credit is negatively associated with the\nlikelihood of problems. The number of co-authors increases the likelihood of\nproblems, which was in the expected direction. However, there is an inverse\nrelationship between the percentage of authors at another university and the\nlikelihood of problems, which is counter to our geographic hypothesis. Authors\nwith a bad undeserved co-authorship experience in their past were more apt to\nreport problems in their recent research publication, although motivations to\ncollaborate were not significant. The year a PhD was granted is positively\nassociated with problems, indicating that younger academics are more likely to\nexperience problems than are their older counterparts. Although gender overall\nwas not significant, interactions males in mathematics and computer science and\nmales in engineering reduced the likelihood of problems. The model is\nstatistically significant and 80% of responses are correctly classified.\nTable 1. Logit model of Likelihood of Problems in Recent Research Publication\nVariables\ncreditdis_yesno\nlnrecent_numcoauth\npermale\nperothuniv\nmov_helpcoauthor\nmov_productivity\ncareerbad_undeservedcoaur\nyearphdr\nmale2\nmale2bio\nmale2phys\nmale2math\nmale2eng\nConstant\n\nLogit(problems)\n-0.624\n0.712\n-0.003\n-0.011\n0.043\n-0.012\n1.108\n0.026\n0.709\n-0.721\n-0.933\n-1.446\n-1.007\n-53.561\n\nRobust standard errors (parens.)\n(0.288)**\n(0.184)***\n(0.004)\n(0.004)**\n(0.042)\n(0.057)\n(0.276)***\n(0.013)*\n(0.562)\n(0.673)\n(0.688)\n(0.741)*\n(0.605)*\n(26.256)**\n\nLog likelihood=-254.84898, Wald (chi square) significant at 1%, Pseudo R2=.13\n* significant at 10%; ** significant at 5%; *** significant at 1%\n\nSummary\nThere are many conceptual studies and case studies of the social and\norganizational processes by which researchers make decisions about\ncontributions, credit sharing and authorship shared credit (see for example Fine\nand Kurdek, 1999). However , systematic, large sample, studies remain scarce\n(e.g. Vinkler, 1993; Floyd, et al., 1994), hence this work’s contribution.\n\n1618\n\nAcknowledgments\nThe authors thank Derrick Anderson and Daniel Fay for their assistance. This\nstudy was undertaken with support from the National Science Foundation under\nAward # 1026231. Any opinions, findings, and conclusions are those of the\nauthors and do not necessarily reflect the views of the sponsors.\nReferences\nBozeman, B. &amp; E. Corley. (2004). Scientists&#x27; collaboration strategies:\nimplications for scientific and technical human capital. Research Policy\n33:599-616.\nBozeman, B. &amp; M. Gaughan. (2007). Impacts of grants and contracts on\nresearchers’ interactions with industry. Research Policy, 33, 5: 694-707.\nBozeman, B., J. Youtie &amp; D. Libaers (2006). Institutionalization of university\nresearch centers: The case of the National Cooperative Program in Infertility\nResearch. Technovation 26: 1055-163.\nBozeman, B., J. Youtie, C. Slade, &amp; M. Gaughan. (2012). Nightmare\nCollaborations, Paper presented at the Annual Meeting, International Society\nfor the Social Study of Science, Cophenhagen, 2012.\nBozeman, B., D. Fay &amp; C. Slade (2013). Research Collaboration and Academic\nEntrepreneurship: A State of the Art Review. Journal of Technology Transfer,\nin press, on line first.\nBrockner J. &amp; B. Wiesenfeld (1996). An integrative framework for explaining\nreactions to decisions: Interactive effects of outcomes and procedures.\nPsychological Bulletin 120(2): 189-208.\nChompalov, I., J. Genuth, &amp; W. Shrum. (2002). The organization of scientific\ncollaborations.&quot; Research Policy 31:749-767.\nChompalov, I. &amp; W. Shrum. (1999). Institutional collaboration in science: A\ntypology of technological practice.&quot; Science Technology &amp; Human Values\n24:338-372.\nCohen, J. J. (2004). Realizing our quest for meaning. Academic Medicine:\nJournal of The Association of American Medical Colleges, 79(5), 464-468.\nDevine, E. B., Beney, J., &amp; Bero, L. A. (2005). Equity, Accountability,\nTransparency: Implementation of the Contributorship Concept in a Multi-site\nStudy. American Journal of Pharmaceutical Education, 69, 455-459.\nDrenth, J. P. H. (1998). Multiple Authorship: The Contribution of Senior Authors.\nJAMA: Journal of the American Medical Association, 280(3), 219-221.\nFine, M. A. &amp; Kurdek, L. A. (1993) Reflections on Determining Authorship\nCredit and Authorship Order on Faculty-Student Collaborations, American\nPsychologist, 48, 11, 1141-1152.\nFinholt, T. (2002). Collaboratories. Annual Review of Information Science and\nTechnology, 36, 73-108.\nHeffner, A.G., (1981). Funded research, multiple authorship, and subauthorship\ncollaboration in four disciplines. Scientometrics 3, 5–12.\n\n1619\n\nKatz, J. (1994). Geographical proximity and scientific collaboration,\nScientometrics, 31(1): 31-43\nKatz, J. S. &amp; B. R. Martin. (1997). What is research collaboration? Research\nPolicy 26:1-18.\nKlingensmith, M. E., &amp; Anderson, K. D. (2006). Educational scholarship as a\nroute to academic promotion: a depiction of surgical education scholars.\nAmerican Journal of Surgery, 191, 533-537.\nLagnado, M. (2003). Increasing the trust in scientific authorship. British Journal\nof Psychiatry 183(1), 3-4.\nLee, S. &amp; B. Bozeman. (2005). The Effects of Scientific Collaboration on\nProductivity. Social Studies of Science, 35, 5:673-702.\nLevsky, M. E., Rosin, A., Coon, T. P., Enslow, W. L., &amp; Miller, M. A. (2007). A\nDescriptive Analysis of Authorship Within Medical Journals, 1995--2005.\nSouthern Medical Journal, 100: 371-375.\nMcCrary, S. V., Anderson, C. B., Jakovljevic, J., Khan, T., McCullough, L. B.,\nWray, N. P. (2000). A National Survey Of Policies on Disclosure of Conflicts\nof Interest in Biomedical Research. New England Journal of Medicine,\n343(22): 1621-1626.\nMarusic, M., Bozikov, J., Katavic, V., Hren, D., Kljakovic-Gaspic, M., and\nMarusic, A. (2004). Authorship in A Small Medical Journal: A Study of\nContributorship Statements by Corresponding Authors. Science and\nEngineering Ethics, 10(3): 493-502.\nMelin, G., (2000). Pragmatism and self-organization: research collaboration on\nthe individual level, Research Policy 29, 3: 1140-1670.\nMowatt, G., Shirran, L., Grimshaw, J. M., Rennie, D., Flanagin, A., Yank, V., et\nal. (2002). Prevalence of Honorary and Ghost Authorship in Cochrane\nReviews. JAMA: Journal of the American Medical Association, 287(21):\n2769-2771.\nPichini, S., Pulido, M., and Garcia-Algar, O. (2005). Authorship in Manuscripts\nSubmitted to Biomedical Journals: An author&#x27;s Position and Its Value. Science\nand Engineering Ethics, 11(2): 173-175.\nRennie, D. (1998). Freedom and Responsibility in Medical Publication: Setting\nthe Balance Right. JAMA: Journal of the American Medical Association,\n280(3), 300-302.\nRennie, D., &amp; Flanagin, A. (1994). Authorship! Authorship! JAMA: Journal of\nthe American Medical Association, 469.\nRennie, D., Flanagin, A., &amp; Yank, V. (2000). The Contributions of Authors.\nJAMA: Journal of the American Medical Association, 89.\nRennie, D., Yank, V., &amp; Emanuel, L. (1997). When authorship fails. A proposal\nto make\nShrum, Wesley, Ivan Chompalov, &amp; Joel Genuth. 2001. Trust, Conflict and\nPerformance in Scientific Collaborations. Social Studies of Science 31: 681697.\n\n1620\n\nShrum, Wesley, Joel Genuth &amp; Ivan Chompalov (2007) Structures of Scientific\nCollaboration. Cambridge, MA: MIT Press.\nSinger, N. (2009). Medical papers by ghostwriters pushed therapy, New York\nTimes, August 4, 21-22\nTulandi, T., Elder, K., &amp; Cohen, J. (2008). Responsibility and accountability of\nauthors and co-authors. Reproductive BioMedicine Online, 763-764.\n\n1621\n\nSOFTWARE PATENTING IN ASIA\nPoh-Kam Wong1 and Yuen-Ping Ho2\n1\n\npohkam@nus.edu.sg\nEntrepreneurship Centre, National University of Singapore, 21 Heng Mui Keng Terrace,\nLevel 5, Singapore 119260\n2 yuenping@nus.edu.sg\nEntrepreneurship Centre, National University of Singapore, 21 Heng Mui Keng Terrace,\nLevel 5, Singapore 119260\n\nAbstract\n\nThis paper examines software patents trends in Asia using patents granted to Asian\ninventors by the USPTO from 1980 to 2011. The various definitions of software adopted\nin prior literature are summarized and two classification-based definitions are used in the\nanalysis. We found that globally, software patenting has grown faster than other types of\nUSPTO-granted patents, especially more so over the last decade. Two thirds of software\npatents are invented in the major software producing economies of North America,\nGermany, France and the United Kingdom. One quarter of software patents are invented\nin Asia, with Japan accounting for much of this share. Excluding Japan, Asia contributes a\nmore modest 7%. However, software patenting in non-Japan Asia is far outpacing the rest\nof the world over the last decade, even growing faster than in the major software\nproducing economies of North America and Europe. This is driven by rapid growth in\nseveral key economies, namely Korea, India and Taiwan, with China close behind.\nNonetheless, the contribution of software to national patents portfolios of non-Japan Asian\neconomies is still relatively low compared to the global average. The exception is India,\nwhere software patents account for 38% of patents in the last 5 years.\n\nConference Topic\n\nTechnology and Innovation Including Patent Analysis (Topic 5)\n\nIntroduction\nPatents as a protection mechanism for software is a relatively recent phenomenon\ndating to the 1990s, when court decisions in the US widened the scope of\npatentable subject matter to include computer-implemented methods and\nprocesses. There remains considerable disagreement in the international\ncommunity on whether it is desirable to allow software to be patented rather than\nrelying on the copyright protection mechanism. Much of the disagreement stems\nfrom differing views on the macroeconomic impact of software patents,\nparticularly the effects of a patents regime on the level of innovation in software\ndevelopment (Jaffe and Lerner, 2006). The debate remains largely unresolved as\nthere has been little empirical research on this topic (Bessen, 2011).\n\n1622\n\nAt the firm level however, there are a number of persuasive arguments favouring\npatents over traditional copyright for software IP, the most important being the\nstronger protection afforded by patent laws. With the growing ubiquity of digital\ntechnologies, companies that invest heavily in software development are seeking\nmore concrete ways to safeguard their software inventions and advance their\ncommercial interests. This has sparked a growing trend of registering software IP\nthrough the patent system, which provides for stronger protection and more clearcut litigation against infringements. Empirical research shows that there has been\na dramatic increase in the propensity to patent software since the pivotal US court\ndecisions on the patentability of computer programs (Bessen and Hunt, 2007).\nHowever, the literature has not specifically focused on software patents\noriginating from Asia. Hence, despite the well-documented economic strength of\nAsian economies and the prominence of Asian companies in the information and\ncommunications technology (ICT) sector, little is known of the contribution of\nAsian inventors to the rising trend of software patenting. This paper is a first\nattempt to address this gap. Specifically, we seek to ascertain if the global growth\nin software patents has been mirrored in Asia, and the relative importance of\nsoftware in the patents portfolios of Asian economies. We also examine\ndifferences between the various Asian economies to identify the regional leaders\nand laggards in software patents. While prior research examined software\npatenting up to the mid-2000s only, our analysis extends to 2011. This is\nimportant, as the explosion of software patenting occurred only over the last\ndecade.\nTable 1 Global Computer Software Spending\n\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\nAverage Growth 20062011\n\nGlobal Spending on Computer Software\nShare of Software\nTotal USD bil\n% change y.o.y.\nin ICT Spending\n(%)\n199\n8.43\n230\n15.6\n8.66\n253\n10.0\n8.86\n275\n8.7\n8.94\n296\n7.6\n8.91\n312\n5.4\n8.82\n305\n(2.2)\n8.97\n325\n6.6\n9.01\n357\n9.9\n8.71\n5.4%\n\nSources: OECD Information Technology Outlook 2010; UNCTAD Information Economy Report\n2012\n\n1623\n\nRecent Trends in the Global Software Market\nIn this section, we present an overview of the global software market to provide\nadditional context for our analysis. As shown in Table 1, worldwide spending on\ncomputer software has increased substantially from USD 199 billion in 2004, to\nUSD 357 billion in 2011.161 Software accounts for 9% of total spending on ICT, a\nshare that has held steady over the years. Excepting 2009, when the global\neconomy was reeling from the financial crisis of 2007-08, spending on computer\nsoftware has grown annually at rates in excess of 5%, and in excess of 10% in the\nearlier part of the post millennium decade. Between 2006 and 2011, computer\nsoftware spending grew at an average 5.4% annually\nTable 2 Software Spending in Asia and Selected Advanced Economies, 2011\n\nASIA\nJapan\nChina\nHong Kong\nTaiwan\nIndia\nSouth Korea\nSingapore\nOther Asia\n\n46\n15\n19\n0.5\n1.5\n2.3\n2.9\n1.2\n4.4\n\nShare of\nEconomy/ Region\nin World Total\nSoftware\nSpending\n12.9\n4.1\n5.2\n0.2\n0.4\n0.6\n0.8\n0.3\n1.2\n\nNORTH AMERICA\nUnited States of\nAmerica\n\n151\n\n42.3\n\n11.7\n\n138\n\n38.8\n\n12.2\n\nEU / EFTA\nFrance\nGermany\nUnited Kingdom\n\n138\n17\n24\n24\n\n38.6\n4.9\n6.8\n6.7\n\n12.2\n11.0\n11.2\n12.9\n\nWorld Total\n\n357\n\n100.0\n\n8.7\n\nSoftware\nSpending 2011\n(USD billion)\n\nSource: UNCTAD Information Economy Report 2012\n\nSoftware Spending\nIntensity (Share of\nSoftware in Total ICT\nSpending)\n4.0\n4.1\n4.4\n2.7\n5.8\n2.4\n3.3\n8.6\n4.0\n\nThe vast share of software spending takes place in North America and Europe, as\nshown in Table 2. Asian economies account for 12.9% of global spending on\n161\n\nIt is noted that data on software sales and spending do not quite capture the full size of software\nactivities, as many companies do in-house software development. Also the figures may not fully\ninclude IT services such as contract programming, nor software which is embodied in other\ntechnology products.\n1624\n\nsoftware, led by Japan and China who contribute 4.1% and 5.2% respectively of\nthe world total. We also observe that there is relatively low software spending\nintensity among individual Asian economies. Software spending intensity is\nproxied by the share of software in the economy&#x27;s total ICT spending. This\naveraged 4% across Asia, and ranged from 2.7% in Hong Kong to 8.6% in\nSingapore, which is the only Asian economy with software spending intensity\napproaching the global average of 8.7%. Comparably, we observe that software\nspending contributes more than 10% of total ICT spending in advanced\neconomies such as USA, France and Germany.\nHaving established an understanding of global trends in software spending, we\nseek to ascertain if these patterns are echoed in patenting trends. Is the production\nof software patents keeping pace with the expansion of the global software\nmarket? There appears to be relatively low expenditure on software in Asia\ncompared to North American and Europe, with Asian economies concentrating\nhigher proportions of spending on the hardware and communications segments of\nICT. Does software patenting in Asia similarly lag behind the more advanced\neconomies?\nData and Methods\nSource for Patents Data\nPatent laws and examination standards vary by jurisdiction. While an ever-present\nfactor in comparative patents analysis, this issue gains increased significance\nwhen examining patents in the field of software. There are vastly divergent\nstandards for granting software patents in the different national patent granting\noffices, with some offices adopting more restrictive stances than others. As a\nresult of several key judgments by the US Supreme Court and the specialist\nFederal Circuit Court, the US Patents and Trademark Office (USPTO) now has\namong the broadest and most inclusive guidelines for patentability of software.\nCurrently, a practical application of a computer-related invention is patentable by\nthe USPTO, as are business methods. Comparably, the European Patent Office\n(EPO) has stringent standards for allowing patents to be granted for software\ninventions. The European Patent Convention (EPC) explicitly states the exclusion\nof “programs for computers” from patentability, although case law shows several\nexceptions to this standard. Among the Asian economies, standards for software\npatentability also vary considerably. Along with the UPSTO, the Japanese Patent\nOffice is regarded as having more lenient laws pertaining to software patents. In\nIndia, patent laws are almost as stringent as the EPC, limiting patentability to a\ncomputer program in the form of its “technical application to industry”. Patent\nlaws in Korea, Taiwan and China fall between the USPTO&#x27;s liberal standards and\nthe stricter provisions of the EPO.\n\n1625\n\nThe use of a common patent-granting agency eliminates concerns pertaining to\ndiffering standards of examination in a cross-border context. All analysis in this\npaper is based on patents granted by the USPTO. The USPTO is selected as one\nof the largest patents granting offices in the world and because the USA is the\npremier target market for technology products and services. This is even more so\nfor software applications in both commercial and consumer domains. With the\nUSPTO’s liberal guidelines for patentability of computer programs and computerimplemented methods, inventors and companies from around the world also have\nadditional incentive to seek software patent protection in the USA.\nPatent counts and patents data from 1980 to 2011 were extracted from the Patsnap\nwebsite, which provides an online database of USPTO patents and a web-based\nsearch engine. Of the extracted detailed fields, the inventor’s country of residence\nis used to assign the nationality of a patent. A patent is categorized as an Asian\npatent if at least one of its inventors is residing in an Asian economy. With this\nconvention, a patent with multiple inventors from multiple economies will be\nassigned multiple countries of origin and will be included in the patent counts of\neach country.\nOrganization of Data to Reflect Developments in Software Patentability\nThe patents data are organized and presented in groups spanning multiple years: a\n11-year group for the period 1980 to 1990, and groupings of five years after 1990,\nwith figures for 2011 separately reported. We chose 1980 as the starting point in\norder to trace developments in software patenting after the pivotal US Supreme\nCourt ruling in Diamond v. Diehr in 1981 provided the first instance of the\nUSPTO being ordered to grant a patent on an invention which utilized computer\nsoftware. Prior to this, the USPTO had been reluctant grants patents on inventions\nrelating to computer software, going so far as to issue formal guidelines in 1968\nstating that a computer program was non-patentable, whether it was claimed as an\napparatus or as a process. The 1981 decision in Diamond v. Diehr led the USPTO\nto modify its position and sparked a period of increased growth in software\npatenting (Hall and MacGarvie, 2009). Nonetheless, the scope of permissible\nclaims was still relatively limited, requiring software to be contained within a\npatentable invention. Indeed, it may be argued that &quot;software patents&quot; in this\nperiod are more accurately described as &quot;software-related&quot;, as they were granted\nfor inventions incorporating software components rather than software inventions\nper se.\nThe five-year groupings after 1990 parallel periods of important judicial\ndevelopments that expanded the scope of computer software as statutory subject\nmatter. In 1991-1995, the Court of Appeals of the Federal Circuit handed down a\nseries of decisions, including In re Alappat (1994), In re Lowry (1994) and In re\nBeauregard (1995), which determined that much of software was patentable. In\nresponse, the USPTO proposed new guidelines in 1995, which were published in\n1626\n\nearly 1996, stating that it would allow software embedded in physical media to be\nclaimed as processes. In addition to these guidelines, the period 1996-2000 saw\nfurther expansion in the scope of permissible software claims when the Federal\nCircuit&#x27;s ruling in State Street Bank &amp; Trust v. Signature Financial Group (1998)\nestablished computer-implemented business methods as patentable.\nIn the most recent period 2006-2010, a series of decisions have examined the\nscope of patentable subject matter pertaining to processes, as well as the means of\ntesting the patentability of process claims. These decisions are of particular\nrelevance to software inventions, particularly those that are not coupled or\ncombined with hardware or machinery. Ruling on In re Bilski (2008), the Federal\nCircuit set forth the machine-or-transformation test for process claims, which\nappears to curtail the patentability of certain software and business methods.\nHowever, this decision was partially reversed by the Supreme Court in Bilski v\nKappos (2010), in which the court rejected the test as the sole test of patentability\nof processes. In the same ruling, the Supreme Court also rejected the categorical\nexclusion of business methods from patent eligibility. While this decision allayed\nfears that In re Bilski would signal the end of software process patents, the\nSupreme Court also emphasized that examiners have the ability to reject method\nclaims as pre-empting an abstract idea. Bilski v Kappos is regarded as a landmark\ndecision for software patentability and its ramifications are as yet unclear. As our\ndataset ends in 2011, we can at best partially assess the impact of this decision on\naggregate software patenting trends.\nDefining and Identifying Software Patents\nIn the literature and at patent offices, there are multiple definitions of what\nconstitutes a &quot;software patent.&quot; The USPTO&#x27;s US Patent Classification (USPC)\nsystem has devoted a section of classes to “computer implemented patents”,\nspanning USPC 700 to USPC 726. This is a broad categorization which was\nfurther expanded upon by Bessen (2011) to include classes of technologies that\nare &quot;reliant on software&quot;. Among &quot;Computer Implemented Patents&quot; are &quot;Business\nMethods Patents&quot; which are assigned USPC 705. In the academic literature,\nscholars have attempted to construct datasets of software patents through keyword\nsearching (Bessen and Hunt, 2007) and identifying patents of top software or ICT\nfirms (Graham and Mowery, 2003; Arora et al., 2007; Hall and MacGarvie,\n2010). In a report on the software industry (Lippoldt and Stryszowski, 2009), the\nOECD utilized the methodology developed by Arora et al. (2007).\nTable 2 summarizes the approaches and definitions that have been used in the\nliterature and in practice. Depending on the definition, the number of identified\nsoftware patents granted by the USPTO in the 32-year period 1980-2011 varies\nfrom 178,889 (Bessen and Hunt’s (2007) keyword search) to over 480,000 patents\n(Bessen’s (2011) expansion of the USPTO’s classification). In this paper, we\nadopt the two methodologies which are based on technology classes assigned in\n1627\n\nthe patent document; namely the USPTO’s classes USPC 700-726 and the\nschematic developed by Arora et al. (2007) which uses 5 IPC classes and has been\nadopted by the OECD.\nTable 2 Definitions of Software Patents\nIdentification Method\n\nTotal USPTO\nPatents 1980-2011\n399,531\n30,315\n249,818\n\nUSPTO\nUSPTO\nGraham and\nMowery\n(2003)\n\n“Computer Implemented Patents” USPC 700-726\n“Business Methods Patents” USPC 705\n3 IPC Classes based on patents of selected\nsoftware firms:\nG06F (Electrical Digital Data Processing)\nG06K (Recognition of Data),\nH04L (Secure Transmission of Digital Info)\n\nBessen and\nHunt (2007)\n\nKeyword search (“software” or “computer\nprogram”, with exclusion words)\n\n178,889\n\nArora et al.\n(2007), used\nby OECD\n(Lippoldt &amp;\nStryskowski,\n2009)\n\n5 IPC Classes: 3 as in Graham &amp; Mowery + 2\nothers\nG06F (Electrical Digital Data Processing)\nG06K (Recognition of Data),\nH04L (Secure Transmission of Digital Info)\nG06T (Image Data Processing)\nG09G (Visual Indicators)\n\n254,387\n\nBessen (2011)\n\nUSPC 700-707, 715-717 (data processing) +\nother selected classes (“reliant on software” and\nin which software firms patent)\n\n481,288\n\nHall and\nMacGarvie\n(2010)\n\nUSPC subclasses based on patents on top ICT\nfirms (details not revealed)\n\nNA\n\nNote: Number of USPTO granted 1980-2011 calculated by authors based on provided definitions\n\nTrends in Global Software Patenting\nRegardless of the definition used, the volume of software patenting has increased\nsignificantly since the 1980s, with growth accelerating in the last decade, as\nshown in Table 3. In 1980, before the Diamond v Diehr decision of 1981, there\nwere relatively few patents with software elements. By 1991, the number of\nsoftware patents granted annually had increased substantially and continued to\ngrow rapidly over the last 20 years. The number of software patents granted in\n2011 is 43,604 when the USPTO definition is used, almost triple the figure of\n15,499 granted in 2001. When the Aroral et al. definition is used, the number of\nsoftware patents granted in 2011 was 28,352, also almost tripling the figure of\n1628\n\n9,578 patents granted ten years earlier. In the five year period, 2006 to 2011,\nsoftware patenting grew at rates ranging from 9% to 11% per annum, depending\non the definition adopted. This outpaces the growth in computer software\nspending which was earlier reported in Table 1 to average 5.4% over the same\nfive year period, and attests to the dramatic surge in software patenting in the last\ndecade.\nCorresponding to this rapid growth, software patents contribute an increasingly\nlarge share of patents granted by the USPTO. This is illustrated in Figure 2.\nUsing the broadest definition (Bessen, 2011), software patents form 18% of all\npatents in 2006-10, increasing from a share of 12% in the previous five year\nperiod. Using the USPTO&#x27;s &quot;computer-implemented&quot; definition, software patents\nconstitute 15% of all patents in 2006-2010, increasing from a share of 10% in the\nperiod 2001 to 2005.\nTable 3 Number and Growth of USPTO-Granted software patents by different\ndefinitions of &quot;software&quot;\nYear of Grant\n\nBessen\n(2011)\n\n1980\n1991\n1996\n2001\n2006\n2011\n\n1,804\n5,347\n9,739\n18,721\n33,527\n51,962\n\nUSPTO\n(USPC\n7XX)\n1,247\n3,990\n8,323\n15,499\n27,702\n43,604\n\nAverage annual\ngrowth 2006-11\n\n9.2\n\n9.5\n\n892\n2,811\n5,091\n9,578\n17,272\n28,705\n\nGraham &amp;\nMowery\n(2003)\n892\n2,811\n4,974\n9,240\n16,878\n28,352\n\nBessen &amp;\nHunt\n(2007)\n232\n1,381\n3,255\n7,555\n12,724\n2,1128\n\n10.7\n\n10.9\n\n10.7\n\nArora et al\n(2007)\n\nFigure 3 expands on Figure 2 by showing the detailed trend in annual grants of\nsoftware patents as a share of all patents issued by the USPTO. We observe that\nin the 1990s and early to mid-2000s, there was generally faster growth in periods\nfollowing major judicial decisions on software patentability. This is especially\napparent when the USPTO definition of software patents is used. Interestingly,\nthere was no easing of growth in the period immediately after the In re Bilski\n(2008) ruling that process claims had to pass the machine or transformation test in\norder to be patentable. While this ruling on the surface suggested that many\nsoftware processes and business methods claims would be invalidated, patent\nattorneys learned to draft software claims as machines or manufactures, rather\nthan as processes. Growth in software patents did appear to ease off slightly in\n2011, after the Bilski v Kappos decision was handed down in 2010. The Bilski\ndecision affirmed that methods and processes may qualify for patent protection,\nbut rejected method claims that are attempts to patent an abstract idea. The\n1629\n\nslowing growth of software patents in 2011 suggests that there is uncertainty over\nhow to distinguish between patentable software and business methods, and nonpatentable abstract ideas. We are mindful that it is premature at this stage to draw\nany conclusions or venture a prediction about the future growth of software\npatents based on a single data point.\n20\n\nShare of Software Patents (%)\n\n18\n\n16\n\n1980-1990\n1991-1995\n\n14\n\n1996-2000\n\n12\n\n2001-2005\n\n10\n\n2006-2010\n\n8\n6\n4\n2\n0\n\nUSPTO\n\nGraham &amp; Mowery\n\nBessen &amp; Hunt\n\nArora et al\n\nBessen (2011)\n\nFigure 2 Share of software patents in total USPTO patents by different definitions of\n&quot;software&quot;\n\nFigure 3 Share of software patents in total USPTO patents, 1990-2011\n1630\n\nTable 4 Software Patents Invented in Asia vs Major Software Producing Economies,\n1980-2011\nALL PATENTS GRANTED BY\nUSPTO (All Technologies)\nNon\nMajor\nAsia with\nJapan\nSW\nJapan\nAsia\nProd.\nTotal patents invented in\nNumber of Software Patents invented in Grouping\nGrouping\n1980-90 7,213\n57\n16,926\n4,563\n31\n11,776 155,676\n6,031\n582,677\n1991-95 8,694\n396\n15,228\n6,051\n259\n11,997 130,132 14,082 331,736\n1996-00 14,559 1,823\n38,507\n9,202\n1,079\n24,733 185,822 38,268 428,421\n2001-05 19,459 3,541\n60,005 12,034 1,896\n32,526 245,618 66,172 493,644\n2006-10 34,799 10,491 107,530 25,157 6,916\n68,487 309,858 110,575 522,938\n2011\n10,024 3,943\n32,796\n7,997\n2,893\n20,263\n80,296\n31,477 140,759\nTOTAL 94,748 20,251 270,992 65,004 13,074 169,782 1.107 m 0.267 m\n2.5 m\nSoftware USPTO (USPC\n7XX) Definition\nAsia\nNon\nMajor\nwith\nJapan\nSW\nJapan\nAsia\nProd.\n\nSoftware Arora et al.\nDefinition\nAsia\nNon\nMajor\nwith\nJapan\nSW\nJapan\nAsia\nProd.\n\nShare of Grouping in Total Software Patents Granted by USPTO (%)\n1980-90\n1991-95\n1996-00\n2001-05\n2006-10\n2011\n\n27.61\n33.66\n24.16\n21.78\n22.54\n22.99\n\n0.22\n1.53\n3.03\n3.96\n6.80\n9.04\n\n64.78\n58.96\n63.90\n67.16\n69.66\n75.21\n\n26.66\n32.11\n24.96\n22.98\n25.03\n27.86\n\n0.18\n1.37\n2.93\n3.62\n6.88\n10.07\n\n68.81\n63.67\n67.09\n62.11\n68.15\n70.59\n\nShare of Grouping in All\nPatents Granted by USPTO\n(%)\n17.98\n0.70\n67.3\n23.58\n2.55\n60.1\n24.63\n5.07\n56.8\n27.46\n7.40\n55.2\n30.96\n11.05\n52.2\n32.41\n12.71\n56.8\n\nNote 1: Major Software Producers are North America, Germany, France and United Kingdom\nNote 2: Figures refer to patents granted by USPTO in stated period, with at least one inventor from\nthe stated region\n\nSoftware Patenting in Asia\nRegion-wide trends\nThe first part of Table 4 shows the number of software patents invented in Asia in\nthe last 32 years.162 As a comparison, Table 4 also reports figures for a grouping\nof major software producing economies: North America (USA and Canada),\nGermany, France and United Kingdom. Using the USPTO definition of software\npatents, close to 95,000 software patents have been granted to inventors from\nAsia, the majority of which were granted to Japanese inventors. This compares\nagainst nearly 271,000 patents invented in the major software producers grouping.\nWhen the more restrictive Arora et al. definition is used, 65,000 software patents\nhave been granted to inventors from Asia. Strikingly, the bulk of Asia’s software\npatents were granted in the last ten years. In the Asian economies other than\n162\n\n&quot;Asia&quot; refers collectively to Japan, China, India, South Korea, Taiwan, Singapore and Hong\nKong. The South East Asian economies (eg. Thailand, Philippines) and South Asian economies (eg.\nBangladesh, Sri Lanka) are excluded as very few USPTO patents are granted to inventors from these\neconomies.\n1631\n\nJapan, more than two thirds of software patents were granted very recently, in the\nperiod spanning 2006 to 2011.\nThe respective contributions of Asia and the major software producers to the\nworld’s pool of software patents are reported in the second part of Table 4. The\ngroup of major software producers have consistently accounted for around two\nthirds of all software patents granted by the USPTO. The share of this grouping\nhas risen gradually to almost 70% in 2006-2010 and climbed to 75% in 2011\n(using the USPTO definition). In contrast, the share of Asian economies exhibits\na more dynamic trend. In the last fifteen years up to 2010, around one fifth to one\nquarter of software patents granted by the USPTO were invented in Asian\neconomies, with Japan contributing much of this share. As shown in Table 4, the\ncontribution of Asian economies to software patenting peaked in the period 19911995 and has since decreased. This lower share is mainly due to the declining\nprominence of Japan as a creator of patented software inventions. The share of\nnon-Japan Asia in software patenting has in fact increased quite substantially in\nthe last 20 years, rising from less than 2% in 1991-95 to almost 7% in the period\n2006-2010 and over 10% in 2011. However, the contribution of non-Japan Asia\nto global software patenting is still relatively small.\nWe recall from Table 2 that Asia&#x27;s share in global software spending was 12.9%\nin 2011 (8.8% excluding Japan). Comparing these figures to the last row in Table\n4, we observe that non-Japan Asia&#x27;s contribution to global software patenting is\ncomparable to its share in global software spending. However, Japan&#x27;s\ncontribution to software patenting is disproportionately higher than its level of\nsoftware spending.\nAs a further comparison, the last two columns of Table 4 report the contribution\nof each grouping to the overall stock of patents granted by the USPTO across all\ntechnology classes. In contrast to the software subset, Asia’s share in overall\npatents has increased steadily over the years. In 2006-2010, Asia-invented patents\naccounted for 31% of all USPTO patents, while Asia’s share of software patents\nwas only 22.5% (USPTO definition) or 25% (Arora et al definition). A similar\ntrend is observed when Japan is excluded. The non-Japan Asian economies\ncontributed 11% of all USPTO patents in 2006-10, but their contribution to the\npool of software patents was a more modest 6.9%. However, the contribution of\nnon-Japan Asia to total software patents rose to 10% in 2011. While still lower\nthan the region&#x27;s share in all patents (12.7%), this shows the continuing expansion\nof software patenting in non-Japan Asia. In comparison to Asia, figures for the\nmajor software producing economies reveal a directly opposite trend. The share of\nthis grouping in all patents has declined steadily, from 67% in the 1980s to 57%\nin 2011. However, this erosion in share has not taken place in the software sector,\nwhere the grouping has strengthened its competitiveness.\n\n1632\n\nTable 5 Average Annual Growth in Software Patents Invented in Asia vs Major\nSoftware Producing Economies\n\nAsia with Japan\nNon Japan Asia\nJapan\nMajor SW Prod.\nWorld\nAsia with Japan\nNon Japan Asia\nJapan\nMajor SW Prod.\nWorld\nAsia with Japan\nNon Japan Asia\nJapan\nMajor SW Prod.\nWorld\n\n19801991199620011990\n1995\n2000\n2005\nSoftware USPTO (USPC 7XX) Definition\n23.68\n12.52\n8.82\n6.53\n68.18\n27.8\n13.72\n23.48\n10.87\n6.68\n4.94\n10.28\n15.19\n20.11\n7.16\n13.04\n14.49\n17.05\n6.68\nSoftware Arora et al. Definition\n21.32\n14.35\n7.56\n-1.71\n62.66\n28.73\n6.92\n21.51\n12.18\n5.44\n4.30\n10.21\n16.07\n16.69\n-7.2\n12.37\n15.12\n14.45\n5.18\nALL USPTO PATENTS (All Technologies)\n12.7\n4.96\n10.31\n0.51\n27.78\n28.29\n22.56\n3.96\n12.13\n2.65\n7.61\n-0.69\n2.88\n2.32\n8.8\n-2.58\n4.60\n3.52\n9.09\n-2.43\n\n20062011\n15.39\n27.13\n10.75\n15.12\n14.26\n27.77\n38.21\n15.93\n29.00\n16.79\n10.01\n15.69\n7.26\n7.25\n8.04\n\nNote 1: Growth rates (%) are for patents granted by USPTO in stated period, with at least one\ninventor from the stated region\nNote 2: Major Software Producers are North America, Germany, France and United Kingdom\n\nTable 5 reports the growth of software patents invented in Asian economies\ncompared with the grouping of major software producers, using both the USPTO\nand Arora et al. definitions of software patents. In the early 1990s, very high\ngrowth rates were recorded because Asian economies other than Japan were\nstarting their patenting activities from small bases. Prior to 2005, software\npatenting in Asia as a whole tended to lag behind the global average growth rate.\nIn the period 2006-2011, growth in Asian software patenting outstripped the rest\nof the world and was almost at par with the group of major software producers. In\nparticular, non-Japan Asia has achieved extremely high growth in the last five\nyear (38% per annum using the Arora et al. definition), higher even the major\nsoftware producers (29%) that had rebounded very strongly from a downturn in\nthe previous period.\nSignificantly, Table 5 also shows that software patents are being invented and\ngranted at a faster rate than patents in other technologies, both globally and\nspecifically in Asia and the major software producing countries. The disparity\nbetween software patents growth and growth in other technologies is most\npronounced when software patents are identified using the Arora et al. definition.\nBetween 2006 and 2011, Asia’s total patent portfolio grew at 10% annually.\n1633\n\nComparably, Asia’s portfolio of software patents increased at a much higher rate\nof 27.8% annually. Similarly, software patents invented in non-Japan Asia grew\n38.2% annually in this period, compared to 15.7% growth across all technologies.\nTrends in Individual Asian Economies\nThe rapid growth in software patenting by non-Japan Asia is driven by a few key\neconomies, as shown in Figure 4. For convenience, only trends in software\npatents as defined by USPTO’s class 7XX are shown. It is noted that the trends\nusing the Arora et al. definition are very similar and the discussion herein will be\nequally applicable in that situation.\n\nNote: Figures refer to patents granted by USPTO in stated period, with at least one inventor from\nthe stated economy\n\nFigure 4 Software Patenting in Selected Asian Economies, 1990-2011(USPTO\nDefinition)\n\nAs seen Figure 4, Korea and Taiwan are the two largest producers of software\npatents in non-Japan Asia, experiencing a great acceleration that began in the\nearly 2000s and which is still being maintained, albeit at a slower rate in the case\nof Taiwan. In the mid-2000s, software patenting took off in India and China, with\nthe number of patents granted annually rising very rapidly. By 2010, India has\ncaught up to Taiwan. In 2010, Indian inventors were granted over 700 patents, the\nfigure rising to over 800 in 2011, matching the numbers granted to Taiwanese\ninventors. China also appears to be quickly catching up to Taiwan and may reach\nTaiwan’s software patents numbers within the next few years. Comparably, the\nnumber of software patents produced in Singapore and Hong Kong is relatively\nsmall.\n1634\n\nAs expected, Taiwan and Korea own the largest software patent portfolios among\nthe Asian economies excluding Japan. As seen in Table 6, Korean inventors have\nproduced 8,113 software patents using the USPTO definition (4,744 using the\nArora et al. definition) while Taiwanese inventors have been granted 5,776\nsoftware patents (3,894 using the Arora et al. definition). Comparably, Singapore\nand Hong Kong have only produced 809 (499) and 265 (137) software patents\nrespectively.\nIn most of the Asian economies, the majority of software patents in the national\nportfolio were granted in over the last five to six years. This is especially the case\nfor China and India, where recently granted patents form over 80% of the\ncountries&#x27; software patents stock.\nTable 6 Number of Software Patents Invented in Asian Economies, 1980-2011\nChina\nUp to 1990\n1991-1995\n1996-2000\n2001-2005\n2006-2010\n2011\nTOTAL\n\nIndia\nTaiwan Korea Hong Kong Singapore\nUSPTO (USPC 7XX) Definition\n5\n4\n33\n5\n8\n2\n12\n18\n116\n224\n9\n17\n32\n46\n519\n1,116\n39\n79\n174\n328\n1,328 1,493\n75\n199\n1,520\n1,869\n2,929 3,879\n99\n386\n745\n871\n851\n1396\n35\n126\n2,488\n3,136\n5,776 8,113\n265\n809\n\nUp to 1990\n1991-1995\n1996-2000\n2001-2005\n2006-2010\n2011\nTOTAL\n\n6\n10\n19\n103\n1,162\n571\n1,871\n\nArora et al. Definition\n1\n21\n1\n11\n91\n126\n33\n333\n636\n143\n821\n583\n1,327\n1,934 2,401\n605\n694\n997\n2,120\n3,894 4,744\n\n2\n9\n19\n26\n64\n17\n137\n\n12\n45\n87\n261\n94\n499\n\nJapan\n7,157\n8,302\n12,741\n15,927\n24,375\n6,118\n74,620\n4,532\n5,795\n8,116\n10,111\n18,219\n5,108\n51,881\n\nNote: Figures refer to patents granted by USPTO in stated period, with at least one inventor from\nthe stated economy\n\nGrowth in software patenting varies across the different Asian economies. The\npattern of growth also varies slightly depending on the definition of software\npatents adopted, as seen in Table 7. For the purposes of discussion, we will focus\non the USPTO definition which is more inclusive and covers a larger number of\nsoftware patents invented in Asia.\nAfter a decade of growth averaging in excess of 20% per annum, Taiwanese\nsoftware patents eased to a slower rate of 15% growth in the last six years. On the\nother hand, Korea experienced slowing growth in the early 2000s, when the\nnumber of software patents granted increased at a modest 2.5% per annum.\n1635\n\nHowever, Korea bounced back in 2006-2011 to record growth of 26% per annum,\noutstripping Taiwan.\nIn the two small NIEs of Singapore and Hong Kong, software patenting has\ngrown at comparably slower rates than the other Asia economies. Hong Kong in\nparticular has not kept pace with the rest of Asia, with annual growth slowing to\n9.8% in the last six years.\nIn the last eleven years, software patenting in China and India grew faster than all\nthe other Asian economies, reflecting the expansion of ICT industries in these two\nemerging giants. China&#x27;s growth in the period post 2005 has been especially\nstrong, almost doubling the growth rate achieved in the early to mid-2000s.\nTable 7 Average Annual Growth in Software Patents in Asian Economies\nChina\n1991-1995\n1996-2000\n2001-2005\n2006-2011\n\n31.61\n16.72\n32.45\n55.35\n\n1991-1995\n1996-2000\n2001-2005\n2006-2011\n\n7.46\n4.56\n42.13\n64.33\n\nIndia\n\nTaiwa\nKorea\nn\nUSPTO (USPC 7XX) Definition\n41.42\n31.61\n204.53\n16.27\n28.27\n29.40\n46.83\n23.90\n2.50\n39.94\n15.15\n25.75\nArora et al. Definition\n42.67\n91.68\n14.87\n25.70\n36.51\n40.63\n15.00\n0.77\n49.13\n24.88\n39.90\n\nHong\nKong\n\nSingapore\n\nJapan\n\n40.63\n12.70\n9.78\n\n56.51\n24.57\n15.50\n22.66\n\n10.87\n6.68\n4.94\n10.75\n\n8.45\n18.47\n15.94\n\n29.67\n17.84\n24.70\n\n12.18\n5.44\n4.30\n15.93\n\nNote: Growth rates are for patents granted by USPTO in stated period, with at least one inventor\nfrom the stated region\n\nThe experiences of these Asian economies contrast with Japan&#x27;s, as seen in the\nlast column of Table 7. While most of the non-Japan Asian economies recorded\nrapid expansion from the 1990s onwards, Japan&#x27;s growth rate slowed in the mid1990s to mid-2000s. From 2006 to 2011, Japan&#x27;s software patenting picked up\npace but still grew at a much slower rate than the other Asian economies\nexcepting Hong Kong. The growth trend in Japan reflects the changing approach\nto managing software IPR among Japanese companies. In the past, Japanese\ncompanies did not attach priority to software and bundled software free with\nmachines and hardware. As a result, the Japanese software industry is\nunderdeveloped compared to other technology sectors. To reverse this, and to\ncapitalize on the opportunities to grow market share in light of the global\ngravitation towards software patenting, Japanese companies began filing\nsoftware-related patents in large numbers.\n\n1636\n\nThe growth of software patenting has increased the share of software inventions\nin the national patent stocks of the Asian economies. Again, the discussion will\nfocus on software patents as defined by the USPTO&#x27;s &quot;computer implemented&quot;\ncategories. It is noted that the trends are similar when the Arora et al. definition is\nused instead.\nTable 8 Share of Software Patents in Total Patents of Asian Economies\nChina\n1980-90\n1991-95\n1996-00\n2001-05\n2006-10\n2011\n1980-90\n1991-95\n1996-00\n2001-05\n2006-10\n2011\n\nIndia\n\nTaiwan\n\nKorea\n\nUSPTO (USPC 7XX) Definition\n2.1\n2.0\n0.9\n0.5\n3.4\n8.1\n1.5\n5.3\n4.2\n7.6\n2.6\n7.8\n4.7\n16.4\n3.9\n6.9\n10.7\n37.7\n6.9\n8.5\n14.9\n48.5\n8.1\n10.4\nArora et al. Definition\n2.6\n0.5\n0.6\n0.1\n2.8\n4.9\n1.2\n3.0\n2.5\n5.5\n1.7\n4.4\n2.8\n7.2\n2.4\n2.7\n8.2\n26.7\n4.5\n5.3\n11.4\n33.7\n6.6\n7.4\n\nHong\nS&#x27;pore\nKong\n\nJapan\n\nMajor\nSW\nProd.\n\nWorld\n\n0.8\n0.8\n2.0\n2.7\n3.2\n6.7\n\n1.6\n5.8\n8.4\n7.8\n12.2\n14.1\n\n3.0\n5.0\n5.5\n5.6\n9.1\n12.5\n\n2.9\n4.6\n9.0\n12.1\n20.6\n23.3\n\n3.0\n4.7\n8.0\n10.0\n15.4\n17.6\n\n0.2\n0.8\n1.0\n0.9\n2.1\n3.2\n\n0.0\n4.1\n4.8\n3.4\n8.3\n10.5\n\n4.8\n7.1\n8.6\n8.9\n12.2\n10.4\n\n2.0\n3.6\n5.8\n6.6\n13.1\n14.4\n\n2.0\n3.4\n4.9\n5.9\n10.0\n11.6\n\nNote 1: For patents granted by USPTO in stated period, with at least one inventor from the stated\nregion\nNote 2: Major Software Producers are North America, Germany, France and United Kingdom\n\nA similar trend in observed in China and Singapore, where software patents\naccount for over 10% of recently patented inventions in these two economies,\nincreasing from 4.7% and 7.8% in the previous period 2001-05. While higher than\nthe shares of software patents in Japan, Korea and Taiwan, the shares in China\nand Singapore are still below the global average.\nThe exception to this trend among Asian economies is India. Since 2001, the\nshare of software patents in total patents granted to Indian inventors has been\nhigher than the global average. In the five year period 2006-2010, software\npatents have grown to form a substantial 37.7% of Indian-invented patents, more\nthan double the global average of 15.4%. More recent figures indicate that the\nshare of software patents in India continues to grow rapidly. Examining patents\ngranted to Indian inventors in 2011, nearly half (48.5%) are software-related,\nalmost triple the global average of 17.6%. This affirms the dominance of ICT in\nIndia&#x27;s innovation landscape and the significance of software in India&#x27;s IP creation\nactivities.\n\n1637\n\nAs shown in Table 8, software patents account for increasingly large shares of\npatents granted to inventors from the seven Asian economies. In the two large\nNIEs of Korea and Taiwan, software patents contribute 8.5% and 6.9%\nrespectively of patents granted in 2006-2010, and 10.4% and 8.1% of patents\ngranted in 2011. These figures have increased from 6.9% and 3.9% in the\nprevious five year period. Nonetheless, the share of software patents is still lower\nthan the global average of 15.4% for 2006-2010 (17.6% for 2011), and much\nlower than the 20.6% (23.3%) share in the grouping of major software producing\ncountries. We observe a similar trend in Japan, where the share of software\npatents in the national patent stock has risen substantially from 5.6% in 20012005 to 12.5% in 2011, but remains much lower than the global average. While\nJapanese, Korean and Taiwanese inventors are producing software patents in\nlarge numbers, and software patents are increasing at high growth rates, the\ncontribution of software to overall national patenting is still relatively low and has\nroom to grow.\nConclusion\nThe analysis in this paper highlights the rapid growth of global software patenting\nover the last ten years, and confirms that this global trend of increasing software\npatenting is also taking place in Asia. In fact, software patents are growing at a\nmuch faster rate in Asian economies than elsewhere. In non-Japan Asia, the\ngrowth in software patents even outpaces growth in the major software producing\ncountries. However, excluding Japan, Asian economies still contribute a relatively\nlow share of the world’s software patent stock, and with the exception of India,\nsoftware patents still form a very small proportion of national patents portfolios.\nIn this regard, the Asian economies still lag behind the advanced economies in\nsoftware patenting, albeit catching up fast.\nReferences\nArora, A., Forman, C. and Yoon, J. (2007). Software. In Jeffrey T. Macher and\nDavid C. Mowery (Eds.), Innovation in Global Industries: American Firms\nCompeting in a New World (pp 53-99). Washington DC: The National\nAcademies Press.\nBessen, J. (2011). A generation of software patents. Boston University School of\nLaw Working Paper, No. 11-31.\nBessen, J. and Hunt, R.M. (2007). An empirical look at software patents. Journal\nof Economics and Management Strategy, 16(1), 157-89.\nGraham, S. J. H. and Mowery, D.C. ( 2003). Intellectual property protection in the\nU. S. software industry. In Wesley M. Cohen and Stephen A. Merrill (Eds.),\nPatents in the Knowledge-Based Economy (pp. 219-58). National Research\nCouncil, Washington: National Academies Press,.\nHall, B. and MacGarvie, M. (2010). The private value of software patents,\nResearch Policy, 39(7), 994-1009.\n\n1638\n\nJafee, A.B. and Lerner, J. (2006). Innovation and its Discontents: How our\nBroken Patent System is Endangering Innovation and Progress, and What to\ndo About it. Princeton: Princeton University Press.\nLippoldt, D. and Stryszowski, P. (2009). Innovation in the Software Sector.\nParis: OECD Publishing.\nvon Graevenitz, G., Wagner, S. &amp; Harhoff, D. (2011). Incidence and Growth of\nPatent Thickets – The Impact of Technological Opportunities and Complexity.\nCEPR Discussion Paper number 6900. London: Centre for Economic Policy\nResearch.\n\n1639\n\nSUPPLY AND DEMAND IN SCHOLARLY\nPUBLISHING: AN ANALYSIS OF FACTORS\nASSOCIATED WITH JOURNAL ACCEPTANCE\nRATES (RIP)\nCassidy R. Sugimoto,1 Vincent Larivière2 and Blaise Cronin1\n1\n\n{sugimoto, bcronin}@indiana.edu\nSchool of Library and Information Science, Indiana University Bloomington (USA)\n2\n\nvincent.lariviere@umontreal.ca\nÉcole de bibliothéconomie et des sciences de l&#x27;information, Université de Montréal;\nObservatoire des Sciences et des Technologies (OST), Centre Interuniversitaire de\nRecherche sur la Science et la Technologie (CIRST), Université du Québec à Montréal,\nMontreal (Canada)\n\nAbstract\n\nThere are many indicators of journal quality and prestige. Although acceptance rates are\ndiscussed anecdotally, there has been little systematic exploration of the relationship\nbetween acceptance rates and other journal characteristics. This study examines such\nrelationships for a set of 1,273 journals across multiple domains. The results suggest that\nacceptance rate is indirectly correlated with citation-based indicators and directly\ncorrelated with journal age. These relationships are most pronounced in the most\nprestigious journals and vary by discipline.\n\nConference Topic\n\nScientometric Indicators (Topic 1), Old and New Data Sources for Scientometric Studies:\nCoverage, Accuracy and Reliability (Topic 2)\n\nIntroduction\nThe scholarly publication system operates on the basis of exchange. As in any\nmarket, there are suppliers (authors) and buyers (journals) of goods (papers).\nAuthors typically want their papers to appear in high profile, high prestige, high\nimpact journals. This signals the value of their goods to the marketplace and,\nultimately, increases their stock of symbolic capital (Bourdieu, 1984; Birnhotz,\n2006). By publishing high impact, highly cited, highly influential papers, a\njournal signals its worth to the marketplace and thereby reinforces its reputation\nand attractiveness to the marketplace. As a general rule, the best authors want to\npublish in the best journals, and the best journals want the best authors (those with\nthe potentially best papers) to publish with them. In a perfect (i.e., optimally\nefficient) market, the best papers would gravitate to the best journals (Oster,\n1980). But in this as so many other markets both suppliers and buyers lack perfect\ninformation. Absent perfect information, the various actors involved rely upon a\n1640\n\nrange of indicators (bibliometric, sociometric, demographic) to guide decisionmaking.\nSpace at the upper end of the market is highly sought after and in limited supply.\nCompetition and ambition often drive scholars to submit papers to journals\nbeyond their reach, creating a cascade of rejected papers that puts added pressure\non reviewers and editors (Cronin &amp; McKenzie, 1992; Kravitz &amp; Baker, 2011;\nCraig, 2010). Economic models have been proposed to analyze, inter alia,\nresearch spillover effects, duality in scientific discovery and congestion in\ninformation processing (Besancenot, Huynh, &amp; Vranceanu, 2009, p. 1). Such\nmodels highlight the “informational frictions” that occur when papers are being\nmatched with journals (Besancenot, Huynh, &amp; Vranceanu, 2009, p. 2). Peer\nreview is the established mechanism for allocating space to papers. Experts\n(editors, editorial board members and external reviewers) assess the quality of\nsubmitted papers and evaluate their suitability for publication. It is assumed that\neditors and reviewers are unbiased in their assessments and that the governing\nnorm of impartiality is not violated (Lee, Sugimoto, Zhang &amp; Cronin, 2013). In\nreality, it is not quite so straightforward, as variations in consensus as to what\nconstitutes quality, broadly conceived, within and across fields, can have an effect\non acceptance rates (Hargens, 1988; Kravitz, Franks, Feldman, Gerrity, Byrne &amp;\nTierney, 2010).\nVariation in journal acceptance rates is an understudied area, not the least because\nof the difficulty in obtaining reliable data. One of the most comprehensive studies\nto date examined the rejection rates of 83 journals across a broad spectrum of\ndisciplinary areas and found that humanities and social science journals have the\nhighest rates and the biological sciences the lowest (Zuckerman &amp; Merton, 1971,\np. 77): “the more humanistically oriented the journal, the higher the rate of\nrejecting manuscripts for publication; the more experimentally oriented, with an\nemphasis on rigour of observation and analysis, the lower the rate of rejection.”\nSubsequent monodisciplinary studies have confirmed these findings (e.g.,\nCherkashin, Demidova, Imai, &amp; Krishna, 2009; Seaton, 1975; Vlachy, 1981;\nRotton, Levitt, &amp; Foos, 1993; Schultz, 2010). One explanation of this is the\ndegree to which a dominant paradigm exists in the given discipline, providing a\nconsensus as to what constitutes valid research (Kuhn, 1970).\nThe complexity of this market exchange system and the amount of variation in\nacceptance rates raise issues of reliability and validity. It has been noted that there\nexists little guidance for computing acceptance rates (Moore &amp; Perry, 2012). At\nface value, the calculation may seem simple enough—the number of papers\naccepted over the total number of papers submitted. However, this is complicated\nby the unreliability of self-report data, the inconsistent definitions of a\nresubmission, the inclusion/exclusion of invited papers or special issues in the\ncalculations, the timeframe used, and the inclusion/exclusion of book reviews,\namong other considerations (Moore &amp; Perry, 2012). Additionally, many studies\nrely on individual surveys of editors/publishers, rather than using a standard\nsource for evaluation. Cabell’s Directories of Publishing Opportunities (Cabell’s\n1641\n\nhenceforth) is one such source, but has been used only rarely (e.g., Haensly,\nHodges, &amp; Davenport, 2008).\nAcceptance rates testify to the relative competitiveness of a journal, but have also\nbeen used as a quality measure. Significant indirect correlations between\nacceptance rates and other proxies of quality (i.e., citation rates, Journal Impact\nFactor [JIF]) have been demonstrated (Lee, Schotland, Bacchetti, &amp; Bero, 2002;\nBuffardi &amp; Nichols, 1981; Haensley, Hodges, &amp; Davenport, 2008). However, and\nwith few exceptions, these have relied on small scale and monodisciplinary\ndatasets and are somewhat dated. Rotton, Levitt, and Foos 1993) found that\nrejection rates were good predictors of citations, while Haensly, Hodges, and\nDavenport (2008) found acceptance rates to be significantly correlated with both\ncitations and survey-based rankings of journals. However, they also noted that\ncirculation was one of the most important predictors of quality (JIF, rejection\nrates, etc.). Here we examine acceptance rates for all journals listed in Cabell’s.\nThis is the largest study of acceptance rates to date and provides a crossdisciplinary analysis of the relationship between acceptance rates and other\njournal quality measures.\nTable 1. Number of unique journals and percent indexed in the JCR by discipline\nDiscipline\n\nSpecialty\n\n# of unique\njournals\n\nBusiness\n\nAccounting\nManagement\nMarketing\nEconomics and Finance\nSubtotal\nComputer Science and\nBusiness Information\nSystems\nEducational Technology and\nLibrary Science\nEducational Curriculum and\nMethods\nEducational Psychology and\nAdministration\nSubtotal\nNursing\nHealth Administration\nSubtotal\nPsychology and Psychiatry\n\nComputer\nScience\nEducation\n\nHealth\nPsychology\nTOTAL\n\n464\n1,652\n217\n1,221\n2,628\n771\n\n# of unique\njournals in\nJCR\n35\n286\n24\n285\n555\n154\n\n%\njournals\nJCR\n7.5%\n17.3%\n11.1%\n23.3%\n21.1%\n20.0%\n\n295\n\n37\n\n12.5%\n\n626\n\n108\n\n17.3%\n\n521\n\n113\n\n21.7%\n\n1,215\n235\n236\n351\n779\n5,092\n\n235\n73\n77\n118\n479\n1,348\n\n19.3%\n31.1%\n32.6%\n33.6%\n61.5%\n26.5%\n\nof\nin\n\nMethods\nWe used three main sources of data: Cabell’s, Thomson Reuters’ Journal Citation\nReports (JCR), and Ulrich’s Periodicals Directory. Cabell’s provides general\ndescriptive information about journals (Cabell’s Directories, 2012). It indexes\n1642\n\njournals in eleven specialties organized into five disciplines (Table 1). Each\njournal can be assigned to multiple specialties. New journals can be recommended\nto the directory by emailing a form to the company. Journal information is\nobtained by contacting editors and/or publishers, but is not independently\nverified.\nBasic metadata for all the journals by specialty was downloaded from Cabell’s,\nincluding acceptance rate and whether the journal was indexed in JCR. In total,\n7,015 records were downloaded for all specialties; these represented 5,092 unique\njournals, as journals appear in multiple specialties (Table 1). Of these, more than\none quarter (N=1,348) of unique journals were listed as indexed in JCR.\nThe 2011 data for both the Science and Social Sciences Journal Citation Reports\nwere downloaded from Thomson Reuters (variables collected are shown in Table\n1). However, all of these data were associated with the abbreviated name of the\njournal. A conversion table and title matching were used to match the Cabell’s\nand JCR data. The JCR data were located for 1,273 unique journals. Journals\ncould not be matched for several reasons: 1) incomplete information was provided\nin Cabell’s (e.g., the title did not include the subtitle, so could not be\ndistinguished from several journals with the same initial title); 2) no such journal\ncould be found in JCR (due either to an erroneous assumption on the part of the\neditor or because the journal had ceased to appear in JCR since the time the editor\nwas surveyed); and 3) the journal was indexed in the Humanities index of Web of\nScience for which Impact Factors are not calculated. In order to account for\ndifferent citation practices across disciplines, we also compiled field-normalized\nImpact Factors, which were obtained by dividing the impact factor of each journal\nby the average impact factor of papers published in the same discipline. Lastly,\njournal start dates were gathered from Ulrich’s Periodicals Directory using the\n“Start Year” field in the database. In the case of journal name changes, the start\ndate of the initial journal was used, not the date at which the journal became\nassociated with the current name.\nResults and Discussion\nAll 1,273 unique journals found in the JCR were analyzed (two-tailed Pearson\ncorrelation analysis) to examine the relationships between journal factors and\nacceptance rates (Table 2).\nAs can be seen, there was an indirect relationship between acceptance rates and\nall citation-related metrics—that is, when the acceptance rate decreases, the\ncitation rate tends to increase. There was a direct relationship between the number\nof articles and the acceptance rate—that is, acceptance increased as the number of\narticles in a given journal increased. There was also a direct relationship between\nstart year and acceptance rate—that is, younger journals tended to have higher\nacceptance rates. The strongest correlations were between acceptance rates and\ncited half-life and acceptance rates, article influence score and field-normalized\nIFs. There was no significant relationship between total cites; all other\nrelationships were significant at either the .05 or .01 level.\n1643\n\nTable 2. Correlations between journal measures and acceptance rates\n2011TotalCites (n=1215)\nImpactFactor (n=1213)\n5YearImpactFactor (n=1008)\nImmediacyIndex (n=1212)\n2011Articles (n=1212)\nCitedHalfLife (n=860)\nEigenfactorScore (n=1215)\nArticleInfluenceScore (n=1008)\nStartYear (n=1232)\nField normalized Impact Factor (n=1189)\n\nAcceptLow\n-.039\n-.059*\n-.098**\n-.070*\n.121**\n-.261**\n-.057*\n-.219**\n.126**\n-.193**\n\nAcceptMed\n-.045\n-0.63*\n-.106**\n-.068*\n.123**\n-.258**\n-.064*\n-.230**\n.131**\n-.204**\n\n*. Correlation is significant at the 0.05 level (2-tailed)\n**. Correlation is significant at the 0.01 level (2-tailed)\n\n163\n\nAcceptHigh\n-.052\n-.066*\n-.113**\n-.065*\n.123**\n-.251**\n-.071*\n-.236**\n.134**\n-.213**\n\nTable 3. Correlation between journal factors and median acceptance rates\nVariable\n\n1st quartile\n\nEigenfactorScore\nArticleInfluenceScore\n\n-.209** (n=304)\n-.232** (n=206)\n\nStartYear\n\n.153** (n=314)\n\n2011TotalCites\nImpactFactor\n5YearImpactFactor\nImmediacyIndex\n2011Articles\nCitedHalfLife\n\n-.175** (n=304)\n-.171** (n=304)\n-.155 (n=260)\n-.085 (n=302)\n-.080 (n=185)\n-.070 (n=185)\n\n2nd quartile\n\n.015 (n=310)\n-.097 (n=309)\n-.114 (n=271)\n-.127* (n=310)\n.048 (n=310)\n-.223**\n(n=212)\n.012 (n=310)\n-.185**\n(n=271)\n.046 (n=305)\n\n3rd quartile\n\n.021 (n=305)\n.048 (n=305)\n.075 (n=255)\n-.006 (n=305)\n.113* (n=305)\n-.065 (n=229)\n.066 (n=305)\n.027 (n=255)\n.111 (n=306)\n\n*. Correlation is significant at the 0.05 level (2-tailed)\n**. Correlation is significant at the 0.01 level (2-tailed)\n\n4th quartile\n\n-.082 (n=296)\n-.012 (n=295)\n-.023 (n=222)\n-.006 (n=295)\n.003 (n=295)\n-.214**\n(n=234)\n-.077 (n=296)\n-.017 (n=222)\n.196**\n(n=307)\n\nIn order to ensure that elite journals were not skewing the results, we divided the\njournals into quartiles by acceptance rate and analyzed each quartile (Table 3).\nThe first quartile contains those journals with the lowest acceptance rates; the\nfourth quartile those with the highest. The strongest relationships between the\nindicators and acceptance rates are in the first quartile, particularly in terms of\ncitation-based indicators, suggesting that there is a relationship between highly\ncompetitive journals (those with low acceptance rates) and high impact journals\n(those with high citation counts). However, the relationship is much more\nnuanced for less competitive journals: as shown in Table 3, very few significant\nrelationships are found below the first quartile. Interesting exceptions are the\n163\n\nAcceptance rates were given in various forms. While some editors provided an exact percentage\n(e.g., 17%) others provided a range (e.g., 10-15%). Therefore, prior to analysis, this field was\nexpanded to three: minimum, median, and maximum. For each analysis, a sensitivity analysis was\nperformed, to ensure that different results would not be achieved using one of these three.\n1644\n\nsignificance of number of articles (i.e., 2011Articles) and acceptance rate in the\n3rd quartile as well as the cited half-life and acceptance rates in the 4th quartile.\nThe relationships between journal factors and acceptance rates were also analyzed\nby discipline (Table 4). Acceptance rates are significantly indirectly correlated\nwith article influence scores across all disciplines. The five-year IF is significantly\nindirectly correlated with all disciplines, except Psychology, and the cited-half life\nis significantly indirectly correlated with all disciplines except computer science,\nwhere it is a direct relationship—suggesting perhaps that for computer science\nrigor is associated with speed. The lack of a significant relationship between\nacceptance rates and start years for computer science and business demonstrates\nthat journal age is not as important in these fields as in others. The JIF is\nsignificantly indirectly related to acceptance rates in Business, Computer Science,\nand Health, but not in Education or Psychology.\nTable 4. Relationships between journal factors and acceptance rates by discipline\nVariable\n\nBusiness\n\n2011TotalCites\n\n-.145**\n(n=510)\n-.267**\n(n=510)\n-.279**\n(n=408)\n-.223**\n(n=509)\n.067\n(n=509)\n-.166**\n(n=330)\n-.174**\n(n=510)\n-.287**\n(n=408)\n.080\n(n=523)\n\nImpactFactor\n5YearImpactFactor\nImmediacyIndex\n2011Articles\nCitedHalfLife\nEigenfactorScore\nArticleInfluenceScore\nStartYear\n\nComputer\nScience\n-.106\n(n=131)\n-.307**\n(n=131)\n-.407**\n(n=108)\n-.155\n(n=130)\n.019\n(n=130)\n.043\n(n=103)\n-.109\n(n=131)\n-.406**\n(n=108)\n.010\n(n=140)\n\nEducation\n\nHealth\n\nPsychology\n\n-.095\n(n=214)\n-.132\n(n=214)\n-.159*\n(n=186)\n-.046\n(n=213)\n.181**\n(n=213)\n-.284**\n(n=145)\n-.108\n(n=214)\n-.256**\n(n=186)\n.161*\n(n=212)\n\n-.316**\n(n=105)\n-.433**\n(n=104)\n-.453**\n(n=78)\n-.200*\n(n=105)\n-.070\n(n=105)\n-.252*\n(n=95)\n-.305**\n(n=105)\n-.485**\n(n=78)\n.213*\n(n=110)\n\n-.036\n(n=433)\n-.050\n(n=432)\n-.078\n(n=390)\n-.099*\n(n-432)\n.164**\n(n=432)\n-.326**\n(n=302)\n.001\n(n=433)\n-.152**\n(n-390)\n.181**\n(n=429)\n\nConclusions\nMost authors would like to see their work appear in a prestigious journal such as\nNature, but probabilistically that is not going to happen. In all likelihood authors\nhave an intuitive sense of how journals in their field stack up—if they don’t there\nis a growing number of discipline-specific rankings on which to rely (e.g., Harris,\n2008)—in terms of reputation and quality and will take a path somewhere\nbetween idealism and pragmatism when it comes to submitting their papers,\nneither aiming too high (waste of time and effort) nor setting their sights too low\n(bad from a career advancement perspective and for one’s morale). In any case,\n1645\n\nrejected papers, which will likely have had some value added as a result of their\nbeing subjected to peer review, will eventually find a home elsewhere, albeit at a\nlower level in the overall journal pecking order (e.g., Bornmann, Weymuth, &amp;\nDaniel, 2010; Sugimoto &amp; Cronin, 2013; Cronin, 2012), but also, sometimes, in\nhigher-end journals (Calcagno et al., 2012). Not everyone can publish in Nature;\nnot everyone should try. Unrealistic expectations, when scaled up, translate into\nsystem inefficiencies and disequilibria, which is bad news all round.\nSpace is consistently mentioned in studies of acceptance rates (e.g.,\nZuckerman &amp; Merton, 1971). In a longitudinal study, Hargens (1988) found that\nrejection rates remained stable, despite increases in submissions, thereby\nchallenging the space argument. However, our research finds a direct correlation\nbetween number of articles published per year and acceptance rates, suggesting\nthat space does in fact play some role. The issue is further complicated by the\ndramatic changes taking place to the traditional scholarly publishing business\nmodel. The introduction of author processing charges is shifting the burden of\npayment from the consumer (individual or institutional) to the author (Solomon &amp;\nBjörk, 2012). Although open access (OA) has not fundamentally altered the\nexchange of space for content, it does require us, as Suber (2008) has observed, to\nthink more closely about the relationship between journal prestige and journal\nquality in an evolving, mixed-mode publishing market, i.e., one combining toll\naccess and open access journals. As a result of accelerating developments in OA\nand the rapid adoption of alternative metrics of scholarly influence and impact\n(e.g., Cronin &amp; Sugimoto, in press) we are seeing an expansion of the indicator\nset that can be used to assess journal quality. Prestige and Journal Impact Factor\nare now only two of the indicators available to authors to evaluate journal quality\nand inform their submission behaviors (e.g., Lozano, Larivière &amp; Gingras, 2012).\nWork has also been done to explore the relationship between cost and prestige\n(eigenfactor.org, 2013). By the same token, journals can deploy a wider range of\nindicators to signal their quality to prospective authors and readers. The market\nmay still be imperfect, but it is becoming more transparent.\nReferences\nBesancenot, D., Huynh, K., &amp; Vranceanu, R. (2009). Desk rejection in an\nacademic publication market model with matching frictions. DR 09008.\nESSEC Business School.\nBirnholtz, J. (2006). What does it mean to be an author? The intersection of\ncredit, contribution and collaboration in science. Journal of the American\nSociety for Information Science and Technology, 57(13), 1758–1770.\nBornmann, L., Weymuth, C., &amp; Daniel, H. -D. (2010). A content analysis of\nreferees’ comments: How do comments on manuscripts rejected by a highimpact journal and later published in either a low- or high-impact journal\ndiffer? Scientometrics, 83, 493-506.\n\nBourdieu, P. (1984). Distinction: A social critique of the judgement of taste. Cambridge,\nMA: Harvard University Press.\n1646\n\nBuffardi, L. C., &amp; Nichols, J. A. (1981). Citation impact, acceptance rate, and\nAPA journals. American Psychologist, 36(11), 1455-1456.\nCalcagno, V., Demoinet, E., Gollner, K., Guidi, L., Ruths, D., de Mazancourt, C.\n(2012). Flows of research manuscripts among scientific journals reveal hidden\nsubmission patterns. Science, 338(6110), 1065-1069\nCherkashin, I., Demidova, S., Imai, S., &amp; Krishna, K. (2009). The inside scoop:\nAcceptance and rejection at the Journal of International Economics. Journal of\nInternational Economics, 77, 120-132.\nCraig, J. B. (2010). Desk rejection: How to avoid being hit by a returning\nboomerang. Family Business Review, 23(4), 306-309.\nCronin, B., &amp; McKenzie, G. (1992). The trajectory of rejection. Journal of\nDocumentation, 48(3), 310-317.\nCronin, B. &amp; Sugimoto, C. R. (Eds.). (in press). Bibliometrics and beyond:\nMetrics-based evaluation of scholarly research. Cambridge, MA: MIT Press.\nCronin, B. (2012). Editorial. Do me a favor. Journal of the American Society for\nInformation Science and Technology, 63(7), 1281.\nEigenfactor.org. (2013). Cost effectiveness for open access journals. Retrieved\nfrom: http://www.eigenfactor.org/openaccess/\nHaensly, P. J., Hodges, P. E., &amp; Davenport, S. A. (2008). Acceptance rates and\njournal quality: An analysis of journals in economics and finance. Journal of\nBusiness &amp; Finance Librarianship, 14(1), 2-31.\nHargens, L. L. (1988). Scholarly consensus and journal rejection rates. American\nSociological Review, 53(1), 139-151.\nHarris, C. (2008). Ranking the management journals. Journal of Scholarly\nPublishing, 39(4), 373-409.\nKravitz, D.J., &amp; Baker, C.I. (2011). Toward a new model of scientific publishing:\nDiscussion and a proposal. Frontiers in Computational Neuroscience, 5(55).\nKravitz, R. L., Franks, P., Feldman, M. D., Gerrity, M., Byrne, C., &amp; Tierney, W.\nM. (2010), Editorial peer reviewers’ recommendations at a general medical\njournal: Are they reliable and do editors care? PLoS One, 59(4), e10072.\nKuhn, T. S. (1970). The Structure of Scientific Revolutions. Chicago: University of\nChicago Press.\n\nLee, C. J., Sugimoto, C. R., Zhang, G., &amp; Cronin, B. (2013). Bias in peer review.\nJournal of the American Society for Information Science and Technology,\n64(1), 2-17.\nLee, K. P., Schotland, M., Bacchetti, P., &amp; Bero, L. A. (2002). Association of\njournal quality indicators with methodological quality of clinical research\narticles. JAMA, 287(21), 2805-2808.\nLozano, G. A., Larivière, V., &amp; Gingras, Y. (2012). The weakening relationship\nbetween the impact factor and papers’ citations in the digital age. Journal of\nthe American Society for Information Science &amp; Technology, 63(11), 21402145.\n\n1647\n\nMoore, M. A., &amp; Perry, S.D. (2012). Oughts v. Ends: Seeking an ethical\nnormative standard for journal acceptance rate calculation methods. Journal of\nAcademic Ethics, 10, 113-121.\nOster, S. (1980). The optimal order for submitting manuscripts. The American\nEconomic Review, 70(3), 444-448.\nRotton, J., Levitt, M., Foos, P. (1993). Citation impact, rejection rates, and journal\nvalues. American Psychologist, 911-912.\nSchultz, D. M. (2010). Rejection rates for journals publishing in the atmospheric\nsciences. American Meteorological Society, 231-243.\nSeaton, H. W. (1975). Education journals: Publication lags and acceptance rates.\nEducational Research, 4(4), 18-19.\nSolomon, D. J. &amp; Björk, B. C. (2012). A study of open access journals using\narticle processing charges. Journal of the American Society for Information\nScience &amp; Technology, 63(8), 1485-1495.\nSuber, P. (2008). Thinking about prestige, quality, and open access. SPARC Open\nAccess Newsletter, 125. Available online at:\nhttp://www.earlham.edu/~peters/fos/newsletter/09-02-08.htm\nVlachy, J. (1981). Refereeing and rejection patterns in physics journals.\nCzechoslovakian Journal of Physics, B31, 453-456.\nZuckerman, H. &amp; Merton, R. K. (1971). Patterns of evaluation in science:\nInstitutionalisation, structure and functions of the referee system. Minerva,\n9(1), 66-100.\n\n1648\n\nA SYSTEMATIC EMPIRICAL COMPARISON OF\nDIFFERENT APPROACHES FOR NORMALIZING\nCITATION IMPACT INDICATORS\nLudo Waltman and Nees Jan van Eck\n{waltmanlr, ecknjpvan}@cwts.leidenuniv.nl\nCentre for Science and Technology Studies, Leiden University, Leiden (The Netherlands)\n\nAbstract\n\nWe address the question how citation-based bibliometric indicators can best be\nnormalized to ensure fair comparisons between publications from different scientific\nfields and different years. In a systematic large-scale empirical analysis, we compare a\nnormalization approach based on a field classification system with three source\nnormalization approaches. We pay special attention to the selection of the publications\nincluded in the analysis. Publications in national scientific journals, popular scientific\nmagazines, and trade magazines are not included. Unlike earlier studies, we use\nalgorithmically constructed classification systems to evaluate the different normalization\napproaches. Our analysis shows that a source normalization approach based on the\nrecently introduced idea of fractional citation counting does not perform well. Two other\nsource normalization approaches generally outperform the classification-system-based\nnormalization approach that we study. Our analysis therefore offers considerable support\nfor the use of source-normalized bibliometric indicators.\n\nConference Topic\n\nScientometrics Indicators (Topic 1).\n\nIntroduction\nCitation-based bibliometric indicators have become a more and more popular tool\nfor research assessment purposes. In practice, there often turns out to be a need to\nuse these indicators not only for comparing researchers, research groups,\ndepartments, or journals active in the same scientific field or subfield but also for\nmaking comparisons across fields. Performing between-field comparisons is a\ndelicate issue. Each field has its own publication, citation, and authorship\npractices, making it difficult to ensure the fairness of between-field comparisons.\nIn some fields, researchers tend to publish a lot, often as part of larger\ncollaborative teams. In other fields, collaboration takes place only at relatively\nsmall scales, usually involving no more than a few researchers, and the average\npublication output per researcher is significantly lower. Also, in some fields,\npublications tend to have long reference lists, with many references to recent\nwork. In other fields, reference lists may be much shorter, or they may point\nmainly to older work. In the latter fields, publications on average will receive only\n\n1649\n\na relatively small number of citations, while in the former fields, the average\nnumber of citations per publication will be much larger.\nIn this paper, we address the question how citation-based bibliometric indicators\ncan best be normalized to correct for differences in citation practices between\nscientific fields. Hence, we aim to find out how citation impact can be measured\nin a way that allows for the fairest between-field comparisons.\nIn recent years, a significant amount of attention has been paid to the problem of\nnormalizing citation-based bibliometric indicators. Basically, two streams of\nresearch can be distinguished in the literature. One stream of research is\nconcerned with normalization approaches that use a field classification system to\ncorrect for differences in citation practices between scientific fields. In these\nnormalization approaches, each publication is assigned to one or more fields and\nthe citation impact of a publication is normalized by comparing it with the field\naverage. Research into classification-system-based normalization approaches\nstarted in the late 1980s and the early 1990s. Recent contributions to this line of\nresearch were made by, among others, Crespo, Herranz, Li, and Ruiz-Castillo\n(2012), Crespo, Li, and Ruiz-Castillo (2012), Radicchi and Castellano (2012c),\nRadicchi, Fortunato, and Castellano (2008), and Van Eck, Waltman, Van Raan,\nKlautz, and Peul (2012).\nThe second stream of research studies normalization approaches that correct for\ndifferences in citation practices between fields based on the referencing behavior\nof citing publications or citing journals. These normalization approaches do not\nuse a field classification system. The second stream of research was initiated by\nZitt and Small (2008), who introduced the audience factor, an interesting new\nindicator of the citation impact of scientific journals. Other contributions to this\nstream of research were made by Glänzel, Schubert, Thijs, and Debackere (2011),\nLeydesdorff and Bornmann (2011), Leydesdorff and Opthof (2010), Leydesdorff,\nZhou, and Bornmann (2013), Moed (2010), Waltman and Van Eck (in press),\nWaltman, Van Eck, Van Leeuwen, and Visser (2013), Zhou and Leydesdorff\n(2011), and Zitt (2010, 2011). Zitt and Small referred to their proposed\nnormalization approach as ‘fractional citation weighting’ or ‘citing-side\nnormalization’. Alternative labels introduced by other authors include ‘source\nnormalization’ (Moed, 2010), ‘fractional counting of citations’ (Leydesdorff &amp;\nOpthof, 2010), and ‘a priori normalization’ (Glänzel et al., 2011). Following our\nearlier work (Waltman &amp; Van Eck, in press; Waltman et al., 2013), we will use\nthe term ‘source normalization’ in this paper.\nWhich normalization approach performs best is still an open issue. Systematic\nlarge-scale empirical comparisons of normalization approaches are scarce, and as\nwe will see, such comparisons involve significant methodological challenges.\nStudies in which normalization approaches based on a field classification system\nare compared with source normalization approaches have been reported by\nLeydesdorff, Radicchi, Bornmann, Castellano, and De Nooy (in press) and\nRadicchi and Castellano (2012a). In these studies, classification-system-based\nnormalization approaches were found to be more accurate than source\n1650\n\nnormalization approaches. However, as we will point out later on, these studies\nhave important methodological limitations. In an earlier paper, we have compared\na classification-system-based normalization approach with a number of source\nnormalization approaches (Waltman &amp; Van Eck, in press). The comparison was\nperformed in the context of assessing the citation impact of scientific journals,\nand the results seemed to be in favor of some of the source normalization\napproaches. However, because of the somewhat non-systematic character of the\ncomparison, the results must be considered of a tentative nature.\nBuilding on our earlier work (Waltman &amp; Van Eck, in press), we present in this\npaper a systematic large-scale empirical comparison of normalization approaches.\nThe comparison involves one normalization approach based on a field\nclassification system and three source normalization approaches. In the\nclassification-system-based normalization approach, publications are classified\ninto fields based on the journal subject categories in the Web of Science\nbibliographic database. The source normalization approaches that we consider are\nbased on the audience factor approach of Zitt and Small (2008), the fractional\ncitation counting approach of Leydesdorff and Opthof (2010), and our own\nrevised SNIP approach (Waltman et al., 2013).\nOur methodology for comparing normalization approaches has three important\nfeatures not present in earlier work by other authors. First, rather than simply\nincluding all publications available in a bibliographic database in a given time\nperiod, we exclude as much as possible publications that could distort the\nanalysis, such as publications in national scientific journals, popular scientific\nmagazines, and trade magazines. Second, in the evaluation of the classificationsystem-based normalization approach, we use field classification systems that are\ndifferent from the classification system used by the normalization approach itself.\nIn this way, we ensure that our results do not suffer from a bias that favors\nclassification-system-based normalization approaches over source normalization\napproaches. Third, we compare normalization approaches at different levels of\ngranularity, for instance both at the level of broad scientific disciplines and at the\nlevel of smaller scientific subfields. As we will see, some normalization\napproaches perform well at one level but not so well at another level.\nThe organization of this paper is as follows. We first discuss the data that we use\nin our analysis, and we then introduce the normalization approaches that we\nstudy. Next, we present the results of our analysis, and finally, we summarize our\nconclusions. We note that a more extensive version of this paper is available\nonline (Waltman &amp; Van Eck, 2013).\nData\nOur analysis is based on data from the Web of Science (WoS) bibliographic\ndatabase. We use the Science Citation Index Expanded, the Social Sciences\nCitation Index, and the Arts &amp; Humanities Citation Index. The data that we work\nwith is from the period 2003–2011.\n\n1651\n\nThe WoS database is continuously expanding. Nowadays, the database contains a\nsignificant number of special types of sources, such as scientific journals with a\nstrong national or regional orientation, trade magazines (e.g., Genetic Engineering\n&amp; Biotechnology News, Naval Architect, and Professional Engineering), business\nmagazines (e.g., Forbes and Fortune), and popular scientific magazines (e.g.,\nAmerican Scientist, New Scientist, and Scientific American). As we have argued in\nan earlier paper (Waltman &amp; Van Eck, 2012), a normalization for differences in\ncitation practices between scientific fields may be distorted by the presence of\nthese special types of sources in one’s database. For this reason, we do not simply\ninclude all WoS-indexed publications in our analysis. Instead, we include only\npublications from selected sources, which we refer to as WoS core journals. In\nthis way, we intend to restrict our analysis to the international scientific literature\ncovered by the WoS database. The details of our procedure for selecting\npublications in WoS core journals are discussed in Appendix A in the more\nextensive version of this paper (Waltman &amp; Van Eck, 2013). Of the 9.79 million\nWoS-indexed publications of the document types article and review in the period\n2003–2011, there are 8.20 million that are included in our analysis.\nIn the rest of this paper, the term ‘publication’ always refers to our selected\npublications in WoS core journals. Also, when we use the term ‘citation’ or\n‘reference’, both the citing and the cited publication are assumed to belong to our\nset of selected publications in WoS core journals. Hence, citations originating\nfrom non-selected publications or references pointing to non-selected publications\nplay no role in our analysis.\nTable 1. Summary statistics for each of the four field classification systems.\n\nWoS\nsubject\ncategories\nClassification\nsystem A\nClassification\nsystem B\nClassification\nsystem C\n\nNo. of\nareas\n235\n\nNumber of publications per area (2007–2010)\nMean\nMedian\nMinimum\nMaximum\n27,524\n16,448\n94\n191,790\n\n21\n\n182,133\n\n137,548\n\n49,577\n\n635,209\n\n161\n\n23,757\n\n19,085\n\n4,800\n\n69,816\n\n1,334\n\n2,867\n\n2,421\n\n820\n\n12,037\n\nThe analysis that we perform focuses on calculating the citation impact of\npublications from the period 2007–2010. There are 3.86 million publications in\nthis period. For each publication, citations are counted until the end of 2011.\nWe use four different field classification systems in our analysis. One is the wellknown system based on the WoS journal subject categories. In this system, a\npublication can belong to multiple research areas. The other three classification\nsystems have been constructed algorithmically based on citation relations between\npublications. These classification systems, referred to as classification systems A,\n1652\n\nB, and C, differ from each other in their level of granularity. Classification system\nA is the least detailed system and consists of only 21 research areas.\nClassification system C, which includes 1,334 research areas, is the most detailed\nsystem. In classification systems A, B, and C, a publication can belong to only\none research area. We refer to Appendix B in the more extensive version of this\npaper (Waltman &amp; Van Eck, 2013) for a discussion of the methodology that we\nhave used for constructing classification systems A, B, and C. The methodology\nis largely based on an earlier paper (Waltman &amp; Van Eck, 2012).\nTable 1 provides some summary statistics for each of our four field classification\nsystems. These statistics relate to the period 2007–2010.\nNormalization approaches\nAs already mentioned, we study four normalization approaches in this paper, one\nbased on a field classification system and three based on the idea of source\nnormalization. In addition to correcting for differences in citation practices\nbetween scientific fields, we also want our normalization approaches to correct\nfor the age of a publication. Recall that our focus is on calculating the citation\nimpact of publications from the period 2007–2010 based on citations counted\nuntil the end of 2011. This means that an older publication, for instance from\n2007, has a longer citation window than a more recent publication, for instance\nfrom 2010. To be able to make fair comparisons between publications from\ndifferent years, we therefore need a correction for the age of a publication.\nWe start by introducing our classification-system-based normalization approach.\nIn this approach, we calculate for each publication a normalized citation score\n(NCS). The NCS value of a publication is given by\n\nNCS \n\nc\ne\n\n(1)\n\nwhere c denotes the number of citations of the publication and e denotes the\naverage number of citations of all publications in the same field and in the same\nyear. Interpreting e as a publication’s expected number of citations, the NCS\nvalue of a publication is simply given by the ratio of the actual and the expected\nnumber of citations of the publication. An NCS value above (below) one indicates\nthat the number of citations of a publication is above (below) what would be\nexpected based on the field and the year in which the publication appeared.\nTo determine a publication’s expected number of citations e in (1), we need a\nfield classification system. In practical applications of the classification-systembased normalization approach, the journal subject categories in the WoS database\nare often used for this purpose. We also use the WoS subject categories in this\npaper.\nWe now turn to the three source normalization approaches that we study. In these\napproaches, a source normalized citation score (SNCS) is calculated for each\npublication. Since we have three source normalization approaches, we distinguish\n1653\n\nbetween the SNCS(1), the SNCS(2), and the SNCS(3) value of a publication. The\ngeneral idea of the three source normalization approaches is to weight each\ncitation received by a publication based on the referencing behavior of the citing\npublication or the citing journal. The three source normalization approaches differ\nfrom each other in the exact way in which the weight of a citation is determined.\nAn important concept in the case of all three source normalization approaches is\nthe notion of an active reference (Zitt &amp; Small, 2008). In our analysis, an active\nreference is defined as a reference that falls within a certain reference window and\nthat points to a publication in a WoS core journal. For instance, in the case of a\nfour-year reference window, the number of active references in a publication from\n2008 equals the number of references in this publication that point to publications\nin WoS core journals in the period 2005–2008. References to sources not covered\nby the WoS database or to WoS-indexed publications in non-core journals do not\ncount as active references.\nThe SNCS(1) value of a publication is calculated as\n\nSNCS\n\n(1)\n\nc\n\n\ni 1\n\n1\nai\n\n(2)\n\nwhere ai denotes the average number of active references in all publications that\nappeared in the same journal and in the same year as the publication from which\nthe ith citation originates. The length of the reference window within which active\nreferences are counted equals the length of the citation window of the publication\nfor which the SNCS(1) value is calculated. The following example illustrates the\ndefinition of ai. Suppose that we want to calculate the SNCS(1) value of a\npublication from 2008, and suppose that the ith citation received by this\npublication originates from a citing publication from 2010. Since the publication\nfor which the SNCS(1) value is calculated has a four-year citation window (i.e.,\n2008–2011), ai equals the average number of active references in all publications\nthat appeared in the citing journal in 2010, where active references are counted\nwithin a four-year reference window (i.e., 2007–2010). The SNCS(1) approach is\nbased on the idea of the audience factor of Zitt and Small (2008), although it\napplies this idea to an individual publication rather than an entire journal. Unlike\nthe audience factor, the SNCS(1) approach uses multiple citing years.\nThe SNCS(2) approach is similar to the SNCS(1) approach, but instead of the\naverage number of active references in a citing journal it looks at the number of\nactive references in a citing publication. In mathematical terms,\nc\n\nSNCS ( 2)  \ni 1\n\n1\nri\n\n(3)\n\nwhere ri denotes the number of active references in the publication from which\nthe ith citation originates. Analogous to the SNCS(1) approach, the length of the\n1654\n\nreference window within which active references are counted equals the length of\nthe citation window of the publication for which the SNCS(2) value is calculated.\nThe SNCS(2) approach is based on the idea of fractional citation counting of\nLeydesdorff and Opthof (2010; see also Leydesdorff &amp; Bornmann, 2011;\nLeydesdorff et al., in press; Leydesdorff et al., 2013; Zhou &amp; Leydesdorff, 2011).\nHowever, a difference with the fractional citation counting idea of Leydesdorff\nand Opthof is that instead of all references in a citing publication only active\nreferences are counted. This is a quite important difference. Counting all\nreferences rather than active references only disadvantages fields in which a\nrelatively large share of the references point to older literature, to sources not\ncovered by the WoS database, or to WoS-indexed publications in non-core\njournals.\nThe SNCS(3) approach, the third source normalization approach that we consider,\ncombines ideas of the SNCS(1) and SNCS(2) approaches. The SNCS(3) value of a\npublication equals\n\nSNCS\n\n( 3)\n\nc\n\n\ni 1\n\n1\npi ri\n\n(4)\n\nwhere ri is defined in the same way as in the SNCS(2) approach and where pi\ndenotes the proportion of publications with at least one active reference among all\npublications that appeared in the same journal and in the same year as the ith\nciting publication. Comparing (3) and (4), it can be seen that the SNCS (3)\napproach is identical to the SNCS(2) approach except that pi has been added to the\ncalculation. By including pi, the SNCS(3) value of a publication depends not only\non the referencing behavior of citing publications (like the SNCS(2) value) but also\non the referencing behavior of citing journals (like the SNCS(1) value). The\nrationale for including pi is that some fields have more publications without active\nreferences than others, which may distort the normalization implemented in the\nSNCS(2) approach. For a more extensive discussion of this issue, we refer to\nWaltman et al. (2013), who present a revised version of the SNIP indicator\noriginally introduced by Moed (2010). The SNCS(3) approach is based on similar\nideas as this revised SNIP indicator, although in the SNCS(3) approach these ideas\nare applied to individual publications while in the revised SNIP indicator they are\napplied to entire journals. Also, the SNCS(3) approach uses multiple citing years,\nwhile the revised SNIP indicator uses a single citing year.\nResults\nWe split the discussion of the results of our analysis in two subsections. In the\nfirst subsection, we present results that were obtained by using the WoS journal\nsubject categories to evaluate the normalization approaches introduced in the\nprevious section. We then argue that this way of evaluating the different\nnormalization approaches is likely to produce biased results. In the second\n1655\n\nsubsection, we use our algorithmically constructed classification systems A, B,\nand C instead of the WoS subject categories. We argue that this yields a fairer\ncomparison of the different normalization approaches.\nResults based on the Web of Science journal subject categories\nBefore presenting our results, we need to discuss how publications belonging to\nmultiple WoS subject categories were handled. In the approach that we have\ntaken, each publication is fully assigned to each of the subject categories to which\nit belongs. This means that some publications occur multiple times in the analysis,\nonce for each of the subject categories to which they belong. Because of this, the\ntotal number of publications in the analysis is 6.47 million.\nTable 2 reports for each year in the period 2007–2010 the average normalized\ncitation score of all publications from that year, where normalized citation scores\nhave been calculated using each of the four normalization approaches introduced\nin the previous section. The average citation score (CS) without normalization is\nreported as well. As expected, unnormalized citation scores display a decreasing\ntrend over time. This can be explained by the lack of a correction for the age of\npublications. Table 2 also lists the number of publications per year. Notice that\neach year the number of publications is 3% to 5% larger than the year before.\nTable 2. Average normalized citation score per year calculated using four different\nnormalization approaches and the unnormalized CS approach. The citation scores\nare based on the 6.47 million publications included in the WoS journal subject\ncategories classification system.\nNo. of publications\nCS\nNCS\nSNCS(1)\nSNCS(2)\nSNCS(3)\n\n2007\n1.51M\n10.78\n1.01\n1.10\n1.03\n1.10\n\n2008\n1.59M\n8.16\n1.01\n1.07\n0.97\n1.07\n\n2009\n1.66M\n5.50\n1.02\n1.07\n0.89\n1.07\n\n2010\n1.71M\n2.70\n1.02\n1.05\n0.68\n1.05\n\nBased on Table 2, we make the following observations:\n Each year, the average NCS value is slightly above one. This is a\nconsequence of the fact that publications belonging to multiple subject\ncategories are counted multiple times. Average NCS values of exactly\none would have been obtained if there had been no publications that\nbelong to more than one subject category.\n The average SNCS(2) value decreases considerably over time. The value\nin 2010 is more than 30% lower than the value in 2007. This shows that\nthe SNCS(2) approach fails to properly correct for the age of a publication.\nRecent publications have a significant disadvantage compared with older\nones. This is caused by the fact that in the SNCS(2) approach publications\nwithout active references give no ‘credits’ to earlier publications (see also\n1656\n\nWaltman &amp; Van Eck, in press; Waltman et al., 2013). In this way, the\nbalance between publications that provide credits and publications that\nreceive credits is distorted. This problem is most serious for recent\npublications. In the case of recent publications, the citation and reference\nwindows used in the calculation of SNCS(2) values are relatively short,\nand the shorter the length of the reference window within which active\nreferences are counted, the larger the number of publications without\nactive references.\n The SNCS(1) and SNCS(3) approaches yield the same average values per\nyear. These values are between 5% and 10% above one (see also\nWaltman &amp; Van Eck, in press), with a small decreasing trend over time.\nAverage SNCS(1) and SNCS(3) values very close to one would have been\nobtained if there had been no increase in the yearly number of\npublications (for more details, see Waltman &amp; Van Eck, 2010; Waltman\net al., 2013). The sensitivity of source normalization approaches to the\ngrowth rate of the scientific literature was already pointed out by Zitt and\nSmall (2008).\nTable 2 provides some insight into the degree to which the different normalization\napproaches succeed in correcting for the age of publications. However, the table\ndoes not show to what extent each of the normalization approaches manages to\ncorrect for differences in citation practices between scientific fields. This raises\nthe question when exactly we can say that differences in citation practices\nbetween fields have been corrected for. With respect to this question, we follow a\nnumber of recent papers (Crespo, Herranz, et al., 2012; Crespo, Li, et al., 2012;\nRadicchi &amp; Castellano, 2012a, 2012c; Radicchi et al., 2008). In line with these\npapers, we say that the degree to which differences in citation practices between\nfields have been corrected for is indicated by the degree to which the normalized\ncitation distributions of different fields coincide with each other. Differences in\ncitation practices between fields have been perfectly corrected for if, after\nnormalization, each field is characterized by exactly the same citation distribution.\nNotice that correcting for the age of publications can be defined in an analogous\nway. We therefore say that publication age has been corrected for if different\npublication years are characterized by the same normalized citation distribution.\nThe next question is how the similarity of citation distributions can best be\nassessed. To address this question, we follow an approach that was recently\nintroduced by Crespo, Herranz, et al. (2012) and Crespo, Li, et al. (2012). For\neach of the four normalization approaches that we study, we take the following\nsteps:\n1. Calculate each publication’s normalized citation score.\n2. For each combination of a publication year and a subject category, assign\npublications to quantile intervals based on their normalized citation score.\nWe work with 100 quantile (or percentile) intervals. Publications are\nsorted in ascending order of their normalized citation score, and the first\n1% of the publications are assigned to the first quantile interval, the next\n1657\n\n1% of the publications are assigned to the second quantile interval, and so\non.\n3. For each combination of a publication year, a subject category, and a\nquantile interval, calculate the number of publications and the average\nnormalized citation score per publication. We use n(q, i, j) and μ(q, i, j) to\ndenote, respectively, the number of publications and the average\nnormalized citation score for publication year i, subject category j, and\nquantile interval q.\n4. For each quantile interval, determine the degree to which publication age\nand differences in citation practices between fields have been corrected\nfor. To do so, we calculate for each quantile interval q the inequality\nindex I(q) defined by\n\nI (q) \n\n1 2010 m\n ( q , i , j )   ( q, i , j ) \n\nn( q , i , j )\nlog\n\n\nn(q) i2007 j 1\n (q)\n  (q) \n\n(5)\n\nwhere m denotes the number of subject categories, n(q) denotes the\nnumber of publications in quantile interval q aggregated over all\npublication years and subject categories, and μ(q) denotes the average\nnormalized citation score of these publications. The inequality index I(q)\nin (5) is known as the Theil index. We refer to Crespo, Li, et al. (2012)\nfor a justification for the use of this index. The lower the value of the\nindex, the better the correction for publication age and field differences.\nA perfect normalization approach would result in I(q) = 0 for each\nquantile interval q. In the calculation of I(q) in (5), we use natural\nlogarithms and we define 0 log(0) = 0. Notice that I(q) is not defined if\nμ(q) = 0.\nWe perform the above steps for each of our four normalization approaches.\nMoreover, for the purpose of comparison, we perform the same steps also for\ncitation scores without normalization.\nThe results of the above calculations are presented in Figure 1. For each of our\nfour normalization approaches, the figure shows the value of I(q) for each of the\n100 quantile intervals. For comparison, I(q) values calculated based on\nunnormalized citation scores are displayed as well. Notice that the vertical axis in\nFigure 1 has a logarithmic scale.\nAs expected, Figure 1 shows that all four normalization approaches yield better\nresults than the approach based on unnormalized citation scores. For all or almost\nall quantile intervals, the latter approach, referred to as the CS approach in Figure\n1, yields the highest I(q) values. It can further be seen that the NCS approach\nsignificantly outperforms all three SNCS approaches. Hence, in line with recent\nstudies by Leydesdorff et al. (in press) and Radicchi and Castellano (2012a),\nFigure 1 suggests that classification-system-based normalization is more accurate\nthan source normalization. Comparing the different SNCS approaches, we see that\n1658\n\nthe SNCS(2) approach is outperformed by the SNCS(1) and SNCS(3) approaches.\nNotice further that for all normalization approaches I(q) values are highest for the\nlowest quantile intervals. These quantile intervals include many uncited and very\nlowly cited publications. From the point of view of the normalization of citation\nscores, these quantile intervals may be considered of less interest, and it may be\nbest to focus mainly on the higher quantile intervals.\n\nFigure 1. Inequality index I(q) calculated for 100 quantile intervals q and for four\ndifferent normalization approaches. Results calculated for the unnormalized CS\napproach are displayed as well. All results are based on the WoS journal subject\ncategories classification system.\n\nThe above results may seem to provide clear evidence for preferring\nclassification-system-based normalization over source normalization. However,\nthere may be a bias in the results that causes the NCS approach to have an unfair\nadvantage over the three SNCS approaches. The problem is that the WoS subject\ncategories are used not only in the evaluation of the different normalization\napproaches but also in the implementation of one of these approaches, namely the\nNCS approach. The standard used to evaluate the normalization approaches\nshould be completely independent of the normalization approaches themselves,\nbut for the NCS approach this is not the case. Because of this, the above results\nmay be biased in favor of the NCS approach. In the next subsection, we therefore\nuse our algorithmically constructed classification systems A, B, and C to evaluate\nthe different normalization approaches in a fairer way.\nBefore proceeding to the next subsection, we note that the above-mentioned\nstudies by Leydesdorff et al. (in press) and Radicchi and Castellano (2012a) suffer\nfrom the same problem as our above results. In these studies, the same\n1659\n\nclassification system is used both in the implementation and in the evaluation of a\nclassification-system-based normalization approach. This is likely to introduce a\nbias in favor of this normalization approach. This problem was first pointed out\nby Sirtes (2012) in a comment on Radicchi and Castellano’s (2012a) study (for\nthe rejoinder, see Radicchi &amp; Castellano, 2012b).\n\nFigure 2. Inequality index I(q) calculated for 100 quantile intervals q and for four\ndifferent normalization approaches. Results calculated for the unnormalized CS\napproach are displayed as well. All results are based on classification system C.\n\nResults based on classification systems A, B, and C\nWe now present the results obtained by using the algorithmically constructed\nclassification systems A, B, and C to evaluate the four normalization approaches\nthat we study. As we have argued above, this yields a fairer comparison of the\ndifferent normalization approaches than an evaluation using the WoS subject\ncategories. In classification systems A, B, and C, each publication belongs to only\none research area.\nWe examine the degree to which, after applying one of our four normalization\napproaches, different fields and different publication years are characterized by\nthe same citation distribution. To assess the similarity of citation distributions, we\ntake the same steps as described in the previous subsection, but with fields\ndefined by research areas in our classification systems A, B, and C rather than by\nWoS subject categories. The results obtained for classification system C are\nshown in Figure 2. Due to space limitations, the results obtained for classification\nsystems A and B are not shown. However, these results can be found in Figures 2\nand 3 in the extended version of this paper (Waltman &amp; Van Eck, 2013).\n\n1660\n\nThe following observations can be made based on Figure 2 combined with\nFigures 2 and 3 in the extended version of this paper:\n Like in Figure 1, the CS approach, which does not involve any\nnormalization, is outperformed by all four normalization approaches.\n The results presented in Figure 1 are indeed biased in favor of the NCS\napproach. Compared with Figure 1, the performance of the NCS approach\nin Figure 2 is disappointing. In the case of classification systems B and C,\nthe NCS approach is significantly outperformed by both the SNCS(1) and\nthe SNCS(3) approach. In the case of classification system A, the NCS\napproach performs better, although it is still outperformed by the SNCS(1)\napproach.\n Like in Figure 1, the SNCS(2) approach is consistently outperformed by\nthe SNCS(3) approach. In the case of classification systems A and B, the\nSNCS(2) approach is also outperformed by the SNCS(1) approach. It is\nclear that the disappointing performance of the SNCS(2) approach must at\nleast partly be due to the failure of this approach to properly correct for\npublication age, as we have already seen in Table 2.\n The SNCS(1) approach has a mixed performance. It performs very well in\nthe case of classification system A, but not so well in the case of\nclassification system C. The SNCS(3) approach, on the other hand, has a\nvery good performance in the case of classification systems B and C, but\nthis approach is outperformed by the SNCS(1) approach in the case of\nclassification system A.\nThe overall conclusion is that in order to obtain the most accurate normalized\ncitation scores one should generally use a source normalization approach rather\nthan a normalization approach based on the WoS subject categories classification\nsystem. However, consistent with our earlier work (Waltman &amp; Van Eck, in\npress), it can be concluded that the SNCS(2) approach should not be used.\nFurthermore, the SNCS(3) approach appears to be preferable over the SNCS(1)\napproach. The excellent performance of the SNCS(3) approach in the case of\nclassification system C (see Figure 2) suggests that this approach is especially\nwell suited for fine-grained analyses aimed for instance at comparing researchers\nor research groups active in different subfields within the same field.\nSome more detailed results are presented in Appendix C in the more extensive\nversion of this paper (Waltman &amp; Van Eck, 2013). In this appendix, we use a\ndecomposition of citation inequality proposed by Crespo, Herranz, et al. (2012)\nand Crespo, Li, et al. (2012) to summarize in a single number the degree to which\neach of our normalization approaches has managed to correct for differences in\ncitation practices between fields and differences in the age of publications.\nConclusions\nIn this paper, we have addressed the question how citation-based bibliometric\nindicators can best be normalized to ensure fair comparisons between publications\nfrom different scientific fields and different years. In a systematic large-scale\n1661\n\nempirical analysis, we have compared a normalization approach based on a field\nclassification system with three source normalization approaches. In the\nclassification-system-based normalization approach, we have used the WoS\njournal subject categories to classify publications into fields. The three source\nnormalization approaches are inspired by the audience factor of Zitt and Small\n(2008), the idea of fractional citation counting of Leydesdorff and Opthof (2010),\nand our own revised SNIP indicator (Waltman et al., 2013).\nCompared with earlier studies, our analysis offers three methodological\ninnovations. Most importantly, we have distinguished between the use of a field\nclassification system in the implementation and in the evaluation of a\nnormalization approach. Following Sirtes (2012), we have argued that the\nclassification system used in the evaluation of a normalization approach should be\ndifferent from the one used in the implementation of the normalization approach.\nWe have demonstrated empirically that the use of the same classification system\nin both the implementation and the evaluation of a normalization approach leads\nto significantly biased results. Building on our earlier work (Waltman &amp; Van Eck,\nin press), another methodological innovation is the exclusion of special types of\npublications, for instance publications in national scientific journals, popular\nscientific magazines, and trade magazines. A third methodological innovation is\nthe evaluation of normalization approaches at different levels of granularity. As\nwe have shown, some normalization approaches perform better at one level than\nat another.\nBased on our empirical results and in line with our earlier work (Waltman &amp; Van\nEck, in press), we advise against using source normalization approaches that\nfollow the fractional citation counting idea of Leydesdorff and Opthof (2010).\nThe fractional citation counting idea does not offer a completely satisfactory\nnormalization (see also Waltman et al., 2013). In particular, we have shown that it\nfails to properly correct for the age of a publication. The other two source\nnormalization approaches that we have studied generally perform better than the\nclassification-system-based normalization approach based on the WoS subject\ncategories, especially at higher levels of granularity. It may be that other\nclassification-system-based normalization approaches, for instance based on\nalgorithmically constructed classification systems, have a better performance than\nsubject-category-based normalization. However, any classification system can be\nexpected to introduce certain biases in a normalization, simply because any\norganization of the scientific literature into a number of perfectly separated fields\nof science is artificial. So consistent with our previous study (Waltman &amp; Van\nEck, in press), we recommend the use of a source normalization approach. Except\nat very low levels of granularity (e.g., comparisons between broad disciplines),\nthe approach based on our revised SNIP indicator (Waltman et al., 2013) turns out\nto be more accurate than the approach based on the audience factor of Zitt and\nSmall (2008). Of course, when using a source normalization approach, it should\nalways be kept in mind that there are certain factors, such as the growth rate of the\nscientific literature, for which no correction is made.\n1662\n\nReferences\nCrespo, J.A., Herranz, N., Li, Y., &amp; Ruiz-Castillo, J. (2012). Field normalization\nat different aggregation levels (Working Paper Economic Series 12-22).\nDepartamento de Economía, Universidad Carlos III of Madrid.\nCrespo, J.A., Li, Y., &amp; Ruiz-Castillo, J. (2012). Differences in citation impact\nacross scientific fields (Working Paper Economic Series 12-06). Departamento\nde Economía, Universidad Carlos III of Madrid.\nGlänzel, W., Schubert, A., Thijs, B., &amp; Debackere, K. (2011). A priori vs. a\nposteriori normalisation of citation indicators. The case of journal ranking.\nScientometrics, 87(2), 415–424.\nLeydesdorff, L., &amp; Bornmann, L. (2011). How fractional counting of citations\naffects the impact factor: Normalization in terms of differences in citation\npotentials among fields of science. Journal of the American Society for\nInformation Science and Technology, 62(2), 217–229.\nLeydesdorff, L., &amp; Opthof, T. (2010). Scopus’s source normalized impact per\npaper (SNIP) versus a journal impact factor based on fractional counting of\ncitations. Journal of the American Society for Information Science and\nTechnology, 61(11), 2365–2369.\nLeydesdorff, L., Radicchi, F., Bornmann, L., Castellano, C., &amp; De Nooy, W. (in\npress). Field-normalized impact factors: A comparison of rescaling versus\nfractionally counted IFs. Journal of the American Society for Information\nScience and Technology.\nLeydesdorff, L., Zhou, P., &amp; Bornmann, L. (2013). How can journal impact\nfactors be normalized across fields of science? An assessment in terms of\npercentile ranks and fractional counts. Journal of the American Society for\nInformation Science and Technology, 64(1), 96–107.\nMoed, H.F. (2010). Measuring contextual citation impact of scientific journals.\nJournal of Informetrics, 4(3), 265–277.\nRadicchi, F., &amp; Castellano, C. (2012a). Testing the fairness of citation indicators\nfor comparison across scientific domains: The case of fractional citation\ncounts. Journal of Informetrics, 6(1), 121–130.\nRadicchi, F., &amp; Castellano, C. (2012b). Why Sirtes’s claims (Sirtes, 2012) do not\nsquare with reality. Journal of Informetrics, 6(4), 615–618.\nRadicchi, F., &amp; Castellano, C. (2012c). A reverse engineering approach to the\nsuppression of citation biases reveals universal properties of citation\ndistributions. PLoS ONE, 7(3), e33833.\nRadicchi, F., Fortunato, S., &amp; Castellano, C. (2008). Universality of citation\ndistributions: Toward an objective measure of scientific impact. Proceedings\nof the National Academy of Sciences, 105(45), 17268–17272.\nSirtes, D. (2012). Finding the Easter eggs hidden by oneself: Why Radicchi and\nCastellano’s (2012) fairness test for citation indicators is not fair. Journal of\nInformetrics, 6(3), 448–450.\n\n1663\n\nVan Eck, N.J., Waltman, L., Van Raan, A.F.J., Klautz, R.J.M., &amp; Peul, W.C.\n(2012). Citation analysis may severely underestimate the impact of clinical\nresearch as compared to basic research. arXiv:1210.0442.\nWaltman, L., &amp; Van Eck, N.J. (2010). The relation between Eigenfactor, audience\nfactor, and influence weight. Journal of the American Society for Information\nScience and Technology, 61(7), 1476–1486.\nWaltman, L., &amp; Van Eck, N.J. (2012). A new methodology for constructing a\npublication-level classification system of science. Journal of the American\nSociety for Information Science and Technology, 63(12), 2378–2392.\nWaltman, L., &amp; Van Eck, N.J. (2013). A systematic empirical comparison of\ndifferent approaches\nfor normalizing citation impact indicators. arXiv:1301.4941.\nWaltman, L., &amp; Van Eck, N.J. (in press). Source normalized indicators of citation\nimpact: An overview of different approaches and an empirical comparison.\nScientometrics.\nWaltman, L., Van Eck, N.J., Van Leeuwen, T.N., &amp; Visser, M.S. (2013). Some\nmodifications to the SNIP journal impact indicator. Journal of Informetrics,\n7(2), 272–285.\nZhou, P., &amp; Leydesdorff, L. (2011). Fractional counting of citations in research\nevaluation: A cross- and interdisciplinary assessment of the Tsinghua\nUniversity in Beijing. Journal of Informetrics, 5(3), 360–368.\nZitt, M. (2010). Citing-side normalization of journal impact: A robust variant of\nthe audience factor. Journal of Informetrics, 4(3), 392–406.\nZitt, M. (2011). Behind citing-side normalization of citations: Some properties of\nthe journal impact factor. Scientometrics, 89(1), 329–344.\nZitt, M., &amp; Small, H. (2008). Modifying the journal impact factor by fractional\ncitation weighting: The audience factor. Journal of the American Society for\nInformation Science and Technology, 59(11), 1856–1860.\n\n1664\n\nTHE TIPPING POINT – OPEN ACCESS COMES OF\nAGE\nÉric Archambault\nEric.archambault@science-metrix.com\nScience-Metrix Inc., Observatoire des Sciences et des Technologies (OST),\nCentre Interuniversitaire de Recherche sur la Science et la Technologie (CIRST),\nUniversité du Québec à Montréal, Montréal, Québec, Canada\n\nAbstract\n\nThe Open Access (OA) model for scientific publications has been examined for years by\nacademics who have argued that it presents advantages in increasing accessibility and,\nconsequently, in increasing the impact of papers. It has been noted that OA availability\nhas increased steadily over the years. However, current measurement has seriously\nunderestimated the proportion of OA peer-reviewed articles. This paper presents the\nresults of a pilot study that shows evidence that the proportion of measured OA is so close\nto 50% that we have most likely passed the tipping point, that is, the stage where the\nmajority of articles become available for free.\n\nConference Topic\n\nTopic 10: Open Access and Scientometrics\n\nIntroduction\nInterest in the academic community for Open Access (OA) publications has been\nincreasing. The initial interest in the use of bibliometric methods focused on\naccessing the so-called citation advantage of OA as opposed to subscription-based\njournals (Antelman, 2004; Harnad &amp; Brody, 2004; Craig, 2007). The literature of\nthe time recognised a clear citation advantage to papers available in OA as\nopposed to papers diffused solely through subscription-based journals. Strong\nadvocacy by authors such as Harnad (2003, 2008, 2012) suggested that benefits\nwould ensue from so-called green OA, that is, research papers self-archived by\ntheir authors in various types of repositories. Unsurprisingly, in this context,\nlibrarians and information scientists noted that they had a new mission, which\nmeant setting up and curating OA repositories (Proser, 2003; Bailey, 2005; Chan,\nKwok, &amp; Yip, 2005; Chan, Devakos &amp; Mircea, 2005 Repanovici, 2012).\nA part of the OA literature has discussed how authors and researchers (Pelizzari,\n2004; Swan &amp; Brown, 2004; Dubini, Galimberti &amp; Micheli, 2010) and publishers\n(Morris, 2003; Regazzi, 2004) would react to this new paradigm. Evidently,\nbusiness and economic models were discussed (Bilder, 2003; Kurek, Geurts &amp;\nRoosendaal, 2006; Houghton, 2010; Lakshmi Poorna, Mymoon &amp; Hariharan,\n2012), but there was also interest in what models academia and libraries would\nfollow (Rowland et al., 2004; Swan et al., 2005; Hu, Zhang &amp; Chen, 2010).\n1665\n\nAs OA continued to make inroads, a growing number of papers examined the\nstate of development of OA in specific countries (Nyambi &amp; Maynard, 2012;\nSawant, 2012; Woutersen-Windhouwer, 2012; Miguel et al., 2013) and in specific\nfields of research (Abad-Garcí et al., 2010; Gentil-Beccot, Mele, &amp; Brook, 2010;\nCharles, &amp; Booth, 2011; Henderson, 2013). In this context, it was not surprising\nto find papers that addressed the general question of OA availability as a\nproportion of the scientific literature, and the proportion of OA papers available in\ndifferent fields of science (Björk et al. 2010; Gargouri et al., 2012).\nThis paper re-assesses OA availability in 2008 through a careful examination of\nrecall, which leads to a doubling of the proportion of OA estimated by Björk et al.\nand by Gargouri et al. The paper argues that the tipping point for OA has been\nreached and that one can expect that, from the late 2000s onwards, the majority of\npublished academic peer-reviewed journal articles were available for free to endusers. The paper presents data for 22 fields of science as well as for the European\nResearch Area countries, Brazil, Canada, Japan, and the US.\nMethods\nAccuracy and Precision: The paper presents the results for the pilot phase of a\nstudy that aims to estimate the proportion of peer-reviewed journal articles which\nare freely available, that is, OA for the last ten years (the pilot study is on OA\navailability in 2008). It builds on two important concepts: (1) accuracy, reflected\nin the quality of the instruments used and the care taken in making measurements;\n(2) precision, which involves repeated measures, sampling and statistical analysis\n(see figure 1)—the later concept will be called statistical precision for reasons\nthat will become obvious.\n\nFigure 1. Accuracy and statistical precision (Adapted from\nhttp://en.wikipedia.org/wiki/Accuracy_and_precision)\n\nStatistical precision can be approximated with the margin of error (ME). For a\nproportion (p) where the population is finite and known (N), is not systematically\nmuch larger than the sample size (n), and in which the values are discrete (for\n1666\n\nexample, papers), given a critical score Z (which will be set at 0.95 in the study),\nME is calculated as follows:\n√\n\n(\n\n)(\n(\n\n)\n)\n\nWhat complicates the use of these definitions is the need to examine accuracy\nwith two more concepts used in information retrieval: recall and precision (hence\nthe need to call the previous concept ‘statistical precision’; the second precisionrelated concept will be knonw as ‘retrieval precision’). Recall is the proportion of\nrelevant records that are retrieved, while retrieval precision is the proportion of\nretrieved records that are relevant. If an instrument retrieves 25 records of which\nonly 20 are relevant, and fails to retrieve 30 additional relevant records, its\nretrieval precision is 20/25 = 80% while its recall is 25/50 = 50%. Precision is\nsynonymous with Type I errors (false positives), and recall with type II errors\n(false negatives). Thus, a high recall means that an instrument returned most of\nthe relevant results, while high retrieval precision means that it retrieved more\nrelevant results than irrelevant ones. Note that assessing the real positives\naccurately is frequently a distinct problem, as is the case in the present study.\nLet us call π the proportion of the whole population of peer-reviewed papers that\nare OA. One cannot easily measure π directly because the population of scientific\npapers is relatively large, and there is currently no satisfactory complete repertory\nof that population. Hence, it is unlikely in the short term that someone will find\nanother way than sampling to calculate p, an approximation of π. Though it is\nnearly impossible for p to equal π, it is the aim of this study to offer a robust\ndesign that will ensure that p is reasonably close to π. In the present study, two\nprincipal proportions will be calculated: (1) the overall proportion of OA\nliterature; and (2) the proportion of the scientific literature published in gold\njournals. Before entering into the methodological details associated with the\nmeasurement as such, it is important to produce operational definitions of OA,\ngreen OA, gold OA and hybrid OA.\nTypes of OA scientific literature: Peter Suber suggests that ‘[o]pen-access (OA)\nliterature is digital, online, free of charge, and free of most copyright and\nlicensing restrictions.’164 An effective definition of OA for this study is the\nfollowing: ‘OA, whether Green or Gold, is about giving people free access to\npeer-reviewed research journal articles.’165 The following operational definitions\nof gold and green OA will be used in the present study.\n Gold OA refers to papers published in journals that provide free access to\n[peer-reviewed scholarly] papers. Authors sometimes, but not always, pay\na fee for these publications. In the present study, Gold journals are those\nthat provide cover-to-cover, instant access to articles.\n164\n\nhttp://www.earlham.edu/~peters/fos/overview.htm.\nhttp://scholarlykitchen.sspnet.org/2011/09/07/oa-rhetoric-economics-and-the-definition-ofresearch/.\n165\n\n1667\n\nGreen OA generally refers to authors’ self-archiving [of papers accepted\nin academic journals following a successful peer-review process].\n Hybrid OA is an increasingly important trend in scientific publishing by\nwhich authors pay for their papers to be available in OA in an otherwise\nnot OA journal—‘[h]ybrid open access journals provide Gold OA only\nfor those individual articles for which their authors (or their author’s\ninstitution or funder) pay an OA publishing fee.’166\nA note on the concept of open-access versus toll-access literature is in order here.\nOA is rarely free, and can generally be seen as moving the toll plaza before the\npublication process as opposed to placing it after it. Open access will rarely\nentirely miss exacting a toll somewhere, be it on taxpayers&#x27; or on philanthropists&#x27;\nfunds, or on the time of volunteers. Thus, the term toll-access, to distinguish the\nnon-OA literature, is avoided here.\n\n\nPeer-reviewed journal articles and original contributions to knowledge: A\ncentral part of the scientific literature is comprised of papers published in peerreviewed journals (Larivière et al., 2006). This study concentrates on peerreviewed, scholarly articles and omits the many other types of vehicles that are\nused for the written diffusion of scientific knowledge, namely books and\nconference proceedings, as well as research reports, mimeos and other\nheterogeneous forms, collectively called grey literature. A best practice in\nbibliometrics is to use only articles that can be considered original contributions\nto knowledge. The tradition in the Web of Knowledge (and its predecessor, the\nScience Citation Index) was to restrict the selection of document types to articles,\nnotes and reviews (Carpenter &amp; Narin, 1980). In Scopus, the tagging of articles is\nsubstantially more complex, and a combination of Source Type and Document\nType is required to keep only what can be considered original contributions to\nknowledge. The present study uses the following operational definition: articles\nthat use references and are cited. This definition, and empirically obtained\nthresholds, can be used to prune Source Type\nDocument Type\nthe Scopus production database of Book Series\nArticle\ntrade journals and non-original\nConference Paper\nReview\ncontributions to knowledge (at the\nShort Survey\nmacro level rather than at the\nArticle\narticle level to prevent the Conference Proceeding\nReview\nexclusion of papers that have not\nJournal\nArticle\nyet been cited). The resulting types\nConference Paper\nof documents used are presented in\nReview\nthe accompanying side box.\nShort Survey\nCalculating the denominator: An important aspect of the project involves\ndetermining the proportion of OA papers by precisely estimating the number of\n166\n\nhttp://en.wikipedia.org/wiki/Open_access.\n\n1668\n\nOA peer-reviewed papers (the numerator) and dividing this by a carefully\ndesigned estimate of the number of peer-reviewed articles (the denominator) for\neach of the selected 22 disciplines and for the total literature. A decision was\nmade to use the Ulrich periodical database to provide an estimate of the\ndenominator, and these data and rights to use them were acquired for this study.\nThe strengths and weaknesses of Ulrich data are well known: for example, some\njournals that should be classified as peer-reviewed are not (and the reverse is also\ntrue). A good example of this is the OA journal Activités, which mentions that\n‘Texts that have been submitted to Activités (www.activites.org/) will be assessed\nby two referees (called upon in view of the article). Each will give his or her\nopinion on the text.’167 Despite this, and a description that clearly suggests\nscholarly content and the presence in papers of references to scholarly work,\nUlrich has not classified this journal as refereed. Although several journals are\nlikely to be classified ‘Academic/Scholarly’ in Ulrich and might be considered as\ncontributing to science, this category cannot be included en masse as it comprises\na substantial amount of material published in universities that has little scientific\ncontent. This is the case, for example, with the ‘The Hilltop’, classified by Ulrich\nas Academic/Scholarly, and claiming to be the ‘The Student Voice of Howard\nUniversity’ (see http://www.thehilltoponline.com/). Consequently, the selection\nwas restricted to Ulrich listed journals considered refereed/peer-reviewed AND\nAcademic/Scholarly. Although imperfect, Ulrich remains the most extensive and\nauthoritative and probably the least biased source of data on academic peerreviewed journals and is therefore a solid calibration instrument for a systematic\ninvestigation of the peer-reviewed literature.\nThe core use of Ulrich in this project was to calibrate the proportion of papers\nfrom each of 22 disciplines used to present disaggregated statistics. The reason\nUlrich is preferred is because article-level database publishers such as Elsevier\n(publisher of Scopus) and Thomson (Web of Science) are faced with choices\nhaving important commercial and profitability impacts. When selecting journals\nto be included for an article-level database such as Scopus, deciding whether to\ninclude a journal has a direct impact on production costs and partly because of\nthis, database publishers tend to have a bias towards larger journals (economies of\nscale) and larger publishers (lowest transaction costs and economies of scale).\nHowever, whether a journal is small or large in terms of number of articles has\nsubstantially fewer consequences when it is included in a journal title database,\nwhere journal size can be expected to little impact on cost (some differences\nremain as it is likely easier to find information about the larger journals).\nUlrich cannot be used alone as it does not contain article-level information. The\ncore work of the present project involved using a fully-licensed version of\nElsevier’s Scopus database hosted in house and conditioned over several years to\nproduce bibliometric statistics. This meant that it was possible to randomly select\npapers among the millions of papers indexed. Ulrich was used to ‘calibrate’ the\n167\n\nhttp://www.activites.org/resources/activites.eng.book.pdf.\n1669\n\nproportion of peer-reviewed journal articles for each of the 22 fields used in this\npaper to present detailed statistics. The technique used to determine this\nproportion involved the following steps: 1) journals in Ulrich were matched to\nthose contained in Scopus; 2) journals that intersected were given the discipline\nthat was already contained in our classification of Scopus journals (for those that\ndid not intersect, the Ulrich classification was compared with that used in our\nclassification, and a matching table was used to attribute one of 22 disciplines to\neach of the journals); and 3) the number of articles per discipline was counted in\nthe intersecting set, while the number of articles in the Ulrich set with no Scopus\ncounterparts was determined by projecting the average number of articles for the\n50% journals in Scopus with the fewest articles per journal. The reason for using\nthe average number of articles for the 50% smaller journals is that experience has\nrevealed that databases such as Scopus and the Web of Science index the largest\njournals first. For instance, the Web of Science covers about 12,000 journals, and\nScopus about 18,000. Despite a 50% increase in journal coverage, Scopus only\nhas about 20% more articles. A sensitivity analysis was performed to see the\neffect of calculating the average for the 75%, 50%, and 25% smallest journals\n(ranked by decreasing number of articles), and the results were broadly similar.\nStrategy to measure the proportion of gold OA: Somewhat distinct strategies\nwere used to calculate the occurrence of gold OA and total OA. For gold articles,\nan estimate of the proportion of papers was made from the random sample by\nmatching the journals that were known to be gold in 2008. These journals were\nobtained from the Directory of Open Access Journals (DOAJ) and the list of OA\njournals in PubMed Central. This was done by matching journals’ ISSN, E-ISSN\nand names from Scopus to the relevant records in the sample (the matching had\nabout 100% precision, but recall may have been imperfect, hence the figures\npresented here can be considered a floor, rather than a ceiling).\nStrategy to measure the OA proportion of scientific articles: Two samples and\na sub-sample were produced to undertake a pilot study to measure OA availability\nin 2008 given the definition and assumptions presented above. A first sample of\n20,000 was produced for early testing, and a sub-sample of 500 records was\ndrawn from this sample to determine the availability of papers in OA using\nvarious search engines; a ‘ground truth’ was established by combining the\nvalidated results of these tests.\nA second random sample of 20,000 records was drawn from Scopus and used to\nperform the measuring stage of the pilot study. This sample was restricted to\npapers published in 2008, and the results were restricted to original contributions\nto knowledge; records where the journal name or the record type contained a\nconference were excluded. Records for which the discipline was unknown were\nalso set aside. The eligible record set from 2008, comprising somewhat more than\n1.36 million records in Scopus, was ‘tossed&#x27; five times using a pseudo-random\nmethod (using the newid() command in SQL Server), a subset of 100,000 records\n1670\n\nwas selected, placed in a subset, and tossed again. These 100,000 records were\nthen imported into Excel, where a straightforward analysis of the distribution of\nthe records by discipline was performed. This analysis showed that a subsample\nof 20,000 records would keep few records in three of the smaller disciplines\n(Philosophy &amp; Theology, Visual &amp; Performing Arts, and General Arts,\nHumanities &amp; Social Sciences). For these disciplines, a random sample of 100\nrecords was selected, and for the Built Environment &amp; Design discipline, the 101\nrecords that were part of the 100,000 records were all selected. As the objective\nwas to produce a record set of 20,000, a subsequent selection was done for 19,599\nrecords. These were selected by tossing the 100,000 a few more times using the\nrand() command in Excel, then proceeding to the selection of the required number\nof records.\nTechnique used to harvest OA articles: Although the pilot study was meant to\nbuild on the method pioneered by Björk et al. and human judgment was to be\nused in searching for and categorising the presence of OA, the pilot study has led\nto a gradual, but fundamental, modification of the original approach. After nearly\ntwo months of work, it became apparent that using professionals would be costprohibitive and too slow for a large scale study over several years.\nA test was then conducted with 20,000 records being provided to the Steven\nHarnad team in Montreal. This relatively blind test produced recall that was good;\nthe scores computed were much higher than those presented in previous papers,\nincluding results by Harnad’s team. This was due to the use of Scopus, as\nopposed to the Web of Science as Harnad’s team had done before. Some 500\nrecords of this set were then extracted randomly and extensive testing was\nperformed. The records were all searched manually in Google Scholar, Google,\nand Microsoft Academics. Records that could be downloaded for free and that\ncame from any of these sources were considered OA, and the carefully verified\nsample a ‘ground truth.’\nThese tests led to the following observations: Google Scholar and Google have\nsubstantial overlap, but each search engine has a somewhat distinct set of positive\nresults. Microsoft Academics does not add much to the combined results of\nGoogle and Google Scholar. Importantly also, the results obtained suggest that the\naccuracy of the harvesting instrument, and the coverage of the database, are more\nimportant than a large sample size (statistical precision). For instance, the team\nled by Harnad measured only 22% of OA in 2008 overall ‘out of the 12,500\njournals indexed by Thomson Reuters using a robot that trawled the Web for OA\nfull-texts’ (Gargouri et al., 2012). Likewise, Bj rk et al. found a score of 20%\nusing Scopus and Google as a search engine. When the Harnad team ran their\nrobot on our Scopus sample, the proportion of total OA jumped to close to 32%,\ncompared with the 22% they obtained in WoS as mentioned in their paper (this\noriginal sample was prepared rapidly for testing and might not have been\nperfectly random, so these results should be seen as tentative). This shows that a\n\n1671\n\ntechnique to measure the proportion of OA literature based on the Web of Science\nproduces fairly low recall and seriously underestimates OA availability.\nExtensive testing was done with the subsample of 500 records. Because the\noriginal was not necessarily 100% random, this subsample cannot necessarily be\nconsidered as totally representative, but the results are nonetheless instructive.\nThe results for the Harnad robot are as is and contain a few false positives, so the\nreal positive score is actually lower. The Scholar, Google and Ground Truth\nresults were manually validated and the documents downloaded, and as such, they\ncan be considered accurate. The Ground Truth comprises the combined validated\nresults from Google and Google Scholar in addition to one result from Microsoft\nAcademics. Results from Microsoft Academics are not shown, as only the\nnegative results from Scholar and Google were tested to examine whether this\nadded any substantial results to the previous ones.\nTable 1. Availability of OA in a sample of 500 Scopus records, 2008\nResult\nFALSE\nTRUE\nTotal\n% OA\n\nUQAM (Harnad)\n350\n150\n500\n30%\n\nScholar\n293\n207\n500\n41%\n\nGoogle\n290\n210\n500\n42%\n\nGround Truth\n262\n238\n500\n48%\n\nSource: Computed by Science-Metrix\n\nThis extensive analysis therefore suggests that 48% of the literature published in\n2008 may be available for free. Despite their high level of performance, neither\nGoogle nor Google Scholar can be expected to crawl the Web perfectly or to have\na search engine so robust that it systematically presents all the relevant records in\nthe first page of results (which we limited our analysis to), and hence cannot be\nexpected to have a 100% recall, especially for academic articles (Arlitsch &amp;\nO&#x27;Brien, 2012). Consequently, one can infer that OA availability very likely\npassed the tipping point in 2008 (or earlier) and that the majority of peerreviewed/scholarly papers published in journals in that year are now available for\nfree in one form or another to end-users.\nThese results suggest that using Scopus and an improved harvester ‘to trawl the\nWeb for OA full-texts’ could yield substantially more accurate results than the\nmethods used by Björk et al. and Harnad et al.\nResults\nTable 1 presents data on OA availability overall and for Gold journals (pure Gold,\nin that it does not include journals with an embargo period or traditional-model\njournals offering pay-per-article OA). Pay-per-article OA, journals with embargo\nperiods and journals allowing partial indexing following granting agencies’ OA\npolicies are considered hybrid, and these data are bundled here with green OA\n(self-archiving). Papers in each of the 22 fields have been recalibrated given the\nmethod presented before (calibration based on Ulrich).The overall rate calculated\n1672\n\nwith the current harvesting instrument is 42% (plus or minus three percentage\npoints). Considering that the instrument used has imperfect recall and considering\nthat OA Gold journals are likely to be under-represented in both Scopus and the\nUlrich database, this can be considered a floor rather than an upper limit.\nOA availability varies considerably among disciplines. It seems that the tipping\npoint has been passed (OA availability over 50%) in Biology, Biomedical\nResearch, Mathematics &amp; Statistics, and General Science &amp; Technology.\nAccording to these data, a third or less of the papers can be found in OA in\nChemistry, Enabling &amp; Strategic Technologies, Historical Studies, and\nEngineering, while less than one paper out of five can be accessed free in\nCommunication &amp; Textual Studies and in Visual &amp; Performing Arts. However,\none must be careful with these last two figures as the statistical error is of the\nsame order of magnitude as the measured proportion.\nTable 2.Proportion of OA per discipline, 2008\nField\nAgriculture, Fisheries &amp; Forestry\nBiology\nBiomedical Research\nBuilt Environment &amp; Design\nChemistry\nClinical Medicine\nCommunication &amp; Textual Studies\nEarth &amp; Environmental Sciences\nEconomics &amp; Business\nEnabling &amp; Strategic Technologies\nEngineering\nGeneral Arts, Humanities &amp; Social Sciences\nGeneral Science &amp; Technology\nHistorical Studies\nInformation &amp; Communication Technologies\nMathematics &amp; Statistics\nPhilosophy &amp; Theology\nPhysics &amp; Astronomy\nPsychology &amp; Cognitive Sciences\nPublic Health &amp; Health Services\nSocial Sciences\nVisual &amp; Performing Arts\nAll Publications\n\nPapers\n780\n1,031\n1,618\n100\n1,621\n5,157\n249\n599\n627\n1,267\n1,168\n25\n165\n232\n590\n625\n164\n1,872\n436\n581\n1,051\n43\n20,000\n\nGreen &amp; Hybrid\n%\nPapers\n199\n26 ± 6\n477\n46 ± 4\n858\n53 ± 2\n30\n30 ± 15\n379\n23 ± 4\n1,609\n31 ± 2\n33\n13 ± 19\n228\n38 ± 5\n246\n39 ± 6\n301\n24 ± 4\n290\n25 ± 4\n11\n44 ± 12\n52\n32 ± 9\n48\n21 ± 13\n220\n37 ± 5\n333\n53 ± 4\n52\n32 ± 15\n747\n40 ± 3\n193\n44 ± 6\n194\n33 ± 6\n313\n30 ± 6\n7\n16 ± 20\n6,818\n34 ± 4\n\nGold\n%\nPapers\n125\n16 ±\n161\n16 ±\n141\n9 ±\n7\n7 ±\n154\n9 ±\n501\n10 ±\n15\n6 ±\n28\n5 ±\n23\n4 ±\n75\n6 ±\n17\n1 ±\n0.2\n1 ±\n40\n24 ±\n20\n9 ±\n30\n5 ±\n31\n5 ±\n10\n6 ±\n89\n5 ±\n17\n4 ±\n70\n12 ±\n96\n9 ±\n0.9\n2 ±\n1,649\n8 ±\n\nOA\n7\n6\n5\n25\n5\n2\n24\n9\n11\n5\n8\n70\n10\n17\n9\n10\n27\n5\n13\n8\n8\n44\n6\n\nPapers\n324\n638\n999\n37\n532\n2,110\n48\n256\n269\n376\n307\n11\n92\n68\n250\n364\n62\n836\n210\n264\n408\n8\n8,467\n\n42\n62\n62\n37\n33\n41\n19\n43\n43\n30\n26\n45\n56\n29\n42\n58\n38\n45\n48\n45\n39\n18\n42\n\n%\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n±\n\n4\n3\n2\n14\n3\n2\n17\n5\n5\n4\n4\n12\n6\n12\n5\n4\n14\n3\n6\n5\n5\n19\n3\n\nIt is more delicate to interpret the proportion of Gold OA because of the large\nstatistical error (resulting from the small sample and low occurrence). The overall\nGold OA availability measured here is 8%, and this is generally consistent with\nthe literature. Note however that this report uses a strict definition of Gold OA,\nand that many previous studies might have included disembargoed papers and\npay-per-article OA, which is not the case here. Gold OA is widespread in General\nScience &amp; Technology, Agriculture, Fisheries &amp; Forestry, Biology, Public Health\n&amp; Health Services, and Clinical Medicine. Less than 2% of the papers are\n\n1673\n\navailable in Gold journals in Visual &amp; Performing Arts, Engineering and General\nArts, Humanities &amp; Social Sciences.\nThe prevalence of papers in hybrid forms (non-Gold) is especially high in\nMathematics &amp; Statistics and Biomedical Research. Less than one paper out of\nfour can be found in hybrid forms in Engineering, Enabling &amp; Strategic\nTechnologies, Chemistry, Historical Studies and the Visual &amp; Performing Arts.\nA question that has animated OA advocates has been the so-called citation\nadvantage of OA. This question is examined briefly in Table 3 using the Average\nof Relative Citation (ARC), a measure that reflects citation rates and is\nnormalised to account for differences among scientific specialities in the\npropensity to use references and receive citations. These data present the relative\ncitation rate of OA publications overall, Gold OA and hybrid OA forms relative\nto publications in each discipline. A score above 1 denotes that papers are more\ncited than in the field overall, while a score below 1 means that these publications\nare less frequently cited. For instance, papers in Agriculture, Fisheries &amp; Forestry\nreceive roughly the same level of citation (0.98) in OA overall than they do\nusually (the base measure is 1.0 for whole set of papers in a discipline).\nImportantly though, Gold OA papers are cited only half as frequently on average\n(0.49), although self-archived and other hybrid forms are cited 28% more\nfrequently than the discipline&#x27;s average (1.28).\nTable 3. Scientific impact (ARC) of OA publications, 2008\nField\nAgriculture, Fisheries &amp; Forestry\nBiology\nBiomedical Research\nBuilt Environment &amp; Design\nChemistry\nClinical Medicine\nCommunication &amp; Textual Studies\nEarth &amp; Environmental Sciences\nEconomics &amp; Business\nEnabling &amp; Strategic Technologies\nEngineering\nGeneral Arts, Humanities &amp; Social Sciences\nGeneral Science &amp; Technology\nHistorical Studies\nInformation &amp; Communication Technologies\nMathematics &amp; Statistics\nPhilosophy &amp; Theology\nPhysics &amp; Astronomy\nPsychology &amp; Cognitive Sciences\nPublic Health &amp; Health Services\nSocial Sciences\nVisual &amp; Performing Arts\nAll Publications\n\n1674\n\nAll Publications\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n1.00\n\nGreen &amp; Hybrid\n1.28\n1.35\n1.17\n1.07\n1.18\n1.66\n1.23\n1.04\n1.39\n1.37\n1.49\n1.28\n2.60\n1.10\n1.50\n1.11\n1.28\n1.21\n1.21\n1.31\n1.38\n1.15\n1.36\n\nGold\n0.49\n0.55\n0.84\n0.25\n0.38\n0.59\n1.55\n1.19\n0.07\n0.64\n0.13\n0.00\n0.40\n0.22\n0.73\n0.71\n0.61\n1.05\n0.86\n0.68\n0.52\nn.c.\n0.59\n\nOA\n0.98\n1.15\n1.13\n0.91\n0.95\n1.40\n1.33\n1.05\n1.28\n1.23\n1.41\n1.25\n1.64\n0.84\n1.40\n1.07\n1.18\n1.19\n1.18\n1.14\n1.18\n1.02\n1.21\n\nAn overall OA advantage occurs in all but four disciplines (Agriculture, Fisheries\n&amp; Forestry; Chemistry; Built Environment &amp; Design; Historical Studies). Gold\nOA only presents a citation advantage in three disciplines (Communication &amp;\nTextual Studies; Earth &amp; Environmental Sciences; Physics &amp; Astronomy), and in\nthose disciplines, except for one (Physics &amp; Astronomy), the citation advantage is\ngreater in Gold OA than in hybrid OA forms. Hybrid OA forms always present a\ncitation advantage.\nThese data require careful interpretation. First, many Gold journals are younger\nand smaller, and these factors have an adverse effect on the citation rate and the\nARC. Authors frequently prefer reading and citing more established journals, and\nit is a difficult endeavour to start a journal from scratch. It takes time to build a\nreputation and to attract established authors. It is possible though that Gold\njournals might provide an avenue for less mainstream, more revolutionary\nscience. If so, the signature would be a much greater level of variation between\nthe more highly cited papers and the baseline with no citation. Also, the ARC is\nnot scale-invariant, and larger journals have an advantage as this measure is not\ncorrected sufficiently for journal size (namely, it is not a scale-independent\nmeasure). So it might not always be the Gold nature of journals that lowers their\n‘citedness’; instead several structural aspects might be at play. Even so, the Gold\njournal industry is young, and it is still difficult to separate the wheat from the\nchaff. In this respect, it might be useful for authors to examine Beall’s List of\n‘potential, possible, or probable predatory scholarly open-access publishers’ to\nlower one&#x27;s risk of spending money on journals that do not espouse scientific\npublishing best practices.168\nA last aspect of the analysis based on the pilot study data is the examination of\nOA availability per country (for EU27, EFTA, Accession countries, ERA, and\nfour comparables). Please note that fractional counting was used here as it was\ndeemed as potentially providing a more precise portrait of the situation. In\nfractional counting, if two authors are from separate countries, each country is\ngiven half a publication. In contrast, full paper counting would have ascribed one\npaper to each country. One advantage of fractional counting is that one can add\nthe fractions for all countries’ output in a table and obtain a total. A drawback is\nthat statistics might not seem as intuitive. In the table, the fractions of papers are\npresented only for scores below 10 (for example, 11 papers; 3.2 papers). The\nEU27, EFTA, and ERA all have roughly the same level of OA as that observed at\nthe world level, though there are noticeable differences among countries.\nExcluding countries with less than 50 papers (sum of all the fractions), the EU\ncountries with the greatest OA proportions are the Netherlands, Finland,\nRomania, Portugal, and the United Kingdom. The countries with the lowest rate\nof OA adoption are Hungary, the Czech Republic, Poland, Germany, and\nDenmark. In countries outside the EU27, it is noteworthy that the US seems to\nhave passed the tipping point (50%). Even more salient is the proportion of 62%\n168\n\nhttp://scholarlyoa.com/publishers/.\n1675\n\nobserved in Brazil. This is no doubt due largely to the exemplary work performed\nby Scielo, which plays a key role in the Southern hemisphere in making scientific\nknowledge more widely available.\nDiscussion\nOne has to be careful when interpreting the results presented in this paper as the\nmethodological instruments are not fully developed, and results could vary with\ngrowing accuracy. As a general rule, further development of the ‘trawler’ will\nincrease recall and therefore, the proportion of OA presented here will surely\nincrease. Sample size can be fine-tuned to obtain a satisfactory level of statistical\nprecision as the margins of error presented above were certainly high in several\nareas. Future exercise will balance the sample more carefully to augment the\nnumber of papers from the smaller countries and the presence of papers from the\nsmaller disciplines. We also endeavour to develop a robust method to distinguish\nmore clearly between Gold OA, Hybrid OA and non-fully Gold journals, and selfarchiving (‘Green OA’). This presents many challenges, and statistics should be\npresented on the condition that they must not be too inaccurate. Other authors\nhave presented results suggesting that OA availability was only half as high as\ncarefully and prudently measured here, and this is certainly a reminder that it\nmight be preferable to be reflective. Previous authors have measured what was in\ndatabases, or what search engines were able to do. Our goal here is to estimate the\nproportion of peer-reviewed academic-level literature which is available for free.\nMeasuring how well Google Scholar fares at identifying a part of this is certainly\nan interesting exercise in itself, but it does not address our central question.\nFinding that the tipping point has been reached in open access is certainly an\nimportant discovery. This means that the publishing industry is undergoing\nrevolutionary change and at a pace much faster than anticipated, in large part\nbecause previous measures of OA availability proved to be misleading. This\nmeans that aggressive publishers such as Springer are likely to gain a lot in the\nredesigned landscape, whereas those attached to the old days are likely to suffer\nand to lose market share. The impression gained in carrying out this study and\ndeveloping our OA ‘trawler’ is that the tool plaza is being moved to the beginning\nof the publishing process, away from the back-end of the process, and thus from\nthe libraries and closer to researchers. Despite what several authors thought, and\nargued for, green OA only appears to move slowly, whereas Gold OA and hybrid\ntoll before the process as opposed to toll after are in the fast lane. Efforts need to\nbe made to characterise these changes.\nIf the toll plaza changes from the end of the process to the front-end, one category\nof workers is likely to be highly affected: the university and research centre\nlibrarian. Librarians have been highly affected already by the shift from paper to\ndigital media and losing the responsibility of spending the large sum paid in\njournal subscriptions will certainly create another large dent in their traditional\nsphere of responsibilities. If the tool plaza is just moved, it means that researchers\nwill have control over the toll.\n1676\n\nThe market power will shift tremendously from the tens of thousands of buyers\nthat publishers’ sales staff nurtured to the millions of researchers that will now\nmake the atomistic decision of how best to spend their publication budget. Much\nhas been said about the cost of publishing in gold and hybrid OA, but one has to\nplace this in perspective. The cost of academic papers in the US is about $125,000\non average (HERD divided by number of papers by academia) so adding or\nincluding a $2,000 publication fee in this envelope is certainly going to break the\nbank. The question is rather whether the switch to a more atomistic market will\nreduce, augment or leave unchanged the negotiating power of publishers. One\nwill have to stay tuned and watch the gales of creative destruction at play.\nTable 4. Proportion of OA availability by country, 2008\nGroup\n\nCountry\n\nEU27\n\nAustria\nBelgium\nBulgaria\nCyprus\nCzech Republic\nDenmark\nEstonia\nFinland\nFrance\nGermany\nGreece\nHungary\nIreland\nItaly\nLatvia\nLithuania\nLuxembourg\nMalta\nNetherlands\nPoland\nPortugal\nRomania\nSlovakia\nSlovenia\nSpain\nSweden\nUnited Kingdom\nTotal EU27\nEFTA\nIceland\nLiechtenstein\nNorway\nSwitzerland\nTotal EFTA\nCandidate Turkey\nCroatia\nMacedonia\nTotal Candidate\nIsrael\nTotal ERA\nOthers\nUnited States\nJapan\nCanada\nBrazil\n\nSource:Computed by Science-Metrix\n\nPapers\n107\n185\n24\n5.1\n92\n145\n15\n96\n773\n1,016\n143\n74\n63\n604\n6.9\n21\n1.4\n2.5\n313\n229\n82\n64\n43\n34\n549\n220\n1,147\n6,055\n8\n1\n95\n194\n296\n327\n38\n3\n368\n137\n6,855\n4,524\n1,072\n598\n450\n\nGreen &amp; Hybrid\nPapers\n%\n32\n30%\n77\n42%\n8.9\n37%\n1.1\n21%\n28\n30%\n48\n33%\n3.6\n25%\n41\n43%\n254\n33%\n316\n31%\n50\n35%\n21\n28%\n23\n36%\n214\n35%\n4.5\n65%\n9.2\n44%\n0.1\n4%\n1.1\n45%\n150\n48%\n56\n25%\n31\n37%\n25\n39%\n14\n32%\n10\n29%\n162\n30%\n73\n33%\n465\n41%\n2,118\n35%\n3\n35%\n1\n100%\n31\n32%\n65\n34%\n99\n33%\n65\n20%\n16\n41%\n1\n42%\n82\n22%\n59\n43%\n2,358\n34%\n2,140\n47%\n349\n33%\n243\n41%\n89\n20%\n\nGold\nPapers\n10\n5.0\n2.0\n0.9\n5.7\n5.2\n2.9\n5.5\n41\n59\n11\n2.8\n3.7\n32\n3.0\n1.0\n0.4\n14\n27\n8.2\n5.8\n7.0\n3.8\n55\n11\n59\n383\n1\n9\n14\n25\n50\n4\n2\n56\n4\n467\n220\n76\n29\n212\n\nOA\n%\n10%\n3%\n8%\n18%\n6%\n4%\n20%\n6%\n5%\n6%\n8%\n4%\n6%\n5%\n0%\n14%\n72%\n15%\n4%\n12%\n10%\n9%\n16%\n11%\n10%\n5%\n5%\n6%\n13%\n0%\n10%\n7%\n8%\n15%\n11%\n58%\n15%\n3%\n7%\n5%\n7%\n5%\n47%\n\nPapers\n42\n82\n11\n2.0\n33\n54\n6.5\n47\n295\n375\n61\n24\n26\n246\n4.5\n12\n1.1\n1.5\n164\n83\n39\n31\n21\n14\n217\n84\n523\n2,500\n4\n1\n40\n79\n124\n115\n20\n3\n138\n63\n2,825\n2,360\n425\n273\n301\n\n%\n40%\n44%\n45%\n39%\n36%\n37%\n45%\n49%\n38%\n37%\n43%\n32%\n42%\n41%\n65%\n58%\n76%\n60%\n53%\n36%\n47%\n48%\n49%\n40%\n40%\n38%\n46%\n41%\n48%\n100%\n42%\n41%\n42%\n35%\n52%\n100%\n37%\n46%\n41%\n52%\n40%\n46%\n67%\n\n1677\n\nAcknowledgments\nThis research has received support from the European Commission.\nReferences\nAbad-García, M. F., Melero, R., Abadal, E., &amp; González-Teruel, A. (2010). Selfarchiving of biomedical papers in open access repositories. Autoarchivo de\nartículos biomédicos en repositorios de acceso abierto, 50(7), 431-440. doi:\n10.1371/journal.pbio.0040157.\nAntelman, K. (2004). Do open-access articles have a greater citation impact?\nCollege &amp; Research Libraries, 65(5), 372–382.\nArlitsch, K., &amp; O&#x27;Brien, P. S. (2012). Invisible institutional repositories:\nAddressing the low indexing ratios of IRs in Google Scholar. Library Hi Tech,\n30(1), 60-81. doi: 10.1108/07378831211213210.\nBailey Jr, C. W. (2005). The role of reference librarians in institutional\nrepositories. Reference Services Review, 33(3), 259-267.\nBilder, G. (2003). Ingenta&#x27;s economic and technical models for providing\ninstitutional OA archives. Information Services and Use, 23(2-3), 111-112.\nBjörk, B. C., Welling, P., Laakso, M., Majlender, P., Hedlund, T., &amp; Gudnason,\nG. (2010). Open Access To The Scientific Journal Literature: Situation 2009.\nPLoS ONE, 5(6). doi: 10.1371/journal.pone.0011273.\nCarbone, P. (2007). Consortium negotiations with publishers - Past and Future.\nLIBER Quarterly, 17(2).\nChan, D. L. H., Kwok, C. S. Y., &amp; Yip, S. K. F. (2005). Changing roles of\nreference librarians: The case of the HKUST Institutional Repository.\nReference Services Review, 33(3), 268-282. doi: 10.1108/00907320510611302\nChan, L., Devakos, R., &amp; Mircea, G. (2005). Workshop 2: Implementing and\nfilling institutional repositories introduction, Leuven-Heverlee.\nCharles, L., &amp; Booth, H. A. (2011). An Overview of Open Access in the Fields of\nBusiness and Management. Journal of Business and Finance Librarianship,\n16(2), 108-124. doi: 10.1080/08963568.2011.554786\nCraig, I. D., Plume, A. M., McVeigh, M. E., Pringle, J., &amp; Amin, M. (2007). Do\nopen access articles have greater citation impact? A critical review of the\nliterature. Journal of Informetrics, 1(3), 239-248. doi:\n10.1016/j.joi.2007.04.001.\nDubini, P., Galimberti, P., &amp; Micheli, M. R. (2010). Authors publication\nstrategies in scholarly publishing. In ELPUB 2010 International Conference\non Electronic Publishing, Helsinki (Iceland), 16-18 June 2010.\nGargouri, Y., Larivière, V. Gingras, Y. and Harnad, S. (2012). Green and Gold\nOpen Access Percentages and Growth, by Discipline. In Archambault, É,\nGingras, Y. and Larivière. V. (2012). Proceedings of 17th International\nConference on Science and Technology Indicators, Montréal: Science-Metrix\nand OST.\n\n1678\n\nGentil-Beccot, A., Mele, S., &amp; Brooks, T. C. (2010). Citing and reading\nbehaviours in high-energy physics. Scientometrics, 84(2), 345-355. doi:\n10.1007/s11192-009-0111-1\nHarnad, S. (2003). The research-impact cycle. Information Services and Use,\n23(2-3), 139-142.\nHarnad, S. (2008). Waking OA&#x27;s &quot;slumbering giant&quot;: The university&#x27;s mandate to\nmandate open access. New Review of Information Networking, 14(1), 51-68.\ndoi: 10.1080/13614570903001322.\nHarnad, S. (2012). Open access: A green light for archiving. Nature, 487(7407),\n302. doi: 10.1038/487302b\nHarnad, S., &amp; Brody, T. (2004). Comparing the impact of open access (OA) vs.\nnon-OA articles in the same journals. D-Lib Magazine, 10(6).\nHenderson, I. (2013). Open-Access and Institutional Repositories in Fire\nLiterature. Fire Technology, 49(1), 155-161. doi: 10.1007/s10694-010-0198-1\nHoughton, J. W. (2010). Economic implications of alternative publishing models:\nSelf-archiving and repositories. LIBER Quarterly, 19(3-4), 275-292.\nHu, C., Zhang, Y., &amp; Chen, G. (2010). Exploring a New Model for Preprint\nServer: A Case Study of CSPO. Journal of Academic Librarianship, 36(3),\n257-262. doi: 10.1016/j.acalib.2010.03.010\nKurek, K., Geurts, P. A. Th M., &amp; Roosendaal, H. E. (2006). The split between\navailability and selection: Business models for scientific information, and the\nscientific process? Information Services and Use, 26(4), 271-282.\nLakshmi Poorna, R., Mymoon, M., &amp; Hariharan, A. (2012). A study of select\nopen access journals and their business models listed in DOAJ in the fields of\ncivil and structural engineering. Journal of Structural Engineering (India),\n39(4), 458-468. doi: 10.1371/ journal.pone.0020961.\nLarivière, V., Archambault, É., Gingras, Y. &amp; Vignola-Gagné, É. (2006). The\nPlace of Serials in Referencing Practices: Comparing Natural Sciences and\nEngineering with Social Sciences and Humanities, Journal of the American\nSociety for Information Science and Technology, 57(8), 997-1004. doi:\n10.1002/asi.20349.\nMiguel, S., Bongiovani, P. C., Gómez, N. D., &amp; Bueno-de-la-Fuente, G. (2013).\nProspect for Development of Open Access in Argentina. Journal of Academic\nLibrarianship, 39(1), 1-2. doi: 10.1016/j.acalib.2012.10.002\nMorris, S. (2003). Open Publishing: How publishers are reacting. Information\nServices and Use, 23(2-3), 99-101.\nNyambi, E., &amp; Maynard, S. (2012). An investigation of institutional repositories\nin state universities in Zimbabwe. Information Development, 28(1), 55-67. doi:\n10.1177/0266666911425264\nPelizzari, E. (2004). Academic authors and open archives: A survey in the social\nscience field. Libri, 54(2), 113-122.\nProsser, D. (2003). Institutional repositories and Open access: The future of\nscholarly communication. Information Services and Use, 23(2-3), 167-170.\n\n1679\n\nRegazzi, John. (2004). The Shifting Sands of Open Access Publishing, a\nPublisher&#x27;s View. Serials Review, 30(4), 275-280. doi:\nhttp://dx.doi.org/10.1016/j.serrev.2004.09.010\nRepanovici, A. (2012). Professional profile of digital repository manager. Library\nHi Tech News, 29(10), 13-20. doi: 10.1108/07419051211294473\nRowland, F. et al. (2004). Delivery, management and access model for e-prints\nand open access journals. Serials Review, 30(4), 298-303. doi:\n10.1016/j.serrev.2004.09.006\nSawant, S. (2012). Past and Present Scenario of Open Access Movement in India.\nJournal of Academic Librarianship. doi: 10.1016/j.acalib.2012.11.007\nSwan, A. et al. (2005). Developing a model for e-prints and open access journal\ncontent in UK further and higher education. Learned Publishing, 18(1), 25-40.\ndoi: 10.1087/0953151052801479\nSwan, A., &amp; Brown, S. (2004). Authors and open access publishing. Learned\nPublishing, 17(3), 219-224. doi: 10.1087/095315104323159649\nWoutersen-Windhouwer, S. (2012). The Future of Open Access Publishing in the\nNetherlands: Constant Dripping Wears Away the Stone. Journal of Academic\nLibrarianship. doi: 10.1016/j.acalib.2012.11.015\n\n1680\n\nTO WHAT EXTENT CAN RESEARCHERS’\nINTERNATIONAL MOVEMENT BE GRASPED\nFROM PUBLISHED DATA SOURCES?\nYasuhiro Yamashita1 and Daisuke Yoshinaga2\n1\n\nyaya@jm.kj.yamagata-u.ac.jp, 2 yoshinaga@kdw.kj.yamagata-u.ac.jp\nPlanning and Research Support Department, Yamagata University, 1-4-12, Kojirakawamachi, Yamagata-shi, 99-8560 Yamagata (Japan)\n\nAbstract\n\nUsing CVs or Short Bios in published resources, such as the Internet enables us to analyze\nmany issues concerning researchers’ careers. However, relatively little effort has been\ndevoted to this area, and availability of this method, concerning target researchers, such as\nthe sector of their institution, country of residence, their visibility (i.e., the impact of their\npublications) was not known enough. To trace this activity, we examine how many\ncontributions that we were able to unveil in terms of authors’ countries of origin by using\ntwo types of samples: highly cited papers and papers that have yet to be cited at all. Then,\nwe analyze the influence of these researchers’ international movement. The results show\nthe full landscape of the movement’s influence on national publication, the characteristics\nof each country in term of researchers’ countries of origin, their research experience and\nacquisition of the research funds of both internationally moved and domestic researchers.\nFinally, we assess the limitations of the method and topic to be addressed concerning this\nmethod.\n\nConference Topic\n\nOld and New Data Sources for Scientometric Studies: Coverage, Accuracy and Reliability\n(Topic 2).\n\nIntroduction\nWhile the international movement of researchers is one of the most important\nissues of science and technology policies in many countries, almost no tool which\ncan be used for comprehensive study has been utilized to analyze it. Thus, there\nhave been relatively few studies devoted to quantitative studies of researcher’s\ninternational movement in the area of scientometrics. Although researchers’\nidentifier in conformity to ORCID, such as the “Researchers ID”, might partially\nsolve this problem partially in the future, their coverage is relatively low at\npresent, and it does not cover their life history before their first publication. We\nexplore to what extent we can obtain researchers’ origin from published data\nsource such as the Internet, then analyze the effect of movement of two kinds of\nresearchers; (1) researchers who wrote highly cited papers in the period of 2004 to\n2006; (2) those who wrote papers not cited in the same period.\n\n1681\n\nThere are several methods proposed for grasping researchers’ history other than\nquestionnaires (e.g. Cruz-Castro &amp; Sanz-Menendez, 2010) and above-mentioned\nresearchers’ identifiers. The first method is using CVs or Short Bios published\n(e.g. Jonkers, 2010; Jonkers &amp; Tijssen, 2008; Lepori &amp; Probst, 2009). This\nmethod has advantages of nature not strain on surveyed researchers. To pursue\nresearchers’ careers more exhaustively, Dietz and his colleagues utilized the\nmethod of asking researchers to send their CVs via E-mail, using the method of\ncollecting researchers’ histories via the Internet concurrently (e.g. Dietz et. Al.,\n2000; Corley, Bozeman &amp; Gaughan, 2003; Dietz &amp; Bozeman, 2005). Although\nthis method has the advantage of enabling collection with “unpublished’ CVs, put\naway non-invasive features of collecting published CVs. Before using this method\nregularly, other non-invasive method should be assessed to minimize surveyed\nresearchers’ workloads.\nAs for other methods of collecting researchers’ histories directly, extracting\ninformation on researchers&#x27; careers from journals which contain researchers’\nShort Bios, was utilized by few researchers such as Furukawa et al. (2011) and\nYamashita et al. (2007). This method enabled collecting career information on\nresearchers who might not tend to publish their information, such as employees of\nindustry, Ph.D students or postdoctoral fellows. On the other hand, the area of\nresearch would be limited because journals which contain researchers Short Bios\nare rare.\nThomson Reuters’ database, called “HighlyCited.com” also enabled grasping\noutstanding researchers’ career information systematically (such as Ioannidis,\n2004). While systematic data is attractive to analyze, this database cannot be used\nto pursue “ordinary researchers”. So, alternative data sources are needed to grasp\nwhole tendencies of a field/organization.\nAlternative method for pursuing researchers was utilized by Laudel (2003). She\ninsisted that using bibliographic database is more favorable than collecting CVs\nor questionnaires, since it made it possible to avoid influence of incompleteness\nof the CV data. This method seems to be effective for outstanding researchers or\nthat with names not so common. However, as for researchers of Asian origin,\ntheir initials are frequently so common to identify individuals, and old records\nwithout direct linkage of each author to his/her affiliation in the Web of Science\nprevent us from accurate identification of each researcher, and to guarantee\nprecision of data, each paper of respective researchers in the study should be\nconsulted. Moreover, researchers can be pursued only after their first publications,\ntherefore, it is difficult to grasp researchers’ origin by this method. Thus, the\nbibliometrics method can be applied to a limited number of outstanding\nresearchers.\nOn the other hand, method utilizing surname as an indicator of researchers’ origin\nis also used to grasp researchers’ origin (such as Jonkers, 2010; Lewison &amp;\nKundra, 2008). This method is suitable to utilize large samples since it does not\nneed to seek each researcher’s life history directly. However, surnames do not\nalways indicate their own origin, but family origin since they do not contain any\n1682\n\ninformation on the period of their migration. Therefore, this method can be used\nfor pursuing researchers’ family origin using large samples containing a certain\nerror margin.\nAs above stated, each existing method to pursue researchers’ movement or origin\nhas its advantage and shortcomings, and is not used broadly because of its\nlaborious nature and lack of coverage. Under the above-mentioned constraint,\nmethods utilizing published information enables relatively free research design\nwithout constraint of selection of target field or researchers surveyed, without any\nlabor of researchers surveyed. So, this method seems to be favorable for\nmonitoring the situations of a certain research field. Thus, in this research, we\nvalidate this method by applying it to a basic engineering research field of\nartificial intelligence, which has the ability of broad industrial applications, can be\nexpected to have researchers of broad country/sector origin, and in which\nrelatively many publications are issued each year. For validating to what extent\nwe can grasp the tendency of the whole field taking into consideration various\nresearchers, we (1) seek all researchers’ career information of sample papers and\n(2) explore both highly cited and uncited papers to examine how researchers’\n“visibility” affects their traceability. While “random sampling” from all\npublications in the field seems more valid to test the tendency of the entire field,\nwe use two extreme samples for comparison, since it is difficult to obtain enough\nsamples representing the field due to the high labor requirement.\nData and Methodology\nWe used publication data from the field of “Computer Science, Artificial\nIntelligence” published between 2004 and 2006 to make sure enough time had\npassed after publication, extracted from Web of Science database provided by\nThomson Reuters. The retrieval was executed in January 2011. All top 1% cited\npapers (hereafter “highly cited papers”) and randomly sampled papers without\nany citation (hereafter “uncited papers”) were extracted from the whole sample.\nSince we had already presented about feature of highly cited papers concerning\nresearchers’ movement (Yamashita, 2011), we focus on the comparison between\nthe two samples based on the previous study. Document type “Article” was used\nfor analysis. Number of sample uncited paper 1% of whole sample almost as\nmany as highly cited papers. CV or Short Bio of each author of sample papers\nwas retrieved on the Internet or extracted from journals.\nOf various information contained in each CV or Short Bio, we mainly focused on\nthe origin of researchers, which can be extracted commonly.\nEach author’s contribution to each paper was counted fractionally, one by number\nof authors, to avoid overrating, mainly because we aimed to explore its\napplicability to assessment of national/institutional publication. Number of\npublications was counted focusing two periods; (1) number of papers of country\n“A” by their affiliating country (hereafter Ni(A)), and (2) number of papers of\ncountry “A” by researchers’ origin (hereafter No(A)). To analyze effect of\nresearchers’ flow between two countries, (3) number of papers published in\n1683\n\ncountry A by researchers originated in country B (hereafter Nc(A,B)) were also\ncounted. Researchers’ countries of origin were defined as that in which they\nobtained bachelor or equivalent degree or where they were born, along with the\nauthors’ previous study (Yamashita et al., 2007). As for European continental\ncountries, in the case that countries in which researchers’ obtained their master\ndegrees were designated without bachelor, it was also accounted as their origin.\nIdentification rate was assessed by rate of papers of which researchers’ origin was\nunveiled, since we focused on international movement of researchers. Thus, other\ninformation contained in CVs or Short Bios was excluded from our assessment of\nour identification rate.\n100%\n90%\n\n17%\n37%\n\n80%\n70%\n60%\n\n43%\n\nUnknown\n\n50%\n44%\n\n40%\n\nInt. moved\n\n30%\n20%\n\nDomes c\n\n40%\n\n10%\n\n19%\n\n0%\nHighly-Cited\n\nUncited\n\nFigure 1. Breakdown of both highly cited and uncited papers by authors’ origin.\n\nResult\nIdentification rate of researchers’ origin\nAuthors’ origin was unveiled as much as 83.2% of the total 140 highly cited\npapers, while it was as low as 62.3% in 138 uncited papers (Figure 1). As for the\nbreakdown of each sample, the highly cited papers consist of almost the same\ncontribution of both international-moved researchers and domestic researchers\n(researchers who worked in their countries of origin), besides the uncited papers\ncontain only 18% contributions of internationally-moved researchers. However,\nthe contribution of unveiled researchers in uncited papers was as high as 37.7%,\ntherefore it is difficult to estimate the contribution of internationally-moved\nresearchers in uncited paper, which was much lower than that of highly cited\npapers.\nBoth the percentages of highly cited and uncited papers counted by authors’\naffiliation (Ni(A)) are presented in Figures 2 and 3 respectively. The top five\ncountries of highly cited papers were, the US (sharing 44.8%), China (9.4%), the\nUK (6.0%) , Taiwan (5.0%) and France (4.7%) . Out of these five countries, the\n1684\n\nSlovenia\n\nIsrael\n\nAustralia\n\nSpain\n\nFinland\n\nNetherlands\n\nSingapore\n\nSwitzerland\n\nGermany\n\nFrance\n\nCanada\n\nUK\n\nTaiwan\n\nUS\n\n100%\n90%\n80%\n70%\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nBreakdown by researchers&#x27; origin\n\n50%\n45%\n40%\n35%\n30%\n25%\n20%\n15%\n10%\n5%\n0%\n\nChina\n\nShares of Ni(A)\n\nshare of the US has an oligopolistic share, however, more than half of these US\npapers were published by foreign-origin researchers. On the other hand, uncited\npapers were produced by researchers affiliated with institutes in Russia (13.3%),\nthe US (10.4%), Canada (7.1%), Italy (6.9%) and China (6.8%) respectively. The\ndistribution of uncited papers’ countries was more equivalent without occupation\nby any specific country. The authors’ origins were unveiled in most countries for\nhighly cited papers, whereas they were not unveiled in many countries, such as\nRussia, China and Taiwan for uncited papers. The low coverage of Russia seemed\nto be caused by sparse information disclosure, not by the visibility of researchers,\nso the systematic bias might have occurred due to information inequality across\ncountries.\n\nUnknown\nForeing origin\nDomes c\nShares of Ni(A)\n\n14%\n\n10%\n8%\n6%\n4%\n\nFinland\n\nTurkey\n\nGreece\n\nNetherlands\n\nSpain\n\nAustralia\n\nUK\n\nIndia\n\nCzech Republic\n\nChina\n\nTaiwan\n\nItaly\n\nCanada\n\n0%\n\nUS\n\n2%\n\nRussia\n\nShares of Ni(A)\n\n12%\n\n100%\n90%\n80%\n70%\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nBreakdown by researchers&#x27; origin\n\nFigure 2. Shares of Ni(A) of highly cited publications and their breakdown by\nresearchers’ origin\n\nUnknown\nForeign origin\nDomes c\nShares of Ni(A)\n\nFigure 3. Shares of Ni(A) of uncited publications and their breakdown by\nresearchers’ origin\n1685\n\nHow does coverage should change by impact of papers? A scatter plot of\ncountries which appeared in both highly cited and uncited papers showed the\nchange of coverage according to the impact of the papers (Figure 4). Canada,\nSpain and Netherlands did not change their coverage by citation impact, and\ncoverage of both highly cited and uncited papers exceeded 80%. Countries of\nwhich coverage changed significantly were Taiwan, China and UK. Their\ncoverage of researchers’ origin remained at approximately 40%. Thus,\nadvantaged researchers should be selected if their origin or movement is analyzed\nin this field.\nIden fica on rate of researchers&#x27; career of uncited papers\n\n100%\n90%\n\nSpain\n\n80%\n\nFinland\n\n70%\n\nCanada\n\nNetherlands\nUS\n\n60%\n\nTaiwan\n\n50%\n\nChina\n40%\n\nUK\n30%\n20%\n10%\n0%\n0%\n\n20%\n\n40%\n\n60%\n\n80%\n\n100%\n\nIden fica on rate of researchers&#x27; origin of highly cited papers\n\nFigure 4. Identification rate of both highly cited and uncited papers.\n\nIn addition, it seemed reasonable to assume that researchers’ disclosure of their\norigin should depend on sectors of their institutes, such as, university, public\nresearch institute, industry, and so on. For example, university researchers seem\nto have a tendency to disclose their CVs on their institutes’ websites.\nFigure 5 shows the identification rate of researchers’ origin by the three most\nproductive sectors (university, public research institute, and industry). The\nidentification rate was increased by citation impacts in all three sectors. The\nlargest difference of the three sectors appeared in the public research institute,\nwhich was mainly caused by the Russian researchers of this sector who had a\ntendency not to disclose their career information. If all Russian researchers were\nremoved from the uncited papers, the identification rates of the university, public\nresearch institute, and industry were relatively similar (70%, 65% and 56%\nrespectively). The identification rate of both highly cited and uncited papers of\n\n1686\n\nindustrial researchers was close to each other: they tend not to expose individual\nresearchers, regardless of their contributions\n\nUniversity\n\nPubl. Res. Inst.\n\nHighly-Cited\nUncited\n\nIndustry\n\n0%\n\n10% 20% 30% 40% 50% 60% 70% 80% 90% 100%\nIden fica on rate of authors&#x27; origin\n\nFigure 5. Identification rate of researchers’ origin by their institutional sectors.\n\nInternational movement of authors of both higyly-cited and uncited papers\nIn this section, we report our comparison of the influence of researchers’\ninternational movement on the publication of highly cited papers in comparison\nthat of uncited papers. The identification rate of uncited papers was relatively low,\nand there were countries of which identification rates were very low, so only\nlimited interpretation was possible. However we attempt to grasp tendencies as far\nas possible, by analysis excluding data of which authors’ origin was not unveiled.\n\nFigure 6. Influence of researchers’ movement on national highly cited publications.\n\n1687\n\nA glance at the overall influence of researchers’ flow between two countries\nrevealed a noticeable number of papers published by researchers who moved from\nChina or India to the US (Figure 6). They are both giants in terms of sending\nmassive amounts of research personnel to other countries, particularly the US and\nEuropean countries. The difference between the two movements is that China\nproduced its own highly cited publications (at a rate that is second only to that of\nthe United States), whereas India produced limited ones.\n\nFigure 7. Influence of researchers’ movement on national uncited publications.\n\nOn the other hand, as for uncited papers, there were relatively low numbers of\npublications by internationally moved researchers (Figure 7). Russia which did\nnot publish any highly cited papers, showed the highest Ni(A), however, it had no\npublication by foreign originated researchers. In contrast, India which provided\nhighly cited researchers to other countries, published uncited papers domestically.\nIn the case of the Russian researchers in our sample, they published all of their\narticles in the “Journal of Computer and Systems Sciences International” which is\nthe English-translated version of the Russian theoretical journal. Moreover, most\nof the articles indexed into the field of “Computer Science, Artificial Intelligence”\nin the WoS by Russian researchers were published in the journal. So it can be\npresumed to be one of the most major Russian journals in the field and the\nRussian original version might be cited by domestic journals which might not be\nindexed into the WoS. Therefore, it should be taken into account that there might\nbe some unavoidable geographic bias of citation.\nFigures 8 and 9 show the fact that most countries except for the US, provided\nresearchers who published highly cited papers to other countries while uncited\npapers were published by domestic researchers who did not move to other\ncountries than that of their origin. Comparison of highly cited and uncited papers\nrevealed the fact that researchers who published highly cited tended to move to\n1688\n\nSpain\n\nMexico\n\nCanada\n\nTurkey\n\nIsrael\n\nNetherlands\n\nRussia\n\nAustralia\n\nUK\n\nGermany\n\nIndia\n\nFrance\n\nUS\n\nTaiwan\n\n100%\n90%\n80%\n70%\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nBreakdown by places of residence\n\n20%\n18%\n16%\n14%\n12%\n10%\n8%\n6%\n4%\n2%\n0%\n\nChina\n\nShare of No(A)\n\nother countries from their origin. The reason might be both that researchers with\nability to produce high-impact tended to seek leading-edge research environment\nthat utilize their ability, or that brilliant researchers had more chance to carry out\ntheir research in advanced countries with leading-edge research environment.\nBesides, two Asian research personnel providing giants, China and India, showed\ncontrasting features; researchers of Chinese origin produced both highly cited and\nuncited papers domestically in certain percentages, while those of India published\nmost of highly cited papers abroad and half of uncited papers domestically. Thus,\nit could be suggested that China facilitated more leading-edge research\nenvironment. Researchers of US origin produced all their highly cited papers\ndomestically, therefore, it was suggested that the US attracted both domestic and\nforeign-origin outstanding researchers.\n\nAbroad\nHome country\nShare of No(A)\n\n7%\n\n100%\n90%\n80%\n70%\n60%\n50%\n40%\n30%\n20%\n10%\n0%\n\nShare of No(A)\n\n6%\n5%\n4%\n3%\n2%\n\nBrazil\n\nUK\n\nNetherlands\n\nIran\n\nGermany\n\nCanada\n\nCzech Republic\n\nSpain\n\nTurkey\n\nRussia\n\nGreece\n\nIndia\n\nTaiwan\n\nUS\n\nItaly\n\n0%\n\nChina\n\n1%\n\nBreakdown by places of residence\n\nFigure 8. Shares of No(A) of highly cited publications and their breakdown by their\nplaces of researchers’ residence\n\nAbroad\nHome country\nShare of No(A)\n\nFigure 9. Shares of No(A) of uncited publications and their breakdown by their\nplaces of residence\n1689\n\nWhat types of careers did the authors of highly cited papers have? There were\nseveral variables indicating researchers’ career, such as current or former\npositions, experience of doing research abroad and number of years of active\nresearch. Here, we present only years of research experience, since we could not\napply the former two indicators to our study because of our research design; many\nShort Bios did not reveal positions or accurate working periods, and two different\ndata sources, CVs/Short Bios and the Web of Science database were used for our\nstudy, so it was difficult to learn of the researchers’ experience before the\npublication of specific papers. The years of research experience was defined as\nnumber of years after researchers’ obtained their bachelor or equivalent degrees,\nalong with our previous study (Yamashita et al., 2007). Here, we used a head\ncount not the researcher’s number of publications.\nThe mean years of experience of authors of highly cited papers was 15.8 (15.1\nyears for internationally moved researchers, 16.2 years for domestic researchers),\nand was relatively shorter than that of uncited (18.6 years for all, 18.4 for\ninternationally moved, and 18.7 for domestic). Distribution of experience years\nshowed that researchers with 6 to 15 years of experience occupied half of\ninternationally moved researchers who published highly cited papers, while those\nwith same years of experience occupied only 34% of internationally moved\nresearchers published uncited papers. Although, more detailed analysis of\nresearchers position was needed for securing accuracy, the result suggested that\nmany younger researchers before earning tenure published their highly cited\npapers abroad.\n\nAll\n\n15%\n\n22%\n\n19%\n\n14%\n\n14%\n\n9%\n\n8%\n\nequal or less than 5 years\n6 to 10 years\n11 to 15 years\n\nInt. moved\n\n10%\n\n20%\n\n30%\n\n11%\n\n17%\n\n5% 7%\n\n16 to 20 years\n21 to 25 years\n26 to 30 years\n\nDomes c\n\n16%\n\n18%\n\n0%\n\n10%\n\n20%\n\n30%\n\n18%\n\n40%\n\n16%\n\n50%\n\n60%\n\n12%\n\n70%\n\n12%\n\n80%\n\n9%\n\nmore than 31 years\n\n90% 100%\n\nFigure 10. Years of research experience of authors of highly cited papers.\n\nDeveloped countries are now recognizing excellent foreign-origin researchers as\nengines of knowledge production, which raised a question in our minds: is there\nany difference between the environments of researchers who published highly\ncited papers and those who published uncited papers? We analyzed research\nfunds, which are among the most important resources for conducting research.\n1690\n\nAll\n\n20%\n\n17%\n\n9%\n\n13%\n\n16%\n\n10%\n\n15%\n\nequal or less than 5 years\n6 to 10 years\n11 to 15 years\n\nInt. moved\n\n17%\n\n17%\n\n8%\n\n15%\n\n17%\n\n15%\n\n10%\n\n16 to 20 years\n21 to 25 years\n26 to 30 years\n\nDomes c\n\n0%\n\n21%\n\n17%\n\n9%\n\n10%\n\n20%\n\n30%\n\n13%\n\n40%\n\n50%\n\n15%\n\n60%\n\n70%\n\n8%\n\n80%\n\n18%\n\nmore than 31 years\n\n90% 100%\n\nFigure 11. Years of research experience of authors of uncited papers.\n\nWe gathered funding information from the “Acknowledgements” section of each\npaper. For some studies, only a fraction of the authors had been supported by\nfunding; yet in many of such cases, the funds were acknowledged on a general\nlevel. They were not linked to specific authors. So, we chose to attribute all\nfunding information to every author of a paper. The authors indicate their\nacknowledgements voluntarily, so papers that did not designate any funds were\nnot necessarily unfunded. Because of the abovementioned restrictions, only large\ndifferences between the two groups might be significant.\nThe rate of papers (excluding those that could not be obtained) with funding\ninformation were 45% for highly cited papers, which is 10% higher than that of\nuncited. It was difficult to identify the difference between the two groups, because\nthe difference was not so large.\n\nhighly cited\n\n45%\n\n55%\n\ndesignated\nnot designated\nuncited\n\n34%\n\n0%\n\n66%\n\n20% 40% 60% 80% 100%\n\nFigure 12. Rate of funding indication into the “Acknowledgements” section.\n\n1691\n\nHowever, a breakdown according to status of movement showed a difference\nbetween them. For highly cited authors, there were almost no differences between\nthe two groups, whereas there were tremendous differences between uncited\nauthors. Thirty-six percent of domestic researchers were funded, and only 20% of\ninternational researchers were funded. Therefore, it seems that highly cited papers\ntended to be produced by funding that international researchers could obtain as\neasily as could domestic researchers, regardless of the amount.\n50%\n45%\n\n46%\n\n43%\n\n40%\n\n36%\n\n35%\n30%\nInt. moved\n\n25%\n\n20%\n\n20%\n\nDomes c\n\n15%\n10%\n5%\n0%\nhighly cited\n\nuncited\n\nFigure 13. Rate of funding indication into the “Acknowledgements” section\naccording to researchers’ international movement status.\n\nConclusion\nOur study was limited to a relatively small sample in a specific field, so our\nresults might not apply to all fields. However, at least for highly cited papers,\nespecially those written by university researchers, this method based on published\nresearchers CVs or Short Bios proved to be effective from our study. However,\nthere were countries of where identification rates were systematically low, such as\nRussia. Such countries might pose a strong bias to data, so in the case of random\nsampling from a whole population, analysts should be careful.\nOur study also revealed the fact that industrial researchers do not tend to unveil\ntheir career information. So researchers’ CVs or Short Bios should be collected\nperiodically, especially for the fields relating to industrial application, because\nmany researchers move across sectors.\nOn the other hand, our analysis of international movement revealed that both\ndomestic and internationally moved researchers contribute to national\npublications almost equally. Especially, the influence of researchers’ flow from\nthe two Asian giants (China and India) to the US was observed. However, profiles\nof them were contrastive; Chinese researchers produced their highly cited papers\ndomestically to some extent, whereas Indian researchers tended to produce most\nof highly cited papers in abroad. What caused their contrastive natures? One\npossible interpretation is their policies concerning the use of foreign outstanding\n1692\n\nresearch personnel originated in them. Jonkers (2008b) reported that China\nimplemented many programs to attract overseas Chinese scholars to return their\nhome country whereas India had not been nearly as keen to do so. To analyze this,\ncareers of researchers should be analyzed tolerating certain amount of error\nattributed to a lack of order or accurate period of them in researchers’ CVs or\nShort Bios.\nOur analysis of researchers’ years of experience and of their funding for their\npapers revealed that highly cited papers were produced utilizing researchers with\n6 to 15 years after taking bachelor degree, and produced in the environment in\nwhich foreign-origin researchers could use funds as much as domestic researchers\neither directly or indirectly. Although it is kept in mind that the research funds\ndesignated in papers were not necessarily distributed to all authors, and their\namount was out of consideration, these results suggested that highly cited papers\nwere produced in an environment where young excellent foreign-origin\nresearchers were utilized and were allowed to take research funds regardless of\ntheir origin.\nThe present research utilized uncited papers for comparison with highly cited and\ncould depict some natures of highly cited papers. However, factors which leave\npapers uncited seemed to be so diverse that assessment of them seemed\nproblematic. As MacRoberts &amp; MacRoberts (2010) pointed out, uncited papers\nwere not necessary to be not used. While many papers published by researchers\nworking in Russian institutes were not cited in our study, it should be taken into\naccount that they are published in a journal translated from an original Russian\njournal. Thus if they were assessed, citation that the original Russian paper\nobtained should be taken into account.\nFinally, the present study aimed to analyze the influence of human capital on\nnational publications of highly cited papers, so we focused on output not on\nresearchers. However, authors of highly cited papers do not always publish highly\ncited papers, and authors of uncited papers might have a chance to publish highly\ncited papers during their long career. Although we could not find any authors who\npublished both highly cited and uncited papers in our sample, such situations\nmight occur in other contexts Thus, our research design required each author to be\ndealt with as an aggregation, since its population contained inherent noise to some\nextent.\nQuantitative analyses based on researchers’ career information provide us with\nabundant suggestions, that cannot be obtained by bibliometrics solely. However,\nits laborious nature and low coverage would be caused by the nonstandardized\nformatting of CVs and Short Bios. Therefore, for analyzing researchers dealing as\ncollective, it is desirable to develop a method for efficient data gathering and\ncoding.\n\n1693\n\nAcknowledgments\nThis research was supported by the JST/RISTEX research funding program titled\n“Science of Science, Technology and Innovation Policy” and by JSPS KAKENHI\nGrant Number 23500304.\nReferences\nCorley, E.A., Bozeman, B. &amp; Gaughan, M. (2003). Evaluating the impacts of\ngrants on women scientists’ careers: The curriculum vita as a tool for research\nassessment. In P. Shapira and S. Kuhlmann (Eds), Learning from science and\ntechnology policy evaluation: Experiences from the U.S. and Europe, (pp.293315).\nCruz-Castro, L. &amp; Sanz-Menendez, L. (2010). Mobility versus job stability:\nAssessing tenure and productivity outcomes. Research Policy, 39, 27-38.\nDietz, J.S., Chompalov, I., Bozeman, B. &amp; Park, J. (2000). Using the curriculum\nvita to study the career paths of scientists and engineers: An exploratory\nassessment. Scientometrics, 49, 419-442.\nDietz, J. S., &amp; Bozeman, B. (2005). Academic careers, patents, and productivity:\nindustry experience as scientific and technical human capital. Research Policy,\n34, 349-367.\nFurukawa, T., Shirakawa, N. &amp; Okuwada, K. (2011). Quantitative analysis of\ncollaborative and mobility networks. Scientometrics 87, 451-466.\nIoannidis, J.P.A., (2004). Global estimates of high-level brain drain and deficit.\nFASEB Journal, 18, 936-939.\nJonkers, K. (2008a). Chinese researchers returning home: Impacts of international\nmobility on research collaboration and scientific productivity,\nScientometrics,77, 309-333.\nJonkers, K. (2008b). A comparative study of return migration policies targeting\nthe highly skilled in four major sending countries, Analytical Report, MIREMAR 2008/05, European University Institute.\nJonkers, K. (2010). Mobility, Migration and the Chinese Scientific Research\nSystem, Oxford: Routledge.\nLepori, B. &amp; Probst, C. (2009). Using curricula vitae for mapping scientific fields:\nA small-scale experience for Swiss communication sciences. Research\nEvaluation, 18, 125-134.\nLewison, G. &amp; Kundra, R.(2008). The internal migration of Indian scientists,\n1981–2003, from an analysis of surnames. Scientometrics, 75, 21-35.\nLaudel, G. (2003). Studying the brain drain: Can bibliometric methods help?,\nScientometrics 57, 215-237.\nMacRoberts, M.H. &amp; MacRoberts, B.R. (2010), Problems of citation analysis: A\nstudy of uncited and seldom-cited influences. Journal of the American Society\nfor Information Science and Technology, 61, 1-13.\nSandström, U. (2009). Combining curriculum vitae and bibliometric analysis:\nmobility, gender and research performance, Research Evaluation, 18, 135-142.\n\n1694\n\nYamashita, Y., Tomizawa, H., Ueno, S. &amp; Kondo, M.(2007, June). Influence of\nthe International migration of researchers on national publications in three\nfields of engineering. Poster session presented at the 11th International\nConference on Scientometrics and Informetrics. Madrid.\nYamashita, Y. (2011, July). An attempt to grasp researchers’ international\nmigration. Poster session presented at the 13th International Conference on\nScientometrics and Informetrics. Durban.\n\n1695\n\nTO WHAT EXTENT IS THE H-INDEX\nINCONSISTENT? IS STRICT CONSISTENCY A\nREASONABLE REQUIREMENT FOR A\nSCIENTOMETRIC INDICATOR?\nYuxian Liu1\n1\n\nyxliu@tongji.edu.cn\nTongji University, Tongji University Library, Siping Street 1239,200092 Shanghai,\n(China)\n\nAbstract\n\nWe use a combinatorial approach to calculate the probability of inconsistency of the hindex and try to figure out the factors that influence the probability of the occurrence of\nthis inconsistency. We observe that only when the number of new papers that two authors\npublish is not smaller than the difference of the h-indices of these two authors, and the\nnumbers of citations that these papers have received are not smaller than the larger hindex of two authors, the inconsistency problem of the h-index can occur. We hence argue\nthat inconsistency of the h-index is caused by the progress that the laggard is making so\nthat the laggard can catch up to the trendsetter. In this sense we suggest that some\ninconsistency should be tolerated when we design a scientometric indicator to measure the\ndevelopment of science or the progress of a scientist. We show by our calculations that\nfactors such as the h-indices of two authors, the difference between their h-indices, the\nmaximum numbers of citations that two authors can receive, the number of new papers\nthat the authors publish later and the number of citations received by these new papers all\ninfluence the probability of inconsistency of the h-index.\n\nIntroduction\nThe notion of an indicator is a powerful concept in scientometric research.\nValidity and reproducibility are two basic requirements to decide if an indicator is\nacceptable. Validity means that one has to make sure that one really measures\nwhat is intended to be measured. Reproducibility means that under identical\nconditions results must be identical.\nRecently consistence and independence are proposed as requirements for the\nacceptance of a research indicator (Bouyssou&amp;Marchant, 2010, 2011a, 2011b;\nMarchant, 2009a, 2009b, Waltman and van Eck, 2009a, 2009b, 2011). However,\nthe meaning of (and difference between) the terms consistence and independence\nis not always clear. Here we use the term consistence with respect to ranking two\nauthors, if the following rule holds.\nConsider two authors, A1 and A2, where A1 is considered strictly better\nthan A2 according to the given ranking method for authors; if now the\ntwo authors improve their paper/citation record by the same (absolute)\n1696\n\namount, then A1 must stay strictly better than A2 (Bouyssou &amp;\nMarchant, 2011b).\nThe notion of congruousness as defined by Rousseau is slightly different from\nconsistence. Rousseau (2011) uses a reference set to determine scores and\nrankings. This reference set is subdivided into K disjoint classes; if a document\nbelongs to class K, then it receives a score xk. If the reference set does not change,\nthen all class borders do not change and the score of an element will not change.\nIn this case an indicator will be consistent.\nHowever, if indicators are designed to measure the development of science, it is\nunavoidable to add one or more new articles that change the reference set by\nwhich we define classes. We then have to know what happens to the value of an\nindicator if a new articleis published. Rousseau (2011) argued that it was always\npossible—by exploiting these small changes—to prove inconsistency. Here we\nask the questions: “To what extent do these small changes give rise to\ninconsistency? Which factors influence the extent of inconsistency?”\nWe use the h-index (see definition below) to illustrate the notion of inconsistency.\nQuestions\nThe h-index is defined as follows: A scientist has an h-index of h if h of his\npapers each have at least h citations and his remaining papers each have fewer\nthan h + 1 citations (Hirsch 2005).\nIf we rank the papers of scientist S according to the number of citations each of\nthese papers has received then the first h paper must have at least h citations.\nThepapers ranked between rank 1 and rank h form the h-core. Papers ranked after\nrank h form the h-tail(Hirsch 2005, Liu &amp; Rousseau 2009).\nFor our investigations we assume that, in a given field F, there exists a maximum\nnumber of citations over the period of interest. As an example we take this\nmaximum equal to 7. In general this maximum is denoted as\n. We assert that\nthis assumption is reasonable since the maximum number of citations in any field\nis finite and can be obtained from the used database. Now we randomly select two\nauthors, author A and author B, in this field and ask in how many ways numbers\nof citations of publications in the h-core can lead to the h-indices of these two\nauthors. The h-index of author A is hA , and the h-index of author B is hB. As a\ncase study we assume that the h-index of author A is 5 and that of author B is 3.\nThere are no further restrictions so that the number of citations of an article\nwritten by A or B both author A and author B can reach the field’s maximum\nnumber of citations.\nSuppose that each of the above authors publishes the same number of additional\npapers and that, for each of these papers, each author receives exactly the same\nnumber of citations. How will the new papers change the h-index of these two\nauthors? In which situations can the h-index of author A become higher than the\n1697\n\nh-index of author B? In which situations can this not happen? To what extent is\nthe h-index inconsistent? Is strict consistency a reasonable requirement for a\nscientometric indicator?\nArrays of numbers of citations of the papers in the h-core that can make the\nh-index of an author be equal to h\nThere are h papers in the h-core if the h-index of an author is h. The h numbers of\nreceived citations constitute an array. How many arrays can make the h-index of\nan author be equal to h? Concretely how many arrays can make the h-index of\nauthor A be ? How many arrays can make the h-index of author B be ?\nThis question can be formulated as a combinatorial problem. For author A, these\nnumbers of citations can be any hA integers in the set of integers in the interval\n. So\nintegers are repeatedly selected from the set of integers in the\ninterval\nand then ranked in the\npositions. In how many different ways\ncan this be done?\n) to denote the number of selections from the set of integers in\nWe use (\nthe interval\n.\n(\n\n)\n\n)\n\n(\n\n(\n\n)\n\n(\n\n)\n\nThis expression is sometimes referred to as an -combination with repetitions.\nFor author A,\n; these 5 integers are repeatedly selected from the set\n{5,6,7}.\n(\n\n)\n\n( )\n\nThere 21 arrays are shown in table 1.\nTable 1. Arrays of the numbers of citations of the papers in the h-core of the author\nA\n7,7,7,7,7\n7,7,7,7,6\n7,7,7,6,6\n\n7,7,6,6,6\n7,6,6,6,6\n6,6,6,6,6\n\n7,7,7,7,5\n7,7,7,5,5\n7,7,5,5,5\n\n7,5,5,5,5\n5,5,5,5,5\n6,6,6,6,5\n\n6,6,6,5,5\n6,6,5,5,5\n6,5,5,5,5\n\n7,7,7,6,5\n7,7,6,6,5\n7,6,6,6,5\n\n7,7,6,5,5\n7,6,6,5,5\n7,6,5,5,5\n\nIn our study the numbers of citations of the papers in h-tail don’t influence the\nchange of the h-index, so we do not consider them.\nFor author B,\nthese 3 integers are repeatedly selected from the set of\nintegers in the interval [3,7].\n(\nThese 35 arrays are shown in table 2.\n\n1698\n\n)\n\n( )\n\nTable 2. Arrays of the numbers of citations of the papers in the h-core of author B\n3,3,3\n4,3,3\n4,4,3\n4,4,4\n5,3,3\n\n5,4,3\n5,4,4\n5,5,3\n5,5,4\n5,5,5\n\n6,3,3\n6,4,3\n6,4,4\n6,5,3\n6,5,4\n\n6,5,5\n6,6,3\n6,6,4\n6,6,5\n6,6,6\n\n7,3,3\n7,4,3\n7,4,4\n7,5,3\n7,5,4\n\n7,5,5\n7,6,3\n7,6,4\n7,6,5\n7,6,6\n\n7,7,3\n7,7,4\n7,7,5\n7,7,6\n7,7,7\n\nThe number of the new papers and the numbers of citations of these new\npapers that can give rise to the problem of inconsistency of the h-index\nIf author A and author B publish the same number of new papers receiving the\nsame numbers of citations, how many papers must author A and author B publish\nand how many citations must these papers receive so that the h-indices of these\ntwo authors will lead to an inconsistency problem?\nWe use #(P) to denote the number of new papers that two authors publish and we\nuse\nto denote the new h-index of author A and\nto denote the new h-index\nof author B. Then we have the following inequalities:\n\nAs\n\nhA &gt; hB\n( )\n( )\n( ( )\n\nIf now ( )\nthen\n\n)\n( )\n.\n\nSo the problem of inconsistency will not occur in this case.\nWe use ( ) to denote the number of citations received by the two authors’ new\npapers.If the number of citations received by a new paper is not larger than the\nsmaller h-index of the two authors (assume it is ), ( )\n, then the hindices of these two authors will not change. The problem of inconsistency cannot\noccur.\nIf the numbers of citations that these papers receive are larger than the smaller h( )\nindex but less than the larger h-index of the two authors,\n, these\npapers cannot make the h-index of author B increase to . This will also not give\nrise to an inconsistency.\nThese considerations lead to proposition A.\nProposition A: if the number of new papers that two authors publish is smaller\nthan the difference of the h-indices of these two authors, this will not give rise to\nan inconsistency. If the numbers of the citations these papers have received are\n\n1699\n\nless than the larger h-index of two authors, then again there will be no\ninconsistency.\nHence, only when the number of new papers that two authors publish is not\nsmaller than the difference of the h-indices of these two authors and the numbers\nof the citations these papers have received are larger than or equal to the larger hindex of the two authors, the problem of inconsistency can occur.\nWe now only consider situations for which the inconsistency problem can occur\nand check to what extent the h-index is inconsistent, i.e. we only consider\n( )\nsituations such as\n.\nChange of the arrays of the numbers of citations of the papers in the original\nh-core and the numbers of citations of new papers\nWe now calculate the number of new arrays of each author formed by the\nnumbers of citations of the papers in the h-core and the new papers the author\npublish. The corresponding numbers of citations of the additional papers of author\nA and author B are the same. We use ( ) to denote the number of citations the\n( )\npaper that ranked at the first place has received. And also\n. how\nmany arrays can be formed by these numbers of citations of the papers in the hcore and the new paper? This is equivalent to the combinatorial problem of\ndetermining in how many different ways\nintegers can be repeatedly\nselected from the set of integers in the interval\n.\n) to denote the number of combinations of these numbers of\nWe use (\ncitations of the papers in the h-core of author A and of the one new paper by\nauthor A.\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\n( )\n\nThese 28 arrays are shown in table 3.\nTable 3. Arrays of the numbers of citations of the papers in the h-core and one new\npaper of author A\n7,7,7,7,7,5\n7,7,7,7,6,5\n7,7,7,6,6,5\n7,7,6,6,6,5\n\n7,6,6,6,6,5\n6,6,6,6,6,5\n7,7,7,7,5,5\n7,7,7,5,5,5\n\n7,7,5,5,5,5\n7,5,5,5,5,5\n5,5,5,5,5,5\n6,6,6,6,5,5\n\n6,6,6,5,5,5\n6,6,5,5,5,5\n6,5,5,5,5,5\n7,7,7,6,5,5\n\n7,7,6,6,5,5\n7,6,6,6,5,5\n7,7,6,5,5,5\n7,6,6,5,5,5\n\n7,6,5,5,5,5\n7,7,7,7,7,6\n7,7,7,7,6,6\n7,7,7,6,6,6\n\n7,7,6,6,6,6\n7,6,6,6,6,6\n6,6,6,6,6,6\n7,7,7,7,7,7\n\n) to denote the number of combinations of these numbers of\nWe use (\ncitations of the papers in the h-core and one new paper of author B. This new\npaper also receives ( ) citations.Then how many combinations do these\nnumbers have? This is equivalent to finding the number of ways in which we\n1700\n\nselect\nintegers repeatedly from the set of integers in the interval\nminus the number of ways we select\nintegers repeatedly from the set of\nintegers in the interval\n.\n(\n\n)\n\n(\n(\n\n)\n)\n\n(\n\n)\n\n(\n\n( )\n\n)\n\n( )\n\nThese 65 arrays are shown in table 4.\nTable 4. Arrays of the numbers of citations of the papers in the h-core and one new\npaper of author B\n7,7,7,7\n7,7,7,6\n7,7,6,6\n7,6,6,6\n6,6,6,6\n7,7,7,5\n7,7,6,5\n7,6,6,5\n6,6,6,5\n7,7,5,5\n7,6,5,5\n6,6,5,5\n7,5,5,5\n\n6,5,5,5\n5,5,5,5\n7,7,7,4\n7,7,6,4\n7,6,6,4\n6,6,6,4\n7,7,5,4\n7,6,5,4\n6,6,5,4\n7,5,5,4\n6,5,5,4\n5,5,5,4\n7,7,4,4\n\n7,6,4,4\n6,6,4,4\n7,5,4,4\n6,5,4,4\n5,5,4,4\n7,4,4,4\n6,4,4,4\n5,4,4,4\n7,7,7,3\n7,7,6,3\n7,6,6,3\n6,6,6,3\n7,7,5,3\n\n7,6,5,3\n6,6,5,3\n7,5,5,3\n6,5,5,3\n5,5,5,3\n7,7,4,3\n7,6,4,3\n6,6,4,3\n7,5,4,3\n6,5,4,3\n5,5,4,3\n7,4,4,3\n6,4,4,3\n\n5,4,4,3\n7,7,3,3\n7,6,3,3\n6,6,3,3\n7,5,3,3\n6,5,3,3\n5,5,3,3\n7,4,3,3\n6,4,3,3\n5,4,3,3\n7,3,3,3\n6,3,3,3\n5,3,3,3\n\nWe now calculate the number of arrays formed by the numbers of citations in the\nh-core of each author and two new papers published by each author. The numbers\nof citations of two new papers of author A are the same as those received by\nauthor B. We use ( ) to denote the number of citations received by one paper\nand use ( ) to denote the number of citations the other paper has received. We\n( )\n( )\nhave:\n,\n.\nHow many arrays can be formed by these numbers of citations of author A? This\nproblem is equivalent to the combinatorial problem of finding in how many\ndifferent ways\nintegers can be repeatedly selected from the set of integers\nin the interval\n.\n) to denote the number of combinations of these numbers of\nWe use (\ncitations of the papers in the h-core and two new papers of author A.\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\n( )\n\nThese 36 arrays are shown in table 5.\n1701\n\nTable 5. Arrays of the numbers of citations of the papers in the h-core and two new\npapers of author A\n7,7,7,7,7,7,7\n7,7,7,7,7,7,6\n7,7,7,7,7,7,5\n7,7,7,7,7,6,6\n7,7,7,7,7,6,5\n7,7,7,7,7,5,5\n\n7,7,7,7,6,6,6\n7,7,7,7,6,6,5\n7,7,7,7,6,5,5\n7,7,7,7,5,5,5\n7,7,7,6,6,6,6\n7,7,7,6,6,6,5\n\n7,7,7,6,6,5,5\n7,7,7,6,5,5,5\n7,7,7,5,5,5,5\n7,7,6,6,6,6,6\n7,7,6,6,6,6,5\n7,7,6,6,6,5,5\n\n7,7,6,6,5,5,5\n7,7,6,5,5,5,5\n7,7,5,5,5,5,5\n7,6,6,6,6,6,6\n7,6,6,6,6,6,5\n7,6,6,6,6,5,5\n\n7,6,6,6,5,5,5\n7,6,6,5,5,5,5\n7,6,5,5,5,5,5\n7,5,5,5,5,5,5\n6,6,6,6,6,6,6\n6,6,6,6,6,6,5\n\n6,6,6,6,6,5,5\n6,6,6,6,5,5,5\n6,6,6,5,5,5,5\n6,6,5,5,5,5,5\n6,5,5,5,5,5,5\n5,5,5,5,5,5,5\n\n) to denote the number\nWe now discuss the situation of author B. We use (\nof combinations of these numbers of citations of the original papers in the h-core\nand two new papers of author B. These two new papers also receive ( ) and\n( ) citations.\n(\n\n)\n\n(\n(\n\n)\n)\n\n(\n\n)\n\n( )\n\n(\n\n)\n\n( )\n\nThese 120 arrays are shown in table 6\nTable 6. Arrays of the numbers of citations of the papers in the h-core and two new\npapers of author B\n7,7,7,7,7\n7,7,7,7,6\n7,7,7,7,5\n7,7,7,7,4\n7,7,7,7,3\n7,7,7,6,6\n7,7,7,6,5\n7,7,7,6,4\n7,7,7,6,3\n7,7,7,5,5\n7,7,7,5,4\n7,7,7,5,3\n7,7,7,4,4\n7,7,7,4,3\n7,7,7,3,3\n7,7,6,6,6\n7,7,6,6,5\n7,7,6,6,4\n7,7,6,6,3\n7,7,6,5,5\n\n1702\n\n7,7,6,5,4\n7,7,6,5,3\n7,7,6,4,4\n7,7,6,4,3\n7,7,6,3,3\n7,7,5,5,5\n7,7,5,5,4\n7,7,5,5,3\n7,7,5,4,4\n7,7,5,4,3\n7,7,5,3,3\n7,7,4,4,4\n7,7,4,4,3\n7,7,4,3,3\n7,7,3,3,3\n7,6,6,6,6\n7,6,6,6,5\n7,6,6,6,4\n7,6,6,6,3\n7,6,6,5,5\n\n7,6,6,5,4\n7,6,6,5,3\n7,6,6,4,4\n7,6,6,4,3\n7,6,6,3,3\n7,6,5,5,5\n7,6,5,5,4\n7,6,5,5,3\n7,6,5,4,4\n7,6,5,4,3\n7,6,5,3,3\n7,6,4,4,4\n7,6,4,4,3\n7,6,4,3,3\n7,6,3,3,3\n7,5,5,5,5\n7,5,5,5,4\n7,5,5,5,3\n7,5,5,4,4\n7,5,5,4,3\n\n7,5,5,3,3\n7,5,4,4,4\n7,5,4,4,3\n7,5,4,3,3\n7,5,3,3,3\n7,4,4,4,4\n7,4,4,4,3\n7,4,4,3,3\n7,4,3,3,3\n7,3,3,3,3\n6,6,6,6,6\n6,6,6,6,5\n6,6,6,6,4\n6,6,6,6,3\n6,6,6,5,5\n6,6,6,5,4\n6,6,6,5,3\n6,6,6,4,4\n6,6,6,4,3\n6,6,6,3,3\n\n6,6,5,5,5\n6,6,5,5,4\n6,6,5,5,3\n6,6,5,4,4\n6,6,5,4,3\n6,6,5,3,3\n6,6,4,4,4\n6,6,4,4,3\n6,6,4,3,3\n6,6,3,3,3\n6,5,5,5,5\n6,5,5,5,4\n6,5,5,5,3\n6,5,5,4,4\n6,5,5,4,3\n6,5,5,3,3\n6,5,4,4,4\n6,5,4,4,3\n6,5,4,3,3\n6,5,3,3,3\n\n6,4,4,4,4\n6,4,4,4,3\n6,4,4,3,3\n6,4,3,3,3\n6,3,3,3,3\n5,5,5,5,5\n5,5,5,5,4\n5,5,5,5,3\n5,5,5,4,4\n5,5,5,4,3\n5,5,5,3,3\n5,5,4,4,4\n5,5,4,4,3\n5,5,4,3,3\n5,5,3,3,3\n5,4,4,4,4\n5,4,4,4,3\n5,4,4,3,3\n5,4,3,3,3\n5,3,3,3,3\n\nChange in h-index values of authors A and B\nIf each of author A and author B publishesthe same number of new papers, such\nthat they receive the same numbers of citations (pairwise) and such that the\nnumbers of citations are all larger than , then what do the h-indices of both\nauthors become?\nWe assume that the h-index of author A becomes\nand the h-index of author B\nbecomes\nafter each of the above authors published one new paper with the\nsame number of citations. The h-index of author A becomes\n, the h-index of\nauthor B becomes\nafter each of the authors published two more papers. The\nnumbers of citations of these papers are all not smaller than .\nIt is possible that the h-index will increase by one, and it is also possible that the\nh-index will not change after the author publishes one more paper receiving a\nnumber of citations larger than h. For the two authors with different h-indices, it\nis possible that the larger h-index increases by one, and the smaller h-index stays\nthe same. It is also possible that the larger h-index does not change but the smaller\nh-index increase by one. It is also possible that the h-indices of both authors\nincrease by one or stay the same. These possible changes of the h-indices are\nshown in table 7.\nTable 7. Possible changes of the h-indices of author A and author B after adding\nsome more papers\noriginal h-indices\n\nAdding one\npaper\n,\n\n,\n,\n,\n\n,\n\n, only when\nObviously the first step to reach\n\nAdding two\npapers\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n\n, the problem of inconsistencycan occur.\nis that\n.\n\n1703\n\nIf\n,both authors publish one more article, the number of citations of\nthis paper is larger than , then only when\n, i.e.\nthe last row and the third column in the table 7do we have an inconsistency.\nIf\n, when both authors only publish one more paper, there is no\nproblem of inconsistency. The problem of inconsistency only occurs when both\nauthors publish two more papers:\n. This situation is\nshown in the last row and the fifth column in table 8.\nWhen is\n? If\nand\n, there must at least be two\nnew papers. When is\n? If\nand\nthere must at\nleast be three new papers. Other situations are feasible; however, we do not go\nfurther. We just discuss how the smaller h-index catches up with the larger one.\nProbability of inconsistency\nWe now use our example to calculate the probability that\nand the probability that\nwhen\n.\nIf\n, then the h-index of author A must stay the same and the\nh-index of author B must increase by one when the two authors publish one more\npaper.\nIf\n, then the h-index of author A must stay the same and the hindex of author B must increase by two after publishing each two more papers.\nWe first calculate the probability of\nwhen both authors\npublish one new paper,and then the probability of\nwhen both\nauthors publish two new papers.\nAuthor A as well as author B publish one newpaper\nThere are\nintegers in the arrays formed by the numbers of citations of the\noriginal papers in the h-core and one new paper of author A. If the h-index of\nauthor A didn’t change after the author A published one more article, then the\ninteger in the (\n) position must be smaller than\n, since all numbers\nof citations of these papers are not smaller than , so\nmust be placed in this\nposition. The other\nintegers are selected from the set of integers in the interval\n.\nHow many arrays can make\n? This is equivalent to acombinatorial\nproblem in how many different ways\nintegers can be repeatedly selected from\nthe set of integers in the interval\n.\nWe use (\nand use ( (\n) to denote the probability of\n))\nto denote the number of arrays that make\n.\n(\n\n1704\n\n(\n\n))\n\n(\n\n)\n\n(\n\n)\n\n( )\n\n(\n(\n\n(\n\n)\n\n)\n\n(\n\n)\n\n(\n\n)\n\n)\n\n(\n(\n\n(\n\n)\n)\n\n)\nWe then discuss the probability of\nafter author B published one more\npaper. The number of citations this paper has received is larger than .\nWe use (\n. We use ( (\n) to denote the probability of\n))\nto denote the number of arrays that make\n.\n(\n(\n\n(\n(\n\n)\n\n)\n\n)\n\n(\n\n(\n\n(\n\n)\n\n)\n\n))\n\n(\n\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\nWe now discuss the probability of\n(\n) to denote the probability of\n(\n(\n\n)\n\n)\n(\n\n(\n\n))\n\n(\n\n)\n\n(\n\n)\n\nand\nand\n\n(\n\n)\n\n(\n\n)\n\n) (\n\n)\n\n(\n\n)\n\n(\n(\n\n. We use\n.\n) (\n) (\n\n)\n\n(\n\n)\n\n)\n\n(\n\n)\n\nThis is a case of potential probability of inconsistency. The larger h-index is still\nlarger than the smaller, though the advantage of author A has become\nsmaller.\nBoth author A and author B publish two new papers\nThere are\nintegers in the arrays formed by the numbers of citations of the\noriginal papers in the h-core and two new papers of author A.\nIf the h-index of author A didn’t change after author A published two more\narticles, then the integer in the (\n) position must be smaller than\n,\nsince all numbers of citations of these papers are not smaller than , so\nmust\nbe placed in this position. The first\nintegers are from the set of integers in the\ninterval\n. How many arrays can make\n?This is equivalent to the\ncombinatorial problem of finding in how many different ways\nintegers can be\nrepeatedly selected from the set of integers in the interval\n.\n\n1705\n\nWe use\n( (\n\nto denote the probability of of\n) ) to denote the number of arrays that make\n(\n\n(\n\n(\n\n))\n\n(\n\n)\n\n(\n(\n\nWe use\n( (\n\n(\n\n(\n\n)\n\n(\n\n(\n\n)\n\n( )\n\n)\n\n(\n\n)\nand use\n\n)\n\n( )\n\n(\n\n(\n\n))\n\n)\n\n)\n)\n\n)\n\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\n(\n\n)\n\nand\n\n.\n\nto denote the probability of\n(\n\n(\n\n)\n\n( )\n\n(\n\n(\n\n(\n\n(\n\n)\n\n.\n\n))\n\n(\n\nWe now discuss the probability of\nWe use\n\n)\n\nto denote the probability of\n) ) to denote the numbers of arrays that make\n\n)\n\n)\n\n(\n\n.\n\n)\n\n(\n\n(\n\n(\n\n))\n\n(\n\n)\n\n(\n(\n\nand use\n\n)\n\n(\n\n)\n)\n\n(\n\n) (\n\n)\n\n(\n\n) (\n\n)\n\nand\n\nWe list all our calculations in table 8\nTable 8. Probability of inconsistency. (The maximum number of citations is 7, the hindex of author A is 5, and the h-index of author B is 3).\n\npublishes one\npaper\npublishes two\npapers\n\n1706\n\nAuthor\n\nTotal\nnumber\nof arrays\n\nNumber of arrays\nthat might give rise\nto inconsistency\n\nA\nB\nA\nB\n\n28\n65\n36\n120\n\n21\n34\n21\n21\n\nProportion\n\n0.75\n0.523\n0.583\n0.175\n\nProbability\nof\ninconsistenc\ny\n0.392308\n0.102083\n\nUsing the same method we also calculate the probability of inconsistency of the\nh-index when the difference of the h-indices is 1, still assuming that the maximum\nnumber of citations is 7. So the larger h-index changes from 2 to 7, and the\nsmaller one changes from 1 to 6. The results are shown in table 9.\nTable 9. Comparison of the probability of inconsistency between different h-indices\nAuthors\nA\nB\nA\nB\nA\nB\nA\nB\nA\nB\nA\nB\n\nTotal\nnumber of\narrays\n56\n27\n70\n55\n56\n69\n28\n55\n8\n55\n1\n7\n\nNumber of arrays\nthat might give rise\nto inconsistency\n21\n21\n35\n35\n35\n35\n21\n21\n7\n21\n1\n1\n\nProportion\n\nProbability of\nboth authors\n\n0.375\n0.778\n0.5\n0.636\n0.625\n0.507\n0.75\n0.381\n0.875\n0.382\n1\n0.143\n\n0.291667\n0.318182\n0.317029\n0.286364\n0.334091\n0.142857\n\nFigure 1. Change of the probability of inconsistency according to the h-index\n\nFrom figure 1, we can see that the probability of inconsistency is increasing when\nthe h-index is small, it reaches a maximum when the h-index is in the middle\nbetween 0 and the maximum number of citations, then decreases, but in the end, it\nfluctuates again. It reaches a minimum when the larger h-index is equal to the\nmaximum number of citations.\n1707\n\nConclusion and Discussion\nWe illustrated the fact that the probability of inconsistency of the h-index can be\ncalculated by combinatorial theory. We showed the factors such as the h-indices\nof two authors, the difference between the h-indices of the authors, the maximum\nnumbers of citations of that two authors can receive, the number of the new\npapers the authors publish and the numbers of citations these new papers receive,\nthat influence the probability of inconsistency of the h-index.\nWe still did not investigate how these factors influence the extent of the\ninconsistency in detail. Intuitively, the larger the maximum number of citations\nand the bigger the difference between the h-indices of the authors is, the smaller\nthe probability of inconsistency. Our preliminary calculations confirm this point,\ni.e., the probability of inconsistency of the h-index is smaller when the difference\nof the h-indices of authors is 2 than when the difference of the h-indices is 1.\nHowever this aspect should be further investigated so that we know exactly, or at\nleast approximately, how the probability of inconsistency changes according to\nthe h-indices of the authors and the maximum number of citations. It should also\nbe checked if the extent of inconsistency can be tolerated. If 0.1probability of\ninconsistency cannot be tolerated, then how about 0.0001? How can the h-index\nand the maximum number of citations of each author lead to such a low\nprobability of inconsistency?\nWhat does inconsistence mean to the development of science or to the progress of\na scientist? We observe that only when the number of papers that two authors\npublish later is not smaller than the difference of the h-indices of these two\nauthors, and the numbers of citations that these papers have received is larger than\nor equal to the h-index of author A, i.e., the higher h-index of two authors, the\nproblem of inconsistency may occur. Can we think of inconsistency as a sign that\nauthor B is making progress? If the number of citations really is a scientific\nstandard, then author B has published some more papers and the papers have\nreceived so many citations that these papers can enter the h-core of author A.\nWhy is it not a sign that author B is catching up with author A? Consider two\nauthors, the first one has 1000 papers with 1000 citations each. The second has\nonly one paper with one citation, the h-index of the first author is 1000 whereas\nthe h-index of the second is 1. When each of the above authors publishes 1000\nmore papers with 1000 citations, the h-index of the first author is now still 1000,\nand the h-index of the second author also reaches 1000, why can we not regard\nsuch an event as showing that the second author is making great progress and the\nfirst author just publishes on the same level?\nIs consistency a necessary requirement when scientific indicators are designed to\nmeasure the development of science or the progress of a scientist? Our world is\ndiverse, and hence how things in the world develop is also diverse. When the\nworld is always consistent, the trendsetter is always a trendsetter, the laggard is\nalways a laggard, and all scientists behave as the soldiers in parade formation. Is\nthis possible? If the laggard makes some progress, we certainly should say he\n1708\n\nbecame a better scientist. How does a laggard catch up with the trendsetter?\nCertainly if he does much better than the trendsetter, then we say he is making\nsuch a progress that he is now as good as or even better than the trendsetter.\nHowever, if he does as well as the trendsetter, it is also progress. Isn’t it? Progress\nis made in different ways, science also develops in different ways, not in a\nconsistent way. Scientific indicators designed to measure the development of\nscience and the progress of a scientist should tolerate these differences.\nAcknowledgement\nThis work was prepared when I was dealing with a crisis of life. I sincerely thank\nfor the support from all members of the Class 1987 of Agricultural Information\nScience in Nanjing Agricultural University, Lu Junxi, Liang Jin, Du Juan, Wang\nHaiying, Yan Sulan, Zhang Min, Yin Jiahui, Wei Wenjie, Yao Junlan,\nQiuXuejun, Xu Wenyi, Dong Xiaoyun and many blog friends who encouraged\nme to pass through such a tough and tedious period. I thank Cao Cong for\ntolerating the delay of a collaborative work again and again. I also thank Raf\nGuns and Ronald Rousseau for valuable comments on an early version of this\nwork. This work is supported by the National Natural Science Foundation of\nChina (NSFC grant No. 71173154).\nReferences\nBouyssou, D., &amp; Marchant, T. (2010). Consistent bibliometric rankings of authors\nand journals. Journal of Informetrics, 4, 365–378.\nBouyssou, D., &amp; Marchant, T. (2011a). Bibliometric rankings of journals based\non impact factors: An axiomatic approach. Journal of Informetrics, 5(1),75–86.\nBouyssou, D., &amp; Marchant, T. (2011b). Ranking scientists and departments in a\nconsistent manner. Journal of the American Society for Information Science\nand Technology, 62(9), 1761–1769.\nHirsch, J. E. (2005). An index to quantify an individual’s scientific research\noutput. Proceedings of the National Academy of Sciences of the United States\nof America, 102(46), 16569–16572.\nLiu, Y. X., &amp; Rousseau, R. (2009). Properties of h-type indices: The case of\nlibrary classification categories. Scientometrics, 79(2), 235–248.\nMarchant, T. (2009a). An axiomatic characterization of the ranking based on the\nh-index and some other bibliometric rankings of authors. Scientometrics,\n80(2), 325–342.\nMarchant, T. (2009b). Score-based bibliometric rankings of authors. Journal of\nthe American Society for Information Science and Technology, 60(6), 1132–\n1137.\nRousseau, R. (2012). Basic Properties of Both Percentile Rank Scores and the I3\nIndicator. Journal of the American Society for Information Science and\nTechnology, 63(2), 416-420.\nRousseau, R. (2011). Percentile rank scores are congruous indicators of relative\nperformance, or aren’t they? arxiv.org/pdf/1108.1860\n1709\n\nWaltman, L. &amp; van Eck, N.J. (2009a). A taxonomy of bibliometric performance\nindicators based on the property of consistency. In B. Larsen &amp; J. Leta (Eds.),\nProceedings of the 12th International Conference on Scientometrics and\nInformetrics (ISSI 2009) (pp. 1002–1003). Sao Paulo, Brazil: BIREME &amp;\nFederal University of Rio de Janeiro.\nWaltman, L., &amp; van Eck, N.J. (2009b). A simple alternative to the h-index. ISSI\nNewsletter, 5(3), 46–48.\nWaltman, L., &amp; van Eck, N.J. (2011). The inconsistency of the h-index.\nAvailableat:\nhttp://arxiv.org/ftp/arxiv/papers/1108/1108.3901.pdf\n[refertopublishedarticle]\nWaltman, L., van Eck, N.J., van Leeuwen, T.N., Visser, M.S., &amp; van Raan, A.F.J.\n(2011a). Towards a new crown indicator: Some theoretical considerations.\nJournal of Informetrics, 5(1), 37–47.\nWaltman, L., van Eck, N.J., van Leeuwen, T.N., Visser, M.S., &amp; van Raan, A.F.J.\n(2011b). Towards a new crown indicator: An empirical analysis.\nScientometrics, 87(3), 467–481.\n\n1710\n\nTOWARD A TIME-SENSITIVE MESOSCOPIC\nANALYSIS OF CO-AUTHOR NETWORKS: A CASE\nSTUDY OF TWO RESEARCH SPECIALTIES\nTheresa Velden1, Syed Ishtiaque Ahmed2, Scott Allen Cambo2, and Carl Lagoze1\n1\n\ntvelden, clagoze @umich.edu\nSchool of Information, University of Michigan, Ann Arbor, 105 S. State Street, Ann\nArbor, MI 48109 (USA)\n2\n\nsa738, sac355 @cornell.edu\nDept of Information Science, Cornell University, 301 College Avenue, Ithaca, NY 14850\n(USA)\n\nAbstract\n\nIn this paper we extend the mesoscopic analysis of scientific collaboration networks\nintroduced in Velden et al. (2010) by adding a temporal dimension. We explore the\ntemporal evolution of collaboration networks over a twenty-year period in two research\nspecialties in the chemical and physical sciences. As a first step we compare global\ncharacteristics of the evolution of our networks with co-author networks covered in the\nrecent literature to gauge their correspondence to those networks and assess the impact of\ndata pre-processing steps that we perform on these global characteristics. Based on this\ncomparison, we confirm (Milojevic 2010), but dispute the findings of (Abbasi et al 2012)\nof evidence suggesting a preferential attachment mechanism at work that would explain\nthe evolution of network structure. We then turn to studying the growth and evolution of\nnetwork structure at the level of connected components, and at the level of individual\nauthors and groups of authors joining the network. Both fields we study experience a\nperiod of steady linear growth between 1996-2005, and the dominant social mechanism is\nthe entry of independent new groups into the field that initially do not collaborate with\nexisting groups in the field. Another important, similarly strong mechanism is that of\njunior researchers joining existing research groups in the field. Initial results indicate\nsubtle field differences that require further study.\n\nConference Topic (see http://issi2013.org/about.html).\n\nCollaboration Studies and Network Analysis (Topic 6) and Visualisation and Science\nMapping: Tools, Methods and Applications (Topic 8)\n\nIntroduction\nThis paper reports on our latest results in a multiyear project that employs a\nmixed network analytic and ethnographic approach to understand the factors\nunderlying field-specific attitudes towards openness and sharing of scholarly data.\nWe report initial results of adding a temporal dimension to an analysis of\nscientific collaboration networks that provide evidence for comparative study of\ncommunity structures and collaboration patterns across scientific fields. The\n1711\n\naddition of a temporal dimension to the analysis allows us to study the dynamic\nprocesses involved in the evolution of a scientific community and to determine\nfield specific patterns.\nThis work aims at advancing an ethnographically grounded approach to the\nmesoscopic analysis of collaboration networks (Velden et al. 2010, Velden &amp;\nLagoze 2013). By introducing a temporal dimension to the mesoscopic analysis of\nscientific networks we pursue the following two related goals. First we hope to\nincrease the accuracy of community structure resolution to guide the strategic\nsampling of ethnographic field sites and interview partners in qualitative research\n(Velden &amp; Lagoze 2013). Further, we aim to improve the validity of models that\nexplain global evolution of network structures by linking dynamic features of\nnetwork growth to specific social processes that can be verified in ethnographic\nfield studies.\nPrevious work has oftentimes conceptualized co-author nodes as autonomous\nactors driven by individualistic mechanisms such as preferential attachment,\nignoring the actual social composition of research collectives and the various\nsocially distinct processes contributing to global network growth and\ndensification. Supported by ethnographic insights, we can connect mesoscopic\nnetwork features to notions of research groups, group leadership and implied\nseniority, inter-group collaboration, between-group migration, and ephemeral\none-off exchanges. The promise of a mesoscopic approach is to support the\ninterpretation of network dynamics in terms of distinct, superimposed social\nprocesses that can be verified and understood by ethnographic observation, and\nhence should allow us to significantly improve the validity of models to explain\nnetwork evolution.\nAs first steps toward a time-sensitive mesoscopic analysis of co-author networks,\nwe investigate in this study the following research questions:\nHow do global network metrics and specific results on network growth for our\ntwo datasets compare to the characteristics observed in other co-author networks\nrecently studied? Our initial goal is to check that the data sets and the fields that\nwe study are not outliers among other fields and data sets studied in the recent\nliterature. We also want to assess the influence of pre-processing, data-cleaning\nsteps such as author name disambiguation and hyper-authorship extraction,\ndescribed in the Methods &amp; Data section below, on global network metrics. For\ncomparison we chose the following recent studies of co-author network growth\nand the evolution of its structure: two studies that investigate how authors join\nand establish new links in co-author networks (Abbasi et al. 2012, Milojevic\n2010), and a comparative study of the evolution of the giant component in eight\nscientific fields (Bettencourt et al. 2009).\n\n1712\n\nHow do the co-author networks in the two research specialties evolve at the level\nof connected network components, and in particular in terms of the evolution of a\ngiant component and network? We consider both accumulative network growth\nand dynamic network growth. In an accumulative scheme, co-author links and\nauthor nodes are added to the network in 1-year time steps over the entire 20-year\nrange of our data, without ever removing any links or nodes. Accumulative\ngrowth has been the basis of most previous studies of the evolution of network\ntopology (e.g. Newman 2001, Barabasi et al 2002). By also studying dynamic\ngrowth, we explore the evolution of network structure at a point in time, where\n‘point in time’ refers to a time window of fixed size, aggregating co-author\nactivity over a certain number of years and then moving that window along the\ntime axis in 1-year steps. We document and compare between the two fields the\nflows between major components in the accumulative and dynamic scheme.\nHow do individual authors join the network? As we will discuss below,\npreferential attachment models that do not consider the social structure of\nresearch specialties and its organization in research groups fail to explain the\nevolution of co-author networks. To understand the specific social processes by\nwhich new authors enter a research specialty (e.g. a student joining a group\nalready active in the field, or as a member of a research group that newly becomes\nactive in this particular research specialty) we set out to identify network patterns\nthat may represent specific entry scenarios and to quantify them. This allows us to\nassess their prevalence and to compare them across fields to look for\ncommonalities or potentially significant field differences.\nMethods &amp; Data\nWe are developing an open source code base (http://github.com/tvelden/\ncommunities) that allows us to flexibly generate co-author networks following\ndifferent time-slicing schemes: ‘accumulative’ for tracking the accumulative\ngrowth of the network, and ‘sliding’ for generating a dynamic view of the\nevolution of network structures by considering only publications in a specific time\nwindow. This sliding window can move across the entire time range covered by\nthe available data. We have integrated methods into the code that support the\nmesoscopic analysis of networks, such as the network clustering code by Rosvall\n&amp; Bergstrom (2008) and our own implementation of a node classification\nalgorithm for clustered networks by Guimera et al (2007). This classification\nscheme allows us to distinguish types of nodes by their structural embedding into\ntheir surrounding co-author cluster and by their out of cluster connectivity. For\nexample, hub nodes extracted from our networks by this classification scheme\ntypically correspond in real life to research group leaders (Velden et al. 2010).\nWe employ lexical queries that extract from the Web of Science (WoS) of\nThomson Reuters the publication output of two research specialties in the\n\n1713\n\nphysical and chemical sciences between 1991- 2010, one in synthetic chemistry\n(field 1), and one at the boundary of physics and physical chemistry (field 2).\nTable 1. Basic Network Properties\n\nField 1\nField 2\n\n# papers\n\n# authors\n\n12,641\n56,122\n\n13,397\n60,457\n\n# edges\n(weighted)\n58,375\n315,491\n\n# edges\n(unweighted)\n31,858\n166,203\n\ntime period\n1991-2010\n1991-2010\n\nAn important step in our analysis is the cleaning of data. An initial step is the\nnormalization of author names. We capitalize names and concatenate hyphenated\nnames. Next, to improve the accuracy of the co-author networks, we apply an\nauthor name disambiguation algorithm that has been shown to improve the\nresolution of individual authors. This step removes misleading distortions in the\nnetwork structure due to name homonymy (Velden et al. 2011). We further use a\nstatistical approach to define hyper-authorship in a data set-specific way169 and\nuse it to exclude a small set of papers (1-3%) that are not representative of the\nresearch style in the long-tail science fields that we study here. A manual analysis\nfinds that in many cases those hyper-authorship papers represent out-of-scope\npapers that the lexical query mistakenly captured. In a few cases we also find\nlarge-scale collaborations that contribute to the specific field we study, but\nrepresent only a marginal sub-community within the field. Finally, we exclude\nauthors who have co-authored only a single paper. About 2⁄3 of authors are\nremoved in this step. The reduced data is much more manageable for analysis and\nvisualization purposes. The effects of these reduction steps on network topology\nare reported in the results section. In the following we will use the labels ‘norm’\nto refer to the data that has been merely name normalized, ‘norm-dis’ to data that\nhas been normalized and disambiguated, ‘norm-dis-hfree’ for data that has been\nadditionally filtered to exclude hyper-authorship papers, and finally ‘norm-dishfree-red’ for the data that has undergone all four preprocessing steps and\nrepresents our preferred data set for future analyses.\nResults\nHere we report the results of our network analysis of data in two research\nspecialties, following the list of research questions outlined in the introduction.\nComparison of Global Network Metrics\nWe compare the following global network metrics with those obtained by\nBettencourt et al. in their study of eight scientific fields (Bettencourt et al. 2009):\nthe relative size of the giant component, the evolution of the diameter of the giant\n169\n\nGiven the long-tail distribution of co-authors over papers, we use a non-parametric approach to\nidentify hyper-authorship papers as outliers based on median absolute deviation (described in\nhttp://rfd.uoregon.edu/files/rfd/StatisticalResources/outl.txt).\n1714\n\ncomponent defined as the maximum shortest distance between any pair of nodes\nin the network, and the scaling parameter of network densification.\nAs shown in table 2, we find that our network data represent scientific fields\nwithin a typical range of topological characteristics. In particular, for both of our\nfields, the scaling parameter for network densification is greater than 1.0 and\nsimilar e.g. to the field of carbon nanotubes. Following the argument by\nBettencourt et al., this is an indication that we are dealing with ‘non-pathological’\nfields, that is a community of researchers that share concepts and techniques,\nwhich facilitates collaboration. Further, it is likely that the network metrics of our\ndata would be even more similar to Bettencourt et al. if their data were\npreprocessed in the same way170,171. This trend is indicated by the results we\nobtain for our only minimally treated data (‘norm’) in table 2.\nTable 2. Comparison of Global Network Metrics\n\nField1 (norm-dis-hfree-red)\nField1 (norm)\nField2 (norm-dis-hfree-red)\nField2 (norm)\nString theory\nCarbon Nanotubes\n\ngiant\ncomponent (%\nedges)\n~ 77\n~ 87\n~ 86\n~ 92\n~ 90\n~ 95\n\ndiameter\ngiant\ncomponent\n~ 34\n~ 30\n~ 42\n~ 29\n16\n12-14\n\nscaling parameter\nnetwork\ndensification\n1.14\n1.13\n1.18\n1.27\n1.36\n1.17\n\nInfluence of Data Cleaning on Global Metrics\nThe influence of the data cleaning steps on global network metrics is documented\nin table 3. Both fields show similar trends. The overall effects of cleaning the data\non the global metrics of the resulting co-author networks are the following:\nThe relative giant component size of the final network is around 10% smaller than\nthe giant component size derived from the initial data. The diameter of the giant\ncomponent increases with the processing by about 25% (field 1) and 34% (field\n2). The scaling parameter of field densification initially decreases and then\nincreases again for the various pre-processing steps. All values obtained are\nwithin the desirable range of &gt; 1 and the fluctuations are modest, well within the\n170\n\nThe data used by Bettencourt et al. is non-disambiguated. Also, whereas we consider two author\nname initials where provided, they consider only first initials of author names thereby worsening the\nproblem of name homonymy. Further their data processing does not include a reduction step like the\none we used.\n171\nThe difficulty comparing results across studies by different authors highlights the desirability of\ndata sharing within the scientometric community, which would facilitate cross-validation and build\na sound empirical basis for observations across research fields.\n\n1715\n\nrange of differences found between different fields within Bettencourt et al’s\nanalysis of eight scientific fields. The peak of the degree distribution (Milojevic\n2010) remains at three for both fields until the final reduction step, when it falls to\n2 after all 1-paper authors have been removed from the data set. Finally, the\nproportion of authors that constitute the hook part of the distribution (roughly all\nauthors with less than 9 collaborators for our data) increases through the data\ncleaning process by about 10%. The biggest increase is caused by the removal of\nhyper-authorship papers, presumably since in this step a significant number of\nauthors that contributed to the long tail of the distribution were removed.\nTable 3. Influence of Pre-processing Steps on Global Metrics\n\nGiant size (% edges)\nField 1\nField 2\nGiant Diameter\nField 1\nField 2\nNetwork Densification\nField 1\nField 2\nPeak of Degree Distrib.\nField 1\nField 2\n% Authors in ‘Hook’\nField 1\nField 2\n\nnorm\n\nnorm-dis\n\nnorm-dis-hfree\n\nnorm-dis-hfreered\n\n86.9\n92.6\n\n69.2\n76.2\n\n67.5\n71.4\n\n76.7\n84.2\n\n~29\n~30\n\n~32\n~36\n\n~33\n~39\n\n~34\n~41\n\n1.13\n1.27\n\n1.12\n1.22\n\n1.10\n1.14\n\n1.14\n1.18\n\n3\n3\n\n3\n3\n\n3\n3\n\n2\n2\n\n81.0\n72.6\n\n82.2\n76.7\n\n88.3\n86.1\n\n88.6\n84.0\n\nAs would be expected the data cleaning steps affect the numerical values of\nglobal network metrics. However, from these observations we conclude that the\nnetwork based on cleaned data preserves the important topological features of the\ninitial network. The numerical changes are below an order of magnitude, and\ncharacteristics such as the scaling parameter that Bettencourt et al. use to identify\npathological fields remain within the acceptable range (&gt; 1).\nCorrelation of node centrality measures with preferential attachment\nWe check whether we can reproduce for our data the results of Abbasi et al.\n(2012) regarding the role of preferential attachment as a mechanism driving\nnetwork growth. Abbasi et al. compared three node centrality metrics\n(betweenness, degree, closeness) for their correlation with preferential\nattachment. They investigated the hypothesis that existing nodes in the network\nwith higher centrality values attract a higher number of co-authors that are either\n‘newbies’ (new in the field) or ‘oldies’ (existing members of the field that they\n1716\n\nhad not previously co-authored with). Their major finding was that betweenness\ncentrality trumps degree centrality for attracting newbie authors, which\ntraditionally had been the focus of preferential attachment models. However, in\ntheir data, degree centrality correlates stronger with the number of new\ncollaborations with ‘oldies’ authors. Their data set covered a single field of\nresearch (steel structure research from 1999-2009) and they called for broader\nvalidation of this finding across further scientific fields.\nIn contrast to Abbasi et al. we cannot confirm for our data that betweenness\ncentrality drives preferential attachment of newbie authors to existing authors in\nthe field, outperforming degree centrality. Instead we obtain correlation values\nthat are very similar for degree centrality and betweenness centrality (figure 1).\nAlso our data show an even lower correlation strength for betweenness centrality\nthan that reported by Abbasi et al. (between 0.15 and 0.25 for field 1, and 0.10\nand 0.20 for field 2). We consider the 0.23 to 0.32 Spearman correlation strengths\nthat Abbasi et al. report for the correlation of betweenness centrality with number\nof collaborations with newbie authors as relatively low, having limited\nexplanatory value for the variation observed in the number of links existing\nauthors form with new authors. Similar to Abbasi et al. we find that degree\ncentrality has the highest correlation values for new co-author links between\nalready existing authors. Those correlations are of medium strength (around 0.45\nfor both fields, figure 1).\nWe double-checked whether the deviation of our results from Abbasi et al’s could\nbe explained through the different pre-processing steps we applied to clean our\ndata. We assume that the version of our data that includes name disambiguation\nand removes hyper-authorship papers but omits the last preprocessing step of\nremoving 1-paper authors may be closest to the cleaning protocol that Abbasi et\nal. used. However, even for this data we cannot find confirmation of their result\nof the dominant role of betweenness centrality for preferential attachment of new\nauthors to existing authors. Instead for our data in this treatment regime degree\ncentrality slightly dominates over betweenness centrality.\nDegree distribution and deviations from scaling law behavior (Milojevic 2010)\nAs pointed out by Milojevic (2010) power law scaling of the distribution of\nnumber of collaborators (associated with a hypothesized preferential attachment\nmechanism at work), is not the dominant feature characterizing such distributions\nin co-author networks. Instead, the majority of authors (88% in the 2000-2004\ndata set of nano-science publications studied by Milojevic) are included in the\nlog-normal hook of the distribution. We find similar numbers for the proportion\nof authors constituting the hook, ranging between 70% and 90% depending on the\nfield and data pre-processing steps used (table 3).\n\n1717\n\nMilojevic interprets the hook and its peak as suggestive of a characteristic mode\nof collaboration corresponding to the typical number of collaborators needed in a\nresearch field to produce a publishable result. Our data for both fields display the\nsame log-normal hook feature with a peak at 2 collaborators. These peak values\nare slightly smaller than those in nano-science subfields such as applied physics\nor materials chemistry that are intuitively comparable to our fields. As discussed\nabove, this could be due to differences in pre-processing of the data. The data\nused by Milojevic is probably best compared to our initial data, i.e. the data set\nwithout name disambiguation, without removal of hyper-authorship, and without\nremoving 1-paper authors. For this version of our data we obtain peaks at 3\ncollaborators for both fields (see table 3), the same Milojevic finds in 2000-2004\nfor the analytical chemistry subfield within nano sciences, but lower by one than\nfound by her for the applied physics and the materials chemistry subfields within\nnano sciences.\nNetwork growth at the component level\nThe focus in this result section is on how the network grows at the level of\nconnected components, and in particular how the giant component of the network\ngrows.\nInitially we consider the accumulative view, i.e. the network as it grows by adding\nyear-by-year new authors and new co-author links without removing any from\nprevious years. When plotting the temporal evolution of the absolute size of the\nsecond largest component of the co-author network we noticed that the second\nlargest component showed distinct reductions in size every few years. Within an\naccumulative scheme this phenomenon can only be explained by the second\nlargest component having merged with the largest component, thereby allowing a\npreviously smaller component to move up the ranks and become the second\nlargest component even if smaller in size than the second largest component in the\nprevious year. We investigated whether these ‘feeding events’ of the giant\ncomponent by merging with the second largest component account for a\nsubstantial part in the growth of the giant component. We call this the Staging\nArea Hypothesis, i.e. the notion that the second largest component constitutes a\nmajor staging area for the giant component and that the largest component of a\nnetwork gradually grows and evolves into the giant component of the network\nthrough subsequent absorption of the second largest component. Our subsequent\nanalysis led to a rejection of this hypothesis for our data. We checked the\ncontribution of the second largest component to the growth of the largest\ncomponent and found that in none of our networks was the giant component\nprimarily fed by the second largest component of the previous years (figure 2).\nNew authors joining the field as well as authors that were previously part of\ncomponents smaller than the second largest component provide for significantly\nstronger influx channels.\n\n1718\n\nLinks between Existing Authors and New Authors\n\n0.4\n\n●\n●\n\n0.2\n\n●\n●\n\n●\n\n●\n●\n\n●\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\nSpearman correlation\n\nSpearman correlation\n\n0.4\n\n0.2\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n\n0.0\n\n●\n\n●\n\n0.0\n\nField 1\n−0.2\n\n1995\n\n2000\n\n2005\n\n●\n\n●\n\nField 2\n−0.2\n\n2010\n\n1995\n\n2000\n\n2005\n\n2010\n\nNew Links between Existing Authors\n●\n\n●\n\n●\n●\n\n●\n\n●\n●\n\n●\n\n0.4\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n\n●\n\n0.4\n\n●\n\n0.0\n\n1995\n\n2000\n\n2005\n\n●\n\n●\n●\n\n0.2\n\n●\n\nField 2\n\nField 1\n−0.2\n\n●\n\n●\n\n●\n\n0.2\n\n0.0\n\n●\n●\n\n●\n\nSpearman correlation\n\nSpearman correlation\n\n●\n\n●\n\n2010\n\n−0.2\n\n1995\n\n2000\n\n2005\n\n2010\n\nFigure 1: Correlation of node centrality scores of existing authors with co-author\nlinks to new authors (top) and with new co-author link to existing authors (bottom).\n\nWe also explore a dynamic perspective on the evolution of network components.\nWe start by investigating the effect of window size on the size and evolution of\nthe largest component of the co-author network. Publications are a fuzzy indicator\nof collaborative relationships, since they typically constitute only the end point of\na successful research project, they lag somewhere between a few months up to\nseveral years behind the most intensive collaborative activity, and do not come\nout in strict chronological order of the underlying research activities. This\nsuggests that one needs to accumulate data from a certain minimum number of\nyears to capture the concurrent collaborative activities within a research group\nand its surrounding research community. We find for our data that for small sizes\nof the time window the largest component size fluctuates and mostly stagnates\n1719\n\nover time. Only for a window size of 5 years and larger do we find stable growth\nof the giant component (for field 2 we observe a slight decline at the end of this\nperiod however). Hence, we chose a 5-year sliding window for our subsequent\ndynamic analysis.\nField 1\n\n75\n\n●\n\n50\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n25\n\n●\n●\n\n100\n\nField 2\n\nField 1\n\n●\n\nField 2\n% of authors newly joining largest component\n\n% of authors newly joining largest component\n\n100\n\n75\n●\n\n●\n●\n\n50\n\n●\n●\n\n●\n\n●\n●\n\n●\n●\n\n●\n\n●\n\n●\n●\n\n●\n\n●\n\n●\n\n●\n\n●\n\n25\n\n●\n\n0\n\n0\n1995\n\n2000\n\n2005\n\n2010\n\n1995\n\n2000\n\n2005\n\n2010\n\nFigure 2: Source of nodes that newly join the giant component to check staging area\nhypothesis.\n\nTo visually explore the dynamic evolution of network components we use an\nonline alluvial generator provided by Edler &amp; Rosvall (2010) to show the\ntemporal flow of authors between major components. This free online\nvisualization tool generates the alluvial diagram from a chronologically organized\nseries of networks. In their implementation, they basically show the flows among\nnode clusters in a clustered network. However, in our case we were interested in\nthe evolution of the connected components in the network. So, we generated a\nshadow-version of our networks that represent the components formally as\nclusters; and then we used the alluvial visualization tool to visualize the flows\nbetween the network components. We also considered the ‘not yet active authors’\nin each time slice and represented them as an additional network component;\nthese are authors who did not publish during the current network slice, or any of\nthe previous slices, but who eventually published sometime in the future. The\nresulting visualization for field 1 is shown in figure 3, however the corresponding\nvisualization for field 2 could not be obtained using the online tool available\nbecause of the size of the network.\nAs illustrated, the largest proportion of new (‘not yet active’) authors that get\nactivated in a time step feed into the giant component. This contribution of new\nauthors to the giant component dwarfs the contribution from continuing authors\nthat were part of the giant component during the previous 5-year time window.\nThis phenomenon is most pronounced for the growth period 1996-2000, and the\n1720\n\ntrend is similar, if less pronounced, for field 2. Consequently, new authors\ndominate the influx into the giant component even more so in the dynamic picture\nthan the accumulative scheme.\n\nFigure 3: Alluvial flow of network nodes (authors) between network components for\nfield 1 from a dynamic perspective\n\nHow New Authors Join A Research Specialty\nThe observations by Milojevic, as well as our own results that show the weak\ncorrelations between node centrality values and the attraction of new authors by\nexisting authors, point to the weakness of a simple preferential attachment growth\nmodel to explain the evolution of co-author networks. Therefore we set out to\nhave a closer look at how new authors join the network. To study the process by\nwhich the majority of new authors join the network each year, we go beyond a\nmacroscopic approach that considers generic attachment patterns and break down\nthe analysis to a mesoscopic level of analysis supported by ethnographic\nobservations. Both field 1 and field 2 represent experimentally oriented research\nspecialties in physics and chemistry. Their research communities are dominated\nby mid-sized research groups, typically composed of graduate students,\npostdoctoral associates and technicians, and led by a senior researcher (professor).\nBased on insights from ethnographic studies of these fields (Velden 2013) we can\nposit several realistic social processes through which new authors become active\nin these fields:\nScenario 1: a graduate student or a postdoctoral researcher joins a research group\nalready publishing in the respective field and is trained within that group.\nScenario 2: as members of a research group that has been previously active in\nother areas and now starts to contribute to the research in the field independently\nas an autonomous actor\n1721\n\nScenario 3: a research group that enters the field by teaming up with a group\nalready active in the field and contributes to the research in the field in\ncollaboration with that group.\nTo derive a quantification of the relative importance of these social processes\nfrom the co-author networks and to compare them across fields, we develop an\nalgorithmic procedure that attempts to map new authors entering the field each\nyear to one of these scenarios based on their structural position within the 1-year\nco-author network in the year when they publish for the first time in the field, in\ncombination with additional information derived from the 20-year accumulative\nnetwork. A mesoscopic perspective provides us with the following network\nconstructs that we make use of to operationalize and distinguish those processes:\nConnected components: we distinguish connected components in the 1-year\nnetwork based on whether they are composed solely of new authors, or solely of\nrecurring authors, or of both.\nCo-author Clusters: we extract the modular substructure of the accumulative 20year co-author network172 using an information theoretic algorithm (Rosvall &amp;\nBergstrom 2008) that subdivides the nodes in the co-author network into clusters\nthat can be interpreted as research groups or collectives of very closely\ncollaborating research groups (Velden et al. 2010).\nHub nodes: based on the structure of the clustered, accumulative co-author\nnetwork, we can distinguish between hub nodes and non-hub nodes (Guimera et\nal. 2007). Hub nodes are defined as those nodes within a cluster of nodes that\nhave a disproportionally high number of within-cluster links. As reported\nelsewhere (Velden et al. 2010), hub nodes within co-author networks are\ncharacteristic of the bibliographic footprint of research group leaders over time.\nWith the help of these constructs we operationalize the cases described in a two\nstep procedure that eventually maps new nodes in the annual slice of the coauthor network to one of the three scenarios. Nodes that cannot be mapped are\nassigned to a fourth scenario; essentially new nodes with an unresolved entry\nscenario. In a first step we parse each connected network component to assess its\npotential for representing the bibliographic footprint of one of the scenarios.\nDepending on the outcome of this assessment, the new nodes included in the\ncomponent then get mapped either directly, or sometimes only after further\nanalysis, to one of the four scenarios.\nGiven a network component that only consists of new authors, we map all these\nnew authors to scenario 1. If a network component includes both new and\nrecurring authors, we check for the presence of hub nodes. If we find in a\ncomponent a linked pairs of hub nodes where one hub node is a new node and one\n172\n\nThis accumulative co-author network is constructed from publication data of the entire 20-year\nrange from 1991-2010.\n1722\n\nhub node is a recurring node, we consider the network component a candidate for\nrepresenting scenario 3, i.e. a new research group entering the field through\ncollaboration with an existing research group. However, before mapping all new\nnodes in this component to scenario 3, we evaluate whether the new hub node\nalong with new non-hub nodes connected to it plausibly represent a new research\ngroup173. To this end we evaluate the relative connection strength between the\nnew non-hub nodes with the new hub node and the existing hub nodes (including\nfuture years) to decide whether they can be counted as the research group of a\nresearch group leader newly entering the field or rather peers of a student who\nonly later becomes a research group leader. For space limitations we here cannot\nprovide the full algorithm specification. Instead it will be made available in the\ndocumentation of the source code available at http://github.com/tvelden/\ncommunities).\nThe results of our analysis are depicted in figure 4. We restrict our interpretation\non a central 10-year time window (1996-2005) that represents a period of linear\ngrowth in both fields and should only be marginally affected by boundary\neffects174. We find that most authors join the field as part of new groups of\nauthors becoming active in the field. However, there is also a relevant number of\nnew authors who enter as new, presumably junior authors (students, postdocs)\njoining an existing group. Between 20-30% of new authors cannot be mapped to\nany of the cases (listed as scenario 4) since the interlinking patterns are too\ncomplex to be interpreted in an obvious way. With our approach we could\ndetermine only a very small number of new authors that enter the field as a group\nthat immediately engages in collaboration with an existing group (and hence may\nbe drawn into the field through collaboration with an existing group). We further\nobserve that the two fields differ with regard to the percentage of nodes that can\nbe mapped to either scenario 1 or cannot be resolved (scenario 4). Field 1 shows a\nhigher percentage of scenario 1 authors whereas field 2 has a higher percentage of\nunresolved cases, consistent with our previous observation of the predominance\nof single hub clusters in field 1 and higher rates of inter-group collaboration and\nmultiple hub clusters in field 2 (Velden et al. 2010). This may point to field\n173\n\nThe identification of hub nodes is based on clustering the 20-year accumulative co-author\nnetwork. In a separate analysis we determined that it takes hub nodes about 5 years of publishing\nactivity to expose the bibliographic footprint of a hub node. Hence a new author in the field that is\ncategorized by us as a hub node may either be a research group leader from the beginning or a junior\nresearcher (student, postdoc) who trains with an existing research group leader and later in her\ncareer becomes herself a research group leader active in this field.\n174\nFor this analysis we have to consider boundary effects at both ends of the time range covered by\nour entire data set. We can expect to overestimate the number of new authors and underestimate the\nnumber of recurring authors at the beginning of the time interval due to lack of knowledge about\npublishing activity of authors in the field before 1991. In an explorative analysis we found that this\nerror is likely to reduce to less than 10% about 5-8 years into the time interval. At the end of the\navailable time window we have issues with correctly recognizing hub nodes since the bibliographic\nfootprint of a research group leader that enters the field 5 years or less before 2010 will remain too\nweak to be recognized as a hub node.\n1723\n\ndifferences in the predominance of entry routes. However, it could also mean that\nthe entry routes into the community are very similar in both fields but that the\nresolution of scenarios is made more difficult for field 2 because of the higher rate\nof inter-group collaborations. This question needs further exploration.\n\nFigure 4: Quantification of social processes how new authors enter network each\nyear. Scenario 1: authors enter the field by joining and existing research group.\nScenario 2: authors enter as part of a new, independent research group. Scenario 3:\nauthors enter field as members of a new research group that collaborates with an\nexisting research group. Scenario 4: authors that we could not map to any of these\ncases.\n\nConclusions\nWe suggest that attempts at explaining the dynamics of co-author network growth\nin terms of realistic social scenarios need to distinguish carefully between the\ndifferent types of nodes and processes underlying co-authorship collaborations.\nAs seen, for example, from the analysis of the role of node centrality values in\ndriving network growth, a generic preferential attachment mechanism has limited\nvalue for explaining the structural evolution of co-author networks. Instead, we\nbelieve that the evolution of collaboration networks in scientific communities and\nthe nature of field-specific collaboration patterns would be more valuable if\ngrounded by ethnographic observations. In this paper we report first steps for\nintroducing time dimension into the analysis of co-author networks at the\nmesoscopic level. We focus on co-author networks, however in future work we\nanticipate including the temporal analysis of layered citation and co-author\nnetworks with the goal mapping of community structures within scientific fields\n(Velden &amp; Lagoze 2013).\n\n1724\n\nWe note that our experiences with the replication of other authors’ results\nrevealed a number of critical issues that underline the potential benefit of an open\ndata approach, allowing routine sharing of the data sets underlying published\nanalyses, for developing a strong reliable empirical base for field comparisons.\nAcknowledgments\nNational Science Foundation Grant No OCI-1025679, International Fulbright\nScience and Technology Fellowship for S.I. Ahmed.\nReferences\nAbbasi, A., Hossain, L., &amp; Leydesdorff, L. (2012). Betweenness centrality as a\ndriver of preferential attachment in the evolution of research collaboration\nnetworks. Journal of Informetrics, 6(3), 403-412.\nBarabâsi, A. L., Jeong, H., Néda, Z., Ravasz, E., Schubert, A., &amp; Vicsek, T.\n(2002). Evolution of the social network of scientific collaborations. Physica A:\nStatistical Mechanics and its Applications, 311(3), 590-614.\nBettencourt, L. M. a., Kaiser, D. I., &amp; Kaur, J. (2009). Scientific discovery and\ntopological transitions in collaboration networks. Journal of Informetrics, 3(3),\n210-221.\nEdler, D. and Rosvall, M. (2010), The Map Generator software package, online at\nhttp://www.mapequation.org.\nGuimera, R.; Sales-Pardo, M. &amp; Amaral, L. (2007), &#x27;Classes of complex networks\ndefined by role-to-role connectivity profiles&#x27;, Nature Physics 3(1), 63-69.\nMilojević, S. (2010). Modes of collaboration in modern science: Beyond power\nlaws and preferential attachment. Journal of the American Society for\nInformation Science and Technology, 61(7), 1410-1423.\nNewman, M. E. (2001). Clustering and preferential attachment in growing\nnetworks. Physical Review E, 64(2), 025102.\nRosvall, M. &amp; Bergstrom, C. (2008), ‘Maps of information flow reveal\ncommunity structure in complex networks&#x27;, PNAS 105, 1118.\nVelden, T.; Haque, A. &amp; Lagoze, C. (2011), Resolving Author Name Homonymy\nto Improve Resolution of Structures in Co-author Networks, in &#x27;JCDL&#x27;11, June\n13-17, 2011, Ottawa, Ontario, Canada&#x27;.\nVelden, T.; Haque, A. &amp; Lagoze, C. (2010), &#x27;A new approach to analyzing\npatterns of collaboration in co-authorship networks: mesoscopic analysis and\ninterpretation&#x27;, Scientometrics 85(1), 2 19-242.\nVelden, T. (2013), ‘Explaining Field Differences in Openness and Sharing in\nScientific Communities’, CSCW 2013: Computer Supported Cooperative\nWork, February 23 - 27 2013, San Antonio, TX.\nVelden, T. &amp; Lagoze, C. (accepted), ‘The Extraction of Community Structures\nfrom Publication Networks to Support Ethnographic Observations of Field\nDifferences in Scientific Communication’, JASIST\n\n1725\n\nTOWARDS THE DEVELOPMENT OF AN\nINDICATOR OF CONFORMITY\nRichard Klavans1, Kevin W. Boyack2, Aaron A. Sorensen3, and Chaomei Chen4\n1\n\nrklavans@mapofscience.com\nSciTech Strategies, Inc., Berwyn, PA 19312 (USA)\n2\n\nkboyack@mapofscience.com\nSciTech Strategies, Inc., Albuquerque, NM 87122 (USA)\n3\n\nA.Sorensen@elsevier.com\nElsevier, B.V., New York, NY 10017 (USA)\n4\n\ncc345@drexel.edu\nCollege of Information Science &amp; Technology, Drexel University, Philadelphia, PA\n19104 (USA)\n\nAbstract\n\nAn indicator of conformity – the tendency for a scientific paper to reinforce existing belief\nsystems – is introduced. This indicator is based on a computational theory of innovation,\nwhere an author’s belief systems are compared to socio-cognitive norms. Evidence of the\nvalidity of the indicator is provided using a sample of 4180 high impact papers in two\nexperiments. The first experiment is based on a 10 year model of the scientific literature.\nThe robustness of the first experiment is tested using an alternative method for calculating\nthe indicator and two 16-year models of the scientific literature.\n\nConference Topic\n\nScientometric Indicators (Topic 1); Science Policy and Research Evaluation (Topic 3)\n\nIntroduction\nFor the past 50 years, there has been a working assumption in scientometrics that,\noverall, highly cited papers are innovative. As a consequence, there is a\ncorresponding use of citation counts and other impact-related metrics to make\nresource allocation decisions in nations throughout the world (Geuna &amp; Martin,\n2003; Hicks, 2012; Martin, 2011). A university or institution is considered\ninnovative if they have scientists that produce highly cited papers. National\nfunding agencies are publicly criticized as being non-innovative if they didn’t\nfund authors of highly cited papers (Nicholson &amp; Ioannidis, 2012).\nThis assumption leads to significant questions that have not been considered.\nSpecifically, what if many of these high impact papers are not really innovative,\nbut simply reinforce the status quo? What might this policy of rewarding high\nimpact do to the ability of a nation to fund highly innovative research? We simply\n1726\n\nhaven’t looked at the possibility that high impact papers are reinforcing existing\nbelief systems (i.e., our definition of conformity). Rewarding conformity will\nreduce the innovative output of a university or a nation.\nThe idea of an indicator of non-innovativeness, or conformity, is bound to be\ncontroversial because no one wants their work to be publicly recognized as not\nbeing innovative. On the other hand, there is a need to ensure that resources that\nare [hopefully] earmarked for innovative activities are not redirected towards\ninstitutions with a track record of non-innovative, but highly influential, research.\nThis is a particularly difficult problem during a financial crisis where there is an\nacross-the-board requirement to cut funding. It is politically easy to say no to a\nhighly innovative (and potentially risky) program that hasn’t been funded or\nwhere the researchers have little influence. It is much harder to cut the noninnovative program where the researchers are well established in a prestigious\nlaboratory and have very high influence.\nTo the best of our knowledge, there is no scientometric research on high impact\ndocuments that are conforming. This study is a first step toward proposing an\nindicator of conformity. In the remainder of the paper we set the stage by\nreviewing related research. A preliminary experiment that was intended to\ndevelop an indicator of innovativeness (but unintentionally yielded potential\ninformation on conformity) is then described. A more comprehensive experiment\nintended to further explore the idea of conformity is elucidated. Finally, we\nsummarize our results and point to further research that should be conducted.\nBackground\nThe idea that high impact papers are innovative is a commonly held belief. This\nwas not always the case. This idea was extremely controversial in the 1960’s\nwhen it was championed by Eugene Garfield. Garfield’s idea was to create\ndatabases that listed scientific articles and their citations. These data became the\nbasis of a commercial business (the Institute for Scientific Information or ISI) and\nbecame the organizing basis for the newly emerging academic field of\nscientometrics. Although retrieval was the primary purpose for introduction of the\ncitation index, citation analysis soon became common, and was found to be a\nvalid way to identify highly influential scientists, journals and papers. As\nevidence it was shown that Nobel Prize winners are among the most highly cited\nscientists (Garfield, 1977; Garfield &amp; Malin, 1968; Garfield &amp; Welljams-Dorof,\n1992). Citation data were used to create a Journal Impact Factor (Garfield, 1972,\n2006) that is now widely used. Between 1977 and 1993, Current Contents\npublished over 4000 interviews with authors of citation classics describing the\ncontributions of their highly cited papers. The cumulative evidence that highly\ncited papers are innovative seems overwhelming.\n\n1727\n\nThe possibility that high impact papers might not be innovative was brought up\nwhen citation analysis started. Most notable was the concern that a citation might\nbe negative, perfunctory, or inflated due to self-citations (MacRoberts &amp;\nMacRoberts, 1989, 1996; Moravcsik &amp; Murugesan, 1975). These criticisms have\nbeen dealt with over time. There was no strong evidence that negative or\nperfunctory citations were systematically distorting impact indicators. A selfcitation doesn’t mean that a paper isn’t innovative. Rather, it could simply signal\nthat a researcher is building on his or her prior work. The only criticism that was\ngenerally considered legitimate was that review papers should be considered\nseparately because of their unique role in science. Review papers were\ncorrespondingly identified and treated separately. They are typically excluded\nfrom ISI’s list of high impact papers. What is left standing is the belief that highly\ncited papers, except for the review papers and a few exceptions, had to be\ninnovative. This is such a widely held belief that a failure to fund high impact\nresearch was considered as legitimate sign of conformity by the editorial board of\nNature (Nicholson &amp; Ioannidis, 2012).\nThe possibility that high impact papers might be conforming is not an area of\nresearch in citation analysis. However, there is a significant amount of research on\nidentifying innovative documents. It is from this stream of research that the\nproposed indicator was accidently developed.\nA first experiment\nThe first experiment we designed built on the work of Chen et al. (2009) who\nused network analysis to identify innovative scientific papers. Chen posited that\ninnovative papers would be located in the structural holes in citation networks.\nThe scientific literature is envisioned as a network. Using co-citation analysis this\nnetwork is composed of references, which are thought of as concept symbols that\na newer paper builds upon. Typically, there are dense clusters of references that\ntend to be cited together. These dense clusters are separated from other dense\nclusters of references, and when visualized, look like islands in an archipelago.\nThe essence of Chen’s argument is that potentially innovative papers would tend\nto have high network betweenness. Using the analogy of islands, an innovative\npaper is more likely to appear somewhere between existing islands than in the\ncenter of an island. A new paper that cites multiple islands, or builds on the\nwisdoms of multiple islands, is more likely to be innovative than a paper\npredominantly referencing a single island.\nOur intent was to conduct a large scale test of Chen’s computational theory.\nRather than duplicating their method, which operates on local datasets (one-at-atime) and uses a relatively complex method for calculating network betweenness,\nwe designed an experiment that would preserve their intent while using global\nmodels (in which the islands are all pre calculated) and simpler calculations.\n\n1728\n\nWe operationalized the notions of innovation (which correlates with betweenness)\nand conformity (which correlates with status quo, or lack of betweenness) using\nour global model as follows. Given a paper and its references, a pair of references\nthat come from different clusters is a vote for betweenness or innovation.\nConversely, a pair of references that come from the same cluster is a vote for\nstatus quo or conformity. We also needed to deal with missing information\nbecause our models do not necessarily include all references. In cases where one\nor both of the references were missing, we considered this as an undecided vote.\nIn this experiment, for a given paper we counted votes from all possible pairs of\nreferences into three bins – innovative, conforming, or undecided.\nIn our study we also had the advantage of having a significant amount of full text\ninformation (2007 full text from Elsevier). It has been shown that proximate pairs\nof references (which can only be determined from full text) are more similar than\npairs of references that are far apart in the text (Boyack, Small, &amp; Klavans, 2013).\nWith this information, one can test the effect of reference proximity on the votes –\none can test whether more proximate pairs of references are better predictors of\nconformity or innovation than all pairs of references.\nThe most difficult issue in our experiment was in the design of the dependent\nvariable. How do we know if we have identified an innovative paper? Chen’s\napproach requires a significant amount of effort – measured in hours at least and\nperhaps days per turning point paper. We addressed this problem by looking at\nthe stability of the flow of science using a global model of science. Our working\nhypothesis was that turning point papers would be in (a) unstable flows or (b)\nflows that are in increasingly unstable environments.\nIt is important to elaborate on this idea. The method used to describe the structure\nof science used by Chen, and used in this first study, is co-citation analysis. Cocitation analysis is used to identify citation networks, or the islands that are\npopulated with references. There are, however, subtle differences in how these cocitation models are created that influenced the design of this experiment. Chen\nuses a local model (papers and their references are retrieved based on topic\nsearch) and aggregates data over multiple years (Chen, 2012). By contrast, we use\na global model (all of the documents in the Scopus database), create models each\nyear to represent the socio-cognitive structure for that year, and then link models\nyear-to-year to show changes in socio-cognitive structures. This approach, along\nwith measurements of its accuracy, is described elsewhere (Boyack &amp; Klavans,\n2013; Klavans &amp; Boyack, 2011). In addition, the a priori identification of all of\nthe islands each year allows us to simplify the indicators. As mentioned above,\npairs of reference can “vote” for innovativeness, conformity, or can be undecided.\nUse of our global model also allows us to provide a relatively simple indicator of\nwhen the flow of science has been disrupted. One simply locates the island\n1729\n\nassociated with a high impact paper and looks at year-to-year discontinuity –\nwhen does the island appear and when does it disappear. It is this unique\ncharacteristic of our global co-citation model – the cluster start and end dates –\nthat we are building on. As the dependent variable, we focus on the stability of the\nisland (the citation network) most associated with a high impact paper. If a paper\nis a turning point paper, then the island associated with the turning point paper\nshould be unstable or have increasing instability.\nIt is also important to note that, at this stage of the experiment, we were only\ninterested in an indicator of innovative papers. We expected that the dependent\nvariable (the stability of the island) would be negatively associated with\ninnovativeness votes, positively associated with conformity votes, and not related\nto the undecided votes. Or, stated differently, we didn’t know which measure\nwould be better: innovativeness or not being conforming. Since we expected a\nlarge percentage of the votes would be undecided, it wasn’t clear which indicator\nwould by better.\nThe data used in this experiment consisted of over four thousand papers where we\nhave full text data. This sample was based on first identifying the 16,427 top 1%\n(most highly cited by 2010 by discipline) papers that were published in 2007. A\ntotal of 4216 of these papers were found in the Elsevier 2007 full text corpus.\nSeveral of these papers did not have a sufficient number of references to generate\na meaningful statistic. A total of 4180 papers had a minimum of 5 references and\nwere also found in our 2007 co-citation model.\nTable 1. Correlation of votes for innovation and conformity with co-citation cluster\nage (stability) using different distances between reference pairs.\nDistance between pairs (in characters)\nGeneral Statistics\nAvg. #votes/paper\n#papers (#votes &gt;10)\n% Innovative votes\n% Conforming votes\n% Undecided votes\n\n0\n\n375\n\n1500\n\n6000\n\nALL\n\n108\n3295\n32.4\n26.7\n40.8\n\n200\n3992\n36.1\n21.5\n42.4\n\n465\n4119\n39.8\n16.4\n43.8\n\n1126\n4156\n42.1\n12.8\n45.1\n\n4847\n4180\n43.4\n10.0\n46.6\n\nPearson correlation with stability\n% Innovative votes\n% Conforming votes\n% Undecided votes\n\n-0.307\n0.362\n-0.039\n\n-0.263\n0.404\n-0.061\n\n-0.207\n0.416\n-0.064\n\n-0.163\n0.401\n-0.061\n\n-0.133\n0.379\n-0.052\n\nBoth full text and bibliographic data from Scopus were used to determine\nreference pairs. As shown in Table 1, varying distances between reference pairs\nwere used. These distances corresponded roughly to same citing location\n(distance=0), same sentence (375 characters), same paragraph (1500 characters)\n\n1730\n\nor same section (6000 characters). We also created the traditional co-citation pairs\n(all possible pairs in the bibliography).\nThe average number of votes per paper increases dramatically with distance\nbetween reference pairs. The average paper has only 108 votes (pairs of\nreferences) when one only count pairs of references in the same bracket. This\nincreases to 1126 votes when one uses the largest distance (references roughly in\nthe same section of a paper) and 4847 votes when one assumes that all references\nare related to each other once (the final column in Table 1). The number of papers\nthat have meaningful indicators increases with distance between pairs. For\nexample, if we assume that a paper had to have a minimum of 10 votes for an\nindicator to be meaningful, we could only create indicators for only 3295 (out of a\npossible 4180) papers if we use the smallest distance between pairs. Pairs of\nreferences are more similar (the % Conformity statistic goes up) as the distance\nbetween the pairs goes down. This is consistent with our recent findings\nproximate pairs of references are more similar than pairs of references that are far\napart in the text (Boyack et al., 2013).\nThe drop in the sample size affects the correlation between the three dependent\nvariables (%innovative; %conforming; %undecided) and stability (the total age of\nthe thread is our surrogate for overall island stability). When we only use pairs\nthat are in the same bracket, the indicator for innovativeness and conformity are\nhighly correlated with stability and in the expected direction. But, as the distance\nincreases, the correlation between the innovativeness indicator and stability\ndeteriorates. By contrast, the correlation between the conformity indicator and\nstability increases slightly and remains surprisingly strong.\nThe fact that the innovative indicator and conforming indicator were not moving\ntogether was due to the increasing role of the undecided votes. When the distance\nbetween pairs was smallest, the undecided votes accounted for 40.8% of all votes\nand the correlation between %Innovative and %Conformity was relatively small\n(-0.20). As the distance increases, the percentage of undecided votes increases (to\na maximum of 46.6%) and the correlation between innovativeness and conformity\ndecreases (to -0.08). Basically, the indicator of conformity and innovative are\nweakly related to each other because of the large percentage of undecided votes.\nThey act more independently of each other as the conditions change.\nA regression model for these data (see Table 2, below) shows a similar pattern in\nthe deteriorating impact of the innovative indicator and the strong impact of the\nconformity indicator.\nIn this case, we tested whether the number of years that an island survived after\n2007 was a function of the age of the island in 2007 (expected to be positive),\ninnovativeness (expected to be negative) and conformity (expected to be\n1731\n\npositive). The T-statistics for each of these variables in the regression equation are\nall significant at the .001 level. All of the signs are in the expected direction. But\nmost importantly, the pattern in the T statistics is consistent with what we\nobserved in Table 1. The effect of the innovativeness indicator becomes weaker\nas the distance between pairs increases and the number of observations increases.\nThe T statistic for the conformity indicator is high and remains strong over the\nentire domain.\nTable 2. Regression statistics for the experiment of Table 1 where survival = f(Age,\n%Innovative, %Conforming).\nDistance between pairs (in characters)\nAvg. #votes/paper\n#papers (#votes &gt;10)\nT-statistic (age)\nT-statistic (%Innovative)\nT-statistic (%Conforming)\nAdjusted R-square\n\n0\n108\n3295\n33.01\n-7.82\n10.41\n0.369\n\n375\n200\n3992\n35.90\n-7.20\n11.79\n0.366\n\n1500\n465\n4119\n36.41\n-6.15\n13.02\n0.364\n\n6000\n1126\n4156\n37.58\n-4.43\n12.53\n0.358\n\nALL\n4847\n4180\n38.81\n-3.66\n11.93\n0.355\n\nIt is at this point that we realized that Chen’s notion of betweenness and its\nimplications worked, but in an unexpected direction. Instead of creating an\nindicator of innovativeness, the model has created a very strong indicator of\nconformity. And it was at this point that we realized the possible implications of\nthe results. An indicator of conformity represented a significant research\nopportunity; we simply had never heard of any researcher developing conformity\nindicators. But more importantly, we realized that some very high impact papers\nwere doing exactly the opposite of what we had assumed. They were re-enforcing\nexisting beliefs rather than challenging them. We therefore designed a follow-up\nexperiment to explore these issues further.\nFollow-up experiment\nGiven the unexpected results of the preliminary experiment, and the potentially\ncontroversial nature of the implications of those results, we determined to conduct\na more detailed experiment whose purpose was to test the robustness of the\npreliminary experiment. The central feature of this follow-up experiment was a\nnew global model of science that had been recently developed by Waltman &amp; van\nEck (2012). Their model was unique in two respects. First, they clustered ten\nyears of publication data in one pass (almost 10 million articles from the Web of\nScience). This, in itself, was a significant accomplishment. Second, this was the\nfirst time a global model was created using direct citation analysis and ten years\nof data. Further elaboration of their accomplishment is needed to appreciate its\nimportance and corresponding application for developing an indicator of\nconformity.\n\n1732\n\nDirect citation analysis (i.e. who cites whom) was the method that was originally\nused by Garfield (1973). But direct citation analysis had, for 50 years, only been\nused for local models (i.e. creating a historiography around key papers). Boyack\n&amp; Klavans (2010) had created the first large-scale direct citation model using five\nyears of Scopus and Medline data, but found that direct citation produced\nsignificantly inferior document clusters than co-citation analysis. Waltman &amp; van\nEck argued that a global direct citation model needed a much longer time window\nto be accurate – five years was too short a time to allow the direct citation\nnetworks to emerge. Their results, using ten years of data, were creating very\nmeaningful results. After seeing their article posted on ArXiv in March, 2012, we\ncontacted the authors immediately, and were impressed with the case examples\nthat they provided to us. We started using their code in April, 2012 to replicate\ntheir results using the Scopus database. Overall, we found that Waltman &amp; van\nEck were correct – direct citation models based on a time period of 10 years or\nlonger are just as accurate as co-citation models as measured using textual\ncoherence (Boyack &amp; Klavans, 2013). We therefore proceeded to push the\nboundaries further – creating a 16-year model (the longest period possible with\nthe Scopus database).\nA 16-year direct citation model and a 16-year co-citation model were developed\nover the next few months, and are both used in the follow-up experiment. Each of\nthese global models is used to generate clusters of documents (islands). But the\nnature of the islands is quite different. The islands from a co-citation model\nrepresent a snapshot of the socio-cognitive belief systems for a single year. These\nbelief systems are relatively unstable over time; many islands are sinking and\nmany new islands appear each year. By contrast, the islands from a direct citation\nmodel represent a retrospective view (from 2011) about citation history. These\nislands are much more stable over time; relatively few islands sink or are born. A\ndescription of the methodology for created these two models can be found in\nBoyack &amp; Klavans (2013).\nWe also changed the way that pairs of references are identified and how the votes\nare weighted in the second experiment. These are minor changes in methodology,\nand were done to explore the robustness of our findings using slightly different\nprocedures. Specifically, we decided to use citances (sentences that includes\nreferences) instead of distance between pairs for two reasons. First, citances will\nallow us, in future studies, to look more deeply into the words that are used when\none cites a paper. We have recently been exploring citance analysis as an\nalternative method for identifying breakthrough papers (Small, Boyack, &amp;\nKlavans, 2013). There was no a priori reason why this approach might also be\nuseful for identifying conforming papers. The second reason for citance analysis\nwas to provide an alternative way to weight the votes. In the first experiment, all\npairs of references were weighted equally. In this study, each citance gets one\nvote. Fractionalization was done based on the number of reference pairs in a\n1733\n\ncitance so that a very long citance with tens of references doesn’t overwhelm the\nresults.\nThe same data, indicators and dependent variables are used as in the first\nexperiment. The correlations and regression analyses for the citance analysis were\ncalculated for high impact papers with at least three citances (n=4025). The\ncorrelations and regression analysis for the bibliographic analysis were done for\nall papers with 10 or more votes and which could also be assigned to islands\n(4187 papers).\nTable 3. Correlation and regression results from the second experiment.\nDistance between pairs\n\nCC\nCitance\n\nCC\nALL\n\nDC\nCitance\n\nDC\nALL\n\n4057\n22.1\n20.9\n57.0\n\n4187\n29.8\n7.3\n63.0\n\n4057\n37.8\n18.7\n43.6\n\n4187\n44.4\n5.5\n50.2\n\nPearson correlation with stability\n%Innovative votes\n%Conforming votes\n%Undecided votes\n\n-0.132\n0.345\n-0.190\n\n-0.008\n0.362\n-0.176\n\n-0.144\n0.368\n-0.122\n\n-0.029\n0.370\n-0.115\n\nRegression statistics\nT-statistic (age)\nT-statistic (%Innovative)\nT-statistic (%Conforming)\nAdjusted R-square\n\n29.8\n-4.0\n16.3\n0.284\n\n30.1\n0.54*\n18.1\n0.286\n\n29.3\n-4.1\n15.4\n0.285\n\n29.9\n-1.6*\n14.3\n0.269\n\nStatistics\n#papers\n% Innovative votes\n% Conforming votes\n% Undecided votes\n\n* not significant\n\nThese results are consistent with those reported in Tables 1 and 2. The indicator\nfor conformity has a high correlation with stability, while the indicator for\ninnovativeness has a poor correlation with stability. In the regression equations,\nthe impact from the conformity indicator remains strong while the impact from\nthe innovativeness indicator is weak or not significant. Overall, the correlations\nare slightly lower than those reported in Tables 1 and Table 2, which may easily\nbe attributed to choosing citance analysis (which corresponds roughly to the 375\ncolumn in Tables 1 and 2) and the alternative weighting procedure.\nAdditional analyses were not considered necessary at this point. Our intent was to\ndetermine if the conformity indicator was robust using a different socio-cognitive\nmodel of science and a different method for identifying and weighting reference\npairs. It was not our intent to figure out how to maximize the correlations or rsquare values. And while we did explore different transforms (to deal with\n1734\n\nskewness in the dependent and independent variables), the overall results\nremained the same. The correlation between the conformity indicator and the\nstability of the clusters associated with high impact papers remained very high (in\nsome cases exceeding 0.40) and did not drop below 0.345. Different models and\ndifferent weighting systems did not result in a deterioration of this relationship.\nClusters are more likely to survive if they contain a high impact conforming\npaper, even after adjusting for the history of the cluster.\nDiscussion and implications\nWhat started as an operationalization of Chen’s computational theory of\ninnovativeness has had unintended consequences: the development of a paperlevel indicator of conformity (for high impact papers) that is relatively robust.\nOne could use either a co-citation or a direct citation model to determine the\npercentage of reference pairs that are in the same cluster. The data from both\nmodels could be combined. The use of full text is not necessary; comparable\nresults (in terms of explanatory value) can be found using the bibliography at the\nend of a paper and making the traditional assumption that all references are\nequally related to each other. There are, however, significant shortcomings in this\nstudy that should be emphasized at this point.\nFirst, the choice of the dependent variable (i.e. the stability and survival of\nclusters) is not optimal. It was used as an indirect indicator, which is appropriate\nif one is using large sample size and scanning for useful indicators. A more direct\nindicator of conformity, such as author opinions of the innovativeness or\nconformity of their own papers, or a completely different research design is\nneeded in order to proceed further.\nSecond, we have not taken into account the cluster associated with the citing\npaper. We are actually dealing with triplets – pairs of reference papers and the\nciting paper. The computational theory was not initially formulated in this way\nand may need to be revised. For example, if the citing paper is in one cluster, and\nboth of the cited papers are together but in a different cluster, should this be a vote\nfor conformity or innovativeness?\nThird, more thought needs to be given to the large number of undecided votes.\nWhat do they represent? In the co-citation model, they are mostly references that\nhave a low citation rate in 2007- they represent concept symbols that are not\nmembers of the socio-cognitive norms for 2007. But there is information\nembedded in these concept symbols. The question is- how can one pulls out this\ninformation? In the direct citation model, the undecided references are mostly\nolder. There is no reason that these older references can’t be assigned to reference\nclusters. Doing so would reduce the number of undecided votes.\n\n1735\n\nFinally, thought needs to be given to the strategic implications of generating a\npaper-level indicator of conformity. There may be situations where high\nconformity is needed (i.e. helping to stabilize an exceptionally unstable\nenvironment). But there also may be situations where high conformity is\nattracting resources would be put to better use by funding innovative (and\npotentially risky) work. Further work is needed to unpack what is meant by\nconformity and the role (both positive and negative) it might serve in creating a\nvibrant and effective research system.\nReferences\nBoyack, K. W., &amp; Klavans, R. (2010). Co-citation analysis, bibliographic\ncoupling, and direct citation: Which citation approach represents the research\nfront most accurately? Journal of the American Society for Information\nScience and Technology, 61(12), 2389-2404.\nBoyack, K. W., &amp; Klavans, R. (2013). Advances in constructing highly detailed,\ndynamic, global models and maps of science. Journal of the American Society\nfor Information Science and Technology, under review.\nBoyack, K. W., Small, H., &amp; Klavans, R. (2013). Improving the accuracy of cocitation clustering using full text. Journal of the American Society for\nInformation Science and Technology, in press.\nChen, C. (2012). Predictive effects of structural variation on citation counts.\nJournal of the American Society for Information Science and Technology,\n63(3), 431-449.\nChen, C., Chen, Y., Horowitz, M., Hou, H., Liu, Z., &amp; Pelligrino, D. (2009).\nTowards an explanatory and computational theory of scientific discovery.\nJournal of Informetrics, 3, 191-209.\nGarfield, E. (1972). Citation analysis as a tool in journal evaluation. Science,\n178(4060), 471-479.\nGarfield, E. (1973). Historiographs, librarianship, and the history of science. In C.\nH. Rawski (Ed.), Toward a theory of librarianship: Papers in honor of Jesse\nHauk Shera (pp. 380-402). Metuchen, NJ: Scarecrow Press.\nGarfield, E. (1977). The 250 most-cited primary authors, 1961-1975. Part II. The\ncorrelation between citedness, Nobel prizes and Academy memberships.\nEssays of an Information Scientist, 3, 337-347.\nGarfield, E. (2006). The history and meaning of the journal impact factor. Journal\nof the American Medical Association, 295(1), 90-93.\nGarfield, E., &amp; Malin, M. V. (1968). Can Nobel Prize winners be predicted?\nPaper presented at the 135th Annual Meeting of the AAAS.\nGarfield, E., &amp; Welljams-Dorof, A. (1992). Of Nobel class: A citation perspective\non high impact research authors. Theoretical Medicine, 13(2), 117-135.\nGeuna, A., &amp; Martin, B. R. (2003). University research evaluation and funding:\nAn international comparison. Minerva, 41, 277-304.\nHicks, D. (2012). Performance-based university research funding systems.\nResearch Policy, 41(2), 251-261.\n1736\n\nKlavans, R., &amp; Boyack, K. W. (2011). Using global mapping to create more\naccurate document-level maps of research fields. Journal of the American\nSociety for Information Science and Technology, 62(1), 1-18.\nMacRoberts, M. H., &amp; MacRoberts, B. R. (1989). Problems of citation analysis:\nA critical review. Journal of the American Society for Information Science,\n40(5), 342-349.\nMacRoberts, M. H., &amp; MacRoberts, B. R. (1996). Problems of citation analysis.\nScientometrics, 36(3), 435-444.\nMartin, B. R. (2011). The Research Excellence Framework and the &#x27;impact\nagenda&#x27;: are we creating a Frankenstein monster? Research Evaluation, 20(3),\n247-254.\nMoravcsik, M. J., &amp; Murugesan, P. (1975). Some results on the function and\nquality of citations. Social Studies of Science, 5(1), 86-92.\nNicholson, J. M., &amp; Ioannidis, J. P. A. (2012). Conform and be funded. Nature,\n492, 34-36.\nSmall, H., Boyack, K. W., &amp; Klavans, R. (2013). Identifying emerging topics by\ncombining direct citation and co-citation. Paper presented at the submitted to\nISSI 2013.\nWaltman, L., &amp; Van Eck, N. J. (2012). A new methodology for constructing a\npublication-level classification system of science. Journal of the American\nSociety for Information Science and Technology, 63(12), 2378-2392.\n\n1737\n\nTRACING RESEARCH PATHS OF SCIENTISTS BY\nMEANS OF CITATIONS\nMarianne Hörlesberger and Beatrix Wepner\nmarianne.hoerlesberger@ait.ac.at and beatrix.wepner@ait.ac.at\nAIT Austrian Institute of Technology GmbH, Donau City Straße 1, A-1220 Vienna\n(Austria)\n\nAbstract\n\nThis contribution presents an approach for tracing research paths of scientists based on\ntheir profile of cited references. The results could be applied for analysing the\ndevelopment of single or groups of scientists in their own area or into a new field. This\nmight be interesting for evaluation for research grants or also for investigation of transdisciplinary research centres. Our approach utilises the cosine powerfully and provides\nclear results.\n\nConference Topic\n\nManagement and Measurement of Bibliometric Data within Scientific Organizations\n(Topic 9); Science Policy and Research Evaluation: Quantitative and Qualitative\nApproaches (Topic 3)\n\nIntroduction\nHas a scientist moved from one research field into another or has he / she stayed\nin the same research domain since the beginning of the research carrier? Such a\nquestion might be important for instance for supporting scientists to create their\nown research topics and environment, to give them the chance to build up an\nindependent research field. A movement out of the familiar research area might\nbe risky for a scientist, but would indicate an aspect of frontier research, which is\nan intrinsically risky endeavour [5]. Another application of our approach could be\nthe answer to the question in trans- or interdisciplinary research institutes to make\ndifferent approaches of scientists originating from various disciplines visible.\nWhile most publications in bibliometrics, scientometrics, or informetrics deal\nwith the analysis of a high number of scientists, or journals this contribution\npresents indicators for the investigation of individual authors. The shift of a\nscientist to a new domain can be unveiled by investigation of his / her cited\nreference profile.\nThe cited references of scientific publication represent the knowledge on which\nthe research work is based on. Leaving the familiar research environment and\nmoving into a new area entails changing the knowledge base of his / her research\nfield [6].\n1738\n\nThe underlying hypothesis of our approach could be formulated as follows. If a\nscientist shifts to a new research domain he / she will cite different references to a\ngreater extent than he / she has done in his / her previous work. Stepping out of\nthe well-known knowledge base (expressed in the set of cited references) and\nresearch environment creates new opportunities as well as potential risk, and there\nis an interest in defining and identifying such a path and people changing from\none field toward another [2]. These considerations lead us to develop indicators\nfor such situations.\nWe consider the knowledge base on which the work of a scientist is built on.\nData\nSince we closely work with a research centre “TRIBOLOGY”, a very interdisciplinary domain, where scientists from the various fields such as material\nscience, engineering, physics, chemistry, or mathematics work together, we\ndecided to investigate the development of the citation profile of 20 authors in this\nresearch area. These scientists with at least ten publications up to 200 over several\nyears are taken into account.\nThe authors were selected from a general bibliometric study in “TRIBOLOGY”\nand combined with some authors from the research centre itself. For each author\nthe publications available in Web of Science were recorded. The investigation in\nthis contribution is therefore limited to Web of Science data.\nMethod\nThere are different possible concepts and indicators based on mathematics,\nbibliometrics, information theory, economic, or even physics which offer several\nideas (as already described in many publication, under many others in (Boyack K\nW et al. 2010, [1]), (Chen C. 2005, [2]), (Czerwon HJ et al. 1995, [3]), Egghe L,\n2009, [4]). Various disciplines provide algorithms and indicators for our research\nquestion, taking statistical, geometrical, or network analysis points of view into\naccount. Moreover there are also approaches coming from economics (e.g. Gini\ncoefficient), or of information theory (entropy) perspective. A discussion about\ndifferent approaches is summarized in Leydesdorff and Rafols 2011 (in [7]), but\nthey discuss the indicators in the context of “interdisciplinarity”. The difference to\nour approach lies in the application to different datasets, thus we do not consider\nthe interdisciplinarity but rather the specialisation and the development of\nindividual authors in their own research field.\nThe concept idea of the introduced approach here is to apply the trigonometrically\nfunction cosine. But first the data has to be prepared appropriately.\n\n1739\n\nWe consider all publications of a scientist recorded from Web of Science175. Then\nwe list all references and allocate them to all publications in the following way. If\na considered cited reference (CR) is cited by paper X, the entity value is 1. In case\nthe considered CR is not cited by paper X, the entity value is 0. This is done for\nall papers of a considered author.\nIn this way we get a vector e.g. (1, 0, 0, 1, 1, 0, 0, 0, 1, ...) for each paper. Then\nfor each couple of papers, the cosine is calculated.\nThe trigonometric function cosine is a function of an angle. Is the angle\northogonal the cosine takes the value 0. Is the angle 0 the cosine takes the value 1.\nIn other words the cosine takes the value 1 in case the two vectors are identical\nand takes the value 0 if the two vectors are orthogonal, because the inner product\nof two vectors (the numerator in F1) is 0. The cosine of two vectors a, b is given\nby the following formula\n\ncos (a, b) \n\na b\n| a ||b |\n\nF1\n\nLet us apply these considerations to our data “cited references”. We except a\ncosine value closer to 1 in case the cited references concur in two considered\npapers. If the cited references do not concur the cosine would take a value closer\nto 0. These considerations are motivated by (Czerwon HJ et al. 1995, [3]).\nIn this way we get n-1 cosine values for each author, when his / her number of\npapers is n. Now the cosine value path can be validated by checking the\nkeywords, titles, abstracts so that big changes (a cosine value close to 0) from one\npaper to the next or hardly any changes (a cosine value close to 1) can be\nexplained.\nFor getting an overview of the shift in the reference profile over all papers all\ncosine values are summarised and divided through the whole number of\nconsidered papers of an author. This approach allows us to compare all our 20\nauthors in the dataset and provides an interesting result.\nResults\nIndividual authors\nThe cosine of the two CR vectors describes in a simple value how similar two\narticles are. It makes obvious how long a scientist works on a specific topic, if he\n/ she works on various topics, or when he / she moves to a new topic.\nFigure 1shows a cited reference profile of Author_L. The values on the x-axis (the\nzeros) indicate a strong change in the research topics. Although we consider here\nonly cited references this hypothesis could be validated by investigating the titles,\nkeywords, and abstracts of the considered papers. In areas where the cosine is\n175\n\nWeb of Science provide the cited references in a relatively well standardised format.\n\n1740\n\nhigh strong change in the topic represented in the titles, abstracts, and keywords\ncan be noticed.\n\nFigure 1. Cited reference profile of Author_L. The y-axis presents the cosine values.\nOn the x-axis are the years (1 is the oldest, 127 is the youngest, whereas several\npapers are published in one year) of the papers publication.\n\nA closer look on the papers uncover that the papers 16 and 17 for instance have\nvery similar cited references. They deal with hip, knee replacement. The papers\n52 to 61 cite different references, also 73 to 90, etc. Since paper 105 the term\nmolybdenum disulfide occurs, which is discussed in the following publications.\nThe last papers (121 to the end) are assigned to different topics in electrical wear,\neven though a similar field but considering various applications and materials thus\nreverting to different knowledge-bases.\nThe cited reference profile of Author_S is presented next (Figure 2). The research\ntopics of this author have not changed so much resulting in a higher cosine value.\nThis fact can be underlined by checking the keywords, abstracts, and titles of his /\nher papers. The research of Author_S develops more continuously with few\ninterruptions, which can be seen in those periods where the cosine is zero.\n\nFigure 2. Cited reference profile of Author_S. The y-axis presents the cosine values.\nOn the x-axis the papers are ranked in chronological order (1 is the oldest, 60 is the\nyoungest, whereas several papers are published in one year).\n1741\n\nThe scientific career of the following Author_F (Figure 3) has developed\ncontinuously in a specific topic, namely physical vapour deposition, hard\ncoatings, ultrathin coating, and nano (the high peaks in Figure 3). When the\ncosine values are zero the application field of his / her research has changed.\n\nFigure 3. Cited reference profile of Author_F. The y-axis presents the cosine values.\nOn the x-axis the papers are ranked in chronological order (1 is the oldest, with a\nlong scientific career of 201 papers).\n\nAuthor_T is a young scientist building up his research in one specific field. He\n/she has worked continuously on “turbulent boundary-layer flows”.\n“Turbulences”, “bluff body”, or “separation” are some keywords describing his /\nher work. The cosine profile in Figure 4 demonstrates this fact clearly.\nAuthor_O’s cited reference profile indicates longer periods, where he / she works\nagain and again on different topics. The peaks in the profile (Figure 5) show\nclearly the changes in the scientific works. They deal with “tribological\nproperties”, “nanoparticles”, “lubrications”, or “ultra-high-molecular-weight”,\n“polyethylene/liquid crystalline polymer composites”.\n\n1742\n\nFigure 4. Cited reference profile of Author_T. The y-axis presents the cosine values.\nOn the x-axis the papers are ranked in chronological order (1 is the oldest, 12 the\nyoungest).\n\nFigure 5. Cited reference profile of Author_O. The y-axis presents the cosine values.\nOn the x-axis the papers are ranked in chronological order (1 is the oldest, 89 the\nyoungest).\n\nThese samples confirm that the introduced approach is a useful method for\ninvestigating the shift to a new research field of a scientist.\n\n1743\n\nA set of authors\nLet us consider all investigated 20 authors and put their results into one chart. For\ndoing so we applied the following procedure. All cosines of one author were\nsummarised. After that this yield result was divided by the numbers of articles of\neach author. Then these values were ranked increasingly. The result is presented\nin Figure 6. When we summarise all cosine values of an author the amplitudes are\nweakened, of course. Nevertheless this one value (the sum of all cosine values of\none author divided through the number of his / her publications) indicates\ngenerally if an author changed his / her research topic significantly or not.\n\n0.180\n\nStrong changes in the use of\nCRs\n Changes in research\ntopics\n\nSome changes in the use of CRs\n Slight movement in the\nresearch topic (e.g. new\napplications)\n\nHardly any changes in the use\nof CRs\n Stay in the same research\ntopic\n\n0.160\n\n0.140\n0.120\n0.100\n0.080\n0.060\n0.040\n0.020\n0.000\n\nFigure 6. The overall cited reference profile of the 20 investigated authors.\n\nDiscussion\nThis approach unveils that if the articles placed in a chronological order the\ncosine clearly and easily shows differences in the knowledge-base a scientist\nreverts to. Also when comparing groups of authors using the cosine value\nsummarised and standardized in relation to the number of papers of each author\n(Figure 6) provides a good insight to researcher publishing in different areas\nversus authors researching in constant and stable fields.\nHowever the weakness of this linear approach is if an author published papers in\ntwo or more fields in parallel he appears to excursive. Therefore we work\ncurrently on developing a matrix method where all cited references of all papers\n\n1744\n\nof an author are compared with each other so that parallel or intertwined research\nstrings can be made visible.\nReferences\n[1] Boyack K W; Klavans R. (2010). Co-citation analysis, bibliographic\ncoupling, and direct citation: Which citation approach represents the research\nfront most accurately? Journal of the American Society for Information\nScience (JASIST). V 61(12), p 2389-2404.\n[2] Chen C. (2005). Measuring the movement of a research paradigm. In Proc. of\nSPIE-IS&amp;T, Visualization and Data Analysis. V 5669, p 63-76. San Jose.\n[3] Czerwon HJ; Glänzel W. (1995). A New Methodological Approach to\nBibliographic Coupling and Its Application to Research-Front and Other Core\nDocuments. Proceedings of the 5th International Conference on Scientometrics\nand Informetrics, p 7-10. River Forrest, Illinois, US.\n[4] Egghe L; Leydesdorff L. (2009). The relation between Pearson&#x27;s correlation\ncoefficient r and Salton&#x27;s cosine measure. Journal of the American Society for\nInformation Science (JASIST). V 60(5), p 1027-1036.\n[5] Holste D; Scherngell T; Roche I; Hörlesberger M; Besagni D; Francoise C;\nCuxac P; Schiebel E. (2012). Capturing frontier research in grant proposals\nand initialanalysis of the comparison between model vs. peer review. STIConference 2012, 5-8 September, Montreal.\n[6] Hörlesberger M; Holste D; Schiebel E; Roche I; Francois C; Besagni D;\nCuxac P. (2011). Measuring the Preferences of the Scientific Orientation of\nAuthors from their Profiles of Published References. ENID (European\nNetwork of Indicator Designers) 7-11 September, Rome.\n[7] Leydesdorff L; Rafols I. (2011). Indicators of the interdisciplinarity of\njournals: Diversity, centrality, and citations. Journal of Informetrics. V5, p 87100. DOI: 10.1016/j.joi.2010.09.002\n\n1745\n\nTRACKING ACADEMIC REGIONAL WORKFORCE\nRETENTION THROUGH AUTHOR AFFILIATION\nDATA\nSharon Kitt\ns.kitt@ballarat.edu.au\nUniversity of Ballarat, University Drive, Mount Helen VIC 3353 Australia\n\nAbstract\n\nAcademic mobility is considered a standard requirement for the development and\nprogression of an academic research career. However, this career mobility is at odds with\nthe drive to recruit and retain professionally-qualified workers in regional Australia, to\nensure future generations of regional Australians have capacity to access higher education\nin their home region. To date, little work has been completed regarding the retention of\nactive research staff in regional Australia. The purpose of this paper is twofold: to\ndetermine the viability of using author affiliation data as listed on publications to track an\ninstitutional cohort of authors by their affiliation; also, to determine if data analysed using\nthis method revealed any insights regarding the retention of academic staff. Whilst using\nauthor affiliation data was found to be viable, it required extensive data manipulation and\ncleansing. Once analysed, the data revealed intriguing insights into the retention and\nmovement of active academic researchers. Implications for regional higher education will\nbe discussed.\n\nConference Topic\n\nScience Policy and Research Evaluation: Quantitative and Qualitative approaches (Topic\n3); Research Fronts and Emerging Issues (Topic 4); Management and Measurement of\nBibliometric data within scientific organisations (Topic 9)\n\nIntroduction\nMobility in the academic research workforce has long been a desired goal and an\noft-stated requirement of building a successful academic career, although this may\nnot be entirely through choice but of necessity (Morano-Foadi, 2005). Harrigan\n(1997) cites three reasons that academic staff leave an institution: “involuntary\n(did not earn tenure, dismissed for cause); voluntary (dissatisfied with position,\nfound better career opportunity, higher salary elsewhere); or end of career\n(retirement or death).” Research into academic workforce movement focuses on\nthe voluntary component of this, usually related to international movements of\nstaff (Cantwell, 2011; Hugo, 2005; Jöns, 2007) – that is, either emigration from or\nimmigration to a defined country, on a fixed term or permanent basis. Such\nstudies reveal the benefits to knowledge production of academic mobility, as\n“cultural and geographical proximity and distance continue to shape international\n\n1746\n\nacademic exchange and enable the identification of different national academic\ncultures around the globe” (Jöns, 2007, p102).\nConsequently, many governments across the world are actively encouraging the\ntrans-national movement of research staff through provision of information via\nonline ‘mobility portals’ (http://www.mobility.org.au/outgoing/portals). Australia\ntoo has a program to encourage incoming and outgoing researcher migration\n(http://www.mobility.org.au/). Several reports commissioned by the Australian\ngovernment explicitly detail this requirement for mobility in creating innovation\n(Cutler, 2008; DIISR, 2009). This globalisation of research effort and staffing\n(Fahey &amp; Kenway, 2010) for Australian researchers has been hailed as a positive\nstep forward for the creation of new paradigms of knowledge. It could be\nexpected that large nation-states, such as the USA and Australia, would see a\ndegree of internal movement within the higher education sector due to the same\ngeographical proximity benefits, but there has been scant attention given to\nmapping the degree to which this may or may not occur.\nOf course, in creating a positive environment encouraging global research staff\nmovement, there is an associated impact on academic staff retention at the\ninstitutional level. Essentially turnover and retention are two sides of the same\ncoin: turnover is the rate at which staff leave regardless of when they commenced;\nand retention is the rate at which employees from the same cohort stay at the\ninstitution (CIPD, 2012). Research into turnover focuses on the reasons\nemployees leave, whereas retention research focuses on the reasons why they\nstay.\nIn a 2008 survey by the United Kingdom’s Higher Education Funding Council for\nEngland, academic turnover rates were given as 6%, the lowest of any\nemployment group within the higher education sector (UCEA, 2008), with other\nstudies suggesting annual turnover rates of 12.8% (Glandon &amp; Glandon,\n2001).The concept of low academic turnover is more of a concern rather than high\nturnover, although both ends of the spectrum were identified as being\nproblematic (UCEA, 2008) given the desire to have a mobile knowledge\nworkforce. Turnover rates focus on academic staff as a homogenous group,\nwithout any connection between the turnover rate and the type of academic staff\nbeing lost to the institution. For example, would a turnover rate of 6% be\nacceptable if it contained the most-published research academics within an\ninstitution?\nIn terms of calculating retention rates, it is usually measured as the changes in\nworkforce composition between two points in time, usually year-to-year.\nHowever, for examining academic workforce retention, and taking into\nconsideration academic contracts and tenure, a more longitudinal perspective on\nretention is required. There is a paucity of data surrounding academic staff\n1747\n\nretention rates, however two studies have found that retention over a 10 year\nperiod is around 50% (Harrigan, 1997; Kaminski &amp; Geisler, 2012).\nAlthough academic mobility is seen as important for researchers and knowledge\ncreation, it is the antithesis of desire in establishing and retaining professionallyqualified individuals within regional settings. Regional Australia - much like\nregional areas in any large or sparsely populated country - faces significant\nchallenges in not only attracting but retaining professionally-qualified staff such\nas medical workers (Humphreys, Jones, Jones, &amp; Mara, 2002; Mills, Birks, &amp;\nHegney, 2010; Moore, Sutton, &amp; Maybery, 2010), teachers (Plunkett &amp; Dyson,\n2011), engineers and accountants (Carson, Coe, Zander, &amp; Garnett, 2010). Higher\neducation of students in rural and regional areas requires an academic workforce\nto support this, which in turn requires the initial attraction and the longer term\nretention of these new professionals to the rural or regional area (Hugo &amp; Morriss,\n2010). However, recent reviews on academic workforce issues either barely\nmention rural and regional problems in passing (Hugo &amp; Morriss, 2010) or ignore\nthem entirely (Coates &amp; Goedegebuure, 2012).\nA further compounding issue for building a sustainable, regional academic\nworkforce is that of the ageing of the Australian population, where even the\nacademic workforce demographic is increasingly clustered towards retirement age\n(Hugo &amp; Morriss, 2010). This is not a problem unique to Australia (Edwards &amp;\nSmith, 2009); thus the pool of talent that can be drawn upon to fill positions\nvacated by retiring academic in regional Australia is diminishing world-wide.\nThus rural and regional Australia faces three strong challenges in developing and\nretaining an academic workforce: firstly, from the culture of academe itself that\nmandates mobility in determining academic career success; secondly from the\nchallenges that face the retention of all professional groupings in a regional or\nrural environment; and thirdly, from an ageing and shrinking academic workforce.\nUse of author affiliation data\nEach time an author has an academic paper published, a related institutional\naddress or institutional affiliation is also recorded. This institutional affiliation is\nused to identify the origin and further contact details of the authors using a variety\nof non-mandated, non-standardised address fields such as school, faculty,\nuniversity name, campus name, suburb, state and country. This then forms part of\nbasic citation data that can be exported electronically from bibliographic\ndatabases. For this study, the data were exported from the Elsevier citation\ndatabase Scopus due to its availability in the author’s home institution.\nThe use of institutional affiliation is not uncommon within the scientometric and\nbibliometric literature. These analyses are usually one of the following varieties:\n\n1748\n\n\n\n\n\n\n\nTo compare a number of institutions by publication activity e.g.\n(Sorensen, 1994)\nTo examine research activity by geographic areas, usually limited to a\nspecific discipline e.g. in tropical medicine (Falagas, Karavasiou, &amp;\nBliziotis, 2006), in cardiovascular diseases (Rosmarakis et al., 2005), and\nin terrorism studies ((Reid &amp; Chen, 2007)\nTo undertake network analyses for research collaborations and their\nevaluations (Ye, Song, &amp; Li, 2012)\nTo determine journal quality by using institutional affiliation as a proxy\n(Agrawal, Agrawal, &amp; Rungtusanatham, 2011; Gorman &amp; Kanet, 2005).\n\nThus, institutional affiliation data is typically used as a representation of quality\nfor a journal, an institution, a geographic area, or all three combined. What is not\napparent in the literature is a way of using affiliation data to tackle questions\nsurrounding the human resourcing issues of academic mobility via publication\noutputs.\nPurpose\nThe aim of this paper is to firstly examine the feasibility of using author\naffiliation data as a method of tracking research workforce retention. Secondly, if\nfeasible, to examine any insights the affiliation data may reveal regarding\nacademic retention and movement. Thus degree to which the retention issues are\ncurrently at play within an Australian regional academic environment and how\nbibliometric data can assist in understanding the issue are the main foci of this\npaper\nMethod\nA university based in regional Australia was chosen to be the case study for this\nresearch. Located over an hour from the state capital city, the institution itself has\nsmall but not an insignificant cohort of research staff occupying several nearby\nregional campuses. Importantly, the university itself had no metropolitan\npresence, making it feasible to examine the author affiliation data without fear of\nthe data being biased due to the influence of urban campuses. The Scopus\ndatabase was then interrogated to determine the name variations for the casestudy university as due to institutional mergers and other reasons, an institution\nmay have one or more names listed. Fortunately, in this case there was only one\naffiliation name listed. So, on the 25 September 2012 all journal papers published\nin the years 2005, 2006, 2010 and 2011 that had any authors listed with the casestudy institutional affiliation were extracted from Scopus. These papers were\nextracted as two, two-year cohorts; 2005-6 forming the baseline cohort, with\n2010-11 forming the second, comparison cohort. The two-year grouping of\ncohorts was selected for a variety of reasons: firstly, to account for disciplines that\nmay have very different publishing frequencies; secondly, to account for staff that\nmay have newly arrived at the institution and required some start up time; and\n1749\n\nfinally, it aligns with the formulae used by the Australian Government in\ncalculating federal grant allocations, where the number of publications are\naveraged over a two year period. The five year period between cohorts was\nconsidered by the author to be adequate to allow for some indication of staff\nmobility to be evidenced.\nFrom the affiliation search, 613 articles were extracted for the period 2005-6 and\n2010-11. The bibliographic data extracted included author affiliations for all\nauthors on the articles. An initial scan of the data resulted in one article being\ndiscarded due to the date of publication actually being 2012. Three other articles\nwere discarded as they were still listed as being in press at 2011 so their official\ndate of publication was unclear. One further article was discarded due to being a\nduplicate record in Scopus (confirmed and later deleted by Scopus). Out of an\ninitial extraction of publication affiliation data, a total of 607 documents remained\nviable for analysis and form the basis of this study.\nData issues\nPrevious research using author affiliation data noted the requirement for extensive\ndata cleansing and matching to ensure the accuracy of affiliation data (Neuhaus &amp;\nDaniel, 2008), which was also found to be an issue within this study. Whilst it is\npossible to view disambiguated author affiliation data within Scopus as part of the\nnormal viewing of citations, as an exported dataset affiliations were provided as a\nheterogeneous string variable within the same field. For example, a preliminary\ninvestigation revealed that whilst author names were mostly recorded\nconsistently, their affiliation declarations were vastly different across all\ninstitutions within the extracted dataset. This made it difficult to identify the\nnumber of institutional authors on a paper without manually reviewing the data.\nIn this case study, affiliation was necessary to identify only authors that had an\naffiliation listed with the institution. However in examining the data the\nvariations within the affiliation fields included:\n\n\n\n\n\n\n\n\nvariations of the name or abbreviated name of the university (such as\n“Univ of X”, “Uni of X”, “X Uni”, et al)\nvariations in the address of the university (PO box, street address, no\naddress given)\nvariations in the name of the suburb, or no suburb listed\nvariations in the postal code/zip code of the address (e.g. 1234, 1233, no\npostcode)\nInclusion or exclusion of the School or Faculty name\nInclusion or exclusion of the State\nInclusion or exclusion of the Country (Australia)\n\nThe variety within the data sets as per the above make difficult the development\nof programmatic filters or algorithms to easily cleanse the data into a homogenous\n1750\n\nset. It also complicates searches conducted within the dataset, as data elements\nthat purportedly reveal affiliation may be overlooked or mistakenly included. For\nexample, whilst the University itself contains a unique city name, searching for\nthe name of the city also revealed authors that have published with a universityaffiliated staff member but were themselves affiliated with other city institutions,\nsuch as the city library. Within the bounds of this study it was important to\nexclude such author affiliations to ensure the accuracy of the results.\nA case study approach to this study proved to be useful, as it was feasible to\nmanually examine each of the authors affiliated with the institution and check\neach of the papers within the extracted dataset. That is, namesakes and name\nvariants were identified and reconciled against institutional staff lists and other\npublication data (where available). In this way, author details were normalised\nwithin the dataset to ensure that the two cohort datasets where internally valid.\nThus each affiliated author was represented by only one name in each cohort and\npaired across cohorts. Non-affiliated authors – that is, those that were not\naffiliated with the case study institution in either cohort, were not disambiguated\nnor normalised and therefore the numbers of authors should be taken as indicative\nonly.\nAuthor identification aside, an unanticipated side issue was that of incorrect\nauthor matching by Scopus, where publications by authors with similar names\nwere associated incorrectly with an affiliated author. This was identified for five\ninstitutionally-affiliated authors. Requests were submitted to and acted upon by\nScopus for correction in three of these cases, with the remaining two being\nsufficiently complicated cases requiring further manual intervention by the author\nthemselves (these two authors and their publications were ‘cleaned’ by the author\nof this analyses for the purposes of the case study only). Whilst five authors per\n159 is a relatively small error rate (3%), it would be of interest to delve further\nwithin the Scopus database to determine if this incorrect citation attribution is\nrepresentative of all author data within Scopus. If so, this has considerable\nimplications for the accuracy of Scopus data for bibliometrics and other research\nwork.\nResults\nThere were 607 journal articles reviewed for this study. In the 2005-2006 baseline\ncohort, 203 valid papers were used, with the remaining 404 papers in the 2010-11\ncomparison cohort. Table 1 (below) describes the characteristics of the cohorts.\nComparisons between the two cohorts paint an interesting picture of activity\nduring these two time periods. In 2005-6 there were 330 instances of the\ninstitutionally-affiliated authors on 203 papers, with the average number of\ninstitutional authors per paper being 1.6. In 2010-11, the number of affiliated\nauthors nearly doubled to 650; however, the average number remained the same\n1751\n\nat 1.6 affiliated authors per paper. Similarly, there was a decrease in the relative\npercentage of unique lead authors, from 0.8 to 0.6 per paper. This means whilst\nthe number of papers is increasing, this may be due to a higher publishing rate\nfrom a smaller group of authors, but less of these authors are actually named as\nfirst author. Whilst the average numbers of all authors per paper increased from\n2.65 to 4.00, this figure was skewed by one paper that had more than 350\ncollaborators. Removing this paper as an outlier would reduce the average\nnumbers of authors per paper for 2010-11 to 3.13.\nTable 1. Scopus dataset characteristics\nDescription\nNo. of papers from Scopus used\nNo. of affiliated (normalised) and non-affiliated\n(non-normalised) authors on all papers\nNo. of affiliated authors on all papers\nNo. of unique affiliated authors on all papers\nAvg no. of affiliated authors per paper\nAvg no. of unique affiliated authors per paper\n\nBaseline\nCohort 2005-06\n203\n\nComparison\nCohort 2010-11\n404\n\n538\n\n1614\n\n330\n159\n1.6\n0.8\n\n650\n241\n1.6\n0.6\n\nFigure 1. 2010-2011 publication activity of all institutionally-affiliated authors from\nthe 2005-6 dataset\n\nLooking at the differences between 2005-6 and 2010-11 (Figure 1), a picture of\nthe retention activity of the 2005-6 baseline cohort can be seen. In summary, of\nthe 159 authors listed in 2005-2006 baseline cohort, 62 (39%) authors were still\n1752\n\npublishing journal articles affiliated with the institution in 2010-11 and were\nclassified as “affiliated research active.” Additionally, it means that of the 241\nunique affiliated authors listed for the Institution in 2010-11, only a quarter of\nthese (the 62 authors) were staff at the institution five years previously.\nThrough examination of the institutional staff contact directory from the 20102011 years, it was determined that 20 (13%) of the 2005-6 cohort were still\nemployed at the institution but were not actively publishing – the “affiliated nonresearch active”. By inspecting their position title and corporate location, it was\nclear that some of these affiliated non-active academic staff had at some point\nmoved into senior administrative or executive positions of the institution.\nHowever, a number had retained their academic position but had not continued to\npublish academically.\nTherefore, 97 authors (61% of the initial cohort) in total had not published papers\naffiliated with the institution in the subsequent cohort years. Whilst as described\nabove, 20 of these 97 were still at the case-study institution, further investigation\nregarding these remaining non-affiliated group 77 authors was then conducted.\nOf the 31 researchers that remained research active at other institutions, 20 moved\nto another Australian institution and 11 were publishing at an overseas institution.\nThese are the research-active, non-affiliated group. Of these, only 2 of the 20\nresearchers that remained in Australia, remained at a regional institution – the rest\nwere publishing from a metropolitan institution. So of the initial cohort of 159\nactive affiliated researchers, 11% were no longer situated within regional\nAustralia. Essentially, the data suggests that if a researcher left the case-study\ninstitution to remain an active researcher, it was to continue their research career\nat a non-regional organisation.\nFor the non-research active, non-affiliated group, these were still 24 authors that\nhad left the case-study institution and moved to another institution. However\nwithin the confines of the second cohort timeline, these 24 authors did not publish\nwithin the 2010-11 period. This was determined through examination of their\nScopus author history record, which records the latest affiliation of the author as\nper their most recent publication. The current status of these authors in terms of\nwhether they were still employed within their latest institution was deemed\nbeyond the scope of the current study.\nFor those that were not affiliated, 22 (14% of the initial cohort) of these were no\nlonger employed by the institution but had no further publications or affiliations\nlisted for them within the Scopus database with any other institution. These were\nthe proverbial “‘one-hit wonders’” (Harzing &amp; Van der Wal, 2008), only\npublishing one paper under their name. That is, 14% of the actively publishing\n\n1753\n\nworkforce had effectively disappeared five years later, lost to the case-study\ninstitution and academia generally.\nThus through tracking author affiliations through citation datasets, the retention\nrate for actively publishing academic staff from 2005-2006 to 2010-2011 was\n52% over 5 years. This compares favourably to the retention rates reported in the\nliterature. However, if only actively publishing academics were included, that\nretention rate drops to 39%.\nDiscussion\nThe primary purpose of this case study was to examine the retention of a cohort of\nacademic staff from a single regional institution, through the use of their author\naffiliation data. It was found that only 39% of staff were actively publishing with\nthe same regional institution after five years. This is much lower than the reported\nretention rate of academic staff of 50% across a ten year period. The difference\nmay be accounted for as that this study examined active, publishing researchers as\nopposed to all academic staff within the institution. It is highly likely that the loss\nof 61% of actively publishing– and one would assume actively researching –\nauthors would have a deleterious effect on the ability of the case-study institution\nto nurture and grow research activity. There is however a paucity of research\nregarding the reasons for attrition and the resultant impacts, particular in the\ncontext of regional higher education. Indeed, it may be possible that this retention\nfigure could be higher, lower or representative of institutions throughout the\nAustralian higher education sector. Of similar concern to regional higher\neducation research production was the 13% of authors located within the\ninstitution but not actively publishing. To support these researchers to research\nand publish would assist in the amelioration of issues arising from an apparently\nregional transient workforce. It would be worth further consideration as to the\nreasons why this is occurring and how institutions could support these academics\nto remain actively publishing researchers. Further investigation on the results and\nimpact of this retention rate is needed to fully assess these issues.\nOne surprising result was the number of authors with a sole publication. These\nauthors make up 14% of the original publishing cohort and are a curious anomaly.\nThey clearly are individuals that are capable of undertaking an academic career\nevidenced through their ability to create academic publications, but through\nunknown circumstances have not. Questions arise whether their separation from\nthe institution – and indeed academic life – was voluntary, involuntary or due to\nend-of-career issues. Perhaps a further option – end of academic career – could be\nput forward as a fourth reason for career mobility. Further research could\ninvestigate why these individuals did not pursue an academic career and whether\nthat is an anomaly of this regional institution, all regional institutions or all\ninstitutions in general. Additionally, if these authors have moved into industry, it\n\n1754\n\nwould be worth examining ways in which institutions can keep these authors\ninvolved with academia to perhaps enhance university-industry collaborations.\nFor the researchers from the 2005-2006 cohort that did leave the institution and\nremained in Australia, all but two out of twenty remained in regional Australian\ninstitutions. With such a limited case study it is difficult to determine whether this\nis an anomaly of the dataset used in this case-study or a representation of ‘brain\ndrain’ from regional Australia. However this case study does suggest that\nretention of research active academic staff within regional Australia requires\nfurther attention to determine who is leaving regional institutions and more\nimportantly, why. For the case study institution at least, it should be a cause for\nconcern.\nThe other purpose of this study was to determine the feasibility of using citation\ndatasets containing author affiliations as a data source for higher education\nresearch. This study supported that it was a feasible method, which in turn\nprovided insight regarding the retention issues facing regional institutions.\nHowever, the size of the dataset used in this study needs to be taken into\nconsideration when preparing to replicate this type of analysis with larger and/or\nmultiple institutions. A key factor in the success of using this dataset was the\nability by the study’s author to track down authors on a case-by-case basis. It was\nrelatively simple to identify the whereabouts of 159 authors after a period of 5\nyears; to take this per capita approach with author datasets that are larger (more\nauthors) or more complex (multiple sites, multiple institutions) requires a\nconsiderable investigative investment. In the future, it may be that projects such\nas ORCID (Open Researcher and Contributor ID) may provide a way of ensuring\nthis data is consistently recorded for all researchers, particularly as Scopus\nsupports this initiative (ORCID, 2012). Meanwhile, automated or algorithmic\napproaches must ensure that they can operate within the data inconsistencies\nidentified before they are able to be fully employed in such research.\nConclusion\nThis case study analysis undertaken is a novel approach to the use of bibliometric\ndata, expanding the role author affiliation beyond that of merely a base to contact\nauthors into readily accessible data to inform university human resource planning.\nIt appears that retention of actively researching academic staff from this regional\ninstitution is low compared to expected retention rates of all academic staff.\nAdditionally, the case study uncovered the phenomena of ‘one-hit wonders’, who\nmay be a source of untapped talent that have moved into industry that could be\nbetter affiliated with institutions. This case study provides the first look at the\nmovement of academic staff from the institution, where it appears that those that\ndo separate from the institution do so to be employed at a metropolitan university.\nA corollary to this study will be an inward migration study conducted to examine\nwho published at the institution for the first time in 2010, and from where they\n1755\n\noriginated. Whilst this case study shows that using the data in this way is viable,\nto do so requires considerable data reconciliation and validation. Regardless, the\nlevel of brain drain from a regional Australian institution has been tracked for the\nfirst time, and the loss of these active researchers to the region has considerable\nimpacts on the institution – and regional higher education in general, now and in\nthe future.\nAcknowledgments\nThe author acknowledges the assistance of the Collaborative Research Network,\nUniversity of Ballarat.\nReferences\nAgrawal, V., Agrawal, V., &amp; Rungtusanatham, M. (2011). Theoretical and\nInterpretation Challenges to Using the Author Affiliation Index Method to\nRank Journals. Production and Operations Management, 20(2), 280–300.\nCantwell, B. (2011). Transnational Mobility and International Academic\nEmployment: Gatekeeping in an Academic Competition Arena. Minerva,\n49(4), 425–445.\nCarson, D., Coe, K., Zander, K., &amp; Garnett, S. (2010). Does the type of job\nmatter?: Recruitment to Australia’s Northern Territory. Employee Relations,\n32(2), 121–137.\nCoates, H., &amp; Goedegebuure, L. (2012). Recasting the academic workforce: why\nthe attractiveness of the academic profession needs to be increased and eight\npossible strategies for how to go about this from an Australian perspective.\nHigher Education, 64(6), 875–889.\nCutler, T. (2008). Venturous Australia Report (pp. 1–36). Melbourne, Australia:\nCutler &amp; Company Pty Ltd.\nDepartment of Innovation, Industry, Science and Research (DIISR). (2009).\nPowering Ideas: An innovation agenda for the 21st century (pp. 1–76).\nCanberra ACT: Commonwealth of Australia.\nEdwards, D., &amp; Smith, T. F. (2009). Supply issues for science academics in\nAustralia: now and in the future. Higher Education, 60(1), 19–32.\nFahey, J., &amp; Kenway, J. (2010). Moving ideas and mobile researchers: Australia\nin the global context. The Australian Educational Researcher, 37(4), 103–114.\nFalagas, M. E., Karavasiou, A. I., &amp; Bliziotis, I. a. (2006). A bibliometric analysis\nof global trends of research productivity in tropical medicine. Acta tropica,\n99(2-3), 155–9. doi:10.1016/j.actatropica.2006.07.011\nGlandon, S., &amp; Glandon, T. (2001). Faculty turnover and salary compression in\nbusiness schools: Comparing teaching and research missions. Journal of\nApplied Business Research, 17(2), 33–40.\nGorman, M. F., &amp; Kanet, J. J. (2005). Evaluating Operations\nManagement?Related Journals via the Author Affiliation Index.\nManufacturing and Service Operations Management, 7(1), 3–19.\n\n1756\n\nHarrigan, M. (1997). An Analysis of Faculty Turnover at UW-Madison.\nAssociation of Insitutional Researchers of the Upper Midwest’s Annual\nMeeting (pp. 1–8).\nhttp://apir.wisc.edu/retirement/An_Analysis_of_Faculty_Turnover_at_UWMadison_1997.pdf\nHarzing, A.-W., &amp; Van der Wal, R. (2008). Google Scholar as a new source for\ncitation analysis. Ethics in Science and Environmental Politics, 8, 61–73.\nHugo, G. (2005). Demographic Trends in Australia’s Academic Workforce.\nJournal of Higher Education Policy and Management, 27(3), 327–343.\nHugo, G., &amp; Morriss, A. (2010). Investigating the ageing academic workforce:\nstocktake. Retrieved from\nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.177.2863&amp;rep=rep1\n&amp;type=pdf\nHumphreys, J. S., Jones, M. P., Jones, J. a, &amp; Mara, P. R. (2002). Workforce\nretention in rural and remote Australia: determining the factors that influence\nlength of practice. The Medical journal of Australia, 176(10), 472–6.\nJöns, H. (2007). Transnational mobility and the spaces of knowledge production:\na comparison of global patterns, motivations and collaborations in different\nacademic fields. Social Geography, 2(2), 97–114.\nKaminski, D., &amp; Geisler, C. (2012). Survival analysis of faculty retention in\nscience and engineering by gender. Science, 335(17 February), 864–866.\nMills, J., Birks, M., &amp; Hegney, D. (2010). The status of rural nursing in Australia:\n12 years on. Journal of the Royal College of Nursing Australia, 17(1), 30–37.\nMoore, T., Sutton, K., &amp; Maybery, D. (2010). Rural mental health workforce\ndifficulties: a management perspective. Rural and remote health, 10(3), 1519.\nMorano-Foadi, S. (2005). Scientific Mobility, Career Progression, and Excellence\nin the European Research Area. International Migration, 43(5), 133–162.\nNeuhaus, C., &amp; Daniel, H.-D. (2008). Data sources for performing citation\nanalysis: an overview. Journal of Documentation, 64(2), 193–210.\nORCID (2012). About us. Retrieved January 13, 2013, from\nhttp://about.orcid.org/\nPlunkett, M., &amp; Dyson, M. (2011). Becoming a Teacher and Staying One:\nExamining the Complex Ecologies Associated With Educating and Retaining\nNew Teachers in Rural Australia. Australian Journal of Teacher Education,\n36(1).\nReid, E. F., &amp; Chen, H. (2007). Mapping the contemporary terrorism research\ndomain. International Journal of Human-Computer Studies, 65(1), 42–56.\nRosmarakis, E. S., Vergidis, P. I., Soteriades, E. S., Paraschakis, K.,\nPapastamataki, P. a, &amp; Falagas, M. E. (2005). Estimates of global production\nin cardiovascular diseases research. International journal of cardiology,\n100(3), 443–9.\nSorensen, J. (1994). Scholarly productivity in criminal justice: Institutional\naffiliation of authors in the top ten criminal justice journals. Journal of\nCriminal Justice, 22(6), 535–547.\n1757\n\nThe Chartered Institute of Personnel and Development (CIPD). (2012). Employee\nturnover and retention. HR Factsheet. Retrieved November 21, 2012, from\nhttp://www.cipd.co.uk/hr-resources/factsheets/employee-turnoverretention.aspx\nUCEA Universities &amp; Colleges Employers Assocation. (2008). Recruitment and\nRetention of Staff in Higher Education 2008 (p. 20). Retrieved from\nhttp://www.universitiesuk.ac.uk/Publications/Documents/Recruitment_and_Re\ntention_2008.pdf\nYe, Q., Song, H., &amp; Li, T. (2012). Cross-institutional collaboration networks in\ntourism and hospitality research. Tourism Management Perspectives, 2-3, 55–\n64.\n\n1758\n\nTRENDS OF INTELLECTUAL AND COGNITIVE\nSTRUCTURES OF STEM CELL RESEARCH: A\nSTUDY OF BRAZILIAN SCIENTIFIC\nPUBLICATIONS\nRaymundo das Neves Machado 1 &amp; Jacqueline Leta 2\n1\n\nraymacha@ufba.br\nUniversidade Federal da Bahia (UFBA), Instituto de Ciência da Informação,\nDepartamento de Processos e Fundamentos da Informação, Rua Basílio da Gama, s/n –\nCampus Universitário do Canela (Brazil).\n2\n\njteta@biomet.ufrj.br\nUniversidade Federal do Rio de Janeiro (UFRJ), Instituto de Bioquímica, Programa de\nEducação, Gestão e Difusão em Biociências, Prédio do CCS, Bloco B - sala 39, Cidade\nUniversitária (Brazil).\n\nAbstract\n\nThe present work maps the intellectual and cognitive structures of Brazilian research on\nstem cell in the period 1991 - 2010. Using the technique of author co-citation, we found\nthat stem cell research in the country was marked by core authors from medical areas in\nthe first decade and gradually they were outnumbered by specialists in the field. The\ntechnique of co-word analysis indicates that Brazilian research on stem cell initially had a\nmore experimental and basic nature while, in more recent years, it also assumed an\napplied nature. This situation is accompanied by a notably increase in the number of\nBrazilian scientific publications and authors within this field. In the study period we also\nnoted a series of initiatives in Brazil to stimulate stem cell research in the country, which\nincreased the country’s worldwide recognition. Our results suggest that Brazilian research\non stem cell is in line with that in the context of global science.\n\nConference Topic\n\nVisualisation and Science Mapping: Tools, Methods and Applications (Topic 8)\n\nIntroduction\nDuring the last two decades, the number of Brazilian scientific publications\ncatalogued in the mainstream databases has increased notably (Regalado, 2010).\nThis has been a result of a combination of many internal and external factors,\nincluding the continuous investment of the public sector in qualifying human\nresources and improving infrastructure as well as the inclusion of dozens of new\nBrazilian titles in major scientific databases (Leta, 2011).\nThe Brazilian impressive growth in terms of scientific publications led the\ncountry to the 13th position in the world’s ranking. However, a careful look at this\ngrowth reveals that Brazilian’s main efforts are devoted to issues or research\n1759\n\nthemes of more international interest, especially in the fields of biomedicine,\nbiology, agriculture and physics (Glanzel et al, 2006; Leta, 2011). Countries with\nsuch performance can be included in the bioenvironmental model (REIST-2,\n1997), and, in the case of Brazil, this particular feature has historical roots related\nto the flourishing of science in the country.\nThe recent presence and success of Brazilian science in the fields of biology and\nbiomedicine can be observed by its participation, for instance, in large-scale\nprojects. Although Brazil did not take part as a member of the Human Genome\nProject consortium, the country has made some important contributions to this\n“big science” project not only by cloning genes of specific interest but mainly by\nheading the Human Cancer Genome Project. This project, sponsored by both the\nSao Paulo State Research Foundation (FAPESP) and the Ludwig Institute for\nCancer Research, had 29 laboratories engaged in sequencing more than one\nmillion of expressed sequence tags related to some human cancers (Kimura &amp;\nBaia, 2002). Evidence of Brazilian presence in global science arena has been\nhighlighted by one of the most prestigious scientific journals, Nature. In 2011,\nBrazilian biomedicine was featuring on its cover (Nature Medicine, 2011) and the\ncountry’s potentialities in some scientific fields, especially in some hot topics,\nincluding stem cell, were emphasized by the journal.\nStem cells are cells found in all multicellular organisms (including plants) with\nthe potential to divide and differentiate into other specialized cells as well as to\nself-renew (Maron-Gutierrez et al., 2009). The concept was proposed in the\nbeginning of 20th century but it took some decades before scientists could really\nmanipulate these cells. The year of 1981 was the landmark in the history of stem\ncell research: when scientists succeed in getting the first embryonic stem cells\nfrom a mammalian. From then on, knowledge on stem cell, especially on those\nrelated to mammalians, has been expanded at a quick pace due to its potential to\nbe used in human beings.\nThe first Brazilian studies on stem cell are dated from the late 1980 ́s, when the\ncountry’s first paper (Correa et al., 1987) was published. Brazil has been\npioneering in stem cell research in Latin America and has developed many\ninitiatives to stimulate collaborative projects in the area. As a result, the country is\namong the top five countries producing induced pluripotent stem cells. Among\nthe achievements is the approval of a federal regulation that determines norms for\nmanipulating and developing research on embryonic stem cell, in 2005 (Rehen &amp;\nPaulsen, 2007). The coordination of the largest stem cell clinical trial in the world\n(a 1,200-person study) (Nature Medicine, 2011) and the foundation of a Brazilian\nNetwork on Cell Therapy in 2008 (composed by 52 laboratories) are other\nexamples of the country recent efforts to develop competencies in this hot topic.\nIn this scenario, the interest and the potential uses of stem cell knowledge in\nglobal health have stimulated bibliometric studies to better understand the\ndynamics of its production through science communication. Ho et al. (2003)\nstudied the scientific performance of South Korea, Singapore, Hong Kong and\nTaiwan on stem cell from 1981 to 2001. Li et al. (2009) investigated the world’s\n1760\n\nscientific output on stem cell from 1991 to 2006, focusing on its main trends and\npatterns. Zhao &amp; Strotmann (2011a, 2011b) carried out a study based on author\nco-citation analysis to identify the intellectual structure of research on stem cell\npublished in the period of 2004 – 2009. An &amp; Wu (2011) applied the method of\nco-word analysis to analyze journal articles related to stem cell in the period\n2001-2010. Also, Cantos-Mateos et al. (2012) investigated the Spanish scientific\noutput in stem cell research published in the period 1997-2007.\nDrawing upon the results of these studies, we made the following questions: do\nintellectual and cognitive structures change in time for a given research field? Do\nintellectual and cognitive structures change among countries with different\ncultures for a given research field? Using the analyses of author co-citation and\nco-word, we present some preliminary data from Brazilian scientific publications\non stem cell. This pilot study is part of a larger project that aims mapping the\nmain intellectual and cognitive structures of stem cell studies in the last decades\nand in some countries, all emerging economies, with different cultures: Brazil,\nChina, India, South Africa and Russia.\nMethodology\nBrazilian publications on stem cell were retrieved on December 4th, 2012, directly\nfrom Web of Science (WoS) the ISI/Thomson Reuters’ on line database that is\navailable for most of Brazilian research institutions. 176\nCombining the terms “stem cell” or “stem cells” as main topic and “Brasil” or\n“Brazil” as address, a total of 1,607 Brazilian publications was found for the\nwhole period covered by WoS. Nevertheless, as the early 1991s may be taken as\nthe turning point for stem cell research, publications dated before 1991 were not\nconsidered in this study. All metadata available for the Brazilian publications (that\nis, publications with at least one Brazilian address) published from 1991 to 2010\nwere then selected and downloaded. In order to identify and map the intellectual\nand cognitive structures of Brazilian knowledge on stem cells, two main analyses\nwere processed: author co-citation analysis (ACA) (White &amp; Griffith, 1981) and\nco-word analysis (CWA) (Callon, 1991). According to the literature (ex.: Chen &amp;\nIbekwe-Sanjuan, 2010), ACA allows the identification of “intellectual structure of\na scientific knowledge domain in terms of the groupings formed by accumulated\ncocitation trails in scientific literature”. As for CWA analysis, it may help “to\nidentify the relationships between ideas within the subject areas presented in these\ntexts” (He, 1999, p. 134), to “analyze research trends and generate hypothesis and\ndiscover knowledge” (Jeong &amp; Kim, 2010, p. 242) and “it is a powerful technique\nfor discovering and describing the interactions between different fields in\nscientific research” (Muñoz-Leiva et al. 2011, online)\nThe co-word analysis was based on keywords listed in the publications.\nMisspelled words were corrected and synonyms were grouped into single terms.\nAfter this “cleaning” step, we analyzed the data on author co-citation and co176\n\nWoS can be accessed through: http://apps.webofknowledge.com/WOS_GeneralSearch_input.do?last_prod=\nWOS&amp;SID=1D6MpmmCDcbeemialnG&amp;product=WOS&amp;highlighted_tab=WOS&amp;search_mode=GeneralSearch\n1761\n\nwords, using Bibexcel software, version 2012-06-13, Microsoft Excel and\nVOSviewer, version 1.5.2.\nAs one of the goals of this study was to investigate time changes in cognitive and\nintellectual structure, all analyses were processed in 5-year periods, 1991-1995,\n1996-2000, 2001-2005 and 2006-2010. As our main goal was to identify and map\nthe pairs of co-occurrences, we opted to carry on a descriptive analysis for both\nACA and CWA, instead of carrying a multivariate analysis, which is more\nfrequent in co-occurrence studies.\nTable 1. Characteristics of Brazilian publications on stem cell in each period.\nCharacteristic\n\n1991-1995\n37\n\nPublications (a)\nOnly Articles\n33\n(b)\nAuthors (c)\n132\nCited\n1,090\nReferences (d)\nb/a\n0.89\nc/a\n2.86\nc/b\n3.21\nd/b\n33.03\nMain Research Plant\nSciences\nAreas*\n(7)\nNeurosciences &amp;\nNeurology (5)\nLife Sciences &amp;\nBiomedicine\nOther Topics (4)\nResearch\n&amp;\nExperimental\nMedicine (3)\nImmunology (3)\n\n5-year Period\n1996-2000\n2001-2005\n106\n326\n\n2006-2010\n1,138\n\n83\n\n226\n\n772\n\n474\n\n1,466\n\n5,313\n\n2,812\n\n7,625\n\n30,021\n\n0.78\n0.69\n0.68\n4.47\n4.50\n4.67\n5.71\n6.48\n6.88\n38.88\n33.74\n38.89\nHematology\nHematology\nCell\nBiology\n(15)\n(40)\n(102)\nBiochemistry &amp; Research\n&amp; Hematology (88)\nMolecular\nExperimental\nResearch\n&amp;\nBiology (12)\n(26)\nExperimental\nPlant Sciences Medicine (26) Medicine (83)\n(11)\nOncology (26) Neurosciences &amp;\nVeterinary\nImmunology\nNeurology (68)\nSciences (10)\n(24)\nTransplantation\nNeurosciences\n(60)\n&amp; Neurology\n(10)\nMain research areas refer to the WoS classification. Details are found at WoS homepage\n(see note 1). The number of articles for each main research area is shown in parenthesis.\n\nResults\nFor an overview of Brazilian publications in each of the 5-year period, a brief\ndescriptive analysis based on bibliometric variables is presented in Table 1.\nBrazilian research on stem cell has grown substantially since the 1991s, which\ncan be observed both by the total number of publications and by the number of\nauthors in the byline of the articles. Concerning the number of total publications\n(including all original articles, meeting abstracts, reviews, proceedings paper,\nletters and editorial materials), a larger increase than that observed for original\n1762\n\narticles was found. However, the ratio author per publication had a lower increase\nthan that observed for author per article, suggesting that a larger number of\nBrazilian researchers may be involved in producing new knowledge on stem cell.\nConsidering the research areas, a shift is noted along the four periods studied.\nNevertheless, some areas tend to be more frequent among the top five listed in\nTable 1, as follows: Hematology, Cell Biology, Research &amp; Experimental\nMedicine, Neurosciences &amp; Neurology and Immunology. This trend is in\naccordance to the results shown by Li et al. (2009), who analyzed the global\npublication on stem cell, from 1991 to 2006. After classifying publications in 167\nmain fields, the authors found that Hematology, Cell Biology and Immunology\nwere ranked among the top five in terms of number of publications. In the\nauthors’ words “at the outset of the 21st century, increasing attention was paid to\nthe field of cell biology, while the number of stem cell related articles in cell\nbiology went beyond the oncology for the first time in the year of 2006” (Li et al.,\n2009, p. 45). In a more recent study, Cantos-Mateos et al. (2012) have also\nidentified Hematology as one of the main fields among Spanish scientific\npublications on stem cell.\nThe author co-citation analysis\nThe most cited authors in Brazilian publications on stem cells are listed in Table\n2. Although some of the most cited names appear in more than one period (as it is\ncase of G Paxinos and EC Perini), we can note that the list of most cited authors\nvaries considerably in each period.\nTable 2. The most cited authors in Brazilian publications on stem cell in each period.\n1991-1995\nAmendt K\nFeldberg W\nGuertzen PG\nJames EK\nPaxinos G\n\n5-year Period\n1996-2000\n2001-2005\nAkin DE\nPaxinos G\nWilson JR\nLjungman P\nGluckman\nE Charbord P\nJohansen\nDA Dexter TM\nMetcalfe CR\nGlucksbe H\nPaxinos G\nPerin EC\nVansoest PJ\nStrauer BE\n\n2006-2010\nPittenger MF\nZuk PA\nOrlic D\nJohansen DA\nPerin EC\nGronthos\nDominici M\nCaplan AI\n\nS\n\nIt is noteworthy mentioning that this analysis considered the first author only.\nThis is in accordance to Zhao &amp; Strotmann (2001, p. 674) statement about the\nmeasures of first author in ACA “First-author counting tends to identify\nresearchers who have conducted highly influential studies and emphasize a\nresearcher’s unique areas of study and most influential contributions”.\nThe set of most cited authors constituted the main sources of ACA. For this\nreason, some of the most cited authors do also appear among the co-cited authors\n(Table 3), suggesting a positive relationship between higher number of citations\n1763\n\nand co-citation. The set of most cited authors constituted the main sources of\nACA. For this reason, some of the most cited authors do also appear among the\nco-cited authors (Table 3), suggesting a positive relationship between higher\nnumber of citations and co-citation.\nTable 3 lists the pairs of co-cited authors with the highest frequency of co-citation\nin each period as well as the respective research areas where they have published,\naccording to WoS classification. In the 1991-1995 period, the co-cited authors\npublished in journals classified, for instance, in Neurosciences &amp; Neurology, the\narea with the second highest number of publications in the period (position\nrankings appear in the parenthesis). In the period 1996-2000, the pair Akin and\nWilson, for instance, has published in journals classified in Agriculture, the eighth\narea in terms of number of publications in this period. By the second period on,\nwe note that research areas spread, which may be an evidence of the extension of\nstem cell research to other fields.\nTable 3: Co-cited authors and their respective research areas in Brazilian\npublications on stem cell in each period.\n5-year Period\nAuthor 1\n1991-1995\nFeldberg W\nAmendt K\nAmendt K\n\nResearch Áreas\nNeurosciences &amp; Neurology (2nd);\nLife Sciences &amp; Biomedicine Other Topics (3rd); Research &amp;\nExperimental Medicine (4th)\n1996-2000\nAkin DE\nWilson JR\nVeterinary Sciences (4th);\nAgriculture (8th)\nJohansen D\nMetcalfe CR\nPlant Sciences (3rd); Veterinary\nSciences (4th); Life Sciences &amp;\nBiomedicine - Other Topics (7th);\nAgriculture (8th)\n2001-2005\nPerin EC\nStrauer BE\nCardiovascular System &amp;\nCardiology (17th);\nPathology (16th)\n2006-2010\nOrlic D\nPerin EC\nCell Biology (1st); Research &amp;\nExperimental Medicine (3rd);\nTransplantation (5th);\nPharmacology &amp; Pharmacy (6th);\nCardiovascular System &amp;\nCardiology (18th)\nGronthos S\nZuk PA\nCell Biology (1st); Hematology\n(2nd); Immunology (7th) ;\nOncology (8th); Surgery (10th);\nBiotechnology &amp; Applied\nMicrobiology (12th); Veterinary\nSciences (16th)\nResearch areas refer to the WoS classification. Details are found at WoS homepage (see\nnote 1). The number of articles for each main research area is shown in parenthesis\n\n1764\n\nAuthor 2\nGuertzen PG\nGuertzen PG\nFeldberg W\n\nAnother relevant feature is the symmetric between the pairs of co-cited authors\nand the research areas. In the first period, the distribution of pairs and research\nareas indicates strong symmetry, i.e., there is a strong similarity between authors\nand research areas. This analysis shows three co-cited authors forming three\npairs: (a) Feldberg and Guertzen, (b) Amendt and Guertzen and (c) Amendt and\nFeldberg. It is worth noting that the German Wilhelm Feldberg and the Brazilian\nPedro Gaspar Guertzen were productive and widely known in the field of\nphysiology; Amendt, also German, was an specialist in the field of cardiovascular\nresearch. Such trends explain the strong presence of the medical field in this\nperiod.\nAs for the second period, we found two pairs of authors highly co-cited: (a) Akin\nand Wilson and (b) Johansen and Metcalfe. Worth mentioning is that Danny E.\nAkin is a researcher at the Department of Agriculture, in the USA Agricultural\nResearch Service; and Metcalfe is an specialist in the field of Botanics. For the\nthird period, only one pair, Perin and Strauber, was high co-cited. Here, it is\nimportant to highlight that Strauber, a visiting professor at University of Rostock,\nin German, is one of the pioneers in the field of cardiac stem cell therapy. He is\nthe author with both the highest frequency of co-citation and the highest density\nin Medicine, Transplantation and Cardiovascular System &amp; Cardiology.In the\nfourth period of analysis, two pairs, (a) Orlic and Perin and (b) Zuk and Gronthos\nwere the most co-cited authors. At least two of these authors are affiliated to a\nresearch institute devoted to the investigation of stem cell. Emerson C. Perin is\nthe director of the Stem Cell Center at the Texas Heart Institute, in the US; Stan\nGronthos, the co-director of the Centre for Stem Cell Research, Robinson\nInstitute, at University of Adelaide, in Australia, who has patented a cell isolation\ntechnique to be used in stem cell preparations. Donald Orlic coordinates research\nprojects in pluripotent hematopoietic stem cell, at the Hematopoiesis Section,\nfrom Genetics and Molecular Biology Branch, of the National Human Genome\nResearch Institute/NIH.\nFigure 1 shows the density of authors co-cited in Brazilian papers on stem cell,\naccording to Van Eck &amp; Waltman (2010). Authors shown in Figure 1 are also\nthose with the highest levels of co-citation. As for the period 1991-1995, this set\nof authors shows the same level of density (as we may see by the size of the\nnodes), indicating that this network structure is well delineated. For the following\nperiods, we note that authors differ in terms of density and that different clusters\nare formed, just as mentioned previously (Table 3).\nTime trends for ACA suggest important changes in the intellectual structure of\nBrazilian publications on stem cell, mainly from the 2001-2005 period, when\nBrazilian research in this area seemed to take a new route, inspired by some key\ninternational specialists on stem cell.\n\n1765\n\nSize of the nodes indicates the density of co-cited authors.\nFigure 1: Author co-citation maps from Brazilian publications on stem cell in each\nperiod.\n\nCo-word analysis\nIn order to map thematic trends in the field of stem cell, we carried out a co-word\nanalysis (CWA) from keywords, as they “are the last link in the chain, used to\nshed light on the cognitive structure of a field [...]” (Cantos-Mateos et al., 2012,\np. 567). Along the four study periods, the number of keywords increased\nremarkably: from 191, in 1991-1995, to 3,246, in 2006-2010. As for the pairs of\nkeywords, we observe another strong increase: from 4, in 1991-1995, to 29, in\n2005-2010. In fact, a closer look at the data reveals that the share of keywords\nwith frequency decreased, while the share of keywords with frequency higher\nthan one increased (Table 4). This is an indicative that, over the periods, new\nterms were incorporated into stem cells’ corpus of knowledge and constituted\n“hot keywords” for the field.\nTable 4. Distribution of keywords’ frequency of Brazilian publications on stem cell\nin each period.\n5-year Period\n1991-1995\n(%)\n1996-2000\n(%)\n2001-2005\n(%)\n2006-2010\n(%)\n\n1766\n\n1\n174\n(91.10)\n379\n(85.55)\n975\n(81.05)\n2,420\n(74.55)\n\nFrequency of Keywords (with no duplication)\n2\n3\n4-6\n7-9\n≥10\n12\n4\n1\n(6.28)\n(2.09)\n(0.52)\n43\n10\n10\n1\n(9.71)\n(2.26)\n(2.26)\n(0.23)\n134\n33\n40\n11\n10\n(11.14)\n(2.74)\n(3.33)\n(0.91)\n(0.83)\n433\n144\n143\n37\n72\n(13.34)\n(4.44)\n(4.41)\n(1.14)\n(2.22)\n\nTotal\n191\n(100)\n443\n(100)\n1,203\n(100)\n3,246\n(100)\n\nFigure 2 illustrates three examples of keywords, whose frequencies increased\nduring the four periods: bone-marrow, differentiation and transplantation. We\nnote the same trend for these examples: keywords’ frequencies were very low\nduring the first two periods; in the following two periods, their frequencies\nincreased n-fold and they became “hot keywords”.\n\nFrequency\n\n80\n70\n\nBone_marrow\n\n60\n\nDifferentiation\nTransplantation\n\n50\n40\n30\n20\n10\n0\n\n1991-1995\n\n1996-2000\n\n2001-2005\n\n2006-2010\n\n5-year Period\nFigure 2: Time trends of three keywords extracted from Brazilian publications on\nstem cell in each period.\n\nHence, we can infer that these terms emerged in the beginning of 1991’s and were\nnot the focus of Brazilian research on stem cell at that time. In the last years,\nhowever, this picture changed and these terms (thematic) are now prominent.\nTable 5 lists the keywords with highest frequency (in parenthesis) as well as the\nkeywords with the highest number of co-occurrences. It is easy to note that some\nkeywords appear with high frequencies in more than one period, especially after\nthe third one. Worth mentioning is that this period is marked by the approval of a\nBrazilian regulation establishing rules for manipulating and developing research\non embryonic stem cell. Also in this period, Brazil became one of the pioneers in\nusing adult stem cells to treat some heart diseases and in establishing a novel\nprocedure, a transplant of bone marrow cells in patients with heart failure due to\nChagas’ disease (Mendonça, online, p. 33).\nFrom the third period on, two keywords call our attention: differentiation and\ntransplantation. They are on the basis of stem cell research. Differentiation is the\nprocess by which any cell (not specialized) becomes specialized; a basic\ncharacteristic of stem cells. On the other hand, transplantation is an application of\nstem cells. Another key term is bone marrow, which co-occurs with terms as invitro, expression, transplantation, progenitor cells and differentiation. Together,\nthese terms not only point to the basic aspects of stem cell research but also\nunderline its applied feature, which is clearly noted in the more recent periods.\n1767\n\nTable 5: List of keywords with higher frequencies and with higher number of cooccurrences from Brazilian publications on stem cell in each period.\n5-year\nPeriod\n1991-1995\n\nKeywords selected for CWA\n\nKeywords with higher number\nof co-occurrences\nBlood-pressure\nBrain-stem\nRat\n\nBrain-stem (4)\nBlood-pressure (3)\nHematopoietic stem-cells (3)\nRat (3)\nStem-cells (3)\n1996-2000 Stem-cells (7)\nStem-cells\nBone-marrow (6)\nBone-marrow\nCells (5)\nColony-stimulating factor\nColony-stimulating factor (5)\nProgenitor cells\nExpression (5)\nProgenitor cells (5)\n2001-2005 Stem-cells (24)\nDifferentiation\nIn-vitro (20)\nDisease\nExpression (19)\nExpression\nBrain-stem (16)\nIn-vitro\nDifferentiation (14)\nStem-cells\nStem-cell transplantation (14)\nTransplantation\nDisease (11)\nBone-marrow\nBone-marrow-transplantation (11)\nBone-marrow-transplantation\nTransplantation (11)\nStem-cell transplantation\nBone-marrow (11)\n2006-2010 Stem-cells (105)\nProgenitor cells\nIn-vitro (90)\nBone-marrow\nDifferentiation (76)\nDifferentiation\nProgenitor cells (72)\nIn-vitro\nExpression (64)\nStem-cells\nTransplantation (63)\nTransplantation\nBone-marrow-transplantation (60)\nExpression\nBone-marrow (52)\nNote: Numbers in parenthesis represent the frequency of each keyword in the respective\nperiod.\n\nFigure 3 presents the map of keywords with the highest frequencies of density,\nindicating the time trends for themes in Brazilian publication on stem cell. The\nmaps show that the number of keyword pairs increased from the first to the last\nperiod. Some of the keywords appeared in more the one period, while others\ndisappeared or grew in importance in the field (larger nodes). In other words,\nsome themes were giving way to others. In this cognitive movement, stem cell\nresearch starts with a more experimental and basic scope, which turns gradually\ninto applied.\n\n1768\n\n(Size of the nodes indicates the density of co-words).\nFigure 3: Keyword maps from Brazilian publications on stem cell in each period.\n\nSome Remarks and Conclusion\nUsing the techniques of author co-citations and co-words, we examined Brazilian\noutput on stem cell research over time. Our main goal was to map time trends of\nintellectual and cognitive structures of stem cell research in Brazil. Despite their\npotential use, it is worth highlighting that both ACA and WCA generate data that\nare proxies, and not the reality, of the dynamics of scientific work. Also important\nis the fact the methodological choices we have opted (for instance: a single\ninformational source and a search strategy focused in a few number of keywords)\ndetermined the set of studied publications.\nDespite these limitations, we believe that the collection of data presented in this\npaper provide a striking picture of how stem cell research has been carried on in\nBrazil. In this pilot study, we did not applied techniques of multivariate analyses,\nas one would expect. Instead, we opted to focus in co-citation frequency analyses\nand bibliometric maps. Hence, using descriptive analyses, we found that the onset\nof stem cell research in the country had a strong base of authors from medical\nareas. But, along the periods, these authors were outnumbered by experts in the\nfield. It was also possible to identify that Brazilian research initially had a more\nexperimental and basic nature, which gradually assumed an applied nature. This\nsituation is accompanied by a notably increase in the number of Brazilian\nscientific publications and authors within this field.\nOur results suggest that Brazil, an emerging country with no established scientific\ntradition, may already have the key ingredients to become an important player in\nstem cell research and develop a prominent role in global science at large.\nResearch on stem cell is very challenging, especially for its many potential\napplications to the healing of many human illnesses. This aspect justifies the huge\nrush for new knowledge and new procedures in this field, which has involved an\n1769\n\n“army” of researchers around the world and from different specialties. Therefore,\nstudying the dynamics of author co-citations and co-words in this field may help\nto better understand how the intellectual and cognitive structure of a promising\nand highly dynamics field behaves. Hence, the next step of our work includes a\ncomparative analysis between Brazil and other emerging countries.\nAcknowledgments\nWe are grateful to CNPq (Conselho Nacional de Desenvolvimento Científico e\nTecnológico) for financial support and to Sonia Maria Ramos Vasconcelos (IBqM\n– UFRJ) for comments and review of the manuscript.\nReferences\nAn, X.Y. &amp; Wu, Q.Q. (2011). Co-word analysis of the trends in stem cells field\nbased on subject heading weighting. Scientometrics, 88, 133–144.\nNature Medicine (2011). Biomedicine in Brazil. Nature Medicine, 11(10), 1169.\nCantos-Mateos, G. et al. (2012). Stem cell research: bibliometric analysis of main\nresearch areas through KeyWords Plus. Aslib Proceedings: New Information\nPerspectives, 64 (6), 561-590.\nCallon, M. et al. (1991). Co-word analysis as a tool for describing the network of\ninteractions between basic and technological research—the case of polymer\nchemistry. Scientometrics, 22(1), 155–205.\nChen, C. &amp; Ibekwe-Sanjuan, F. (2010). The structure and dynamics of cocitation\nclusters: a multiple-perspective cocitation analysis. Journal of the American\nSociety for Information Science and Technology, 61(7):1381409.\nCorrea, J.B.C. (1987). Ester-type lignin-xylan linkages in the cell-wall of stems of\nmimosa-scabrella. Anais da Academia Brasileira de Ciências. 59(5), 179-184.\nGlänzel, W. et al. (2006). Science in Brazil. Part 1: a macro-level comparative\nstudy. Scientometrics, 67(1), 67–86.\nHo, Y. S. et al. (2003). Assessing stem cell research productivity. Scientometrics,\n57(3), 369-376.\nJeong, S. &amp; Kim, H-G. (2010). Intellectual structure of biomedical informatics\nreflectedin scholarly events. Scientometrics, 85, 541–551\nKmura, E.T. &amp; Baia, G.S. (2002). Rede ONSA e o Projeto Genoma Humano do\nCâncer: Contribuição ao Genoma Humano. Arq Bras Endocrinol Metab,\n46(4), p. 325-329.\nLeta, J. (2011). Growth of Brazilian Science: a real internalization or a matter of\ndatabases ́ coverage?. In: 13th International Conference of the International\nSociety for Scientometrics and Informetrics, 2011, Durban, Africa do Sul.\nProceedings of the ISSI 2011 Conference. Leiden, Zululand: Leiden Univ &amp;\nZululand Univ, v. 1. p. 392-397.\nLi, Ling-Li . et al. (2009). Global stem cell research trend: Bibliometric analysis\nas a tool for mapping of trends from 1991 to 2006. Scientometrics, 80 (1), 41–\n60.\n\n1770\n\nMaron-Gutierrez, T. et al. (2009). Terapia com células-tronco na síndrome do\ndesconforto respiratório agudo. Rev. bras. ter. intensiva, 21(1), 51-57.\nMendonça. V. L. Possibilidades de utilização de células-tronco humanas e os\nobstáculos a serem vencidos para viabilizar seu uso em terapia. Available:\nhttp://genoma.ib.usp.br/educacao/A_USP_vai_a_sua_Escola_parte4.pdf.\nAcesso em: 11 jan. 2013.\nMuñoz-Leiva, F. et al. (2011). An application of co-word analysis and\nbibliometric maps for detecting the most highlighting themes in the consumer\nbehaviour research from a longitudinal perspective. Qual Quant, Available:\nhttp://sci2s.ugr.es/publications/ficheros/QuQu.pdf., Acesso: 5 jan. 2013.\nRegalado, A. (2010). Brazilian Science: Riding a Gusher. Science, 330 (6009),\n1306-12.\nRehen, S. &amp; Paulsen, B. (2007). Células-tronco: o que são? Para que servem? Rio\nde Janeiro: Vieira &amp; Lente.\nREIST-2. (1997). The European Report on Science and Technology Indicators\n1997.EUR 17639. Brussels: European Commission.\nVan Eck, N.J. &amp; Waltman, L. (2009). How to normalize cooccurrence data? an\nanalysis of some well-known similarity measures. Journal of the American\nSociety for Information Science and Technology, 60(8) , 1635–1651.\nVan Eck, N.J. &amp; Waltman, L. (2010). Software survey: VOSviewer, a computer\nprogram for bibliometric mapping. Scientometrics, 84(2), 523–538.\nZhao, D. &amp; Strotmann, A. (2011). Intellectual structure of stem cell research: a\ncomprehensive author co-citation analysis of a highly collaborative and\nmultidisciplinary field. Scientometrics, 87, 115–131.\nZhao, D. &amp; Strotmann, A. (2001). Counting first, last, or all authors in citation\nanalysis: a comprehensive comparison in the highly collaborative stem cell\nresearch field. Journal of the American Society forr Information Science and\nTechnology, 62(4), 654–676.\nWhite, H.D. &amp; Griffith, B.C. (1982). Authors as markers of intellectual space:\nCo-citation in studies of science, technology and society. Journal of\nDocumentation, 38( 4), 255–272.\n\n1771\n\nUSE OF ELECTRONIC JOURNALS IN\nUNIVERSITY LIBRARIES: AN ANALYSIS OF\nOBSOLESCENCE REGARDING CITATIONS AND\nACCESS\nChizuko Takei1, Fuyuki Yoshikane2 and Hiroshi Itsumura3\n1\n\nnaoe.chizuko@ynu.ac.jp\nUniversity of Tsukuba, Graduate School of Library, Information and Media Studies, 1-2\nKasuga, Tsukuba, Ibaraki (Japan)\n2\n\nfuyuki@slis.tsukuba.ac.jp, 3hits@slis.tsukuba.ac.jp\nUniversity of Tsukuba, Faculty of Library, Information and Media Science, 1-2 Kasuga,\nTsukuba, Ibaraki (Japan)\n\nAbstract\n\nThis research analyzes the obsolescence of citations and access with respect to a broad\nrange of subjects, including fields that have not been dealt with in previous research,\nshedding light on the differences between these two types of obsolescence and the\ncharacteristics for each field. The targets of analysis were 473 journals that were randomly\nsampled from all of Springer’s 11 subject fields. Using metrics such as Cited Half-life and\nDownload Half-life, the study investigated the relationship concerning the rate of\nobsolescence for citations and access. As a result, comparatively strong and significant\ncorrelations were seen in “Chemistry and Materials Science” and “Engineering” with\nrespect to long term obsolescence, and “Biomedical and Life Sciences” with respect to\nshort term obsolescence (p &lt; 0.05).\n\nConference Topic\n\nManagement and Measurement of Bibliometric Data within Scientific Organizations\n(Topic 9) and Bibliometrics in Library and Information Science (Topic 10).\n\nIntroduction\nSince the early 2000s, package-type contracts for electronic journals, the so-called\nBig Deal, have been rapidly adopted among university libraries in Japan.\nIrrespective of the university’s size, the Big Deal drastically increased the number\nof journal titles that could be accessed at contract universities. It also played a part\nin bridging the digital divide between universities and in promoting the\ndevelopment of information infrastructures there. However, future prices and\naccess to the Big Deal depend on historic expenditures of an institution as well as\ncurrent cancellations. With on-going budget cuts and increasing prices of journals,\nprice hikes for the Big Deal are putting pressure on library budgets. This situation\nmakes it difficult for libraries not only to maintain existing subscriptions, but also\nto subscribe to new journals. As withdrawal from the Big Deal results in a\n1772\n\ndramatic decrease in the number of titles that can be used, and in turn, a collapse\nof the library’s academic information framework, the building collections of\njournal backfiles that, in some way, alleviate the impact of these losses is a matter\nof urgency.\nThe development collection of journal backfiles differs from that of current files,\nwhich have a strong tendency to become fixed owing to budgetary considerations.\nThis is because many universities have library staff introduce journal backfiles by\nutilizing sources such as special proposals received from publishers just before\nthe accounting period to make decisions and proposals. However, few universities\nin Japan have sought to implement a planned introduction of journal backfiles by\nscrutinizing the level of on-campus demand and the effectiveness of such an\nintroduction. Instead, universities have a strong tendency to select and purchase it\nwithin the limits of the amount left in the budget.\nPrevious research has been conducted on effective methods for introducing\nelectronic journals largely focused on the new introduction of current files, such\nas the identification of core journals or the rate at which they can be supplied.\nHowever, there has been very little research on the effective development of\njournal backfiles. Investigations into the development of journal backfiles require\nperspectives focusing on the documents that fall into disuse, i.e., obsolescence.\nObsolescence in books is investigated on the basis of the number of times a book\nis used by lending year or accession year. In the case of journals, on the other\nhand, their obsolescence is based on citations and access of materials.\nUnderstanding the relationship between both types of obsolescence will make it\npossible to estimate the obsolescence of access based on information about the\nobsolescence of citations. Correspondence between both has already been\nexamined for certain fields, such as chemistry, and for specific journals. However,\nthe nature of documental use (citations and access) varies by field, and it is\npossible that trends in the differences between both also differ by field. Thus, this\nresearch employs several indices of obsolescence, some of which have not been\nadopted in previous studies, and analyzes obsolescence in access and citations for\na wide range of subjects, including fields that have not been examined in previous\nstudies. We shed light on the differences between both types of obsolescence and\ntheir characteristics in each field.\nRelated Research\nTo evaluate journal collections, many studies have been conducted on the\nrelationship between citations and downloads (access). For instance, Duy and\nVaughan (2006) analyzed local citation data and Impact Factor (IF) with journal\nusage in the fields of chemistry and biochemistry. For the former case good\ncorrelations were seen, whereas no significant correlation was observed between\nIF and journal usage. Further examples can be found in McDonald (2007), Bollen\nand Van de Sompel (2008), or Watson (2009). In particular, there are several\n1773\n\nstudies on obsolescence in access and citation of electronic journals. Nicholas et\nal. (2005) surveyed synchronous obsolescence of access. They reveal that over\nhalf of all use was accounted for by items published within the last 15 months.\nMoreover, some studies have analyzed the relationship between citations and\naccess by calculating the density of citations and that of access and then\ncomparing both (e.g., Moed, 2005; Kurtz et al., 2005; Brody et al., 2006; Chu &amp;\nKrichel, 2007).\nIn recent years, Schloegl and Gorraiz (2010; 2011) have performed more\nmultifaceted studies related to oncology and pharmacology by using such indices\nas IF, Immediacy Index (II), and Cited Half-life (CHL). While in the case of\noncology journals, their results showed that the mean of Usage half-life is 1.7\nyears, and CHL is 5.6 years in 2006, similar results were found in the case of\npharmacology journals. Furthermore, they computed that so-called “download\ncitation half-life ratio” and found a medium sized correlation between CHL and\nUsage half-life in pharmacology (r = 0.42). Wan et al. (2010) examined the\nrelationship between Download Immediacy Index (DII) and citation indicators\nusing the Chinese full-text database CNKI. They found DII has a potential to be a\npredictor for other indices such as h-index. While a moderate correlation between\nDII and II was observed in the field of agriculture and forestry (r = 0.57), in the\ncase of psychology a strong correlation was found (r = 0.8). However, these\nanalyses have only been performed on selected fields and journals, such as\norganic chemistry, astronomy, and astrophysics.\nMethodology\nThe survey employed in this research focuses on Yokohama National University\n(YNU), Japan. YNU consists of four undergraduate colleges (College of\nEducation and Human Sciences, College of Economics, College of Business\nAdministration, and College of Engineering Science) and five graduate schools\n(Graduate School of Education, Graduate School of International Social Sciences,\nGraduate School of Engineering, Graduate School of Environment and\nInformation Sciences, and Graduate School of Urban Innovation). The\nuniversity’s membership comprises around 600 full-time teaching staff, around\n10,000 students (around 2,600 graduate and 7,500 undergraduate students), and\n300 full-time non-teaching staff. It is a medium-sized national university that does\nnot have a medical school in Japan.\nThis research employed Springer’s usage data from January 2010 to August 2012.\nSpringer is one of the publishers with whom YNU has the Big Deal subscription\nand provides statistics on the use of full texts by publication year (COUNTER\nJournal Report 5). We randomly sampled 473 journals from each of the 11 subject\nfields covered by Springer. The procedure of sampling is as follows.\n\n1774\n\nWe identified a total of 1,492 titles, excluding journals whose full text had never\nbeen accessed in YNU from the 2,912 titles available for the two years and eight\nmonths from January 2010 to August 2012. These titles were arranged in\ndescending order of access count for each field. Springer’s COUNTER Journal\nReport 5 defines the number of downloads, the number of times used, or the\nnumber of times accessed as the number of times the full text of an article is used.\nAs with many studies, we employ this definition, and refer it here as access count.\nIn order to survey the degree to which the scale of access count influences its\nobsolescence, these titles were then separated into three layers according to the\ncumulative ratio of access count in the field, considering that the cover ratio of the\naccess count is often used to examine target subscriptions to electronic journals in\nJapan. 15 journals were randomly sampled from each of the layers; for layers with\nfewer than 15 journals, the total number of journals was taken to be the target of\nresearch. Table 1 shows all subscription journals by field. Here, journals whose\ndata could not be obtained from Journal Citation Reports (JCR) and those with an\naccess count of 0 were excluded. Among these, 473 titles became the targets of\nresearch for this survey (the number of titles: 32 (BS) + 45 (BL) + 40 (BE) + 45\n(CM) + 45 (CS) + 45 (EE) + 41 (EG) + 45 (HS) + 45 (MS) + 45 (MD) + 45 (PA)\n= 473).\nTable 1. Number of titles for each layer of cumulative ratio of access count in each\nfield.\nSubject of Springer\nBehavioral Science (BS)\nBiomedical and Life Sciences (BL)\nBusiness and Economics (BE)\nChemistry and Materials Science\n(CM)\nComputer Science (CS)\nEarth and Environmental Science\n(EE)\nEngineering (EG)\nHumanities, Social Sciences and Law\n(HS)\nMathematics and Statistics (MS)\nMedicine (MD)\nPhysics and Astronomy (PA)\nWhole\n\n0%–\nless 70%\n7\n31\n22\n\n70%–\nless 90%\n12\n56\n10\n\n90%–\n100%\n13\n123\n20\n\nWhole\n\n28\n\n37\n\n68\n\n133\n\n16\n\n18\n\n30\n\n64\n\n22\n\n30\n\n55\n\n107\n\n11\n\n22\n\n26\n\n59\n\n18\n\n19\n\n17\n\n54\n\n22\n40\n22\n239\n\n31\n47\n23\n305\n\n44\n51\n35\n482\n\n97\n138\n80\n1,026\n\n32\n210\n52\n\nIn addition, the research was performed on the basis of the following hypotheses:\nHypothesis 1: Obsolescence is slow in fields such as humanities and\nmathematics for both citations and access, but is fast in fields such as\nphysics and medicine.\n1775\n\nHypothesis 2: Indices that demonstrate a strong correlation differ by field.\nIn order to verify the above hypotheses, the situation in each field was examined\nusing the following indices as measures of obsolescence:\n(1) Obsolescence of citations:\n(1A) CHL, (1B) II/IF (ratio between II and IF)\n(2) Obsolescence of access:\n(2A) DHL, (2B) DII/DIF (ratio between DII and DIF)\nEach of these indices represents values as of 2011. Data for CHL, II, and IF were\nobtained from JCR. DHL refers to Download Half-life and was calculated in the\nsame way as CHL. It signifies that “the number of journal publication years from\nthe current year going back whose articles have accounted for 50% of the total\ndownloads (access) received in a given year.” DII and DIF correspondingly apply\nthe definitions of II and IF to access and signify the access count generated during\nthe period for calculating the corresponding index (DII as well as II: 2011; DIF as\nwell as IF: 2009–2010). Note that these are used with the addition of one so as to\navoid the division by zero. Because Springer’s statistics contained sections in\nwhich access count for multiple publication years had been calculated together,\nthis research employed access count divided by the number of years in the section\nas the access count for each year.\nCHL and DHL express slower obsolescence as values become higher, whereas\nII/IF and DII/DIF express faster obsolescence as values become higher. In\naddition, while CHL and DHL are the indices of obsolescence of use that take\ninto consideration long periods of time, II/IF and DII/DIF are indices that focus in\nparticular on the change in usage during several years after publication. DII/DIF,\nthe ratio between DII and DIF, has not been used until now in obsolescence\nanalysis. However, given that use of journals is generally concentrated at the time\ndirectly after publication, it seems that DII/DIF would also prove useful as an\nindex representing the characteristics of the nature of documental use. Therefore,\nit was used in combination with II/IF in this research. The survey examined the\ndegree of accordance—that is to say, correlation—of obsolescence between\ncitations and access for each field with respect to the long term (CHL and DHL)\nand the short term (II/IF and DII/DIF).\nIf the characteristics of each field are revealed like Hypothesis 1, it also becomes\nclear that the main target to develop journal backfiles is the field whose\nobsolescence is slow. In addition, if good correlations are found between the\nindices of citations and access in some fields by examining Hypothesis 2, the\ninformation of CHL or II/IF is enough to determine the strategy to collect journal\nbackfiles for those fields. That is, it suggests the predictability of the use of\njournal backfiles by the information before introducing them in those fields. On\n1776\n\nthe other hand, as for the fields where no correlation is found between the two\ntypes of indices, we should take into consideration both types of indices to collect\njournal backfiles.\n\nFigure 1. DHL by field.\n\nFigure 2. DHL by field and layer of cumulative ratio of access count.\n\n1777\n\nResults and Discussion\nGeneral Situation regarding the Obsolescence of Access\nFig. 1 calculates the DHL of journals that were the target of analysis and sets out\nthe resulting median values for each field. “Mathematics and Statistics” (12.14),\n“Behavioral Science” (10.00), and “Humanities, Social Sciences and Law” (7.50)\nare long, whereas “Computer Science” (3.33) is short. More detailed results are\nshown in Fig. 2, in which DHL values are calculated for each layer of the\ncumulative ratio of access count in each field. Whereas DHL values do not vary\nwidely among the layers in the fields whose obsolescence is slow, the values tend\nto vary in the fields whose obsolescence is fast. DHL values show that the layer\nwith the lowest access count (over 90%) tends to be shorter than other layers in\nthe latter fields.\nGeneral Situation regarding the Obsolescence of Citations\nFig. 3 obtains the CHL of journals that were the target of analysis from JCR and\ntotalizes the median values. “Mathematics and Statistics” had the largest value of\nCHL obtained from JCR, which is 10 (JCR describes values of CHL over 10\nyears as 10), whereas “Engineering” (5.40) and “Medicine” (5.70) had shorter\nvalues. Furthermore, Fig. 4 shows the content of Fig. 3 by layer of the\n\ncumulative ratio of access count. In contrast to DHL, no differences were\nseen by layer.\n\nFigure 3. CHL by field.\n\n1778\n\nFigure 4. CHL by field and layer of cumulative ratio of access count.\n\nCorrelations between Access and Citations\nIn order to see the degree to which the obsolescence of citations and access are in\naccordance, observations were made of the correlations between (A) CHL and\nDHL; and between (B) II/IF and DII/DIF, respectively (Figs. 5 and 6). The\ndistributions of II/IF and DII/DIF have high values of skewness (4.86 and 5.16,\nrespectively). Moreover, as mentioned previously, we cannot obtain exact values\nfor CHL from JCR, where the maximum value of CHL is 10, with values above\nthis also being treated as 10. Thus, Spearman’s rank correlation coefficient ρ is\ndetermined instead of the product–moment correlation coefficient, which should\nbe applied to interval scales or ratio scales compliant to normal distribution. Table\n2 shows the correlation coefficients for (A) CHL vs. DHL and (B) II/IF vs.\nDII/DIF by field.\nThe correlation coefficients for all 11 fields were (A) ρ = 0.44 and (B) ρ = −0.02,\nthat is, no strong correlation was observed. In particular, almost no correlation\nwas found with (B), which was not significant at a standard of 5%. With regard to\nindividual fields, in the case of (A), somewhat strong and significant correlations\nof 0.6 or higher were seen in “Chemistry and Materials Science” (ρ = 0.69) and\n“Engineering” (ρ = 0.68) (p &lt; 0.05). In the case of (B), the degree of correlation\nwas weak in all fields. Furthermore, as for (B), there were not only positive\ncorrelations but also negative correlations. Among these, relatively strong and\nstatistically significant correlations were observed in “Biomedical and Life\nSciences” (ρ = 0.35) (p &lt; 0.05).\n\n1779\n\nFigure 5. (A) Scatter diagram for CHL vs. DHL.\n\nFigure 6. (B) Scatter diagram for II/IF vs. DII/DIF.\n\n1780\n\nTable 2. The degree of correlation of obsolescence between citations and access.\nSubject of Springer\nBehavioral Science (BS)\nBiomedical and Life Sciences (BL)\nBusiness and Economics (BE)\nChemistry and Materials Science (CM)\nComputer Science (CS)\nEarth and Environmental Science (EE)\nEngineering (EG)\nHumanities, Social Sciences and Law (HS)\nMathematics and Statistics (MS)\nMedicine (MD)\nPhysics and Astronomy (PA)\nWhole\n* Significant (p &lt; 0.05)\n\nA\n0.04\n0.31\n0.29\n0.69\n0.30\n0.61\n0.68\n0.06\n0.39\n0.37\n0.47\n0.44\n\n*\n*\n*\n*\n*\n*\n*\n*\n\nB\n-0.10\n0.35\n-0.02\n0.09\n-0.03\n-0.13\n0.07\n-0.27\n-0.21\n-0.11\n0.14\n-0.02\n\n*\n\nConclusions\nThe results of this research reveal a tendency for the obsolescence of citations and\naccess to be comparatively long for both “Mathematics and Statistics” and\n“Behavioral Science.” In contrast, it is short in the natural science fields other\nthan “Mathematics and Statistics.” These results are largely in line with\nHypothesis 1. Note that in regard to journals belonging to the layer with the\nlowest access count, it was observed that obsolescence was fast in many fields.\nWith respect to correlations between the obsolescence of citations and access, a\ntrend was observed in which these differ depending on the field and index. As for\nlong term obsolescence (CHL and DHL), the degree of correlation differed by\nfield, but all fields demonstrated a positive correlation. In other words, fields with\nfast obsolescence of citations witnessed a tendency toward fast obsolescence of\naccess. Meanwhile, with respect to short term obsolescence (II/IF and DII/DIF),\nno consistent trend was observed. Whether the correlation was positive or\nnegative depended on the field.\nIn most fields, the correlation between obsolescence of citations and that of access\nwas stronger in the long term (CHL and DHL) than in the short term (II/IF and\nDII/DIF). However, in the cases of “Biomedical and Life Sciences,” “Humanities,\nSocial Sciences and Law,” and “Behavioral Science,” the correlation of the latter\nwas stronger. This result was posited in Hypothesis 2, in which indices with a\nstrong correlation differ depending on the field. Furthermore, while only weak\ncorrelations were observed in most fields for both the long term and the short\nterm, the fields of “Engineering” and “Chemistry and Materials Science” showed\nsomewhat strong correlations of 0.6 or higher regarding long term obsolescence.\nIn other words, this result suggests that with respect to these two fields, it is\n\n1781\n\npossible to a certain degree to predict the long term obsolescence of access on the\nbasis of the value of CHL obtained from JCR.\nTherefore, these trends provide suggestions for introducing effective journal\nbackfiles. However, the results of this research have direct relevance only to the\nsituation at a particular university. If we are to obtain more general insights,\nfuture research needs to incorporate surveys that are broader in scope and that\norganize these trends based on the size and type of university (e.g., scienceversus humanities-oriented universities, or research- versus education-oriented\nuniversities).\nReferences\nBollen, J. &amp; van de Sompel, H. (2008). Usage impact factor: The effects of\nsample characteristics on usage-based impact metrics. Journal of the American\nSociety for Information Science and Technology, 59(1), 136-149.\nBrody, T., Harnad, S. &amp; Carr, L. (2006). Earlier web usage statistics as predictors\nof later citation impact. Journal of the American Society for Information\nScience and Technology, 57(8), 1060-1072.\nChu, H. &amp; Krichel, T. (2007). Downloads vs. citations in economics:\nRelationships, contributing factors &amp; beyond. In: Proceedings of the 11th\nInternational Society for Scientometrics and Informetrics Conference, pp. 207215, Madrid, Spain, June 25-27.\nDuy, J. &amp; Vaughan, L. (2006). Can electronic journal usage data replace citation\ndata as a measure of journal use? An empirical examination. The Journal of\nAcademic Librarianship, 32(5), 512-517.\nKurtz, M. J., Eichhorn, G., Accomazzi, A., Grant, C., Demleitner, M., Murray, S.\nS., Martimbeau, N. &amp; Elwell, B. (2005). The bibliometric properties of article\nreadership information. Journal of the American Society for Information\nScience and Technology, 56(2), 111-128.\nMcDonald, J. D. (2007). Understanding journal usage: A statistical analysis of\ncitation and use. Journal of the American Society for Information Science and\nTechnology, 58(1), 39-50.\nMoed, H. F. (2005). Statistical relationships between downloads and citations at\nthe level of individual documents within a single journal. Journal of the\nAmerican Society for Information Science and Technology, 56(10), 1088-1097.\nNicholas, D., Huntington, P., Dobrowolski, T., Rowlands, I., Jamali, M.H.R. &amp;\nPolydoratou, P. (2005). Revisiting ‘obsolescence’ and journal article ‘decay’\nthrough usage data: An analysis of digital journal use by year of publication.\nInformation Processing and Management, 41(6), 1441-1461.\nSchloegl, C. &amp; Gorraiz, J. (2010). Comparison of citation and usage indicators:\nThe case of Oncology journals. Scientometrics, 82(3), 567-580.\nSchloegl, C. &amp; Gorraiz, J. (2011). Global usage versus global citation metrics:\nThe case of Pharmacology journals. Journal of the American Society for\nInformation Science and Technology, 62(1), 161-170.\n1782\n\nWan, J.-K., Hua, P.-H., Rousseau, R. &amp; Sun, X.-K. (2010). The journal download\nimmediacy index (DII): Experiences using a Chinese full-text database.\nScientometrics, 82(3), 555-566.\nWatson, A. B. (2009). Comparing citations and downloads for individual articles.\nJournal of Vision, 9(4), 1-4.\n\n1783\n\nUSING MONTE CARLO SIMULATIONS TO\nASSESS THE IMPACT OF AUTHOR NAME\nDISAMBIGUATION QUALITY ON DIFFERENT\nBIBLIOMETRIC ANALYSES.\nJan Schulz1\n1\n\njan.schulz@bwl.tu-freiberg.de (ORCID: 0000-0002-2312-0588)\nTU Bergakademie Freiberg, Lessingstr. 45, 09599 Freiberg (Germany)\n\nAbstract\n\nBibliometric analyses depend on the quality of data sets and the author name\ndisambiguation process which attributes written papers with names on it to real persons.\nErrors of the author name disambiguation process can distort the results of the analyses.\nTo assess the resulting error in the analyses outcomes, Monte Carlo simulations can be\nused. This paper presents a basic algorithm of such simulations and how errors will lead to\nchanges to the results of different kinds of analyses (rankings and regressions analysis\nwith number of papers as dependent variable).\nThe results show that rakings of authors are more depended on data set quality than\nregression coefficients. Both mean and individual per person data set quality is important\nfor valid ranking results. Regression coefficients change less than 10% under current\nautomatic attribution processes quality.\n\nConference Topic\n\nOld and New Data Sources for Scientometric Studies: Coverage, Accuracy and Reliability\n(Topic 2) and Scientometrics Indicators: Criticism and new developments (Topic 1).\n\nIntroduction\nBibliometric data sets are the basis for several different analyses, ranging from\nrankings of authors and institutions up to inferring—combined with other data\nsets—the effects of author or other characteristics on research productivity. As\nsuch, publication performance measurements are important to evaluate scientists\nand research institutions and base policy decisions on it (e.g. Abramo &amp;\nD’Angelo, 2011; Frey, 2003)\nAll such analysis depend on the quality of the underlying data sets: errors in the\ndata set will affect the results of these analyses and potentially wrong conclusions\nand decisions could be drawn from these wrong analyses results.\nProblems of assessing the impact of errors in the data\nManually cleaning up the underlying bibliometric data sets is time and resource\nconsuming and with millions of articles not feasible (Wang et al., 2012). As such\nit is important to know the impact of errors in bibliometric data sets on the\n1784\n\nresulting analysis result. Such assessments of the impact can be done by using a\nsample of the data set and manually checking and cleaning up this sample before\ncomparing the analyses results from both data sets. This process is itself time and\nresource consuming and—as a manual step is involved—potentially still not error\nfree. This paper will introduce Monte Carlo simulations as a different mean to\nassess the impact of errors in bibliometric data sets on analyses results.\nData and Methods\nAttribution process and error measurements\nErrors in the bibliometric data set can have two sources: (1) the underlying raw\ndata sets (e.g. Web of Science or Scopus) can contain typos, omissions, or other\nerrors or (2) the process which attributes a paper to an entity (e.g. an author)\nwrongly attributes it to the wrong entity. This process is known as author name\ndisambiguation process (ANDP). The results of both errors are that some entities\nhave more and others have less than their real share of articles attributed to them.\nTo mitigate such problems more signals than only the author names are used in\nthe ANDP, such as the email address or even web searches (see Table 11 for\nexamples), but even the most sophisticated ANDP is not error free.\nThe quality of an ANDP and the resulting data-set can be measured by precision,\nrecall and F1 scores (Heath et al., 2009; Torvik &amp; Smalheiser, 2009). Precision is\nthe ratio between correctly attributed and all attributed papers and recall the ratio\nbetween correctly attributed papers and all papers written by a person. The\nharmonic mean of both indicators is called F1-score. All indicators are between\nzero and one with high values signaling better quality.\nTable 11: Reported quality measures of different author name disambiguation\nprocesses.\nF1 score (±95% CI)\n0.36±0.05 –\n0.46±0.14\n\nType\nUnsupervised learning\n\n0.76±0.08\n\nWeb searches as signal\n\n0.767±0.060\n\n„Self training“\n\n0.953\n\nManual reference list\n\nDataset and method details\nTop 14 common names in the DDPL\ndata set, automatic machine learning\nmethods (clustering, SVM) (Heath et\nal., 2009)\nTop 14 common names in the DDPL\ndata set (Heath et al., 2009)\nSurvey of authors, auto generated\ntraining set (co-authors, email) (Levin et\nal., 2012)\nItalian National Citation Report\n(D&#x27;Angelo, Giuffrida, &amp; Abramo, 2011)\n\nTable 1 shows mean F1 scores from different ANDP implementations and their\n95% confidence interval (if available or derivable), which were measured by\ncomparing the results of the ANDP against a manually cleaned sample. Quality\n1785\n\nvaries wildly and increases with more signals and manual training steps. Quality\nis between 0.36 and 0.77 for fully automatic ANDP and better than F1=0.90 for\nANDPs with reference lists or manual attribution steps. The confidence intervals\nshow that these quality measurements differ greatly for individual researchers.\nFor commercial available data sets such as the Web of Science or Scopus no such\nF1 scores could be found but Torvik &amp; Smalheiser (2009, p. 21) reports that for\n“139 cases [...] Web of Science and Scopus split 7.8% (11/139) and 18.7%\n(26/139) of [pairs of papers from the same author] into separate clusters”,\nmeaning that both databases have high false negative counts.\nMonte Carlo simulations\nTo assess the impact of such errors, Monte Carlo simulation can be used. Monte\nCarlo simulations use “random sampling and statistical modeling to estimate\nmathematical functions and mimic the operations of complex systems” (Harrison,\n2010, p. 17). Instead of mathematically deriving the statistical distribution of the\nerror (the differences between analysis results of the real and the measured data\nset) from the distribution of the errors in the data set, Monte Carlo simulations\nfirst simulate the data set and the errors and afterwards apply the analysis to both\nthe real and the measured data set and the differences of the resulting analyses are\ncounted. Doing this a few hundred or thousand times produces the distribution of\nthe differences between both analysis results.\nSimulated data sets\nTwo different bibliometric analyses are looked at: The use of author productivity\nin the form of papers-per-author values for (1) rankings of authors and (2) as an\ninput in regression analysis. The simulations were done with a range of data\nquality.\nAs a first step, the real productivity values (written papers per author) of a list of\nauthors were simulated (\n). In real world data sets,\nfollows a\npower law distribution (Clauset, Shalizi, &amp; Newman, 2009), meaning there a lots\nof authors with just a one or a few papers but only a few with hundreds of papers.\nFor the analysis of the impact of errors on rankings, this value was generated\ndirectly from a power law distribution. For the analysis of the impact of errors on\nregression analysis the productivity of an author was assumed to be dependent on\ntwo different observed author characteristics (e.g. “network position”, normal\ndistributed with\nand\n) and one non-observed variable noise which\nsubsumes all other influences (normally distributed with\nand\n). The\nfinal values were computed as\n. This value is\nlog normal distributed which has similar properties as a power law distribution\nand in real world data sets it is usually hard to distinguish from a power law\ndistribution (Stringer, Sales-Pardo, &amp; Nunes Amaral, 2008, p. 2).\n\n1786\n\nIn a second step, errors, based on mean F1 score (\n) and the variance of\nindividual F1 scores (\n), were introduced to these\nvalues to derive\nmeasured values.\nFor the purpose of this study, it was assumed that precision and recall were\nequally valued resulting in the same mean value for each quality indicator (F1\nscore = precision = recall).\nPrecision and recall values per author were normally distributed with\n(\n). σ was specified relative\nand\nto the maximal possible change as e.g. a mean data quality of\nof an\nindividual data sets for one authors means that this data sets F1 score can only\ngain 0.1 before reaching perfect data quality. Some generated values were outside\nof the range [0..1] and had to be cut at these levels.\nFrom these individual precision and recall values, falsely attributed ( ) and\nfalsely not attributed ( ) counts per author were derived. The measured\nproductivity was computed as\n.\nBoth\nand\nwere varied in the simulations.\nranged from\n0.5 to 1.0, meaning the mean data quality ranged from “about half the observed\npapers are wrongly attribute and half of the real one are not attributed” to “perfect\ndata quality”.\nranged from 0.0 to 0.5. For each different quality\nspecification 500 simulation runs were performed with 2500 persons each.\n\nFigure 2: Correlation between (a) absolute values for author productivity and (b)\nbetween rankings of authors based on author productivity (both measured in papersper-author). Each field stands for a specified data quality and is the mean correlation\nvalue of 500 simulations of 2500 authors. Contour lines represent equal correlation\nvalues and are spaced 0.05 apart.\n\nSensitivity analyses\nTo measure the sensitivity of the results of the analysis regarding different data\nset qualities, multiple comparison methods were employed: the overall effect was\nassessed by correlating the\nvalues with its\ncounterparts. To\nassess the effect of data set quality on rankings, the correlation between both\nrankings was used (Wang et al., 2012, p. 400) and additionally the changes in the\nTop-10 list were tallied. For regression analysis\n(\n) was regressed\n1787\n\non the simulated author characteristics. The standard deviation as well as the\nrange of observed regression coefficients was used as an indicator of the impact\nof errors on the resulting regression analysis (Cortez &amp; Embrechts, 2013, p. 3).\nFindings\nImpact on author rankings\nFigure 2a shows the correlation between real and measured absolute papers-perauthor values for a range of data qualities (specified in mean F1 scores and\nvariance of individual F1 scores). The upper right corner represents perfect data\nquality and the resulting correlation is 1.0. The correlations become lower for\nboth lower F1 scores and higher variance in individual F1 scores.\nFigure 2b shows the correlation between rankings for different data qualities.\nCompared to the correlation values of absolute values the correlation value for\nrankings is lower for higher data qualities but does not drop down as fast as the\ncorrelation values of absolute values. Both, mean data quality and individual\nperson’s data quality are important: both contribute roughly equally to the\nreduced correlations between real and measured papers-per-author values.\nThe difference between absolute and rank correlation is shown in Figure 3 for\nrelative variance of 0.19, which corresponds roughly to the best automatic\nANDPs as shown in Table 1. Correlations of rankings are consistently lower for\nthe whole range of F1 scores.\n\nFigure 3: Detailed view at relative variance of 0.19 and with varied F1 scores: (a)\ncorrelation values for rankings and absolute papers-per-author values; (b) changes\nin the Top-10 ranking.\n\nTo get a better picture what these correlation values mean for rankings, the mean\nchanges to the Top-10 list for different mean F1 scores at relative variance of 0.19\nare shown in Figure 3(b). At a low data quality of\n, almost half of the\npersons in the Top-10 list are changed. Even at a data quality of\n, on\naverage 0.5 persons are changed. Using 0.76 as the mean quality of a data set of\nthe best fully automatic ANDP, on average 1.5 persons are changed in the Top-10\nlist.\n1788\n\nImpact on regression analysis\nFigure 4 shows the results of the analysis of the impact of data set quality on the\nresults of a regression analysis. The displayed regression coefficient had a\nsimulated real value of “1”. Figure 4a shows the standard deviation of this\nregression coefficient at different data qualities. With a maximal standard\ndeviation of 0.01 the resulting regression coefficients deviate little from the real\nvalue on the simulated range of data qualities. Looking at the maximal difference\nbetween individual regression coefficients (Figure 4b), the maximal difference is\n0.07, meaning that even in the worst case, the regression coefficients are only off\nby 7%.\n\nFigure 4: Properties of regression coefficients with a simulated real value of “1” at\ndifferent data qualities: (a) Standard deviation of regression coefficients; (b)\nmaximal difference of regression coefficients (max. value – min. value). Each field\nstands for a specified data quality and is based of 500 simulations of 2500 authors.\n\nFigure 5: Detailed view at relative variance of 0.19 and at different F1 scores: (a)\nregression coefficient (real value = 1); (b) standard deviation of regression\ncoefficient.\n\nIn contrast to the results of the analysis of rankings, at least for better data set\nquality, regression coefficients are more influenced by relative variance of\nindividual data quality measures.\n1789\n\nFigure 5 shows again a detailed view of different mean F1 scores at relative\nvariance of 0.19. The maximal range between individual regression coefficients\n(Figure 5a) is 0.02 and declines with better F1 scores. The simulated regression\ncoefficients are off by at most 1%. Looking at the standard deviation of regression\ncoefficients, deviation is lower with better mean data set quality (Figure 5b) and\ndrops from 0.0030 to about 0.0016.\nLooking at F1 score = 0.76 (the best fully automatic ANDP) the simulated\nregression coefficients are off by at most 0.5% and have a standard deviation of\nless than 0.2%.\nDiscussion and Conclusion\nThe aim of this study was to show the application of Monte Carlo simulation to\nassess the impact of errors in bibliometric data sets on analysis results.\nThe analysis of the impact of data quality on rankings shows, that data quality is\nan important factor for the validity of such rankings. For data set qualities\ncomparable with data set quality produced by the best fully automatic ANDP,\nabout 1.5 persons are changed in the Top-10 list of such rankings.\nIt was also shown that both mean data quality and variance in individual data\nquality are important. As such it is important that ANDP implementations and\nanalyses based on such data sets report both the mean data quality measures\n(precision, recall, and/or F1 scores) and the variance of individual quality\nmeasures for each person.\nPossible problems arise from mixing authors from different cultures/ countries, as\nsome countries have a highly skewed distribution of names (e.g. Korean names;\nAksnes, 2008) or names with a higher probability of typos (e.g. German umlauts;\nFenner, 2011). This implies different types of errors (lower precision or lower\nrecall measures, respectively) for authors from these countries. Both effects lower\nthe mean data quality as well as imply differences in individual data quality,\nwhich would reduce the validity of rankings.\nIn the analysis of the impact of data quality in regression analysis, the underlying\ndata set quality has almost no impact on the resulting regression coefficient, even\nfor bad data qualities. For data set qualities of the best fully automatic ANDP, the\nobserved regression coefficients were off by at most 0.5%.\nAs the simulated errors in the data set are not correlated to the independent\nvariables (characteristics of authors) they only add more noise to the regression\nmodel but do not influence the value of the regression coefficients. The\nimplication is that regression analysis with bibliometric data sets should test for\nsystematic differences in errors which are correlated to independent variables (as\nwould be the case of country as an independent variable) and which could\ninfluence the validity of the regression results.\nThe adaption a unique identifier for scholarly authors, such as of ORCID\n(http://about.orcid.org/), will make ANDP obsolete and therefore the problem of\nbibliometric data set quality for rankings will hopefully be reduced (Fenner,\n2011).\n1790\n\nReferences\nAbramo, G., &amp; D’Angelo, C. A. (2011). Evaluating research: from informed peer\nreview to bibliometrics. Scientometrics, 87(3), 499–514. doi:10.1007/s11192011-0352-7\nAksnes, D. W. (2008). When different persons have an identical author name.\nHow frequent are homonyms? Journal of the American Society for\nInformation Science and Technology, 59(5), 838–841. doi:10.1002/asi.20788\nClauset, A., Shalizi, C. R., &amp; Newman, M. E. J. (2009). Power-Law Distributions\nin Empirical Data. SIAM Review, 51(4), 661. doi:10.1137/070710111\nCortez, P., &amp; Embrechts, M. J. (2013). Using sensitivity analysis and\nvisualization techniques to open black box data mining models. Information\nSciences, 225(0), 1–17. doi:10.1016/j.ins.2012.10.039\nD&#x27;Angelo, C. A., Giuffrida, C., &amp; Abramo, G. (2011). A heuristic approach to\nauthor name disambiguation in bibliometrics databases for large-scale research\nassessments. Journal of the American Society for Information Science and\nTechnology, 62(2), 257–269. doi:10.1002/asi.21460\nFenner, M. (2011). Author Identifier Overview. LIBREAS.Library Ideas, 7(1),\n24–29.\nFrey, B. S. (2003). Publishing as prostitution? - Choosing between one&#x27;s own\nideas and academic success. Public Choice, 116(1/2), 205–223.\ndoi:10.1023/A:1024208701874\nHarrison, R. L. (2010). Introduction to Monte Carlo Simulation. AIP Conference\nProceedings, 1204, 17–21. doi:10.1063/1.3295638\nHeath, F., Rice-Lively, M. L., Furuta, R., Pereira, D. A., Ribeiro-Neto, B.,\nZiviani, N., ... (2009). Using web information for author name\ndisambiguation. In Proceedings of the 2009 joint international conference on\nDigital libraries - JCDL &#x27;09 (pp. 49–58). ACM Press.\nLevin, M., Krawczyk, S., Bethard, S., &amp; Jurafsky, D. (2012). Citation-based\nbootstrapping for large-scale author disambiguation. Journal of the American\nSociety for Information Science and Technology, 63(5), 1030–1047.\ndoi:10.1002/asi.22621\nStringer, M. J., Sales-Pardo, M., &amp; Nunes Amaral, L. A. (2008). Effectiveness of\nJournal Ranking Schemes as a Tool for Locating Information. PLoS ONE,\n3(2), e1683 EP -. doi:10.1371/journal.pone.0001683\nTorvik, V. I., &amp; Smalheiser, N. R. (2009). Author name disambiguation in\nMEDLINE. ACM Transactions on Knowledge Discovery from Data, 3(3), 1–\n29. doi:10.1145/1552303.1552304\nWang, D. J., Shi, X., McFarland, D. A., &amp; Leskovec, J. (2012). Measurement\nerror in network data: A re-classification. Social Networks.\ndoi:10.1016/j.socnet.2012.01.003\n\n1791\n\nVISUALIZING AND COMPARING THE\nDEVELOPMENT OF SCIENTIFIC\nINSTRUMENTATION VS ENGINEERING\nINSTRUMENTATION\nChunjuan Luan1, Xianwen Wang2 and Haiyan Hou3\n1\n\njulielcj@163.com\nDalian University of Technology, School of Administration &amp; Law, WISE Lab, Dalian\nCity Linggong Road 2#, 116023 Dalian (P. R. China)\n2\n\nxianwenwang@dlut.edu.cn\nDalian University of Technology, School of Administration &amp; Law, WISE Lab, Dalian\nCity Linggong Road 2#, 116023 Dalian (P. R. China)\n3\n\nhtieshan@dlut.edu.cn\nDalian University of Technology, School of Administration &amp; Law, WISE Lab, Dalian\nCity Linggong Road 2#, 116023 Dalian (P. R. China)\n\nAbstract\n\nLaboratory instrumentations are considered a significant factor leading to innovation. But\nwhat are the developing trends like of Scientific Instrumentation (SI) and Engineering\nInstrumentation (EI)? Are their trends also appear to be exponential law? How many\nstages are existing in SI &amp; EI developing process? what are the network structures like of\nSI &amp; EI? What are the similarities and differences between SI &amp; EI in terms of their\ntrends, stages, and network structures? Few related studies have been found yet, and this\nstudy intends to explore the above questions by using patent analysis and social network\nanalysis, hoping get an overview concerning the characteristics of SI &amp; EI developing\nduring 1963-2011. Results show that both developing trend curves of SI &amp; EI are striking\nsimilar, tend to be polynomial developing trend, and have striking similar stages clustered\nand separated by SPSS. Comparing network structures of SI &amp; EI (2011) shows that,\nElectrical and Electronic is the biggest sub-network for both networks. Comparing top\nsubject areas of SI &amp; EI shows that, Chemistry, is the biggest Subject Area in SI, and\nComputer Science is the first Subject Area in EI. Still some related questions should be\nfurther explored.\n\nConference Topic\n\nTechnology and Innovation Including Patent Analysis (Topic 5) and Visualisation and\nScience Mapping: Tools, Methods and Applications (Topic 8).\n\nIntroduction\nIt is widely acknowledged that SI &amp; EI are vital to science &amp; technology (S&amp;T)\ndevelopment. But what are the developing trends like of SI &amp; EI? Are their trends\n1792\n\nalso appear to be exponential law? How many stages are existing in SI &amp; EI\ndeveloping process? what are the network structures like of SI &amp; EI? What are the\nsimilarities and differences between SI &amp; EI in terms of their trends, stages, and\nnetwork structures? Few related studies have been found yet, and this study intend\nto explore the above questions, hoping get an overview concerning the\ncharacteristics of SI &amp; EI developing.\nIn this study, Scientific Instrumentation (SI) and Engineering Instrumentation (EI)\nare included in Laboratory Equipment (LE). SI is mainly used in scientific\nresearch, and EI is chiefly applied in engineering practice. SI &amp; EI are two\nparallel sub-fields belonging to the upper field of Instrumentation-MeasuringTesting in the so called World Patent Database of Derwent Innovations Index\n(DII).\nThe existing studies are mainly pertinent to SI, few concerning EI. Studies related\nto SI include the following facets. Firstly, determinants to SI innovation. Hippel\n(Hippel 1976) had a sample of one hundred and eleven scientific instrument\ninnovations studied to determine the roles of instrument users and instrument\nmanufacturers in the innovation processes which culminated in the successful\ncommercialization of those instruments, and found that approximately 80% of the\ninnovations judged by users to offer them a significant increment in functional\nutility were in fact invented, prototyped and first field-tested by users of the\ninstrument rather than by an instrument manufacturer. Bergen and Pearson\n(Bergen and Pearson 1983) argued project management and innovation in the\nscientific instrument industry.\nSecondly, innovations between SI users and SI manufacturers. Riggs and\nVonhippel (Riggs and Vonhippel 1994) also explore the relationship between the\nsources of innovation and incentives to innovate in a sample of 64 innovations\nrelated to Auger and Esca, two types of scientific instrument used to analyze the\nsurface chemistry of solid materials. And found that innovations with high\nscientific importance tend to be developed by instrument users, while innovations\nhaving high commercial importance tend to be developed by instrument\nmanufacturers.\nSome related studies concerning SI have also been explored, such as analyzing\npractices and achievements in United States-Kingdom and West Germany in the\nscientific instrument industry (Bergen 1982); scientific instruments as keys to\nartificial revelation (Beaver 1988), and the relationship of scientific instruments,\nscientific progress and the cyclotron (Baird and Faust 1990), et al..\nThe extant studies are mainly conducted by using a considerably smaller sample,\nand discuss some issues related to determinants to SI innovation or difference\ninnovation between SI users and manufacturers, et al.. No related studies\nconcerning the developing trends, stages and network structures of SI &amp; EI have\nbeen found, yet.\nPatent data from DII are selected to visualize and compare the developing trends,\nstages and network structures of SI &amp; EI in this study. For patent documents\ncontain rich technical information related to intellectual property rights and\n1793\n\nimportant research results (Lawson, Kemp et al. 1996; Tseng, Lin et al. 2007;\nMagerman, Van Looy et al. 2010), and are usually considered the proper datasets\nin the analysis of technology and industry developing.\nThis paper is organized as follows: Following this introduction, Section 2\nintroduces related studies. Section 3 presents the dataset and methodologies in\nthis study. Section 4 visualize and compare trends, stages and network structure\nof SI &amp; EI. Section 5 concludes this study and discusses the findings and the\nimplications.\nLiterature review\nOn developing trends of SI &amp; EI\nAfter Price’s exponential growth constant was presented, the exponential growth\nlaw has been tested widely, especially in science development and related\ndomains. Leydesdorff and Zhou (Leydesdorff and Zhou 2005) proposed that in\nChina and Korea, in addition to publications, their citation rates keep pace with\nthe exponential growth patterns, albeit with a delay. Furthermore, some related\nstudies have revised Price’s exponential law, for example, Su and Han (Su and\nHan 1998) replaced by a polynomial of degree n-1 to Price’s exponential law, and\ntheir research showed that the new model was more convincing than the former\nones, and they also gave detailed calculation procedure, examples, parameter\nvalues and mean square errors. What are the developing trends like of SI &amp; EI?\nAre their trends also appear to be exponential law, or others? No related studies\nhave been found yet.\nOn developing stages of SI &amp; EI\nPhasing or stage division is usually the fundamental work in bibliometric\nresearching. Averaging method (Hou, Kretschmer et al. 2008) or visual method\n(Makovetskaya and Bernadsky 1994) is generally employed in stage dividing.\nStudies concerning stages division of SI &amp; EI have not been found. Therefore, a\nnew method by using SPSS (Statistical Package for the Social Sciences) will be\ntried to cluster and separate developing stages of SI &amp; EI.\nOn network structures of SI &amp; EI\nSocial network analysis (SNA) is not a formal theory in sociology but rather a\nstrategy for investigating social structures (Otte and Rousseau 2002). SNA has\nwidely employed in scientometrics, such as collaboration analysis (Kretschmer\nand Aguillo 2004; Wagner and Leydesdorff 2005; Schilling and Phelps 2007;\nHou, Kretschmer et al. 2008; Leydesdorff and Wagner 2008); co-citation analysis\n(Wouters and Leydesdorff 1994; Otte and Rousseau 2002; Marion, Garfield et al.\n2003; Johnson and Oppenheim 2007; Chen, Chen et al. 2009; Leydesdorff 2009;\nWang, Zhang et al. 2011); co-occurrence analysis (Small 1973; Morris 2001;\nLeydesdorff and Vaughan 2006; Leydesdorff 2007; Waltman and van Eck 2007;\nJeong and Kim 2010), et al.. However, only a few studies on technology network\n1794\n\nby using SNA have been found. The existing studies focus on the influence of\nbusiness strategies on technological network activities (Gemunden and\nHeydebreck 1995; Vanhaverbeke, Gilsing et al. 2012); high-technology network\nin northern Finland (Jauhiainen 2006); the role of transnational corporations in the\nChinese science and technology network (Hennemann 2011); global technology\nanalysis (Nam and Barnett 2011), et al.. Studies concerning network structure of\nSI &amp; EI by using patent analysis have not been found.\nData and Methodology\nData in the study\n1. Data retrieval\nThe data in this study is retrieved from Derwent Innovations Index (abbr. as DII\nbelow). DII is one of the most comprehensive databases collecting patent\ndocuments in the world, begun in 1963 and currently published by the Thomson\nReuters. DII includes three parts: Chemistry, Engineering and Electric &amp;\nElectronics. Every week 25, 000 patent documents published by more than 40\npatent offices and 45, 000 patent citation documents from 6 important copyright\noffices are input into DII. The date used in our statistics has been officially\npublished. Because one patent family include one basic patent and one or more\nequivalent patent(s), the number of patents in this study is of the basic patent, not\nall applications. The basic patent publication date is definite.\nEach bibliographic patent record in DII is assigned with three different\nclassification standards: International Patent Classification (IPC), Derwent Class\nCode (DC), and Derwent Manual Code (MC). DC is used to retrieve the data of\nSI &amp; EI, for among DCs, S02 represents Engineering Instrumentation and S03\nrepresents\nScientific\nInstrumentation.\nTime\nspan=1963-2011;\ndatabase=CDerwent, EDerwent, MDerwent.\n2. Data format converting and processing\nData downloaded from DII should be converted first. Data format conversion\nfunction of CiteSpace (Chen 2006) is employed to convert the patent publications\ninto the web of science export format, for most of the data-processing research\nsoftware such as CiteSpace, Bibexcel, et al. being designed originally to process\ndata with the format of Web of Science, and now CiteSpace also provides data\nformat conversion function for several other kinds of data downloaded from\nPubMed, arXiv, ADS, and NSF Award Abstracts et al. (Chen 2010). Bibexcel\n(Persson 2012) and Ucinet (Jang 2000) are applied to analyze the converted patent\ndata of SI &amp; EI.\nSeparating developing stages of SI &amp; EI\n1. Selection of variables\n\n1795\n\nSeparating developing stages is usually the fundamental and premise work before\ndoing some research. Selecting variables is the necessary preparation when\nemploying SPSS to cluster and separate developing stages. Three variables are\nalways the minimum requirement. These variables should operate a same\nstandard, and change continuously. For example, when SI developing stages is\nseparated, different years and different number of patent filings in different years\nare two proper variable, but how to choose the third variable is not easy. Different\nnumber of DC (Derwent Class Code) in different years is selected as the third\nvariable at last, after comparing with other variables. The main reason of choosing\nDC is DC operates a unified standard other than IPC, MC, et al. which operate a\nhierarchical classification system.\n2. Hierachical Cluster Analysis\nAccording to at least three different variables, employing Hierachical Cluster\nAnalysis embedded in the software of SPSS (Statistical Package for the Social\nSciences), selecting cluster method of Between-groups linkage, and measured by\nSquared Euclidean Distance, choosing a proper rang of solutions, then several\npossible solutions can be got, and a best result could be picked out.\nVisualizing network structure\nAccording to the methodologies and procedures elaborated in the article of\n“Mapping the evolution of technology network in the field of solar energy\ntechnology” (Luan, Hou et al. 2012) , networks of SI &amp; EI are drawn out\nrespectively, and their network structures are compared with each other.\n\nFigure 1. Developing trend curves and stages of SI &amp; EI during 1963-2011.\n\n1796\n\nAnalysis and results\nComparing the developing trends of SI &amp; EI\nDuring 1963-2011, total patent filings of SI are 766, 122, and those of EI are 657,\n365, existing a gap of 108, 757. The developing trends of SI &amp; EI are shown in\nFigure 1.\nThe two developing trend curves are striking similar in Figure 1. Both of them\ndemonstrate an increasing developing trend obviously over time, with fluctuating\na bit during their going up ways. Differing from the exponential growth law of\nscientific development, the two curves of SI &amp; EI are tend to be polynomial\ndeveloping trend, with goodness of fit of 0.934 and 0.933, respectively.\nComparing the developing stages of SI &amp; EI\nAccording to three different variables, that is, different publication years, different\nnumber of publications (patent filings in this paper) in different years, and\ndifferent number of Derwent Class Classifications (DC), by using the Analysis\nFunctions called Hierachical Cluster Analysis embedded in the software of SPSS\n(Statistical Package for the Social Sciences), all the years during 1963-2011 are\nclustered and separated into 4 stages. Stage I: 1963-1973, a infancy stage,\ndeveloping speed in this stage is slow; Stage II: 1974-1995, a steady growing\nstage, developing speed in this stage is steady; Stage III: 1996-2006, a rapid\ngrowing stage, in this stage, patent filings develop at a comparatively rapid speed;\nStage IV: 2007-2011, a highly speeding stage, this stage enjoying an extraordinary\nfast speed.\nDeveloping stages of SI &amp; EI are clustered by using SPSS, respectively, but it is\nstriking that the two developing stage curves are nearly the same, so they are\ncombined together in Figure 1.\nComparing network structures of SI &amp; EI in 2011\n1. Network structure of SI in 2011\nThe data in the latest year of 2011 are selected to be drawn network, and network\nstructures are compared between SI &amp; EI.\nAll the patent filings of 54, 098 in 2011 are analyzed by using the hypertext\nsoftware of Bibexcel. These patent filings are pertinent to 278 different\ntechnology classifications in terms of DCs. The total frequency of 278 DCs\namong 54, 098 records is 160, 306, mean value of DCs in each record is 2.96. 278\nDCs are all chosen in doing technology co-classification analysis. After getting\nthe co-classification matrix of the 278 technology classifications, Jaccard index is\nused to obtain the normalized matrix. Netdraw tool of Ucinet is employed to draw\nthe network of SI in 2011, respectively. By adjusting the threshold continuously,\nwe get the clear main component network (Figure 2). The size of the nodes\nrepresents the value of degree centrality in Figure 2.\n\n1797\n\nFigure 2. Network structure of Scientific Instrumentation (SI): 2011, degree.\n\nFigure 3. Network structure of Engineering Instrumentation (EI): 2011, degree.\n\nGirvan–Newman algorithm is used to cluster sub-networks, and so the network\nstructure of SI is demonstrated in Figure 2. Electrical and Electronic is the\nbiggest sub-network, which is surrounded by several chemicals related subnetworks. The second biggest sub-network is Polymer Chemistry Instruments,\n1798\n\nlocating in the center of the whole network. In addition, there are several\ncomparatively smaller sub-networks on the edge, such as Industrial Electric\nEquipment, Electrophotography &amp; Photography and Building and Construction,\net al..\n2. Network structure of EI in 2011\nBy using the same steps and methods, network structure of EI in 2011 is obtained\n(Figure 3). The biggest sub-network is Electrical and Electronic; which is\nfollowed by another comparatively bigger sub-network named Polymer Chemical\nInstruments; and sub-networks such as Electrical Medical Equipment, Polymer\nApplications, Industrial Electric Equipment, Vehicles Engineering, et al.. And\nsub-networks as Chemical Refinery Engineering and Electrophotography and\nPhotography are smaller ones.\nComparing top subject areas of SI &amp; EI: 2011\nAccording to the Subject Areas provided in DII, we compare top Subject Areas of\nSI &amp; EI in 2011. Subject Areas with proportion ≥1% are listed in Table 1 and\nTable 2.\nTable 1. Top Subject Areas with proportion ≥1% of SI in 2011.\nRanking\n\nSI: Subject Areas (Total 89)\n\n% of SI\n\n*\n*\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\nEngineering\nInstruments &amp; Instrumentation\nChemistry\nComputer Science\nPharmacology &amp; Pharmacy\nBiotechnology &amp; Applied Microbiology\nPolymer Science\nGeneral &amp; Internal Medicine\nTransportation\nEnergy &amp; Fuels\nCommunication\nFood Science &amp; Technology\nAgriculture\nOptics\nImaging Science &amp; Photographic Technology\nMetallurgy &amp; Metallurgical Engineering\nWater Resources\n\n99.88%\n99.88%\n41.29%\n21.27%\n20.01%\n14.22%\n12.64%\n8.94%\n4.18%\n3.96%\n2.59%\n2.39%\n2.31%\n1.90%\n1.76%\n1.64%\n1.40%\n\n1799\n\nTable 2. Top Subject Areas with proportion ≥1% of EI in 2011.\nRanking\n\nEI: Subject Areas (Total 63)\n\n% of EI\n\n*\n*\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\nEngineering\nInstruments &amp; Instrumentation\nComputer Science\nTransportation\nChemistry\nPolymer Science\nCommunication\nGeneral &amp; Internal Medicine\nEnergy &amp; Fuels\nMetallurgy &amp; Metallurgical Engineering\nConstruction &amp; Building Technology\nOptics\nImaging Science &amp; Photographic Technology\nMining &amp; Mineral Processing\nPharmacology &amp; Pharmacy\n\n99.92%\n99.92%\n25.75%\n16.79%\n13.05%\n7.00%\n4.25%\n4.02%\n3.64%\n2.33%\n1.98%\n1.93%\n1.43%\n1.27%\n1.11%\n\nIt should be noted that Subject Areas of Engineering, and Instruments &amp;\nInstrumentation, are excluded in analyzing, due to almost all the data are\nconcerning these two Subject Areas. It also should be noted that total percentage\nexceeds 100%, because of multidisciplinary distributing of patent filings in terms\nof Subject Areas.\nTotal 89 Subject Areas are related to SI. Chemistry, is the biggest Subject Area in\nSI, with 41.29% of total in 2011; Computer Science is the second biggest Subject\nArea, with 21.27% of total; and the third one is Pharmacology &amp; Pharmacy, with\nthe proportion of 20.1%. Followed by Biotechnology &amp; Applied Microbiology,\nand Polymer Science. The ratio of the top 5 Subject Areas exceeds 10%.\nTotal 63 Subject Areas are pertinent to EI. Differing from SI, Computer Science,\nis the first Subject Area in EI, with 25.75% of total in 2011; Transportation, is the\nsecond biggest Subject Area, with 16.79% of total; and the third one is Chemistry,\nwith the proportion of 13.05%. Followed by Polymer Science, Communication\nand General &amp; Internal Medicine. Only the top 3 Subject Areas exceeds 10%\nconcerning proportion.\nComparing overlapping of SI &amp; EI\nSome laboratory instrumentations are used in scientific research, so they are\nassigned in the field of SI in DII, and at the same time, they maybe also be used in\nengineering, therefore they are also assigned in the field of Engineering\nInstrumentation in DII. This results in overlapping of SI &amp; EI. Analyzing and\n\n1800\n\ncomparing the overlapping of SI &amp; EI, will help us understand which one depends\nthe other more during their developing process.\n\nFigure 4. Overlapping of SI &amp; EI: 1968-2011.\n\nIt should be noted that (Figure 4) no overlapping of SI &amp; EI emerged when patent\nfilings were less before the year of 1967; SI &amp; EI have been overlapping since the\nyear of 1968, so SI &amp; EI overlapping analysis is conducted during 1968-2011.\nThe same, according to three different variables, that is, different years, different\npercentage of SI included in EI in different years, and different percentage of EI\nincluded in SI in different years, also by using the Analysis Functions called\nHierarchical Cluster Analysis embedded in the software of SPSS, all the years\nduring 1968-2011 are clustered and separated into 5 stages. Stage I: 1968-1973,\na big gap stage, the proportion of “SI included in EI” is much higher than that of\n“EI included in SI” in this stage, which indicating that EI depends on SI more in\nthis period; Stage II: 1974-1983, a comparatively consistent stage, two curves\nmatches so well in this stage; Stage III: 1984-1993, an increasing stage, both\ncurves appear to be going up dominant trend in this period, and EI ; Stage IV:\n1994-2002, a fluctuating stage, in this stage both curves wave fiercely; Stage V:\n2003-2011, a descending stage, two curves demonstrate decreasing in fluctuating.\n\n1801\n\nConclusions and discussions\nConclusions\nUsing patent data in the field of Scientific Instrumentation (SI) and Engineering\nInstrumentation (EI) worldwide downloaded from one of the most comprehensive\nworld patent databases Derwent Innovation Index (DII) during 1963-2011, we\nvisualize and compare the developing trends, developing stages, network\nstructure, top subject areas, and overlapping of SI &amp; EI during 1963-2011, and\nhave an overview concerning SI &amp; EI developing.\nThe two developing trend curves are striking similar, and are tend to be\npolynomial developing trend, with perfect goodness of fit of 0.934 and 0.933,\nrespectively.\nAccording to three different variables, by using the Analysis Functions called\nHierarchical Cluster Analysis embedded in the software of SPSS (Statistical\nPackage for the Social Sciences), we get another striking finding, that is, all the\nyears during 1963-2011 are clustered and separated into 4 stages, and the\ndeveloping stages of SI &amp; EI are exactly the same, both are as follow: 1963-1973,\na infancy stage; 1974-1995, a steady growing stage; 1996-2006, a rapid growing\nstage and 2007-2011, a highly speeding stage.\nComparing network structures of SI &amp; EI (2011) shows the similarity is that,\nElectrical and Electronic is the biggest sub-network for both networks. The\ndifference is that, as far as SI network structure, there are several chemicals\nrelated sub-networks, and some other sub-networks such as Industrial Electric\nEquipment, Electrophotography &amp; Photography and Building and Construction,\net al..; when it comes to EI network structure, except for the biggest sub-network,\nfollowed by another comparatively bigger sub-network named Polymer Chemical\nInstruments; and sub-networks such as Electrical Medical Equipment, Polymer\nApplications, Industrial Electric Equipment, Vehicles Engineering, et al...\nComparing top subject areas of SI &amp; EI shows that, Total 89 Subject Areas are\nrelated to SI; total 63 Subject Areas are pertinent to EI. Chemistry, is the biggest\nSubject Area in SI, with 41.29% of total in 2011; Computer Science is the second\nbiggest Subject Area, with 21.27% of total. Differing from SI, Computer Science,\nis the first Subject Area in EI, with 25.75% of total in 2011; Transportation, is the\nsecond biggest Subject Area, with 16.79% of total.\nComparing overlapping of SI &amp; EI shows that, all the years during 1968-2011\nconcerning SI &amp; EI overlapping are clustered and separated into 5 stages: 19681973, a big gap stage; 1974-1983, a comparatively consistent stage; 1984-1993,\nan increasing stage; 1994-2002, a fluctuating stage; and 2003-2011, a descending\nstage.\nDiscussions\nDiffering from the exponential law in science developing, both trends of SI &amp; EI\ncurves show a polynomial developing trend with fluctuations. What are the\n\n1802\n\nreasons, and what impacts on science and technology developing, should be\nfurther studied.\nWhat affects developing stages of SI &amp; EI? And what characteristics concerning\nscience and technology developing are resulted by the different stages? Related\nstudies should be explored next.\nOnly network structures of SI &amp; EI in 2011 have been visualized and compared.\nHow are both network structures evolving? And what are the characteristics in\ndifferent stages like? Such questions still need sufficient time to investigate.\nOn subject areas and overlapping of SI &amp; EI, also need time and energy to explore\nin details.\nFindings in this study will benefit us comprehending the regulation of SI &amp; EI,\nthe relationship of SI &amp; EI, and the impacts of SI &amp; EI on science and technology\ndeveloping.\nAcknowledgments\nThis work was supported by the Natural Science Foundation of China (NSFC)\nunder Grant 71073015, 71103022.\nReferences\nBaird, D. and T. Faust (1990). cientific instruments, scientific progress and the\ncyclotron. British Journal for the Philosophy of Science, 41(2): 147-175.\nBeaver, D. D. (1988). The secrets of science unlocked - scientific instruments as\nkeys to artificial revelation. Science Technology &amp; Human Values, 13(3-4):\n373-384.\nBergen, S. A. (1982). The r-and-d production interface - united-kingdom and\nwest-german practices and achievements in the scientific instrument industry.\nR &amp; D Management, 12(1): 21-25.\nBergen, S. A. and A. W. Pearson (1983). Project-management and innovation in\nthe scientific instrument industry. Ieee Transactions on Engineering\nManagement, 30(4): 194-199.\nChen, C. (2010). CiteSpace: 2003-2012. Retrieved October 6, 2012 from:\nhttp://cluster.cis.drexel.edu /~cchen /citespace/.\nChen, C. M. (2006). CiteSpace II: Detecting and visualizing emerging trends and\ntransient patterns in scientific literature. Journal of the American Society for\nInformation Science and Technology, 57(3): 359-377.\nChen, C. M., Y. Chen, et al. (2009). Towards an explanatory and computational\ntheory of scientific discovery. Journal of Informetrics, 3(3): 191-209.\nGemunden, H. G. and P. Heydebreck (1995). The influence of business strategies\non technological network activities. Research Policy ,24(6): 831-849.\nHennemann, S. (2011). The role of transnational corporations in the chinese\nscience and technology network. Erdkunde, 65(1): 71-83.\nHippel, E. V. (1976). Dominant role of users in scientific instrument innovation\nprocess. Research Policy, 5(3): 212-239.\n\n1803\n\nHou, H., H. Kretschmer, et al. (2008). The structure of scientific collaboration\nnetworks in Scientometrics. Scientometrics, 75(2): 189-202.\nJang, Y. S. (2000). The worldwide founding of ministries of science and\ntechnology, 1950-1990. Sociological Perspectives, 43(2): 247-270.\nJauhiainen, J. S. (2006). Multipolis: High-technology network in northern\nFinland. European Planning Studies, 14(10): 1407-1428.\nJeong, S. and H. G. Kim (2010). Intellectual structure of biomedical informatics\nreflected in scholarly events. Scientometrics, 85(2): 541-551.\nJohnson, B. and C. Oppenheim (2007). How socially connected are citers to those\nthat they cite? Journal of Documentation, 63(5): 609-637.\nKretschmer, H. and I. F. Aguillo (2004). Visibility of collaboration on the Web.\nScientometrics, 61(3): 405-426.\nLawson, M., N. Kemp, et al. (1996). Automatic extraction of citations from the\ntext of English-language patents - An example of template mining. Journal of\nInformation Science, 22(6): 423-436.\nLeydesdorff, L. (2007). &quot;Should co-occurrence data be normalized? A rejoinder.&quot;\nJournal of the American Society for Information Science and Technology\n58(14): 2411-2413.\nLeydesdorff, L. (2008). On the normalization and visualization of author cocitation data: Salton&#x27;s cosine versus the Jaccard index. Journal of the American\nSociety for Information Science and Technology, 59(1): 77-85.\nLeydesdorff, L. (2009). How are New Citation-Based Journal Indicators Adding\nto the Bibliometric Toolbox? Journal of the American Society for Information\nScience and Technology, 60(7): 1327-1336.\nLeydesdorff, L. and L. Vaughan (2006). Co-occurrence matrices and their\napplications in information science: Extending ACA to the Web environment.\nJournal of the American Society for Information Science and Technology,\n57(12): 1616-1628.\nLeydesdorff, L. and C. S. Wagner (2008). International collaboration in science\nand the formation of a core group. Journal of Informetrics, 2(4): 317-325.\nLeydesdorff, L. and P. Zhou (2005). Are the contributions of China and Korea\nupsetting the world system of science? Scientometrics, 63(3): 617-630.\nLuan, C. J., H. Y. Hou, et al. (2012). Mapping the evolution of technology\nnetwork in the field of solar energy technology. 17th International Conference\non Science and Technology Indicators (STI) , Montreal, Quebec, Canada.\nProceedings of STI 2012 Montreal, 561-568.\nMagerman, T., B. Van Looy, et al. (2010). Exploring the feasibility and accuracy\nof Latent Semantic Analysis based text mining techniques to detect similarity\nbetween patent documents and scientific publications. Scientometrics, 82(2):\n289-306.\nMakovetskaya, O. and V. Bernadsky (1994). Scientometric indicators for\nidentification of technology system life-cycle phase. Scientometrics, 30(1):\n105-116.\n\n1804\n\nMarion, L. S., E. Garfield, et al. (2003). Social network analysis and citation\nnetwork analysis: Complementary approaches to the study of scientific\ncommunication (SIG MET). Humanizing Information Technology: From Ideas\nto Bits and Back. Medford, Information Today Inc. Eric Archambault (Ed.),\nProceedings of the 66th Asist Annual Meeting, 40: 486-487.\nMorris, T. (2001). Visualizing the structure of medical informatics using term cooccurrence analysis: II. INSPEC perspective. Proceedings of the 64th Asist\nAnnual Meeting, Medford, Information Today Inc. 38: 489-497.\nNam, Y. and G. A. Barnett (2011). Globalization of technology: Network analysis\nof global patents and trademarks. Technological Forecasting and Social\nChange, 78(8): 1471-1485.\nOtte, E. and R. Rousseau (2002). Social network analysis: a powerful strategy,\nalso for the information sciences. Journal of Information Science, 28(6): 441453.\nPersson, O. (2012). BibExcel. Retrieved October 6, 2012 from:\nhttp://www8.umu.se/inforsk/Bibexcel/.\nRiggs, W. and E. Vonhippel (1994). Incentives to innovate and the sources of\ninnovation - the case of scientific instruments. Research Policy, 23(4): 459469.\nSchilling, M. A. and C. C. Phelps (2007). Interfirm collaboration networks: The\nimpact of large-scale network structure on firm innovation. Management\nScience, 53(7): 1113-1126.\nSmall, H. G. (1973). Relationship between citation indexing and word indexing study of co-occurrences of title words and cited references. Proceedings of the\nAmerican Society for Information Science, 10: 217-218.\nSu, Y. and L. F. Han (1998). A new literature growth model: Variable exponential\ngrowth law of literature. Scientometrics, 42(2): 259-265.\nTseng, Y. H., C. J. Lin, et al. (2007). Text mining techniques for patent analysis.\nInformation Processing &amp; Management, 43(5): 1216-1247.\nVanhaverbeke, W., V. Gilsing, et al. (2012). Competence and Governance in\nStrategic Collaboration: The Differential Effect of Network Structure on the\nCreation of Core and Noncore Technology. Journal of Product Innovation\nManagement, 29(5): 784-802.\nWagner, C. S. and L. Leydesdorff (2005). Network structure, self-organization,\nand the growth of international collaboration in science. Research Policy,\n34(10): 1608-1618.\nWaltman, L. and N. J. van Eck (2007). Some comments on the question whether\nco-occurrence data should be normalized. Journal of the American Society for\nInformation Science and Technology, 58(11): 1701-1703.\nWang, X. W., X. Zhang, et al. (2011). Patent co-citation networks of Fortune 500\ncompanies. Scientometrics, 88(3): 761-770.\nWouters, P. and L. Leydesdorff (1994). Has price dream come true - is\nscientometrics a hard science. Scientometrics ,31(2): 193-222.\n\n1805\n\nWEB BASED IMPACT MEASURES FOR\nINSTITUTIONAL REPOSITORIES\nAlastair G Smith\n1\n\nalastair.smith@vuw.ac.nz\nVictoria University of Wellington/ Te Whare Wānanga o te Ūpoko o te Ika a Māui,\nSchool of Information Management, Rutherford House, 23 Lambton Quay, Wellington\n6140, (New Zealand/Aotearoa)\n\nAbstract\n\nThis study investigated webometric measures that could be used to evaluate the impact of\ninstitutional repositories, using Australasian university repositories as a case study. URL\ncitation inlinks (occurrences of the repositories’ URL in the text of web pages), as found\nthrough Google searches, were counted. As well as links from the general web, links\nmade from other Australasian academic institutions and from Wikipedia were counted.\nFor repositories with significant deposit ratios, there appeared to be a small correlation\nbetween the URL citation inlinks from other Australasian academic institutions, and some\nconventional measures of research impact: the ISI citations/paper, the QS ranking score,\nand the ERA quality score. Repositories with higher deposit ratios appeared to achieve\nmore inlinks from other Australasian academic institutions, indicating the value of\nrepositories encouraging high deposit rates of their institutions research output.\nInstitutions with repositories that had a high Wikipedia Web Impact Factor were not\nnecessarily highly ranked in terms of inlinks from other tertiary institutions or ISI\ncitations per paper. This indicates that repositories impact on the general web is different\nfrom their impact on the research community.\n\nConference Topic\n\nWebometrics (Topic 7); Scientometric Indicators (Topic 1)\n\nIntroduction\nInstitutional Repositories are a common way for institutions to make their\nresearch outputs available. This study investigated opportunities for webometric\nevaluation of the research done by institutions through their repositories.\nMost commonly webometric studies use inlink counts: links made from other\nwebsites to the site being studied. These are viewed as being analogous to\ncitations in conventional publishing (Gairin, 1997). Either total inlink counts are\nused, or a Web impact factor (Almind &amp; Ingwersen, 1997), analogous to the\nJournal Impact Factor for conventional publications. The Web Impact Factor is\ndefined as the ratio of the inlink counts to a measure of the size of website, for\nexample the number of pages.\n\n1806\n\nThere are a number of ways reported in the literature for counting the inlinks\nmade to a website such as an institutional repository. Unfortunately several tools\nused in the past are no longer available. An early study of Web Impact Factors for\nAustralasian universities (Smith &amp; Thelwall, 2002) used Alta Vista to identify\npages linking to the universities, but this tool is no longer available. Yahoo Site\nExplorer was used by many studies, for example to create a ranked list of world\nclass universities (Ortega &amp; Aguillo, 2009), but since Yahoo has been merged\ninto Bing, the Site Explorer tool no longer provides useful link data. Thelwall and\nSud (2011) reviewed alternative methods of estimating the online impact of\norganisations, including URL citation inlinks (discussed below) and\norganisational title mentions.\nThe current study used the technique of URL citation inlinks, proposed by\nKousha and Thelwall (Kousha &amp; Thelwall, 2007). This uses a search engine such\nas Google to locate in-text mentions of URLs associated with an institutional\nrepository, which can be assumed to be links to documents at the repository.\nThere have been other webometric studies of institutional repositories. Placing\nresearch materials in repositories was found to increase the amount of data\navailable for bibliometric analysis (Scholze, 2007). Zuccala et al (2007) studied\nan institutional repository by using web link analysis and server logs in order to\ninvestigate how users located and used the repository. An analysis of the web\npresence of Indian state universities (Shukla &amp; Poluru, 2012) found that open\naccess institutional repositories were helpful in increasing the visibility of\ninstitutions on the Web. A range of webometric measures have been used to\ncreate\nthe\nRanking\nWeb\nof\nWorld\nRepositories\n(http://repositories.webometrics.info) (Aguilllo et al 2010) in order to support the\nuse of repositories for scientific evaluation purposes.\nA previous paper (Smith, 2012) found little correlation between impact measures\nof institutional repositories calculated from a new search engine Blekko\n(http://blekko.com/), and conventional research impact measures. The paper\nsuggested that since links to institutional repositories are different in nature from\nconventional measures of research impact, measures for institutional repositories\nshould be considered to be complementary to conventional measures, rather than\ndirectly comparable.\nIn the current study, impact measures were calculated based on:\n Links from the general Web\n Links from academic domains, which might be considered to be more\nequivalent to conventional measures of research impact\n Links from Wikipedia, which might be considered to be more indicative\nof the impact that the repository has in making research available to the\nlay community. A previous paper (Smith, 2011) identified a significant\n1807\n\nnumber of links from Wikipedia to institutional repositories, and\nproposed that the value of institutional repositories may lie in making\nresearch available to the general Web community, rather than to the\nresearch community.\nResearch Questions\nThis study addressed the following questions:\n\n1. What impact factor measures are appropriate for evaluating the impact\nof institutional repositories on the Web?\n2. Do web based impact factors for institutional repositories correlate with\nconventional impact measures of the research output of institutions?\n3. Do institutional repositories have a greater impact if a higher\nproportion of their research output is in the institutional repository?\n4. Are there specific impact factors that reflect the different impact that\ninstitutional repositories have?\nMethodology\nThis study investigated institutional repositories at tertiary institutions in\nAustralasia (Australia and New Zealand). These were identified from ROAR\n(http://roar.eprints.org/). Repositories with less than 1000 items reported in\nROAR were excluded, resulting in 39 institutional repositories being included in\nthe study.\nGoogle was searched with a formulation that identified pages that contained URL\ncitation inlinks. The search excluded links from the institution itself (on the\nargument that these would be likely to be navigational links or self citations).\nGoogle was set not to record search history or use previous searches in\ninterpreting the search formulation. This is important, since Google by default\nattempts to optimise the search on the basis of a users previous searching, which\nof course is counterproductive for webometric work. The data was collected in\nJanuary 2013.\nA typical formulation, for example for University of Auckland, was:\n&quot;researchspace.auckland.ac.nz&quot; -site:auckland.ac.nz\n\nThis searched for web pages which included, in the text of the page, the basic\nURL of the archive, and excluded pages on the University of Auckland site.\nInitially, only links from the institutional repository itself were excluded, for\nexample:\n&quot;researchspace.auckland.ac.nz&quot; -site:researchspace.auckland.ac.nz\n\nHowever scanning the results indicated that this still included many pages at the\ninstitution which were either navigational in nature, or self citations (a staff\nmember linking to their publications from their home page, for example), and it\n1808\n\nwas decided that the formulation excluding all links from the institution was more\nappropriate.\nIn some cases an institutional repository had more than one URL, for example\nAustralian National University required a formulation:\n&quot;digitalcollections.anu.edu.au&quot; OR\n&quot;dspace.anu.edu.au&quot; -site:anu.edu.au\n\nThis searched for web pages that included, in the text of the page, either of the\nbasic repository URLs, but excluded pages at the ANU site.\nThe Web Impact Factor for each repository was calculated by dividing the URL\ncitation inlinks count by the number of documents in the institutional repository.\nThe number of documents in the institutional repository was taken from ROAR.\nIn addition to the basic URL citation inlinks count, some counts were done of\ninlinks from specific types of domains.\nAn Academic Institution Inlinks Count, which might be more comparable to the\ncitations made between research publications, was found by adding to the basic\nformulation a requirement that linking pages were in the Australasian academic\ndomains, edu.au or ac.nz. So for example the formulation for University of\nAuckland became:\n&quot;researchspace.auckland.ac.nz&quot; -site:auckland.ac.nz site:edu.au OR\nsite:ac.nz\n\nThis of course is only identifying links from Australasian academic institutions,\nand a more global formulation would include all academic domains (.edu, .ac.uk,\nindividual domains of European academic institutions which generally have\nsecond level domain, for example uni-muenchen.de, etc). However this would\nlead to an excessively complex search formulation and it was decided that links\nwithin Australasia would give sufficient indication of the viability of the concept\nof an educational inlinks count.\nAn Academic Inlinks Web Impact Factor was calculated from the academic\ninlinks count, by dividing the academic institution inlinks count by the number of\ndocuments at the repository.\nTo measure the impact of the institutional repositories on the general lay\ncommunity, a Wikipedia inlink count was calculated by adding to the search\nformulation a requirement that links were made from Wikipedia. So for example\nthe formulation for University of Auckland became:\n&quot;researchspace.auckland.ac.nz&quot;\n-site:auckland.ac.nz site:wikipedia.org\n\nA Wikipedia Web Impact Factor was calculated from this by dividing the\nWikipedia inlinks count by the number of documents at the repository. Due to the\nrelatively small number of Wikipedia inlinks in relation to the number of\n1809\n\ndocuments in the repository, the Wikipedia Web Impact Factor was multiplied by\n1000 to give a whole number.\nSeveral conventional measures of research impact were identified and used as\ncomparisons with the impact measures calculated in the study. These were:\n The number of citations/paper for each institution, taken from\nThomson/ISI’s Essential Science Indicators, part of the Web of\nKnowledge. The version used covered documents indexed by ISI in 20022012.\n The overall score from the QS world rankings of universities\n(http://www.topuniversities.com/university-rankings/world-universityrankings/2011). The QS rankings are a widely accepted measure of the\nquality of academic institutions worldwide. Only 26 institutions in the\ncurrent study had QS ranking scores, since only the top 400 institutions\nworldwide were published.\n An average research excellence score derived (Hare &amp; Trounson, 2012)\nfrom the 2010 ERA (Excellence in Research for Australia) research\nassessment carried out by the Australian Research Council. This of course\nwas only available for the 29 Australian institutions in the study.\nThe study also looked at the extent to which an institutional repository contained\na significant proportion of the research output of the institution. Mustatea (2008)\nfound that many institutional repositories only contain a small proportion of the\ninstitution’s publications when compared with the publications indexed in the ISI\ndatabases. In the current study, a ratio, the Deposit Ratio, was calculated. This\nwas the ratio of documents deposited in the institutional repository, compared\nwith the number of papers indexed by ISI in Essential Science Indicators. This is\nof course a crude measure, since there will be documents in the repository that\nwould be not appropriate for indexing by ISI, and outputs indexed by ISI that may\nnot be deposited in the repository for copyright or other reasons.\nResults\nThe study addressed the first research question, “What impact factor measures are\nappropriate for evaluating the impact of institutional repositories on the Web?” by\ninvestigating a range of measures based on URL citation inlink counts to the\nrepositories. The usefulness of these measures is addressed in the answers to the\nfollowing research questions.\nThe second research question asked “Do web based impact factors for\ninstitutional repositories correlate with conventional impact measures of the\nresearch output of institutions?” No correlation was found between the different\nWeb Impact Factors and the conventional measures of research impact. While it is\ndisappointing that the Web Impact Factor of institutional repositories appears not\nto be a useful substitute for conventional measures of research impact, it is not\n1810\n\nsurprising. As mentioned earlier, links to institutional repositories come from\ndifferent sources, and are made for different reasons, than the academic citations\non which conventional measures are partly based. Also, the documents in a\nrepository may include materials not representative of the institution’s research\noutput, including for example student work and digitised material such as\nhistorical photographs. So a Web Impact Factor calculated on the basis of the raw\nnumber of documents in the repository may not be a good measure of the inlinks\nper research output.\nWhen total inlink count is considered, the picture changes a little. For the group\nof repositories as a whole there is no appreciable correlation between the total\ninlink count and the conventional measures. However if only repositories that had\nan Deposit Ratio of more than 1 (the ratio of the number of documents in the\nrepository to the number of papers indexed by ISI was greater than 1) were\nconsidered, there appeared to be small but positive correlations between the total\nlink count from educational institutions and the conventional measures: the ISI\ncitations/paper, the QS score, and the ERA score.\n\nFigure 1. URL citation inlinks from Australasian tertiary institutions (Deposit\nRatio&gt;1) compared with ISI citations per paper (Pearson correlation coefficient\n0.15).\n\nGiven the small numbers, the best indication of the relatively weak correlations\nare the scattergraph representations in Figures 1-3. For reference, the Pearson\n1811\n\ncorrelation coefficients are also included. Note that QS and ERA scores were not\navailable for all institutions. Only repositories with a Deposit Ratio greater than 1\nare included.\n\nFigure 2. URL citation inlinks from Australasian tertiary institutions (Deposit\nRatio&gt;1) compared with QS score (Pearson correlation coefficient 0.14).\n\nFigure 3. URL citation inlinks from Australasian tertiary institutions (Deposit\nRatio&gt;1) compared with ERA score (Pearson correlation coefficient 0.27).\n1812\n\nThis indicates that there may be value in calculating inlink counts that come from\nother research institutions, since these are likely to reflect the research value of\nthe material in the repository. However the weak correlation means that further\nresearch using a larger set of repositories is needed, and that inlink counts for the\ninstitutional repository are unlikely to be a substitute for conventional measures of\nthe research impact of institution as a whole.\nAddressing the third research question, “Do institutional repositories have a\ngreater impact if a higher proportion of their research output is in the institutional\nrepository?” the study compared the Deposit Ratio of the repositories with URL\ncitation inlink counts. This appeared to show a positive correlation. An indication\nof the relationship is shown graphically in Figure 4.\n\nFigure 4. URL citation inlinks from Australasian tertiary institutions compared with\nDeposit Ratio of repository (Pearson correlation 0.68).\n\nIf this correlation is real, it appears to indicate that there is value in an institution\nmaximising the number of research outputs in its repository, for example through\nmandatory deposit of publications. Higher deposit rates increase the visibility of\nthe repository, and the chances of links being made from other research\ninstitutions.\nIn addressing the fourth research question, “Are there specific impact factors that\nreflect the different impact that institutional repositories have?” the study looked\nat the URL citation inlink count for links coming from Wikipedia, as a way of\ngauging the impact of the repositories on the general lay Web community. Neither\n1813\n\nthe Wikipedia inlink count, nor the corresponding Wikipedia Web Impact Factor,\ncorrelated with the conventional measures of research impact. This is to be\nexpected, since Wikipedia has a different purpose than research publishing.\nHowever the Wikipedia inlink count and the Wikipedia Web impact factor\nprovide measures of the extent to which the repository is having an impact on the\ngeneral lay Web community. Table 1 shows the top 10 institutional repositories\nby Wikipedia Web Impact Factor (multiplied by 1000 to bring the figure to an\nintegral number). The Web Impact Factor has been chosen in this case because\nWikipedia is likely to reference many of kinds of documents that are held in\ninstitutional repositories, for example photographs. For comparison, the table also\nshows these institutions’ ranks by the inlink count from Australasian academic\ninstitutions and by their ISI Citations per paper.\nTable 1. Top 10 institutional repositories by Wikipedia Web Impact Factor.\nInstitution\n1. University of Sydney\n2. University of Waikato\n3. Victoria University of Wellington\n4. Bond University\n5. Flinders University\n6. University of Technology Sydney\n7. Massey University\n8. University of Otago\n9. University of Tasmania\n10. University of Canterbury\n\nWikipedia\nWIF\n(x1000)\n60\n19\n15\n13\n12\n10\n9\n5\n5\n5\n\nAcademic\nCitation\nInlink Rank\n14\n17\n24\n16\n25\n7\n15\n30\n11\n13\n\nISI\nCitation/paper\nRank\n5\n21\n27\n36\n16\n35\n23\n4\n15\n22\n\nThis indicates that institutions that have repositories with a significant impact on\nthe general Web may not be those that have high impact in the research\ncommunity.\nIn this study, links from Wikipedia were investigated, but of course links from\nother kinds of Web sites could be measures of the impact of a repository on the\ngeneral Web. For example, links from blogs, Twitter feeds, Facebook, etc could\nbe investigated.\nConclusions\nThis exploratory study has investigated a range of webometric measures to\nevaluate the impact of institutional repositories. This is important given the\nresources that many research institutions are investing in their repositories.\nIt appears that the conventional web impact factor of institutional repositories\ndoes not correlate with conventional measures of research impact. This may be\n1814\n\ndue to the number of documents in a repository not corresponding well with the\nconventional research output of an institution, as well as links being made to\nrepositories for different reasons than citations are made to conventional\npublications. However there appears to be a small correlation between the number\nof links made to repositories from other academic institutions, and some\nconventional measures of research impact, for repositories with a high deposit\nratio. This indicates that webometric measures based on links from research\ninstitutions to institutional repositories could be useful evaluation tools;\nparticularly if the repositories achieve high deposit rates of the institutions\nresearch output. This also indicates that there may be scope for specialist web\ncrawlers, such as the University of Wolverhampton’s SocSciBot\n(http://socscibot.wlv.ac.uk/), to evaluate repositories for their research impact,\nsince it appears that measures based on links from other research institutions,\nrather than the general web, are most valuable in terms of evaluating the research\nimpact of the repository. There may also be value in structuring repositories in\nsuch a way that research material is differentiated from other material such as\nstudent work and digitised images.\nThe study also indicates that the research impact of a repository, as measured by\nthe inlink counts from other tertiary institutions, may be enhanced by high deposit\nrates. While this is not surprising, it is a useful indicator to institutions that it is\nbeneficial to encourage researchers to deposit their work in the repository.\nThe study also investigated measures of the repositories’ impact on the general\nweb. The specific example of links from Wikipedia was explored, showing that\ninstitutions whose repositories had a high impact in terms of their Wikipedia Web\nImpact Factor were not necessarily those that had a high conventional research\nimpact. This reflects institutional repositories’ value as a way of making research\navailable to the general Web community, as well as to the research community.\nThis exploratory study is limited by being carried out on a limited number of\ninstitutions in a specific geographic area. Future research should see if the\nfindings can be replicated over a broader sample of repositories. There is also\nscope for studies of the repositories’ impact on the general Web, looking at\nwebsites such as blogs, Twitter and Facebook.\nReferences\nAguillo, I., Ortega, J., Fernández, M., &amp; Utrilla, A. (2010). Indicators for a\nwebometric ranking of open access repositories. Scientometrics, 82(3), 477486.\nAlmind, T. C., &amp; Ingwersen, P. (1997). Informetric analyses on the world wide\nweb: Methodological approaches to “Webometrics”. Journal of\nDocumentation, 53(4), 404–426.\n\n1815\n\nGairin, J. R. (1997). Valoracion del impacto de la informacion en internet:\nAltavista, el &quot;citation index&quot; de la red. impact assessment of information in the\ninternet: Altavista, the citation index of the web. Revista Espanola De\nDocumentacion Cientifica, 20(2), 175-81.\nHare, J., &amp; Trounson, A. (2012). Excellence in research for Australia lays bare\nresearch myths. The Australian, (4/12/2012) Retrieved January 18 2013 from:\nhttp://www.theaustralian.com.au/higher-education/excellence-in-research-foraustralia-lays-bare-research-myths/story-e6frgcjx-1225998312883\nKousha, K., &amp; Thelwall, M. (2007). Google scholar citations and Google\nWeb/URL citations: A multi-discipline exploratory analysis. Journal of the\nAmerican Society for Information Science &amp; Technology, 58(7), 1055-1065.\nMustatea, N. (2008). To what extent is material in institutional repository\nrepresentative of an institution&#x27;s research output? Report submitted to the\nSchool Of Information Management, Victoria University of Wellington in\npartial fulfilment of the requirements for the degree of Master of Library And\nInformation Studies.\nOrtega, J. L., &amp; Aguillo, I. F. (2009). Mapping world-class universities on the\nweb. Information Processing &amp; Management, 45(2), 272-279.\nScholze, F. (2007). Measuring research impact in an open access environment.\nLiber Quarterly: The Journal of European Research Libraries, 17(1-4), 220232.\nShukla, S. H., &amp; Poluru, L. (2012). Webometric analysis and indicators of\nselected Indian state universities. Information Studies, 18(2), 79-104.\nSmith, A. G. (2011). Wikipedia and institutional repositories: An academic\nsymbiosis? Proceedings of the ISSI 2011 Conference, Durban, South Africa.\n(pp. 794-800)\nSmith, A. G. (2012). Webometric evaluation of institutional repositories.\nProceedings of the 8th International Conference on Webometrics Informetrics\nand Scientometrics (WIS) &amp; 13th COLLNET 2012 Meeting, Seoul, Korea. (pp.\n722-729).\nSmith, A. G., &amp; Thelwall, M. (2002). Web impact factors for Australasian\nuniversities. Scientometrics, 54(3), 363–380.\nThelwall, M., &amp; Sud, P. (2011). A comparison of methods for collecting web\ncitation data for academic organizations. Journal of the American Society for\nInformation Science and Technology, 62(8), 1488-1497.\nZuccala, A., Thelwall, M., Oppenheim, C., &amp; Dhiensa, R. (2007). Web\nintelligence analyses of digital libraries: A case study of the National\nElectronic Library For Health (NeLH). Journal of Documentation, 63(4), 55889.\n\n1816\n\nWHAT IS THE IMPACT OF SCALE AND\nSPECIALIZATION ON THE RESEARCH\nEFFICIENCY OF EUROPEAN UNIVERSITIES?177\nAndrea Bonaccorsi1, Cinzia Daraio2* and Léopold Simar3\n1\n\na.bonaccorsi@gmail.com\nDipartimento di Ingegneria dell&#x27;Energia dei Sistemi del Territorio e delle Costruzioni,\nUniversity of Pisa (Italy)\n2\n\ndaraio@dis.uniroma1.it\n* Corresponding author.\nDepartment of Computer, Control and Management Engineering Antonio Ruberti,\nUniversity of Rome “La Sapienza”, via Ariosto, 25 I-00185 Roma (Italy)\n3\n\nleopold.simar@uclouvain.be\nISBA, Université Catholique de Louvain, Louvain-la-Neuve (Belgium)\n\nAbstract\n\nThe main objective of this paper is to analyse the impact of size and specialization on the\nresearch efficiency of European universities. The proposed approach builds on the notion\nthat university production is a multi-input multi-output process different than standard\nproduction activity (Bonaccorsi and Daraio, 2004). We apply a conditional efficiency\nanalysis approach (Badin, Daraio and Simar, 2012a,b; Daraio and Simar, 2007) in a\ndirectional distance framework to evaluate the impact of size and specialization on the\nresearch efficiency of 401 European universities, from 19 European countries. Data refer\nmainly to the year 2008 and include universities that in 2005-2009 have published at least\n100 publications in Scopus database.\nIn particular we assess the impact of scale and specialization distinguishing their role on\nthe efficient frontier and on the distribution of inefficiencies. Size seems to have a\nnegative impact on most efficient units and on units that are lagging behind. On the\ncontrary, specialization seems to have a slightly positive impact on the best performers\nand on catching-up universities.\n\nKeywords\n\nresearch evaluation,\nuniversities.\n\nquantitative\n\napproach,\n\nscientometric\n\nindicators,\n\nEuropean\n\nConference Topics\n\nScience Policy and Research Evaluation: Quantitative and Qualitative Approaches (Topic\n3) and Scientometrics Indicators (Topic 1).\n177\n\nL. Simar acknowledges research support by IAP Research Network P7/06 of the Belgian State\n(Belgian Science Policy).\n1817\n\nIntroduction and policy relevance\nEconomies of scale and scope in academic activities are the object of a new\ninterest.\nThe interest in the issue of economies of scale has a number of motivations. From\na policy point of view, it is important to determine whether larger units are more\nefficient in order to allocate public funding departing from a pure proportional\nformula. In some cases this has led to an explicit policy of consolidation of\nuniversities. The most known case was the Australian government decision in the\nlate 1980s to define a minimum threshold of student size (in the range 5000-8000\nstudents) in order to force universities to merge. More recently the Swedish\ngovernment has promoted a policy of consolidation. In almost all cases the\nunderlying assumption has been that small universities are inefficient.\nFrom the administrator point of view the issue of economies of scale is also\nrelevant, however. Small universities may be interested in understanding whether\ntheir size is financially sustainable in the long run, and those universities that aim\nto grow may want to know at which size the increases in efficiency are exhausted.\nIt is not surprising that a large literature has been developed on the issue of\neconomies of scale. Brinkman and Leslie (1986) review the first 60 years of\nempirical studies, most of which from United States. After almost 20 years, Cohn\nand Cooper (2004) have offered a comprehensive survey of findings from the cost\nfunction perspective, while Johnes (2004) has reviewed the efficiency literature.\nIn turn, economies of scope are also discussed at length. One of the interests is in\nidentifying and measuring the complementarity between teaching and research,\nwhich is at the core of the Humboldtian model of university (Schimank and\nWinnes, 2000).\nEconomies of scope emerge from the joint use of common inputs (Baumol,\nPanzar and Willing, 1982). In the case of universities, the common input is the\nhuman capital of professors and researchers. It is important to ask whether the\ncost of producing separately teaching and research would be lower than producing\nthem together, keeping quality constant. The overwhelming evidence is that it is\nmore efficient to organize teaching and research in the same organization, asking\nacademic staff to allocate their time budget accordingly (Johnes, 2004). For\nexample, Dundar and Lewis (1995) found that joint production is more efficient\nup to 300% of mean output in a sample of US universities, due to joint utilization\nof faculty, administrators, support staff, equipment and services. Longlong et al.\n(2009) argued that a reform of the Chinese system that forced researchers in the\ntraditional Academy system to teach would generate a large increase in efficiency\ndue to pervasive economies of scope at all levels of output.\nBonaccorsi, Daraio and Simar (2013), illustrate in details how to measure the\nimpact of scale and scope in a directional distance framework, extending the\napproach of Simar and Vahnems (2012). A directional distance framework is\nmore flexible with respect to the traditional radial approach, because it allows to\nchoose the direction along which to assess the distance from the efficient frontier\n\n1818\n\nand allows to include, in an easy way, non-discretionary inputs/outputs in the\nanalysis.\nThe main objective of this paper is to analyse the impact of size and specialization\non the research efficiency (given their level of teaching) of European universities\nthat in 2009 have published at least 100 publications (including any type of\ndocuments, that is, articles, reviews, short reviews, letters, conference papers, etc)\nin Scopus database.\nIn this paper we apply the approach of Bonaccorsi, Daraio and Simar (2013) that\nbuilds on the notion that university production is a multi-input multi-output\nprocess in which, differently from standard production activity, the relationship\nbetween inputs and outputs is not deterministic (Bonaccorsi and Daraio, 2004).\nIn particular we assess the impact of scale and specialization separately and then\njointly, distinguishing their role on the efficient frontier and on the distribution of\ninefficiencies.\nMethodology\nFrom a methodological point of view, there have been two major research\ndirections.\nThe first has worked directly with cost functions as the dual of production\nfunctions. Here the main difficulty has been the modelling of a production\nfunction which is, by definition, not only multi-input (as any production\nfunction), but also multi-output. The traditional econometric techniques used to\nestimate economies of scale in a monoproduct setting were clearly inadequate.\nThe turning point has been the development of a full scale theory of multiproduct\nfirm by Baumol, Panzar and Willig (1982), who introduced the distinction\nbetween ray economies of scale (long run average costs decrease with the increase\nin the volume of production of all outputs, keeping the proportion between\nvarious outputs constant) and product-specific economies of scale (average costs\nfor each product decrease with the increase in the volume of that specific output).\nAnother development was the rigorous definition of economies of scope. Based\non this theory, several solutions to the problem of econometric specification were\nsuggested, with the flexible fixed quadratic cost function (FFQC), the translog\nand the constant elasticity of scale (CES) as the most adopted solutions. In this\nline of research the existence and magnitude of economies of scale and scope is\nderived from the sign and size of the coefficients directly estimated on cost data.\nThe second has adopted the approach introduced by Farrell (1957), based on\nfrontier analysis techniques. In this line of research most studies applying a\nnonparametric approach (see e.g. Grosskopf and Yaisawarng, 1990) have\nfollowed the approach developed by Fare (1986) by which, the existence and\nmagnitude of economies of scale and scope is derived from the difference\nbetween the efficiency scores of observed DMUs and the scores that would be\nobtained if the specialized DMUs were aggregated. However, also this approach\nsuffers from some weaknesses. Firstly, it introduces a sample size bias because\n1819\n\nthe number of DMUs is artificially increased, secondly it is sensitive to extremes\nor outliers in the data; and thirdly it always relies on the convexity assumption\nbecause data envelopment analysis is applied.\nIn this paper we apply a more general approach (Bonaccorsi, Daraio and Simar,\n2013) to investigate on the existence of economies of scale and scope. It is based\non a directional distance approach, its probabilistic characterization and uses\nnonparametric, nonconvex and robust to outliers efficiency estimators for the\ninvestigation of the impact of scale and scope as external environmental\nconditions.\nEfficiency analysis techniques rely on the basic and intuitive idea of efficiency as\nthe best use of resources (i.e. use of the lowest levels of inputs, x) to produce the\nmaximum feasible amount of outputs (y). Related to efficiency is the concept of\ndominance that consists in using no more inputs to produce at least the same level\nof outputs and in doing better in at least one dimension.\nIn particular, technical efficiency can be operationalized in terms of input or\noutput distance functions or can be measured with respect to a specific direction.\nThe distance of each unit is measured with respect to the frontier of the\nproduction possibility set, , defined as:\n{(\n\n(1)\n\n}.\n\n)\n\nThe popular Farrell (1957) output distance of the unit (x,y) from the frontier of ψ\nis given by:\n(\n\n)\n\n{\n\n(\n\n)\n\n(2)\n\n},\n\nand it measures the maximum feasible proportionate expansion of all outputs (y)\nattainable given the inputs level used (x).\nDirectional distances have been introduced by Chambers, Chung and Fare (1998)\nand are discussed at length in e.g. Fare and Grosskopf (2000). They are a\ngeneralization of the Farrell’s approach. The objective of directional distances is\nto look for improvements in approaching the frontier in a given direction\n(\n).\nA directional function, that we name also gap function, g, can be defined as:\n(\n\n)\n\n{\n\n( -\n\n)\n\n}.\n\n(3)\n\nAs it can be seen by its definition, the directional or gap function g is “additive”\nbecause it gives the amount or “gap” that has to be subtracted from the input x\nand at the same time has to be added to the output y in the units of the direction d\nto reach the frontier. On the contrary, the traditional Farrell output oriented\ndistance function is multiplicative and can be obtained as a special case from the\n1820\n\ndirectional distance, by choosing as direction d=(0,y), that is to select units own\noutputs as the direction vector.\nIt is immediate to note that the directional efficiency g, in this last specific case\ncorresponds to the Farrell output efficiency score as follows:\n(\n\n)\n\n(\n\n(4)\n\n)-\n\nIf a unit has a Farrell efficiency score ( )\n, this means that its gap or\ndirectional efficiency score will be g=0.2 and this means that the unit has a gap of\n20% in its output production: it can increase the production of its outputs by 20%.\nNote that the gap fuction expresses the possible improvements in units given by\nthat in our case here corresponds to the own outputs of the analysed unit.\nAlthough in the traditional output oriented approach\nand\ncorresponds\nto points that are on the efficient frontier; in the directional distance framework,\nand a unit that is on the efficient frontier has a\n.\nHaving introduced the framework, we can now reformulate the setting in a\nprobabilistic way. Following Daraio and Simar (2005), the joint probability\nmeasure of (X,Y) and the associated probability of being dominated, HXY(.) can\nbe defined as:\n(\nand\n\n)\n\n(\n\n(5)\n\n)\n\nis the support of (X,Y), i.e.:\n{(\n\n)\n\n(\n\n(6)\n\n}.\n\n)\n\nIn this framework, Simar and Vanhems (2012) define a probabilistic version of a\ndirectional distance as follows:\n(\n\n)\n=\n\n{\n\n{\n( -\n\n( -\n\n)\n)\n\n}=\n\n(7)\n\n}\n\nA consistent nonparametric estimator of g(x,y;Ѱ,dx,dy) can be obtained by\nplugging a consistent nonparametric estimator of HXY(.) in equation (7). For\nfurther details, see Bonaccorsi, Daraio and Simar (2013).\nIn the lines of Daraio and Simar (2005), Simar and Vanhems (2012) introduce\nconditional directional distances as follows. Be\nan external or\nenvironmental variables set that might influence the production process without\nbeing inputs or outputs under the control of the unit. The conditional directional\ndistance efficiency score g(.|z) measures the gap efficiency score given or\nconditioned by the external or environmental factors Z, and can be defined as\nfollows:\n1821\n\n(\n\n)\n\n{\n\n( -\n\n)\n\n}\n\n(8)\n\nA consistent nonparametric estimator of g(.|z) can be obtained by plagging a\nconsistent nonparametric estimator of\n( ) in equation (8). For further details,\nsee Bonaccorsi, Daraio and Simar (2013).\nAccordingly, also robust versions of these conditional directional distances can be\ndefined being less influenced by extremes or outliers, namely directional distance\nof order-m or order-α. Following Daraio and Simar (2005, 2007) the comparison\nof conditional efficiency scores, i.e. efficiency scores computed taking into\naccount the external factors Z, with unconditional efficiency scores (the efficiency\nscores computed without taking into account the Z factors) is important to shed\nlights on the influence of external or environmental variables on the performance\nof the analysed units. In particular, in the lines of Daraio and Simar (2005; 2007),\nthe investigation of the ratios between conditional and unconditional directional\nefficiency scores is relevant to assess the impact of Z on the production process of\nthe analysed units. We define δ(Z) as the following ratio:\n( )\n\n(\n\n)\n\n(\n\n)\n\n(9)\n\nand in the following we indicate its robust version as ( )178.\nIn this framework, an increasing trend (increasing regression line) of the δs with Z\nindicates a positive impact of the external factor (Z), whilst a decreasing trend\n(decreasing regression line) of δs with Z points to a negative impact of Z on the\nproduction process. A straight nonparametric regression line indicates no effect of\nZ on the production process. This is because when Z is favourable to the\nproduction process we expect that the conditional directional distances (defined in\nequation 8) will be much smaller compared to the unconditional ones for small\nvalues of Z. Therefore, the ratios (defined in equation 9) will increase with Z, on\naverage. On the contrary, when Z is detrimental to the production process, the\nvalues of the conditional directional distances will be much smaller compared to\nthe unconditional ones for larger values of Z. For this reason, the nonparametric\nregression line of over Z will be decreasing.\nWe adopt a directional distance framework in which we assess the distance from\nthe frontier taking a specific direction. The direction is the factor of research\n(FRES) given the teaching activity carried out (TODEG5) and given the level of\ninputs used. In this framework, we assess the impact of size and specialization on\nthe efficient frontier and on the distribution of inefficiency. After an analysis of\ntheir impact in isolation, we investigate their joint effect.\n\n178\n\n)\n\nIt has to be noted that when (\n, because\n(\n\n1822\n\n)\n)\n\n(\n\n, then, by construction (\n), and so ( )\n\nData\nWe exploit a large database, recently constructed by the EUMIDA Consortium\nunder a European Commission tender, supported by DG EAC, DG RTD, and\nEurostat. This database is based on official statistics produced by National\nStatistical Authorities in all 27 EU countries (with the exception of France and\nDenmark) plus Norway and Switzerland. The EUMIDA project, relying on the\nresults of the Aquameth project (Bonaccorsi and Daraio, 2007; Daraio et al. 2011)\nincluded two data collections: Data Collection 1 (DC 1) included all higher\neducation institutions that are active in graduate and postgraduate education (i.e.\nuniversities), but also in vocational training. Data refer to 2008, or to 2009 in\nsome cases.\nOf these institutions, 1364 are defined research active institutions: of these only\n850 are also doctorate awarding. They are the object of Data Collection 2 (DC 2),\nfor which a larger set of variables were collected.\nTable 1. Definitions of inputs, outputs and conditioning factors\nInput/Output/Conditioning factor\nInput\nNACSTA\nACSTAF\nPEREXP\nNOPEXP\nFINP\nOutput\nTODEG5\nTODEG6\nINTPUB\nFRES\nConditioning factors\nTOTSTUD\nSPEC\n\nDefinition\nNumber of non academic staff\nNumber of academic staff\nPersonnel expenditures in PPS\nNon-personnel expenditures in PPS\nInput factor or input index including:\nNACSTA,ACSTAF,PEREXP,NOPEXP\nTotal Degrees ISCED5\nTotal Degrees Doctorate\nNumber of published papers in Scopus (Scimago)\nFactor of research or research index, including:\nTODEG6, INTPUB\nProxy of size. It is given by Total Students\nenrolled ISCED 5+ Total Students enrolled\nISCED 6\nSpecialization Index of the scientific output\n(Scimago)\n\nSource: Eumida DC 2 and Scimago.\n\nWe integrate the EUMIDA data, in particular the DC 2 dataset, with the Scimago\ndata (SIR World Report 2011, period analyzed 2005-09) that include institutions\nthat have published at least 100 scientific documents of any type during the years\n2005-2009 as collected by Scopus database. From Scimago data we used in\nparticular the number of publications in Scopus (including any type of documents,\nthat is, articles, reviews, short reviews, letters, conference papers, and so on,\ncalled hereafter INTPUB) and the Specialization index (SPEC) of the university\n1823\n\nthat indicates the extent of thematic concentration-dispersion of an institution’s\nscientific output; its values range between 0 to 1, indicating generalistic vs.\nspecialized institutions respectively. This indicator is computed according to the\nGini Index and in our analysis it is used as a proxy of the specialization of the\nuniversity. Table 1 defines and describes the inputs, outputs and conditioning\nfactors that are used in the following analysis.\nThe monetary values are expressed in purchasing power standard (PPS). The\nconversion was carried out by dividing the values expressed in national currency\nby the respective Purchasing Power Parity (Eurostat PPP_EU27 - Purchasing\npower parities EU27 = 1, for the education sector), for the year 2008.\nThe final number of universities considered in the analysis is 401 and they come\nfrom 19 European countries. We excluded in fact, universities for which\nexpenses, or number of academic staff or number of students, or number of\npublications data were not available.\nThe following Table 2 shows some descriptive statistics on inputs, outputs and\nconditioning factors used in the analysis.\nTable 2. Descriptive statistics on inputs, outputs and conditioning factors- whole\nsample (401 obs.)\nNACSTA\nACSTAF\nPEREXP\nNOPEXP\nTODEG5\nTODEG6\nINTPUB\nTOTSTUD\nSPEC\n\nMinimum\n59.00\n65.00\n4501077.76\n5104884.60\n.00\n.00\n300.00\n331.00\n.40\n\nMaximum\n8606.00\n6571.00\n674760008.45\n699593733.99\n28215.00\n1855.00\n33610.00\n181693.00\n1.00\n\nMean\n1496.89\n1470.21\n142577882.82\n87111330.32\n3881.57\n200.72\n5570.78\n20258.25\n.69\n\nStd. Deviation\n1408.39\n1058.13\n121662901.93\n94924980.37\n3146.21\n214.42\n5625.99\n17485.77\n.13\n\nResults\nWe run a preliminary descriptive analysis on the variables reported in Table 1 and\nwe decided, on the base of this investigation, given the very high correlations\nfound (higher than 0.90), to aggregate the inputs (NACSTA, ACSTAF, PEREXP,\nNOPEXP) in a single input index, named FINP, and two of the outputs\n(TODEG6, INTPUB), highly correlated, in a research index, named FRES.\nThe model formulated for the estimation of the technical efficiency of European\nuniversities is based on a output oriented directional distance function, in which\nwe use the input index as an input and two outputs, namely the research index and\nthe Total number of Degrees at ISCED5 level (TODEG5), keeping this last one as\na nondiscretionary output. Summing up, we estimate the technical efficiency of\nEuropean universities in their research activity, proxied by the research index,\n1824\n\ngiven the level of teaching they are running, as proxied by TODEG5. We estimate\nseveral nonparametric and nonconvex efficiency scores that are summarized in\nTable 3, where we report some descriptive statistics on the computed efficiency\nscores. N_DOM is the number of points that dominate the analysed unit; on\naverage the European universities analysed in this paper, are dominated by 7 other\nEuropean universities; however, an high variation exists as N_DOM goes from a\nminimum value of 0 to a maximum value of 95.\nFDH_DIR is the output directional distance efficiency measure computed on a\nFree Disposal Hull estimator (Deprins, Simar and Tulkens, 1984).\nGAPS_TODEG6 measures the existing gap (compared to the most efficient units)\non the variable TODEG6 existing when an FDH_DIR efficiency approach have\nbeen applied. The European universities analysed in this paper, given their inputs\nand the level of teaching which are carrying out, could have produced on average\n79 more Doctorate Degrees (TODEG6).\nGAPS_INTPUB measures instead the existing gap in the production of number of\npapers (INTPUB); on average the European universities in our sample could\nproduce 2114 more papers, given their inputs and their level of teaching.\nRobust_DIR is the output directional distance efficiency measure computed on a\nrobust nonparametric estimator that does not envelop the 5% of most efficient\nunits in the sample. The following gaps reported in Table 3.\nRob_GAPS_TODEG6 and Rob_GAPS_INTPUB, are the estimated gaps, in\nTODEG6 and in INTPUB respectively, obtained by applying Robust_DIR\ndirectional efficiency measure, and are computed taking out from the comparison\nthe 5% of the most efficient units. It appears that the European universities\nanalysed could produce, on average, 22 more Doctorate Degrees and could\npublish 578 more papers. The high standard deviation of the robust gaps and the\nbig range of variation of gaps (from -384 to 372 for TODEG6; from -10305 to\n9970 for INTPUB) points to the existence of heterogeneous results. This\nheterogeneity could be due also to differences in the data available for the\ndifferent countries and more investigations on the comparability and reliability of\ndata have to be carried out.\nTable 3. Descriptive statistics on the efficiency analysis results (whole sample 401\nobs.)\nN_DOM\nFDH_DIR\nGAPS_TODEG6\nGAPS_INTPUB\nRobust_DIR\nRob_GAPS_TODEG6\nRob_GAPS_INTPUB\n\nMinimum\n.00\n.00\n.00\n.00\n-.49\n-384.33\n-10305.40\n\nMaximum\n95.00\n9.81\n581.31\n15588.00\n9.08\n371.82\n9969.95\n\nMean\n7.05\n.76\n78.83\n2113.66\n0.53\n21.54\n577.62\n\nStd. Deviation\n12.58\n1.23\n99.30\n2662.61\n1.21\n79.73\n2137.88\n\nNote: robust efficiency scores calculated with alpha=0.95.\n\n1825\n\nDetailed summary statistics by country are not reported to save space.\nAfter that, we analysed the impact of size and of scientific specialization, firstly in\nisolation and after that jointly. Size is proxied by the total number of enrolled\nstudents at all levels (both graduate and post graduate ones), TOTSTUD, while\nthe scientific specialization is proxied by the variable SPEC.\nConsidered in isolation, we observed that size seems to have no effect on the\nresearch efficiency of the analysed European universities, given their level of\nteaching. In particular, Size does not have any clear effect on the most efficient\nuniversities, and seems to have almost no effect on the universities that are\nlagging behind. A similar effect is observed for scientific specialization. It seems\nthat SPEC does not play any role on the efficiency if considered in isolation.\nThe joint impact of size and specialization is illustrated in the following figures.\nFigure 1 illustrates the impact of size and specialization on the efficient frontier of\nanalysed units. In particular, the 3-dimensional plot reported on the left illustrates\nthe ( ) defined in equation (9), i.e. the ratios between conditional and\nunconditional efficiency scores, versus the conditioning factors, Z, that in this\ncase are size (Z1) and specialization (Z2). The two panels reported on the right\nillustrate the marginal effect of each Z variable on the efficient frontier. The top\npanel on the right of Figure 1 reports the impact of size on the efficient frontier;\nwhilst the bottom panel on the right of Figure 1 presents the impact of\nspecialization on the efficient frontier of units. Globally, it appears that there is an\nU-shape effect of size (Figure 1 top panel on the right): up to around 45000\nenrolled students (TOTSTUD) we observe a decreasing trend of the deltas which\npoints to a negative impact of size on the research efficiency of universities\nwhilst, after 45000 TOTSTUD we see a small range of increasing trend (positive\nimpact) which should be interpreted with care, because it is determined only by a\nfew large universities. On the contrary, SPEC seems to have an homogeneous or\nslightly increasing trend on research efficiency (Figure 1 bottom panel on the\nright).\nFigure 2 shows the impact of size and specialization on the distribution of\ninefficiencies of the analysed units. The 3-dimensional plot reported on the left\nillustrates the ( ) that are the robust deltas computed with respect to a median\nfrontier (to catch the impact on the average of the distribution of the inefficiencies\nand not on the most efficient boundary as in the previous figure) versus the\nconditioning factors size (Z1) and specialization (Z2). The top panel on the right of\nFigure 2 presents the impact of size on the distribution of inefficiencies; whilst the\nbottom panel on the right of Figure 2 shows the impact of specialization on the\nunits that are lagging behind. Generally, it seems that there is a negative impact of\nsize on the distribution of inefficiencies among universities (decreasing trend, see\nFigure 2 top panel) whilst specialization seems to have an inverted U-shape effect\nwith a positive impact (up to 0.8) and then a negative impact, even if in the range\nwith SPEC higher than 0.8 there are only a few observations (see Figure 2 bottom\npanel).\n1826\n\nEffect of Z1 on the frontier\n\n(Z)\n\n0.5\n\n0.8\n\n(Z)\n\n0.6\n\n0.4\n0.3\n0.2\n0.5\n\n1\n\n1.5\n\n2\n\n0.4\n\n2.5\n\n3\n\n3.5\n\n4\n\n4.5\n\n5\n\nvalues of Z\n\n4\n\nx 10\n\n1\n\nEffect of Z2 on the frontier\n\n0.2\n\n6\n\n0.8\n\n(Z)\n\n0.5\n\n0\n1\n4\n0.6\nZ2\n\n0\n\n0.3\n0.2\n\n4\n\n2\n0.4\n\n0.4\n\nx 10\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nvalues of Z2\n\nZ1\n\nFigure 1. Joint impact of Size -TOTSTUD (Z1) and Specialization - SPEC (Z2) on\nthe efficient frontier (of research given teaching).\n\n1.5\nEffect of Z on the distribution of inefficiency\n\n1\n\n1\n\n1\n\n\n (Z)\n\n(Z)\n\n0.5\n0\n\n0.5\n0\n\n1\n\n-0.5\n\n2\n\n3\n\n4\n\n5\n\n6\n\nvalues of Z\n\n4\n\nx 10\n\n1\n\nEffect of Z on the distribution of inefficiency\n2\n\n-1\n1\n\n1\n\n0.6\n0.5\nZ2\n\n0.4\n\n0\n\nZ1\n\n1\n\n\n1.5\n\n (Z)\n\n2\n\n0.8\n\n5\n\nx 10\n\n0.5\n0\n\n0.4\n\n0.5\n\n0.6\n\n0.7\n\n0.8\n\n0.9\n\n1\n\nvalues of Z\n\n2\n\nFigure 2. Joint impact of size -TOTSTUD (Z1) and Specialization - SPEC (Z2) on the\ndistribution of inefficiency.\n\nConclusions\nIn this paper we apply a general approach (Bonaccorsi, Daraio and Simar, 2013)\nto investigate on the existence of economies of scale and scope in research\nefficiency of European universities given their level of teaching. It is based on a\ndirectional distance approach, its probabilistic characterization and uses\nnonparametric, nonconvex and robust to outliers efficiency estimators for the\ninvestigation of the impact of scale and scope as external environmental\nconditions.\nWe disentangled the impact of scale and specialization distinguishing their role on\nthe efficient frontier and on the distribution of inefficiencies. We find that size\nseems to have a negative impact on most efficient units and on the distribution of\ninefficiencies, with the exception of a few large universities that remain isolated.\nOn the contrary, specialization seems to be positive both for efficient units and for\nunits that are lagging behind, except for a few highly specialized universities that\nseems to suffer from a negative impact of SPEC on the research efficiency.\n1827\n\nThe great heterogeneity in the performance found, shows that there exists large\ndifference across European universities. This heterogeneity could also be due to\ndifferences in the data available for the different countries and more\ninvestigations on the comparability and reliability of data have to be carried out.\nSelected References\nBadin L., Daraio C., Simar L. (2012a), How to Measure the Impact of\nEnvironmental Factors in a Nonparametric Production Model, European\nJournal of Operational Research, 223, 818–833.\nBadin L., Daraio C., Simar L. (2012b) Explaining Inefficiency in Nonparametric\nProduction Models: the State of the Art, Annals of Operations Research, DOI\n10.1007/s10479-012-1173-7.\nBaumol, W.J., J.C. Panzar and R.D. Willig (1982), Contestable Markets and the\nTheory of Industry Structure, New York: Harcourt Brace Jovanovich.\nBonaccorsi A., Daraio C. (2004), “Econometric approaches to the analysis of\nproductivity of R&amp;D systems. Production functions and production frontiers”,\nin H.F. Moed, W. Glanzel and U. Schmoch (edited by), Handbook of\nQuantitative Science and Technology Research, Kluwer Academic Publishers,\n51-74.\nBonaccorsi A., Daraio C. (2005), “Exploring size and agglomeration effects on\npublic research productivity”, Scientometrics, Vol. 63, No. 1, 87–120.\nBonaccorsi A., Daraio C. (2007), eds, Universities and Strategic Knowledge\nCreation. Specialization and Performance in Europe, Edward Elgar Publisher,\nCheltenham (UK).\nBonaccorsi, A., Daraio C., Simar, L. (2006), “Advanced indicators of productivity\nof universities. An application of Robust Nonparametric Methods to Italian\ndata”, Scientometrics, Vol. 66, No. 2, 389-410.\nBonaccorsi A., Daraio C. and Simar L. (2013), Economies of scale and scope\nusing directional distances with Application to European universities,\nTechnical report DIAG, Roma.\nBrinkman, P.T. and L.L. Leslie (1986) “Economies of scale in higher education:\nSixty years of research”. The Review of Higher Education, 10 (1), 1-28.\nCohn E. and S.T. Cooper (2004) ‘Multi-product cost functions for universities:\neconomies of scale and scope’. In G. Johnes and J. Johnes (Eds.), The\nInternational Handbook on the Economics of Education. Cheltenham: Edward\nElgar.\nDaraio C., Simar, L. (2005), “Introducing Environmental Variables in\nNonparametric Frontier Models: a Probabilistic Approach”, The Journal of\nProductivity Analysis, 24 (1), pp. 93-121.\nDaraio C., Simar L. (2007), Advanced Robust and Nonparametric Methods in\nEfficiency Analysis. Methodology and Applications, Springer, New York\n(USA).\n\n1828\n\nDaraio C. et al. (2011), The European University landscape: A micro\ncharacterization based on evidence from the Aquameth project, Research\nPolicy, 40, 148–164.\nDundar, H. and D.R. Lewis (1995) ‘Departmental productivity in American\nUniversities: Economies of scale and scope’. Economics of Education Review,\n14(2), 119–144.\nFare, R, (1986) Addition and efficiency, Quarterly Journal of Economics, 101(4),\n861-865.\nFarrell, M. (1957), ‘The measurement of productive efficiency’, Journal of the\nRoyal Statistical Society, Series A, 120, 253–81.\nGrosskopf, S., S. Yaisawarng, (1990), Economies of scope in the provision of\nlocal public services, National Tax Journal, 43(1), 61-74.\nJohnes, J. (2004). ‘Efficiency measurement’. In G. Johnes, &amp; J. Johnes (Eds.),\nThe International Handbook on the Economics of Education. Cheltenham:\nEdward Elgar.\nLonglong, H., L. Fengliang, M. Weifang (2009). ‘Multi-product total cost\nfunctions for higher education: The case of Chinese research universities’.\nEconomics of Education Review, 28, 505–511.\nSchimank U. and M. Winnes (2000), ‘Beyond Humboldt? The relationship\nbetween teaching and research in European university systems. Science and\nPublic Policy, 27, 398-408.\nSimar, L. and Vanhems A. (2012), Probabilistic Characterization of Directional\nDistances and their Robust Versions, Journal of Econometrics, 166, 342-354.\n\n1829\n\nWHICH FACTORS HELP TO PRODUCE HIGH\nIMPACT RESEARCH? A COMBINED\nSTATISTICAL MODELLING APPROACH\nFereshteh Didegah1, Mike Thelwall2, Paul Wilson3\n1\n\n1,2,3\n\nf.didegah@wlv.ac.uk, 2m.thelwall@wlv.ac.uk, 3pauljwilson@wlv.ac.uk\nStatistical Cybermetrics Research Group, School of Technology, University of\nWolverhampton, Wulfruna Street, Wolverhampton WV1 1LY UK\n\nAbstract\n\nThis study uses an appropriate statistical model to simultaneously assess five factors under\nthe control of researchers that may help to produce highly cited research: individual\ncollaboration; institutional collaboration; international collaboration; research funding;\nand abstract readability in Biology &amp; Biochemistry, Chemistry and Social Sciences. Using\na negative binomial-logit hurdle model, the results show that individual collaboration is a\nsignificant determinant of citation counts in all three areas. Institutional teamwork gives a\ncitation advantage in Social Sciences but international teamwork shows no significant\nassociation with citation counts. Research funding very significantly associates with\nincreased citation counts in Biology &amp; Biochemistry and Chemistry but abstract\nreadability is not found to be significant. In summary, individual teamwork and research\nfunding are the keys to high impact research, at least in these three areas.\n\nConference Topic\n\nScientometrics Indicators: Introduction\n- Criticism and new developments\n- Relevance to Science and Technology, Social Sciences and Humanities (Topic 1).\n\nIntroduction\nConducting high impact research seems to be a common goal for researchers. For\nexample, the link between excellent writing skills and high impact research has\nbeen extensively discussed, mainly based upon the advice of senior researchers\n(Zimmerman, 1989). Citation counts are widely acknowledged as the main\nresearch impact indicator and empirical studies have been carried out to seek\nassociations between citation counts and various objective and easily measurable\nproperties of the research. These include the impact of the publishing journal\n(Boyack &amp; Klavans, 2005), research collaboration (Gazni &amp; Didegah, 2010), the\ninterdisciplinarity of the article references (Larivière &amp; Gingras, 2010), the\nnumber and impact of references (Boyack &amp; Klavans, 2005), and the size of the\nrelated field (Lovaglia, 1989).\nBased on the above findings, authors seeking to maximise the impact of their\nresearch may select high impact journals to publish in and may also be\nparticularly careful to ensure that their literature review does not miss any\n1830\n\nrelevant highly cited papers. If they wish to conduct high impact type of research\nthen they may also seek to engage in collaborations (hence generating more coauthors). Nevertheless, unscrupulous scholars may even examine lists of\nsignificant factors associated with increased citations and try to manipulate those\nthat they have control over. For example they may invite scholars to be co-authors\nwhen their contribution does not merit it or cite largely irrelevant high impact\nwork.\nThis study examines the association between research collaboration, research\nfunding and article abstract readability and citation counts. The goal is to assess\nwhich factors under the control of researchers are most important for the\nproduction of high impact research. Research collaboration has been frequently\nanalysed (Sooryamoorthy, 2009) and the other two factors have also been\nexamined (Zhao, 2010; Gazni, 2011) but they have not been examined\nsimultaneously for multiple research fields using an appropriate statistical model.\nThis is an important omission because inappropriate models may generate\nmisleading conclusions and non-simultaneous tests may identify apparently\nimportant factors that are not relevant when other factors are also considered. This\nstudy fills this gap by applying a negative binomial-logit hurdle model to three\ndifferent subjects.\nLiterature review\nAs introduced above, research citation impact has been shown to be related to a\nnumber of objective properties of articles. One of the most common factors\npositively associated with increased citations is research collaboration (Gazni &amp;\nDidegah, 2010; Sooryamoorthy, 2009). Publishing in a high impact journal is also\none of the foremost factors associated with higher citation counts (Boyack &amp;\nKlavans, 2005). The reputation of authors is also known a determinant of citation\nimpact (Peters &amp; van Raan, 1994). The five factors that are examined in this study\nare individual collaboration, institutional collaboration, international\ncollaboration, research funding and readability of abstracts. Among the factors\npreviously studied, these factors seem to be most under the control of the authors.\nPublishing in high impact journals was not included because this is itself an\nindicator of successful research and is an external approval indicator, like citation\ncounts, rather than being an aspect of the research itself. Literature on the three\nfactors is reviewed in the next sub-sections.\nResearch collaboration\nMulti-author research is becoming more common (Gazni, Sugimoto, &amp; Didegah,\n2012; Persson, Glänzel, &amp; Danell, 2004) and receives more citations than solo\nresearch (Gazni &amp; Didegah, 2010; Sooryamoorthy, 2009; Leimu &amp; Koricheva,\n2005a&amp;b). However, a few studies have found no correlation between more\nauthors and increased citations (Bornmann, Schier, Marx, &amp; Daniel, 2012;\nHaslam et al., 2008). These studies&#x27; findings are often not generalizable, however\nbecause they are limited to a single country (Sooryamoorthy, 2009), a single\n1831\n\ninstitution (Gazni &amp; Didegah, 2010), a single field of study (Leimu &amp; Koricheva,\n2005a&amp;b; Haslam et al., 2008) or a specific journal (Bornmann, Schier, Marx, &amp;\nDaniel, 2012). Using correlation and regression tests, a correlation between\ncitation counts and the number of authors has been found (Gazni &amp; Didegah,\n2010; Sooryamoorthy, 2009; Leimu &amp; Koricheva, 2005a&amp;b; Haslam et al., 2008)\nbut the extent to which the number of authors contributes to increased or\ndecreased citations has not been determined. The difference between the results of\nprevious studies might have resulted from the differing samples of publications\nused and, in particular, there may be disciplinary differences. Whereas previous\nstudies have conducted detailed micro-level analyses, the current study is done at\na macro level and is not limited to a single country, institution, field or journal.\nInternational collaboration can also lead to increased citation counts\n(Sooryamoorthy, 2009; Glänzel, 2001; Glänzel &amp; Schubert, 2001; Katz &amp; Hicks,\n1997; Narin, Stevens, &amp; Whitlow, 1991). Conversely, however, an investigation\nof Harvard University publications found no correlation between international\ncollaboration and citation counts (Gazni &amp; Didegah, 2010), and this may be a\nspecial case for Harvard, as a world-leading institution. Most studies are\ngeographically or institutionally limited and hence are difficult to generalise. Two\nstudies (Glänzel, 2001; Glänzel &amp; Schubert, 2001) avoid this issue by taking the\nfull Science Citation Index (SCI) during a one or two-year period. However, they\ndo not cover social sciences fields. This research fills this gap in the literature by\nstudying social sciences in comparison to life and physical sciences. To measure\nthe impact of international collaboration on citation counts, the very simple\nmethod of comparing the mean citation of domestic collaboration with\ninternational collaboration is often used. This has the limitation that the difference\nmay be spurious: caused by factors other than the ones investigated. International\ncollaboration seems to be particularly beneficial for small institutions (Goldfinch,\nDale, &amp; DeRouen, 2003) rather than big institutions (Gazni &amp; Didegah, 2010).\nInstitutional collaboration, which involves researchers from different institutions,\nalso associates with the higher citation impact of papers (Gazni &amp; Didegah, 2010;\nSooryamoorthy, 2009; Narin &amp; Whitlow, 1990). These studies are also\ngeographically and institutionally limited and do not have the coverage of the\ncurrent study. A simple correlation was tested to examine the association between\ninstitutional collaboration and citation counts.\nAbstract readability\nReadability refers to the level of difficulty of the language used to write a text.\nUsing the Flesch difficulty score, Gazni (2011) found that papers with less\nreadable abstracts were cited more than the papers with more readable abstracts in\nthe five top institutions in the world. It may be that in the world’s top institutions\ntheir high prestige ensures that their less readable abstracts seem more impressive,\nwhereas unreadable abstracts may be taken as a sign of incompetence for\nresearchers at other institutions. Alternatively, less readable abstracts may\nassociate with higher citation areas of study, such as the more quantitative fields.\n1832\n\nHowever, medical articles with structured abstracts, using different sections in a\nway that is known to be more readable (Hartley &amp; Benjamin, 1998), are, on\naverage, more cited than articles with traditional unstructured abstracts (Hartley &amp;\nSydes, 1997).\nIt seems that there is not a strong relationship between article readability and\ncitation impact in the sub-fields of Social Sciences: Marketing, Psychology and\nEducation Science (Stremersch, Verniers, &amp; Verhoef, 2007; Hartley, Sotto, &amp;\nPennebaker, 2002; Hartley &amp; Trueman, 1992). Finally, three decades ago, Bottle,\nRennie, Russ and Sardar (1983) claimed that the readability of articles was\nsignificantly decreasing although the reasons for this were not clear and it is not\nknown if this trend has continued.\nGiven that abstract readability and its association with research citation impact\nhas been studied only to a limited degree, larger scale investigations are needed.\nThis study partly addresses this demand.\nResearch funding\nIt is widely believed that insufficient funding can lead to shortcomings in research\n(Reed et al., 2007). For example, a higher citation impact is expected when\nfunding is provided (Levitt, 2011). A number of studies have claimed an\nassociation between research impact and funding in Medical Education research\n(Read et al., 2007), Library and Information Science (Zhao, 2010), and\nBiomedical research (Lewison &amp; Dawson, 1998) but with the caveat that it varies\nacross subject domains in a single country (Jowkar, Didegah, &amp; Gazni, 2011).\nHowever, a decade before Zhao (2010), Cronin and Shaw (1999) did not find an\nassociation between research grants and the citation impact of papers in\nInformation Science. Research funding also seems not to be a significant\ndeterminant of increased citations in Psychology (Haslam et al., 2008) and so\nthere may be disciplinary differences in the importance of funding. The\nresearchers basically compared the average citations of the entire funded research\nwith that average of the unfunded research in a single field whereas this study will\nexamine and compare the citation impact of funded vs. unfunded research at a\npaper level.\nResearch questions\nThe factors examined here have been previously investigated: particularly\nresearch collaboration and research funding. The current study aims to fill three\nknowledge gaps in the literature: first, there is a lack of consensus on the\ninfluence of citation factors since different studies came to different conclusions\non the effect of a specific factor; second, the literature is silent on the extent to\nwhich the factors determine the impact; and lastly, most literature on the influence\nof factors considered them separately and mostly within a single field. There is a\nparticular problem with overlapping factors, such as collaboration and\ninternationality. For example, more international papers tend to have more authors\nso if international research is more cited is this because it is international or\n1833\n\nbecause it has more authors (and vice versa)? Therefore, this study seeks to\nsimultaneously analyse the three factors of citation impact in three different fields\nof research that are representatives of three broad areas of science (Life Sciences,\nPhysical Sciences and Social Sciences). It goes further than the simple correlation\nbetween the factors and citation impact and provides evidence of the extent to\nwhich these factors associate with increased or decreased citations. This study\nseeks to answer two research questions:\n1. Which factors under the control of the researcher associate with increased\ncitation impact, taking into account that some of these factors overlap?\nThis concerns individual collaboration, institutional collaboration,\ninternational collaboration, research funding and abstract readability.\n2. To what extent do the determinants of citation impact associate with\nincreased citation counts?\nMethods\nPublications from Biology &amp; Biochemistry, Chemistry and Social Sciences\ncovered by Thomson Reuters’ Web of Science (WoS) from 2000-2009 were\nextracted (16,378 articles in Chemistry, 16,058 articles in Biology &amp;\nBiochemistry, and 15,932 articles in Social Science) by systematic sampling\nbased upon the year of publication and the sub-fields. Using the list of journals\nprovided by ScienceWatch.com classifying each journal into one of the 22 ESI\nfields, a journal-based method of searching was used to find and download the\nrelated publications. Only two types of documents, articles and conference\nproceedings, were included because original research is mainly published in these\ntwo types of documents (Milojević &amp; Leydesdorff, 2012).\nAlthough the subject classification in WoS is journal-based, it is well-established\nand has frequently been used by scientometricians to classify individual papers.\nThe three fields were picked up from a list of 22 different subject fields classified\nby Essential Science Indicators (ESI) in WoS. Biology &amp; Biochemistry was\nchosen as a representative for life sciences and Chemistry was chosen as a\nrepresentative for physical sciences (See Nagaoka, Igami, Eto, &amp; Ijichi (2011) for\nthe categorization of subject fields), as they both are the largest fields (based on\nnumber of their publications) in their own category.\nDependent and independent variables\nThe number of citations to papers is the dependent variable and the independent\nvariables are research collaboration, research funding and readability of abstract.\nThree different patterns of research collaboration were used: individual\ncollaboration (number of authors in each paper), institutional collaboration\n(number of institutions in each paper) and international collaboration (number of\ncountries in each paper). To measure individual collaboration, the number of\nauthors per paper was automatically counted from the WoS authors’ names field.\nTo identify and count institutional and international collaborations, the number of\ndistinct institutions and countries contributing to the WoS affiliation field of each\n1834\n\npaper was automatically counted. A research paper was counted as funded if there\nwas an entry in its WoS funding field. WoS contains funding acknowledgement\ndata from August 2008 forward (Thomson Reuters Technical Support, 2013). Due\nto the data limitation, we could not include funding variable in the model for the\nall ten years. We ran extra models and included funding variable with the other\nfour variables for 2009 data only. The Flesch Reading Ease Score was used to\nmeasure the readability of the abstracts. There are numerous formulae to measure\nthe readability of a text but the Flesch score seems to be the most popular and the\nMicrosoft Office Word 2010 API was used to automatically calculate it.\nStatistical procedures\nCount models provide a structural framework for analysing the count data. Given\nthat the dependent variable of our study is count data (citation counts), these types\nof regression models are the most appropriate. The research data set is\noverdispersed (i.e. the variance of the data is greater than its mean). A Poisson\nregression model, the basic count model, assumes mean and variance equality\n(Cameron &amp; Trivedi, 2001); therefore a Poisson model cannot adequately deal\nwith overdispersed data and this option was rejected.\nInitially, standard, zero-inflated and hurdle negative binomial models were\nconsidered. A standard negative binomial model is frequently used to model\noverdispersed data. Hurdle models seek first to determine the probability of an\nobservation being positive or zero, and then the parameters of the count\ndistribution for positive observations. Zero-inflated models assume two types of\nzeros in the data: zeros which arise from a count distribution and zeros which\narise from a “perfect-zero” distribution (Hilbe, 2011). We fitted these three\nmodels on the dataset and hurdle models were found to give the best fit to the\ndata. The hurdle model is also intuitively a good choice because it seems\nreasonable to assume that it is a significant hurdle for a paper to receive its first\ncitation but after this it is more likely to be cited in the future. More citations may\noccur because a cited paper is listed higher in information retrieval systems (e.g.,\nGoogle Scholar) or because the endorsement of a citation reported in such\nsystems.\nThere are different types of hurdle model. Logit and complementary log-log\n(cloglog) hurdle models were fitted on the data set and found to have identical\nAIC values. AIC (Akaike Information Criterion) is an indicator of the statistical\ngoodness of fit and helps to choose between two models. The logit and cloglog\nmodels are the binary models for modelling the zero counts and specify the\nrelationship between the predictors and the dependent variable. As the results\nfrom the logit model are easier to interpret, it was decided to report the logit\nmodel (Hilbe, 2011). In the negative binomial-logit hurdle model, two parameters\nare predicted with the negative binomial model: The overdispersion parameter\nand the mean of negative binomial model. With the log model, odds ratio in the\nform of Log [P(citations&gt;1)/P(citations=0)] is predicted.\n\n1835\n\nTable 1. The results of hurdle model in Biology &amp; Biochemistry (2000-2009)\nLogit model\nNo. of Authors\nNo. of Countries\nReadability of Abs.\nConstant\nNB model\nNo. of Authors\nNo. of Countries\nReadability of Abs.\nConstant\nalpha (the dispersion\nparameter)\n\nCoef.\n0.06\n0.122\n-0.005\n2.033\nCoef.\n0.05\n0.029\n-0.01\n2.558\n\nExp(Coef.)\n1.062\n1.129\n0.995\n7.64\nExp(Coef.)\n1.051\n1.03\n0.99\n12.91\n\nStd. Err.\n0.012\n0.06\n0.002\n0.096\nStd. Err.\n0.004\n0.02\n0.001\n0.034\n\nz\n4.89\n2.04\n-2.21\n21.13\nz\n12.63\n1.47\n-10.71\n74.78\n\nP&gt;z\n0.000\n0.042\n0.027\n0.000\nP&gt;z\n0.000\n0.143\n0.000\n0.000\n\n0.572\n\n1.772\n\n0.021\n\n26.67\n\n0.000\n\n[95% Conf. Interval]\n0.036\n0.084\n0.005\n0.239\n-0.01\n-0.001\n1.845\n2.222\n[95% Conf. Interval]\n0.042\n0.058\n-0.01\n0.069\n-0.012\n-0.008\n2.491\n2.625\n0.53\n\n0.614\n\nResults\nThe results of negative binomial-logit hurdle model provide coefficients for both\nthe negative binomial (non-zero citation counts) and the logit (proportion of\nuncited papers) components of the model (tables 1 to 7). For each subject\ncategory, two hurdle models are run, one for the whole ten years (2000-2009)\nexcluding research funding variable and another only for 2009 including research\nfunding.\nBiology &amp; Biochemistry In Biology &amp; Biochemistry (2000-2009), the coefficients\nof the negative binomial model show that only the number of authors associates\nwith increased citations. The positive significant coefficient for the number of\nauthors indicates that a one-unit change in the number of authors increases the\nmean citation count by 5%: for papers that are cited at least once, each extra\nauthor attracts, on average, 5% more citations. The number of countries is not a\nsignificant determinant of citation counts (p&gt; 0.05) in this field. With respect to\nthe logit model, the number of countries is significantly associated with decreased\nzero citations and a one-unit change in the number of countries decreases the\nmean number of zero citation articles by 13% (Table 1). To handle the collinearity\nissue (the high correlation between the number of institutions and the two other\nresearch collaboration factors) the number of institutions was removed from the\nmodel since there is a high correlation between this variable and the number of\nauthors and the number of countries. The effect of this variable on citation counts\nwas separately scrutinized in more detail. Keeping the number of authors and the\nnumber of countries constant at different values, extra hurdle models were run. In\nthe majority of cases, the coefficient of the number of citations is not significant\nand the results are not consistent and vary from one number of countries to\nanother. So the overall evidence of the impact of the number of institutions in\nBiology &amp; Biochemistry is unclear (Table 4), but it seems that this is not an\nimportant factor. Abstract readability is strongly associated with decreased\ncitation counts and increased zero citations. Whilst abstract readability is highly\nstatistically significant, the exponential coefficient of 0.99 in both the negative\nbinomial and logit models indicates that this variable has no practical significance\n(Table 1).\n1836\n\nTable 2. The results of hurdle model in Biology &amp; Biochemistry including research\nfunding (2009)\nLogit model\nNo. of Authors\nNo. of Countries\nFunding\nReadability of Abs.\nConstant\nNB model\nNo. of Authors\nNo. of Countries\nFunding\nReadability of Abs.\nConstant\nalpha\n\nCoef.\n0.045\n-0.018\n0.658\n-0.008\n0.217\nCoef.\n0.059\n0.070\n0.248\n-0.010\n0.370\n0.566\n\nExp (Coef.)\n1.046\n0.982\n1.931\n0.992\n1.242\nExp (Coef.)\n1.060\n1.072\n1.282\n0.990\n1.448\n1.760\n\nStd. Err.\n0.022\n0.102\n0.121\n0.005\n0.199\nStd. Err.\n0.015\n0.079\n0.104\n0.004\n0.179\n0.156\n\nz\n2.080\n-0.180\n5.450\n-1.670\n1.090\nz\n4.020\n0.880\n2.380\n-2.720\n2.070\n3.630\n\nP&gt;z\n0.037\n0.861\n0.000\n0.095\n0.276\nP&gt;z\n0.000\n0.378\n0.017\n0.007\n0.038\n0.000\n\n[95% Conf. Interval]\n0.003\n0.088\n-0.218\n0.182\n0.421\n0.895\n-0.017\n0.001\n-0.173\n0.607\n[95% Conf. Interval]\n0.030\n0.087\n-0.086\n0.226\n0.044\n0.453\n-0.018\n-0.003\n0.020\n0.720\n0.260\n0.871\n\nAccording to the results of the negative binomial model in Biology &amp;\nBiochemistry (2009), research funding is strongly associated with increased\ncitations and one-unit change in the research funding increases the mean citation\ncount by 28.2%. Other factors are behaving the same to the ten-year model. With\nrespect to the logit model, research funding is significantly associated with\ndecreased zero citations (Table 2).\nTable 3. The results of hurdle model in Chemistry (2000-2009)\nLogit model\nNo. of Authors\nNo. of Countries\nReadability of Abs.\nConstant\nNB model\nNo. of Authors\nNo. of Countries\nReadability of Abs.\nConstant\nalpha\n\nCoef.\n0.076\n0.357\n-0.003\n1.031\nCoef.\n0.017\n0.049\n-0.008\n2.165\n0.869\n\nExp(Coef.)\n1.079\n1.428\n0.997\n2.805\nExp(Coef.)\n1.018\n1.05\n0.992\n8.718\n2.384\n\nStd. Err.\n0.012\n0.06\n0.002\n0.083\nStd. Err.\n0.006\n0.028\n0.001\n0.044\n0.03\n\nz\n6.24\n5.95\n-2.17\n12.46\nz\n2.92\n1.77\n-8.75\n49.62\n28.71\n\nP&gt;z\n0.000\n0.000\n0.03\n0.000\nP&gt;z\n0.004\n0.078\n0.000\n0.000\n0.000\n\n[95% Conf. Interval]\n0.052\n0.1\n0.239\n0.474\n-0.007\n0.000\n0.869\n1.193\n[95% Conf. Interval]\n0.006\n0.029\n-0.005\n0.104\n-0.01\n-0.006\n2.08\n2.251\n0.81\n0.928\n\nChemistry In Chemistry (2000-2009) with respect to the negative binomial part of\nthe hurdle model, the number of authors is the only determinants of increased\ncitations and a one-unit change in the number of authors increases the expected\nmean citation count by about 2%. With respect to the logit model, the number of\nauthors and the number of countries are significantly associated with decreased\nzero citations and a one-unit change in the number of authors and the number of\ncountries decreases the expected mean zero citation by around 8% and 43%. The\nnumber of institutions was removed from the model due to a high collinearity.\nHowever, fixing the number of authors and the number of countries at different\nvalues, we again ran extra hurdle models to more precisely study this variable but\nno clear evidence was obtained (Table 7). Although abstract readability is\n1837\n\nstatistically significantly associated with decreased citation counts and increased\nzero citations, its association is of no practical significance (Table 3).\nWith respect to the negative binomial model in Chemistry (2009), research\nfunding is a significant determinant of increased citations and a one-unit change\nin this variable increased the mean citation counts by 42.3%. According to the\nlogit part of the hurdle model, research funding is associated with decreased zero\ncitations and a one-unit change in this variable decreases zero citations by 8.2%.\nThe number of authors is not a significant determinant of increased citations in\nthe one-year model but it is significantly associated with decreased zero citations\n(Table 4).\nTable 4. The results of hurdle model including research funding in Chemistry (2009)\nLogit model\nCoef. Exp(Coef.) Std. Err.\nNo. of Authors\n0.096\n1.101\n0.025\nNo. of Countries\n0.244\n1.277\n0.119\nFunding\n0.733\n2.082\n0.104\nReadability of Abs. -0.005\n0.995\n0.004\nConstant\n-0.684\n0.505\n0.187\nNB model\nCoef. Exp(Coef.) Std. Err.\nNo. of Authors\n0.019\n1.019\n0.019\nNo. of Countries\n0.071\n1.073\n0.095\nFunding\n0.353\n1.423\n0.104\nReadability of Abs. -0.018\n0.983\n0.003\nConstant\n0.464\n1.59\n0.188\nalpha\n0.87\n2.387\n0.189\n\nz\n3.92\n2.06\n7.08\n-1.24\n-3.67\nz\n0.97\n0.75\n3.38\n-5.11\n2.46\n4.6\n\nP&gt;z\n0.000\n0.04\n0.000\n0.214\n0.000\nP&gt;z\n0.331\n0.456\n0.001\n0.000\n0.014\n0.000\n\n[95% Conf. Interval]\n0.048\n0.144\n0.011\n0.477\n0.53\n0.936\n-0.012\n0.003\n-1.049\n-0.318\n[95% Conf. Interval]\n-0.019\n0.056\n-0.115\n0.257\n0.148\n0.557\n-0.024\n-0.011\n0.094\n0.833\n0.499\n1.241\n\nSocial Sciences In Social Sciences (2000-2009), the number of countries is neither\na significant determinant of citation counts nor zero citations (p&gt; 0.05). With\nrespect to the negative binomial model, the positive significant coefficients of the\nnumber of authors and the number of institutions indicate their association with\nincreased citations. The expected mean citation count increased by 8.7% for each\nextra author and by 5.1% for each extra institution. With respect to the logit\nmodel, a one-unit change in the number of authors and the number of institutions\ndecreases the mean zero citation by 12.8% and 11.3% respectively. Abstract\nreadability associates with decreased citation counts, although it has no practical\nsignificance. Moreover, with respect to the logit model, there is no significant\nassociation between this variable and zero citations (Table 5).\nIn Social Sciences (2009), research funding was also taken into account. Results\nshow that there is no significant association between research funding and citation\ncounts, although this variable is associated with 80% decrease in zero citations.\nThe results for the number of authors and the number of countries in the one-year\nmodel are similar to the results of the ten-year model but the abstract readability is\nbehaving differently in the one-year model. This variable is significantly\nassociated with increased citations in Social Sciences (2009) and a one-unit\nchange in the abstract readability increased the citation counts by 0.5% (Table 6).\n1838\n\nThe overdispersion parameters are significant in all three models further justifying\nthe negative binomial model (p for alpha&lt;0.001).\nTable 5. The results of hurdle model in Social Sciences (2000-2009)\nLogit model\nNo. of Authors\nNo. of Institutions\nNo. of Countries\nReadability of Abs.\nConstant\nNB model\nNo. of Authors\nNo. of Institutions\nNo. of Countries\nReadability of Abs.\nConstant\nalpha\n\nCoef.\n0.12\n0.107\n0.024\n-0.002\n0.616\nCoef.\n0.083\n0.049\n0.023\n-0.003\n1.133\n1.314\n\nExp(Coef.)\n1.128\n1.113\n1.024\n0.998\n1.851\nExp(Coef.)\n1.087\n1.051\n1.023\n0.997\n3.104\n3.72\n\nStd. Err.\n0.017\n0.033\n0.066\n0.002\n0.076\nStd. Err.\n0.013\n0.023\n0.044\n0.001\n0.067\n0.058\n\nz\n7.21\n3.24\n0.36\n-1.25\n8.06\nz\n6.54\n2.13\n0.52\n-2.09\n16.95\n22.71\n\nP&gt;z\n0.000\n0.001\n0.717\n0.212\n0.000\nP&gt;z\n0.000\n0.033\n0.603\n0.037\n0.000\n0.000\n\n[95% Conf. Interval]\n0.088\n0.153\n0.042\n0.172\n-0.105\n0.153\n-0.005\n0.001\n0.466\n0.765\n[95% Conf. Interval]\n0.058\n0.108\n0.004\n0.095\n-0.064\n0.11\n-0.006\n0.000\n1.002\n1.264\n1.2\n1.427\n\nTable 6. The results of hurdle model including research funding in Social Sciences\n(2009)\nLogit model\nNo. of Authors\nNo. of Institutions\nNo. of Countries\nFunding\nReadability of Abs.\nConstant\nNB model\nNo. of Authors\nNo. of Institutions\nNo. of Countries\nFunding\nReadability of Abs.\nConstant\nalpha\n\nCoef.\n0.14\n0.174\n0.241\n0.589\n0.0005\n-0.769\nCoef.\n0.048\n0.057\n0.125\n0.074\n0.005\n-3.423\n3.28\n\nExp(Coef.)\n1.15\n1.19\n1.272\n1.802\n1.0005\n0.464\nExp(Coef.)\n1.049\n1.058\n1.133\n1.076\n1.005\n0.033\n26.57\n\nStd. Err.\n0.024\n0.43\n0.101\n0.137\n0.003\n0.159\nStd. Err.\n0.013\n0.026\n0.146\n0.199\n0.002\n5.684\n2.75\n\nz\n5.8\n4.06\n2.37\n4.28\n0.16\n-4.85\nz\n3.53\n2.21\n0.86\n0.37\n1.99\n-0.6\n1.19\n\nP&gt;z [95% Conf. Interval]\n0.000\n0.093\n0.187\n0.000\n0.09\n0.258\n0.018\n0.041\n0.441\n0.000\n0.319\n0.859\n0.87\n-0.006\n0.007\n0.000\n-1.080\n-0.458\nP&gt;z [95% Conf. Interval]\n0.000\n0.021\n0.074\n0.027\n0.006\n0.109\n0.391\n-0.161\n0.412\n0.71\n-0.317\n0.465\n0.046 0.00008\n0.01\n0.547 -14.563\n7.718\n0.049\n-2.11\n8.69\n\nDiscussion and conclusions\nThe analysis of the factors affecting citation counts of the papers that are cited at\nleast once indicates that one component of research collaboration, the number of\nauthors, is the only factor associated with increased citations in the ten-year\nmodel in the three subject fields. This factor also very significantly associates\nwith decreased zero citations. Conversely, however, a study of a specific journal\nin Chemistry found no correlation between the number of authors and increased\ncitation counts. This difference may result from the difference between the microlevel and macro-level analyses (Bornmann, Schier, Marx, &amp; Daniel, 2012) or the\nsmaller sample size for the single journal studied giving insufficient statistical\n1839\n\npower to identify the association. The number of authors has not been found to be\na significant determinant of citations in social and personality psychology\n(Haslam, et al., 2008). The authors believed that team-working is not necessarily a\ntrue reflection of research collaboration in this field.\nTable 7. The results of extra hurdle models (only the negative binomial part) for the\neffect of the number of institutions on citation counts using a range of different fixed\nnumbers of authors and countries (e.g., 3au_2cnty means 3 authors from 3 different\ncountries)\nStatus\n2au_1cnty\n3au_1cnty\n4au_1cnty\n5au_1cnty\n6au_1cnty\n7au_1cnty\n8au_1cnty\n9au_1cnty\n10au_1cnt\ny\n3au_2cnty\n4au_2cnty\n5au_2cnty\n6au_2cnty\n\nBiology &amp; Biochemistry\nExp\nCoef.\nP&gt;|z|\n(coef.)\n-0.044\n0.96\n0.52\n-0.054\n0.95\n0.05\n-0.098\n0.91\n0.01\n0.99\n0.9\n0.0003\n0.055\n1.06\n0.01\n-0.017\n0.98\n0.7\n-0.102\n0.90\n0.04\n0.0054\n1.01\n0.9\n\nSample\nSize\n1935\n2307\n2144\n\n2au_1cnty\n3au_1cnty\n4au_1cnty\n\nChemistry\nExp\nCoef.\n(coef.)\n-0.27\n0.76\n-0.168\n0.85\n-0.11\n0.90\n\n1772\n\n5au_1cnty\n\n-0.065\n\n1315\n864\n499\n325\n\n6au_1cnty\n7au_1cnty\n8au_1cnty\n9au_1cnty\n\nStatus\n\n0.00\n0.00\n0.02\n\nSampl\ne Size\n2562\n3090\n2686\n\n0.94\n\n0.18\n\n1713\n\n-0.102\n-0.1\n0.08\n0.03\n\n0.90\n0.90\n1.08\n1.03\n\n0.05\n0.14\n0.48\n0.74\n\n1008\n505\n188\n135\n\nP&gt;|z|\n\n0.125\n\n1.13\n\n0.1\n\n199\n\n10au_1cnty\n\n0.028\n\n1.03\n\n0.8\n\n67\n\n0.02\n-0.125\n0.02\n-0.11\n\n1.02\n0.88\n1.02\n0.90\n\n0.85\n0.2\n0.68\n0.04\n\n377\n452\n448\n423\n\n3au_2cnty\n4au_2cnty\n5au_2cnty\n6au_2cnty\n\n0.03\n-0.069\n-0.056\n-0.25\n\n1.03\n0.93\n0.95\n0.78\n\n0.84\n0.53\n0.5\n0.01\n\n424\n513\n448\n289\n\nNo clear evidence of the number of institutions was found in both Chemistry and\nBiology &amp; Biochemistry but in Social Sciences, the number of institutions is a\nsignificant determinant of both increased citation counts and decreased zero\ncitations in this field.\nThe number of countries has been a significant factor for increased citations in the\nmajority of previous studies except for an institutionally-limited investigation of\nHarvard University. This university is one of the world’s top universities and it\nseems logical in this context that its researchers benefit more from institutional\ncollaboration than from international collaboration (Gazni &amp; Didegah, 2010).\nHowever, the results of current study also show that the number of countries is a\nsignificant determinant of increased citation counts in none of the three fields.\nThe contradiction between the results of this study and some previous studies of\ninternational and institutional collaboration may result from the limited\ngeographical and institutional coverage of previous research whereas the current\nstudy has a global coverage and seeks results at a macro-level. This study goes\nbeyond a simple correlation between a predictor variable and citation counts. A\nco-analysis of predictors is considered here and the results are therefore more\nreliable although factors not considered in the analysis may also influence the\nresults. Furthermore, the influence of research collaboration on research citation\n1840\n\nimpact is not uniform and varies across domains particularly for the institutional\nand international types of collaboration (Gazni &amp; Didegah, 2010; Sooryamoorthy,\n2009). However, the general tendency acknowledges the positive impact of the\nnumber of authors on the citation counts in all fields of science (Franceschet &amp;\nCostanini, 2010).\nReceiving grants from funding agencies brings many advantages to the research\ncommunity by supporting researchers and paving the way for creative and high\nquality research especially in equipment-based research fields. The current study\nfound that while there is a very strong significant impact of funding on citation\ncounts in Biology &amp; Biochemistry and Chemistry, there is no significant\nassociation between this variable and citation counts in Social Sciences.\nTherefore, it seems that Life Sciences and Physical Sciences are performing much\nbetter than Social Sciences in the area of receiving grants and publishing high\nimpact research papers. This is probably resulted from the different natures of the\nsubject fields that are experiment and equipment-based such as Chemistry and\nBiology &amp; Biochemistry or theory-based such as Social Sciences. Receiving\nfunds is so vital to an experiment-based research to provide the required\nequipment and conduct its experiments. So, the result of a funded research in such\na research field is considerably different from a non-funded research and high\nimpact results for funded research in experiment-based subject fields are expected\ndue to less limitation in accessing resources and equipment.\nPrevious studies have also found that funding is not a significant determinant of\ncitation counts in Psychology (Haslam et al., 2008) and Information Science\n(Croin &amp; Shaw, 1999) which are in Social Sciences category. However, there are\nmore studies that found funded research to be more highly cited than unfunded\nresearch in Life and Physical Sciences such as Medical Education, Biomedical\nresearch, Material Sciences, and Physics (Read et al., 2007; Zhao, 2010; Lewison\n&amp; Dawson, 1998; Jowkar, Didegah, &amp; Gazni, 2011).\nAbstract readability was found to be statistically a significant determinant of both\ndecreased citation counts and increased zero citations in Biology &amp; Biochemistry\nand Chemistry but its influence was too small to be of practical value in the\nexamined fields. This is whilst this variable is significantly associated with\nincreased citations in Social Sciences meaning that the easier the abstract, the\nmore number of citations in this field. However, previous research confirmed a\nnegative association between the readability of abstract and citation impact of\npublications in the top institutions of the world (Gazni, 2011). As with previous\nstudies of readability of the texts, all readability measures have a common\nlimitation; they do not consider the characteristics of readers. The readers of\nscientific papers are experts in their own fields and have prior knowledge and\ninterest in them. Hence an abstract graded as difficult based on its Flesch score\nmay not be difficult for the scholars of the field (Gazni, 2011). On the other hand,\nscholars may scan the abstracts for keywords to find if the paper is relevant rather\nthan reading the entire abstract.\n\n1841\n\nIn conclusion, this study attempted to identify effective determinants of research\ncitation impact for scholars to help them to choose styles of high impact research.\nTeam working was found to be a good determinant of citation impact in all three\nfields examined and the more number of authors, the higher the citation impact of\nthe paper. Inter-institutional collaboration was a determinant of higher citation\nimpact in the Social Sciences while international collaboration associates with\ncitation counts in none of the fields. Moreover, research funding is very\nsignificantly associated with increased citations in Biology &amp; Biochemistry and\nChemistry and abstract readability contributes to increased citation counts in\nSocial Sciences. The results do not encourage seeking international partners in the\ndisciplines studied and writing more readable abstracts as neither seem to favour\ncitation impact in Biology &amp; Biochemistry and Chemistry.\nAcknowledgements\nThis research is part of the FP7 EU-funded project ACUMEN on assessing Web\nindicators in research evaluation.\nReferences\nBottle, R. S., Rennie, J. S., Russ, S. &amp; Sardar, Z. (1983). Changes in the\ncommunication of chemical information I: some effects of growth. Journal of\nInformation Science, 6, 103-108.\nBornmann, L. &amp; Daniel, H. D. (2007). Multiple publication on a single research\nstudy: does it pay? The influence of number of research articles on total\ncitation counts in biomedicine. Journal of American Society for Information\nScience, 58, 1100-1117.\nBornmann, L., Schier, H., Marx, W. &amp; Daniel, H-D. (2012). What factors\ndetermine citation counts of publications in chemistry besides their quality?\nJournal of Informetrics, 6, 11-18.\nBoyack, K. W. &amp; Klavans, R. (2005). Predicting the Importance of Current\nPapers. Proceedings of ISSI 2005, 335–342. Edited by P. Ingwersen and B.\nLarsen. July 24-28, Stockholm, Sweden.\nCameron, C. A. &amp; Trivedi, P. K. (2001). Essentials of Count Data Regression, A\ncompanion to theoretical Econometrics. Oxford: Blackwell.\nCronin, B. &amp; Shaw, D. (1999). Citation, funding acknowledgement and author\nnationality in four information science journals. Journal of Documentation, 55,\n402–408.\nFranceschet, M. &amp; Costantini, A. (2010). The effect of scholar collaboration on\nimpact and quality of academic papers. Journal of Informetrics, 4, 540-553.\nGazni, A. (2011). Are the abstracts of high impact articles more readable?\nInvestigating the evidence from top research institutions in the world. Journal\nof Information Science, 37 (3), 273-281.\nGazni, A. &amp; Didegah, F. (2010). Investigating Different Types of Research\nCollaboration and Citation Impact: A Case Study of Harvard University’s\nPublications. Scientometrics, 87(2), 251-265.\n1842\n\nGazni, A., Sugimoto, C. R., &amp; Didegah, F. (2012). Mapping world scientific\ncollaboration: authors, institutions, and countries. Journal of the American\nSociety for Information Science &amp; Technology (JASIS&amp;T), 63(2), 323-335.\nGlänzel, W. (2001). National characteristics in international scientific coauthorship relations. Scientometrics, 51(1), 69-115.\nGlänzel, W. &amp; Schubert, A. (2001). Double effort=Double impact? A critical\nview at international co-authorship in chemistry. Scientometrics, 50(2), 199214.\nGoldfinch, S., Dale, T., &amp; DeRouen, K. (2003). Science from the periphery:\nCollaboration, networks and “periphery effects” in the citation of New Zealand\nCrown Research Institutes articles, 1995–2000. Scientometrics, 57(3), 321–\n337.\nHartley, J., &amp; Benjamin, M. (1998). An evaluation of structured abstracts in\njournals published by the British Psychological Society. British Journal of\nEducational Psychology, 68(3), 443-456.\nHartley, J., Sotto, E., Pennebaker, J. (2002). Style and substance in psychology:\nAre influential articles more readable than less influential ones? Social Studies\nof Science, 32, 321-334.\nHartley, J. &amp; Sydes, M. (1997). Are structured abstracts easier to read than\ntraditional ones? Journal of Research in Reading, 20(2), 122-136.\nHartley, J. &amp; Trueman, M. (1992). Some observations on using journal articles in\nthe teaching of psychology. Psychology Teaching Review, 1(1), 46-51.\nHaslam, N. et al. (2008). What makes an article influential? Predicting impact in\nsocial and personality psychology. Scientometrics, 76(1), 169-185.\nHilbe, J. M. (2011). Negative Binomial Regression, second edition (5th print,\n2012). Cambridge, UK: Cambridge University Press.\nJowkar, A., Didegah, F. &amp; Gazni, A. (2011). The Effect of Funding on Academic\nResearch Impact: A case study of Iranian publications. Aslib Proceedings,\n63(6): 593-602.\nKatz, J. S., &amp; Hicks, D. (1997). How much is a collaboration worth? A calibrated\nbibliometric model. Scientometrics, 40(3), 541-554.\nLariviere, V. &amp; Gingras, Y. (2010). On the relationship between\ninterdisciplinarity and scientific impact. Journal of the American Society for\nInformation Science and Technology, 61, 126-131.\nLeimu, R., &amp; Koricheva, J. (2005a). What determines the citation frequency of\necological papers? Trends in Ecology &amp; Evolution, 20, 28-32.\nLeimu, R., &amp; Koricheva, J. (2005b). Does scientific collaboration increase the\nimpact of ecological articles? BioScience, 55, 438-443.\nLevitt, J. M. (2011). Are funded articles more highly cited than unfunded articles?\nA preliminary investigation. Proceedings of the ISSI 2011 conference, Durban,\nSouth Africa, 1013-1015.\nLewison, G. &amp; Dawson, G. (1998). The effect of funding on the outputs of\nbiomedical research. Scientometrics, 41, 1-2, 17-27.\n\n1843\n\nLovaglia, M.J. (1989). Status characteristics of journal articles for editor’s\ndecisions and citations. The Society for Social Studies of Science Annual\nMeeting, November 15- 18, University of California at Irvine, Irvine, CA.\nMilojević, S. &amp; Leydesdorff, L. (in press). Information Metrics (iMetrics): A\nResearch Specialty with a Socio-Cognitive Identity? Scientometrics.\nNagaoka, S., Igami, M., Eto, M., &amp; Ijichi, T. (2011). Knowledge Creation\nProcess in Science: Basic findings from a large-scale survey of researchers in\nJapan. Report by National Institute of Science and Technology Policy\n(NISTEP), Institute of Innovation Research (IIR), Hitotsubashi University.\nNarin, F. &amp; Whitlow, E. S. (1990). Measurement of scientific co-operation and\nco-authorship in CEC related areas of science. Report EUR 12900. Office for\nOfficial Publications in the European Communities, Luxembourg.\nNarin, F., Stevens, K., &amp; Whitlow, E. S. (1991). Scientific cooperation in Europe\nand the citation of multinationally authored papers. Scientometrics, 21(3), 313323.\nPersson, O., Glänzel, W., &amp; Danell, R. (2004). Inflationary bibliometric values:\nThe role of scientific collaboration and the need for relative indicators in\nevaluative studies. Scientometrics, 60(3), 421-432.\nPeters, H. P. F. &amp; van Raan, A. F. J. (1994). On Determinants of Citation Scores:\nA Case Study in Chemical Engineering. Journal of the American Society for\nInformation Science, 45(1), 39-49.\nReed, D. A. et al. (2007). Association between Funding and Quality of Published\nMedical Education Research. Journal of American Medical Association.\n298(9), 1002-1009.\nSooryamoorthy, R. (2009). Do types of collaboration change citation?\nCollaboration and citation patterns of South African science publications.\nScientometrics, 81(1), 177–193.\nStremersch, S. Verniers, I. &amp; Verhoef, P. C. (2007). The quest for citations:\ndrivers of article impact. Journal of Marketing, 71, 171-193.\nThomson Reuters Technical Support (2013). Available at: http://ipscience.thomsonreuters.com/support/.\nZhao, D. Z. (2010). Characteristics and impact of grant-funded research: a case\nstudy of the library and information science field. Scientometrics, 84(2), 293306.\nZimmerman, J. L. (1989). Improving a manuscript’s readability and likelihood of\npublication. Issues in Accounting Education, 4, 458-466.\n\n1844\n\nPOSTERS\n\nTHE 2-YEAR MAXIMUM JOURNAL IMPACT\nFACTOR\nMaría Isabel Dorta-González1 and Pablo Dorta-González2\n1\n\nisadorta@ull.es\nUniversidad de La Laguna (Spain)\n2\n\npdorta@dmc.ulpgc.es\nUniversidad de Las Palmas de Gran Canaria (Spain)\nmatures slowly with a journal from a\nfield in which impact matures rapidly.\nIn this paper, we provide a source\nnormalization approach based on\nvariable citation time windows and we\nempirically compare this with the\ntraditional normalization approach based\non a fixed target window.\nThe variable citation time window\nThe delimitation among fields of science\nhas until now remained an unsolved\nproblem because these delineations are\nfuzzy at each moment in time and\ndevelop dynamically over time.\n\nCitations in year t\n\nIntroduction\nDuring decades, the journal impact\nfactor (JIF) has been an accepted\nindicator in ranking journals. The 2-year\njournal impact factor (2-JIF) counts\ncitations to one and two year old\narticles, while the 5-year journal impact\nfactor (5-JIF) counts citations from one\nto five year old articles. However, there\nare increasing arguments against the\nfairness of using the JIF as the sole\nranking criteria (Althouse et al., 2009;\nBensman, 2007; Bornmann &amp; Daniel,\n2008).\nThese indicators are not comparable\namong fields of science for two reasons:\n(i) each field has a different impact\nmaturity time, and (ii) because of\nsystematic differences in publication\nand\ncitation\nbehaviour\nacross\ndisciplines. Citation-based bibliometric\nindicators need to be normalized for\nsuch differences in order to allow for\nmeaningful between-field comparisons\nof citation impact (Dorta-González &amp;\nDorta-González, 2010, 2011).\nThere is not an optimal fixed impact\nmaturity time valid for all the fields. In\nsome of them two years provides a good\nperformance whereas in others three or\nmore years are necessary. Therefore,\nthere is a problem when comparing a\njournal from a field in which impact\n\nJA\n\nJB\n\nJC\n\nJD\n\nField in which impact\nmatures slowly\n\nField in which impact\nmatures rapidly\nt\n\nt−1\n\nt−2\n\nt−3\n\n2-JIF\n\nt−4\n\nt−5\n\nt−6\n\nt−7\n\nt−8\n\ntime window\n\n2M-JIF for journals B and D\n5-JIF\n\nFigure 1. Citations distribution of journals\n\nThe choice for a variable rather than a\nfixed citation time window is based on\nthe observation that in many fields\ncitations have not yet peaked after 2\nyears, and in other fields citations have\npeaked long before 5 years. Therefore,\n1847\n\nthe application of a 2-year variable\nwindow is the optimal compromise for\nfields in which impact matures slowly in\nreaching its maximum citations while\nnot penalising fields in which impact\nmatures rapidly.\nFigure 1 shows the citations distribution\nof four journals with different\nperformance. Journals A and C belong\nto a field in which impact matures\nrapidly, while journals B and D belong\nto a field in which impact matures\nslowly. Then A has greater impact than\nC, and B has greater impact than D.\nNevertheless, which journal has greater\nimpact, A or B? And, C or D?\nWe define the rolling impact factors in\nyear t of journal i as:\nNCitti, t  j  NCitti, t  j 1\nR j -JIFt i\n\n, j 1,...,h,\nNArtti j  NArtti j 1\nand the 2-year maximum journal impact\nfactor in year t of journal i as following:\n2M-JIFt i  max j 1, ,h R j -JIFt i  .\nThe idea is to consider, for each journal,\nthe citation time window with the\nhighest average number of citations (i.e.,\nthe most advantageous period for each\njournal).\nMaterials and Methods\nThe bibliometric data was obtained from\nthe online version of the 2011 Journal\nCitation Reports (JCR) Science edition.\nIn the comparative analysis one journal\ncategory from each of the eight clusters\nobtained by Dorta-González &amp; DortaGonzález (2013) were considered. This\nwas done in order to obtain journals\nwith\nsystematic\ndifferences\nin\npublication and citation behaviour. A\ntotal of 618 journals were considered.\nThe categories and the number of\njournals are as follows: Astronomy &amp;\nAstrophysics (56); Biology (85);\nEcology (134); Engineering, Aerospace\n(27); History &amp; Philosophy of Science\n1848\n\n(56); Mathematics, Interdisciplinary\nApplications (92); Medicine, Research\n&amp;\nExperimental\n(112);\nand\nMultidisciplinary Sciences (56).\nTable 1. Journal impact factors\nJournal title\n\n2-JIF\n\nAIAA J\nAM NAT\nANN NY ACAD SCI\nASTRON ASTROPHYS\nASTROPHYS J\nBIOL PHILOS\nBIOMETRIKA\nBRIT J PHILOS SCI\nECOLOGY\nECONOMETRICA\nEXP HEMATOL\nFASEB J\nHIST SCI\nIEEE T AERO ELEC\nSYS\nJ ECONOMETRICS\nJ GUID CONTROL\nDYNAM\nLIFE SCI\nP NATL ACAD SCI\nUSA\nP ROY SOC A-MATH\nPHY\nPHYS REV D\nPLOS ONE\nSTRUCT EQU\nMODELING\nTRENDS ECOL EVOL\nVACCINE\n\n1.057\n4.725\n3.155\n4.587\n6.024\n1.203\n1.913\n1.097\n4.849\n2.976\n2.905\n5.712\n0.667\n\n2MJIF\n1.458\n5.750\n3.372\n4.587\n6.024\n1.714\n3.141\n1.587\n6.868\n6.721\n3.497\n6.875\n0.818\n\n5-JIF\n1.277\n5.280\n2.997\n3.979\n5.102\n1.360\n2.575\n1.364\n6.007\n4.700\n3.088\n6.340\n0.699\n\n1.095\n\n2.288\n\n1.680\n\n1.349\n\n3.297\n\n2.496\n\n0.941\n\n1.370\n\n1.159\n\n2.527\n\n2.880\n\n2.732\n\n9.681 11.167 10.472\n1.971\n\n2.086\n\n1.987\n\n4.558\n4.092\n\n4.558\n5.756\n\n4.027\n4.537\n\n4.710 11.965\n\n7.195\n\n15.748 18.335 16.981\n3.766 4.163 3.700\n\nResults and discussion\nTable 1 shows a sample of 24 randomly\nselected journals from those with the\ngreatest overall impact (total citations)\nin eight JCR categories. Notice the\nampleness in the interval of variation for\neach indicator. The 2-JIF varies from\n0.667 to 15.748, while 2M-JIF varies\nfrom 0.818 to 18.335, for example. The\ngeneral pattern is an increment in the\n2M-JIF. However, this increment is in\npercentage terms much higher in the\nsmaller values. This effect produces a\nconcentration of data in the case of 2MJIF, and consequently a reduction in the\n\nvariance. Table 2 shows the centraltendency measures for the aggregate\ndata. It also shows the between-group\nvariances. Note that all target windows\nreduce the between-group variance.\nHowever, the maximum citation time\nwindow produces the greatest reduction\n(3.203). Thus, this normalization by\nvariable target windows reduces the\nbetween-group variance over 80%,\nwhen compared to within-group\nvariance.\nTable 2. Central-tendency and variability\nmeasures\nMeasures\nMedian\nMean\nWithin-group variance\nBetween-group variance\nReduction in variance\n\n2-JIF 2M-JIF 5-JIF\n1.245 1.745 1.531\n2.142 2.827 2.481\n3.203 3.998 3.505\n0.709 0.795 0.728\n2.494 3.203 2.777\n\nConclusions\nDifferent scientific fields have different\ncitation practices and citation-based\nindicators need to be normalized for\nsuch differences. In this paper, we\nprovide\na\nsource\nnormalization\napproach, based on a variable target\nwindow and we compare it with a\ntraditional normalization approach based\non a fixed target window.\nThe empirical application shows that our\nmaximum citation time window reduces\nthe between-group variance in relation\nto the within-group variance more than\nthe rest of the indicators analyzed.\nFinally,\nthe\njournal\ncategories\nconsidered are in very different areas in\nrelation to the impact maturity time.\nSome of them are penalized by the 2-JIF\nand favored by the 5-JIF, and vice versa.\n\nThis is the main reason why it is\nnecessary to be cautious when\ncomparing journal impact factors from\ndifferent fields. In this sense, our index\nhas behaved well in a great number of\njournals from very different fields.\nReferences\nAlthouse, B. M., West, J. D., Bergstrom,\nC. T., &amp; Bergstrom, T. (2009).\nDifferences in impact factor across\nfields and over time. Journal of the\nAmerican Society for Information\nScience and Technology, 60(1), 27–\n34.\nBensman, S. J. (2007). Garfield and the\nimpact factor. Annual Review of\nInformation Science and\nTechnology, 41(1), 93–155.\nBornmann, L., &amp; Daniel, H. D. (2008).\nWhat do citation counts measure? A\nreview of studies on citing behavior.\nJournal of Documentation, 64(1),\n45–80.\nDorta-González, P., &amp; Dorta-González,\nM. I. (2010). Indicador bibliométrico\nbasado en el índice h. Revista\nEspañola de Documentación\nCientífica, 33(2), 225–245.\nDorta-González, P., &amp; Dorta-González,\nM. I. (2011). Central indexes to the\ncitation distribution: A complement\nto the h-index. Scientometrics, 88(3),\n729–745.\nDorta-González, P., &amp; Dorta-González,\nM. I. (2013). Comparing journals\nfrom different fields of science and\nsocial science through a JCR subject\ncategories normalized impact factor.\nScientometrics (in press). DOI\n10.1007/s11192-012-0929-9\n\n1849\n\nACCURACY ASSESSMENT FOR BIBLIOGRAPHIC\nDATA\nMarlies Olensky\nmarlies.olensky@ibi.hu-berlin.de\nHumboldt-Universität zu Berlin, Berlin School of Library and Information Science, Unter\nden Linden 6, 10099 Berlin (Germany)\nIntroduction\nWhile a variety of bibliometric and\nbibliographic studies compared the two\nmain bibliometric data sources Web of\nScience (WoS) and Scopus (e.g. Meho\n&amp; Yang, 2007) in terms of coverage,\noverlap, citation counts, etc., only a few\nstudies\n(also)\ninvestigated\nthe\nunderlying problem: data quality of the\ndata values (e.g. Hildebrandt &amp; Larsen,\n2008). What do we know about the data\nquality situation in WoS and Scopus?\nAnd what is the impact of data quality\non citation analysis? In order to answer\nthese questions, we need to take one\nstep back and find a suitable method to\nassess data quality in these sources. This\nstudy investigates if an automated\nassessment, as described in the data\nquality literature, could be used to\nevaluate one aspect of data quality,\nnamely data accuracy, for bibliographic\ndata. The data accuracy of two\nbibliographic datasets from WoS and\nScopus is assessed and compared to a\nmanual assessment method. The results\ncontribute\nto\nthe\nresearch\non\ndetermining the impact of data accuracy\non citation analysis.\nInaccuracies in bibliometric data\nsources\nMoed &amp; Vriens (1989) conducted a\nstudy on the accuracy of citation counts,\npitfalls during data collection and the\ninfluence of random and systematic\n1850\n\nerrors on the citation analysis. They\noutline errors and variations occurring in\nthe fields author name, journal title,\npublication year, volume and starting\npage number. In 2008, Hildebrandt &amp;\nLarsen as well as Larsen, Hytteballe\nIbanez &amp; Bolling carried out two related\nstudies on errors in the WoS. Larsen,\nHytteballe Ibanez &amp; Bolling (2008)\ninvestigated WoS’ automatic matching\nand linking algorithm, identified\npatterns of errors and came up with\nimprovements to the algorithm. The\noverall results showed that of 33,024\ncitations 6.2% were erroneous with at\nleast one error. Hildebrandt &amp; Larsen\n(2008) took a closer look at the high\nerror rate in the field of Law. They\nfound the most common errors in WoS\nwere in the fields cited page, author\nnames and year. On the whole, none of\nthe previous studies looked further into\nfinding a standardized method of how\nthese errors could be rated and there is\nno distinct framework that allows a\nsystematic analysis of data quality in\nbibliometric data sources.\nData quality / accuracy assessment\nThe literature provides a variety of\ntechniques to assess data quality in\ndatabases and summarises those in\ndifferent data quality assessment\nframeworks (e.g. Batini, Cabitza,\nCappiello et al., 2008). However, before\napplying one or more of these\nframeworks to bibliographic data, one\n\nshould test if they are suitable for this\npurpose. Most of the frameworks follow\nRedman’s definition of data quality\n(1996, pp. 245). This study chooses to\ninvestigate data accuracy as one of the\nfour dimensions of data quality of data\nvalues (the others are completeness,\nconsistency and timeliness).\nData quality (DQ) literature defines data\naccuracy basically as the ratio of correct\nand incorrect values. A slightly more\ncomplex way to calculate data accuracy\nis to measure the distance between the\nvalues stored in the database and those\nassumed to be correct. Among others,\nRedman\n(1996)\nsuggests\nthe\nLevenshtein or the Jaro-Winkler\ndistance function. The Levenshtein\nscore equals the number of singlecharacter edits to turn one value into the\nother, whereas the Jaro-Winkler score\nmeasures the similarity of two strings.\nIdeally, the values from the database are\nmeasured against the real-world objects.\nResearch questions and data sample\nThe author addresses the following\nresearch questions:\n Do the data sources differ with\nregard to their data accuracy scores\nwhen assessed according to the DQ\nmethod and manually?\n As opposed to using the original\npublication for verification, could\nthe publication list on the\ninstitutional website serve as silver\nstandard to simplify the data\naccuracy assessment?\nWoS and Scopus provide good coverage\nof chemistry literature that is why two\nNobel Prize winners, one Englishspeaking and one from a non-English\nspeaking country, from that domain\nwere chosen: Roger D. Kornberg, an\nAmerican biochemist and Professor at\nStanford University School of Medicine\n\nand Gerhard Ertl, a German physicist\nand Professor emeritus at the\nDepartment of Physical Chemistry at\nFritz-Haber-Institut der Max-PlanckGesellschaft in Berlin, Germany.\nPublications of both Nobel Prize\nwinners were retrieved for a publication\nperiod of 10 years (1998-2007),\nregardless whether they were the first or\nco-author. Articles and proceedings /\nconference papers were analysed, all\nother publication types were excluded.\nMethodology\nThe full bibliographic records from\nWoS and Scopus were downloaded,\ninvestigated and compared to the\noriginal publication (gold standard) and\nthe data from the institutional websites\n(silver standard). Bibliographic data\naccuracy is characterized by the data\nfields of author name(s) (including first\nand second initial of the given names),\narticle title, journal title, volume\nnumber,\npublication\nyear\nand\npagination (Olensky, 2012), which are\ntherefore used as assessment parameters.\nThe automated evaluation calculated the\nLevenshtein distance score for each\nbibliographic field, comparing it to the\noriginal publication and the data from\nthe institutional websites. The findings\nof a previous literature study (Olensky,\n2012), where the author investigated the\ndefinition of what an inaccuracy is as\nwell as the weighting of these in the\ndifferent bibliographic fields, were\nconsidered\nduring\nthe\nmanual\nassessment.The author analysed the\ndiscrepancies the automatic evaluation\nhad found and assigned inaccuracy\npoints (IAP) to the respective data fields\nin order to weigh inaccuracies according\nto their impact: 0 = accurate, 1 = minor,\n2 = medium, 3 = major inaccuracy.For\neach assessment method, the scores\nwere accumulated for each record per\ndataset and the total accuracy scores\n1851\n\nwere calculated. Additionally, the data\nsource providing the lowest score per\nrecord was determined and accumulated\nper dataset.\nResults and Conclusion\nThe main result is that the Levenshtein\ndistance function is a good means to\ndetermine whether a data record\ncontains discrepancies, but the score\ndoes not provide a true picture of how\ninaccurate a field is without the\napplication of additional rules. Table 1\nillustrates the accuracy scores from the\nmanual and the automated evaluation.\nTable 1. Accuracy scores compared to\noriginal publication and website,\nautomated/manual assessment method, on\nrecord level.\nWoS\nErtl Kornb.\nOrig.aut.\n30% 27%\nWebs.aut. 38%\n15%\nΔ\n8%\n12%\nOrig.man. 59% 73%\nWebs.man. 55% 81%\nΔ\n4%\n8%\n\nScopus\nErtl Kornb.\n37%\n38%\n8%\n5%\n29%\n33%\n75%\n90%\n59%\n87%\n16%\n3%\n\nThe rules found in the course of the\nmanual assessment reflect most of the\nrequired adjustments to be made to the\nautomatic\nassessment\nmethod.\nRegarding the question whether the\npublication list from the institutional\nwebsite could be used as silver standard\ninstead of manually gathering the\nbibliographic data from the original\npublications, further analysis is needed\nand more websites need to be examined\nfor their suitability.\nIn contrast to the accuracy scores on\nrecord level, the accuracy scores per\nfield are high (≥ 95%). This proves that\nboth, WoS and Scopus, provide very\naccurate data values and the difference\nbetween them is marginal. Both\n1852\n\nassessment methods confirmed that\nScopus provides the most accurate data\nfor both data samples. In future work,\nthe author will apply the modified\nassessment method to a larger, more\nrepresentative data sample that includes\ncited and citing publications. Also, the\nimpact on citation analysis will be\ninvestigated with the ultimate goal of\nfinding a standardized assessment of\nbibliographic data accuracy.\nReferences\nBatini, C., Cabitza, F., Cappiello, C., &amp;\nFrancalanci, C. (2008). A\ncomprehensive data quality\nmethodology for Web and structured\ndata. International Journal of\nInnovative Computing and\nApplications, 1(3), 205–218.\nHildebrandt A.L., Larsen B. (2008).\nReference and Citation Errors – a\nStudy of Three Law\nJournals.Presentation of student\nwork at the Royal School of Library\nand Information Science.\nCopenhagen, Denmark.\nLarsen B., Hytteballe Ibanez K., Bolling\nP. (2008). Error Rates and Error\nTypes for the Web of Science\nAlgorithm for Automatic\nIdentification of Citations.\nPresentation of student work at the\nRoyal School of Library and\nInformation Science.Copenhagen,\nDenmark.\nMeho, L. I., &amp; Yang, K. (2007). Impact\nof Data Sources on Citation Counts\nand Rankings of LIS Faculty: Web\nof Science vs. Scopus and Google\nScholar. Journal of the American\nSociety for Information Science and\nTechnology, 58(13), 2105–2125.\nMoed, H. F., &amp; Vriens, M. (1989).\nPossible inaccuracies occurring in\ncitation analysis. Journal of\nInformation Science, 15(2), 95‐107.\n\nOlensky, M. (2012). How is\nBibliographic Data Accuracy\nAssessed? In É. Archambault, Y.\nGingras, &amp; V. Larivière (Eds.),\nProceedings of 17th International\nConference on Science and\n\nTechnology Indicators (pp.628–639).\nMontréal.\nRedman, T. C. (1996). Data quality for\nthe information age. The Artech\nHouse computer science library.\nBoston Mass.: Artech House.\n\n1853\n\nANALYSIS OF SEARCH RESULTS FOR THE\nCLARIFICATION AND IDENTIFICATION OF\nTECHNOLOGY EMERGENCE (AR-CITE)\nRobert K. Abercrombie, Bob G. Schlicher, and Frederick T. Sheldon\nabercrombier@ornl.gov, schlicherbg@ornl.gov, and sheldonft@ornl.gov\nOak Ridge National Laboratory, 1 Bethel Valley Road, Oak Ridge, TN 37831-6085\n(USA)\nIntroduction\nThis research examines emerging\ntechnologies from initial discovery (via\noriginal scientific and conference\nliterature), through critical discoveries\n(via original scientific, conference\nliterature and patents), transitioning\nthrough Technology Readiness Levels\n(TRLs) and ultimately on to commercial\napplication. The purpose of this study is\nto address the relationships among\nmultiple\ndisparate\nsources\nof\ninformation as a way to explain\nsystematically the emergence of new\ntechnologies from innovation on\nthrough to commercial application with\nregards to TRLs. In one example, we\ninvestigate the combinations of four\ndistinct and separate searchable on-line\nnetworked sources (i.e., scholarly\npublications and citation, patents, news\narchives, and on-line mapping networks)\nas they are assembled to become one\ncollective network (a data set for\nanalysis of causal relations). In another\nexample,\nwe\ninvestigate\nthe\ncombinations of five categories of data\nsources (i.e., university R&amp;D, industry\nR&amp;D, product emergence, and two\nlevels of annual market revenue [$1B\n(USD) and $10B (USD)]). These\nestablished networks and relationships\nform the basis analyze the temporal flow\nof activity (searchable events) for the\n\n1854\n\nmultiple example subject domains that\nwe investigated.\nBackground Related Work\nThe logical sequence of milestones is\nderived from our analysis of a\npreviously documented data set and\ntechnology that includes the initial\ndiscovery (evident via original scientific\nand\nconference\nliterature),\nthe\nsubsequent critical discoveries (evident\nvia original scientific, conference\nliterature and patents), and the\ntransitioning through the various TRLs\nultimately to commercial application\n(Abercrombie, Udoeyop, &amp; Schlicher,\n2012).\nThe TRL is defined as a measure used to\nassess the maturity of evolving\ntechnologies\n(devices,\nmaterials,\ncomponents, software, work processes,\netc.) during their development and in\nsome cases during early operations\n(&quot;Defense Acquisition Guidebook,&quot;\n2012). TRLs can serve as a helpful\nknowledge-based\nstandard\nand\nshorthand for evaluating and classifying\ntechnology maturity, but they must be\nsupplemented with expert professional\njudgment.\nResearch\nHypothesis\nand\nExperimental Design\nThe question we investigate is the\nfollowing. “Can one map the life cycle\nof a technology in a standard\n\nmethodological way to quickly identify\nand classify the emergence of a specific\ntechnology?”\nUsing the technology evolution model\n(TEM) developed in our prior work\n(Abercrombie, et al., 2012), a step wise\nanalysis was conducted, applying the\ndefinitions of the TRLs to the\ncorresponding milestones in the TEM to\ntwo case studies. The first case study\napplied the TEM to investigate the\noriginal Simple Network Management\nProtocol (SNMP) data set spanning the\nyears 1988–2008. The second case study\nconducted a similar step-wise TRL\nanalysis on a data set, spanning the\nyears 1965–2011 (Lee et al., 2012). This\nsecond study addressed the evolution of\neight specific subject areas of\nfundamental research in Information\nTechnology\n(IT)\n(Digital\nCommunications,\nComputer\nArchitecture, Software Technologies,\nNetworking, Parallel &amp; Distributed\nSystems,\nDatabases,\nComputer\nGraphics, and AI &amp; Robotics), and\nrespective industry interest categories\n(Broadband\n&amp;\nMobile,\nMicroprocessors,\nPersonal\nComputing,\nInternet &amp; Web, Cloud Computing,\nEnterprise Systems, Entertainment &amp;\nDesign, and Robotics &amp; Assistive\nTechnologies) documenting university\nresearch (equivalent to scholarly pursue)\nand industry R&amp;D (represented in\npatents and trade secrets) evolution to\nproducts with their respective market\nshare.\nResults\nThe first data set consists of four distinct\nand\nseparate\nsearchable\non-line\nnetworked sources (i.e., scholarly\npublications and citation, patents, news\narchives,\nand\non-line\nmapping\nnetworks). The data reflects a time line\nof the technology transitions categorized\nby TRLs as shown in Figure 1. These\n\nresults convinced us to adapt the TEM\nso that the TRLs are used to determine\nthe stage in the sequence of evolution\n(technology transfer).\nThe second case study uses the modified\nTEM to study a data set created from\nsurvey data from the IT Sector (Lee, et\nal., 2012) measuring the relationships\namong universities, industry, and\ngovernments’\ninnovations\nand\nleadership. Figure 2 identifies the TRL\ntransitions on eight subject areas of\nfundamental research in IT and industry\ninterest categories.\n\nFigure 1. SNMP Technology Identification\nby TRLs.\n\nFigure 2. Area of Fundamental IT\nResearch Technology Identification by\nTRLs.\n\nDiscussion and Conclusion\nIn general, when a new technology is\nfirst invented or conceptualized, it is not\nsuitable for immediate application.\nInstead, new technologies are usually\nsubjected\nto\nexperimentation,\nrefinement, and increasingly realistic\n1855\n\ntesting.\nHowever,\napplying\nthe\ndefinitions of the TRL transitions\nprovides\na\nstepwise\nconcrete\nexplanation for the subject technology’s\nevolution thus giving insight into its\nmaturity and market impact.\nThis work examines and clarifies how to\nsystematically classify the technology\nevolution starting from an initial\ndiscovery (via original scientific and\nconference literature), through critical\ndevelopments (via original scientific,\nconference literature and patents),\ntransitioning\nthrough\nTRLs\nto\ncommercial application and significant\neconomic impact. The relationships\namong multiple disparate sources of\ninformation were addressed, as a way to\nexplain systematically the identifiable\nstates of new technologies, from\ninnovation on through to commercial\napplication. In the first case study we\nselected a very well-known documented\ntechnology to test the TRL transitioning\nhypothesis. In the second case study the\nTRL transitioning hypothesis was\nvalidated by selecting a cross-section of\nfundamental IT research domains and\ntheir corresponding industry interest\ncategory spanning 1965–2011. In both\nstudies, applying the TRL transitioning\ntechnique to the documented subject\nareas resulted in trends that clarified and\nrefined the identification of the\nemergent\ntechnology.\nThe\nTRL\ntransitions, in the modified TEM, are\nuseful in the creation of business\nintelligence.\nBusiness\nintelligence\nassists in providing a basis for strategic\nbusiness decision(s). Further research is\nneeded to refine the critical underlying\ndata sources. In this study only two\neconomic impact categories were used.\nTo better under the progression (i.e.,\nenabling breakthroughs) of technology\ntransfer, it will be necessary to\nsubdivide\nthe\neconomic\nimpact\n\n1856\n\ncategories into smaller bin sizes.\nAnother area of investigation is to\naddress the associated supply chains\namong the industry interest categories.\nWe would like to better understand how\ninventions from one category affect\n(overlap) the emergence (development)\nproperties in another category (e.g.,\nphone\nhardware\nversus\niTunes\nsoftware). Moreover, we intend to\ninvestigate alternative techniques to\nbetter understand key agents of change\n(i.e., TRL transitioning) toward a more\nrobust identification of technology\nemergence.\nAcknowledgments\nThis manuscript has been authored by a\ncontractor of the U.S. Government\n(USG) under contract DE-AC0500OR22725. Accordingly, the USG\nretains a nonexclusive, royalty-free\nlicense to publish or reproduce the\npublished form of this contribution, or\nallow others to do so, for USG purposes.\nReferences\nAbercrombie, Robert K., Udoeyop,\nAkaninyene W., &amp; Schlicher, Bob\nG. (2012). A study of scientometric\nmethods to identify emerging\ntechnologies via modeling of\nmilestones. Scientometrics, 91(2),\n327-342. doi: 10.1007/s11192-0110614-4\nDefense Acquisition Guidebook. (2012).\nRetrieved January 15, 2013, from\nhttps://acc.dau.mil/CommunityBrow\nser.aspx?id=518692&amp;lang=en-US\nLee, Peter, Dean, Mark E., Estrin,\nDeborah L., Kajiya, James T.,\nRaghavan, Prabhakar, &amp; Viterbi,\nAndrew J. (2012). Continuing\nInnovation in Information\nTechnology. Washington, DC: The\nNational Academies Press.\n\nAPPLICATIONS AND RESEARCHES OF GIS\nTECHNOLOGIES IN BIBLIOMETRICS\nWang Xuemei1, 2, Ma Mingguo2, Li Xin2, Zhang Zhiqiang1and Ma Jianxia1\n1\n\nwxm@lzb.ac.cn; zhangzq@lzb.ac.cn; majx@lzb.ac.cn\nLanzhou Branch of the National Science Library, Scientific Information Center for\nResources and Environment, Chinese Academy of Sciences, Lanzhou, 730000 (China)\n2\n\nmmg@lzb.ac.cn; lixin@lzb.ac.cn\nCold and Arid Regions Environmental and Engineering Research Institute, Chinese\nAcademy of Sciences, Lanzhou, 730000 (China)\nIntroduction\nThe literatures normally involve some\nspatial related information. The basic\ninformation source is the authors’\ninstitutes, cities and countries of articles,\nciting and cited articles. For example,\nthe study areas, sampling points,\nobserving points, sampling units,\nsampling strips are this kind of\ninformation.\nGeographic Information System (GIS)\nintegrates hardware, software, and data\nfor capturing, managing, analyzing, and\ndisplaying all forms of geographically\nreferenced information. It is widely use\nin practically every profession. There\nare also some practical applications and\ninitial research works in recent years. In\nthis paper, the advance of applications\nand researches of GIS technologies in\nbibliometrics was reviewed. Then the\npotential and further works was\ndiscussed in the prospect part.\n\nexample, the author affiliations, cities\nand countries of author and co-authors\nare normally included in the literature.\nBecause the names of cities and states\nhave fixed formats, they can be linked\nwith the vector data within the spatial\ndistribution information (Wang &amp; Ma,\n2009). The author affiliations are also\nrelatively customary. Sometimes the\nshorter form or subsidiaries are used,\nwhich can be normalized based on the\nunit dictionary.\nThere are abundant toponym (place\nname) information in the abstracts and\ntexts of the literature. These toponym\ndata can also be linked with the vector\ndata. But the toponym data is very\ncomplicated. There are various place\nforms, such as towns, mountains, rivers,\nlakes, or streets. But the least of the\ndifficulties is the linkage between the\nplace names with the map coordinates\nreference place points or regions.\nTherefore the researches can focus on\nsome thematic place names.\n\nSpatial information mining from the\nliterature\nFor the spatial analysis and display, the\nraw spatial information is the important\nbase and need to be extracted from large\nmass of literature. Some information\nwith the regular structure can be\nextracted automatically and quickly. For\n\nSpatial display and basic spatial\noperations\nSpatial display and spatial query are the\nbasic operations of the GIS tools. The\nGIS is used directly in the digital library\nconstruction. With the development of\nthe WEBGIS, more and more literature\n1857\n\ndatabase websites begin to use WEBGIS\nto display the spatial distribution of the\nauthors, the spatial relationship among\nthe co-authors and citations. For\nexample,\nthe\nBioMedExperts,\nAuthorMapper\nwere\ndeveloped\nbyGoogle Earth or Google map. Some\nother browsing tools were developed for\ngeographic digital library, such as\nGeoVIBE andLitmap.\nThe literature citation of a research unit\n(e.g. researcher, laboratory, institute,\ncity or country) can also be displayed on\nspatial map. The interannual changes\ncan be shown by using histogram or\ntrend line for each spatial vector feature.\nWhen the spatial feature was queried,\nthe linked database of multi-year data\ncan be shown. The patent is also an\nimportant literature format. The\nUSPTO’s patent data are mapped and\ndisplayed using overlays to Google\nMaps. The overlays indicate both the\nquantity and quality of patents at the city\nlevel (Leydesdorff&amp;Bornmann, 2012).\nOn the contrary, it is difficult to display\nspatial-linked information with the\nirregular structure on the internet. The\nmost important step is the information\nextraction of other items with the\nirregular structure, which is the work\nfocus in the future. After this step, the\nspatial information linked with the\nvector data was extracted from the\nliterature, it could be inputted into the\nGIS tools.\nSpatial analysis\nSpatial analysis is the process to conduct\nspatial data various kinds of handling,\nand then get information, clues and\nknowledge from that. Here it can\nadvance the deep data mining of the\nspatial-linked information from the\nliterature. GIS provides the specialized\nplatforms\nfor\ncomputing\nspatial\nrelationships among spatial units. The\nmost commonly used spatial analysis\n1858\n\nmethods include tracking analysis,\nbuffer analysis, overlay analysis, route\nanalysis, network analysis, spatial\ninterpolation, geostatistical analysis. The\napplication of the GIS spatial analysis in\nBibliometrics is still in its beginning\nstage.\nFor example, the spatial interpolation\nmethod can be used to find the high\ndensity regions based on the highlycited paper numbers. It can also be used\nto detect the “hot regions” of the\nscientific publication and citation\n(Bornmann&amp;Waltman,\n2011). The\ngeostatistical analysis was used in the\ngeostatistics literature indexed from\nWeb of Science, Scopus and Google\nScholar (Heng, Minasny&amp; Gould,\n2009). The buffer regions were used to\nanalyze the spatial distribution of the\nsampling points in Qinghai-Tibet\nPlateau as the increasing distance with\nthe traffic lines, such as railway and\nhighway (Wang, Ma, Li, &amp; Zhang,\n2012).\nQuantitative indexes\nSome Bibliometrics indexes were\ndeveloped to quantify the characteristics\nand amounts of the literatures.When\nthese quantitative indexes of the\nresearch units are linked with the spatial\npositions of these research units, they\ncan be displayed, queried and retrieved\nspatially. Some newly developed\nquantitative indexes with geographical\nposition and direction are more suitable\nfor spatial representation and analysis by\nusing GIS technologies.The distance\nfactor is also used to measure the spatial\ndistribution pattern of the bidirectional\nknowledge flow. The spatial distance is\ncalculated among the citing or cited\npapers based on the GoogleMapAPI and\nYahoo PlaceFinder. But the relative\nresearches are still in the initial stage\nand made in recent years.\n\nConclusions and discussion\nFor promoting the application and\nresearch of the GIS in Bibliometrics,\nthere are some works can be carried out\nin the future.\n(1) Application of regular information\nstructure. The regular information\nstructure can be queried and calculated\ninstantly and automatically. If there is\nmore\ngeographically\nrelative\ninformation with regular structure in the\narticles, it is easier for literature\ndatabase to display its resources using\nthe GIS platforms. Some international\nstandards can be set up especially for the\nscientific publication. The authors and\ntheir affiliation information need be\nstandardized in formats and word use.\nThe spatial position involved in main\ntext can also be standardized with the\nunified templates. But there are\ndifferences of the written requirement\namong various journals.\n(2) Preparation of basic thematic maps.\nFor the researchers who are engaged in\nthe Bibliometrics, it is difficult to collect\nand arrange the basic thematic maps for\nlinking the geographically relative\ninformation. Even though there are\nsome WEBGIS resources can be used\nopenly, some special applications need\nmore preparation work. For a given\nstudy area (e.g. Qinghai-Tibet Plateau,\nAmazon Basin), there are a lot of hot\nspot position names to call the local\nmountains, lakes, rivers, villages, and so\non. These position names are normally\nnot included in the general map\nplatforms, which need more collection\nand arrangement works.\n(3) Development of information\nrecognition tools. It is a key process to\nextract the geographically relative\ninformation from numerous scientific\narticles for using GIS in the\nBibliometrics. There are seldom special\ntools to realize information recognition\neasily. Some tools can be developed\n\ncurrently for the thematic information\nrecognition. It is also need to develop a\ntool to extract the coordinate\ninformation with latitude and longitude\nposition and output to the standard\ngeographic format.\n(4) Development of the internet display\nplatforms. There are a lot of internet\nelectric maps online, which are widely\nused and developed fast. We can use\nthese platforms to expand the functions\nto afford the information display and\nquery of spatial literature information.\nMore functions can be released\nespecially for the application of GIS in\nliterature representation. If possible, a\nspecifically designed internet display\nplatform is excepted to developed for\nrealizing this application needs.\nAcknowledgments\nThis work was supported by Special\nProject of Literature Ability of Chinese\nAcademy of Sciences, and the National\nNatural Science Foundation of China\n(grant no.: 40701133).\nReferences\nBornmann L. &amp;Waltman L. The\ndetection of “hot regions” in the\ngeography of science—A\nvisualization approach by using\ndensity maps. Journal of\nInformetrics 5 (2011c) 547– 553.\nHeng, T., Minasny, B. &amp; Gould, M.\n(2009).A geostatistical analysis of\ngeostatistics.Scientometrics, 80(2):\n491-514.\nLeydesdorff L. &amp;Bornmann L. Mapping\n(USPTO) Patent Data using\nOverlays to Google Maps. Journal of\nthe American Society for\nInformation Science and Technology\n63(7) (2012) 1442-1458.\nWang, X. M. &amp; Ma, M. G.\n(2009).Spatial information mining\nand visualization for Qinghai-Tibet\nPlateau&#x27;s literature based on GIS.\n1859\n\nProceedings of International\nSymposium on Spatial Analysis,\nSpatial-Temporal Data Modeling,\nand Data Mining (ISSA 2009) (pp.\n74920T, 1-8). Wuhan.\n\n1860\n\nWang, X. M., Li, X., Ma, M. G., &amp;\nZhang, Z. Q. (2012).Spatial analysis\non the geographical information of\nthe scientific literature for qinghaitibet plateau. Advances in Earth\nScience, 27(11): 1288-1294.\n\nAPPROPRIATE COVERAGE OF SCHOLARLY\nPUBLISHING IN THE SOCIAL SCIENCES AND\nHUMANITIES - A EUROPEAN OVERVIEW\nGunnar Sivertsen1, Elea Giménez-Toledo,2 and Tim C. E. Engels3\n1\n\ngunnar.sivertsen@nifu.no\nNordic Institute for Studies in Innovation, Research and Education (NIFU),\nWergelandsveien 7, NO-0167 Oslo, Norway\n2\n\nelea.gimenez@cchs.csic.e\nG.I.de Evaluación de Publicaciones Científicas (EPUC), Centro de Ciencias Humanas y\nSociales (CCHS) Spanish National Research Council (CSIC) C/ Albasanz, 26-28., 28037\nMadrid, Spain\n3\n\ntim.engels@ua.ac.be\nCentre for R&amp;D Monitoring (ECOOM), University of Antwerp, Middelheimlaan 1, B2020 Antwerp, Belgium, and Antwerp Maritime Academy, Noordkasteel Oost 6, B-2030\nAntwerp, Belgium\nIntroduction\nAchieving full coverage of the scholarly\npublications in the social sciences and\nhumanities (SSH) in bibliographic data\nsources is notoriously difficult (Hicks,\n1999; Archambault et al., 2006;\nNederhof, 2006). Although commercial\ndatabases such as the Web of Science\n(WoS) and Scopus have made\nconsiderable advances in increasing the\ncoverage of the archival journals and\narticles in these fields, they still give\nlimited representation of the SSH (Hicks\nand Wang, 2009) especially of output by\nresearchers in non-English-speaking\ncountries (Lariviére and Macaluso,\n2011). In Flanders, Norway and Spain,\nhowever, attempts have been made to\ncover the scholarly output in the SSH\nand its publication channels more\nsystematically and comprehensively\n(Sivertsen, 2010; Engels et al., 2012;\nGimenez-Toledo et al., 2013).\nIn this poster, we will present an\noverview of how European countries\n\nmanage to cover the publications in the\nsocial sciences and humanities in\nbibliographic databases for statistics,\nassessment and/or funding of research.\nIt is our hypothesis that there are recent\nachievements with regard to better\ncoverage in several countries. Still, they\nare not yet visible on the European\nlevel. Hence there is a need for an\noverview and maybe also a potential for\ncollaboration between the initiatives.\nMethods\nWe have performed a survey on email\nsince February 2013 by contacting 28\ncolleagues in 28 countries and asking\nthem to answer the questions cited\nbelow. If no response, we will contact\nother colleagues in the same country. So\nfar, we have responses from 19\ncountries. We expect this number to\nincrease before we finalize the poster,\nwhich we will design with the following\nelements:\n- A map of Europe visualizing the\nmain results from each country\n1861\n\n-\n\nTables summarizing in more detail\nthe results from the survey\nA short text discussing the results\nand their implications.\n\nThe questionnaire\nThe questions covered by our survey are\ncited below:\n\nb. At the institutional level:\nc. Other:\n5. Are the researchers themselves\nproviding and/or correcting their\ndata?\n6. Are the data complete from the point\nof view of the individual researcher?\n7. Are the data available in a database\nthat can be searched and analysed?\na. If yes, supply URL:\n\n1. In your country, are comprehensive\nbibliographic data (exceeding the\njournal coverage in ISI Web of\nKnowledge or Scopus) for scholarly\npublishing in the social sciences and\nhumanities collected systematically\n(not only as individual publication\nlists) and continuously (i.e. not only\nas part of a survey) for the purpose\nof research information, statistics,\nassessment or funding?\n\n8. If there are examples of published\nstudies based on these data, please\ngive one or more references:\n\nIf no, you may reply without\ncontinuing to the other questions. If\nyes,\n\n10. Please add more information if you\nwould like to do so (e.g. more details\nabout the types of data).\n\n2. Are these publication types covered?\na. Articles\nin\npeer-reviewed\ninternational journals\nb. Articles\nin\npeer-reviewed\nnational journals\nc. Articles in edited scholarly books\nand book series\nd. Scholarly monographs\ne. Publications for students and\nnon-academic audiences\n3. For which purpose?\na. Research information\nb. Statistics and studies\nc. Research assessment\nd. Project funding\ne. Institutional funding\nf. Full text repositories\ng. Other:\n\nResults and discussion\nThe preliminary result is that there are\nvariations within Europe from countries\nthat\nhave\nachieved\ncomplete\nrepresentations of the scholarly output in\nthe SSH to countries with no\nrepresentation at all. We observe that\nseveral countries in Eastern Europe have\nimplemented database or current\nresearch information systems (CRIS)\nthat cover SSH output to a large extent.\nIn the Nordic countries too, several\ninitiatives\nhave\nsuccessfully\nimplemented. In large countries such as\nGermany, a more mixed pattern\nemerges, often with databases that are\nfocused on one or more disciplines\nrather than the whole of the SSH. We\nconclude that in several countries clear\nprogress has been made in achieving\ncomprehensive coverage of SSH output.\nThe full results of our survey will be\npresented and discussed in the poster.\n\n4. At which level are the data collected\n(please provide URL to relevant\norganization(s)?\na. At the national level:\n1862\n\n9. Please name relevant organizations\nor persons that you would like us to\nknow of:\n\nReferences\nArchambault, E. et al. (2006)\n‘Benchmarking Scientific Output in\nthe Social Sciences and Humanities:\nThe Limits of Existing Databases’,\nScientometrics, 68: 329–42.\nEngels, T. C. E., Ossenblok, T. L. B.\nand Spruyt, E. H. J.(2012)\n‘Changing Publication Patterns in\nthe Social Sciences and Humanities,\n2000-2009’, Scientometrics, 93 (2).\n373-390.\nGimenez-Toledo, E., Tejada-Artigas, C.,\nand Manana-Rodriguez, J. (2013).\nEvaluation of scientific books&#x27;\npublishers in social sciences and\nhumanities: Results of a survey.\nResearch Evaluation, 22 (1): 64-77.\nHicks, D. (1999) ‘The Difficulty of\nAchieving Full Coverage of\nInternational Social Science\nLiterature and the Bibliometric\nConsequences’, Scientometrics, 44:\n193–215.\n\nHicks, D. and Wang, J. (2009) Towards\na Bibliometric Database for the\nSocial Sciences and Humanities. A\nEuropean Scoping Project\n(Appendix 1 to Martin et al., 2010).\nArizona: School of Public Policy,\nGeorgia University of Technology.\nLariviére, V. and Macaluso, B. (2011)\n‘Improving the Coverage of Social\nScience and Humanities\nResearchers’ Output: The Case of\nthe Érudit Journal Platform’, Journal\nof the American Society for\nInformation Science &amp; Technology,\n62: 2437–42.\nNederhof, A. J. (2006) ‘Bibliometric\nMonitoring of Research Performance\nin the Social Sciences and the\nHumanities: A Review’,\nScientometrics, 66: 81–100.\nSivertsen, G. (2010). A performance\nindicator based on complete data for\nthe scientific publication output at\nresearch institutions. ISSI\nNewsletter, 19 (6), 22-28.\n\n1863\n\nARE REGISTERED AUTHORS MORE\nPRODUCTIVE?\nSarah Heeffer1, Bart Thijs2, and Wolfgang Glänzel3\n1\n\nsarah.heeffer@kuleuven.be\nKU Leuven, ECOOM and Dept. MSI, Leuven (Belgium)\n2\n\nbart.thijs@kuleuven.be\nKU Leuven, ECOOM and Dept. MSI, Leuven (Belgium)\n3\n\nwolfgang.glanzel@kuleuven.be\nKU Leuven, ECOOM and Dept. MSI, Leuven (Belgium)\nLibrary of the Hungarian Academy of Sciences, Dept. Science Policy &amp; Scientometrics,\nBudapest (Hungary)\nIntroduction\nThe identification of authors in\nbibliographic databases and their\nassignment to research universities,\nresearch institutions or companies is still\none of the big challenges in\nScientometrics at the micro and meso\nlevel. Correct author identification is\nindispensable, above all, in longitudinal\nstudies on scientific careers, studies of\nresearchers’ mobility or in monitoring\nconstitution and performance of\nresearch teams (Strotman &amp; Zhao,\n2012). Recently the large abstract and\ncitation databases Web of Science\n(Thomson\nReuters)\nand\nScopus\n(Elsevier)\nhave introduced their\nResearcherID\nand Author ID,\nrespectively. Both are supposed to\nuniquely identify scientific authors but\nexperience has taught us that these IDs\nare not yet fully implemented and that\nerrors and multiple assignments are not\nquite the exception to the rule.\nThe present study aims at a systematic\nanalysis\nof\nthe\ncleanness\nof\nResearcherIDs, their acceptance by\nauthors and their implementation in the\nmirror of national research output and\n1864\n\nsubject-specific peculiarities as reflected\nby major science fields. Finally we have\nanalysed in how far ResearcherIDs can\nbe used to represent national and fieldspecific publication-activity patterns.\nThe latter question is important to find\nreference standards for publication\nactivity such as otherwise only known\nfor citation indicators so far.\nData sources and data processing\nIn order to use a reasonable publication\nset we have selected seven countries\nfrom Europe and one country from Asia.\nThese countries are Austria, Belgium,\nGermany, Hungary, Netherlands, China,\nSwitzerland and UK.\nAll ‘citable’\ndocuments with at least one author from\nthese countries and one or more authors\nwith ResearcherID (RID) have been\ndownloaded from the 2009–2011\nvolumes of the online version of\nThomson Reuters’ (TR) Web of Science\n(WoS). It should be stressed that the\nauthor with RID needs not necessarily\nbe affiliated with an institution in the\ncountries in question. After download\nthese papers have been matched with all\npublications from these countries\nextracted from the WoS custom-data set\n\nlicensed at ECOOM. In a following step\nall RIDs have been uniquely assigned to\ncountries on the basis of TR’s affiliation\ntag. RID’s from foreign countries have\nbeen removed from the national sets. All\nauthors without RID have also been\nassigned to countries and – as far as\npossible – disambiguated on the basis of\nname and first initial and affiliation.\nAfter the cleaning process a certain\namount of homonyms and synonyms\nstill remains in the data set as well as\nsome uncertainty about the authors’\nconsequent and correct mention of their\nidentifiers. All papers have been\nassigned to major fields on the basis of\nthe Leuven-Budapest classification\nscheme. Papers can be assigned to more\nthan one field or country due to journal\nassignment\nand\nco-authorship,\nrespectively.\nTable 1. Shares of RID authors and\npapers with RID authors per country\n[Data sourced from Thomson Reuters\nWeb of Knowledge]\nCountry\nAUT\nBEL\nDEU\nHUN\nNLD\nCHN\nCHE\nGBR\n\nPapers A (%) B (%) C (%)\n36272 45.7\n12.1 27.1\n53682 42.8\n13.7 28.4\n277524 41.2\n15.4 22.9\n17073 49.6\n20.9 31.6\n97625 45.1\n19.2 30.2\n423510 36.5\n13.0 26.4\n69958 47.8\n16.5 19.6\n298857 48.8\n12.5 27.7\n\nLegend: A = Mean share of RID per paper, B =\nshare of papers with RID, C = share of authors\nwith RID\n\nMethods and results\nResearcher names associated with RIDs\nwere matched with author names as they\nappear on the paper. This allowed us to\nidentify some problems. First, RIDs are\nnot only used by authors. Some\ninstitutes and author groups mark their\npublications by an RID. Some RIDs\nclaim several papers while the\nresearcher name does not match any of\n\nthe authors. A RID is not always unique.\nSome authors have created and are using\ndifferent RIDs to claim the same papers\nwith these different RIDs. The\noverwhelming share of RIDs, however,\nseems to be created by individuals and\nused in a correct manner.\nTable 1 displays the mean shares of\nauthors with RID (A) and the share of\npapers (B) respectively authors (C) with\nan RID. On an average, 40%–50% of\nauthors on a paper have a RID\nregistration. In China we have found the\nlowest share, while Hungary and the UK\nhave the highest one around 50%.\nNational shares of papers with RID\nauthors is much lower; it ranges\nbetween 12% and 21%. Here Hungary\nand the Netherlands are at the high end\nand the UK has jointly with Austria the\nlowest share. Similarly, Hungary and the\nNetherlands have the highest shares of\nregistered authors but unlike the\nprevious\nstatic,\nGermany\nand\nSwitzerland form the low end here.\nRoughly one quarter to one third of all\nauthors from the country selection use a\nRID registration. These effects are not\nthe result of foreign collaboration since\nco-authors from other countries have\nbeen removed from the statistics.\nTable 2. Mean publication activity of RID\nauthors vs. authors in RID papers and all\nauthors per country [Data sourced from\nThomson Reuters Web of Knowledge]\nCountry\nAUT\nBEL\nDEU\nHUN\nNLD\nCHN\nCHE\nGBR\n\nA\n3.89\n4.52\n4.95\n4.00\n4.00\n23.34\n4.32\n4.09\n\nB\n3.35\n3.16\n3.84\n2.99\n3.02\n9.26\n4.60\n3.13\n\nC\n7.73\n7.02\n7.56\n4.76\n7.77\n8.33\n6.81\n5.39\n\nLegend: A = Mean activity of all authors, B =\nMean activity of authors in RID papers, C = Mean\nactivity of RID authors\n\n1865\n\nTable 3. Mean publication activity of all\nauthors (A) vs. RID authors (C) per major\nfield [Data sourced from Thomson\nReuters Web of Knowledge]\nField\nA\nB\nC\nE\nG\nH\nI\n\nA\n2.17\n2.40\n3.12\n2.14\n3.58\n1.89\n2.98\n\nC\n3.05\n3.01\n4.76\n2.37\n4.10\n1.90\n3.53\n\nField\nM\nN\nO\nP\nR\nS\nZ\n\nA\n3.11\n2.51\n1.74\n4.96\n1.97\n1.67\n2.48\n\nC\n4.40\n3.84\n2.25\n4.85\n2.28\n2.15\n3.53\n\nLegend: A: agriculture &amp; environment; B:\nbiosciences (general, cellular &amp; subcellular\nbiology; genetics); C: chemistry; E: engineering;\nG: geosciences &amp; space sciences; H: mathematics,\nI: clinical and experimental medicine I (general &amp;\ninternal medicine); M: clinical and experimental\nmedicine II (non-internal medicine specialties); N:\nneuroscience &amp; behavior; O: social sciences II\n(economical &amp; political issues), P: physics; R:\nbiomedical research; S: social sciences I (general,\nregional &amp; community issues), Z: biology\n(organismic &amp; supraorganismic level)\n\nThe mean activity of all authors in the\nRID set is generally somewhat lower but\nstill in line with the activity of all\nauthors. Here the Chinese value is more\nrealistic. As expected, the activity of\nauthors using RID (cf. column C in\nTable 2) is distinctly higher than the\nactivity of all authors (except for China).\nHowever, China has still the highest\nactivity, followed by the Netherlands,\nAustria and Germany. Of course, these\nvalues can be influenced by national\npublication profiles, therefor we have a\nlook at subject-specific peculiarities of\nactivity patterns before we have a closer\nlook at the distribution of papers over\n1866\n\nauthors using or not using RID. Because\nof the bias in the Chinese data, we have\nremoved China in the following. Table 3\nshows the mean activity (all authors vs.\nRID) for 12 major fields in the sciences\nand two fields in the social sciences.\nAgain, the mean publication activity of\nRID authors generally exceeds that of\nthe reference standard based on all\nauthors. Physics forms the only\nexception.\nAlso\nsubject-specific\npeculiarities\ncan\nbe\nobserved:\nmathematics and the social sciences\nhave the lowest standards, followed by\nbiomedical research and engineering.\nThe deviation of the values presented in\nTable 3 from those in Table 2 are caused\nby the ‘multidisciplinarity’ of authors:\nRID authors are active in 2.5 fields on\nan average, while all authors in about\n2.2 fields.\nThe mean activity of all authors in all\nfields combined amounts to 4.71, that of\nRID authors 6.87. Similarly, the\ncorresponding share of authors with one\npaper amounts to 43.1% and 21.7%,\nrespectively. Furthermore, RID authors\nare more productive at the high end of\nthe distribution. The distribution is\nplotted in Figure 1. It goes without\nsaying that the two distributions are\ndistinctly different and it needs no\nfurther significance test.\n\nRelative frequency\n\nThe comparison of publication activity\nreveals other aspects of national patterns\nof RID use. The mean activity is\ncertainly distorted by insufficient name\ndisambiguation. Although the national\nstatistics for all authors reflect similar\nactivity for most countries (ranging\nfrom 4 to 5), China’s extreme average\nactivity points to identification issues.\n\n50%\n45%\n40%\n35%\n30%\n25%\n20%\n15%\n10%\n5%\n0%\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7 8 9 10 11 12 13 14 15 &gt;15\nNumber of papers\n\nFigure 1. Relative frequency of\npublication activity of RID authors (bars)\nvs. all authors (line). [Data sourced from\nThomson Reuters Web of Knowledge]\n\nConclusions\nThe validity of name disambiguation for\nsome countries like China proved to be\nbeyond tolerance. Nevertheless, the\nresults leave no doubt. The extent of\nRID registration is still low and differs\namong countries. We also found that\nauthors with RID are usually more\nproductive than others. RID might\ntherefore not (yet) be used to derive\n\nreference\nactivity.\n\nstandards\n\nfor\n\npublication\n\nReference\nStrotman, A. &amp; Zhao, D. (2012), Author\nname disambiguation: What\ndifference does it make in authorbased citation analysis? JASIST,\n63(9), 1820–1833.\n\n1867\n\nARE THE BRIC AND MITS COUNTRIES\nIMPROVING THEIR PRESENCE IN THE\nINTERNATIONAL SCIENCE?\nElba Mauleon1, Daniela De Filippo2\n1\n\nelba114@hotmail.com\nPostdoctoral Fellowship supported by the Spanish Ministry of Education through FECYT\n2\n\ndfilippo@bib.uc3m.es\nLEMI (Department of Library and Information Science), Carlos III University of Madrid,\nMadrid 126, Getafe, Spain\nIntroduction\nIn 2001, the Goldman Sachs group\ncoined the name of BRIC countries to\ngroup under this abbreviation the more\ndynamic emergent economies of the\ninternational market: Brazil, Russia,\nIndia and China (Wilson and\nPurushothaman, 2003). Ten years later,\nthe same group proposes a new\nabbreviation, the MIST to talk about the\neconomies of Mexico, Indonesia, South\nKorea and Turkey.\nNowadays BRIC and MIST countries\nare recognized as the most dynamic\ncountries, which are facing well the\nglobal crisis. An interesting question is\nwhether this growth can also be\nevidenced in the scientific and\ntechnological fields. We would like to\nexplore the ability of these countries to\nintegrate into the international scientific\ncommunity and strengthen their\npositions in the coming years.\nPurpose of research\nAccording with this, the objective of this\nwork is to determine if these emergent\ncountries show the same push in the\nscientific and technological dimensions\nthan the one described in their economic\nactivity. In this sense, the goals of this\ninvestigation are:\n1868\n\n- To explore the evolution of the\nscientific output of BRIC and MIST\ncountries in the two last decades. What\nwas the evolution of the world share of\nBRICS and MITS scientific output?\n- To measure the impact of the scientific\noutput of these countries in the\ninternational scientific community.\nFinally, this work aims at offering data\nto detect if BRIC and MIST countries\nare the new strategic actors that will\nreplace the countries that traditionally\nhave led the scientific and technological\nactivity. In this sense, the following\nindicators were calculated for each\ncountry:\na) Scientific activity indicators:\n Annual evolution of the number of\ndocuments\n Productivity: scientific production\nper million inhabitants\nb) Influence and impact of the\nknowledge produced by BRIC and\nMIST countries:\n Annual evolution of the number of\ncitations per document.\n Percentage\nof\nnon-cited\ndocuments.\nc) Socioeconomic indicators:\n Annual evolution of the Gross\nDomestic Expenditure on Research\nand Development.\n\nd) International scientific influence of\nknowledge producing and diffusing\ninstitutions:\n Annual evolution of the number of\njournals from these countries\nincluded in JCR.\n Collaboration habits: percentage of\ndocuments\nin\nnational,\ninternational\nand\nwithout\ncollaboration.\n Number of academic institutions\nfrom BRIC and MITS countries in\nthe international ranks.\ne) Specialization Index: the percentage\nof documents and their annual evolution\nby broad scientific area was calculated.\nMethods\nOne of the most visible results of the\nscientific activity is the diffusion of the\ninvestigation in peer review journals of\nrecognized prestige. In agreement with\nthis premise, the scientific publications\nof BRIC and MIST countries have been\nobtained using as source of data the\ninternational database Web of Science\n(WoS). The use of this database allows\nus to obtain the scientific production of\nthese countries in its more international\nscope, which turns out essential to\nanalyze the integration of these\ncountries into the international scientific\ncommunity.\nAnother aspect considered in this work\nhas been the presence of higher\neducation institutions from these\ncountries in international rankings, such\nas the ARWU ranking -elaborated by\nthe University of Shanghai- and THE produced by TIMEs-.\nFinally\nadditional\nsources\n–as\nUNESCO, World Bank- were consulted\nto obtain data related to other R&amp;D\nactivities. The period of analysis was\n1990-2010.\n\nTable 1. Number of journals in JCR by\ncountries\nCOUNTR\nY\nBrazil\nRussia\nIndia\nChina\nBRIC\n%BRIC\nvs JCR\nMexico\nIndonesia\nTurkey\nSouth\nKorea\nMITS\n%MITS\nTotal\nJCR\nGermany\nCanada\nUSA\nFrance\nItaly\nJapan\nUK\nG7\n%G7 vs\nJCR\nJournals\nin JCR\n\nSCI\nSSCI\n1997 2004 2010 1997 2004 2010\n9\n16\n89\n2\n2\n20\n96 104 147\n9\n8\n6\n37\n47\n94\n5\n3\n5\n20\n71 138\n3\n3\n6\n162 238 468\n19\n16\n37\n3,26\n\n3,99\n\n5,8\n\n1,14\n\n0,93\n\n1,35\n\n5\n0\n1\n\n7\n0\n3\n\n28\n0\n49\n\n4\n0\n1\n\n4\n0\n1\n\n13\n0\n12\n\n6\n\n27\n\n75\n\n0\n\n2\n\n12\n\n12\n\n37\n\n152\n\n5\n\n7\n\n25\n\n0,24\n\n0,62\n\n1,88\n\n0,30\n\n0,41\n\n0,91\n\n381 427 545\n52\n52 110\n73\n75\n94\n31\n28\n26\n1915 2289 2724 1010 982 1229\n153 143 189\n23\n17\n25\n51\n65 121\n1\n1\n13\n133 160 207\n9\n7\n8\n999 1267 1592 325 419 725\n3705 4426 5472 1451 1506 2136\n74,65 74,15 67,78 86,78 87,97 78,21\n4963 5969 8073 1672 1712 2731\n\nPreliminary results\nScientific production\nFrom 1990 to the present time a\nremarkable growth in the number of\npublications of the BRIC countries is\nobserved. Its scientific production in\nWoS increased from 69,764 documents\nin 1990 (7% of the world) up to 311,077\n(17% of the world) in 2010. Of the four,\nChina and Brazil present the greater\ngrowth in the period. On the other hand,\nthe scientific production of the MIST\nrepresent 5,020 publications in 1990\n(0,5% of WoS) and 93,169 in 2010 (5%\nof the world). These data show the\nincreasing international visibility they\nhave gained. The significant growth of\nproduction can be explained, in part, by\nthe increasing number of journals\n1869\n\npublished in these countries and\nincluded in JCR. Table 1 shows the\nevolution of the number of journals and\nthe percentage each group represents in\nthe total world. It can be seen that while\nthe G7 is still the predominant group,\nemerging countries have been gaining\nground.\nAcademic visibility\nThe presence of higher education\ninstitutions of BRIC and MIST countries\nin international rankings is also a\nreflection of their increasing visibility\n(Table 2). In less than a decade, not only\nthe number of universities among the\nworld&#x27;s leading has increased, but also\nthe position of those already included\nhas improved.\nTable 2. Presence of BRIC and MIST\nuniversities in international rankings\n\nCountry\nBrazil\nRussia\nIndia\nChina\nMexico\nIndonesia\nTurkey\nSouth Korea\n\nARWU\n2003\n2010\n(500\n(500\nuniv)\nuniv)\n4\n7\n0\n2\n1\n2\n12\n29\n1\n1\nWithout data\n1\n1\n8\n10\n\nTHE\n2004\n2010\n(200\n(200\nuniv)\nuniv)\n0\n2\n1\n2\n0\n1\n6\n16\n0\n0\n0\n0\n0\n0\n3\n4\n\nDiscussion and conclusions\nThroughout this study we have observed\na remarkable growth of the BRIC and\nMITS countries not only through\neconomic indicators but also in the\n\n1870\n\nscientific and academic fields. The\nnotable increase of international\nproduction, the upward trend in the\nimpact and visibility of these\npublications and the growing presence\nof their universities in the international\nrankings suggests these “developing\neconomies” are evolving towards\n&quot;knowledge economies&quot; (Dahlman and\nAubert, 2001). We consider that these\ncountries are the new players that will\nhave a predominant role in science and\ntechnology in the coming decades.\nReferences\nCooper, J (2006) “Of BRICs and brains:\nComparing Russia with China, India,\nand other populous emerging\neconomies” EURASIAN\nGEOGRAPHY AND\nECONOMICS, 47 (3): 255-284\nDahlman, C.y Aubert,J.E China and the\nKnowledge Economy. Seizing the\n21st Century. Washington, DC:\nWorld Bank, WDI Development\nStudies, 2001.\nUNESCO (2010) El Informe de la\nUNESCO sobre la Ciencia, 2010\nUNESCO, Paris\nwww.unesco.org/science/psd\nWagner, C; Kit Wong, S (2012)\n“Unseen science? Representation of\nBRICs in global science“\nScientometrics 90 (3): 1001-1013\nWilson, D. y Purushothaman, R.\nDreaming with BRICs: The Path to\n2050. New York, NY: Goldman\nSachs, Global Economics Paper No.\n99, October 1, 2003.\n\nJOURNAL IMPACT FACTOR, EIGENFACTOR,\nJOURNAL INFLUENCE AND ARTICLE\nINFLUENCE\nChia-Lin Chang1, Michael McAleer2 and Les Oxley3\n1\n\nchangchialin@nchu.edu.tw\nDepartment of Applied Economics, National Chung-Hsing University (Taiwan)\n2\n\nm.mcaleer@gmail.com\nEconometrisch Instituut, Faculteit der Economische Wetenschappen, Erasmus Universiteit\nRotterdam (The Netherlands)\n3\n\nloxley@waikato.ac.nz\nDepartment of Economics, University of Waikato, Private Bag 3105, Hamilton (New\nZealand)\n1. Introduction\nWe examine the practical usefulness of\ntwo new journal performance metrics,\nnamely the Eigenfactor Score, which\nmeasures “importance”, and Article\nInfluence Score, which measures\n“prestige”, using ISI data for 2009 for\nthe 200 most highly cited journals in\neach of the Sciences and Social\nSciences. We compare them with two\nexisting ISI metrics, Total Citations and\nthe 5-year Impact Factor (5YIF) of a\njournal. We show that the Sciences and\nSocial Sciences are different in terms of\nthe strength of the relationship of\njournal performance metrics, although\nthe actual relationships are very similar.\nMoreover, the importance and prestige\njournal performance metrics are shown\nto be closely related to the two existing\nISI metrics, and hence add little in\npractical usefulness to what is already\nknown.\n2.\nKey\nResearch\nAssessment\nMeasures (RAM).\nLeading journal performance measures\nare:\n\n(1) 2-year impact factor (2YIF); (2) 5year impact factor (5YIF); (3)\nEigenfactor score: The Eigenfactor\nscore (see Bergstrom (2007), Bergstrom,\nWest and Wiseman (2008), and\nBergstrom and West (2008)) is a\nmodified 5YIF. (4) Article Influence:\nThe Article Influence score measures\nthe relative importance on a per-article\nbasis, and is a standardized Eigenfactor\nscore.\n3. Empirical Results\nFigures 1-4 evaluate the 200 most\nhighly cited journals, according to 2YIF,\nin both the sciences and social sciences\nfor 2009. These figures relate the\nEigenfactor score to Total Citations and\nthe Article Influence score to 5YIF. The\nTotal Citations data for 2009 for the\nSciences and Social Sciences were\ndownloaded from ISI on 19 June 2010\nand 20 June 2010, respectively.\nA simple linear regression, with the\nEigenfactor score as a function of Total\nCitations, is given in Figures 1 and 3 for\nthe Sciences and Social Sciences,\nrespectively. The estimated model\nshows that the Eigenfactor score\n1871\n\nincreases, on average, by 0.000004 and\n0.000003 for each unit increase in Total\nCitations for 2009 for the Sciences and\nSocial Sciences, respectively.\nFigure 1. Eigenfactor Score and Total\nCitations for 200 Most Highly Cited\nJournals in Sciences for 2009\n\nEigenfactor Score = -0.022*+3.3E-06* x Total\nCitations + error, R2=0.931, * significant at 5%\n\nThe goodness-of-fit measures, namely\nR2 = 0.931 and R2 = 0.659 for the\nSciences\nand\nSocial\nSciences,\nrespectively, show that the Eigenfactor\nscore can be estimated accurately,\nespecially for the Sciences, on the basis\nof a simple linear regression against\nTotal Citations.\nFigure 2. Article Influence Score and\n5YIF for 200 Most Highly Cited Journals\nin Sciences for 2009\n\n0.00000396 in Ferscht (2009) for the\nSciences, based on ISI Total Citations\ndata for 2007, is in accordance with the\nresult obtained in the present paper, as is\nthe value of R2. Another simple linear\nregression, with the Article Influence\nscore as a function of 5YIF, is given in\nFigures 2 and 4 for 2009 for the\nSciences\nand\nSocial\nSciences,\nrespectively. The estimated models\nshow that the Article Influence score\nincreases, on average, by 0.489 and\n0.479 for each unit increase in 5YIF for\n2009 for the Sciences and Social\nSciences, respectively.\nFigure 3. Eigenfactor Score and Total\nCitations for 200 Most Highly Cited\nJournals in Sciences for 2009\n\nEigenfactor Score=0.029*+1.99E-06* x Total\nCitations + error, R2=0.659, * significant at 5%\n\nFigure 4. Article Influence Score and\n5YIF for 200 Most Highly Cited Journals\nin Sciences for 2009\n\nArticle Influence = -0.719*+0.489* x 5YIF +\nerror, R2=0.923, * significant at 5%\n\nThe approximate relationships between\nthe Eigenfactor score and Total\nCitations can be expressed as:\nEigenfactor score = k (Total Citations)\nwhere k = 0.0000033 and k = 0.000002\nfor Sciences and Social Sciences,\nrespectively. The estimated value of k =\n1872\n\nArticle Influence=0.160*+0.479* x 5YIF + error,\nR2=0.572, * significant at 5%\n\nThe goodness-of-fit measures, as given\nby R2 = 0.923 and R2 = 0.572 for 2009\n\nfor the Sciences and Social Sciences,\nrespectively, show that the Article\nInfluence score can be approximated\nvery accurately for the Sciences, and\nreasonably accurately for the Social\nSciences, on the basis of a simple linear\nregression relationship of Article\nInfluence score against 5YIF, namely:\nArticle Influence score = 5YIF/2.\nAlthough the goodness-of-fit value of R2\nobtained in the present paper is slightly\nhigher than in Franceschet (2009),\nnamely R2 = 0.880, in relating the\nArticle Influence score to 5YIF, the\nlatter paper had an effect of 5YIF on\nArticle Influence score of 0.452, which\nis very similar to that proposed above.\n4. Conclusions\nAlthough the Sciences and Social\nSciences are dramatically different in\nterms of the strength of the underlying\nrelationship of the journal performance\nmetrics considered in this paper, the\nactual empirical relationships are very\nsimilar. As Article Influence is a\nmodification of 5YIF, it is perhaps not\nsurprising that the two scores are highly\nand positively correlated.\nGiven the very high correlations\nbetween the Eigenfactor score and Total\nCitations, and between the Article\nInfluence score and 5YIF, and the\ncorresponding high R2 values for the\nsimple\nlinear\nregressions,\nthe\nEigenfactor score and Article Influence\nscore would not seem to be entirely\nnecessary for the Social Sciences, and\nnot at all necessary for the Sciences,\nrelative to the leading journal\nperformance measures that are already\navailable, namely Total Citations and\n5YIF, respectively.\n5. References\nArendt, J. (2010), Are article influence\nscores comparable across scientific\n\nfields?, Issues in Science and\nTechnology Librarianship, 60.\nBergstrom C. (2007), Eigenfactor:\nMeasuring the value and prestige of\nscholarly journals, C&amp;RL News, 68,\n314-316.\nBergstrom, C.T. and. West (2008),\nAssessing citations with the\nEigenfactorTM metrics, Neurology,\n71, 1850–1851.\nBergstrom, C.T., J.D. West and M.A.\nWiseman (2008), The EigenfactorTM\nmetrics, Journal of Neuroscience,\n28(45), 11433–11434.\nDavis, P.M. (2008), Eigenfactor: Does\nthe principle of repeated\nimprovement result in better\nestimates than raw citation counts?,\nJournal of the American Society for\nInformation Science and\nTechnology, 59(13), 2186-2188.\nElkins, M.R., C.G. Maher, R.D. Herbert,\nA.M. Moseley and C. Sherrington\n(2010), Correlation between the\njournal impact factor and three other\njournal citation indices,\nScientometrics, 85, 81-93.\nFersht, A. (2009), The most influential\njournals: Impact factor and\nEigenfactor, Proceedings of the\nNational Academy of Sciences of the\nUnited States of America, 68836884.\nFranceschet, M. (2010), Journal\ninfluence factors, Journal of\nInformetrics, 4, 239-248.\nISI Web of Science (2010), Journal\nCitation Reports, Essential Science\nIndicators, Thomson Reuters ISI.\nRousseau, R. et al. (2009), On the\nrelation between the WoS impact\nfactor, the Eigenfactor, the SCImago\njournal rank, the article influence\nscore and the journal h-index,\nConference Proceedings, Nanjing\nUniversity, 2009.\n\n1873\n\nASEP ANALYTICS. A SOURCE FOR\nEVALUATION AT THE ACADEMY OF SCIENCES\nOF THE CR\nJana Doleželová1 and Zdeňka Chmelařová2\n1\n\ndolezelova@knav.cz, 2chmelarova@knav.cz\nLibrary of the Academy of Sciences of the Czech Republic v.v.i., Národní 3, 115 22\nPrague, Czech Republic\nRepository of the Academy of\nSciences of the Czech Republic [1]\nSince 1994, the Library of the\nAcademy of Sciences of the Czech\nRepublic [2] has been the coordinator\nof bibliographic database ASEP, which\ncontains the records of publishing\nactivities of 54 institutes of the\nAcademy of Sciences of the Czech\nRepublic. The total number of records\nexceeds 216,000 (with an average\nannual increase of 11,000), they are\ndivided into 29 categories, and 72\ntrained administrators of institutional\ndata participate in their creation.\nStarting from 2012, full texts may be\nsaved with each record. The data is\npublished as an on-line catalogue,\nselected entries can be displayed in\ndifferent formats, and the data may be\nprinted out or saved for future use. This\ndatabase is used to evaluate the\nscientific results achieved by the\ninstitutes, departments or individual\nresearchers of the Academy of Sciences\nof the Czech Republic, either in that\ninstitution or in the entire country.\nWithin the Czech Republic, the\nevaluation is based on the results\nsubmitted to Information Register of\nResearch and Development results [3],\nmaintained\nby\nthe\nResearch,\nDevelopment and Innovation Council\n[4].\n\n1874\n\nFig. 1: Home page of ASEP Analytics for\nan institute\n\nASEP Analytics [5]\nASEP Analytics was created as a\nsoftware extension that provides\nanalytical reports derived by a\ncombination of queries and calculations\nfrom the data stored in the ASEP\ndatabase, which cannot be displayed\ndirectly in the catalogue. Each institute,\nits scientific teams and authors have\naccess to web pages with the same\ngraphic layout - menu, filters for setting\nthe query (time period, document type\netc.) and the field of data (Fig. 1).\nGraphic Presentations\nAnalytics\n\nin\n\nASEP\n\nAnalyses of research areas\nInstitutes of the Academy of Sciences\nof the Czech Republic are active in\nthree distinct research areas (I.\nMathematics, Physics and Earth\nSciences, II. Life and Chemical\nSciences, III. Humanities and Social\n\nSciences), which are further divided into\nsections.\nExamples of charts for research areas\n(Fig. 2) and charts for sections (Fig. 3).\n\nfactor, or applied outputs (patents, pilot\nplant, prototype, specialized map,\nindustrial\nand\nutility\nmodel,\nmethodology, norms, software) for a\nselected period of time. It is also\npossible to obtain diverse outputs and\nstatistics, e.g. the average impact of an\ninstitute (Fig. 5) or the number of\ndifferent types of results for each\ndepartment within an institute (Fig. 6).\n\nFig. 2: Number of documents from the\nAcademy of Sciences of the CR for a\nselected period of time.\n\nFig. 4: Record result (journal with impact\nfactor article)\n\nFig. 3: Number of documents in sections\nfor a selected period of time.\n\nAnalyses of institutes, scientific teams\n(departments), and researchers\na) Summaries of publications by\ninstitutes or researchers in a selected\nperiod of time. Every record shows a\nreference to the Information Register of\nResearch and Development results,\nwhich is a characterization of the result\nwithin the Czech Republic, a link to\nWeb of Science database, DOI, R&amp;D\nCouncil evaluation, or possibly a full\ntext in the repository (Fig. 4).\nb) Statistics by Institute/Department/\nAuthor\nThe charts and tables can display a\nvariety of indicators such as the number\nof results pertaining to specific types of\ndocuments, or journals with impact\n\nFig. 5: Average impact factor of an\ninstitute\n\n1875\n\nFig. 6: Number of results by document\ntype and department\n\nc) Relevance of financial support\nThe results are obtained with financial\nsupport from the government budget and\nother financial sources. It is possible to\nshow the results of the institutes for\nprojects funded from the public budget,\nwhich appear in the Central register of\nResearch and Development projects\ndatabase [6] administered by the\nResearch, Development and Innovation\nCouncil, inclusive of their rating by\nCouncil methodology, along with the\nresults arising from institutional\nfunding.\nConclusion\nASEP Analytics displays summaries and\nstatistical data showing the results\nattained by the individual institutes of\n\n1876\n\nAcademy of Sciences of the Czech\nRepublic. Evaluation of scientific results\nis a complex task, and the information,\nespecially for a qualitative evaluation by\nASEP Analytics, is being gradually\nexpanded and perfected as required by\nthe rules of evaluation in the Czech\nRepublic. ASEP Analytics generates\nsynoptic information that constitutes one\nof the tools for evaluation, particularly\nqualitative, of institutes and researchers\nby various subjects.\nAcknowledgement\nProject was supported with institutional\nsupport RVO:67985971.\nReferences\n[1] http://www.library.sk/i2/i2.entry.cls?\nictx=cav&amp;language=2&amp;op=search\n[2] http://www.lib.cas.cz/\n[3] http://www.isvav.cz/prepareResult\nForm.do\n[4] http://www.vyzkum.cz\n[5] http://www.lib.cas.cz/arl/\n[6] http://www.isvav.cz/prepareProject\nForm.do\n\nASSESSING AN INTERVAL OF CONFIDENCE TO\nCOMPILE TIME-DEPENDENT PATENT\nINDICATORS IN NANOTECHNOLOGY\nDouglas H. Milanez1, Thiago D. Macedo2, Roniberto M. Amaral3, Leandro I. L.\nde Faria4 and Jose A. R. Gregolin5\n1\n\ndouglas@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n2\n\nthiagoma89@gmail.com\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n3\n\nroniberto@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n4\n\nleandro@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n5\n\ngregolin@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\nIntroduction\nPatent indicators have been extensively\nused\nto\nassess\nnanotechnology\ndevelopments due to their objectiveness\nand great capability to compare results\nin complex and interdisciplinary fields.\nPatent documents, which include patent\napplication and granted patent, are rich\nsources information and they can be\nused to depict trends and support\nplanning and decision making (Mogee,\n1997; OECD, 2009). Usually, the\nbibliographic\ndata\nfrom\npatent\ndocuments are used to develop patent\nindicators, thus bibliographic databases,\nsuch as the worldwide Derwent\nInnovations Index (DII) has been\npreferably used (Wang &amp; Guan, 2012;\n\nMilanez, Morato, Faria &amp; Gregolin,\n2013). An important criterion for\ncompiling patent indicators is the\nreference year because every patent\ndocument includes several dates\nreflecting the timing of the invention,\nthe patenting process and the strategy of\nthe applicant. The OECD Patent Manual\n(2009) recommends using the priority\ndate as it is closest to the date of\ninvention. Nevertheless, there is a delay\nbetween the date of application and the\ndate when the information becomes\navailable in databases. This delay\nincludes the period until the publication\nof the patent application, which varies\naccording to national regulations, but it\nis usually assumed to be 18 months after\nthe filing date (Mogee, 1997; OECD,\n1877\n\nTable 1. Total of patent documents for\neach subject analyzed.\nSubject\nNanotechnology\n&quot;carbon nanotub*&quot;\nfulleren*\ngraphene*\n\nTotal of Patent\n161,121\n16,094\n3,071\n1,897\n\nThe delay period for each record was\ninvestigated comparing the interval from\nthe year of the prioritizing (first filing)\nand the year of indexing the patent\nbibliographic data in DII, which was\naccessed from the Derwent Primary\nAccession Numbers. According to DII\n(2013), this code consists of the year\nwhen items entered in the database\nfollowed by a six digit code. For every\n1878\n\nNanotechnology\nCumulative percentage of\npatent documents\n\nMaterials and Method\nSamples of nanotechnology and some\nselected\nnanomaterial\npatent\nbibliographic data were retrieved from\nthe DII using the search expressions\nfrom Table 1 applied in the Topic field.\nIn the case of nanotechnology, it was\nused the modular search strategy\nproposed by Porter et al (2008). All\nsearches were carried out between 20\nand 21 May, 2012 for the time spam\nfrom 2000 to 2011 and the total of\npatent documents recovered is shown in\nTable 1. All data were collected and\nanalyzed\nseparately\nusing\nthe\nbibliometric software VantagePoint®\n(version 5.0).\n\ndelay period, the number of patents and\ntheir percentage representation was\nobtained.\nFor\ninstance,\n23,758\nnanotechnology patents were indexed in\n2010; from this total, 8,928 were applied\nfirstly in 2009, which means a two year\ndelay and represents 37.6% from the\ntotal nanotechnology patent indexed in\n2010. After calculating the percentage\nfor every year of indexing, the average\nwas obtained for each delay period.\nMoreover, the general average was\ncalculated for all subjects.\nCNT\n\nFullerene\n\nGraphene\n\n100,0\n90,0\n80,0\n70,0\n60,0\n50,0\n40,0\n30,0\n20,0\n10,0\n0,0\n\n&lt; 1 1 2 3 4 5 6 7 8 9 10 &gt; 10\nInterval between first application and indexing (year)\n\nFigure 1. Cumulative percentage of patent\ndocuments available in database\naccording to the delay period.\n\nCumulative percentage of\npatent documents\n\n2009) and the period for index\nbibliographic data. Consequently, it can\nbe observed that there have been\ndeclines in late years of time-dependent\nindicators. This paper aims to analyse\nthe number of patents available in DII\naccording to the interval between the\nyear of the first applications and the year\nof indexing in order to establish an\ninterval of confidence to compile patent\nindicators in nanotechnology.\n\n100,0\n90,0\n80,0\n70,0\n60,0\n50,0\n40,0\n30,0\n20,0\n10,0\n0,0\n&lt; 1 1 2 3 4 5 6 7 8 9 10 &gt; 10\nInterval between first application and indexing (year)\n\nFigure 2. Average of the cumulative\npercentage of patent documents available\nin databases according to the delay\nperiod.\n\nResults and Discussion\nThe cumulative percentage of patent\ndocuments available in databases\nincreased\nstably\nfor\ngeneral\n(nanotechnology)\nand\nspecific\n(nanomaterials) subjects, as can be seen\nin Figure 1. This result suggests the\n\ndatabase indexes in similar criteria\nregardless of the subject or its size in\nterms of the number of patents. Figure 2\npresents the average cumulative\npercentage of the patent documents from\nall subjects evaluated according to the\ndelay period.\nOnly 2.68% of the whole patent dataset\nwas available on the DII database less\nthan a year from the first application\nwhereas this value increased to just\n32.9% after one year. However, the\ncumulative percentage grew sharply to\n90.9% after two years from the\napplication and it is a consequence for\nthe general patent secrecy of 18 months.\nFurthermore, as suggested by the charts,\nsome patent documents could take more\nthan 10 years before being indexed on\nthe DII database. A possible explanation\nfor this might be that the database does\nnot monitor all patent repositories from\nworldwide; therefore a document from a\nnon-monitored country may enter in the\ndatabase only if it is published in a\nmonitored country. The availability of\npatent documents in DII to compile\npatent indicators increased when the\ninterval of the first application and the\nindexing period is high enough. This\nmeans that for a search conducted for\nthe time spam (indexing year) from\n2000 to 2011, few patents from the\npriority year of 2011 and 2010 will be\naccessible. Even for patent documents\nfrom 2009, there is a lack of some\ndocuments, although it has given\nconfidence to state indicators until this\nyear.\nConclusion\nThe delay between the first application\nand the indexing period in DII is mainly\ndue to the regular period of 18 months\nof secrecy in most countries’ regulation.\nTherefore, most patent documents are\naccessible in the database after at least\ntwo years. The same time the outcomes\n\nset the availability of the patent\ndocuments, they also give intervals of\nconfidence to develop time-dependent\nindicators and other quantitative\nanalyses.\nAcknowledgements\nThe authors are grateful to the Brazilian\nNational Council for Technological and\nScientific Development (process number\n160087/2011-2), the São Paulo Research\nFoundation\n(process\nnumber\n2012/16573-7) and the Graduate\nProgram in Materials Science and\nEngineering at the Federal University of\nSão Carlos.\nReferences\nMilanez, D. H., Morato, R., Faria, L. I.\nL., &amp; Gregolin, J. A. R. (2013).\nAssessing nanocellulose\ndevelopments using science and\ntechnology indicators. Materials\nResearch. Retrieved March 15, 2013\nfrom http://www.scielo.br/pdf/mr/\n2013nahead/aop_1715-12.pdf\nMogee, M. E. (1997). Patents and\nTechnology Intelligence. Keeping\nabreast of science and technology:\ntechnical intelligence for business.\nColumbus: Battelle Press.\nOECD. (2009). OECD Patent Statistics\nManual. Retrieved March 10, 2013\nfrom http://dx.doi.org/\n10.1787/9789264056442-en\nPorter, A. L., Youtie, J., Shapira, P., &amp;\nSchoeneck, D. J. (2008). Refining\nsearch terms for nanotechnology.\nJournal of Nanoparticle Research,\n10(5), 715–728.\nWang, G., &amp; Guan, J. (2012). Value\nchain of nanotechnology: a\ncomparative study of some major\nplayers. Journal of Nanoparticle\nResearch, 14(2).\nDerwent Innovations Index. (2013).\nGlossary of Thomson Scientific\nterminology. Retrieved March 15,\n1879\n\n2013 from http://ip-science.thomson\nreuters.com/support/patents/patinf/te\nrms/#P\n\n1880\n\nBIBLIOMETRIC INDICATORS OF YOUNG\nAUTHORS IN ASTROPHYSICS: CAN LATER\nSTARS BE PREDICTED?\nFrank Havemann1 and Birger Larsen2\n2\n\nfrank.havemann@ibi.hu-berlin.de\nInstitut für Bibliotheks- und Informationswissenschaft, Humboldt-Universität zu Berlin,\nDorotheenstraße 26, D 10099 Berlin (Germany)\n2\n\nblar@iva.dk\nRoyal School of Library and Information Science, Birketinget 6,\nDK-2300 Copenhagen S (Denmark)\nIntroduction\nMost bibliometric indicators are not\ndeveloped for the evaluation of\nindividual researchers. We test selected\nindicators with respect to their validity\nat the level of the individual researcher\nby estimating their power to predict later\nsuccessful researchers. For this reason,\nwe compare bibliometric indicators of a\nsample of astrophysics researchers who\nlater co-authored highly cited papers\n(later stars, for short) before their first\nlandmark paper with the distributions of\nthese indicators over a random control\ngroup of young authors in astronomy\nand astrophysics.\nHere we present results obtained with\nsome\nstandard\nbasic\nindicators\n(Wildgaard et al. 2013). We will extend\nthe study to more sophisticated\nmeasures with the aim to find the best\nindicators for predicting later stars. We\nimagine that later stars apply for a job in\nan astrophysical research institute five\nyears after their first paper in a journal\nindexed in Web of Science (WoS). Do\nthey perform better bibliometrically than\nthe average of applicants with the same\nperiod of publishing?\n\nData and method\nWe inspected 64 astronomy and astrophysics journals to find researchers who\nstarted publishing after 1990 and had\npublished for a period of at least five\nyears in WoS journals. We excluded\nthose who had more than 50 co-authors\non average because evaluating those\nbig-science authors cannot be supported\nby bibliometrics. We draw a random\nsample of 331 authors mainly publishing\nin this field and affiliated longer in\nEurope then elsewhere. The latter\ncriterion contradicts with the international character of astrophysics research but makes the sample more\nhomogenous with respect to the\neducational and cultural background of\nthe researchers.\nTo find authors with highly cited papers,\nfor each journal considered we ranked\npapers with more than four citations per\nyear and less than ten authors according\nto their citations per year. We excluded\npapers with ten or more authors because\nwe want to have later stars whose contributions to the successful papers are not\nto small. From the top 20 percent of\nthese paper rank-lists we extracted all\nEuropean authors of highly cited papers.\nWe obtained 362 candidates who\n1881\n\npublished their first highly cited paper at\nleast five years after their first paper in\none the 64 journals.\nWe ranked these later-star candidates\naccording to their number of highly\ncited papers. We went through this list\nand checked whether the authors had\nreally five years or more to wait for the\nbreak-through paper if all their papers in\nWoS-journals are taken into account.\nWe chose the first 40 authors to keep the\neffort manageable.\nFor all WoS-papers of the 40 later stars\nand of the 331 random authors\n(downloaded at Humboldt-University,\nBerlin) all citing papers were determined by CWTS, Leiden.\nAll bibliometric indicators presented\nbelow are based on papers and their\ncitations within the first five years of the\nauthor. To compare only authors with\nsimilar collaboration behaviour we\nrestricted both samples to authors with\nless than four and more than one coauthor on average ending up with 30\nlater stars and 179 random authors.\nFor\neach\nbibliometric\nindicator\nconsidered, we test whether both\nsamples behave like random samples\ndrawn from the same population by\napplying a one-sided Wilcoxon rank\nsum test with continuity correction. We\ntest the null hypothesis that for both\nsamples we have the same probability of\ndrawing an author with a larger value in\nthe other sample. The alternative hypothesis is that indicator values of later\nstars exceed the values of random\nauthors\n(cf.\nwikipedia\nhttp://en.\nwikipedia.org/wiki/Mann-WhitneyWilcoxon_test).\nResults\nUntil now we have calculated and tested\ntwo absolute output and two absolute\ninfluence indicators, respectively:\nnumber of papers,\n\n1882\n\nfractional paper score giving each of k\nauthors of a paper a 1/k-fraction of it,\nnumber of citations, and\nfractional citation score giving each of k\nauthors of a paper a 1/k-fraction of its\ncitations.\nIn addition we calculated the widely\nused Hirsch index, a number combining\ninfluence and output performance in an\nuncontrolled manner (Hirsch 2005). The\nlater stars perform somewhat better than\nrandom authors (s. Table 1) but the\ndistributions are rather similar (s.\nFigures 1 and 2).\nIn the last column of Table 1 we list the\nfailure probability p of rejecting the null\nhypothesis that both samples behave like\nrandom samples drawn from the same\npopulation.\nTable 1: Median indicators of samples and\ntest probability p\nIndicator\nstars random\nNumber of papers\n8\n6\nFractional score\n2.72\n2.00\nNr. of citations\n38\n25\nFractional citations 10.51\n6.67\nHirsch index\n3\n3\n\np\n.083\n.062\n.051\n.031\n.245\n\nDiscussion\nThe high failure probabilities of\nrejecting the null hypothesis indicate\nthat the differences found are not\nstatistically significant for all indicators\nbut the fractional citation score where\nwe have at least a significance on the 5\npercent level. Thus, it is very unlikely to\ndiscover a later star in astrophysics by\ncomparing her output with the output of\na random author. The Hirsch index\nmakes no difference at all. The number\nof citations does also not help much.\nThere is also no difference when we\ncompare citations per paper and year of\nboth samples (data not shown). The only\nmoderately helpful of the indicators\nconsidered here is fractionally counted\n\nnumber of citations. We will extend the\nstudy to other indicators of output and\ninfluence including variants of the\nHirsch index.\n\nAcknowledgments\nWe thank Jesper Schneider for helpful\ndiscussions and Paul Wouters for\nproviding citation data. The analysis\nwas done for the purposes of the\nACUMEN project, financed by the\nEuropean\nCommission,\ncf.\nhttp://research-acumen.eu/.\nReferences\nHirsch, J. E. (2005). An index to\nquantify an individual’s scientific\nresearch output. Proceedings of the\nNational Academy of Sciences\n102(46), p. 16569–16572.\nWildgaard, L., Schneider, J., &amp; Larsen,\nB. (2013). Quantitative Evaluation of\nthe Individual Researcher: a review\nof the characteristics of 114\nbibliometric indicators.\nForthcoming.\n\nFigure 2. Sum of citation fractions\n\n1883\n\nBIOLOGICAL SCIENCES PRODUCTION: A\nCOMPARATIVE STUDY ON THE MODALITIES OF\nFULL PHD IN BRAZIL OR ABROAD\nDaniel Henrique Roos, Luciana Calabró, Nilda Vargas Barbosa, João Batista\nTeixeirada Rocha and Diogo Onofre Souza\ndaniel_varzeano@hotmail.com; luciana.calabro.berti@gmail.com;\nnvbarbosa@yahoo.com.br; jbtrocha@yahoo.com.br; diogo@ufrgs.br\nFederal University of Rio Grande do Sul, Departamento de Bioquímica, Rua Ramiro\nBarcelos, 2600 – anexo, Porto Alegre, RS (Brazil)\nIntroduction\nScience has been regarded as an\ninformation\nproduction\nsystem\nespecially in the form of publications.\nTherefore, science must be considered\nas a broad social system whose function\nis crucial to promote the dissemination\nof\nscientific\nand\ntechnological\nknowledge [1].\nThe academic structure built in Brazil\nallowed a significant expansion of the\nnational scientific community and its\nscientific production. Until the mid1990s, the construction of this scientific\nbase occurred relatively fast by the\ntraining of masters and doctors abroad,\nwith a legal commitment to return to\nBrazil. Three mechanisms enabled this\npolicy: 1- the awarding of grants to\nprofessionals with a permanent position\nin an institution in Brazil, 2- the\ninclusion of clauses specifying the\nimmediate return after getting the title in\nthe deed of undertaking signed by\nfellows; 3- the government efforts for\nthe establishment of international\nagreements with &quot;receiving countries&quot; to\nprevent the granting of a residence\npermited to former fellows [2].\nTherefore, this work was planned to\nanalyze and compare the evolution of\nscientific production (number of articles\npublished,\nnumber\nof\ncitations,\n1884\n\nauthoring type and journal impact factor\n(IF)) of researchers with full doctorate\nin Brazil or abroad in the areas of\nbiochemistry, biophysics, physiology,\npharmacology and related fields.\nMethodology\nThe present study compared the\nscientific production of former fellows\nwith Full Doctorade in Brazil (FDB) or\nAbroad (FDA) in the area classified by\nCAPES as Biological Sciences II\n(Physiology,\nBiochemistry,\nPharmacology and related areas such as\nmolecular biology, cell biology,\nEnzymology, etc). The scientific\nproduction of researchers was analyzed\nduring the first nine (9) years after the\nend of doctorate course and covered a\nsample (total along the period) of 19\n(nineteen) former fellows from each\nmodality. The data collected included:\nnumber of articles published; number of\ncitations and impact factor of the\njournal. These data were obtained from\nthe database of CAPES, CNPq\nLattes, Web of Science (Institute for\nScientific Information (ISI) and Scival Scopus).\nResults\nThe number of articles published by\nFDB increased gradually in the three\n\ntriennia analyzed after the end of\ndoctorate (Fig. 1). This growth profile\nwas not observed for FDA. The results\nalso demonstrate that the average of\narticles published by FDB was higher\nthan FDA during the last two triennia\n(Fig. 1).\n\nFig. 1- Mean of articles published\nby triennium. Open bar; Brazilian\nformer fellows and Closed bar; Abroad\nformer fellows. n = 19.\n\nThe IF and number of citations were\nanalyzed in order to evaluate qualitative\nparameters of publications. The mean IF\nof articles published by FDB is\napproximately 2.0 (two) and that this\nvalue remain constant during the studied\nperiod (Fig. 2). The mean IF of article\nfrom FDA was also constant during the\nanalyzed triennia; however with a higher\nvalue (around 3.5 – 4) than that from\nFDB (Fig. 2).\n\nFig. 3- Mean of citations per article by\ntriennium. First triennium 3A; Second\ntriennium 3B; Third triennium 3C; AC –\nAll Citation; WSC – Without Self\nCitation; WAC Without All Citation of\nAuthors; Open bar; Brazilian\nformer fellows and Closed bar; Abroad\nformer fellows. n = 19.\n\nFig. 2 - Mean of impact factor\nby triennium. Open bar; Brazilian\nformer fellows and Closed bar; Abroad\nformer fellows. n = 19.\n\nThe average of citations by articles in\nthe respective triennia for FDA and\nFDB is shown in Figure 3. In order to\ndetail the analysis regarding the quality\nof articles published, the data were also\nevaluated without self-citations (WSC:\nwithout the self-citations of the author\nand WAC: without the citations of all\nauthors of the article). The results show\nthat in all triennia, the average of\ncitations by article is higher for FDA\nwhen compared to the FDB. Indeed, the\npercentage of self-citation WAC in the\n1885\n\narticles published by FDB is slightly\nlarger than FDA (Fig. 3). Taken\ntogether, the data depicted in Figure 2\nand 3 indicate a higher impact of articles\npublished by FDA than that of FDB.\nThe number of articles published as\ncorresponding\nauthor\nmay\nbe\nconsidered, at least in part, an indicator\nof scientific independence of the exfellows, since the corresponding author\nis expected to answer questions of\nreviewers and interacts with the journal\nand the scientific community. Moreover,\nin most of the cases, the corresponding\nauthor is the person responsible for the\nscientific project and usually the\nscientific advisor of one of the other\nauthors. To include in the work a\nmeasure of scientific independence, we\nanalyzed the percentage of articles\npublished by FDB and FDA as\ncorresponding author.\nFor both\ndoctorate modalities the percentage of\narticles as corresponding author\nincreases during the triennia period.\nThis parameter was slightly larger for\nFDB when compared to FDA (Fig. 4).\nOverall, these results indicate that the\nscientific independence of FDB is\ngreater and faster than FDA.\nConclusions\nThe results showed in this study allow\nus to infer that, in terms of number, the\nFDB may be contributing significantly\nto the current growth in the quantity of\n\n1886\n\nscientific articles published by Brazilian\ncommunity. However, the quality of\narticles published by FDB was lower\nthan that published by FDA (quality\nhere evaluated both by the IF of the\njournals and by the number of citation of\nthe papers), perhaps, indicating that the\nproduction of scientific articles by FDB\nwas more centered in quantity than in\nquality. On the contrary, FDA\npublication attitude seems to be more\ndirected to quality than quantity. In a\ngeneral,\nthe results presented here\nsignalize to the government policies the\nneed to invest more in the postgraduation programs to enhance the\nrelevance of Brazilian articles in terms\nof scientific quality\nAcknowledgements\nThis work was supported by grants\nfrom, UFSM; UFRGS; FAPERGS;\nCAPES; CNPq; FINEP (IBN-Net) and\nINCT-EM.\nReferences\n[1] Macias-Chapula, C.A. (1998). O\npapel da informetria e da\ncienciometria e sua perspectiva\nnacional e internacional. Ciência da\nInformação, 27(2), 134-140.\n[2] Schwartzman, S. (1978). Struggling\nto be born: The scientific community\nin Brazil. Minerva, 16(4), 545-580.\n\nA CITATION ANALYSIS ON MONOGRAPHS IN\nTHE FIELD OF SCIENTOMETRICS,\nINFORMETRICS AND BIBLIOMETRICS IN CHINA\n(1987-2010)\nYuan Junpeng, Yang Yang, Pan Yuntao, Wu Yishan\njunpengyuan@126.com\nInstitute of Scientific and Technical of Information of China, Beijing 100038, China\nIntroduction\nScholarly books and monographs play a\nsignificant\nrole\nin\nresearch\ncommunication, providing important\nscientific review in some disciplines and\nthe latest research for others. Many\nstudies have analysed citations to books\n(Small 1979, Glänzel 1999, Tang 2008,\nGiménez-Toledo2009, Kousha, 2009).\nThere are only few investigations have\nexamined citations from books (Chung\n1995, Book Citation Index, Chen 2009).\nThis article carries out citation analysis\non monographs in the field of\nscientometrics,\ninformetrics\nand\nbibliometrics in China between 1987\nand 2010. Using metrology and statistics\nmethods to analysis references in the\nmonographs,\npaper\nfound\nsome\ninteresting conclusions and partially\nexpanding the object of citation analysis\nto monographs.\n\nmonographs, the monographs are ranked\nby publication year in table 1.\nTable1 The bibliographic of\nscientometrics, informetrics and\nbibliometrics monographs in China\nserial Title\nnumber\n\nAuthor\n\nAge\n\nGender\n\n1\n\nLuo\nShisheng\nQiu\nJunping\nWang\nChongde\nDing\nXuedong\nLuo\nShisheng\nLiang\nLiming\n\n42\n\nMale\n\n41\n\nMale\n\n52\n\nMale\n\n2\n3\n4\n5\n6\n7\n8\n\n9\n\n10\n\nData and Methods\nThe data sources of monographs are\nfrom the National Library of China\n(NLC). We accessed monographs\ndatabase of NLC, use the keywords\nscientometrics,\ninformetrics\nand\nbibliometrics to search monographs.\nOverall, the search strategy retrieved\nabout 28 volumes books in the field\nsince 1987. After delete 7 volumes\nsymposiums,\nget\n21\nvolumes\n\n11\n12\n\n13\n\nPublication\nyear\nAn Introduction to 1987\nBibliometrics\nBibliometrics\n1988\nBibliometrics\nCourse\nAn Basic of\nBibliometrics\nGenerality on\nBibliometrics\nScientometrics:\nIndicator, Model,\nApplication\nMethodology of\nScientometrics\nIndicator of\nScience and\nTechnology and\nEvaluation Method\nDevelopment\nScience and\nTechnology\nMathematical\nPrinciple\nScientometrics:\nTheoretical\nExploration and\nCase Study\nMethodology\nResearch of\nScientometrics\nNetwork\nInformation\nResources\nEvaluation\nInformetrics\n\n1990\n1993\n1994\n1995\n1999\n\nMale\n49\n\nMale\n\n46\n\nFemale\n\nPang\n49\nJingan\nLuo\n55\nShisheng\n\nMale\n\n2005\n\nGu\n54\nXingrong\n\nMale\n\n2006\n\nLiang\nLiming\n&amp; Wu\nYishan\nFang\nYong\n\n57\n/48\n\nFemale/\nMale\n\n38\n\nMale\n\n2007\n\nPang\nJingan\n\n55\n\nMale\n\n2007\n\nQiu\n60\nJunping\nGuo\n31\nQiang &amp;\nLiu\nJunyou\nHou\n37\nHaiyan\n\nMale\n\n2000\n\n2006\n\n14\n\nAn Introduction to 2007\nInformetrics\n\n15\n\nMapping\nKnowledge\n\n2008\n\nMale\n\nMale\n\nFemale\n\n1887\n\n16\n17\n18\n\n19\n20\n21\n\nDomains of\nScientometrics\nContent Analysis 2008\nin Bibliometrics\nWebometrics: a\n2009\nTheoretical and\nEmpirical Study\nWebometrics:\n2009\nTheory, Tools and\nApplications\nInformetrics and\n2010\nApplication in\nMedical\nAdvanced Course 2010\nin Scientometrics\nScientometric\n2010\nAnalysis of Highly\nCited\nPapers(1979-2008)\n\nQiu\nJunping\nZhang\nYang\n\n61\n\nMale\n\n34\n\nMale\n\nSun\nJianjun\n&amp; Li\nJiang\nWang\nWei\n\n47/27 Male\n\n51\n\nMale\n\nYuan\n37\nMale\nJunpeng\nHe\n47/45 Male\nDefang\n&amp; Zheng\nYanning\n\nNote: Serial number in table 1 on behalf of\nmonographs in follows.\n\nResults\nOverview\non\nscientometrics,\ninformetrics\nand\nbibliometrics\nmonographs in China\nAs shown in Table 1, the earliest\nmonograph is An Introduction to\nBibliometrics, which was published in\n1987 and the last one was published in\n2010. With the development of the\ndiscipline, the topics of the monographs\ninclude bibliometrics, scientometrics,\ninformetrics and webometrics. The\nnumber of the monographs in the field\nkept increasing, especially after 2000,\nthe number is 13 accounting for 62% of\nthe total sample.\nAuthors analysis\nTable 1 shows there are 19 authors who\nwrite the monographs in the field. Four\nmonographs are co-author books,\nrepresenting 19.05% of the total number\nof monographs in this study, the serial\nnumber are 10, 14, 18 and 21. Until\n2006, co-author books are appearing and\nit might be because communication in\nresearch is more convenient. Four\nauthors write multiple monographs: Luo\nShisheng and Qiu Junping write 3\nmonographs, followed by Liang Liming\nand Pang Jingan write 2 monographs.\n1888\n\nTwo authors are female and the other\nseventeen authors are male. The average\nage when the author published the\nmonographs is 46. Further analysis of\nauthors’ institution indicates that the\nChinese universities (13 out of 19) are\nthe majority, while there are only 6\nresearch institutes.\nCitations per monograph analysis\nThe total citation rates of 21\nmonographs is 3628 and citations per\nmonograph is 173, the top one is 807. It\nis showed there was no trend for the\ncitations per monograph before 2005,\nbecause the distribution of monographs\nis more dispersed. The number of\ncitations per monograph has been\nincreasing since 2005 and especially\nafter 2008. Further investigation shows\nthat monographs exceeded average\nreferences mostly concentrated in\nscientometrics and informetrics.\nReferences type analysis\nThe references type of the 21\nmonographs mainly is journal and\nmonograph, so we divided the\nreferences type into three types: journal,\nmonograph and others. Scientific\njournals\nas\nrecords,\nreports,\ndissemination and accumulation of\nscientific information carrier, while\ndelivering\nhigh-quality\nscientific\nknowledge, but also to achieve\ntimeliness, breadth, continuity, this\ncannot be done by other type of\nscientific literature. The type of journal\nhas 2568 references, representing\n70.78% of the total number of\nreferences, followed by monograph\n(582) and others (478). From each\nmonograph, the type journal is more\nthan type monograph in 17 monographs.\nIt is worth mentioning that the type\njournal is less than type monograph in\nNo.7, 9, 14 monographs, especially No.\n14 monograph has only monograph\n\nreferences. It might be related to the\nmode of author absorb knowledge and\ncite the references.\nReferences language branch analysis\nChinese, English, Japanese, Russian and\nItalian, etc. are the references language.\nBecause the numbers of reference write\nin Japanese, Russian and Italian is very\nsmall we divided the language branch\ninto three types: Chinese, foreign and\ntranslation. In terms of the total number\nof\nreferences,\nforeign\nlanguage\ndemonstrated its dominant position;\nChinese and translation ranked second\nand third. It indicates that researchers in\nthis field often consult the foreign\nlanguage literature, tracking the latest\nresearch developments, inevitable cite in\ntheir own academic achievement as a\nreference. It is worth mentioning that\nthere only Chinese references in No.8\nand 9, and the number of foreign\nreferences in No.4 is 133, the number of\nChinese references in this monograph\nis only 10.\nTime distribution of references analysis\nAnalysis the references publication year\ndistribution, we can understand the best\ntime to use literature; evaluate the\nstrength of authors to absorption new\ninformation.\nReferences\nhave\ndemonstrated a stable and strong\ngrowing trend. For the increase rate of\nreferences the growth pattern can be\ndivided into four periods. The first\nperiod is from 1909 to 1969, in this\nperiod, the number of references\nincreased slowly, from 1 in 1909 to 26\nin 1969. The second period is from 1970\nto 1980, the number of references\nincreased more quickly, from 15 in 1970\nto 40 in 1980. The third period is from\n1981 to 1995, the number doubled to the\nsecond period, but the number is\nvolatility. The fourth period is from\n1996 to 2009, both the number and the\n\nspeed increased dramatically, the\nnumber is 215 in 2005. Further analysis\nshows that the time of citations\nconcentrated is parallel to the time of\nmonographs dense, which is consistent\nwith the literature use laws.\nConclusions\nIn the field of scientometrics,\ninformetrics and bibliometrics, four\nmonographs are co-author books and\nfour authors write multiple monographs\nand the average age when the author\npublished the monographs is 46. In\naddition, the Chinese universities (13\nout of 19) are the majority. Furthermore,\nthe number of citations per monograph\nhas been increasing since 2005 and\nespecially after 2008. The study aims to\ndivulge the patterns of monographs’\nreference, cited references in books can\nbe difficult to locate, so we select a\nfamiliar field scientometrics to study.\nThe next stage of this study will invite\nexperts in the field to explain the results\nfrom the scientometric analysis.\nAcknowledgments\nThis project was supported by a grant\n(No.70673019) from the National\nScience Foundation of China (NSFC).\nReferences\nChen Guangyu(2009). Sample Selection\nand Citation Analysis: The Case of\nMonograph in the Research on the\nInformation Sources of US China\nStudy. Library and Information\nService 53(14): 20-22, 27. (In\nChinese)\nChung, Y. (1995). Characteristics of\nreferences in international\nclassification systems literature.\nLibrary Quarterly, 65(2), 200-215.\nGiménez-Toledo, E. and A. RománRomán (2009). Assessment of\nhumanities and social sciences\nmonographs through their\n1889\n\npublishers: a review and a study\ntowards a model of evaluation.\nResearch Evaluation,18(3): 201-213.\nGlänzel, W., &amp; Schoepflin, U. (1999). A\nbibliometric study of reference\nliterature in the sciences and social\nsciences. Information Processing &amp;\nManagement, 35(1), 31-44.\nKousha, K., &amp; Thelwall, M. (2009).\nGoogle book search: Citation\nanalysis for social science and the\nhumanities. Journal of the American\nSociety for Information Science and\nTechnology, 60(8), 1537-1549.\n\n1890\n\nSchubert, A. (2002). The Web of\nScientometrics. Scientometrics,\n53(1), 3-20.\nSmall, H. &amp; Crane, D. (1979).\nSpecialties and disciplines in science\nand social science: An examination\nof their structure using citation\nindexes. Scientometrics, 1(5-6), 445461.\nTang, R. (2008). Citation characteristics\nand intellectual acceptance of\nscholarly monographs. College &amp;\nResearch Libraries, 69(4), 356-369.\n\nCITATION PATTERNS FOR SOCIAL SCIENCES\nAND HUMANITIES PUBLICATIONS\nLucy Amez\nlucy.amez@vub.ac.be\nVrije Universiteit Brussel, R&amp;D department and ECOOM\nPleinlaan 2, 1050 Brussel\nIntroduction\nThe distribution of research funding\nprovided by the special Research Fund\nof the Flemish Government (BOF) to\nuniversities is based on a set of\nperformance\ndriven\nindicators\n(Debackere and Glänzel 2004) where\nthe bibliometric component plays an\nimportant role. The majority of the data\nare collected and monitored by\nECOOM, the Centre for R&amp;D\nMonitoring. Whereas initially only Web\nof Science (WOS) indexed items were\ncounted, since 2008 bibliometric data\nare enriched with publications indexed\nby the Flemish Academic Bibliographic\nDatabase for Social Sciences and\nHumanities (VABB-SHW).\nThe VABB-SHW is a retrospective\nbibliographic database, assembling\npublications by authors attached to\nsocial\nsciences\nand\nhumanities\ndisciplines at a Flemish University.\nPublication types include, apart from\njournal/proceedings\narticles,\nauthor/editor of book and book chapters.\nThe BOF regulation stipulates a number\nof eligibility criteria for the inclusion of\nan item, conditions which are both\nformal\n(publicly\naccessible,\nidentification by ISBN/ISSN), as well as\ncontent related: the publication must\nhave been submitted to a prior peer\nreview process by experts in the\ndiscipline and it must contribute to the\n\ndevelopment of new insights or\napplications. An Authoritative Panel\n(AP) of 18 professors affiliated with\nFlemish universities and university\ncolleges, makes a list of journals and\npublishers which, in their view, obeys\nthe content related conditions. The 2012\napproved journal list contained about\n2800 non-WOS indexed titles and 125\npublishers Those lists trigger the final\ninclusion of an institution’s item into the\nVABB-SHW database.\nA\nnumber\nof\nstudies\nby\nECOOM/University\nof\nAntwerp,\nmanager/coordinator of the database,\nprofiled the included publications\n(Engels, Ossenblok &amp; Spruyt 2012). A\nstudy of Ossenblok, Engels &amp; Sivertsen\n(2012) compares the VABB-SHW with\nthe Nordic database Cristin (by which it\nwas inspired) in terms of Web of\nScience coverage and language use.\nWOS coverage of SHW articles can\nvary substantially depending on\ndiscipline, with an average of 30-40%.\nHowever, contrary to the situation in\nNorway, this percentage is increasing\nfor Flemish universities, potentially\npointing to incentive effects caused by\nthe absence of valorization of non-WOS\npublications in the period before 2008.\nWhereas the citations of the Web of\nScience items are monitored by\nECOOM, it is unknown what the\ncitation impact is of non-WOS\npublications accepted for the VABB1891\n\nSHW. The threshold level being\nacademic peer reviewed, the list of\nauthorized titles contains journals with\nboth national and international scope, in\nEnglish or other languages. Therefore,\nthe esteem of the authorized journals\nmight vary, raising questions on how to\nmeasure the influence of the items\nincluded. The choice of publishers on\nthe other hand is generally seen to be\nmore selective, mainly covering\ninternational top scientific publishers.\nThis study analyses the amount of WOS\ncitations obtained by items accepted for\nthe VABB-SHW database. The citations\nare divided by publication type.\nMethod\nA set of 610 VABB-SHW approved\narticles was considered, authored by\nscientists of the Vrije Universiteit\nBrussel (VUB). The publication year is\ntaken between 2002 and 2008. The\ncitations were collected through a cited\nreference search in the online Web of\nScience. This study therefore considers\ncitations of non-WOS, social sciences\nand humanities publications, by Web of\nScience\nincluded\nitems.\nThe\nmethodology is in accordance with the\nextended citation analysis to nonsourced data proposed by Butler and\nVisser (2006). All citations are counted\nfrom the year of publication till 2013.\nThe citation searches were performed\nmainly based on the publication title.\nThis implies there might be citation\nvariants undiscovered, making the\npresented data minimal estimations. Self\ncitations, on the other hand, are\nincluded.\nResults\nResults are represented in Table 1. The\nfirst column gives the publication type,\nthe second indicates the percentage of\nVABB-SHW publications being cited\nby WOS items, column 3 shows the\n1892\n\nCPP, the average citation per\npublication, whereas the last column\nrepresents the largest citation value\nobtained by a publication of that type.\nTable 1: VABB-SHW citations in Web of\nScience\nPublication\ntype\nArticle in\nJournal\nBook as\nauthor\nBook as\neditor\nChapter in\nbook\n\n# PUB\n\n%-CIT\n\nCPP\n\nMCIT\n\n289\n\n25%\n\n1,63\n\n68\n\n32\n\n21,88%\n\n1,34\n\n12\n\n41\n\n21,95%\n\n3,54\n\n92\n\n248\n\n26,61%\n\n1,24\n\n32\n\n#PUB: number of publications per type in VABB-SHW\n(VUB) / %-CIT: percentage of publication receiving at\nleast one citation / CPP: VABB-SHW number of citations\nper publication obtained with the online Web of Science\nCited Reference Search/ MCIT: Maximum value of\ncitation obtained by a publication\n\nFigures indicate that the rate of cited\nnon-source articles, book chapters or\nbooks by WOS-source items varies from\n21% to 26%. On average each authored\nbook or book chapter receives about 1,3\ncitations. For edited books this is\nsubstantially more, around 3 times the\nimpact of an authored book. Almost a\nquarter of the VABB-SHW accepted\narticles are cited and the CPP equals\n1,63. For book chapters, results are in\nline with the findings of Butler and\nVisser (2006) (taken over 5000\npublications\nfrom\n2\nAustralian\nUniversities for the years 1997 and\n1999) where about 30% of the items are\ncited. However, the Australian figures\nindicate a 65% citation for research\nmonographs of commercial publishers\ncontrary to just over 20% in the case of\nthe VABB-SHW. The results are\nremarkable for two reasons: First,\ncontrary to the Australian case, the\nVABB-SHW contains only social\nsciences and humanities items, where\nbook contributions are expected to play\na more prominent role and second\nbecause the AP’s decision towards\n\npublishers is considered to be more\nrestrictive compared to journal titles.\nTable 2: CPP VABB-SHW, AUSTRALIA,\nWOS: The discipline of Law\nPublication type # Pub # Cit\nArticles in\nVABB\n44\n81\nJournal\nBook as author\n9\n11\nChapter in book\n36\n27\nArticles in\nAU\n584\n142\nJournal\nBook as author\n36\n150\nChapter in book 228\n91\nArticles in\nWOS\n24675 39314\nJournal\n\nCPP\n1,84\n1,22\n0,75\n0,24\n4,17\n0,40\n1,59\n\nVABB: figures for the Flemish Academic Database SHW\n/ AU: Australia: Figures taken from Bulter and Visser\n(2006) / WOS: Average number publications period\n2002-2008, citations to 2011: data sourced by Thomson\nReuters Web of Knowledge (formerly referred to as ISI\nweb of science) licence of ECOOM\n\nTable 2 lights out the case of the\ndiscipline of Law, for the VABB-SHW\nand for the study of Bulter and Visser\n(2006). For journal articles, also the\nglobal numbers were taken for the\nmatching WOS subcategory. Clearly not\nall figures are taken over the same time\nspan, although the WOS window is\nclose to that of the VABB-SHW.\nFor journal articles, the VABB-SHW\nCPP is in a close range with the WOS\naverage and is higher than the CPP for\nAustralia. The CPP for book chapters\nresembles the Australian rate more\nclosely. In contrast, for books as author,\nthe overall figures are confirmed,\nmeaning that the number of citations per\nauthored book are much smaller for the\nVABB-SWH [1,2 versus 4,2].\nConclusion\nThis paper analyses the citation impact\nof social sciences and humanities\npublications accepted for the Flemish\nAcademic Bibliographic Database for\nSocial Sciences and Humanities. Results\n\nare preliminary. As work in progress,\nonly data for the Vrije Universiteit\nBrussel\nwere\nconsidered,\nand\nelaboration is needed to publications of\nthe other Flemish universities. However,\nsome clear tendencies can be observed:\nFor journal articles, where the list of\napproved titles is heterogeneous, a\nsubstantial percentage of items is\nreferred to in international literature and\nthe CPP is at about 1,6. For books and\nbook chapters, values are slightly lower,\nbut also a quarter of the items are cited\nand the CPP is higher than 1. The results\nadd to the study of Ossenblok et al.\n(2012) that the VABB-SHW completes\nthe WOS publications not only in terms\nof coverage, but also in terms of citation\nimpact. Results are however not in full\naccordance with the study of Butler and\nVisser (2006) where mainly books as\nauthor stand out as the most important\ncategory in terms of CPP.\nReferences\nButler, L. &amp; Vissser M.S. (2006).\nExtending citation analysis to nonsource items. Scientometrics, 66,\n327-343.\nDebackere, K. &amp; Glänzel, W. (2004).\nUsing a bibliometric approach to\nsupport research policy making: The\ncase of the Flemish BOF-key.\nScientometrics, 59, 253-276.\nEngels, T.C.E., Ossenblok T.L.B. &amp;\nSpruyt E.H.J. (2012). Changing\npublication patterns in the Social\nSciences and Humanities, 20002009. Scientometrics, 93, 373-390.\nOssenblok, T., Engels, T. &amp; Sivertsen,\nG. (2012). The representation of the\nsocial sciences and humanities in the\nWeb of Science: a comparison of\npublication patterns and incentive\nstructures in Flanders and Norway\n(2005-2009). Research evaluation,\n21:4, 280-290.\n\n1893\n\nCOLLABORATION IN THE SOCIAL SCIENCES\nAND HUMANITIES: EDITED BOOKS IN\nECONOMICS, HISTORY AND LINGUISTICS\nTruyken L.B. Ossenblok1 and Tim C.E. Engels2\n1\n\nTruyken.Ossenblok@ua.ac.be\nCentre for Research &amp; Development Monitoring (ECOOM), University of Antwerp,\nMiddelheimlaan 1, 2020 Antwerp (Belgium) (corresponding author)\n2\n\nTim.Engels@ua.ac.be\nDepartment of Research Affairs and Centre for Research &amp; Development Monitoring\n(ECOOM), University of Antwerp, Middelheimlaan 1, 2020 Antwerp (Belgium);\nAntwerp Maritime Academy, Noordkasteel-Oost 6, 2030 Antwerp, Belgium\nIntroduction\nIn order to quantify the degree of\nresearch\ncollaboration,\nseveral\ncollaborative measures based on\nmathematical computation of the\nnumber of co-authors and the cooccurrence of co-author pairs have been\nput forward. Scientific collaboration\nthrough co-authorship of journal articles\nis internationally on the rise, even\nthough important differences between\ndisciplines remain. Co-authorship is\nrarer in the social sciences and\nhumanities\n(SSH)\nin\nparticular.\nMoreover, the SSH disciplines are\nknown to be underrepresented in\ndatabases such as the Web of Science\nand Scopus. As a result the collaboration\nnetwork of social scientists and\nhumanities scholars in particular cannot\nbe faithfully reflected by the applying\ncurrent collaboration measures to data\nextracted from these databases. Better\nmeasures of collaboration in the social\nsciences and humanities are needed\n(Sula, 2012)\nBy looking at collaboration as apparent\nfrom edited books, we want to make a\nbibliometric contribution to the better\n1894\n\nmeasurement of collaboration in the\nsocial sciences and humanities. The\ninclusion of books in the measurement\nof SSH collaboration is obviously\nrelevant, as the publication output of\nSSH entails not only journal articles, but\nalso a substantial proportion of books as\nwell as chapters in edited books (Hicks,\n2004;\nNederhof,\n2006;\nEngels,\nOssenblok, &amp; Spruyt, 2012)\nData and methods\nFor this research we used data from a\nFlemish full coverage database of peer\nreviewed publications in the SSH, the\nVABB-SHW (Engels et al., 2012). All\npublications 2000-2011 by SSH\nresearchers affiliated with a Flemish\nuniversity are indexed. However, only\npublications in journals and with\npublishers that have been the subject of\npeer review prior to publication, are\neligible. All publications in the database\nare categorized in one or more\ndisciplines, depending on the authors’\ndepartmental affiliation(s).\nIn our research an edited book is the\ntraditional edited book where one or\nmore editors coordinate the publication\nof a book to which a number of authors\n\nResults\nIn the three disciplines the average\nnumber of editors per edited book is\nlarger than the average number of\nauthors per book chapter within these\nedited books, i.e. 2,4 editors versus 1,1\nauthors for History; 2,7 versus 1,2 for\nLinguistics, and 3,1 versus 1,9 for\nEconomics. The proportion of books\nedited by more than one editor is for all\nthree disciplines well above 80%\nwhereas the proportion of book chapters\nwith more than one author are well\nbelow 53% (Economics). Thus we\nobserve that across the three disciplines\nbook editing is envisioned as a\ncollaborative\nenterprise,\ntypically\nundertaken by two to four people,\nperhaps because of the diversity of the\ntasks involved. This contrast with the\nco-authorship of the contributions,\nwhich only in Economics are typically\nthe result of collaboration.\n\nTable 12: Book rank by number of book\nchapters (BC) and by unique authors\n(AU)\nbook rank\n\ncontribute one or more chapters. The\neditors can also be one of the authors, as\nmost of the time they (co)write the\nintroduction and the conclusion and/or\none of the chapters. We looked up\ndetails of the edited books 2000-2011 of\nthree\ndisciplines:\nEconomics\n&amp;\nBusiness, History and Linguistics. Per\nedited book the number of book\nchapters, authors per chapter and unique\nauthors was harvested manually on the\ninternet and in the university library.\nThe results on 236 edited books,\ncontaining a total of 3.932 chapters, are\npresented in this poster. 34 books turned\nout not to be edited books (e.g. text\neditions written entirely by the editor),\nand thus were left out of this study, and\n4 books were unavailable both online\nand through interlibrary document\nsupply.\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n...\nN-4\nN-3\nN-2\nN-1\nN\n\nEconomics\nN= 55\n#BC #AU\n63\n134\n52\n98\n47\n74\n44\n67\n43\n66\n38\n63\n35\n60\n22\n46\n20\n37\n20\n34\n19\n31\n19\n30\n17\n26\n17\n25\n16\n25\n16\n25\n16\n25\n16\n24\n15\n23\n14\n23\n14\n23\n14\n22\n13\n22\n...\n9\n12\n9\n12\n8\n12\n8\n9\n8\n6\n\nHistory\nN = 49\n#BC #AU\n87\n94\n34\n34\n30\n29\n22\n23\n22\n22\n22\n21\n22\n21\n22\n21\n21\n21\n21\n20\n20\n20\n19\n19\n19\n19\n17\n18\n17\n18\n17\n18\n16\n17\n15\n17\n15\n16\n14\n16\n14\n16\n14\n16\n13\n15\n...\n...\n9\n8\n8\n8\n8\n8\n7\n7\n7\n7\n\nLinguistics\nN= 132\n#BC #AU\n50\n55\n49\n54\n44\n48\n43\n47\n42\n44\n40\n41\n35\n40\n33\n36\n30\n34\n30\n33\n28\n29\n26\n29\n26\n29\n26\n28\n26\n28\n25\n27\n24\n26\n24\n25\n24\n25\n24\n25\n23\n24\n22\n24\n22\n23\n...\n...\n8\n8\n8\n7\n7\n5\n6\n4\n3\n2\n\nTable 1 shows the number of book\nchapters and the number of unique\nauthors per edited book, ranked\nindependently for each discipline under\nstudy. The number of book chapters is\nan indication of the volume of the edited\nbooks, whereas the number of unique\ncontributors illustrates the breadth of the\nnetwork of the editor(s). To be able to\nmeasure both the volume and the\nbreadth of the editors’ network, we use a\nwell-known measure, namely the Hindex. The H-index is best known as an\nindicator of publication activity and\ncitation impact, but can be defined more\ngenerally as a source-item relationship.\nIn this study we defined the H-index as\n1895\n\nthe largest number n such that you have\nn edited books with n or more book\nchapters (H-BC), respectively unique\nauthors (H-AU).\nThe H-BC and H-AU indicated in Table\n1 demonstrate that within Economics 16\nbooks have at least 16 book chapters and\n22 books have at least 22 unique\ncontributors. This difference between\nvolume and number of contributors\nillustrates the collaborative publication\npattern in edited Economics books. For\nHistory and Linguistics the H-BC and\nthe H-AU are almost identical with 16\nand 17 for History and 22 and 23 for\nLinguistics. This is in line with the large\npercentage of book chapters written by a\nsingle author. However, edited books\nwith one chapter written by a large\nnumber of unique authors combined\nwith a large number of chapters by one\nand the same author, although very\nunlikely in a humanities discipline, can\ngive the same results. The data on the\ntail (book ranks N to N-4) of the\ndistribution illustrate that less than 5%\nof edited books contain contributions by\n8 or less authors. The full data series\nillustrate that in History and Linguistics\nthe majority of the edited books contain\ncontributions by respectively 15 to 24\nand 17 to 28 authors, whereas in\nEconomics there are 23 to 40\ncontributors in a majority of cases.\nThus, in Economics book chapters\ninvolve more collaboration than in\nHistory and Linguistics. In sum, the\ninconsistencies\nof\nthe\nH-index\nnotwithstanding, this poster illustrates\nthat the concept of an H-index for edited\nbooks is fruitful and needs further\nexploration.\nConclusion\n\n1896\n\nBook chapters and (edited) books are an\nimportant scientific publication medium\nwithin the SSH. Using the H-index on\nbook chapters and unique contributors to\nan edited volume, we indicated the\ndifference between three disciplines in\nboth volume of an edited book and in\nbreadth of the editors network.\nAdditional data from other SSH\ndisciplines will allow us to provide a\nbroader perspective and to draw more\ngeneral conclusions. The results\nfurthermore underline the difference in\nnature between co-authoring and coediting and hence the need to take into\naccount the (special) relation between\neditors and chapter authors when\nstudying collaboration patterns. A new\nmeasure for calculating collaboration\nwill be investigated in future research.\nReferences\nEngels, T. C. E., Ossenblok, T. L. B., &amp;\nSpruyt, E. H. J. (2012). Changing\npublication patterns in the social\nsciences and humanities, 2000-2009.\nScientometrics, 93, 373-390.\nHicks, D. (2004). The four literatures of\nsocial science. In H.F.Moed, W.\nGlänzel, &amp; U. Schmoch (Eds.),\nHandbook of quantitative Science\nand Technology Research: The use\nof publication and patent statistics in\nstudies of S&amp;T systems (pp. 473496). Dordrecht: Kluwer Academic.\nNederhof, A. J. (2006). Bibliometric\nmonitoring of research performance\nin the Social Sciences and the\nHumanities: A review.\nScientometrics, 66, 81-100.\nSula, C. A. (2012). Visualizing Social\nConnections in the Humanities:\nBeyond Bibliometrics. Bulletin of\nthe American Society for Information\nScience and Technology, 38, 31-35.\n\nTHE COLLECTIVE CONSEQUENCES OF\nSCIENTIFIC FRAUD: AN ANALYSIS OF\nBIOMEDICAL RESEARCH\nPhilippe Mongeon1 and Vincent Larivière1\n1\n\nphilippe.mongeon@umontreal.ca; vincent.lariviere@umontreal.ca\nÉcole de bibliothéconomie et des sciences de l’information, Université de Montréal, C.P.\n6128, Succ. Centre-Ville, Montréal, QC. H3C 3J7 Canada\nIntroduction\nThe issue of scientific misconduct has\nbeen largely discussed in the scientific\ncommunity over the last few years.\nMajor fraud cases shocked the scientific\ncommunity (e.g., Woo-Suk Wang, Eric\nPoehlman, Diederik Stapel), and the\nnumber of papers retracted each year\nfrom the biomedical literature increased\ntremendously. Scientific misconduct,\nwhich includes fabrication, falsification\nand plagiarism (Merton 1973; Steneck\n2006), accounts for about 53% of these\nretractions\n(Ferric\n2012).\nSuch\nbehaviour has consequences for the\nscientific\ncommunity\n(waste\nof\nresources, misleading of further\nresearch, loss of the public’s trust), for\nthe public (waste of public funds, ill\nadvised decisions potentially affecting\nthe health of individuals), and of course\nfor the person responsible of the\nmisconduct (Steneck 2006). Past studies\nhave looked at the number of citations\nreceived by retracted papers after they\nwere retracted. While some have shown\nan important decline in the number of\npost-retraction citations (Furman et al\n(2012), others only observed a small\ndecline (Budd et al. 1998; Pfeifer and\nSnodgrass 1990) or even no significant\ndecline at all (Neale et al. 2007; Neale et\nal. 2010). Similarly, Neale et al. (2010)\nhave shown that citing authors were not\naware of the retraction.\n\nIt is assumed that co-authors of retracted\npapers are affected by their colleague’s\nmisconduct (Bonetta 2006), but no study\nhas yet attempted to measure the\nconsequence of such retractions on their\nulterior research careers. The purpose of\nthis study is, thus, to provide empirical\nevidence of these consequences, by\nmeasuring the pre and post retraction\nproductivity and scientific impact of\ncollaborators of retracted papers. This\nstudy is timely, considering that the\nincrease in the number of retractions,\ncombined with an increase in number of\nauthors per paper (Larivière et al. 2006),\nallow us to expect that the number of\n“innocent” co-authors affected by the\nmisconduct of their collaborators will\ncontinue to increase in the next few\nyears.\nMethods\nWe used PubMed to find all retraction\nnotices between 1996 and 2006 as well\nas the corresponding retracted paper.\nThe retracted papers were then found on\nthe Web of Science (474), and provided\nus with a list of 1,920 distinct authors.\nRetractions in biomedical and clinical\nresearch (443 retractions and 1,818\nauthors) were then categorized by\nreason for retraction using data from\nAzoulay et al. (2012) or by reading the\nretraction notice. The reason for\nretraction was data fabrication or\n1897\n\nfalsification in 155 cases (35%) and\nplagiarism in 26 cases (5.9%) for a total\nof 181 (40.9%) cases of misconduct\naffecting 633 authors (34.8%). In order\nto focus on the impact on the “innocent”\ncollaborators, we used the data from\nAzoulay et al. (2012) and the retraction\nnotices to identify, for each retracted\npublication, the author(s) that were\nofficially found responsible for the\nmisconduct. 67 authors (10.6%) were\nidentified as responsible for 144\n(79.6%) of the retracted publication for\nmisconduct and were excluded of our\nanalysis. We then searched the WoS for\nall citable publications by all remaining\n1,751 authors within a range of 5 years\nbefore and after the retraction, providing\nus with a sample of 42,011 distinct\npublications, covering 1991-2011.\nTo measure the impact of the retraction\non researchers’ ulterior careers, we\ncalculated for each co-author: 1) the\naverage number of citations received by\nthe co-author’s paper normalized by\nyear and discipline of journal; 2) the\nnumber of published papers and 3) the\nnumber of authors per paper. We\nmeasured those 3 indicators for 5 years\nbefore the retraction and for 5 years\nafter. For authors with retractions on\ndifferent years, data was collected for 5\nyears before the first retraction and 5\nyears after the last. This reduced our\nfinal sample to 37,436 articles and 1,719\nauthors (629 for cases of misconduct).\nResults\nIn cases of misconduct, our results show\nthat the number of researchers that score\nabove average for citations received (i.e.\nlower than one) decreases by about 5%\nafter the retraction (See Figure 1) while\nthe number of researchers that score\nunder average increases. There is no\nsuch decrease in cases of retractions for\nother reasons, where we instead\n1898\n\nobserved a small increase in the number\nof researchers scoring above average.\nOur results (Figure 2) also show that the\nnumber of articles per author is\ndeclining similarly for both cases of\nmisconduct and other reasons of\nretraction.\n\nFigure 1. Average of relative citations\n(ARC) of co-authors’ publications 5 years\nbefore and after retractions\n\nIn both cases, we found that a\nsignificant proportion of authors (about\n25%) did not publish in the 5 years\nfollowing the retraction. The strongest\ndecrease is found among the researchers\nwho have between 1 and 10\npublications, dropping from 56,7% to\n40,2% in the case of misconduct, and\nfrom 59,4% to 43,7% in other cases.\nThis suggests that the retraction of a\npublication can have a decisive effect on\nthe desire (or ability) of individuals to\npursue a scientific career and that this\neffect is potentially stronger amongst\nresearchers who already publish less\nthan others.\nAs for the number of authors per paper,\nwe see no significant trend before and\nafter retractions, both in the case of\nmisconduct and other reasons. This\nsuggests that retractions have no clear\nimpact on collaborative practices of coauthors.\n\nFigure 2. Total number of publications by\nauthors 5 years before and after\nretractions\n\nDiscussion\nOur findings validate the assumption\nthat co-authors are also experiencing the\nconsequences of the misconduct of their\ncolleagues. This is consistent (and\nperhaps related) with the findings of\nAzoulay et al. (2012), indicating that\nwhole research fields are likely to feel\nthe impact of misconduct cases (e.g.,\ndecrease of new entry and funding). Our\nresults provide yet another evidence of\nthreat that misconduct poses for the\nscientific community, which calls for\nmeasures to be taken in order to reduce\nits prevalence not only in the biomedical\nfield, but in the entire scientific\ncommunity.\nReferences\nAzoulay, P., Furman, J. L., Krieger, J.\nL., &amp; Murray, F. E. 2012.\nRetractions. NBER working paper\nseries, 18449.\nBonetta, Laura. 2006. The aftermath of\nscientific fraud. Cell, 124 (5), 873-5.\nBudd, JM, ME Sievert, &amp; TR Schultz.\n1998. Phenomena of retraction reasons for retraction and citations to\nthe publications. Journal of the\nAmerican Medical Association, 280\n(3), 296-7.\n\nFerric C. Fang, R. Grant Steen, &amp;\nArturo Casadevall. 2012.\nMisconduct accounts for the\nmajority of retracted scientific\npublications. PNAS, 109 (42),\n17028-17033.\nFurman, Jeffrey L., Kyle Jensen, &amp;\nFiona Murray. 2012. Governing\nknowledge in the scientific\ncommunity: Exploring the role of\nretractions in biomedicine. Research\nPolicy, 41 (2), 276-90.\nLarivière, V., Gingras, Y. &amp;\nArchambault, É. 2006. Canadian\ncollaboration networks: A\ncomparative analysis of the natural\nsciences, social sciences and the\nhumanities. Scientometrics, 68 (3),\n519-533.\nMerton, Robert K. &amp; Norman W. Storer.\n1973. The sociology of science:\nTheoretical and empirical\ninvestigations. Chicago: University\nof Chicago Press.\nNeale, Anne et al. 2007. Correction and\nuse of biomedical literature affected\nby scientific misconduct. Science\nand Engineering Ethics, 13 (1), 5-24.\nNeale, Anne Victoria, Rhonda K.\nDailey, &amp; Judith Abrams. 2010.\nAnalysis of citations to biomedical\narticles affected by scientific\nmisconduct. Science and\nEngineering Ethics, 16 (2), 251-61.\nPfeifer, Mark P. &amp; Gwendolyn L.\nSnodgrass. 1990. The continued use\nof retracted, invalid scientific\nliterature. The Journal of the\nAmerican Medical Association, 263\n(10),1420.\nSteneck, Nicholas. 2006. Fostering\nintegrity in research: Definitions,\ncurrent knowledge, and future\ndirections. Science and Engineering\nEthics, 12 (1), 53-74.\n\n1899\n\nCOMPARING NATIONAL DISCIPLINARY\nSTRUCTURES: A QUANTITATIVE APPROACH\nIrene Bongioanni1, Cinzia Daraio2 and Giancarlo Ruocco1\n1\n\nirene.bongioanni@uniroma1.it, giancarlo.ruocco@roma1.infn.it\nSapienza University, Department of Physics, Piazzale Aldo Moro 5, 00185 Rome (Italy)\n2\n\ndaraio@dis.uniroma1.it\nCorresponding author\nSapienza University, Department of Computer, Control and Management Engineering\nAntonio Ruberti, Via Ariosto 25, 00185 Rome (Italy)\n\nAbstract\nIn this paper we propose a quantitative\nmeasure to compare the diversity of\ndisciplinary profiles of countries. It is\nbased on the theory of complex systems\nin physics, and in particular on the spinglasses literature (Parisi, 1983; Mezard\net al 1984a,b,; Fisher and Hertz, 1991).\nOur Diversity of Disciplinary Profiles\n(DDP) measure ranges from -1 to 1. The\ninvestigation on the distribution of the\nDDP is particularly interesting: if it\nshows a peak on 1 it means that there is\na convergence of all analysed units\ntowards a unique profile in their\nscientific specialization; if it presents\ntwo peaks, it points to a kind of &#x27;broken\nsymmetry&#x27; situation in which two\ndifferent configurations or patterns of\nscientific specialization emerge. Finally,\na broad distribution of the DDP index\nindicates fully independence of the\nscientific profiles of the different\ncountries.\nWe analyse the number of publications\n(integer count) of European countries in\nthe 27 Scopus subject categories over\n1996-2011. We compare the disciplinary\nprofiles of European countries i) among\nthem; ii) with respect to the European\nstandard; and iii) to the World reference.\n1900\n\nThe distributions of the resulting DDP\nshow that there is a convergence\ntowards a unique European disciplinary\nprofile, confirming a trend of\nglobalization of science in Europe.\nIntroduction\nThe disciplinary structure of the\nscientific production of countries has\nbeen much studied in the literature.\nSeveral studies have analysed national\npublication\nprofiles.\nNational\npublication profiles indeed show\ninteresting features about a country&#x27;s\nresearch system and its national\nscientific policy. Recent works include\nGlanzel et al. (2008), Almeida et al.\n(2009), and Zhang et al. (2011).\nA commonly used approach is based on\nthe study of publication profiles by\ndiscipline. Within this framework, the\nworld’s scientific output is divided into\nmajor scientific fields, and the relative\ncontribution of each country with\nrespect to each field is illustrated on a\nradar chart. The publication profile of a\nnational research system is then\nmeasured by the Relative Specialization\nIndex which indicates whether a country\nhas a relatively lower or higher share in\nworld publications in a given discipline\nthan in its overall share of world total\n\npublications. Beside, several measures\nof\nsimilarities\nor\ndiversities\n(dissimilarities) over given categories\nhave been proposed, including the Pratt\nindex, the Shannon entropy, the\nStirling’s diversity and the Stirling-Rao\ndiversity measure (see for a recent\nsystematization Stirling, 2007).\nOn the contrary, much less explored in\nthe literature is the quantitative\nevaluation of scientific production\nprofiles and the investigation of the\ndistribution of their similarity or\ndiversity measures.\nThe main objective of this paper is to\npropose a quantitative measure to assess\nthe similarity or diversity of countries\ndisciplinary\nspecialization\nand\ninvestigate its resulting distribution.\nMethod\nThe main variables analysed here are the\n, i.e. the share of articles (integer\ncounting) published in a subject\ncategory i for a given country a over the\nsum of publications in 1996-2011\nAt this purpose, we standardize their\nvalues as follows:\n\n,\nwhere\nstands for average of °.\nThese\nhave the following\nproperties:\nand\nThen, the measure of diversity of\nprofiles between research systems a and\nb, named as Diversity of Disciplinary\nProfile index, DDP, called O(a,b), can\nbe calculated as follows:\n\n,\n\nwhere i denotes the subject category and\nN is the total number of subject\ncategories, in our case 27.\nOur DDP measure of similarity or\ndissimilarity of profiles ranges from -1\nmeaning precisely opposite profile, to 1\nmeaning precisely the same profile, with\n0 representing independence, and\nintermediate values indicating inbetween level of similarity or\ndissimilarity.\nMoreover, the examination of the\ndistribution of the overlaps is\nparticularly interesting. If it shows a\npeak on 1 it means that there is a\nconvergence of all analysed units\ntowards a unique profile in their\nscientific specialization; on the contrary\nif it presents two peaks, it points to a\nkind of &#x27;broken symmetry&#x27; situation in\nwhich two different configurations or\npatterns of scientific specialization\nemerge.\nIn addition, the overlap can be\ncalculated with respect to another\ncountry, or with respect to an average or\nstandard value, or with respect to a\ngiven distribution.\nData\nData come from Scopus database and\nrefer to the scientific production of 27\nEuropean countries in the 27 Scopus\nsubject categories (disciplines) from\n1996 to 2011, including the total world\nscientific production by discipline as a\nreference. The available variables\ninclude: number of articles (including\narticles, reviews and conference\nproceedings papers) in integer and\nfractional counts; total number of\ncitations on a 4 year window, relative\ncitation impact, number of articles in top\n10% of most highly cited articles in a\ndiscipline, number of internationally coauthored papers, number of nationally\nco-authored papers and number of single\nauthored papers.\n1901\n\nstandard Europe standard World\n0.994\n0.954\n0.995\n0.960\n0.853\n0.805\n0.691\n0.767\n0.953\n0.908\n0.989\n0.948\n0.952\n0.891\n0.984\n0.944\n0.840\n0.816\n0.978\n0.968\n0.990\n0.956\n0.970\n0.952\n0.968\n0.973\n0.944\n0.882\n0.983\n0.974\n0.993\n0.952\n0.738\n0.773\n0.863\n0.881\n0.670\n0.718\n0.851\n0.892\n0.967\n0.934\n0.931\n0.891\n0.878\n0.892\n0.658\n0.720\n0.890\n0.838\n0.853\n0.901\n0.982\n0.942\n0.658\n0.718\n0.995\n0.974\n0.902\n0.890\n0.105\n\n0.077\n\nResults\nBy applying the methodology described\nabove, we compare the disciplinary\nprofiles of European countries 1)\nbetween them, 2)with respect to the\nEuropean standard and 3) with respect\nto the World reference. We consider the\n, i.e. the shares of articles (integer\ncounting) published in a subject\ncategory i for a given country a.\nIn Table 1 the detailed values of DDP\nbetween each country and the European\n1902\n\nDistribution of DDP - PUB\n\n3.5\n3\n2.5\n\nP(DDP)\n\nCountry\nAUT\nBEL\nBGR\nCYP\nCZE\nDEU\nDNK\nESP\nEST\nFIN\nFRA\nGBR\nGRC\nHUN\nIRL\nITA\nLTU\nLUX\nLVA\nMLT\nNLD\nPOL\nPRT\nROU\nSVK\nSVN\nSWE\nMin\nMax\nMean\nStd.\nDev.\n\nand World standard are reported. Direct\ncomparisons of the “distances” of each\ncountry from the standards (Europe and\nWorld) are made possible thanks to the\ndescriptive statistics reported at the\nbottom of Table 1, including minimum\nand maximum, as well as mean values\nand standard deviations.\nFigure 1 shows the distribution of DDP\nindices calculated on the indicator PUB\n(number of publications in integer\ncounting) among European countries.\nWe can observe that this distribution\npresents a well-defined peak near 1,\nmeaning that European countries have\nsubstantially equivalent specialization\nprofiles. Figure 2 reports the same\ndistribution for the indicator PUBf\n(number of\npapers in fractional\ncounting).\n\n2\n1.5\n\n1\n0.5\n\n0\n-1\n\n-0.8\n\n-0.6\n\n-0.4\n\n-0.2\n\n0\nDDP\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nFigure 1. Nonparametric kernel\ndistribution of the DDP indices among\nEuropean countries. Stock of Publications\n(1996-2011) - integer counting.\nDistribution of DDP - PUBf\n\n3\n\n2.5\n\n2\n\nP(DDP)\n\nTable 1. Diversity of Disciplinary Profile\nIndices among each country and the\nEuropean and World standard. In the\nbottom of the table some descriptive\nstatistics are reported.\n\n1.5\n\n1\n\n0.5\n\n0\n-1\n\n-0.8\n\n-0.6\n\n-0.4\n\n-0.2\n\n0\nDDP\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nFigure 2. Nonparametric kernel\ndistribution of the DDP indices among\nEuropean countries. Stock of Publications\n(1996-2011) - fractional counting.\n\nFigure 3 illustrates the evolution of the\naverage DDP indices of European\ncountries by year, from 1996 to 2011. It\nshows that over time there has been a\nconvergence of European countries over\na unique scientific specialization profile,\nconfirming a trend of globalization of\nscience in Europe.\nDDP Indices Dynamics 1996-2011\n\nFigure 3. Dynamics of DDP indices over\n1996-2011 – PUB integer counting.\n\nFurther developments\nHaving showed the usefulness of the\nproposed approach, there are several\nextensions that will be pursued in\nfurther research. Namely:\n- extending the analysis to all world\ncountries;\n-extending the investigation at different\nlevel of analysis (e.g. at regional level);\n-investigating the dynamics of\nthe\ndisciplinary profiles over time,\n-analysing the behaviour of other\nscientific production indicators, not\nanalysed in this paper, such as citations,\nrelative citation impact, number of\narticles in top 10% of most highly cited\narticles, number of internationally coauthored papers, number of nationally\nco-authored papers and number of single\nauthored papers.\nAcknowledgments\nData have been provided by Elsevier\nwithin the Elsevier Bibliometric\nResearch Project “Assessing the\n\nScientific Performance of Regions and\nCountries at Disciplinary level by means\nof Robust Nonparametric Methods: new\nindicators to measure regional and\nnational Scientific Competitiveness”.\nSelected References\nAlmeida J.A.S., Pais A.A.C.C.,\nFormosinho S.J. (2009), Science\nindicators and science patterns in\nEurope, Journal of Informetrics, 3,\n134-142.\nFisher, K. H., Hertz, J. A. (1991). Spin\nGlasses. Cambridge University\nPress.\nGlanzel W. (2000), Science in\nScandinavia: A bibliometric\napproach, Scientometrics, 48(2),\n121-150.\nGlanzel W., Debackere K., Meyer M.\n(2008), ‘Triad’ or ‘tetrad’? On global\nchanges in a dynamic world,\nScientometrics, 74 (1), 71-88.\nMezard M., Parisi G. Sourlas N.\nToulouse G., Virasoro M. (1984a)\nNature of the Spin-Glass Phase,\nPhysical Review Letters, 52 (13),\n1156-1159.\nMezard M., Parisi G. Sourlas N.\nToulouse G., Virasoro M. (1984b)\nReplica symmetry breaking and the\nnature of the Spin-Glass Phase,\nJournal de Physique, 45 (13), 843854.\nParisi, G. (1983), Order parameter for\nSpin-Glasses, Physical Review\nLetters, 50 (24), 1946-1948.\nStirling, A. (2007). A general\nframework for analysing diversity in\nscience, technology and society.\nJournal of the Royal Society\nInterface, 4(15), 707–719.\nvan Raan A.F.J. (2004), Measuring\nscience, in H.F. Moed, W. Glanzel\nand U. Schmoch\n(edited by), Handbook of Quantitative\nScience and Technology Research,\nKluwer Academic\n1903\n\nPublishers, pp. 19-50.\nZhang, L., Rousseau R, Glanzel W.\n(2011), Document-type country\n\n1904\n\nprofiles, Journal of the American\nSociety for Information Science and\nTechnology, 62(7),1403-1411.\n\nCOMPREHENSIVENESS AND ACCURACY OF\nDOCUMENT TYPES: COMPARISON IN WEB OF\nSCIENCE AND SCOPUS AGAINST PUBLISHER’S\nDEFINITION\nKazuhiro Hayashi1 and Nobuko Miyairi2\n1\n\nkhayashi@nistep.go.jp\nNational Institute of Science and Technology Policy, 3-2-2 Kasumigaseki, Chiyoda-ku,\nTokyo 100-0013 (Japan)\n2\n\nn.miyairi@nature.com\nNature Publishing Group, Chiyoda Bldg., 2-37 Ichigaya Tamachi, Shinjuku-ku, Tokyo\n162-0843 (Japan)\nBackground\nThe document type is an important\nbibliographic element and used in many\nbibliometric studies to segment source\ndata into a meaningful set by different\nnature of scholarly communication.\nArticles, often regarded as most\nsubstantial body of research, constitute\nthe primary source for creating\nbibliometric indicators. Other document\ntypes are often treated differently; some\nare disregarded when calculating\nindicators.\nPast studies\nSince early days of bibliometric\nresearch, document types have been\nused as a facet of analysis (Braun,\nGlänzel &amp; Schubert, 1989). Science\nCitation Index and its siblings by\nInstitute for Scientific Information have\nbeen traditionally the main tool of such\nanalyses; however, as more services\nbecame available in recent years, there\nare studies reporting the coverage and\naccuracy of different systems (Bar-Ilan,\nLevene &amp; Lin, 2007; Jacsó, 2009;\nMichels\n&amp;\nSchmoch,\n2012).\nInterpretation of document types can\n\nvary by subject domain (Sigogneau,\n2000; Harzing, 2013). The assignment\nof document types is usually controlled\nby the database vendor and it influences\nthe calculation of bibliometric indicators\nand\neven\ntriggers\ncontroversies\n(Rossner, Van Epps, &amp; Hill, 2007).\nPurpose of the study\nThe purpose of this study is to examine\nhow document types are treated in\ndifferent services, and consider its\nimplications for bibliometric research in\ngeneral. Our analysis is descriptive and\nnot intended to draw any statistical\ninference. This is a study in progress\nand we report our initial observations\nbelow.\nData collection\nWe collected database records for 18\njournals of Nature Publishing Group\n(NPG) that were published in the years\n2009-2011 from two services: Thomson\nReuters’ Web of Science (WoS) and\nElsevier’s SciVerse Scopus (Scopus).\nWe also used Nature Publishing Index\n(NPI) content management system,\nwhich indexes NPG’s primary research\njournals including those 18 titles, in\n1905\n\norder to cross-check the numbers\nobtained from WoS and Scopus.\nWe used the full journal title for\nsearching in each database, then broke\ndown the results by publication year and\ndownloaded only the records tagged as\n“2009”, “2010”, or “2011”. Note at this\npoint we did not discriminate any\ndocument type.\nTable 1. Number of items indexed in WoS\nand Scopus for NPG journals published in\n2009-2011\nJournal\nWoS\nScopus\nNature\n7712\n7444\nNature Biotechnology\n1059\n1133\nNature Cell Biology\n684\n719\nNature Chemical Biology\n599\n617\nNature Chemistry\n695\n704\nNature Climate Change\n201\n0\nNature Communications\n602\n607\nNature Genetics\n817\n822\nNature Geoscience\n842\n799\nNature Immunology\n629\n648\nNature Materials\n881\n713\nNature Medicine\n1498\n1493\nNature Methods\n905\n901\nNature Nanotechnology\n641\n657\nNature Neuroscience\n869\n888\nNature Photonics\n745\n672\nNature Physics\n817\n789\nNature Structural &amp;\n742\n717\nMolecular Biology\nTotal\n20938\n20323\n\nInitial findings\nWoS vs. Scopus\nThe number of items indexed from each\nof 18 journals often does not agree\nbetween WoS and Scopus (Table 1).\nScopus tends to have more items in life\nscience journals, while WoS tends to\nhave a greater number in physical\nscience journals.\nTaking Nature as an example, we\nexamined how the numbers compare by\ndocument type (Table 2). Between WoS\nand Scopus, “Article”, “Letter” and\n\n1906\n\n“Review”\ncomparable.\n\nseemed\n\nreasonably\n\nTable 2. Number of Nature records\nindexed in WoS and Scopus for\npublication years 2009-2011\nDatabase\nWoS\nScopus\n2009 2010 2011 2009 2010 2011\nYear\n2544 2577 2591 2411 2492 2541\nTotal\nArticle\n800 825 804 881 899 1076\nLetter\n250 268 283 217 231 258\nReview\n66 37\n37 102\n49 74\nEditorial\n780 760 818 195 196 169\n(Material)\nCorrection\n78 68\n79 60\n73 68\n(Erratum)\nNews Item\n381 448 401\nBook\n169 150 147\nReview\nBiographical\n19 21\n22\nItem\nReprint\n1\nNote\n511 633 603\nShort Survey\n442 409 277\nArticle in\n3\n2 15\nPress\nConference\n1\nPaper\n\nTable 3. Comparison of three document\ntypes published in Nature in 2009-2011\nYear / Doc Type\n2009 / Article\n2009 / Letter\n2009 / Review\n2010 / Article\n2010 / Letter\n2010 / Review\n2011 / Article\n2011 / Letter\n2011 / Review\n\nNPI\n117\n666\n20\n145\n669\n13\n136\n658\n16\n\nWoS\n800\n250\n66\n825\n268\n37\n804\n283\n37\n\nScopus\n881\n217\n102\n899\n231\n49\n1076\n258\n74\n\nWoS and Scopus vs. NPI\nThe numbers obtained from each\ndatabase\nshow\nconsiderable\ndisagreement when compared with NPI\n(Table 3). There are more “Article” and\n“Review”, and fewer “Letter” than\npublisher’s definitions.\nThese 3 document types were matched\nby DOI for further investigation, and\nresults were as follows:\n\n Among 398 items labelled as\n“Article” in NPI, WoS classifies 397\nas “Article” and 1 as “Review”. In\nScopus, 394 of them were found as\n“Article” and 4 as “Review”.\n All 1993 items identified as “Letter”\nin NPI were treated as “Article” in\nWoS. In Scopus, 1979 appeared as\n“Article”, 10 as “Article in Press”,\n13 as “Letter”, and 1 as “Review”.\n All 49 “Review” items in NPI were\nclassified as “Review” in both WoS\nand Scopus.\nIn Scopus, there were total of 111 DOIs\nduplicating in more than one record.\nAmong 20 items indexed as “Article in\nPress” in Scopus, 12 had duplications\nlabelled as “Article”. There were no\nsuch duplications found in WoS.\nImplications for further research\nBoth databases classify items in the\n“Letter” section of Nature as “Article”,\nalthough results in Scopus are somewhat\nmixed. This seems reasonable since\nthose items may appear shorter in length\nbut often communicate primary research\nfindings. Items defined as “Articles” and\n“Review” by NPG mostly classified so\nin both database; however more granular\nand systematic comparisons would be\nrequired to understand a few exceptions.\nOn the other hand, there are 40 more\n“Article” and 801 “Letter” in WoS, and\n483 more “Article” and 693 “Letter” in\nScopus, which belong neither of those\nsections of Nature.\nThe composition of these document\ntypes is of our particular interest for\nbroader implications; for example, if\nnon-primary research publications are\nclassified as “Article”, it may result as a\ndiluting effect in the calculation of\ncertain indicators. We plan to extend our\nanalysis to the rest of document types\nand other journals retrieved in our\nsearch.\n\nReferences\nBar-Ilan J., Levene M., &amp; Lin A. (2007).\nSome measures for comparing\ncitation databases. Journal of\nInformetrics, 1(1), 26-34.\nBraun T., Glänzel W., &amp; Schubert A.\n(1989). Some data on the distribution\nof journal publication types in the\nscience. Scientometrics, 15(5-6),\n325-330.\nElsevier B. V. SciVerse Scopus.\nAccessed January 4, 2013 from:\nhttp://www.scopus.com/\nHarzing, A.W. (2013). Document\ncategories in the ISI Web of\nKnowledge: Misunderstanding the\nSocial Sciences? Scientometrics,\n93(1), 23-34.\nJacsó P. (2009). Errors of omission and\ntheir implications for computing\nscientometric measures in evaluating\nthe publishing productivity and\nimpact of countries. Online\nInformation Review, 33(2), 376-385.\nMichels, C., &amp; Schmoch, U. (2012). The\ngrowth of science and database\ncoverage. Scientometrics, 93(3),\n831–846.\nNature Publishing Group. Nature\nPublishing Index. Public access\navailable from:\nhttp://www.natureasia.com/en/publis\nhing-index/\nRossner, M., Van Epps, H., &amp; Hill, E.\n(2007). Show me the data. The\nJournal of Cell Biology, 179(6),\n1091–2.\nSigogneau A. (2000) An Analysis of\nDocument Types Published in\nJournals Related to Physics:\nProceeding Papers Recorded in the\nScience Citation Index Database.\nScientometrics, 47(3), 589-604.\nThomson Reuters. Web of Science.\nAccessed January 4, 2013 from:\nhttp://isiknowledge.com/\n\n1907\n\nCONTRIBUTION OF BRAZILIAN SCIENTIFIC\nPRODUCTION TO MAINSTREAM SCIENCE IN\nTHE FIELD OF MATHEMATICS: A\nSCIENTOMETRICS ANALYSIS (2002-2011)\nRenata Cristina Gutierres Castanha1 and Maria Cláudia Cabrini Grácio2\n1\n\nregutierres@gmail.com\nUNESP – Univ Estadual Paulista, 737 Hygino Muzzi Filho Avenue, 17525-900 Marília\n(Brazil)\n2\n\ncabrini@marilia.unesp.br\nUNESP – Univ Estadual Paulista, 737 Hygino Muzzi Filho Avenue, 17525-900 Marília\n(Brazil)\nIntroduction\nMathematics is an area of research with\ngreat international collaboration due to\nits peculiarities, such as language\nunderstood worldwide and little\nrestriction in relation to material\nresources for carrying out researches,\nwhich are mostly theoretical (Dang &amp;\nZhang, 2003). Luksch &amp; Behrens (2011)\npresented a bibliometric study of\nMathematics in the period 1868- 2008\nworldwide.\nIn Brazil, the scientific production in\nMathematics takes the 16th position in\nproduction rankings, as seen in\nSCImago Country Rank, in period 19962011. Therefore, the need to assess the\nBrazilian scientific production in\nMathematics is highlighted, given the\nlack of studies in the area and the\nimportance of mathematical studies that\nsupport the framework of different\nareas, contributing to the development\nof science as a whole.\nIn this context, bibliometric indicators\nof production, citation and scientific\ncollaboration contribute to identify the\ncurrent scenario of Brazilian scientific\nproduction in Mathematics indexed in\n1908\n\nmainstream\nscience.\nProduction\nindicators contribute to evidence, among\nother\ncharacteristics,\nresearchers,\ninstitutions, journals and countries in a\nscientific community, enabling the\nidentification of their prolific producers.\nPapers have become the most popular\nbasic unit for bibliometric analysis once\nthey present original research results,\nare submitted by a review system based\non evaluation rules, and compose broad\naccess literature. The citation indicators\nshow impact and visibility of an author,\njournal or country within their\ncommunity. Collaboration join efforts to\nprovide better researching conditions for\nthe group involved, offering support,\nexchange, information and resource\nsharing. For studies on collaborative\nanalysis at macro level, such as those\namong countries, scientific collaboration\nis well portrayed by co-authorships of\npublished papers (Glänzel, 2003;\nGlänzel &amp; Schubert, 2004).\nIn light of the presented issues, this\nresearch aims to conduct a diachronic\nstudy of the scientific production in the\nfield of Mathematics with the presence\nof Brazilian researchers, based on\nScopus from 2002 to 2011, identifying\nits impact on the international scientific\n\ncommunity. Moreover, the study\nhighlights the major journals in\nMathematics where these publications\nwere disseminated, the most productive\nBrazilian institutions in this set of\nscientific publications and the main\nBrazilian collaborator countries in\nMathematics studies.\nMethodological procedures\nFrom the search in Scopus, in the field\nof Mathematics, 12,240 articles with at\nleast one author from Brazil were\nretrieved, published from 2002 to 2011.\nThis study considered the prolific\ninstitutions those are responsible for\nmore than 1.5% of published articles in\nMathematics in the period. This\nthreshold (1.5%) was also used to\nanalyze main journals and collaborator\ncountries.\nFor each year, the annual growth rate of\nBrazilian scientific production in the\narea was also calculated. Also, the total\nnumber of citations received by articles\nwith Brazilian authors was obtained, per\nyear. From this data, it was possible to\ncalculate the citations per article per\nyear.\nTable 1. Total of articles, annual growth\nrate, production percentage and citations.\nYear\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\nTotal\n\n#\narticles\n843\n939\n1271\n929\n1060\n1121\n1336\n1590\n1604\n1727\n12420\n\nannual\n%\ngrowth production\n2.2%\n11.4%\n2.0%\n35.4%\n2.3%\n-26.9%\n2.0%\n14.1%\n2.0%\n5.8%\n1.9%\n19.2%\n1.9%\n19.0%\n1.8%\n0.9%\n1.9%\n7.7%\n1.9%\n104.9%\n2.0%\n\nCit per\narticle\n11.6\n8.6\n6.8\n8.3\n7.5\n7.1\n5.7\n3.8\n2.4\n1.0\n5.6\n\nPresentation and analysis of data\nTable 1 shows the diachronic\ndistribution of production and citation\n\nindicators of the Brazilian articles\npublished in Mathematics (2002-2011).\nExcept in 2005, the annual growth rate\nis always positive, more significantly in\n2004, 2008 and 2009. In the\naccumulated period, Brazilian scientific\nproduction in the area more than\ndoubled presenting accumulated growth\nrate of 104.9%.\nDespite\nthis\ngrowth,\nBrazilian\nparticipation in the area, as measured by\nthe percentage of the production,\nremained around 2% throughout the\nperiod, slightly above this percentage in\nthe first years and below that at the end\nof the period.\nRegarding citations, a decreasing trend\nwas observed: the most cited articles\nwere published in 2002 and 2003,\nwhereas in recent years the articles\nreceived fewer than 5 citations on\naverage.\nBrazilian scientific production has been\ndisseminated by 6 major journals:\nPhysical\nReview\nE-Statistical,\nNonlinear, and Soft Matter Physics\n(7.5%);\nPhysica\nA:\nStatistical\nMechanics and Its Applications (5.1%);\nPhysical Review D: Particles, Fields,\nGravitation and Cosmology (4.6%);\nLecture Notes in Computer Science\n(4.1%); Journal of Physics A:\nMathematical and Theoretical (3.2%);\nJournal of Mathematical: Analysis and\nApplications (1.6%). None of these\njournals is Brazilian, three are European\nand three are North American. Four of\nthese journals are in the first quartile of\nthe journals ranking according to\nSCImagoJR,\nindicating\nthat\nthe\nBrazilian production has been inserted\ninto high visibility channels.\nIt is noteworthy that out of the 12,240\nanalyzed articles, 4,764 (38.9%) were\npublished by Brazilian authorship with\nat least one foreign author, thus\nindicating that a significant part of\nBrazilian production in the area has\nbeen developed internationally. Among\n1909\n\nthe 85 collaborator countries, 11 main\ncountries were: United States (10.1%),\nFrance (6.6%), Germany (3.9%), United\nKingdom (3.7%), Spain (3.6%), Italy\n(3.3%),\nChile\n(2.4%),\nRussian\nFederation (2.4%), Canada (2.3%),\nPortugal (2.1%) and Argentina (1.8%).\nTable 2 presents the 21 most productive\nBrazilian institutions in the area. All\ninstitutions most productive have\ngraduate programs and that the graduate\nprograms from USP, UNICAMP, UFRJ,\nIMPA and UFMG have equivalent\nperformance with international centers\nof excellence.\nMost productive institutions are public:\n15 federal institutions and five state\nuniversities. Among state universities,\nthree São Paulo public universities are\nhighlighted, with sponsorship by São\nPaulo Research Foundation (FAPESP).\nThis\nfoundation\nhas\nachieved\ninternational reputation and made\nagreements with research councils in\nseveral countries, including Holland,\nFrance, USA, Canada, Germany and the\nUK (Gibney, 2012). University of São\nPaulo, the largest producer of scientific\npapers in Mathematics, is on the top of\nLatin-American rank in Times Higher\nEducation World University Rankings\n(Gibney, 2012).\nFinal considerations\nBrazilian scientific production presented\na positive annual growth. Most of major\njournals that disseminate Brazilian\nscientific production are in the first\nquartile of the Mathematics journal\nranking.\nThe\nmost\nproductive\ninstitutions have graduate programs and\nare public universities. A significant\npart of Brazilian production has been\ndeveloped in international scientific\ncollaboration.\n\n1910\n\nTable 2. Most productive Brazilian\nInstitutions.\nInstitution (abbreviation)\nUniv. de São Paulo (USP)\nUniv. Est. Campinas\n(UNICAMP)\nUniv. Fed. Rio de Janeiro\n(UFRJ)\nUniv. Est. Paulista (UNESP)\nInst. Nac. de Mat. Pura e Apl.\n(IMPA)\nUniv. Fed. de Minas Gerais\n(UFMG)\nUniv. Federal de Pernambuco\n(UFPE)\nUniv. Fed. Rio Grande Sul\n(UFRGS)\nUniv. Federal Fluminense (UFF)\nUniv. de Brasília (UnB)\nCentro Br. de Pesq. Físicas\n(CBPF)\nUniv. Federal do Ceara (UFC)\nPont. Univ. Cat. R. Janeiro\n(PUC-Rio)\nUniv. Fed. de São Carlos\n(UFSCAR)\nUniv. Federal da Paraíba\n(UFPB)\nUniv. Fed. Santa Catarina\n(UFSC)\nUniv. do Est. Rio de Janeiro\n(UERJ)\nUniv. Estadual de Maringá\n(UEM)\nUniv. Federal do Paraná (UFPR)\nLab. Nac. Comp. Cientifica\n(LNCC)\nUniv. Fed. Rio Grande Norte\n(UFRN)\n\n#\narticles\n2759\n\n%\n22.5%\n\n1329\n\n10.9%\n\n1182\n\n9.7%\n\n714\n\n5.8%\n\n631\n\n5.2%\n\n613\n\n5.0%\n\n534\n\n4.4%\n\n500\n\n4.1%\n\n488\n482\n\n4.0%\n3.9%\n\n404\n\n3.1%\n\n375\n\n3.1%\n\n342\n\n2.8%\n\n320\n\n2.6%\n\n303\n\n2.5%\n\n300\n\n2.5%\n\n289\n\n2.4%\n\n288\n\n2.4%\n\n275\n\n2.2%\n\n244\n\n2.0%\n\n197\n\n1.6%\n\nReferences\nDANG, Y. &amp; ZHANG, W. (2003).\nInternationalization of mathematical\nresearch. Scientometrics, 58 (3),\n559-570.\nGLÄNZEL, W. (2003). Bibliometrics as\na research field: a course on theory\nand application of bibliometric\nindicators. Retrieved from:\nhttp://citeseerx.ist.psu.edu/viewdoc/d\nownload?doi=10.1.1.97.5311&amp;rep=r\nep1&amp;type=pdff .\nGLÄNZEL, W. &amp; SCHUBERT, A.\n(2004). Analyzing scientific\n\nnetworks through co-authorship. In\nMoed et al (eds.), Handbook of\nQuantitative Science and\nTechnology Research (pp. 257-276).\nNetherlands: Kluwer Publishers.\nGIBNEY, E. (2012). Boom times and\ngolden goals. Times Higher\nEducation. Retrieved December 28,\n\n2012 from:\nhttp://www.timeshighereducation.co.\nuk/story.asp?storycode=422083.\nLUKSCH, P. &amp; BEHRENS, H. (2011).\nMathematics 1868-2008: a\nbibliometric analysis.\nScientometrics, 86 (1), 179-194.\n\n1911\n\nCO-OCCURRENCE BETWEEN AUTHORS’\nAFFILIATION AND JOURNAL: ANALYSIS BASED\nON 2-MODE NETWORK\nWei Ruibin1, 2, Wu Yishan1, Tian Dafang2\n1\n\nrbwxy@126.com, Wuyishan@istic.ac.cn\nInstitute of Scientific and Technical Information of China, Beijing, (China)\n2\n\ntdf7011@126.com\nAnhui University of Finance and Economics, Bengbu,Anui (China)\nIntroduction\nCo-words network and co-citation\nnetwork may reveal the relationship\namong words or papers according to\ntheir co-occurrence. These networks\nusually appear as 1-mode network.\nThis paper aims to reveal the\nrelationship\nbetween\nacademic\ninstitutions and their publications based\non 2-mode network. Such network can\nbring out more abundant information\nthan 1-mode network. Through the\ninstitutes-journals 2-mode network, we\ncan find the authors’ submission habit,\nthe productivity of the institutes and the\nattractiveness of a journal toward\npotential authors.\n\ntwo nodes. In this study, the 2-mode\nnetwork included two kinds of\ninformation: the institute and the\njournal. Social network analysis was\nperformed by UCINET. 2-mode\nnetwork is the network between the\nindividual and organization in the social\nnetwork analysis. It is based on the\nduality existed the individual and the\norganization or groups (LIU, 2009). 2mode data can express by a rectangle\nmatrix and it can convert into two 1mode data. In this study the 2-mode data\nincluded the institute and the journal.\nThe 2-mode data can express using the\n2-mode network by the UCINET. The\noriginal\nmatrix\nwas\nnormalized\naccording the average papers’ number.\n\nMethod and Tool\nCo-occurrence analysis and social\nnetwork analysis were used extensively\nin the current studies. Co-occurrence\nmeans that the institute’s author\npublished an article in the some journal.\nSocial Network Analysis (SNA) can be\nconsidered vital for an understanding of\nthis complex and dynamic structure. The\nmajor advantage of SNA method is that\nthey can work at both micro and macro\nlevels in their analysis of relational\nstructure of different objects of study\n(David Mingguillo, 2010). The 2-mode\ndata reflects the relationship between\n\nData Collection\nThe data were retrieved from the\nChinese Social Sciences Citation Index\n(CSSCI). There are 53661 papers\npublished in the 17 journal and there are\n3898 first authors’ affiliations during\n1998 and 2011. The data were divided\ninto three windows which were 19982003, 2004-2007, 2008-2011 according\nto the number of articles. The institutes\nwere the top 25 institutes every window.\nAt last the paper studied 17 journals and\n38 institutes. The journals could be\ndivided into 3 types: the library science\njournal, the information science journal\n\n1912\n\nand the two fields mixed journal. The\ninstitutes included 3 public libraries, 2\nresearch institutes and 33 universities.\nResults and Discussion\nThe change of the institute-journal 2mode network\nThe data findings show that there are\nmore institutes published articles in the\ninformation science journals and the\ninstitutes are relatively less in the library\nscience journals from 1998 to 2003 and\nfrom 2008 to 2011 from the Fig.1, Fig.2\nand Fig.3. On the contrary there are\nmore institutes published library science\narticles in the library science journals\nfrom 2004 to 2007.\nWuhan University, Nanjing University,\nPeking\nUniversity\nand\nNankai\nUniversity are balanced published their\narticles in the library science and the\ninformation science journals from 1998\nto 2003. Lately Sun Yat-Sen University\nand National Science Library of the\nChinese Academy of Sciences entered\nthe first group. Nanjing Agricultural\nUniversity, Zhengzhou University, East\nChina Normal University and Beijing\nNormal University published their\nworks in the 4 mixed journals. It\nillustrates\nthat\nthese\ninstitutes’\nresearchers are interesting both in the\ninformation science and library science.\nBut their productive capability is lower\nthan the first group.\nThe Institute of Scientific and Technical\nInformation of China and similar\ninstitutions\nare\nthe\nimportant\ninformation science institutes and the\nNational Library of China and same\nkinds organizations are the important\nlibrary science institutes.\nSome institutes’ submission shows\nregional characteristic obviously. For\nexample, the Tianjin Library and Nankai\nUniversity published more articles in the\nLibrary Work and Study. The Wuhan\n\nUniversity published more articles in the\nDocument, Information &amp; Knowledge.\nThe National Science Library of\nChinese Academy of Sciences published\nmore articles in the Library and\nInformation\nService.\nThe\nJilin\nUniversity published more articles in the\nInformation Science.\nThe\nLibrary\nand\nthe\nLibrary\nDevelopment are isolated in the Fig.3 it\nmeans the publications of the institutes’\nresearcher are poorly published in the\ntwo journals. It reflected that their\nattractive ability is relatively weak.\n\nFig.1 1998-2003 2-mode Network\n\nFig.2 2004-2007 2-mode Network\n\nFig.3 2008-2011 2-mode Network\n\n1913\n\nThe quantitative Analysis of the\ninstitutes’ Centrality\nIt is more complex of the 2-mode\nnetworks’\ncentrality.\nDegree,\nbetweenness and closeness are 3 indexes\nto measure the centrality of the 2-mode\nnetwork. From the data we can find\nthere is more relativity between degree\nand closeness.\nIn this study the degree of the institute\nmeans its capability published articles in\nthe some journal. The value of the\ndegree, betweenness and closeness are\nchanged in different window. The\ninstitutes can be divided into three parts\nin some window according to the 3\nindex. Wuhan University etc. are the\nfirst class, Shanghai University etc. are\nthe second class and Xi’an Jiao tong\nUniversity are the third class. The first\nclass and the second class are balanced\nin the Information and Library science\nand the third class is asymmetrically\noutstanding in the Information science\nor in the Library science. The situation\nis changed by the time. For example,\nNALCAS is the second class from 1998\nto 2003 and it is the first class from the\n2004 to 2011.\nThe 17 journals can be divided into 3\nparts: Library and Information Service,\nInformation Science, Library Work and\nStudy and so on. The value of the\nJournal of Library Science in China is\nrelatively poor because their numbers of\narticles is less. We should synthetically\ntreat the value according the realistic\nsituation when we analysis the data.\nConclusion\nBased on the institute-journal 2-mode\nnetwork, we could find the relationship\nbetween the institutes and the journals\nform the quantity and quantity. We\ncould divided the institutes and the\njournal into 3 parts according the 3\nindex. It also reflects the feature of the\ninstitutes and the journals.\n1914\n\nAcknowledgments\nThis study supported by the Humanities\nand Social Science Funds of the\nMinistry of Education of the People’s\nRepublic of China (Project Code:\n11YJC870024).\nReferences\nDavid Mingguillo(2010). Toward a new\nway of mapping scientific fields:\nAuthors&#x27; competence for publishing\nin scholarly journals. Journal of the\nAmerican Society for Information\nScience and Technology,61(4),771786\nLiu,Z.H.,Zheng,Y.N.(2011).On research\nspecialty evolution mapping and its\napplication. Journal of The China\nSociety For Scientific and Technical\nInformation,30(11),1178-1186\nMa,R.M.,Ni,C.Q.(2012). Author\nCoupling Analysis: An exploratory\nstudy on a new approach to discover\nintellectual structure of a discipline.\nJournal of Library Science in\nChina,38(198),4-11\nQian,L.J.,Zhang,X.M.,Zheng,Y.N.(2008\n). Study on Appearance of Cooccurrence in Library and\nInformation Science Institutions\nOverseas, Library and Information\nService,52(11),49-52\nSun,H.S.(2012). Author keyword cooccurrence network analysis: an\nempirical research. Journal of\nIntelligence,31(9),63-67\nYang,L.B., Yang,L.Y.,Qiao,Z.H.(2010).\nA Study of Research Institutions’ R\n&amp; D Activities in Genomics Fields,\nLibrary and Information,1,93-98\nZhang,Z.L.Zhang,Z.Q.Li,X.Y.(2011).Co\n-occurrence analysis between\nresearch institutes and keywords\nbased on 2-mode network, Journal of\nThe China Society For Scientific and\nTechnical Information, 30(12),12491260\n\nCOST ANALYSIS OF E –JOURNALS, BASED ON\nTHE SCIENTIFIC COMMUNITIES USAGE OF\nSCIENCE DIRECT ONLINE DATABASE WITH\nSPECIAL REFERENCE TO BANARAS HINDU\nUNIVERSITY LIBRARY, INDIA\nDr.M.Anand Murugan; Dr.Ajay Kumar Srivastav\nIndia,am9996@yahoo.com\nDeputy Librarian,Banaras Hindu University,Varanasi,\nIntroduction\nLibrary services and products have\nassociated costs, including direct\nmonetary costs and indirect costs such\nas time. The decision to acquire or\nprovide a particular product or service\nshould involve an examination of its\ncosts and benefits to library customers.\nTo assess the increasing prices of ejournals, we must find a way to compare\njournals with different amounts and\nquality of content, publishers, and\nsubject-matter. Factors such as time,\ntangential costs such as paper or ink\ncartridges (or any other somewhat\n“hidden” costs), costs for training and\nmaterials, or any other factors that add\nto the cost of providing a service or\nproduct are considered indirect costs.\nMeasuring benefits in a not-for-profit\nenvironment can be even more difficult.\nAs part of the study the researcher\ndecided to examine the three years\nscience e direct online database\ndownloads and subject wise downloads\nof articles. This article describes a study\nin which Cost Analysis was used to\nexamine the cost-effectiveness of an\nelectronic database.\n\nWhy Cost Analysis?\nIt is important to consider users and\ntheir demand for a particular e- journal.\nWho will use this e- journal? How often\nwill they use it? E-journals further\ncomplicate the picture with complex\npricing structures, online searching,\nhyperlinks, and server reliability.\nRegardless, the same problem of\ncomparison remains: what a publisher\ncharges for a particular journal does not\nnecessarily reveal anything about that\njournal’s relative value.\nScience Direct Online Database\nElsevier Science Direct is the world’s\nlargest full-text database in the field of\nscientific, technical and medical (STM)\ninformation. Science Direct offers\nlibraries and scientists globally have\naccess to over eight million full-text\narticles - more than a quarter of the\nworlds electronic STM information from over 1700 peer-reviewed journals,\nan expanding suite of Back files (titles\nloaded from Volume 1, Issue 1), as well\nas a growing range of authoritative\nbooks, including reference works,\nhandbooks, book series and e-books.\nIn India, Science Direct is accessed at\nover 700 institutions - universities,\ncorporate R&amp;D centers, engineering and\n1915\n\nmedical colleges, governmental research\nlaboratories etc\n\nBHU Agreement is very useful to the\nusers of BHU.\n\nUsage Analysis by No. of Downloads\nBHU Library approaches the Science\nDirect for getting the three years usage\ndata. They received 3 years full text\ndownloads details from Science Direct.\nThe following figure arrived based on\nthe science direct full text articles\ndownload. Three years includes 2010,\n2011 and January to September 2012.\n\nUsage Analysis by Subject Collection\nBHU Library approaches the Science\nDirect for getting the subject wise usage\ndata. Science Direct given the usage data\nduring January to September 2012 was\nderived from 13 subject collections\nsubscribed by BHU in 2012.\n\nFigure 2. Usage Analysis by subject\ncollection\nFigure 1. Year Vs. No. of Downloads\n\nThe above Figure 1 shows that the year\nwise downloads of full text science\ndirect article. It clearly shows that Usage\nand downloads of articles in the year of\n2010 to 2012. It is revealed from the\nfigure that 4, 72,769 full text articles\nwere downloaded in the year 2010, But,\nit was reduced in the year 2011, 3,\n58,965 full text articles downloaded.\nCompare to the year 2010 with 2011, it\nwas decreased. Its depends on many\nfactors. But in the year 2012 Banaras\nHindu University subscribed 13 subject\ncollections through 2012 Elsevier &amp;\nBHU Science Direct Agreement. It\nincreased the usage of the Science\nDirect articles. From January to\nSeptember 2012 totally 8, 21, 261 full\ntext articles are downloaded. It may\nincrease in December 2012. This result\nshows that 23 subject collections which\nare subscribed through 2012 Elsevier &amp;\nUGC-INFLIBNET and 2012 Elsevier &amp;\n\n1916\n\nThis Figure 2 states that subject wise\nfull text articles download. This data\nshows that the expected full-text\ndownloads at Banaras Hindu University\nfor the full-year of 2012 is 470,000 articles\ndownload which is an increase of 31%\nover the full-year usage for 2011. This\nfigure 2 shows the usage and research\noutput break-down by various subject\ncollections. It is evident that a significant\ncontribution (53%) to the usage on\nScience Direct during Jan-Sept 2012 was\nderived from 13 subject collections\nsubscribed by BHU in 2012. This usage\nstatistics is an indicator of high\npreference of the Elsevier journals\n(Science Direct) by the researchers of\nBanaras Hindu University.\nCost of per download\nThe researcher aims to identify the cost\nof per download of the article.\nFollowing formula retrieved the cost of\nper article. The no. of download divided\nby total subscription of the particular ejournal package gives the cost of per\n\ndownload.Cost of per download =\nNumber of download / Total Cost of the\nsubscription.\nNo. Year\n1.\n2.\n3.\n\n2010\n2011\n2012\n\nNo. of\nCost of per In $\ndownload download Rs.\n472769\n20.56\n358965\n27.08\n821261\n11.84\n\nThe above table shows in the year 2010,\nno. of downloads was 472769, cost of\nper article download is rupees 20.56, it\nwas increased in the year 2011, due to\ndecreasing the no. of downloads, so cost\nper article is 27.08. But it was\ndramatically decreased in the year 2012,\ndue to overwhelming downloads, cost\nper article is 11.84 rupees. In this table\nshows that no. of downloads per year\ndecides the cost of the article.\nConclusion\nResults of the study suggest that Science\nDirect e-journals do affect use and cost\nof per article download to a significant\ndegree. Most discrete analysis by\nsubject collection will provide the\nlocally useful information for collection\ndevelopment and research output of the\nsubject. In order to accurately assess\ntotal costs of electronic journals,\nhowever our cost model should provide\n\nsome\nvisibility\nfor\nannual\n“administrative”,\n“access”,\nor\n“platform” fees charged by a vendors\nlike Science Direct. The formula for\nincluding these were approximated\nbased on ratios of subscription costs\namong BHU for the titles in the study.\nReferences\nColin K. Mick, “Cost Analysis of\nInformation Systems and Services,”\nAnnual Review of Information\nScience and Technology, Vol.14\n(1979) pp. 37–39\nTenopir, Carol and Donald W. King.\n“Towards Electronic Journals:\nRealities for Scientists, Librarians,\nand Publishers” Washington, DC:\nSpecial Libraries Association, 2000.\nMontgomery, Carol Hansen.“Measuring\nthe Impact of an Electronic Journal\nCollection on Library Costs.” D-Lib\nMagazine, Vol. 6 No. 10 Measuring\ncosts of electronic journals Harter,\nStephen P. and Charlotte E.\nFord.“Web-based\nAnalyses of E-journal Impact:\nApproaches, Problems, and Issues.”\nJournal of the American Society for\nInformation Science, Vol. 51 No. 13\n(2000), pp.1159-1176.\n\n1917\n\nA COVERAGE OVERLAP STUDY ON CITATION\nINDEX: COMMERCIAL DATABASES AND OPEN\nACCESS SYSTEMS\nMing-yueh Tsay1, You-min Lu2 and Yen-chun Lin3\n1\n\nmytsay@nccu.edu.tw\nNational Chengchi University, Graduate Institute of Library, Information Science and\nArchival Studies, NO.64,Sec.2,ZhiNan Rd.,Wenshan District, Taipei City 11605,Taiwan\n(R.O.C)\nIntroduction\nThe ways of knowledge dissemination\nhave been changing with the evolution\nof media, especially in the last decade.\nComputers and webs have demonstrated\ngreat influences on the production,\nretrieval, dissemination and use of\ninformation, and new patterns of\nscholarly communication have been\ndeveloped in the presence of citation\nsystems, both commercial and open\naccess. This study, therefore, aims to\ncompare the above two kinds of citation\nsystems to see their duplication, overlap,\nuniqueness and comprehensiveness.\nTheories of coverage overlap among\nabstract, index and citation databases\nhave been presented by researchers, and\nmany evidence-based studies have been\nconducted\never\nsince\nthen.\n(Martyn,1967; Read &amp; Smith, 2000).\nGluck (1990) defined the journal\ncoverage overlap as the ratio of the\nnumber of journal titles or articles in the\nintersection of two secondary sources to\nthe number in their union. Comparisons\nbetween commercial databases and open\naccess systems have drawn more\nattention as well after the widespread\nuse of the Internet(Jacso; 2005; BarIlan, 2010; and Rensleigh, 2011).\nThe studies on overlap and uniqueness\ncan be very extensive, ranging from all\nsorts of data sources such as publishers,\n1918\n\ndatabases and search engines to all sorts\nof data types including journal articles,\npatents, web resources, and so on. The\napplication of overlap studies may serve\nas references for libraries in selection of\ncitation index databases.\nMethods\nUsing the publications of the thirty A.\nM. Turing Award’s Winners from 1990\nto 2011 as the samples, the present study\nconducted retrievals in two commercial\ncitation databases, such as SCIE,\nScopus, and three open access citation\nsystems of Google Scholar (GS),\nMicrosoft Academic Search (MAS) and\nCiteseerX. The bibliographic records\nretrieved were evaluated and crossreferenced\nto\ndetermine\nthe\ncomprehensiveness,\noverlap\nand\nuniqueness of the five citation databases\naccording to the following steps.\n1. Data Collection:\nThe names of the thirty Turing Award\nwinners were used as queries for authors\nin each database to collect bibliographic\nrecords of their works from 1990 to\n2012. To avoid confusions, background\ninformation about the thirty award\nwinners was essential to identify the\ndata collected; full texts were examined\nfor further confirmation if necessary.\nIn case of any preclusion, no additional\nconditions were added to narrow down\n\nthe search results; records were\nmanually filtered after exportation.\n2. Data Refinement:\nCo-written works by the thirty A. M.\nTuring Award winners were eliminated\nfrom the data collected. The refined data\nset was ready for analysis and\ncomparison.\n3. Data Analysis:\nCross-reference of databases by pair\nwere conducted manually, and the five\ncitation databases were paired as\nfollows: SCIE-Scopus, SCIE-GS, SCIEMAS, SCIE-CiteSeerX, Scopus-GS,\nScopus-MAS, Scopus-CiteSeerX, GSMAS,\nGS-CiteSeerX\nand\nMASX\nCiteSeer . Duplication within and\noverlap\namong\ndatabases\nwere\ndetermined based on authors, year of\npresentation and content of texts.\nResults\nTypes of samples retrieved from SCIE,\nScopus, GS, MAS and CiteSeer X\ninclude academic articles, conference\nproceedings,\npatents,\nunpublished\nmanuscripts, course materials, memoirs,\nand institutional resources. Based on\nthese samples, the results of duplicate\nwithin each database and comparison\namong the five databases were\ndemonstrated and discussed as follows.\nIntra-Duplication within Databases\nDuplication may occur in each database\nfor some reasons. Table 1 lists the\nnumber of records collected, number of\nrecords after refinement, number of\nduplicate, number of records without\nduplicate and percentage of intraduplication. Take SCIE for instance,\nthere are 1,188 records retrieved, which\nare reduced to 1,178 after data\nrefinement, and the number of\nduplicates within the 1,178 records is\n88, accounting for 8% of total records.\nExclusive of the duplicates, 1,090\n\nrecords remained is used in the\nexamination of inter-database overlaps.\nTable 1 Duplication within Each Citation\nDatabase\nDatabase\n\n(A)\n\n(B)\n\n(C)\n\n(D)=\n(B)-(C)\n1,090\n940\n2,250\n2,243\n888\n\n(E)=\n(C)/(B)\n8%\n6%\n10%\n10%\n5%\n\nSCIE\n1,188 1,178 88\nScopus 1,015 1,004 64\nGS\n2,492 2,481 231\nMAS\n2,488 2,479 236\nCiteSeerX 902\n897\n49\nNote:\n(A): Number of Records Collected;\n(B): Number of Records after Refinement;\n(C): Number of Duplicates;\n(D): Number of Records without Duplicates;\n(E): Intra-database Duplication\n\nTable 2 Overlap among Citation\nDatabases in Cross-reference Comparison\nDatabases by pair\n\n(F)\n\n(H)=\n(G)/(D)\n55%\n602\n64%\n50%\n542\n24%\n74%\n809\n36%\n26%\n279\n31%\n70%\n658\n29%\n81%\n763\n34%\n31%\n294\n33%\n57%\n1,282\n57%\n20%\n450\n51%\n22%\n491\n55%\n(G)\n\nSCIE\n488\nScopus\n388\nSCIE\n548\n2 SCIE-GS\nGS\n1708\nSCIE\n281\nSCIE3\nMAS\nMAS\n1434\nSCIE\n811\nSCIE4\nCiteSeerX CiteSeerX 609\nScopus\n282\nScopus5\nGS\nGS\n1592\nScopus\n177\nScopus6\nMAS\nMAS\n1480\nScopus\n646\nScopus7\nCiteSeerX CiteSeerX 594\nGS\n968\n8 GS- MAS\nMAS\n961\nGS\n1800\nGS9\nX\nCiteSeer CiteSeerX 438\nMAS\n1752\nMAS10\nCiteSeerX. CiteSeerX 397\nNote:\n(F): Number of records exclusively indexed;\n(G): Number of Identical Records;\n(H): Overlap Percentage\n1\n\nSCIEScopus\n\nOverlap among Databases: Crossreference\nTable 2 summarizes the number of\nrecords exclusively indexed in each\ndatabase and the pair-wise overlap\namong the five databases under study.\n1919\n\nFor example, for the pair of SCIEScopus, 488 works by the thirty A. M.\nTuring Award winners are exclusively\nindexed in SCIE, accounting for 45% of\ntotal records; while 338 works are\nexclusively indexed in Scopus or 36%\nof total records. Both databases share\n602 identical bibliographies, suggesting\n55% overlap in SCIE and 64% in\nScopus. In consideration of interdatabase overlap, higher percentage\nimplies lower quality, which indicates\nthat SCIE surpasses Scopus in\nuniqueness. Open access citation\nsystems excel commercial citation\ndatabases in general, while uniqueness\nof GS and MAS are better than\nCiteSeerX.\nDiscussion and Conclusion\nThe results of this study reveals that the\ntwo general search engines, i.e., GS and\nMAS, are the most comprehensive and\ntheir number of records without\nduplication is more than twice of SCIE\nand Scopus. The comprehensiveness of\nCiteSeerX is the poorest. In comparison\nof the two commercial citation\ndatabases, SCIE surpasses Scopus in\ncomprehensiveness. The results also\nindicates\nthat\nthe\nintra-database\nduplication is the highest percentage of\n10 for both GS and MS, while CiteSeerX\ndemonstrates the least intra-database\nduplication of 5%.\nThe study of overlap shows that the pair\nof GS-MAS demonstrates the highest\nnumber of identical number, while the\npair of SCIE-CiteSeerX the lowest. SCIE\nsurpasses Scopus in uniqueness, but\nopen access citation systems excel\ncommercial citation databases in\ngeneral, among which GS and MAS is\nbetter than CiteSeerX.\nBased on the findings of this study,\ncitation data of each author, i.e. paper\ncited times, author cited times, author h\nindex, etc. can be included and\n1920\n\ncompared in further studies; whether or\nnot the citation index services provide\nfull-texts, and the number of accessible\nfull-texts can be explored in future\nstudies as well.\nWe hope the findings and suggestions\nbased on the research results may serve\nas references for both commercial and\nopen access service providers, and for\nlibraries who consider to acquire or to\nbuild citation index systems on their\nown. Suggestions on indicators and\ntools for academic assessment are\npresented\nbased\non\nthe\ncomprehensiveness evaluation of each\nsystem as well.\nAcknowledgements\nThis work was supported by grant\nNSC1007-2410-H-004-153-MY2 from\nthe National Science Council, Taiwan,\nR.O.C.\nReferences\nAdriaanse, L &amp; Rensleigh, C. (2011).\nComparing Web of Science, Scopus\nand Google Scholar from an\nenvironmental sciences perspective.\nSouth African Journal of Libraries\nand Information Science, 77(2), 169178.\nBar-Ilan, J. (2010). Citations to the\n“Introduction to Informetrics”\nindexed by WOS, Scopus and\nGoogle Scholar. Scientometrics,\n82(3), 495-506.\nGluck, M. (1990). A review of journal\ncoverage overlap with an extension\nto he definition of overlap. Journal\nof the American Society for\nInformation Science, 41(1), 43-60.\nJacso, P. (2005). As we may search Comparison of major features of the\nWeb of Science, Scopus, and Google\nScholar citation-based and citationenhanced databases. Current\nScience, 89(9), 1537-1547.\n\nMartyn, J. (1967). Tests on abstracts\njournals: Coverage overlap and\nindexing. Journal of Documentation,\n23, 45-70.\n\nRead, E. &amp; Smith, C. (2000). Searching\nfor library and information Science\nliterature: a comparison of coverage\nin three databases. Library\nComputing, 19, 118-126.\n\n1921\n\nFACTORS RELATED TO GENDER DIFFERENCES\nIN SCIENCE: A CO-WORD ANALYSIS\nTahereh Dehdarirad1, Anna Villarroya2 and Maite Barrios3\n1\n\ntdehdari@yahoo.com\nDepartment of Library and Information Science, University of Barcelona, Melcior de\nPalau, 140, 08014 Barcelona (Spain)\n2\n\nannavillarroya@ub.edu\nDepartment of Public Economy, Political Economy and Spanish Economy, University of\nBarcelona, Melcior de Palau, 140, 08014 Barcelona (Spain)\n3\n\nmbarrios@ub.edu\nDepartment of Methodology of Behavioral Sciences, University of Barcelona, Melcior de\nPalau, 140, 08014 Barcelona (Spain)\nIntroduction\nThe issues of gender mainstreaming, the\nrole of gender in academic appointments\nand evaluation, and the participation of\nwomen in science as indicators of social\nand economic progress have attracted\nsubstantial attention from a broad array\nof researchers and national and\ninternational organisms (including, the\nWomen in Industrial Research, 2003;\nthe ENWISE (Enlarge Women in\nScience to East) expert group, 2004; She\nFigures, 2012; the WIRDEM (Women\nin Research Decision Making) expert\ngroup, 2006, and the EU-funded\ngenSET project, 2010, among others).\nHowever, despite some progress, gender\ninequalities in science persist (EC,\n2013).\nA number of studies have sought to\nexplain these discrepancies in various\nareas of science and academia by\nincorporating family-related factors,\npersonal and institutional (structural)\nfactors,\nprofessional\nfactors,\ndemographic and individual issues and\nfactors related to disciplinary fields\n(Ceci and Williams, 2011; Fox,\n1922\n\nFonseca, &amp; Bao, 2011; Hunter &amp; Leahy,\n2010;\nLarivière,\nVignola-Gagné,\nVilleneuve, Gélinas, &amp; Gingras, 2011;\nSax, Hagedorn, Arredondo, &amp; Dicrisi\nIII, 2002).\nHowever, these studies fail to provide\nthe\nkind\nof\nsystematic\nand\ncomprehensive overview of factors\nrelated to gender differences that might\nhelp guide future research and practices\nin the field. The aim of this study,\ntherefore, is to undertake an analysis of\nthe related literature using co-word\nanalysis. Such an analysis helps\nvisualize the division of a field into\nseveral subfields and the relationships\nthat exist between them by providing\ninsights into the evolution of the main\ntopics discussed in the field over the\nyears. Using co-word analysis, the\npresent study aims to determine the\nstructure of the knowledge network on\nthe basis of the co-occurrence of terms,\nin order to describe the current state of\nthe literature examining the factors that\ninfluence gender differences in science.\n\nMethod\nThe data set consists of a corpus of 651\narticles and reviews, published between\n1991 and 2012, dealing with factors\nrelated to gender differences in science.\nThe data were extracted from the ISI\nWeb of Science in February 2013, using\na search that combined the principal\nterms related to the subject.\nTo carry out the co-word analysis, four\nsequential\nsteps\nwere\nfollowed:\nextraction and standardization of the\nkeywords, construction of the cooccurrence matrix, clustering, and visual\npresentation of keyword groups. Authorprovided keywords were extracted from\npapers. Keywords plus was used in\nthose instances when no authorprovided keywords were available.\nKeywords\nand\nphrases\nwere\nstandardized manually and finally a total\nof 170 keywords were selected. In order\nto monitor the development of the\nscientific field, the results were divided\ninto three periods, i.e. 1991-2001\n(n=164 papers, 25.19%), 2002-2007\n(n=147 papers, 22.58%), and 2008-2012\n(n=340 papers, 52.23%).\nThe word-document occurrence matrix\nfor each period was automatically built\nvia SPSS v. 20. The resulting matrices\nwere then exported to Ucinet v.6. In\nUcinet the word-document matrix was\ntransformed into a word co-occurrence\nmatrix; the similarities between items\nwere also calculated using the Jaccard\nsimilarity index. Hierarchical clustering\nanalysis was then conducted via SPSS\nv.20 using Ward’s method and the\nsquared Euclidean distance was applied\nas the distance measure.\nBased on the dendrogram generated by\nthe clustering algorithm, clusters of\nkeywords were derived. The clusters\nwere then transformed into networks in\nUcinet v.6. Finally, after calculating the\ndensity and centrality of each cluster,\nthe keyword networks were displayed in\n\na strategic diagram using Excel. It\nshould be borne in mind that, in each\nstrategic diagram, the volume of the\nspheres is proportional to the number of\ndocuments corresponding to each\ncluster.\nResults\nBased on the hierarchical clustering\nanalysis, four clusters of keywords were\nidentified for the first period (19912001), ten clusters for the second period\n(2002-2007), and finally, sixteen for the\nthird period (2008-2012). A strategic\ndiagram depicting the relative positions\nof each cluster was produced for each\nperiod to facilitate interpretation\n(Figures 1, 2 and 3).\n\nFigure 1. Strategic diagram. Period\n1991-2001\n\nFigure 2. Strategic diagram. Period\n2002-2007\n\nFive motor-themes appeared in the\nupper-right quadrant of the diagrams on\nthe basis of their high density and\ncentrality. The motor-themes were:\n\n1923\n\n“Gender inequalities in labor markets\nand universities” (cluster 1) in the first\nperiod,\n“Career\nsatisfaction\nin\nmedicine” (cluster 1) and “Academic\ncareer in sociology” (cluster 9) in the\nsecond period and finally “Progression\nin academic medicine” (cluster 9) and\n“Staff composition and climate in\nacademia” in the third period (cluster\n11).\nOnly two themes in the diagrams were\npresent in all three periods: “Mobility of\nwomen academics”, and “Institutional\ndiscrimination”. Some themes emerged\nand were maintained in the periods that\nfollowed: “Work-life balance in\nacademia”,\n“Racial inequality in\nhigher education”, and “Progression in\nacademic medicine” appeared in both\nsecond and third periods. “Promotion\ndifferences” appeared in both first and\nsecond periods.\n\nFigure 3. Strategic diagram. Period\n2008-2012\n\nConclusion\nThe present results provide interesting\ninsights into the evolution of the\nliterature examining factors related to\ngender differences in science. An\noverall analysis of the three periods\nclearly revealed an increase in the\nnumber of themes in the most recent\nperiod (2008-2012) and a variety of\nmotor-themes depending on the period\nstudied.\n\n1924\n\nReferences\nCeci, S. J.; Williams, W. M. (2011).\nUnderstanding current causes of\nwomen’s underrepresentation in\nscience. PNAS 108, 8, 3157-3162.\nhttp://www.pnas.org/cgi/doi/10.1073\n/pnas.1014871108\nEnwise. (2003). EUR 20955 — Waste\nof talents: turning private struggles\ninto a public issue. Women and\nScience in the Enwise countries.\nLuxembourg: Office for Official\nPublications of the European\nCommunities.\nEuropean Commission. DirectorateGeneral for Research and Innovation\n(2013). She Figures. Gender in\nResearch and Innovation. Brussels:\nDirectorate-General for Research\nand Innovation.\nFox, M. F., Fonseca, C., Bao, J. (2011).\nWork and family conflict in\nacademic science: Patterns and\npredictors among women and men in\nresearch universities. Social Studies\nof Science, 41(5), 715–735.\nHunter, L. A., &amp; Leahey, E. (2010).\nParenting and research productivity:\nNew evidence and methods. Social\nStudies of Science, 40(3), 433–451.\nLarivière, V., Vignola-Gagné, E.,\nVilleneuve, C., Gélinas, P., &amp;\nGingras, Y. (2011). Sex differences\nin research funding, productivity and\nimpact: an analysis of Québec\nuniversity professors.\nScientometrics, 87(3), 483-498.\nSax, L. J., Hagedorn, L. S., Arredondo,\nM., &amp; Dicrisi III, F. A. (2002).\nFaculty Research Productivity:\nExploring the Role of Gender and\nFamily-related Factors. Research in\nHigher Education, 43(4), 423-46.\nWIR. (2003). Women in Industrial\nResearch: a Wake Up Call for\nEuropean Industry. Brussels:\nEuropean Commission.\n\nTHE CROSSCHECK PLAGIARISM SYSTEM: A\nBRIEF STUDY FOR SIMILARITY\nEdilson Damasio1\n1\n\nedamasio@uem.br\nFederal University of Rio de Janeiro-UFRJ-IBICT. Universidade Estadual de Maringá.\nEduem. Av. Colombo, 5790 bloco 40, CEP 87020-900, Maringá, Paraná (Brazil). Rio de\nJaneiro-IBICT.\nIntroduction\nThe plagiarism identification in articles\nsubmitted for publication in scientific\njournals has been configured as an\nessential requirement for the decision of\nthe scientific editors.\nAmong the different systems of\nidentification\nof\nplagiarism,\nthe\nCrossCheck has been used by leading\nscientific publishers in the world,\nbecause it allows them to identify\nsimilar documents on the Internet or in\nthe others journals (fully or partially)\nthose indexed in its a database. Editors\nof scientific journals countries, unaware\nor no use CrossCheck, is already used\nby reputable scientific journals and\npublishers.\nFrom this premise, this paper aims to\nshow the results of a survey 2012\nCrossCheck Survey, used by CrossRef\nto feedback to the scientific journals\neditors and publishers, about the use the\nSIMILARITY in a new submissions.\nThe objective of the article is compared\nthe results from the journals publish in\nthe scientific community, to the\npercentages of plagiarism identification\nin the CrossCheck Survey.\nWas identified four journals with\npublished the results of similarity\nreports. The Web Of Science and\nScopus it&#x27;s database to results of\njournals with articles with CrossCheck\npercentage of plagiarism articles.\n\nThe low index of journals that publish\nyour similarity results, it’s related to the\nuse of the tools by the editors. The\nsimilarity it’s a support do decision\nmaking by identifying plagiarism and\nscientific misconduct.\nThe four journals, already using\nCrossCheck, to identify the use of the\nsystem is essential for the serial\npublication with identification of\nplagiarism policies defined.\nThe title of the journals will not be\nidentified, and verification period is the\nyear 2004 to 2012. The results will be\ndistributed in journals A B C D.\nCrossCheck\nThe CrossCheck is a system developed\nin cooperative form to the members,\npublishers, journals and your contents.\nAll affiliates must enable your will be\npart of the database.\nAimed mainly to the demand of\nplagiarism and misconduct identified by\neditors of scientific journals. The major\npublishers of the world participate in the\ndatabase in order to have a most\npossible content to area of knowledge.\nThe system is also offered to members\nof CrossRef, which should identify the\nuse of the DOI (Digital Object\nIdentifier) redirection to textual content\npublished.\nPlagiarism and Scientific Journals\nThe plagiarism utilization and ethical\naspects of scientific communication\n\n1925\n\nhave always known by the editor,\nresearchers, teachers and students, and\ndifficult to identify. All these actors are\npossible and require users to identify\nplagiarism system, to assist them in\ncomparing similarity (Fig. 1).\nThe Elsevier director of services\nCatriona Fennell cited by Butler (2010)\nsay with, “Establishing plagiarism\nrequires ‘expert interpretation’ of both\narticles says Fennell. The software gives\nan estimate of the percentage similarity\nbetween a submitted article and ones\nthat have already been published, and\nhighlights text they have in common.\nBut similar articles are sometimes false\npositives, and some incidents of\nplagiarism are more serious than\nothers”.\nSimilarity\nThe scientific literature it’s universal\nand constant increased. Identify the\ncontent for the publication of an article\nand accepted by publishers, researchers,\nall actors and us scientific production.\nScientific journals that can’t error and\npublish similar texts, results, and\nindirectly take plagiarism of texts,\nshowing errata and retractions.\nAn author who wants to identify if\nothers are quoting their texts, this\nmapping is very important to work on\ntheir lines of research and compare their\nscientific production. Identification\nsimilarity systems are essential in\nacademic area.\nThe\nsimilarity\nis\nstudied\nin\nscientometrics and informetrics, the\nwords as objects in databases and\nrecovery variables and measure to the\nrelevance and percentages (number of\ncharacters or words) similar or with\nminor changes (Bornmann et al., 2008).\n\nFigure 1. Scientist and words shake. Font:\nNature comment (2012).\n\nResults\nIn table 1 the results of brief research\nwith four journals in Web Of Science\nand Scopus. This percentage it’s\npublished by the editors. The scientific\nproduction\nabout\nsimilarity and\nCrossCheck users, it’s very small.\nTable 1. Journals and percentage of\nsimilarity with CrossCheck. Font: Web Of\nScience / Scopus\nJournal\nA\nB\nC\nD\n\nTotal n\n216\n56\nna\nna\n\nN\n21\n13\nna\nna\n\n%\n10\n23\n10\n31\n\nCrossCheck Survey Results 2012\nIt’s presented a brief and principal dates\nto the objective the poster. This study\nit’s available and identifies various\npossibilities of the results comparations.\n\nFigure 2. Percentages. Font: CrossCheck\nSurvey (2012)\n1926\n\nCompared with the group of four\njournals the average result of similarity\nwas 32%, so this result is not definitive\npercentage, due mainly to a percentage\nof publishers not characterize that is 10\nor 99% similarity was a plagiarism.\nThus the similarity measure is one to be\nlook at by the publisher and your\nobjectives, focus, area, but the decision\ndepends on textual content which will\nbe similar to that seen by the human eye.\n\nguarantees. The service is offered a low\ncost, a small annuity and checking\ndocuments at a cost of $0,75 US dollars.\nThe system is a useful tool in numerous\nprocesses in institutions, such as\nchecking others documents, theses,\ndissertations, projects, monographs and\nbooks have other costs. The content of\ndatabase is that articles and collections\nto the all journals, and the journal\neditors should use it mainly for\nverification of newly submitted articles\nto journals.\nAcknowledgments\nAcknowledgments to State University of\nMaringa, to Federal University of Rio de\nJaneiro to possibility of research in this\narea (Information Sciences) and to\nCrossRef for the data numbers.\n\nFigure 3. Subject areas. Font: CrossCheck\nSurvey (2012).\n\nFigure 4. CrossCheck similarity report\nresults with percentage and link to the\nresults. Font: Damasio (2012).\n\nConclusion\nThe CrossCheck it’s utilized by Elsevier\nand Nature and others best publishers, is\na large partners to scientific databases.\nIn actual numbers is utilized by 300\npublishers, with 70.000 journals titles,\n40 million of indexed contents, and\n30.000 documents checked monthly.\nThere are methods that content posted\non this system has security and legal\n\nReferences\nBornmann, L., Mutz, R., Neuhaus, C.&amp;\nHans-Dieter, D. (2008). Citation\ncounts for research evaluation:\nstandards of good practice for\nanalyzing bibliometric data and\npresenting and interpreting results.\nEthics in Science and Environmental\nPolitics, 8, 93-102. doi:\n10.3354/esep00084\nButler, D. (2010). Journals step up\nplagiarism policing. Nature, 466,\n167.\nCrossCheck (2012). November 2012\nCrossCheck Survey Results. Oxford:\nCrossRef.\nDamasio, E. (2012). CrossCheck:\nidentificação de plágio por\nsimilaridade. Encontro Brasileiro de\nBibliometria e Cientometria, 3.\nNature comment (2012). How to stop\nplagiarism. Nature, 481, 7379, 2123.\nZhang, Y. (2010). Chinese journal finds\n31% of submissions plagiarized.\nNature, 467. doi: 10.1038/467153d\n\n1927\n\nCUMULATIVE CAPABILITIES IN COLOMBIAN\nUNIVERSITIES: AN EVALUATION USING\nSCIENTIFIC PRODUCTIVITY\nSandra Carolina Rivera-Torres1, Marcela Galvis-Restrepo2 and Jenny CárdenasOsorio3\n1\n\ncrivera@ocyt.org.co;\nHuman Resources Indicators of Sciences and Technology, Observatorio Colombiano de\nCiencia y Tecnología, Carrera 15 No 37-59, Bogotá, Colombia; Universidad Nacional de\nColombia\n2\n\nmgalvis@ocyt.org.co; 3jcardenas@ocyt.org.co\nHuman Resources Indicators of Sciences and Technology, Observatorio Colombiano de\nCiencia y Tecnología, Carrera 15 No 37-59, Bogotá, Colombia\nIntroduction\nResearch was institutionalized in\nColombian universities around fifty\nyears ago with the creation of\ngovernment institutions to stimulate this\nactivity, and the support of loans from\nthe Inter-American Development Bank\n–IDB- that were used to start building\nscientific and technological capabilities\n(Bucheli et al., 2012; CINDA, 2012;\nOECD &amp; The World Bank, 2013). The\ninstitutional development of the science,\ntechnology and innovation system, gives\npriority to research groups as\norganizational units for research; a\nstructure\nlargely\npromoted\nby\nColombian Administrative Department\nof Science, Technology and Innovation\n–Colciencias-, the government body in\ncharge of measuring research group’s\nscientific capabilities and assigning\nresources\naccording\nto\ntheir\nperformance (Villaveces &amp; Forero,\n2007; OCyT, 2012).\nResearch groups as organizational units\nwere adopted by universities and\nresearch institutions as well. Some\nuniversities have even developed their\n1928\n\nown financing schemes intended to\nstimulate their growth and sustainability\n(Colciencias, 2008; OCyT, 2012). In\n2011-2012, the Colombian Observatory\nof Science and Technology –OCyTdeveloped a methodology to evaluate\nthe research groups of one of\nColombia’s leading universities, which\ncan be used for tracking and impact\nevaluation of R&amp;D policy.\nAs a result, in this work we focus on\nscientific capabilities of research groups\nmeasured by their researchers’ scientific\nproduction, as defined by Colciencias’\nmodel. In the previous evaluation\n(OCyT, 2012), we found evidence that\nthe production is highly concentrated in\na few researchers following Zipf’s\npower law in an eight year time frame\n(Sutter &amp; Kochner, 2001). This\napproach allows for a representation\nresearcher’s capabilities, taking into\naccount the accumulated knowledge in\nthe publication trajectory of the\npopulation.\n\nMethodology\nWe looked at publications registered in\nScienTi179 database associated to\nresearchers working in research groups\nin the incumbent university; afterwards,\nwe applied concurrency algorithms to\nmatch those papers, with publications in\nISI- Thomson Reuters Web of Science\ndatabase.\nAdditionally, since the knowledge\ncodified in publications is an\nevolutionary variable that can be\naccumulates over time; in this analysis\nwe use cumulative distributions in order\nto determine the future trend of\nscientific publications as means to\nunderstand the individual’s capabilities\n(Bozeman &amp; Corley, 2004; Lepori &amp;\nBarré, 2008).\n\nwhere nc is the arithmetic half of the\npopulation and γ is the half-width. As\nshown in Figure 1, the distribution is\nuseful to evaluate the behaviour of the\nproduction of researchers each year and\nby accumulating it; we can observe the\ndegree of concentration of the\nknowledge generated.\nFirst, we accumulate the production of\neach researcher in a given scientific\nfield in 2002-2008. In Figure 2 we show\nan example for a population of 167\nresearchers located in the horizontal axis\nin the field of medical sciences of the\nUniversidad de Antioquia (OCyT,\n2012); production is represented in the\nvertical axis.\n\nFigure 2. Accumulated Scientific\nProduction in 2000-2008, Researchers in\nMedical and Health Sciences\n\nFigure 1. Capabilities Measurement Using\nScientific Production\n\nAccording to Abe &amp; Rajagopal (2001)\nthe state of the scientific production of a\ngroup of researchers fits the CauchyLorentz distribution. This means that the\ndifference in productivity p, between the\nmembers (n) of the research group can\nbe modelled with a Lorentz distribution,\ngiven by the equation:\n( )\n(1)\n(\n\n179\n\nThen we organize the results locating\nthe most productive researcher in the\ncentre; the second and third most\nproductive are located to the right and\nleft and so on. Figure 3 shows the data\nin Figure 2 organized in a centralized\nway. These data are shown as an\nexample for a small population of\nresearchers. In the case of Colombian\nuniversities, this tool is useful to\ndescribe the trajectory of the research\ngroups.\n\n)\n\nThe Colombian platform where research groups\nand researchers register their information in order\nto get recognition and resources from Colciencias;\nit contains information on researcher’s curriculum\nvitae (CvLAC) and research groups (GrupLAC)\n\nFigure 3. Centralized Accumulated\nScientific Production in 2000-2008,\nResearchers in Medical and Health\nSciences\n1929\n\nAs shown in Figure 4, production is\nhighly concentrated on a few researchers\nwho have the highest share of the\nscientific production. In this graph we\nfitted a Lorentz distribution to the\ncentralized data.\n\nFigure 4. Lorentz Fitting of the\nCentralized Distribution\n\nUsing Lorentz distributions, the effect of\na researcher in the population can be\ndefined as its percentage contribution\ngiven by the relationship:\n( )\n( )\n(2)\nUsually the centre value is near N/2, so\nit would be enough to find the number γ\n(the half width) to determine the\ndistribution of the production in the\npopulation. A property of the Lorentz\ndistribution is:\n( )\n(3)\n∫\nSo the range [n_c-γ,n_c+γ] (with size\n2γ) contains half of the population. With\nthis result we can define the percentage\nof the population concentrating 50% of\nthe production as:\n(4)\nThis result can be used as a measure for\nthe concentration of production in the\npopulation\nof\nresearchers,\nand\neventually\nfor\nresearch\ngroups&#x27;\ncomparisons.\n\n1930\n\nConclusions\nThe methodology presented here is\nuseful for evaluating variables reflecting\nthe knowledge accumulation observed\nin R&amp;D activities. An additional\napplication consists in mapping the\ntrajectory of different groups like\nindividuals,\nresearch\ngroups\nor\ninstitutions; additionally it is useful to\nobserve the degree of development\nreached by each individual in the S&amp;T\nsystem and use it to target specific\npopulations of highly achieving\nindividuals.\nSpecifically\nin\nthe\nColombian context, the methodology\nhelps to measure capacity while it is\nunderstood that individuals have an\nevolutionary trajectory, and they shape a\ngrowing and heterogeneous community.\nReferences\nAbe, S., &amp; Rajagopal, A. (2001).\nInformation theoretic approach to\nstatistical properties of multivariate\nCauchy-Lorentz distributions.\nJournal of Physics A: Mathematical\nand General, 34(42), 8727.\nBozeman, B., &amp; Corley, E. (2004).\nScientists’ collaboration strategies:\nimplications for scientific and\ntechnical human capital. Research\nPolicy, 33(4), 599-616.\nBucheli, V., Díaz, A., Calderón, J. P.,\nLemoine, P., Valdivia, J. A.,\nVillaveces, J. L., et al. (2012).\nGrowth of scientific production in\nColombian universities: an\nintellectual capital-based approach.\nScientometrics, 91(2), 369-382.\nCINDA. (2010). Educación superior en\nIberoamérica Informe 2010.\nLepori, B., Barré, R., &amp; Filliatreau, G.\n(2008). New perspectives and\nchallenges for the design and\nproduction of S\\&amp;T indicators.\nResearch Evaluation, 17(1), 33-44.\nOCyT. (2012). Indicadores de Ciencia y\nTecnología Colombia 2012.\n\nOECD, &amp; Bank, T. W. (2012). Reviews\nof National Policies for Education:\nTertiary Education in Colombia\n2012. OECD Publishing.\n\nSutter, M., &amp; Kochner, M. G. (2001).\nPower laws of research output.\nEvidence for journals of\neconomics. Scientometrics, 51(2),\n405-414.\n\n1931\n\nA DESCRIPTIVE STUDY OF INACCURACY IN\nARTICLE TITLES ON BIBLIOMETRICS\nPUBLISHED IN BIOMEDICAL JOURNALS\nRafael Aleixandre-Benavent1, Vicent Montalt2, Juan Carlos Valderrama-Zurian3,\nMiguel Castellano-Gómez4\n1\n\naleixand@uv.es\nIHMC López Piñero, CSIC-Plaza Cisneros 4, 46003-Valencia (Spain)\n2\n\nmontalt@trad.uji.es\nDepartament de Traducció i Comunicació. Universitat Jaume I.Campus de Riu Sec. 12071\nCastelló (Spain)\n3\n\njuan.valderrama@uv.es.\nInstituto de Documentación y Tecnologías de la Información. Universidad Católica de\nValencia. C/ Quevedo, 2. 46001-Valencia (Spain)\n4\n\ncastellano_mig@gva.es\nHospital Aranu de Vilanova. Conselleria de Sanitat. Genralitat Valenciana (Spain)\nIntroduction\nAlthough it is a very small part of the\nresearch paper, the title plays an\nimportant role and certain pragmatic\nfunctions as the first point of contact\nbetween writer and potential reader: to\nprovide a general and brief description\nof the content of the article, to attract\nattention evoking interest in the reader,\nto inform, and sometime, to startle\n(Haggan, 2004). Readers generally\ndecide whether to read an article or not\nby seeing the title first. For this reason,\ntitles in science mirror a set of requisites\nthat are crucial to the construction,\ncommunication, and progress of new\nknowledge (Cheng, Kuo and Kuo, 2012;\nSoler, 2007). Many titles do not comply\nwith the standards established in style\nmanual on scientific writing by using\nsensationalist\ndevices\nsuch\nas\ninterrogation marks, exclamation marks,\nmetaphors, double meanings and vague\nexpressions in order to catch the\n1932\n\nreaders’ attention. The purpose of this\narticle is to analyse the lack of accuracy\nof titles in articles on bibliometrics\npublished in biomedical journals.\nMethods\nWe analysed a corpus of 1.100 titles\nincluded in PubMed database between\n2009 and 2011 and retrieved under the\nmajor MeSH topic “bibliometrics”.\nDifferent types of inaccuracy were\nidentified and classified using an\nexplicit typology developed for this\nparticular study.\nResults\n24,7% of the titles contain some type of\ninaccuracy. Editorial titles show a\nhigher percentage of inaccuracy\noccurrences (11.71%) than original\narticles (9.28%) and letters (3.7%). The\nmost frequent type of inaccuracy is\nincluding a question in the title, which\namounts for 32.12% of the papers (table\n\n1). The next category down is vague and\nimprecise expressions (18.98%) (table\n2), acronyms (14.96%) and double\nmeanings (13.88%) (table 3). Some\ntitles also use amusing titles, biblical\nsentences and movie titles (table 4).\nTable 1. Examples of topic-question titles\nH-index-a good measure of research\nactivity?\n(Tidsskr Nor Laegefor.2011;131:24946).\nWhat are we reading now? An update on\nthe papers published in the orthodontic\nliterature (1999-2008).\nJ Orthod. 2011;38:196-207.\nHow to judge a book by its cover? How\nuseful are bibliometric indices for the\nevaluation of &quot;scientific quality&quot; or\n&quot;scientific productivity&quot;?\nAnn Anat. 2011;193:191-6.\nRanking hepatologists: which Hirsch&#x27;s hindex to prevent the &quot;e-crise de foi-e&quot;?\nClin Res Hepatol Gastroenterol. 2011;\n35: 375-86.\nWhat does the Journal&#x27;s impact factor mean\nto you?\nJ Am Diet Assoc. 2011;111:41-4.\nTable 2. Examples of vague expressions\nImpact and scholarship.\nJ Nurs Scholarsh. 2010 Sep 1;42(3):233.\nJournal Impact Factor: it will go away soon.\nClin Chem Lab Med. 2009;47(11):13178.\nSpreading the word.\nNurs Stand. 2009;23:22-3.\nIdeas with impact.\nNurs Inq. 2011;18:277.\nA time of change.\nJ Hum Nutr Diet. 2011;24:1-2.\n\nDiscussion\nWriting the titles to scientific articles is\na challenging exercise that demands the\nuse of various skills. Academic writing\ntextbooks and style manuals have\nproposed the elements of good research\narticles titles (Cheng, Kuo and Kuo,\n\n2012; Swales and Feak, 2004): (1) The\ntitle should indicate the topic of the\nstudy. (2) The title should indicate the\nTable 3. Examples of double meanings\nexpressions\nWatching the river flow.\n(Rev Port Pneumol. 2011;17:197-8).\nImpact factor: vitamin or poison?\n(Sao Paulo Med J. 2010;128:185-6).\nStaying on the cutting edge.\n(Augment Altern Comm. 2010; 26:2235).\nThe race for the impact factor.\n(J Sleep Res. 2009;18:283-4).\nThe road is made by walking.\n(Gac Sanit. 2010;24:1-4).\nThe impact of the impact factor.\n(Can J Urol. 2009;16:4445-6).\nThe first and the last will become the best\n(Orv Hetil. 2010;151:1236-7).\nImpact factor: does it have an impact?\n(J Ayub Med Coll Abbot. 2009; 21:\n180).\nTable 4. Examples of biblical sentences\nand movie titles\nBut many that are the first shall be last, and\nthe last shall be first.\n(FASEB J. 2009;23:1283).\nImpact factor wars: Episode V-the empire\nstrikes back.\n(J Child Neurol. 2009;24:260-2).\nLooking back to the future.\n(Worldviews Evid Based Nurs. 2009;\n6:1-2).\nThe impact factor for evaluating scientists:\nthe good, the bad and the ugly.\n(Clin Chem Lab Med. 2009;47:1585-6).\n\nscope of the study. (3) The title should\nbe self-explanatory to readers in the\nchosen area”. Day and Gastel (2006)\ndefined a good title as “the fewest\npossible words that adequately describe\nthe contents of the paper”. The journals\ndo not often provide rules for writing the\ntitles in its guidelines for manuscript\nsubmission. Moreover, the guidelines\nknown as the Uniform Requirements for\n\n1933\n\nManuscripts submitted to Biomedical\nJournals, or Vancouver style, also\nprovide limited information about how\nthe tiles of papers are to be written.\nTopic-question titles can stimulate\nreader’s interests by the use of a\nquestion. The question title construction\nseems to allow authors the possibility of\nposing questions on such object as an\nindication that, in spite of the current\nstate-of-the-art about it, there are, still,\nqueries in need of reply, interpretation,\nand conclusion (Soler, 2007).\nSince the use of a metaphor can greatly\narouse\nreader’s\ncuriosity,\nthe\njuxtaposition of a metaphor or a double\nmeanings sentence with the real research\ntopic in a compound title seems a clever\nconstruction that can attract readers to\nthink about the association between\nthem. For instance, when readers read\n“The race for the impact factor”, they\nmay be puzzled, but attracted by the\nmetaphorical expression of “the race”,\nas they read the other part of the title,\n“the impact factor”, which reveals the\nresearch topic, they realize what is\nimplied in the metaphor. The use of this\nsort of construction can often make a\nstrong impression on readers.\nSimilar to metaphor-topic titles, the use\nof humor in scientific titles makes sense\nif we take the point of view of the title\nas a persuasion tool for attracting\nreaders, but in general, decrease the\ntendency to read an article and treat its\ncontents seriously (Hartley, 2007).\nConclusions\nIn order to make scientific articles more\neffective, most titles of scientific articles\n\n1934\n\non bibliometric topics use a variety of\ndevices, even if they do not comply with\nthe conventions of scientific writing. We\nrecommend that authors write more\ndescriptive titles that accurately reflect\nthe content of the articles so that readers\ncan understand them better and retrieve\nthem\nbetter\nfrom\nbibliographic\ndatabases. It would be useful in future\nresearch to ask authors about their\npractices in choosing titles when writing\npapers singly or with others.\nReferences\nCheng SW, Kuo CW, Kuo CH.\nResearch article titles in applied\nlinguistics. Journal of Academic\nLanguage &amp; Learning Vol. 6, No. 1,\n2012, A1-A14.\nDay, R. A., Gastel B (2006). How to\nwrite and publish a scientific paper.\nWestport CT: Greenwood Press.\nHaggan, M. (2004). Research paper\ntitles in literature, linguistics and\nscience: Dimensions of attraction.\nJournal of Pragmatics, 36(2), 293317.\nHartley J. There&#x27;s more to the title than\nmeets the eye: Exploring the\npossibilities. Journal of Technical\nWriting &amp; Communication. 2007;\n37:95-101.\nSoler, V. (2007). Writing titles in\nscience: An exploratory study.\nEnglish for Specific Purposes, 26(1),\n90-102.\nSwales, J. M., &amp; Feak, C. B. (1994).\nAcademic writing for graduate\nstudents: Essential tasks and skills\n(1st ed.). Ann Arbor, MI: Univ.\nMichigan Press.\n\nDIFFUSION OF BRAZILIAN STATISTIC\nINFORMATION\nSônia Regina Zanotto1, Samile Andréa de Souza Vanz2 and Ida Regina Chittó\nStumpf3\n1\n\nzanotto.sonia@gmail.com\nIBGE-RS, Av. Augusto de Carvalho, 1205, Cep 90010-390 – Porto Alegre, RS (Brazil)\n2\n\nsamilevanz@terra.com.br\nFederal University of Rio Grande do Sul, Information Science Department, PostGraduation Program on Communication and Information, Rua Ramiro Barcelos 2705 sala\n214, Cep 90035-007 – Porto Alegre, RS (Brazil)\n3\n\nirstumpf@ufrgs.br\nFederal University of Rio Grande do Sul, Information Science Department, PostGraduation Program on Communication and Information, Rua Ramiro Barcelos 2705 sala\n214, Cep 90035-007 – Porto Alegre, RS (Brazil)\nIntroduction\nThis poster brings analysis on citations\nreceived by IBGE – Brazilian Institute\nof Geography and Statistics –\npublications from the perspective of the\ndiffusion factor calculation theory and\nmethodology. Considering that citations\nrepresent a way to measure how\nscientific ideas spread, we have sought\nground in the diffusion factor theory\nproposed by Rousseau, Liu and Ye\n(2012) to present a practical application.\nIBGE has been the official Brazilian\nagency in charge of public statistic\ninformation since 1938; among other\ndocuments it publishes the Census and\nthe National Household Sample Survey\n(PNAD). The citations received by\ndocuments produced by the Institute are\nspread among dozens of scientific\njournals,\npublished\nin\ndifferent\ncontinents and in several languages.\nThis fact in itself indicates that the\npublications are properly disseminated\n(Zanotto, 2011; Zanotto, Vanz &amp;\nStumpf, 2011).\n\nBibliometric indicators are necessary in\nbringing new perspective for the\nunderstanding\nof\nscientific\ncommunication (Frandsen, Rousseau &amp;\nRowlands, 2006). There is consensus\nthat they must be cautiously analyzed\nand interpreted within a context, since\nthey are incomplete as measurement and\nthey generally present isolated results.\nThe impact measurement of citations\nthat has been applied does not take into\nconsideration who or what citing\nsources are or how the citations are\ndispersed, yet in a certain way the\ngeographical reach of citing sources\nrepresents the extension of the\ngeographical impact of the information.\n(Rowlands, 2002). We understand that it\nis necessary to show not only the\nimpact, but also the dimension in which\ninformation is received by the\ncommunity.\nJournal Diffusion Factors have been\nintroduced in order to measure the\ninfluence on scientific research and the\ndiffusion of journals, in an attempt to\ncomplement\nthe\nImpact\nFactor\n(Rowlands,\n2002).\nSince\nits\n1935\n\nintroduction, several researchers have\nbeen developing a measurement called\ndiffusion factor by means of different\ndata collection techniques (Frandsen,\n2004). In Brazil, Rummler (2006)\npresented the Index of Segmental\nDispersion, an indicator that can be\napplied to a tittle, an author, a journal or\na field of knowledge, and considered the\npossibility of measuring the dimension\nof the extension of the impact of a single\nanalysis unit, as it is applied in the\ncitation analysis. More recently,\nRousseau, Liu &amp; Ye (2012) presented\nthe concept that scientific ideas flow\nthrough a layered system and this is how\ndiffusion must be measured. Based on\nthe idea that citations represent the\ndiffusion of knowledge and that the\nstandard Gini coefficient reflects the\nmeasure of such diffusion, the\nRousseau,\nLiu\n&amp;\nYe\n(2012)\nmethodology was applied to citations on\nIBGE publications in the period 20012010 with the purpose of calculating its\ndiffusion factor.\nMethodology\nIBGE scientific output citations were\nidentified in the Web of Science. In the\nCited Author field we used a search key\nmade up of the group of different variant\nforms of the abbreviation and the\ncomplete name of the Institution in\nEnglish and Portuguese for the period\n2001-2010, without any restrictions on\ntype of document to be retrieved.\nCleaning and standardizing procedures\nfor the authors’ names and respective\naffiliated institutions were needed. Data\nwere analyzed with the BibExcel\nsoftware and Microsoft Excel 2007\nprogram for electronic spreadsheets. We\nisolated information on authorship from\nthe AU field and they were accounted\nfor year by year, along with respective\ninformation on institution and country\ncontained in the C1 field of address\n1936\n\nfrom the group of data retrieved. The\ncount and fractioning followed the\nRousseau,\nLiu\n&amp;\nYe\n(2012)\nmethodology.\nResults\nWe identified 3,158 documents citing\nIBGE scientific output in the period\nbetween 2001-2010. When analyzing\nthe authors of these documents, we\nfound 10,707 names, leading to a mean\nof 1.29 citations per author and\nfrequency that ranged from 1 to 19\ncitations of IBGE publications per\nauthor in the period. The citing authors\nwere affiliated to 1,272 different\ninstitutions. Among\nthe 7,587\noccurrences of countries in the\ninstitutional link of the authors, 6,168\n(81.3%) of them referred to Brazil, 9%\nto the United States of America, 2% to\nEngland and the other occurrences were\nspread among 49 different countries.\nThe distribution per continent is the\nfollowing: South America (82.35%);\nNorth America (9.71%); Europe\n(6.93%); and Central America, Asia,\nOceania, Africa and Middle East\n(approximately 1% of citing authors).\n\nFigure 1 – Geographical distribution of\ncountries to which authors who cited\nIBGE scientific output were affiliated to in\nthe period between 2001-2010\n\nOut of the 1,272 institutions to which\nciting authors were affiliated, 748\n(58.80%) were Brazilian or based in\nBrazil, while 518 (40.72%) were\nforeign. Institutions with an educational\nfocus lead (47.96%), followed by P&amp;D\n\ninstitutions (22.88%) and the others\nwere from the public sector, such as\nState Secretaries, hospitals, agricultural\nbusiness, livestock and service, besides\nindustry, among others.\nTable 1 – Gini index applied to citing\nauthors, institutions and countries 20012010\nYear\n\nNumber\nof\nCiting\nArticles\n(CA)\n\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n\n106\n110\n123\n177\n184\n222\n447\n654\n673\n462\n\nFractio Fraction Fraction\nn Sum\nSum\nSum\nCiting\nCiting\nCiting\nAuthor Institution Countri\ns\ns\nes\n(AU)\n(UNI)\n(CO)\n105.49\n70.77\n8.50\n109.24\n70.93\n8.42\n121.76\n76.11\n13.57\n176.00\n97.33\n10.83\n182.25\n91.27\n10.33\n221.22\n122.51\n18.15\n444.96\n185.47\n19.08\n647.92\n243.75\n21.42\n671.42\n264.99\n19.90\n460.72\n254.26\n22.33\n\nSource: Research data\n\nGe\n\n0.89\n0.89\n0.90\n0.89\n0.89\n0.89\n0.89\n0.89\n0.88\n0.89\n\nWith the purpose of proving that the\ncitations reflect satisfactory diffusion of\nthe knowledge produced by IBGE we\napplied the diffusion factors analysis\nproposed by Rousseau, Liu &amp; Ye\n(2012). After applying Ge formula, we\nobtained quite satisfactory results, since\nthe Gini index remained between 0.88 in\n2009 and 0.90 in 2003, indicating a high\ndispersion factor, that is to say, there is a\ngreat number of authors, institutions and\ndifferent countries that cited IBGE\npublications in the period, as can be\nseen in table 1. Although the absolute\nnumber of citations varies increasingly\nin the period, the Ge index remains in\nthe same level in the decade under\nstudy.\nConclusions\nThe greater the number of authors,\ninstitutions and different countries, the\nhigher is the degree of diffusion and this\nratio is clear when analyzing the\nabsolute citations to IBGE. By applying\nthe diffusion factor, we were able to\n\nprove what the absolute numbers\nseemed to suggest: Gini index between\n9.88 in 2009 and 0.90 in 2003 indicate a\nhigh dispersion factor, thus, there is a\ngreat number of authors, institutions and\ndifferent countries that cite IBGE\npublications.\nMuch like Rousseau, Liu &amp; Ye (2012)\nconsidered the study that defined the\nstandardized Gini coefficient (Ge)\npreliminary; this study has shared\nexperimental features and is subject to\ncriticism and comments.\nReferences\nRousseau, R., Liu, Y.&amp; Ye, F.Y. (2012).\nA preliminary investigation on\ndiffusion through a layered system.\nJournal of Informetrics, 6, 177-191.\nFrandsen, T.F. (2004) Journal diffusion\nfactors – a measure of diffusion?\nAslib Proceedings, 56, 5-11.\nFrandsen, T.F., Rousseau, R.&amp;\nRowlands, I. (2006). Diffusion\nfactors. Journal of Documentation,\n62, 58-7.\nRowlands, I. (2002). Journal diffusion\nfactors: a new approach to\nmeasuring research influence. Aslib\nProceedings, 54, 77-84.\nRummler, G. (2006). Modelagem de um\nindicador bibliométrico para análise\nda dispersão de conhecimentos.\nCiência da Informação, 35, 63-71.\nZanotto, S.R., Vanz, S.A.S. &amp; Stumpf,\nI.R.C. (2011). A informação\nestatística oficial produzida pelo\nIBGE e a sua difusão geográfica. In:\nXII Encontro Nacional de Ciência\nda Informação e Biblioteconomia,\nBrasília. (XII ENANCIB).\nZanotto, S.R. (2011). Informação\nestatística oficial produzida pelo\nIBGE: apropriação pela comunidade\ncientífica brasileira no período de\n2001 a 2009. Dissertação de\nMestrado, UFRGS, Porto Alegre,\nBrasil.\n1937\n\nDISCOVERING AUTHOR IMPACT: A NOVEL\nINDICATOR BASED ON CITATION IDENTITY\nLiming Shao1 • Junpeng Yuan • Duanyang Xu\n1\n\nshaolm2012@istic.ac.cn\nInstitute of Scientific and Technical Information of China, Beijing 100038, China\nIntroduction\nThis article provides an alternative\nperspective for measuring impact of an\nauthor by studying the set of all authors\nwho cite the author. Besides, we\npropose a new algorithm which gives\ndifferent weights for the authors in the\ncited author list. Based on this\nalgorithm, a new indicator (citation\nidentity degree) is proposed which can\nquantify the impact of each author. We\ntest the indicator by evaluating author\nimpact in Chinese information science\ncommunity and compare this indicator\nwith citation.\nData\nThe “Chinese Social Science Citation\nIndex’’ (CSSCI) was developed by\nNanjing University. It is an important\ntool for inquiry and assessment of the\nmajor documentation in the area of\nhumanities and social sciences.\nOnly information science fields included\nin CSSCI were identified for\ninvestigation. Data used for the study\nwere limited to the period 2002–2011.\nAmong all of the 9355 publications in\ninformation science field, there are 9335\npublications that have authors and 8515\npublications that have references. At last\nwe chose 8505 publications which have\nboth authors and references as our data.\nMethods\nWe establish several new concepts:\nbasic identity (BI) and citation identity\n1938\n\ndegree (CID). We define basic identity\nas: BI = C / P, C are total citations with\nno self-citations and P are total papers.\nWe also define citation identity degree\nas: CID=ΣBIi•Ni, BIi is the basic\nidentity of author i and Ni are the times\ncited by author i. As is shown in figure1,\nAuthor A was only cited by author B, C,\nD and the cited times are Nb, Nc, Nd.\nThe\nCID\nof\nauthor\nA\nis\nCIDa=BIb•Nb+BIc•Nc+BId•Nd. By doing\nthis normalized weighted algorithm, we\ncan quantify the influence of each\nauthor and compare the influence of\ndifferent author.\n\nFigure 1. Calculation method of citation\nidentity degree\n\nResults and discussion\nAt first, we have discussed the\nrelationship between the number of this\nindicator and citations to see whether it\ncan be used to evaluate the influence of\nauthors. Then, we have analyzed the\nrank of citation identity degree.\nFigure 2 shows the Q-Q plot of citation\ncounts and citation identity degree\nvalues. In this graph, more nodes are\ndistributed around the diagonal line,\nwhich indicate that citation identity\ndegree values and citation counts have\nthe same distribution. Because citation\ncounts follow power-law distribution,\nthe citation identity degree values also\n\nfollow power-law distribution. It means\nthat citation identity degree, to a certain\ndegree, also measures an author’s\nacademic impact.\n\nFigure 4. Citation counts and citation\nidentity degree scores\n\nFigure 2. Citation counts and citation\nidentity degree Q-Q plot\n\nTable 1. Top 20 authors in the citation\nidentity degree and top 20 authors in the\ncitation\nNo.\n1\n3\n4\n5\n\nAuthor\nQiu Junping\nBao\nChanghuo\nMa Feicheng\nYan Yimin\nWan Zhijin\n\n6\n\nWang Congde 299.25\n\n2\n\n7\n8\n9\n\nFigure 3. Distribution of citation and\ncitation identity degree (only top 100)\n\nFigure 3 shows the distribution of\ncitation and citation identity degree\n(only top 100). Although citation counts\nand citation identity values have the\nsame distribution, the citation identity\ndegree is more evenly distributed. As\nthe citation identity degree value is\nbased on weighted algorithm, it gives\nthe impact author more weight and the\ngeneral author less weight, which lead to\nthe discrepancy. Therefore, the citation\nidentity degree values have a higher\ndegree of distinction.\n\nLiang\nZhanping\n\n20\n\n473\n311\n234\n196\n\nLai Maosheng 262.94\n\nHu\nChangping\n\n177\n\nZhang\nXiaolin\nLiu Zhihui\nLu Taihong\nHu\nChangping\nZhang Qiyu\nYue Jianbo\nMiu Qihao\nCheng Feng\nMeng\nGuangjun\nPang Jingan\nZhou\nXiaoying\n\n19\n\n539\n\n192\n\n11\n12\n\n18\n\n669.17\n445.18\n390.08\n\nC\n795\n\nSu Xinning\n\nSu Xinning\n\n14\n15\n16\n17\n\n915.75\n\nAuthor\nQiu Junping\nBao\nChanghuo\nMa Feicheng\nWang Zhijin\nYan Yimin\nZhang\nXiaoling\n\n296.76\n\n10\n\n13\n\nCID\n1001.3\n\n245.63 Lai Maosheng\nLiang\n204.50\nZhanping\n203.46 Zhang Qiyu\n183.69 Wang Congde\n\n177\n174\n166\n163\n\n181.40\n\nCheng Feng\n\n132\n\n177.67\n175.30\n163.66\n156.41\n\nLiu Zhihui\nWu Xiaowei\nQin Tiehui\nPang Jingan\n\n115\n115\n114\n111\n\n147.16\n\nPeng Jinli\n\n108\n\n145.41\n\nWen Youkui\n\n102\n\n144.23\n\nLu Taihong\n\n98\n\nFigure 4 shows the scatter plot of\ncitation counts and citation identity\ndegree values. In this graph, more nodes\nare distributed around the diagonal line,\n1939\n\nwhich indicates that the rank of citation\nidentity degree value is similar to the\nrank of citation counts. We have\ncalculated the coefficient (0.95),\nresidual standard error (10.3) and pvalue (&lt;2.2e-16) of citation counts and\ncitation identity degree values. We find\nthat citation identity degree values and\ncitation counts have high correlations\nfor the lower levels, which indicates that\nthe citation identity degree may yield\nuseful values for the majority of authors.\nFor higher values, the relatively low\ncitation counts have a relatively high\ncitation identity degree values. This\nresult can be interpreted by some\nauthors have a high impact but have\nrarely publications.\nFrom table 1, we can easily conclude\nthat the ranking order of citation identity\ndegree and citation counts are mainly\nconsistent, but the gap amongst the top\n20 authors in citation identity list are far\nbelow that of citation counts list merely.\nTherefore, employing citation identity\ndegree rank in authors’ impact analysis\npossesses better distinction. Difference\nexists in citation identity degree ranking\nand citation counts ranking, i.e. Wang\nChongde’s rank in citation identity\ndegree ranking has been raised 6 places;\nthis is comparatively in line with Pro.\nWang’s identity as one of the earliest\nexperts studying on teaching and\nresearching the theories and methods of\nthe information science and technology\nin China. Yue Jianbo, Miu Qihao, Meng\nGuangjun,and Chou Xiaoying’s name\nare only appeared in top 20 citation\nidentity degree ranking, take Pro. Miu\nfor example, it known to all that Miu\nand Bao are equally famous in Chinese\ncompetitive information domain. Bao\nplaces second both in the list of citation\nidentity degree rank and citation counts\n\n1940\n\nrank. Thus, Bao deserves taking a\nposition in the top 20 of citation identity\ndegree list.\nHowever, there are also some\nlimitations of this study. On the one\nhand, data collected by CSSCI have not\nincluded all articles that an author had\npublished. On the other hand, we\ncompared the new indicator only with\ncitations instead of other indications.\nConclusion\nThe current study provides an\nalternative perspective for measuring\nauthor impact by learning the ideas of\ncitation identity. We evaluate an\nauthor’s impact by discussing the set of\nall authors who cite the author and\npropose a weighted algorithm. A novel\nindicator is also proposed. We test this\nindicator by evaluating author impact in\nChinese information science community\nand compare this indicator with citation.\nFindings show that this new indicator\nprovides a meaningful extension to the\ntraditionally used citation counts for\nauthors.\nReferences\nDing, Y. (2011). Applying Weighted\nPageRank to Author Citation\nNetworks. Journal of the American\nSociety for Information Science and\nTechnology, 62(2), 236-245.\nHirsch, J. E. (2005). An index to\nquantify an individual&#x27;s scientific\nresearch output. Proceedings of the\nNational Academy of Sciences of the\nUnited States of America, 102(46),\n16569-16572.\nWhite, H. D. (2001). Authors as citers\nover time. Journal of the American\nSociety for Information Science and\nTechnology, 52(2), 87-108.\n\nDO NEW SCIENTISTS PREFER COLLABORATING\nWITH OLD SCIENTISTS? AND VICE VERSA?\nZhigang Hu1 Haiyan Hou2 Jianhua Hou3 and Chunlin Jiang4\n1\n\nhuzhigang@mail.dlut.edu.cn\nWISE Lab, Dalian University of Technology, Dalian (China)\nJoint-Institute for the Study of Knowledge Visualization and Scientific Discovery, Dalian\nUniversity of Technology(China)-Drexel University(USA), Dalian(China) and\nPhiladelphia(USA)\n2\n\nseabirdofsummer@gmail.com\nWISE Lab, Dalian University of Technology, Dalian (China)\n3\n\nhqzhixing@gmail.com\nSchool of Humanities, Dalian University, Dalian (China)\n4\n\nchunlinj7873@163.com\nWISE Lab, Dalian University of Technology, Dalian (China)\nIntroduction\nIt is seemingly reasonable to consider\nthat new and fledgling scientists might\nprefer collaborating with old and\nexperienced scientists because they\ncould benefit a lot from that, such as the\nsatisfactory experiment condition, the\nbrilliant ideas, and the opportunity to\npublish paper in top journals, etc.\nMoreover, collaboration of this type is\ngenerally considered as the way for the\nolds to guide the news. Thus,\ncollaboration between new scientists\nand old ones is also called mentoring\ncollaboration\nsometimes.\nSince\nmentoring collaboration is seemingly\nreasonable and valuable, we got a\nquestion: is it really happening?\nMethods\nIn previous researches, Liang et\nal(2001) divided scientists into three\ngroups: younger scientists (age&lt;37),\nmiddle-aged (37&lt;age&lt;50), and elder\n(age&gt;50), and explored how the three\n\ngroups collaborate with each other.\nThey found that Younger-Elder is the\nmain type of age structures of scientific\ncollaborations in computer science in\nChina.\nIn this study, we designed a novel\nmeasurement to identify new and old\nscientists, which is called the academic\nage of scientists. When scientists\npublish their first publication in a field,\ntheir academic career is beginning. Thus\nwe identified a scientist is new when\nhis/her academic age is small and a\nscientist is old when his/her academic\nage is large. In this way, we could\ndivide scientists into the new-scientist\ngroup and the old-scientists group\nsimply and clearly.\nResults\nAs the case, we chose all the authors\nwho published papers in 1990 in the\njournals of four subject categories\n(JCR), namely Computer Science,\nMathematics, Organic Chemistry, and\nVirology.\n1941\n\nIn 1990, the distributions of total\nscientists by academic age in the four\nsubjects are shown in Figure 1.\n\naged 0 is obviously less than expected.\nThe result means to some extent, new\nscientists prefer not to collaborate with\nthe scientists which are also new. This is\nespecially true in experimental subjects\nbecause new scientists require the\nlaboratory and other scientific resources\nsupported by their old collaborators.\n\nFigure 1. The distributions of the total\nscientists by academic age in the four\nsubjects\n\nAccordingly, we divided the authors\ninto two equal group based on their\nacademic ages in 1990. The younger\ngroup is named the new-scientist group,\nand the old one named the old-scientist\ngroup.\nDo\nthe\nnew\nscientists\nprefer\ncollaborating with the old ones?\nWe assumed that new scientists choose\ncollaborators randomly and impartially,\nso the distribution of the new scientists’\ncollaborators by academic age should be\nconsistent with the distribution of all of\nthe scientists by academic age as shown\nin Figure 1. Thus, by investigating the\nconsistency between the expected\ndistribution (as shown in Figure 1) and\nthe actual distribution (as shown in\nFigure 2), we can give answer to above\nquestions.\nAs shown in Figure 2, the two\ndistributions are extremely fit with each\nother. However, in the experimental\nsubjects, the proportion of collaborators\n1942\n\nFigure 2. The distribution of the new\nscientists’ collaborators by academic age\n\nFigure 3. The distribution of the old\nscientists’ collaborators by academic age\n\nDo\nthe\nold\nscientists\nprefer\ncollaborating with the new ones?\nSimilarly, we examined how the old\nscientists choose collaborators and\nwhether they are biased when\nconducting collaboration. Figure 3\nshows the distribution of the old\nscientists’ collaborators and the contrast\nto the expected distributions.\n\nFigure 4 The distribution of the three\nkinds of collaboration pairs: old-old, oldnew, new-new\n\nDo\nscientists\nprefer\nmentoring\ncollaboration or peer collaboration?\nFurther, we verified the above\nconclusions by investigating the\nprobabilities of collaboration pairs of\nthree\ndifferent\nkinds,\nnamely\ncollaborations\nbetween\ntwo\nold\nscientists\n(old-old),\ncollaboration\nbetween two new scientists (new-new),\n\nand collaboration between an old one\nand a new one (old-new). The former\ntwo are also called peer collaboration,\nand old-new collaborations are called\nmentoring collaboration.\nFigure 4 shows the proportion of three\nkinds of collaborations. By comparing\nwith the expected proportion (around\n1:2:1), it is found that for theory\nsubjects like Computer science and\nMathematics, peer collaborations are\npreferable rather than mentoring\ncollaborations.\nConclusion\nIn summary, scientists don’t choose\ncollaborators\naccording\nto\ntheir\nacademic age. For both new and old\nscientists, the distributions of their\ncollaborators by academic age are\nconsistent\nwith\ntheir\nexpected\ndistributions.\nOnly when examining this issue more\ndeeply, we can find some inclinations\nabout collaborator choosing. For\nexample, in theoretical subjects, peer\ncollaborations are more desirable than\nmentoring collaborations; while in\nexperimental subjects, the opposite\ninclination appears.\nReferences\nLiang L, Kretschmer H, Guo Y, Beaver\nDD. Age structures of scientific\ncollaboration in Chinese computer\nscience. Scientometrics.\n2001;52(3):471–86.\n\n1943\n\nDO SMALL AND MEDIUM SIZED BUSINESSES\nCLAIM FOR SMALL ENTITY STATUS? THE CASE\nOF MIT AND STANFORD UNIVERSITY SPINOFFS\nAhmad Barirani\nahmad.barirani@polymtl.ca\nPolytechnique Montréal, P.O. Box. 6079, Downtown Office, Montreal, Qc, H3C 3A7,\nCanada\nIntroduction\nThe USPTO gives the opportunity for\npersons, non-profit organizations and\nbusinesses with less than 500 employees\nto claim for the small entity status (the\nStatus) which entitles them to pay lower\n(50% discount) patent maintenance fees.\nStudies have used the Status to\ndistinguish between patents granted to\nlarge and small firms (Allison and\nLemley, 2000, 2006; Park and Park,\n2006; Allison et al., 2009; FernandezRibas, 2010; Bessen, 2008; Alcacer et\nal., 2009).\nThese studies make the implicit\nassumption that only large corporations\ndo not claim for the Status. However,\nthere could be strategic reasons for\nsmall and medium sized enterprises\n(SMEs) not to apply for the Status.\nAmong\nthe\nrequirements\nfor\nqualification, it is stipulated that at the\ntime that the Status is claimed, there\nmust be no obligation to assign, grant,\nconvey, or license any rights to the\ninvention to any entity that would not, in\nturn, qualify for small entity status\n(Patent\nand\nOffice,\n2001,\n§\n1.27(a)(2)(i)). Thus, SMEs that are\ngoing to license their patents to large\nfirms will not be able to claim for the\nStatus. To what extent are these cases\nwhere SMEs don’t apply for small entity\nstatus widespread?\n1944\n\nMethodology\nA sample of university spinoffs that\noriginate from the MIT and Stanford\nUniversity are employed. After cleaning\nfor strings that describe the firm’s legal\nentity (such as Inc., Corp., etc.), the set\nof patents granted by the USPTO to\nthese spinoffs is extracted. From this set\nof extracted patents, only those that are\nassigned to firms that are located in the\nsame state as their university of origin\n(i.e. Massachusetts for the MIT and\nCalifornia for Stanford University) are\nconsidered. This will avoid taking into\nconsideration homonyms. From this set\nof firms for which patents have been\nmatched in the USPTO, search on\nLinkedIn website is performed in order\nto gather information about current\nnumber of employees. Since not\neveryone has a LinkedIn account, this\ninformation is not always accurate.\nTherefore, only those firms which have\ncurrently less than 350 employees will\nbe used for further analysis. This\ncushion of 150 employees appears to be\nreasonable taking into account that, for a\ntotal of 155 million workers in the US\nworkforce, more than 74 million\nLinkedIn accounts have been created in\nthe US and that the use of the service is\nmore widespread among hi-tech\nprofessionals.\n\nPatents owned by these firms are then\nlinked to USPTO’s maintenance fee\nevents database, from which those that\nare related to the Status are identified.\nPatents that are not associated with the\nStatus will represent false large entity\npatents.\nResults\nTo date, the MIT and Stanford\nUniversity have produced 131 and 227\nspinoffs respectively. From these 358\nfirms, 105 were found to have patents in\nthe USPTO database. Based on searches\nmade on LinkedIn, 60 of these firms are\nactive today and have less than 150\nemployees. Table 1 shows the number\nof patents granted to each of these firms,\nand the number of patents for which a\nsmall entity event is found in the\nmaintenance fee database. As we can\nsee, a substantial number of patents\n(more than 30%) produced by these\nSMEs are not claimed as small entities.\nTable 1. Maintenance fee events for active\nspinoffs from the MIT and Stanford\nUniversity.\nFirm\nanacor pharmaceuticals\napplied genomics\narbor vita\nart technology group\navantec vascular\nbarcelona design\nbiocardia\nbrion technologies\ncaveo technology\ncellgate\ncomentis\ncooligy\ncorcept therapeutics\ncorgentech\ncoverity\ne ink\nember\nfluidigm\n\nAll\nSmall\npatents entity\npatents\n4\n2\n2\n1\n11\n6\n10\n7\n15\n1\n12\n0\n24\n24\n29\n15\n1\n1\n12\n9\n2\n0\n29\n16\n7\n6\n2\n2\n5\n4\n143\n136\n4\n4\n25\n22\n\nTable 1. Maintenance fee events for active\nspinoffs from the MIT and Stanford\nUniversity (continued).\nFirm\n\nAll\nSmall\npatents entity\npatents\ngeneral mems\n1\n0\nharmonix music systems 8\n4\nkosan biosciences\n91\n50\nlightbit\n3\n3\nlightconnect\n9\n8\nlyncean technologies\n5\n5\nmicrobar\n6\n5\nmolecular nanosystems 2\n2\nnearlife\n4\n4\nneophotonics\n19\n1\nneurocrine biosciences\n69\n31\nnovariant\n29\n28\nopen ratings\n2\n1\noptimedica\n2\n2\npanorama research\n1\n1\npicarro\n20\n16\npixim\n46\n46\npredicant biosciences\n5\n1\nrigel pharmaceuticals\n140\n114\nsabio labs\n2\n0\nsensable technologies\n25\n25\nsenvid\n3\n2\nsirf technology\n160\n89\nspinal modulation\n4\n4\nspiracur\n1\n0\nstemcells\n2\n2\nt-ram\n96\n94\ntagsense\n1\n1\ntelik\n27\n2\nterastor\n45\n7\nthingmagic\n6\n0\ntosk\n7\n5\ntrellis bioscience\n7\n6\nvia pharmaceuticals\n3\n1\nviisage technology\n5\n4\nvoltage security\n14\n14\nway systems\n3\n3\nxgene\n2\n2\nzomed international\n8\n8\nzyomyx\n21\n19\nTotal\n1242\n867\n\nConclusions\nStudying a sample of spinoffs\noriginating from the MIT and Stanford\n1945\n\nUniversity, it can be found that a\nsubstantial part of patents produced by\nthese firms where not claimed under the\nsmall entity status. It would thus appear\nthat the small entity status is not a great\nsource of information for finding\nwhether a firm is large or not. However,\ngiven the strict rules under which one\ncan claim for the small entity status, it is\nsafe to conclude that a sample of patents\nfor which events in the maintenance fee\ndatabase are associated with the small\nentity status have been indeed assigned\nto a non-profit organization, an\nindividual or an SME.\nAn inherent limitation to this research\nresides in the fact that a small sample of\nuniversity spinoffs is used. Another\nlimitation consists in using LinkedIn as\na source of information about the\ncurrent size of a company. Data\nobtained from LinkedIn is not always\nreliable as it results from the entry of\ninformation by the users of the service.\nThe discussion in this study can be\ncomplemented\nby\nperforming\ndescriptive and inferential statistics on\ndifferent variables (such as firm age or\nindustry) in order to have a better\nindication of how false large entity\npatents are distributed among SMEs.\nTrend analysis can also be interesting in\norder to observe whether there is a\ntendency for SMEs to claim less often\nfor the Status.\nReferences\nAlcacer, J., Gittelman, M., and Sampat,\nB. (2009). Applicant and examiner\n\n1946\n\ncitations in U.S. patents: An\noverview and analysis. Research\nPolicy, 38(2):415–427.\nAllison, J. and Lemley, M. (2000).\nWho’s Patenting What-An Empirical\nExploration of Patent Prosecution.\nVanderbilt Law Review, 53:2099.\nAllison, J. and Lemley, M. (2006).\n(Unnoticed) Demise of the Doctrine\nof Equivalents, The Stanford Law\nReview, 59:955.\nAllison, J., Lemley, M., and Walker, J.\n(2009). Extreme Value or Trolls on\nTop? The Characteristics of the Most\nLitigated Patents. University of\nPennsylvania Law Review, Vol. 158,\nNo. 1, December 2009, Stanford\nPublic Law Working Paper No.\n1407796.\nBessen, J. (2008). The value of U.S.\npatents by owner and patent\ncharacteristics. Research Policy,\n37(5):932–945.\nErickson, G. (1996). Environment and\ninnovation: The case of the small\nentity. Industrial Marketing\nManagement, 25(6):577–587.\nFernandez-Ribas, A. (2010).\nInternational patent strategies of\nsmall and large firms: An empirical\nstudy of nanotechnology. Review of\nPolicy Research, 27(4):457–473.\nPark, G. and Park, Y. (2006). On the\nmeasurement of patent stock as\nknowledge indicators. Technological\nForecasting and Social Change,\n73(7):793 – 812.\nPatent, U. S. and Office, T. (2001).\nManual of Patent Examining\nProcedure.\n\nDOES SCIENTIFIC KNOWLEDGE PLAY A ROLE\nIN PUBLIC POLICIES? A CONTRIBUTION OF\nSCIENTOMETRICS TO POLITICAL SCIENCE: THE\nCASE OF HTA.\nCyril Benoit1 and Philippe Gorry2\n1\n\ncyril.benoit@scpobx.fr\nCentre Emile Durkheim UMR CNRS 5116, Sciences Po Bordeaux, 11, Allée Ausone- –\n33607 Pessac (France)\n2\n\nphilippe.gorry@u-bordeaux4.fr\nResearch Unit in Theoretical and Applied Economics, UMR CNRS 5113, University of\nMontesquieu Bordeaux IV, 33607 Pessac (France)\nIntroduction\nThe social use of scientific knowledge\ncan take various forms. In the case of\npublic policies, most researches insist on\nthe capacity of decision-makers to\ntechnicize issues with scientific-based\nknowledge.\nIn the health sector,\nprevious work was focused on the link\nbetween the field of academic research\nand that of decision-making (Lavis et\nal., 2006). Recently, some demonstrated\nthe appropriateness of bibliometric\nstudies in observing the factors that\ninfluence the use of scientific-based\nknowledge in public policies (MaciasChapula, 2012). According to them, we\npropose to enhance this approach in\nhealth public policies analysis. Indeed,\nmany of them are based on wide process\nof knowledge circulations.\nTo illustrate this argument, we propose\nto lead a scientometric analysis of\nconditions of emergence of a public\naction instrument (Lascoumes et al.,\n2007): Health Technology Assessment\n(HTA). It has been defined as a form of\npolicy research that examines short-and\nlong-term\nconsequences\nof\nthe\napplication of health technologies\n\n(Banta, 2009). HTA aims to link\nregulation of the healthcare system,\nquality of care, and payment for care\n(Banta et al., 2010). Since the mid2000s, the whole of OECD countries\nand most of middle-income countries\nhave incorporated various HTA tools to\ntheir decision-making process. They\nwere generally institutionalized as\n“HTA agencies”; which provide the\nstakeholders scientific-based assessment\nof cost and benefits of a wide set of\nmedical devices. Its scientific dimension\ncan be considered as the main feature of\nHTA: assessments are led by\nprofessional researchers, proposing a\nrational aid to external decision-makers,\nstrongly related to dedicated research\ncentre.\nNevertheless, we believe that this\nphenomenon raises three major policy\nissues: what were the scientific\nconditions for HTA success? Who were\nthe individuals, and why they linked\nacademic research and decision-making\nprocess? Which are the factors for a\nvirtuous institutionalization of HTA in a\ngiven country?\n\n1947\n\nPurpose\nThe purpose of this work was to\nundertake a historic, descriptive and\nquantitative comparative analysis of\nscientific conditions of emergence of\nHTA as a public action instrument\napplying scientometrics to political\nscience questions.\nMethods\nA literature search on HTA scientific\nproduction was conducted both in\nPubMed &amp; Scopus databases Then, we\nled a bibliometric, network and\ndescriptive statistics analysis on the\ncorpus (2081 publications) with various\nanalysis\ntools\n(KNALIJ,\nMatheoanalyzer,\nIntellixir).\nThe\nlandscape of the HTA field so obtained\nwas deployed in 3 comparative registers.\nA micro-level approach through a\nnetwork analysis was led in order to\nidentify HTA main experts with their\npattern of collaborations. Then, we\nreplaced it in a macro-level perspective\nin mapping the worldwide academic\nresearch. Finally, we explored the link\nbetween these scientific dimensions and\nhealthcare system with PCA analysis.\nResults\nThe temporal distribution of the\npublications suggests a peripheral status\nof our concept in the literature, until a\nturning point in the late 1980’s. Then\nthe growth of the publications became\nexponential with an acceleration rate\nsuperior to related disciplines s (Fig. 1).\nHTA publications were produced by\nauthors grouped in some collective\nresearch schemes organised around one\n‘major author’ (red coloured on Fig.2).\nIndeed, the distribution of publications\nby authors follow a Lotka’s Law.\nA map of concepts was draw to identify\nthe main scientific streams (Fig.3), and\ntime-series analysis help us to\n\n1948\n\ncorroborate\nwith\ninstitutionalization.\n\nHTA\n\nFigure1. Number of HTA publications per\nyear in comparison to related disciplines\n\nFigure 2. Network analysis of HTA\nscientific collaborations\n\nFigure 3. Network map of HTA main\nconcepts\n\nCountry HTA publications productivity\n(Fig.4) is matched in comparison with\nhealth expenses &amp; gross product in\nseveral countries (strongest ratio: at the\ntop, right; weakest ratio: at the bottom,\nleft) (Fig. 5).\n\nFigure 4. Choropleth map of HTA\npublications\n\nFigure 5. PCA plot of country HTA\nresearch according to GDP &amp; health\nexpenses.\n\nDiscussion\nFor the case of HTA, it appears that a\nsmall scholar’s community have\ngradually become independent in the\nscientific field. Although it seems to be\nclosely linked to public health policies,\nthe scholars working on HTA are not\nsubmitted to public purchasing. The\ngrowth of HTA as a field autonomous\nfrom decision-making field and other\ndisciplinary fields permit to consider it\nas a scientific discipline, in the sense of\nP. Bourdieu (Albert et al., 2011). In Fig.\n4 &amp; 5, the absence of formal relation\nbetween the importance of HTA\npublications\nand\nan\nearly\ninstitutionalization of the concept\nconfirm this view. Its career in the\ndifferent fields must be distinguished.\nDespite this autonomy, scholars are in\n\nposition to develop concept that can\ncome out to legitimate new orientations\nin public policies (Roger, 2010).\nWhen scholars seem to influence\ndecision-making process, the position of\neach of them in their field must be\nreconstructed. A bibliometric analysis\nappeared as an appropriate tool to\nconduct such investigation in political\nscience.\nReferences\nAlbert M. &amp; Kleinman D.L (2011).\nBringing Pierre Bourdieu to Science\nand Technology Studies. Minerva,\nVol. 49, 263-273.\nBanta, D. (2009).What is technology\nassessment? International Journal of\nTechnology Assessment in Health\nCare, Vol. 25, 7-9.\nBanta, D., Mathijssen, J., &amp; Oortwjn,\nW., (2010). The role of health\ntechnology assessment on\npharmaceutical reimbursement in\nselected middle-income countries.\nHealth Policy, Vol. 95, 174-184.\nLascoumes, P. &amp; LeGalès, P. (2007).\n“Understanding public policy\nthrough its instruments”,\nGovernance, Vol. 20, 1-21.\nLavis, J. N., Lomas, J., Hamid, M., &amp;\nSewankambo, N. K. (2006).\nAssessing country-level efforts to\nlink research to action. Bulletin of\nthe World Health Organization,\nn°84,\n620-628.\nMacias-Chapula, C. (2012).\nComparative analysis of health\npublic policy research results among\nMexico, Chile and Argentina,\nScientometrics, 1-14.\nRoger, A. (2010). Scholarly constructs\nand the legitimization of European\npolicies. Revue Française de Science\nPolitique (English), Vol. 60, 1-22.\n\n1949\n\nTHE EARLIEST PRIORITY SELECTOR FOR\nCOMPILING PATENT INDICATORS\nDouglas H. Milanez1, Mateus G. Milanez2, Leandro I. L. de Faria3, Roniberto M.\ndo Amaral4 and Jose A. R. Gregolin5\n1\n\ndouglas@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n2\n\nmilaneza@gmail.com\nMLNZ IT Consultancy LTDA, Saverio Talarico Avenue, 220, São Carlos – SP (Brazil)\n3\n\nleandro@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n4\n\nroniberto@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\n5\n\ngregolin@nit.ufscar.br\nFederal University of Sao Carlos, Washington Luis Highway, km 235, São Carlos – SP\n(Brazil)\nIntroduction\nPatent indicators provide an effective\nopportunity to depict patterns of\ntechnological\ndevelopment\nfrom\ncountries and competitors. The OECD\nPatent Statistics Manual (2009) provides\nbasic criteria for compiling patent\nindicators\nand\ntwo\nimportant\nmethodological\nchoices\nare\nthe\nreference date and the country of\nattribution. Due to the legal constraints\nand administrative delays, the manual\nrecommends using the date from the\nfirst priority as it is closest to the date of\nthe invention. Concerning the country of\norigin, patents can be assigned on the\nbasis of the priority country or addresses\nof the inventor or the patentee. Although\nthe suggestion is to use the inventor’s\ncountry in order to reflect the country’s\n1950\n\ninventive activity (OECD, 2009), this\ninformation is not always available on\ndatabases, as in the case of Derwent\nInnovations Index (DII), whose patent\nfamily records include only the priority\ninformation as a source of country of\norigin. A patent family can be defined as\na group of patent publications on a\nsingle invention (Simmons, 2009).\nUsually, a patent family claim the same\npriority (first filing), but they can also\nhave multiple priorities as a result of the\nvariations in legal regulation among\ncountries or rules for creating patent\nfamilies (DII, 2013; Simmons, 2009).\nAccording to DII (2013), only around\n2% of all patent applications indexed\nclaim multiple priorities. However,\nmultiple priorities might affect the\nanalysis of patent indicators as different\ncountries and dates can be wrongly\nincluded in the final indicator. This\n\npaper aims to present software that\nselects the earliest priority from patent\nfamilies indexed in the DII database,\nproviding the correct information to\ncompile patent indicators. A comparison\nof indicators using all priorities or just\nthe earliest one was also conducted.\nMaterials and Methods\nPatent data sample and analysis\nA test dataset of nanotechnology patents\nwas retrieved from the DII database\nusing the modularized Boolean search\nstrategy suggested by Porter et al.\n(2008). The search was carried out on\n23 January, 2013 and 189,481 patent\nfamily\nrecords\nwere\ncollected\nconsidering the time spam from 1995 to\n2012. After treating records in the\nEarliest\nPriority\nSelector\n(EPS)\nsoftware, the data was imported to the\nbibliometric software Vantage Point\n(version 7.0, Search Technology Inc,\nUS). The accurate number of priorities\nwas counted for each record in order to\nquantify the percentage of multiple\npriority records. The influence of using\nall priorities or the earliest was carefully\nexamined for the top 15 countries and\nfor the years.\nThe Earliest Priority Selector\nThe EPS180 is software developed in\nPython language that aims to choose the\nfirst priority of records from DII with\nmultiple priorities. Python is an open\nsource license programming language\nwith clear syntax, extensive standard\nlibraries and modules for a range of task\n(Python, 2013). The EPS imports a\nsingle file with all records collected\nfrom database and its algorithm checks\n\n180\nThe software is freely available at\nhttp://www.nit.ufscar.br/index.php/software/\n154-earliest\n\nthe priority field (called PI) as described\nbelow:\nIf the record presents just one priority,\nthe EPS logically keeps it as the earliest\npriority;\nIf the record presents two or more\npriorities, the EPS compares the priority\ndates and chooses the earliest.\nAlthough most of the records were\naccurately treated with the described\nalgorithm, a few records presented\ndifferent earliest priority numbers with\nthe same date, as exemplified in Table 1.\nIn all of these cases, however, a WO\npriority number was among the earliest\npriorities. Thus, the EPS algorithm picks\nup the WO priority as the earliest date.\nIn addition, the earliest priority selected\nby EPS was added into a new field\n(called PO), which is also included in\nTable 1.\nTable 1. Example of multiple priorities\nfrom DII records (WO2004001100-A1).\nField\nPI\n\nPO\n\nPriority number\nCN80158992\nJP523510\nWOJP063106\nUS353569\nJP093340\nWOJP063106\n\nPriority date\n22 Jul 2009\n22 Jul 2009\n22 Jul 2009\n19 Jan 2012\n16 Apr 2012\n22 Jul 2009\n\nResults and discussion\nFrom the 189,481 nanotechnology\npatent families, 75.9% showed just one\npriority, and then no treatment was\nnecessary. By contrast, from the 24.1%\nwith multiple priorities, 17.0% were\nrecords with two priorities and 3.91%\nwith three priorities. Just a few patent\nfamilies fit in the special case shown in\nTable 1, and they represent 0.55% from\nthe whole nanotechnology patent sample\nand 2.28% from the multiple priorities\ndataset. In this case, even if the selected\ncountry is not the correct one, it is clear\nthat the error will not affect any ranking\nor analysis. Table 2 shows the ranking\n1951\n\nof the top 15 countries considering the\ninformation from all priorities (PI field)\nand from the earliest priority selected by\nEPS (PO field).\nTable 2. Differences in country ranking\nCountry\nCode\nCN\nUS\nJP\nKR\nDE\nCA\nTW\nFR\nRU\nGB\nIN\nAU\nIT\nES\nBR\n\nPI Field\nP\nNP\n1 54293\n2 53329\n3 33015\n4 22553\n5 8384\n6 4712\n7 4492\n8 3530\n9 3461\n10 2596\n11 1244\n12 1237\n13 730\n14 544\n15 491\n\nPO Field\nP\nNP\n1 53224\n2 50837\n3 32555\n4 19371\n5 8115\n17 321\n6 4427\n8 3507\n9 3414\n10 2480\n11 1062\n13 557\n12 727\n14 543\n16 431\n\nChang\ne (%)\n-1.97\n-4.67\n-1.39\n-14.1\n-3.21\n-93.2\n-1.45\n-0.65\n-1.36\n-4.47\n-14.6\n-55.0\n-0.41\n-0.18\n-12.2\n\nGenerally, no significant differences\nwere observed in the country ́s position\n(P) neither great changes in the number\nof patents (NP), except for Canada,\nKorea Australia, India and Brazil. In the\ncase of Canada, it is known that many\nCanadian firms file patents first in the\nUSA, followed by a possible extension\nin Canada at a later stage of the process\n(OECD, 2009). Therefore, the first\npriority was related to the USA not\nCanada. Although the change of the NP\nwas high for Korea Australia, India and\nBrazil, their position in the ranking\nremained pretty much the same. A\npercentage decrease in the annual\nnumber of patents was observed when\nthe year of the earliest priority was\ntaking into account instead of all years\nfrom the priority field. On average, the\nnumber of patent families dropped\n17.7% ± 1.71% for each year in the\nperiod analyzed.\n\n1952\n\nConclusion\nNo significant changes in the country ́s\nperformance were observed when the\nearliest priority was applied instead of\nall priorities. The fall of patent numbers\nis similar for all years from the period\n1995-2010 and the use of the earliest\npriority is a better option due to the\nproximity to the invention, as\nrecommended by the OCDE Patent\nManual (2009). Although there is a bias\nof earliest priority with different\nnumbers and equal dates (Table 1), the\nsolution provided by the EPS does not\nsignificantly affect the final indicators.\nThe accurate selection of the earliest\npriority also helps patent databases that\ndo not provide the country of origin of\nthe applicants or the inventors, as in the\ncase of DII.\nAcknowledgements\nThe authors are grateful to the Brazilian\nNational Council for Technological and\nScientific Development (process number\n160087/2011-2), the São Paulo Research\nFoundation\n(process\nnumber\n2012/16573-7) and the Graduate\nProgram in Materials Science and\nEngineering at the Federal University of\nSão Carlos.\nReferences\nDerwent Innovations Index. (2013).\nWhat is a Patent Family? Retrieved\nFebruary 26, 2013 from\nhttp://images.webofknowledge.com/\nWOKRS59B4_2/help/DII/hs_book_\npart3.html\nOECD. (2009). OECD Patent Statistics\nManual. Retrieved February 26,\n2013 from http://dx.doi.org/\n10.1787/9789264056442-en\nPorter, A. L., Youtie, J., Shapira, P., &amp;\nSchoeneck, D. J. (2008). Refining\nsearch terms for nanotechnology.\nJournal of Nanoparticle Research,\n10(5), 715–728.\n\nPython. (2013). About Python. Retrieved\nFebruary 26, 2013 from\nhttp://www.python.org/about/\n\nSimmons, E. S. (2009). “Black sheep”\nin the patent family. World Patent\nInformation, 31(1),11–18.\n\n1953\n\nEFFICIENCIES IN NATIONAL SCIENTIFIC\nPRODUCTIVITY WITH RESPECT TO MANPOWER\nAND FUNDING IN SCIENCE\nAparna Basu\naparnabasu.dr@gmail.com\nCSIR-National Institute of Science Technology and Development Studies,\nDr. K.S. Krishnan Marg, Pusa Gate, New Delhi 110012, (India)\nIntroduction\nDue to recession in the world economy\nthere is a general trend towards a\nreduction in growth of R&amp;D expenditure\nin the G7 countries. Asian countries like\nChina and Korea have significantly\nincreased their share of investment in\nR&amp;D. China has also substantially\nincreased its output of scientific papers.\nIt is now second to the United States in\nterms of both papers and manpower. We\nask how increased investment of\nresources translates into outputs. Do\ndeveloped countries make more efficient\nuse of their resources? We use the\nnotion of efficiency of scientific output\nfor inputs like manpower and\ninvestment at the country level to\nanswer these questions.\nAlbuquerque’s Model\nAlbuquerque (2005) proposed a simple\nmodel that linked output indicators to\ndevelopment. He showed that paper\nproduction and patent production ratio\nchanges as countries become more\ndeveloped. He termed this technological\n‘maturity’ and took the ratio of papers to\npatents, normalized by population, as\nefficiency. (The ratio decreases as a\nfunction\nof\ndevelopment.)\nIn\nAlbuquerque’s model, less developed\ncountries fall on a line separated by a\nthreshold from developed countries\n\n1954\n\nwhen patents are plotted against papers\n(Fig.1).\nData and methodology\nData on scientific papers is taken from\nthe SCI-Expanded and USPTO for the\nyears 2007 and 2008. GDP and GERD\nare both adjusted to Purchasing Power\nParity (PPP) and compared for selected\ncountries for the years 2002 and 2007.\nManpower is measured in terms of Full\nTime Equivalents (FTEs) engaged in\nR&amp;D. Data on GERD and GDP are\nobtained from the UNESCO Science\nReport 2010.\n\nFig.1. Papers A and Patents P (per mill.\ninhabitants) plotted for less developed\ncountries (squares) and developed\ncountries (circles). From Albuquerque\n2005.\n\nOur definition of efficiency of the\nscience system is the output of papers\nand patents as a ratio of inputs,\nmanpower in R&amp;D and expenditure.\nThis must be distinguished from\nAlbuquerque’s definition. Our definition\nmore closely captures the efficiency\nwith respect to actual expenditure and\nmanpower. We have two dimensions for\nthe outputs, patents and papers, and two\ndimensions\nfor\ninputs,\nresearch\nexpenditure and manpower, leading to a\ntotal of 4 indicators of efficiency.\n\n1.\n3\n\n1.\n4\n\n1.\n0\n\n23.1\n32.6\n8.9\n12.9\n6.3\n2.2\n3.4\n3.4\n1.9\n1.8\n2.0\n0.5\n3.6\n2.1\n\n1.0\n1.6\n0.6\n1.9\n1.5\n0.4\n1.1\n1.1\n0.7\n0.6\n0.7\n0.2\n1.4\n1.2\n\nGERD share/\nGDP share 2007\nGERD/\nGDP 2007-2002\n\n26.1\n35.1\n5\n13.7\n7.2\n1.6\n3.9\n3.9\n2.2\n1.6\n2.0\n0.5\n2.8\n2.4\n\nGERD share/\nGDP share 2002\n\n1.\n2\n\n22.5\n20.7\n10.7\n6.5\n4.3\n4.7\n3.1\n3.2\n2.8\n2.8\n3.2\n2.3\n1.9\n1.9\n\nGERD share 2002\n\n1.\n3\n\n25.3\n22.5\n7.9\n7.4\n4.9\n3.8\n3.7\n3.7\n3.3\n2.9\n2.8\n2.1\n2\n2\n\nGERD share 2007\n\nAustr\nalia\n\n(2)\nGDP share 2007\n\nEU\nUSA\nChina\nJapan\nGermany\nIndia\nFrance\nUK\nItaly\nBrazil\nRussia\nMexico\nKorea\nCanada\n\nGDP share 2002\n\nCountry\n\nTable 1. GERD and GDP shares of\nselected countries\n\n1.0\n1.6\n0.8\n2.0\n1.5\n0.5\n1.1\n1.1\n0.7\n0.6\n0.6\n0.2\n1.9\n1.1\n\n1.\n2\n\n0.0\n0.1\n0.2\n0.1\n0.0\n0.1\n0.0\n0.0\n0.0\n0.1\n-0.1\n-0.0\n0.5\n-0.1\n\n0.\n2\n\nEfficiency is defined as,\nExpenditure efficiency EE(Pap)\n= Papers/GERD\n\n(1)\n\nManpower efficiency ME(Pap)\n= Papers/Manpower\n\n(2)\n\nFor patents,\nPatent Expenditure Efficiency EE(Pat)\n= Patents/GERD\n(3)\n\nPatent Manpower Efficiency ME(Pat)\n= Patents/Manpower\n(4)\nTable 1 below shows the base data of\nGERD and GDP, and their ratios.\nDeveloped countries have higher GERD\nshares as compared to GDP shares\n(GDP is the Gross Domestic Product),\nthe Gross Expenditure on R&amp;D (GERD)\nbeing taken as the expenditure on the\ncreation of new knowledge (Hollanders\nand Soete, 2010). Such countries with\nGERD/GDP &gt;1 are Japan, USA,\nGermany, UK, France, Korea, Australia.\nTable 2 below shows inputs and outputs\nto the science system.\nTable 2Manpower, GERD, Papers and\nPatents for selected countries\nCountry\nAustralia\nBrazil\nCanada\nChina\nFrance\nGermany\nIndia\nItaly\nJapan\nS. Korea\nMexico\nRussia\nSpain\nUK\nUSA\n\nGERD\nBn $\nPPP\n15.36\n20.2\n23.96\n102.4\n42.89\n72.24\n24.79\n22.12\n147.9\n41.3\n55.9\n23.4\n19.34\n41.04\n398\n\nManpower\n(FTE’s)\n87,140\n1,33,266\n1,39,011\n14,23,380\n2,15,755\n2,90,853\n1,54,827\n96,303\n7,09,974\n2,21,928\n37,930\n4,51,213\n1,30,896\n2,61,406\n14,25,550\n\nPapers\nSCI\n2007\n28313\n26482\n43539\n104968\n57133\n76368\n36261\n45273\n74618\n32781\n8262\n27083\n35739\n71,302\n2,72,879\n\nPatents\nUSPTO\n2008\n1516\n124\n3806\n7362\n3631\n9713\n741\n1836\n33572\n6424\n81\n286\n363\n4007\n81811\n\nAnalysis\nIn Fig.2 we plot the expenditure and\nmanpower efficiency of papers. Italy\nhas the highest efficiency EE(Pap) and\nME(Pap) in the production of scientific\npapers. Japan, Korea, USA and\nGermany have values of expenditure\nefficiency\nbelow\naverage.\nThe\nunexpectedly low values of efficiency\nare surprising for Japan and the USA as\nthese, along with Korea and Germany,\nhave shown an increase in the\nGERD/GDP ratio (Table 1.)\nIn Fig.3 we plot the EE(Pat) against the\nExpenditure Efficiency of Papers\n1955\n\nEE(Pap). This is the analogue of\nAlbuquerque’s model (Fig.1) with our\ndefinitions of efficiency. If we compare\nthe curves in the two figures, we note\nthat there is a distribution of points\nalong the X-axis in Fig. 3 that\ncorresponds to the distribution in Fig.1,\nwith a few prominent outliers. For the\nfour countries that stand away from this\ndistribution, namely Japan, USA, Korea\nand Germany, higher patent efficiency is\nnot linked to higher paper efficiency.\n\nFig 2. Efficiency in the production of\npapers w.r.t. Manpower and Expenditure\n\nFig. 3. Patent Efficiency with respect to\nGERD vs. Paper efficiency with respect to\nGERD\n\nThere appears to be an inverse\nrelationship between patents and papers\nin a departure from Albuquerque’s\nmodel.\nA more detailed look at GERD figures\nfor these countries shows 78.2% of total\nR&amp;D expenditure in Japan came from\nthe business sector. It was 67.3% in the\nUS, 67.6% in Germany and 45.1% in\nthe UK (2008 figures). These high\n1956\n\nvalues provide an explanation, viz.,\nGERD funding from the business sector\nis driving patent production in favour of\npaper production.\nSummary\nSome findings are listed below. 1) Italy\nhas the highest efficiency in the\nproduction of scientific papers, with\nrespect to manpower and investments.\n2) Japan has the highest efficiency in\npatent production. 3) Certain countries\nthat have shown increased expenditures\nin R&amp;D, showed at the same time a low\nefficiency in the output of scientific\npapers, which was unexpected. This\nappeared to be compensated in by high\nefficiency in the production of patents.\nWe find that there is a shift from\npublications toward patenting apparently\ndriven by increased investments from\nthe business sector in countries like\nJapan, USA, Korea and Germany.4) It\nfollows that Albuquerque’s model with\na\nsimple\ndemarcation\nbetween\ndeveloped and developing countries is\nno longer true. Better definitions of\nefficiency are required. The trend in\nmore developed countries is not to\nincrease the output of papers, as\nsuggested by the model, but to decrease\nthe output of papers in favour of patents.\nReferences\nAlbuquerque, E. (2005) Science and\nTechnology systems in less\ndeveloped countries. In H.Moed, W.\nGlanzel, U.Schmoch (Eds.)\nHandbook of Quantitative Science\nand Technology Research (pp759778) Kluwer Academic Publishers.\nHollanders, H. &amp; L. Soete (2010). The\ngrowing role of knowledge in the\nglobal economy. In UNESCO\nScience Report 2010, UNESCO\nPublishing.\nUNESCO Science Report (2010)\nUNESCO Publishing.\n\nEMERGENCE OF KEYWORDS IN WEB OF\nSCIENCE VS. WIKIPEDIA\nChristine Rimmert1 , Edith Rimmert2 and Holger Schwechheimer3\n1\n\nchristine.rimmert@uni-bielefeld.de\nBielefeld University, Interdisciplinary Bibliometric Group, Universitätsstr. 25, 33615\nBielefeld (Germany)\n2\n\nedith.rimmert@uni-bielefeld.de\nBielefeld University, Library, Universitätsstr. 25, 33615 Bielefeld (Germany)\n3\n\nholger.schwechheimer@uni-bielefeld.de\nBielefeld University, Interdisciplinary Bibliometric Group, Universitätsstr. 25, 33615\nBielefeld (Germany)\nIntroduction\nTopics appearing in scientific literature\nare also discussed in the open web - thus\nit is worth asking whether the open web\nis an interesting source for bibliometric\nissues. This paper focuses on keywords\nin the Web of Science (WoS) and\nassociated Wikipedia pages. Are WoS\nkeywords\nalso\nrepresented\nin\nWikipedia? When do they emerge in\nWikipedia compared to their first\nappearance in the WoS?\nMethods\nFour samples of keywords (appeared\nafter 2007) were taken from the WoS:\n random selection of 100 author\nkeywords (&#x27;AU&#x27; in the following),\n the 100 most frequent AU keywords,\n random selection of 100 KeyWords\n®\nPlus (&#x27;PL&#x27; in the following) and\n the 100 most frequent PL keywords.\nFor each keyword in each sample the\noccurrence in Wikipedia was checked\nusing four matching conditions:\n\n1. exact match (the keyword is equal to\na title of a Wikipedia page),\n2. redirected match (searching the\nkeyword leads to a redirection to\nanother page),\n3. chapter match (the keyword is equal\nto a chapter on a Wikipedia page)\nand\n4. similar match (a Wikipedia page is\nnamed in a similar way),\nwhere &#x27;similar&#x27; was restricted to\ndifferences concerning singular-plural,\nwell known abbreviations (e.g. &#x27;DNA\nSeq&#x27;), word permutations, typing errors,\npart of speech and missing stop words\nin order to prevent errors. If the WoS\nkeyword contains two keywords (e. g.\n&#x27;keyword1 and keyword2&#x27;), an exact\nmatch of keyword1 or keyword2 is\ncounted as an exact match. The same\napplies for keywords that differ only by\na hyphen. The &#x27;start&#x27; was defined as the\nyear of the first appearance in the WoS,\nrespectively the emergence of the\nWikipedia page.\n\n1957\n\nResults\nMatches\nTable 1 shows the match results. While\nthe random selections have high\npercentages of keywords that could not\nbe found in Wikipedia (AU:83%,\nPL:86%), the situation is better for top\nkeywords (in particular for AU).\nOverall, however, many keywords could\nnot be found (they often seem to be too\nspecific or cannot be matched without\nspecific expertise).\nTable 1. Keyword occurrence in\nWikipedia.\nRandom AU\nRandom PL\nTop 100 AU\nTop 100 PL\n\n1\n2\n9\n27\n15\n\n2\n5\n0\n20\n6\n\n3\n4\n2\n4\n3\n\n4\n6\n3\n16\n5\n\nStart years\nIn order to compare start years, exact,\nredirected and similar matches were\ntaken from the top samples. Table 2 and\nFigure 1 show the differences (in case of\nonly one dot, the start years are the\nsame).\n\nFigure 1. Comparison of Wikipedia and\nWoS start years (AU keywords).\n1958\n\nIn both samples the keywords seem to\nappear in Wikipedia before or\nsimultaneously to their start in the WoS\nin the vast majority of cases (Table 2).\nTable 2. Differences of start years.\nPL\nAU\n\nWoS&lt;Wiki\n5\n5\n\nWoS=Wiki\n11\n6\n\nWoS&gt;Wiki\n10\n52\n\nBut including the variants found while\nsearching Wikipedia pages (single\nwords, similar words and words leading\nto a redirection) and looking at them as\nkeywords in the WoS again provides a\ndifferent picture. 32 of the variants\nfound in the AU sample appear\nthemselves as WoS keywords; 25 (2 in\nthe PL sample) of them have start years\nbefore 2001 – the launching year of\nWikipedia – thus a comparison of start\nyears is no longer appropriate.\nConclusion and further work\nIn the top samples more keywords could\nbe found as titles of Wikipedia pages\nthan in the random samples. It is\npossible that more matches could be\nfound with specific expertise. Among\nthe matched keywords, in the vast\nmajority of cases the start in Wikipedia\nat first sight seems to be earlier than the\nstart in the WoS. In order to receive\nreliable results, however, more matched\nkeywords would be needed. For the\nfuture it would be interesting to look at\nother information of Wikipedia pages,\ne.g. redirections, links (as hints for\nkeyword unification or field delineation\ntasks) and page view statistics, e.g. to\nompare\nthe\ngrowth\nof\npublications/citations\nin\nscientific\ndatabases to the growth of page views in\nWikipedia (available since 2008), see\nFigure 3 for an example.\n\nAcknowledgement\nCertain data included herein is derived\nfrom the “Science Citation Index\nExpanded (SCIE) - Tagged Data”\nprepared\nby\nThomson\nReuters\n(Scientific) Inc. (TR®), Philadelphia,\nPennsylvania, USA: © Copyright\nThomson Reuters (Scientific) 2012. All\nrights reserved.\nReferences\nWikipedia.[http://en.wikipedia.org/]\n\nFigure 3. Example for a comparison of\npage views and publication counts.\n\n1959\n\nENTROPY-BASED DISCIPLINARITY INDICATOR:\nROLE TAXONOMY OF JOURNALS IN SCIENTIFIC\nCOMMUNICATION SYSTEMS.\nJorge Mañana-Rodríguez1\n1\n\njorge.mannana@cchs.csic.es\nConsejo Superior de Investigaciones Científicas, Centro de Ciencias Humanas y Sociales.\nMadrid, España, C/Albasanz 26-28, P.O. Box 28037. T.N.: (0034) 916022795.\nIntroduction\nIn recent decades, the study of\nmultidisciplinarity / disciplinarity has\nemerged as a core topic in science and\ntechnology studies and information &amp;\nlibrary science. IDR, Inter Disciplinary\nResearch (Wagner et al. 2011), is a key\naspect both for policymakers and\nresearchers (National Academies, 2005).\nIn this contribution, the author presents\na new indicator for measuring the\ndegree\nof\ndisciplinarity\nor\nmultidisciplinarity of scientific journals,\nboth in the citing and cited dimensions.\nThe specialization (or disciplinarity)\ndegree of the indicator is directly\nproportional to the percentage of\ncites/references from/to other journals of\nthe same discipline and inversely\nproportional to the Shannon entropy of\nthe distribution of cites/references\nfrom/to journals in disciplines different\nfrom the journal one.\nObjectives:\nIn this work the author seeks for a\nvector based indicator which values\nattempt to capture the degree of\ndisciplinarity or multidisciplinarity (the\nlatter corresponding to the definition in\nRafols &amp; Meyer, 2010) both in citing\nand cited dimensions using the\nminimum necessary information.\n\n1960\n\nTable 1. Interpretation of changes in the\nfrequency distribution of external\ncitations and associated entropy values.\nChange in\nfrequency\ndistribution of\nexternal citation\nΔ Number of\nSC’s involved (Δ\nin the diversity of\nsources)\n\nChange\nin\nentropy\nvalues\nΔH\n\nInterpretation\n\nΔ Unvenness of\nthe distribution of\ncitations among\nSC’S\n\n- ΔH\n\n- ΔH\nassociated\nmultidisciplin\narity\n\nΔ Associated\nmultidisciplinarity\n\nMethodology:\nOnce the data regarding the disciplinary\naffiliation of citing and cited journals in\nJCR Social Sciences Edition 2011, the\nindicator detailed in this section was\napplied to the journals belonging to the\nfirst quartile of JCR-SSCI 2011 Library\nand Information Science. If the journal\non which the indicator is being applied\nis classified in Information Science &amp;\nLibrary Science and it gets 17 citations\nfrom journal B which is classified in\nInformation Science &amp; Library Science\nas well as in Geography, those citations\nwill be counted as internal citations\n(Boolean “or”). The following table\nreflects the interpretation of the changes\nin the entropy values for the\ndenominator of the indicator.\n\nIndicator formulation:\nEntropy-Based Disciplinarity Indicator\n(EBDI):\n\n)\n\nResults:\n\nThe interpretation exemplified in this\ncase is only valid for journals; other\n\n2,12\nEBDI CITED\n\n1,11\n\nJournal of the Association for Information\nSystems; 1.56\n\nJOURNAL OF THE AMERICAN MEDICAL\nINFORMATICS ASSOCI...; 1.34\n\n1,33\n\n1,39\n\n1,39\n\n0,06\n\n0,01\n\nINTERNATIONAL JOURNAL OF GEOGRAPHICAL\nINFORMATION ; 0.02\n\nInternational Journal of Computer-Supported\nCollab...; 0\n\n0,13\n0,01\n\nINTERNATIONAL JOURNAL OF GEOGRAPHICAL\nINFORMATION ; 0.02\n\n0,06\n\nInternational Journal of Computer-Supported\nCollab...; 0\n\n0,01\n\n1,39\n\nTELECOMMUNICATIONS POLICY; 0.21\n\n0,25\n\nINFORMATION &amp; MANAGEMENT; 0.82\n\nTELECOMMUNICATIONS POLICY; 0.21\n\nJOURNAL OF HEALTH COMMUNICATION; 0.03\n\n0,73\nMIS QUARTERLY; 1.01\n\nJOURNAL OF THE AMERICAN MEDICAL\nINFORMATICS ASSOCI...; 1.34\n\nSCIENTOMETRICS; 1.43\n\nINFORMATION &amp; MANAGEMENT; 0.82\n\nJournal of Computer-Mediated Communication;\n0.26\n\n1,39\nJOURNAL OF INFORMATION TECHNOLOGY; 1.02\n\nINFORMATION SYSTEMS RESEARCH; 1.14\n\nJOURNAL OF THE AMERICAN SOCIETY FOR\nINFORMATION SC...; 1.14\n\nINTERNATIONAL JOURNAL OF INFORMATION\nMANAGEMENT; 1.22\n\nJournal of the Association for Information\nSystems; 1.56\n\nMIS QUARTERLY; 1.01\n\n0,13\n\n1,31\n\nJOURNAL OF INFORMATION TECHNOLOGY; 1.02\n\n0,01\n\n0,68\n\nJOURNAL OF HEALTH COMMUNICATION; 0.03\n\n0,68\n\nJOURNAL OF THE AMERICAN SOCIETY FOR\nINFORMATION SC...; 1.14\n\n0,25\n\n1,31\n\n1,33\n\n1,07\n\n1,17\n\n1,01\n\n1,11\n\nINFORMATION SYSTEMS RESEARCH; 1.14\n\n1,07\n\n0,73\n\n2,12\n\n1,17\n\nINTERNATIONAL JOURNAL OF INFORMATION\nMANAGEMENT; 1.22\n\n1,21\n\nCITED TRHRESHOLD (2.36)\n\nCITING THRESHOLD (1.33)\n\nSCIENTOMETRICS; 1.43\n\n1,29\n\nEBDI CITING\n\n1,01\n\nJournal of Computer-Mediated Communication;\n0.26\n\n4,23\n\nEUROPEAN JOURNAL OF INFORMATION SYSTEMS;\n1.66\n\nEUROPEAN JOURNAL OF INFORMATION SYSTEMS;\n1.66\n\nLOW\n\n1,21\n\nINFORMATION SYSTEMS JOURNAL; 1.8\n\nINFORMATION SYSTEMS JOURNAL; 1.8\n\nLOW\n\n1,29\n\nLIBRARY &amp; INFORMATION SCIENCE RESEARCH;\n2.36\n\nLIBRARY &amp; INFORMATION SCIENCE RESEARCH;\n2.36\n\nLOW\n\n4,23\n\nJournal of Informetrics; 2.45\n\n1,02\n\nANNUAL REVIEW OF INFORMATION SCIENCE AND\nTECHNOLOGY; 5.49\n\nHIGH\n\n1,02\n\nMIS Quarterly Executive; 2.87\n\nMIS Quarterly Executive; 2.87\n\nHIGH\n\n6\n\nANNUAL REVIEW OF INFORMATION SCIENCE AND\nTECHNOLOGY; 5.49\n\n4\n\nLOW\n\nSuggested\ninterpretation of\n6\nthe “role” of the\njournal in the Sc\nThe journal might\nbe at the\ndisciplinary core of\nits SC.\nThe journal can be\nconsidered a\n“knowledge\nimporter”.\nThe journal can be\nconsidered a\n“knowledge\nexporter”\nThe journal\nresearch front is\nnot clearly in that\nSC. Its thematic\nrelation to the SC\nis rather tangential.\n\n2\n\nDegree of\ndisciplinarity:\ncited\ndimension.\nHIGH\n\n0\n\nDegree of\ndisciplinarity:\nciting\ndimension.\nHIGH\n\n2\n\n2\n\nTable 2: suggested taxonomy of studied\nunits’ role according to the combination of\n4\ncategorized levels of EBDI.\n\n4\n\n6\n\n(Percentage of internal citations) is\nthe percentage of citations/refs from/to\njournals classified at least in the same\nsubject category as the unit on which\nthe indicator is being calculated\n6\n(percentage of internal citations).\nis the percentage that the\n( )\nentropy associated to the distribution of\n4\nexternal citations (from a different\nsubject category) represents respect the\nmaximum possible entropy associated2 to\nthe distribution of external citations (ln\nn, n being the maximum number of\n0\npossible SC’s in the system, adapted\nfrom Leydesdorff &amp; Rafols, 2011).\n\nJournal of Informetrics; 2.45\n\n(\n\nunits\nwould\nentail\ndifferent\ninterpretations (for example, in the case\nof a subject category, the “degree of\ndisciplinary isolation” could be the axis\nfor the interpretation).\n\nChart 1: Cited and citing indicators\nassociated to journals in the 1st quartile\n(FI) of Information Science &amp; Library\nScience SC in JCR Social Sciences Edition\n2011\n\nAs it can be observed in Chart 1, the\nAnnual Review of Information Science\nand Technology is a clear case of\nknowledge input multidisciplinarity;\npapers whose journals are classified in a\nwide variety of SC’s are cited by the\nauthors publishing in this journal, but\nthe papers published by the journal are\nmainly cited by authors publishing in\nother Information Science &amp; Library\nScience journals: it might be a\n“knowledge importer”.\n1961\n\nMIS Quarterly Executive is highly\ndisciplinary in both dimensions, cited\nand citing. Coherently with previous\nstudies’ results using other indicators\n(Leydesdorff and Rafols, 2011, Op.\nCit.),\nthis\njournal\nis\nhighly\nmonodisciplinary and might be taken as\na core journal, from a knowledge\nclassification perspective. It takes\nknowledge from its SC and transforms it\ninto something mainly interesting for\nresearchers publishing in that SC.\nThe Journal of Informetrics, though its\nvalues in the citing and cited dimensions\nare very close to the quartile threshold,\ncould be placed in the taxonomy as a\n“knowledge importer”, as in the case of\nthe Annual Review of Information\nScience and Technology, since it is\nhighly disciplinary in the cited\ndimension, but multidisciplinary in the\nciting dimension.\nInformation Systems Journal might be a\nclear example of “knowledge exporter”,\nsince it is disciplinary in the cited\ndimension but multidisciplinary in the\nciting\ndimension.\nThe\njournal\nknowledge input frontier is mainly in its\nown SC, but the research published in\n\n1962\n\nthe journal becomes interesting for\nresearchers in other disciplines. In the\nsame profile, it is possible to identify the\nJournal of Information Technology and\nthe journal Information &amp; Management.\nReferences\nNational Academies. (2005). Facilitating\ninterdisciplinary research.\nWashington, DC: National\nAcademies. In Press.\nLeydesdorff, L., &amp; Rafols, I., (2011).\nIndicators of the interdisciplinarity\nof journals: Diversity, centrality, and\ncitations. Journal of Informetrics,\n5(1), 87–100\nRafols, I., &amp; Meyer, M. (2010).\nDiversity and network coherence as\nindicators of interdisciplinarity: case\nstudies in bionanoscience.\nScientometrics, 82(2), 263–287.\nWagner, C. S., Roessner, J. D., Bobb,\nK., Klein, J. T., Boyack, K. W.,\nKeyton, J., Rafols, I., Börner, K.\n(2011). Approaches to understanding\nand measuring interdisciplinary\nscientific research (IDR): a review of\nthe literature. Journal of\nInformetrics, 5(1), 14-26.\n\nTHE EPIDEMIC OF RENAL DISEASE –AN\nEVALUATION OF STATUS (2005-2009)\nMona Gupta1, Divya Srivastava2, Sandhya Diwakar3, Arvind Singh Kushwah4\n1\n\ngmona7@gmail.com003, 2drdivya.srivastava@gmail.com,\nsandhyadiwakar@gmail.com, 4arvindsinghmca@yahoo.com\nScientist B, Indian Council of Medical Research, New Delhi 110029 India\n3\n\nRenal Disease is defined as a slow lose\nof renal function over time. This leads to\na decreased ability to remove waste\nproducts from the body and perform\nhomeostatic functions. There are four\nstages in Renal Diseases which are\nfollowing as:\nStages in Progression of Chronic Kidney\nDisease and Therapeutic Strategies\nComplications\n\nNormal\n\nScreening\nfor CKD\nrisk factors\n\nIncreased\nrisk\nCKD risk\nreduction;\nScreening for\nCKD\n\nDamage\n\n GFR\n\nKidney\nfailure\n\nCKD\ndeath\n\nDiagnosis\nEstimate\nReplacement\n&amp; treatment; progression;\nby dialysis\nTreat\nTreat\n&amp; transplant\ncomorbid\ncomplications;\nconditions;\nPrepare for\nSlow\nreplacement\nprogression\n\nThe symptoms of renal diseases can be\nunderstood by following means:\n\nThe literature survey has indicated that\nthere is no comprehensive work has\nbeen done by any researcher on this\ntopic. Therefore the present study would\nconcentrate on the work being carried\nout by Indian R &amp; D scientist’s vies-avisa Global researchers. The basic data\nfor the analysis has been culled out from\nMEDLINE by using search string\nkidney disease. There are total 2, 90,934\n\npapers indexed worldwide out of which\n5740 are Indian papers during 20052009. For mapping the data suitable\nanalytical software’s will be used. The\nmain Research Areas of CKD: Cronical\nkidney Disease, Renal Disease, Kidney\nfailure, Renal Failure, Renal Disease\nand Chronic kidney disease. In field of\nCronical Kidney Disease there are total\n1.20% workdone worldwide out of\nwhich India has its share of 7.53%,\nCardiovascular disease research share in\nworld context is 20.45% while out of\nwhich 5.57% papers are Indian, Renal\nFailure has maximum publication during\n2005-09(36.13%) while India has share\nof .49% only. There are 29.28%\nresearch in field of renal failure in world\ncontext out of which 1.54% share is\nfrom India. There are 13.04% research\nis on Kidney Failure Including Indian\nresearch share of 1.02%\n\nPublication Growth of Indian Papers in\nWorld Context during 2005-09\n\n1963\n\nResearch Progress of India in World\nContext:\nThere are 40942 papers published in\n2005 followed by 42213(2006),\n110650(2007), 47846(2008) and 49283\nduring 2009.\nResearch\nAreas\nCKD\nCVD\nRenal\nFailure\nRenal\nDisease\nKidney\nFailure\nTotal\n\n2005\n\n2006\n\n490\n601\n703\n11812 11244 11320\n6805 7214 74258\n\nTotal\nPapers\n800\n911\n3505\n12530 12600 59506\n8077 8419 104773\n\n15030 15940 16941\n\n18362 18934 85207\n\n6805\n\n8077\n\n7214\n\n2007\n\n7428\n\n2008\n\n2009\n\n8419\n\n37943\n\n40942 42213 110650 47846 49283 290934\n\nGrowth of Publication in different\nresearch areas during 2005-09\n\nThere is maximum research in Renal\nfailure.\n\nResearch profile of productive indian\nauthors in medicine:\nThe research activities of the most\nproductive 15 Indian authors in Renal\nDisease published 135 and above papers\nduring 2005-09. Of these, six authors\nare affiliated to AIIMS, New Delhi, two\nto\nNational\nInstitute\nof\nImmunohaematology, Mumbai, and one\neach to other institutions. These 10 most\nproductive authors together contributed\n575 papers in renal field during 200509, with an average of 5.75 papers per\nauthor and witnessed the growth of\n20.86% for the papers published from\n2005-09. Eight authors published higher\nnumber of papers than the group\naverage.\nKeyword Analysis:\nCalcium was topmost keyword followed\nby Anemia, Phosphorus, Cardivascular\nDisease and Chronik Kidney Disease\n\nAverage Growth of research areas during\n2005-09\n\n% of Keywords used during 2005-09\n\nThe Compound average growth shows\nthat there is a delectations in all fields\ncan be seen by following table.\n\nMedical colleges:\nResearch productivity and impact of top\n31 most productive Indian medical\ncolleges during 2005-2010\n\nResearch Areas\nCKD\nCVD\nRenal Failure\nRenal Disease\nKidney Failure\nTotal Papers Year Wise\n\n1964\n\nCAG\n-96.6515\n-96.2042\n-95.6189\n-94.7724\n-95.6189\n93.9152\n\nInstitute\nAIIMS, New\nDelhi\nSGPIMS,\nLucknow\nMaulana Azad\nMed Coll Delhi\nKMC, Manipal\nBHUIMS,\nVaranasi\nShree Chitra\nTirunal Inst Med\nSci Tech\nJIPMER\nPuducherry\nUni Coll Med\nSci Delhi\nGovt Med Coll\nHosp\nChandigarh\nPt. B D Sharma\nPost Grad Inst\nMed Sci\n\nTP\n\nTC\n\nACPP H-index\n\n650 1200\n\n1.85\n\n39\n\n567 1000\n\n1.76\n\n35\n\n500\n\n930\n\n1.86\n\n31\n\n450\n\n805\n\n1.79\n\n27\n\n425\n\n726\n\n1.71\n\n24\n\n398\n\n696\n\n1.75\n\n23\n\n312\n\n650\n\n2.08\n\n20\n\n200\n\n595\n\n2.98\n\n19\n\n158\n\n550\n\n3.48\n\n15\n\n111\n\n413\n\n3.72\n\n13\n\nTo conclude, CKD, CVD, Renal Failure,\nRenal Disease and Kidney Failure is a\nproblem of epidemic proportions in\nIndia, and with an increasing diabetes\nburden, hypertension, and growing\nelderly population it is going to increase\neven further. Managing the patient\npopulation. The money invested at this\ntime in establishing a prevention\nprogram for all these are definitely\ngoing to give results in years to come\nand ultimately in the long run will still\nbe cost-effective. This money can be\nutilized for other healthcare programs.\nHowever, it requires a lot of data and\nprofessional lobbying with various\npolicymakers, the MOHFW, and the\nGovernment of India.\n\n1965\n\nEUROPEAN HIGHLY CITED SCIENTISTS’\nPRESENCE IN THE SOCIAL WEB\nAmalia Mas-Bleda1, Mike Thelwall2, Kayvan Kousha3 and Isidro F. Aguillo4\n1\n\namalia.mas@cchs.csic.es\nSpanish National Research Council (CSIC), Institute of Public Goods and Policies, The\nCybermetrics Lab, C/Albasanz 6-28, 28037, Madrid (Spain)\n2\n\nM.Thelwall@wlv.ac.uk\nUniversity of Wolverhampton, School of Technology, Statistical Cybermetrics Research\nGroup, Wulfruna Street, WV1 1LY, Wolverhampton (United Kingdom)\n3\n\nK.Kousha@wlv.ac.uk\nUniversity of Wolverhampton, School of Technology, Statistical Cybermetrics Research\nGroup, Wulfruna Street, WV1 1LY, Wolverhampton (United Kingdom)\n4\n\nisidro.aguillo@cchs.csic.es\nSpanish National Research Council (CSIC), Institute of Public Goods and Policies, The\nCybermetrics Lab, C/Albasanz 6-28, 28037, Madrid (Spain)\nIntroduction\nThe web has given academics new ways\nto collect and disseminate the scholarly\ninformation (Chen et al. 2009; Pitzek\n2002) and they have taken advantage of\nthis in many different ways (Barjak,\n2006, Mas-Bleda &amp; Aguillo, in press;\nMas-Bleda et al, in press). Scientists’\nweb presences have also been\ninvestigated to some extent, often\nthrough personal websites (Barjak, Li &amp;\nThelwall, 2007). A survey of UK\nacademics found these people willing to\ntry free new social web sites but did not\nask about specific services (Procter et\nal., 2010) and another survey confirmed\nthat most were positive about social web\ninitiatives (Ponte &amp; Simon, 2011).\nAnother study of a convenience sample\nsurvey found that academics using one\ntype of social media site were more\nlikely to also use another, and that\nyounger researchers were a little more\nlikely to use the social web than older\n1966\n\nresearchers (Nicholas &amp; Rowlands,\n2011). It is unclear, however, how wide\nthe scholarly uptake of web tools is,\nwhich ones are used, and whether they\nare popular amongst the senior and most\ninfluential researchers.\nResearch questions\nThe objective of this work is to identify\nif an influential group of researchers,\nhighly cited scientists working at\nEuropean institutions, have different\ntypes of web presences: personal\nwebsites and research group websites as\nwell as profiles in Google Scholar,\nMicrosoft Academic Search (MAS),\nMendeley, Academia.edu and LinkedIn.\nThe questions guiding the research are:\n- What proportion of European Highly\nCited (EHC) scientists have these\nweb presences?\n- Are there differences among\ndisciplines?\n- Are younger scientists more likely to\nhave each kind of web presence?\n\nMethod\nEHC scientists were identified using the\nonline directory of highly cited\nresearchers and the previous version of\nthis database, both created by\nISI/Thomson\nReuters\n(www.highlycited.com/). Only 5% were\nwomen, so Microsoft Academic Search\nwas used to increase this percentage. A\ntotal of 1,583 EHC researchers were\nidentified. Deceased researchers were\nremoved to give a final population of\n1,517 scientists, 1,360 (90%) men and\n157 (10%) women. The scientists were\nthen grouped into five broad disciplines:\nengineering, physical sciences (in which\nmaths is included), health sciences, life\nsciences and social sciences. These data\nwere taken from a previous study (MasBleda et al, in press) and then updated.\nFinally, the web presences of the\nscientists were manually searched for\nbetween Nov. 2012 and March 2013.\nResults\nTable 1 shows the proportion of living\nresearchers with different web presences\nfor each discipline. Overall, this group\nof scientists had a low web presence,\nexcept for personal websites and for\nMicrosoft Academic Search. Perhaps the\nmost surprising result was the very low\nuse of Academia, especially for\nresearchers from hard sciences, health\nsciences and life sciences.\nConcerning disciplines, social scientists\nhad the most personal websites (83%),\nbut fewest research group websites\n(1%), suggesting a lack of cooperation\namong researchers in this discipline.\nThis group also had the largest\nproportion of Google Scholar profiles.\nIndependent samples median tests were\nconducted to see if the average age of\nthe scientists having a web presence\ndiffered from the average age of the\nscientists not having a web presence.\nEHC researchers with a personal\n\nwebsite or a profile in Google Scholar or\nLinkedIn, tended to be younger than\nthose who did not (Sig. 0.000 for the\nfirst two and Sig. 0.006 for LinkedIn).\nThe difference in medians was not large,\nhowever, at only three years in most\ncases except for personal websites (6\nyears) and Google Scholar profiles (6\nyears).\nTable 1. Percentage of EHC scientists with\ndifferent web presences for each\ndiscipline.\nDiscipline\nWeb\nEng.\nPhysical\nHealth Life Soc.\npresences\n(n=241) (n=353) (n=435) (n=413) (n=75)\nPersonal\n78.0% 76.5% 53.6% 52.5% 82.7%\nwebsite\nRes.\ngroup\n12.4% 14.7% 18.2% 22.0% 1.3%\nwebsite\nG.\n15.4% 8.8% 6.4% 7.0% 24.0%\nScholar\nMAS\n99.2% 99.2% 98.4% 98.5% 97.3%\nMendeley 6.2%\n4.2% 6.0% 7.7% 8.0%\nAcademia 4.1%\n0.6% 0.7% 0.7% 5.3%\nLinkedIn 27.0% 18.4% 29.0% 19.6% 25.3%\nEng. = Engineering; Physical = Physical sciences\nHealth = Health sciences; Life = Life sciences\nSoc. = Social sciences\n\nChi-square tests were also conducted to\nfor significant differences between types\nof web presence for each discipline. In\nengineering, researchers with profiles in\nLinkedIn also tended to have personal\nwebsite and profile in Google Scholar\nand Academia (p. &lt; 0.05), and those\nwith profiles in Google Scholar also\ntended to have profiles in Mendeley and\nLinkedIn.\nIn the physical sciences, researchers\nwith Google Scholar profiles also tended\nto have personal websites and profile in\nMendeley.\nIn\nhealth\nsciences,\nresearchers with personal websites\ntended to also have Google Scholar and\nLinkedIn profiles. In life sciences,\nresearchers with profiles in Mendeley\n1967\n\nalso tended to have profiles in Google\nScholar and LinkedIn. In social\nsciences, researchers with profiles in\nGoogle Scholar also tended to have\nprofiles in Academia and LinkedIn.\nConclusions\nThe results show that EHC scientists\ntend to have personal websites (created\nby themselves or by their institution)\nand Microsoft Academic Search profiles\n(created by Microsoft), but few have\ncreated a profile in any of the other\nacademic sites investigated. Perhaps\nsurprisingly, the only non-academic site\nin the list, LinkedIn, was the most\npopular social web site. Nevertheless,\nthis presence is much less widespread\nthan it found in a previous study (BarIlan et al, 2012).\nUnsurprisingly, however, there were\ndisciplinary differences in the most\npopular types of site used and younger\nresearchers were more likely to have a\npresence than older researchers in most\ntypes of site. Finally, researchers having\none type of profile were more likely to\nhave another in many cases, suggesting\nthat scientists tend not to restrict\nthemselves to just one type of social\nweb presence, if they choose to create\none at all.\nAcknowledgments\nThis work is supported by ACUMEN\n(Academic Careers Understood through\nMeasurement and Norms) project, grant\nagreement number 266632, under the\nSeventh Framework Program of the EU.\nReferences\nBarjak, F. (2006). The role of the\nInternet in informal scholarly\ncommunication. Journal of the\nAmerican Society for Information\nScience and Technology, 57(10),\n1350-1367.\n\n1968\n\nBarjak, F., Li., X. &amp; Thelwall, M.\n(2007). Which factors explain the\nweb impact of scientists’ personal\nhomepages? Journal of the\nAmerican Society for Information\nScience and Technology, 58(2), 200211.\nBar-Ilan, J., Haustein, S., Peters, I.,\nPriem, S., Shema, H. and Terliesner,\nJ. Beyond Citations: Scholars’\nVisibility on the Social Web. In\nProceedings of 17th International\nConference on Science and\nTechnology Indicators (pp. 98-109),\nMontréal: Science-Metrix and OST.\nChen, C., Sun, K., Wu, G., Tang, Q.,\nQin, J., Chiu, K. et al (2009). The\nimpact of internet resources on\nscholarly communication: a citation\nanalysis. Scientometrics, 81(2), 459474.\nMas-Bleda, A. &amp; Aguillo, I. (in press).\nCan a personal website be useful as\nan information source to assess\nindividual scientists? The case of\nEuropean highly cited researchers.\nScientometrics.\nMas-Bleda, A. Thelwall, M., Kousha, K.\n&amp; Aguillo, I. (in press). Successful\nresearchers publicizing research\nonline: an outlink analysis of\nEuropean highly cited scientists’\npersonal websites. Journal of\nDocumentation.\nNicholas, D. &amp; Rowlands, I. (2011).\nSocial media use in the research\nworkflow. Information Services &amp;\nUse, 31, 61-83.\nPitzek, S. (2002). Impact of onlineavailability of science literature.\nRetrieved March 7, 2013 from:\nhttp://www.vmars.tuwien.ac.at/cours\nes/ proseminar/doc/paperserver.pdf.\nPonte, D. &amp; Simon, J. (2011). Scholarly\ncommunication 2.0: Exploring\nresearchers&#x27; opinions on Web 2.0 for\nscientific knowledge creation,\nevaluation and dissemination. Serials\nReview, 37(3), 149-156.\n\nProcter, R., Williams, R., Stewart, J.,\nPoschen, M., Snee, H., Voss, A. &amp;\nAsgari-Targhi, M. (2010). Adoption\nand use of Web 2.0 in scholarly\n\ncommunications. Philosophical\nTransactions of The Royal Society A,\n368(1926), 4039-4056.\n\n1969\n\nEVALUATING THE INVENTIVE ACTIVITY OF\nFOREIGN R&amp;D CENTERS IN ISRAEL: LINKING\nPATSTAT TO FIRM LEVEL DATA\nDaphne Getz1, Eran Leck2 and Amir Hefetz3\n1\n\nDaphne@sni.technion.ac.il\nSenior Research Felllow, Samuel Neaman Institute for Advanced Studies in Science and\nTechnlogy, Technion – Israel Institute of Technoloy, Technion City, Haifa 32000 (Israel)\n2\n\nleck@sni.technion.ac.il\nResearcher, Samuel Neaman Institute for Advanced Studies in Science and Technlogy,\nTechnion – Israel Institute of Technoloy, Technion City, Haifa 32000 (Israel)\n3\n\nahefet01@campus.haifa.ac.il\nResearcher, Samuel Neaman Institute for Advanced Studies in Science and Technlogy,\nTechnion – Israel Institute of Technoloy, Technion City, Haifa 32000 (Israel)\nAbstract\nThe state of the art in patent statistics\ntoday involves linking patent data to\ncomplementary databases in an attempt\nto supply additional information on the\npatent’s assignees. Notable examples to\nthese types of databases are the plug &amp;\nplay extensions to PATSTAT – OECD\nHAN, the EEE-PPAT tables, OECD\nREGPAT and the OECD ORBIS\ndatabase (business register data). In this\nresearch we set out to investigate the\nscope of inventive activity conducted by\nmultinational companies that established\nlocal branches in Israel. The Israel\nVenture Capital (IVC) database was\nlinked to PATSTAT in order to analyse\nthe inventive activity of these firms. The\noutcome of this exercise resulted in the\ndevelopment of new globalization\nindicators and the attainment of high\nresolution data on the inventive\ncharacteristics of foreign R&amp;D centres\nin Israel.\n\n1970\n\nMethodology\n The unit of measurement for\ninventive activity is “distinct\ninvention” – the earliest (priority)\nfiling of the same application\nanywhere in the world.\n The distinct invention indicator is\nbased on the DOCDB family and is\naimed at neutralizing double\ncounting\nof\nidentical\npatent\napplications (inventions), as a result\nof their filing in different patent\noffices.\n An improved version of KUL&#x27;s EEEPPAT\ntables\n(assignee\nharmonization and sector allocation),\nfor PATSTAT was used to identify\nall foreign owned applications\nattributed to the business sector (Du\nPlessis et al., 2009).\n The resulting data subset was linked\nto\nfirm\nlevel\ndata\n(IVC)\nencompassing rich information on\nthe characteristics of 264 foreign\nR&amp;D centres in Israel.\n\n We are interested in identifying and\nanalysing inventions filed by\nmultinational\ncompanies\nthat\nestablished local branches (&quot;foreign\nR&amp;D centres&quot;) in Israel. The\nownership of these inventions is\nforeign, while the inventors are\nIsraeli.\nResearch Findings\n In the past decade the inventive\nactivity of foreign R&amp;D centres has\nrisen by 144% (Figure 1).\n\ninventions attributed to the business\nsector (Figure 3).\n\nFigure 2: Foreign R&amp;D centres&#x27; share of\ntotal Israeli distinct inventions (business\nsector).\n\nFigure 1 Number of distinct inventions\nfiled by foreign R&amp;D centres.\n\nFigure 3: Foreign R&amp;D centres&#x27; share of\ntotal foreign owned applications (business\nsector).\n\n Distinct inventions filed by IBM,\nSanDisk and Intel constituted 39%\nof the total inventive activity of\nforeign R&amp;D centres in Israel during\nthe 2006-2010 time period (Table 1).\n\n 75% of the inventive activity of\nforeign R&amp;D centres (Figure 4) is\nconducted by well established firms\n(more than 30 years, e.g. Intel, IBM)\nor by new R&amp;D centres in Israel (110 years, e.g. Qualcomm, Samsung).\n\nTable 1: Distinct inventions filed by\nforeign R&amp;D centres (top assignees).\nR&amp;D centre\nIBM\nSanDisk\nIntel\nHP\nMicrosoft\nQualcomm\n\nAll R&amp;D\ncentres\n\n2001-2005\n491\n75\n484\n172\n66\n55\n\n2006-2010\n463\n394\n321\n168\n142\n121\n\n2679\n\n3016\n\n In 2011, the inventive activity of\nforeign R&amp;D centres in Israel\nconstituted 27% of total Israeli\ndistinct inventions (Figure 2) and\n61% of total foreign owned distinct\n\nFigure 4.Distribution of distinct\ninventions filed by foreign R&amp;D centres\nby years of activity in Israel.\n\n More than 95% of distinct inventions\nare attributed to the high technology\nand medium-high technology sectors\n(Figure 5).\n\n1971\n\n In the 1990-2010 time period, at\nleast 1361 distinct inventions were\ntransferred from the ownership of\nIsraeli companies or start-ups to the\npossession of foreign R&amp;D centres\n(MNCs), due to acquisitions or\nmergers (Figure 6, Table 2).\n These 1361 distinct inventions\nconstitute approximately 13.5% out\nof the total patent portfolio of the\nR&amp;D centres.\n\nFigure 5: Distribution of distinct\ninventions by technological intensity.\n\nFigure 6: Number of distinct inventions\nacquired from Israeli firms by foreign\nR&amp;D centres as a result of acquisitions or\nmergers.\n\n1972\n\nTable 2: Distinct inventions acquired from\nIsraeli firms (top acquirers).\nName prior to Current\nacquisition\nR&amp;D centre\naffiliation\nIndigo\nHP\nMedingo\nRoche\nAladdin\nSafenet\nM-Systems\nSanDisk\nAnobit Tech.\nHDC Apple\n\nDistinct\ninventions\n134\n70\n60\n53\n45\n\nConclusions\nIn the past decade, the rate of transfer of\nIsraeli IP, know-how and technology to\nthe possession of foreign R&amp;D centres\nhas substantially increased.\n There is a significant rise in the\nabsolute\nnumber\nof\ndistinct\ninventions filed by foreign R&amp;D\ncentres and in their respective share\nout of total Israeli inventive activity.\n Increasing trend of obtaining Israeli\nIP by means of acquisition of Israeli\nfirms and start-ups. Acquired patents\nare becoming a substantial share out\nof the total patent portfolio of\nforeign R&amp;D centres in Israel.\n These trends should be taken into\naccount in the evaluation of Israel&#x27;s\nnational R&amp;D policy.\nReferences\nDu Plessis, M., Van Looy, B., Song, X.,\n&amp; Magerman, T. (2009). Data\nproduction methods for harmonized\npatent indicators: Assignee sector\nallocation. EUROSTAT Working\nPaper and Studies, Luxembourg.\n\nEVALUATION OF RESEARCH IN SPAIN:\nBIBLIOMETRIC INDICATORS USED BY MAJOR\nSPANISH RESEARCH ASSESSMENT AGENCIES\nAlicia F. Gómez-Sánchez1 and Rebeca Isabel-Gómez2\n2\n\nafgomez@cnic.es\nFundación Centro Nacional de Investigaciones Cardiovasculares (CNIC).\nC/ Melchor Fernández Almagro, 3 28029 Madrid (Spain)\n2\n\nrebeca.isabel.ext@juntadeandalucia.es\nAgencia de Evaluación de Tecnologías Sanitarias de Andalucía (AETSA).\nAvda. Innovación. Edificio ARENA . 41020 Sevilla (Spain)\nIntroduction\nOne of the most important current\napplications\nof\nbibliometrics\nis\nassessment of research, and bibliometric\nindicators can be considered as tools for\nthe evaluation of the scientific\nproductivity of an individual researcher,\na group or an institution.\nTaking this as a starting point, we would\nlike to check who is setting the patterns\nfor scientific output evaluation in Spain\nin the area of biomedicine: What\nindicators have been used in recent\nyears by funding and evaluating\ninstitutions in Spain? Are these\ninstitutions appropriately exploiting the\nresources provided by the bibliometry?\nWhat factors should be taken into\naccount when defining indicators? What\nare the most accurate indicators for\nmeasuring research and performance? In\nbrief, our objective is to observe the\nindicators and criteria that are being\nused by the main Spanish Agencies for\nthe evaluation of researchers and\ninstitutions in Spain.\nMethods\nThis study analyses the evaluation\ncriteria and indicators used by the major\nagencies of the Spanish research\n\nevaluation system. They are the\nNational Assessment and Planning\nAgency\n(ANEP),\nthe\nNational\nEvaluation Commission for Research\nActivity (CNEAI) and the National\nAgency for Quality Assessment and\nAccreditation (ANECA). We compared\nthe indicators used with the main\ncharacteristics\nof\nscientific\ncommunication and publications in the\narea of health sciences and we make\nsome recommendations for measuring\nscience in a more accurate way.\nResearch Evaluation in Spain: Results\nResearch assessment in Spain for a long\ntime had two broad objectives: the preevaluation of research projects for\nfinancing and the external evaluation of\nthe research activity of individual\nresearchers over six-year periods, called\nsexenios. In recent years, we have seen\nthe introduction of other kinds of\nevaluation, for example to provide\naccreditation\nto\ninstitutions\nof\nexcellence or simply to measure\nresearch activity.\nRegarding the indicators and criteria\nused, the quantity of publications is the\nmost demanded criteria for being\nevaluated. The majority of the\nevaluation programs in Spain consider\n1973\n\nabsolute data (number of publications,\nIF, citations, etc.), do not take into\naccount normalized indicators.\nTable 1. Main objectives of Spanish\nAgencies for evaluation of researches.\n\nTypes and proportions or collaborations,\nas well as productivity calculated by\ncounting the number of publications per\nperson and year. The impact factor (IF)\nof the journals is other of the most\nimportant criteria used. The most\ncommon database used in Spain is the\nISI WoS.\nTable 2. Main Indicators used by Spanish\nAgencies for evaluation of researches.\nIndicators used\nOutput\nNormalizad\nImpact\nHigh Quality\nPublications\n(Q1/D1)\nLeadership\nCites per\nDocument\n\nANECA CNEAI ANEP\n\n\n\n\n\n\n\n\n\n\n\n\n\nConclusions and recommendations\nThe\nemployment\nof\nexcellence\nindicators (10% most cited papers in\ntheir respective fields or in topjournals), should be more extended.\nMoreover, other aspects as leadership\nand visibility should be also bear in\nmind.\n1974\n\nFor measuring individual investigators\nother indicators as the h-index or\nnormalized indicators as the crown or\nthe SNIP should be recommendable.\nMoreover, self-citations are usually not\nconsidered and much less uncitedness,\nwhich is not considered at all. It would\nbe also interesting to think about the\nnumber and percentage of documents\ncited and not cited.\nIn order to have a more global and\ncomplete evaluation it would be\nessential to combine different indicators\nand develop an evaluation program\nallowing\na\nmultidimensional,\ncomprehensive assessment, depending\non the needs and objectives of the\nassessment. Furthermore, differences\nshould be taken into account within\ndifferent subject areas. For instance, as\nindicated by the ANEP, in the context of\nhealth sciences it should be considered\nif the results of basic research and\npreclinical are transferred to clinical or\napplied science (e.g. through clinical\nguidelines) and to innovation. To that\neffect, the number of patents or utility\nmodels should also be taken into\nconsideration.\nRecent recommendations, as the &quot;San\nFrancisco Declaration on Research\nAssessment&quot;,\nconfirm\nthe\nhigh\nimportance to review the way scientific\nresearch is evaluated.\nAs a final point, other alternative\nsources and toolkits, for instance the\nF1000 Journal Rankings, ALTmetrics or\nArticle-Level Metrics, should be also\ntaken into account as an alternative\napproach to evaluate the scientific\nimpact of scholarly communications.\nFinally, the way scientific production is\nmeasured in Spain seam not to be really\naccurate and the instruments used are\nnot taking advantage of the real\nevolution of Bibliometrics science.\nPerhaps current development of\nbibliometric units in universities and\nresearch institutions could help to\n\nmaximize\nbenefits\nbibliometrics advances.\n\nfrom\n\nthe\n\nReferences\nANECA. (2013).Agencia Nacional de\nEvaluación de la Calidad y\nAcreditación (ANECA). Retrieved\njanuary, 2013 from\nhttp://www.aneca.es/ANECA\nANECA. (2008). Programa\nACADEMIA. Principios y\nOrientaciones para la Aplicación de\nlos. Criterios de Evaluación.\nRetrieved january, 2013 from\nhttp://www.aneca.es/content/downlo\nad/10527/118089/version/1/file/acad\nemia_14_ppiosyorientaciones.pdf\nANECA. (2010). Informe sobre el\nestado de la evaluación externa de la\ncalidad en las universidades\nespañolas 2010. Retrieved january,\n2013 from\nwww.aneca.es/content/download/12\n369/152900/file/informe_calidadenu\nnis10_120312.pdf\nANECA. (2011). Programa de\nevaluación de profesorado para la\ncontratación: Guía de ayuda al\nsolicitante. Retrieved january 2013\nfrom\nhttp://www.aneca.es/content/downlo\nad/12045/135410/file/pep_guiadeayu\nda_120118.pdf\nMinisterio de Educación Cultura y\nDeporte. (2013). Comisión Nacional\nEvaluadora de la Actividad\nInvestigadora (CNEAI). Retrieved\njanuary 2013 from\nhttp://www.mecd.gob.es/ministerio-\n\nmecd/organizacion/organismos/cneai\n.html\nHuggett, S. (2012). F1000 Journal\nRankings: an alternative way to\nevaluate the scientific impact of\nscholarly communications. Research\nTrend, 26, 7-10.\nMinisterio de Educación Cultura y\nDeporte. (2012). Resolución de 19\nde noviembre de 2012, de la\nComisión Nacional Evaluadora de la\nActividad Investigadora, por la que\nse establecen los criterios\nespecíficos en cada uno de los\ncampos de evaluación. Retrieved\njanuary 2013 from\nhttp://www.boe.es/boe/dias/2012/11/\n29/pdfs/BOE-A-2012-14633.pdf\nMinistry of Economy and\nCompetitiveness. (2012). National\nEvaluation and Foresight Agency\n(ANEP). Retrieved january 2013\nfrom\nhttp://www.idi.mineco.gob.es/portal/\nsite/MICINN/menuitem.29451c2ac1\n391f1febebed1001432ea0/?vgnextoi\nd=3cb39bc1fccf4210VgnVCM1000\n001d04140aRCRD\nSan Francisco Declaration on Research\nAssessment. Putting science into the\nassessment. Recommendations of\neditors and publishers of scholarly\njournals during the Annual Meeting\nof The American Society for Cell\nBiology (ASCB) in San Francisco,\nCA, on December 16, 2012.\nSanz-Menéndez, L. (1995). Research\nactors and the state: research\nevaluation and evaluation of science\nand technology policies in Spain.\nResearch Evaluation, 5(1), 79-88.\n\n1975\n\nAN EXPERIENCE OF THE INCLUSION A NEW\nMETHODOLOGY IN SELECTING THE\nREVIEWERS FOR GRANT APPLICATIONS\nPrimoz Juznic1, Robert Matoh2 and Doris Dekleva Smrekar3\n1\n\nprimoz.juznic@ff.uni-lj.si\nUniversity of Ljubljana, Faculty of Arts, Department of Library, Information Science and\nBook Studies, Aškerčeva 2, 1000 Ljubljana (Slovenia)\n2\n\nmatoh1@siol.net\nBiomedical Research and Innovative Society, Puhova ulica 10, 1000 Ljubljana (Slovenia)\n3\n\ndoris.dekleva@ctk.uni-lj.si\nCentral Technological Library at the University of Ljubljana, Trg republike 3, 1000\nLjubljana (Slovenia)\nIntroduction\nIn Slovenia, to each annual Call for\nresearch projects proposals by the\nSlovenian Research agency about 1,000\napplicants apply. The project selection\nprocess takes place in two stages. In the\nevaluation of projects in first phase\nseveral criteria are used (Juznic et al,\n2010), a combination of bibliometric\nindicators and peer reviews. In the\nsecond phase only peer review\nevaluation in the form of rating, is used.\nIt is important to provide an effective\nand transparent process of selecting\nreviewers, while it is the most part of the\nevaluation of research projects (Lee et\nal, 2013). Modern ways of seeking\nreviewers should provide intellectual\nawareness of the reviewers, the\nexclusion of the conflict of interests or\nprofessional association and it is\ndesirable a good responsiveness of the\ninvited reviewers. (Harley and Acord,\n2011)\nTo evaluate the peer review procedure\nwe analysed the relationship between\nbibliometric methods and expert\nevaluation of proposed projects, the\n1976\n\nresponse of the reviewers and as\npresented in this paper, a degree of\nreliability of the referees&#x27; grades using\nthe &quot;intraclass correlation&quot; method.\nMaterials and Methods\nApplicants have been divided by the six\nmajor research disciplines within the\nsciences according to Slovenian\nResearch Agency Field of research\nClassification (Natural sciences and\nmathematics, Engineering sciences,\nMedical sciences, Biotechnical sciences,\nSocial sciences and Humanities), further\non into greater number of sub-fields and\nfinally by thematically related topics\ninto &quot;clusters&quot; of up to five applications.\nEach project were suppose to have three\nreviewers.\nMain tool for searching and the\nselection of reviewers was Reviewer\nFinder. Basically Reviewer Finder uses\na semantic search, but it also provides a\nlist of potential reviewers with\nindicators of expertise and possible\nconflicts of interest by entering the\ndetails from the application of entire\ncluster (http://info.scival.com/reviewerfinder ). The list of potential reviewers\n\nwere filtered by the criteria of the\nresearchers publishing (h-index, their\nreview publications, publishing in recent\nyears), as well as geographic origin\n(Europe)\nto\nmaximize\ntheir\nresponsiveness.\nUsing Reviewer Finder 544 reviewers\nwere selected. The goal was to find\nsame three reviewers for the evaluation\nof one “cluster” of similar projects.\nAlthough it was not possible for all\nreviewers who were eligible for the\nassessment for more than two projects\nwe found.\nThe biggest share of reviewers, who\naccepted the Agency ́s invitation, came\nfrom Portugal, Finland and Greece (over\n40%). The Italian reviewers were third\nmost numerous in regard of overall sent\ninvitations for participating in this Peer\nevaluation (47), only behind UK (89)\nand\nGermany\n(76),\nbut\ntheir\nresponsiveness score was also above\naverage with 39%. The poorest response\nwas from some Scandinavian countries\n(Sweden and Denmark) and France and\nSwitzerland.\nOne possible assumption, which has\narisen in this case was, that the\nresearchers with higher h-index would\nmore likely to refuse the participation in\npeer evaluation. T-test revealed that in\nthe majority of fields h-index of a\nresearcher was not a determining factor\nin the decision to enter peer review\nprocess.\nIn the research we wanted to assess the\nreliability of the reviewers grades. To\nmeet this aim, a measure of Intraclass\nCorrelation Coefficient (ICC) was used\n(Nichols, 1998). This is a tool, a general\nmeasurement\nof\nagreement\nor\nconsensus, where the Coefficient\nrepresents agreements between two or\nmore raters or evaluation methods on\nthe same set of subjects. ICC has\nadvantages over correlation coefficient,\nin that it is adjusted for the effects of the\nscale of measurements, and that it will\n\nrepresent agreements from more than\ntwo reviewers. The goal was to compare\nthe reliability of grades within the same\nset of reviewers.\nA total of 313 project proposals from 61\nscientific disciplines were included in\nthe study, where each discipline was\nconsidered its own unit of the analysis.\nIn other words, the main goal was to\nmeasure absolute agreement between\nraters/reviewers on each scientific field.\nBecause the same sets of reviewers were\nnot always used in peer evaluation\ninside one discipline (especially when\nthere were more than four or five\napplicants), we must also stress, that\naccording model of ICC was used. In\nthat way, two coefficients were\ncalculated: beside above mentioned\ncoefficient of absolute agreement, which\nis an index for the reliability of different\nreviewers averaged together, the index\nfor the reliability of the ratings for one,\nsingle reviewer, usually lower of the\ntwo, computed by MedCalc statistical\nsoftware, was calculated.\nResults and Discussion\nPositive correlation coefficients were\ndiscovered in 46 out of 59 disciplines,\nwhich is almost 15% better result than in\nthe previous call of proposal, where\nReviewer finder was not used as\nextensively.\nConcerning the level of the reliability, it\nhas been revealed, that the border of\nICC=0,300, which in our case is\nconsidered as a solid level of\nreliability/agreement among reviewers,\nwas surpassed by 76,09% of the\ndisciplines, compared to 71,42% from\nprevious period.\nThe reviewers searching process using\nReviewer Finder, generally turns\nadequate for searching same reviewers\nfor more than one project. Their\nresponse was satisfactory and the\nanalysis also showed a high degree of\n1977\n\nreliability assessment for the majority of\nfields.\n\nNatural sciences and\nmathematics\n\nEngineering sciences and technologies\n\nMedical Sciences\n\nBiomedical\nsciences\n\nSocial sciences\n\nHumanities\n\nICC average measures\n\nGeography\nTheology\nPhilosophy\nArt History\nMusicology\nLiterary sciences\nCulturology\nLinguistics\nEthnology\nAnthropology\nArchaeology\nHistory\nEthnic studies\nSports\nPsychology\nUbranism\nPolitical sciences\nLaw\nAdministrative and organisational sciences\nSociology\nEkonomics\nEducational studies\nBiotechnology\nVeterinarian medicine\nPlant production\nAnimal production\nForestry, wood and paper technology\nPsychiatry\nPublic health\nMetabolic and hormonal disorders\nCardiovascular system\nHuman reproduction\nOnkology\nNevrobiology\nMicrobiology and immunology\nCommunications technology\nHydrology\nTraffic systems\nMetrology\nTextile and leather\nProcess engineering\nElectric devices\nMechanical design\nManufacturing technologies and systems\nElectronic components and technologies\nTelecommunications\nComputer Science and informatics\nSystemy and cybernetics\nMaterials science and technology\nEnergy engineering\nChemical engineering\nCivil engineering\nPharmacy\nControl and care of the enviroment\nComputer intensive methods and applications\nGeology\nBiochemistry and molecular biology\nBiology\nChemistry\nPhysics\nMathematics\n\nPrevious period\nCurrent period\n\n0\n\n0,2\n\n0,4\n\n0,6\n\n0,8\n\n1\n\n1,2\n\nFigure 1. The ICC average measures by\nresearch fields for the current and\nprevious period\n\n1978\n\nReferences\nHarley, D. and Acord, S. K. (2011).\nPeer Review in Academic Promotion\nand Publishing: Its Meaning, Locus,\nand Future. Retrieved September 31,\n2012 from:\nhttp://escholarship.org/uc/item/1xv1\n48c8#page-1\nLee, C. J., Sugimoto, C. R., Zhang, G.\nand Cronin, B. (2013). Bias in Peer\nReview. Journal of the american\nsociety for information science and\ntechnology, 64(1), 2–17.\nNichols, D. P. (1998). Choosing an\nintraclass correlation coefficient.\nRetrieved December 13, 2011 from:\nhttp://www.sph.emory.edu/observera\ngreement/spss.pdf .\nJuznic, P. , Peclin, S. , Zaucer, M.,\nMandelj, T. , Pusnik, M. and\nDemsar, F. (2010). Scientometric\nindicators: peer-review, bibliometric\nmethods and conflict of interests.\nScientometrics, 2, 429-441.\n\nEXPLORING INTERDISCIPLINARITY IN\nECONOMICS THROUGH ACADEMIC\nGENEALOGY: AN EXPLORATORY STUDY\nChaoqun Ni1 and Cassidy R. Sugimoto1\n1\n\n{chni, sugimoto}@indiana.edu\nSchool of Library and Information Science, Indiana University Bloomington,\nBloomington, IN 47405 (USA)\nIntroduction\nInterdisciplinarity has been heavily\nstudied by scientometricians (e.g.,\nLeydesdorff, 2007), mostly relying on\nISI-indexed journals and intercitations\nbetween journals and JCR subject\ncategories\nas\nindicators\nof\ninterdisciplinarity (e.g., Cronin &amp; Meho,\n2007). Few studies have examined\n“author-based\nindicators\nof\ndisciplinarity” (Sugimoto, Ni, Russell,\n&amp; Bychowski, 2011) and those that do,\ntypically focus on co-authorship and\ndisciplinary affiliation of the author to\nclassify disciplinarity (e.g., Schummer,\n2004). However, there are several\nlimitations to such an approach: journal\narticles are not the sole genre of\nscholarly dissemination and are likely to\nskew impressions of disciplinary\ninteraction due to the wide difference in\nproduction\nrates;\nand\nusing\ncollaboration neglects the many\ndisciplines for which sole authorship is\nstill the norm (Ni, Sugimoto, &amp; Jiang,\n2013).\nDoctoral dissertations provide a useful\nalternative for scientometric research.\nAll research disciplines produce\ndissertations; therefore, this genre does\nnot favour certain disciplines. Each\nindividual produces only a single\ndissertation in each discipline; therefore,\ndissertations are not skewed in the\ndirection of subdomains or authors who\n\nmight be inordinately prolific. Finally,\ndissertations provide the opportunity to\nstudy mentoring through advisorship, a\nrelatively unexplored network structure\nfor scientometric research (Russell &amp;\nSugimoto, 2009).\nThis paper extends previous work done\nin the areas of LIS and Sociology\n(Sugimoto, Ni, Russell, &amp; Bychowski,\n2011; Ni &amp; Sugimoto, 2012, 2013) by\nusing the approach of academic\ngenealogy\nto\nexplore\nthe\ninterdisciplinary\ncomposition\nof\nEconomics (Sugimoto, Ni, Russell, &amp;\nBychowski, 2011; Ni &amp; Sugimoto,\n2012; 2013).\nData Collection &amp; Processing\nThis paper relies on the dissertation data\nprovided\nby\nProQuest\ndatabase\n(hereafter PQuest). PQuest covers over\n2.3 million dissertations from about\n1,490 institutions across 66 countries\nfrom the last two centuries. This project\nutilized a subset of the PQuest: those\nlisted in the Economics Subject\nCategory. Thus, any dissertations in\nPQuest with one of their SCs belonging\nto Economics were considered as an\nEconomics dissertation—thus allowing\nthe SC to serve as a proxy for a\ndiscipline. As shown in figure 1, each\nrow is a PQuest Subject Category\n(hereafter SC), and a dissertation can be\nassigned\nto\nmultiple\nSCs.\nA\ndissertations can be assigned with single\n1979\n\nor multiple SCs, and multiple SCs might\nbelong to the same discipline.\nResults Analysis &amp; Conclusions\nOverview of Economics in PQuest\nEconomics is a discipline with long\nhistory and large number of graduates.\nIn PQuest, the earliest Ph.D. dissertation\nwas finished at the year of 1899 at Yale\nUniversity.\nThere\nare\n76,336\ndissertations of Economics in PQuest,\ndistributed unevenly across decades, as\nshown in table 1. Additionally, one of\nthe most important information used in\nthis project, the advisor of each\ndissertation, is not available for all\ndissertations. As shown in table 1, there\nare\nin\ntotal\n41,317\n(54.13%)\ndissertations which provide advisor\ninformation, and majority of which\nconcentrate on the most recent two\ndecades.\nTable 1. Number of Economics\nDissertation &amp;Advisor-available\nDissertation by Decade\nDecade\n≤1900&#x27;S\n1910&#x27;S\n1920&#x27;S\n1930&#x27;S\n1940&#x27;S\n1950&#x27;S\n1960&#x27;S\n1970&#x27;S\n1980&#x27;S\n1990&#x27;S\n≥2000&#x27;s\nTotal\n\n#Diss\n2\n2\n4\n30\n93\n1976\n6903\n10809\n12923\n20687\n22907\n76336\n\n#Diss_Advisor\n0\n1\n0\n0\n0\n11\n0\n4\n2599\n17364\n21338\n41317\n\n%\n0.00%\n50.00%\n0.00%\n0.00%\n0.00%\n0.56%\n0.00%\n0.04%\n20.11%\n83.94%\n93.15%\n54.13%\n\nThe 76,336 dissertations were finished\nby graduates of 497 institutions across\n22 countries, of which 98.21% were\nfinished in institutions located in North\nAmerica. This is probably due to the\nfact that ProQuest itself is North\nAmerican dominant.\n\n1980\n\nOverview of Economics Advisors in\nPQuest\nAs mentioned above, only 41,317\ndissertations\nprovided\nadvisor\ninformation in PQuest, i.e. 15,191\nunique advisors. Only 4,544 (23.67%)\nadvisors were able to be identified for\nthe dissertations (for which these\nadvisors were granted their degrees) in\nPQuest. These advisors, however,\naccount for 47.76% of the total\nadvisorships. For those unique advisors\nidentified, they obtained their degree\nfrom 310 institutions located in 10\ncountries. About 95% of these\ninstitutions are located at U.S.. Harvard\nUniversity ranks first by exporting 211\nadvisors to the discipline of Economics,\nand Stanford University ranks second.\nThe\nDisciplines\nof\nEconomics\nAdvisors\nEconomics advisors got degrees from 76\ndifferent\ndisciplines\n(including\nEconomics). About 82.35% have their\ndissertations only categorized into a\nsingle discipline, and 17.65% of\nadvisors multiple disciplines. It seems\nthat Economics is the major discipline\nexporting advisors to its own field, and\nBusiness Administration and Political\nScience are the second and third. Figure\n1 displays the percentage of advisors\nwho received their degrees in each\ndecade in each of top 10 disciplines.\nEconomics, Business Administration,\nEngineering, Statistics and Health\nSciences are increasingly interacting\nwith Economics over time, by exporting\nadvisors to Economics. On the other\nhand, Political Science, History, and\nPsychology are these three disciplines\nexporting fewer advisors to Economics\nover time.\nThe dissertation of Economics advisors\ncan have only Economics as its\ndiscipline (EcoOnly), Economics and\nother disciplines as its disciplines\n\n(EcoMix), or non-Economics disciplines\nas its disciplines (NonEco). As shown in\nFigure 2, the percentage of advisors\nreceiving their degrees purely in\nEconomics has decreased in the last two\ndecades, while that with a mixture of\nEconomics and other disciplines are\nincreasing. Meanwhile, the percentage\nof Economics advisors receiving\ndegrees from NonEco disciplines is\nincreasing in the last two decades.\n\nFigure 1 Percentage of Economics\nAdvisors Exported by each Discipline by\nDecade\n\nFigure 2. Percentage of EcoOnly, EcoMix\n&amp; NonEco Advisors by Decade\n\nFuture Work\nThis is an in-progress project and only\nshows a preliminary result. The future\nplan on this project is to solve some\nlimitations we encountered. First of all,\nnot all dissertations have advisor\ninformation. For better diachronic\nstudies, manual data collection of these\nadvisors will be necessary. Second,\nauthor-name disambiguation is still not\nperfectly\naccurate\nand\nrequires\nadditional refinement. Lastly, using SCs\nas a proxy for disciplinarity introduces\n\nsome limits to interpretations. Hence,\nfuture efforts will be made to refine\nthese methods and add additional\ndisciplines in order to generate a better\nunderstanding of the interaction of\ndisciplines through academic genealogy.\nAcknowledgments\nThis work was supported by the Faculty\nResearch Support Program from Indiana\nUniversity and the National Science\nFoundation (SciSIP program) (Grant\nNo. SMA-1158670). The authors would\nalso like to thank ProQuest for making\nthis data available for research.\nReference\nCronin, B., &amp; Meho, L.I. (2007). The\nshifting balance of intellectual trade\nin Information Studies. Journal of\nthe American Society for Information\nScience and Technology, 59(4), 551564.\nLeydesdorff, L. (2007). Betweenness\ncentrality as an indicator of the\ninterdisciplinarity of scientific\njournals. Journal of the American\nSociety for Information Science and\nTechnology, 58(9), 1303-1319.\nNi, C., &amp; Sugimoto, C. R. (2012). Using\ndoctoral dissertations for a new\nunderstanding of disciplinarity and\ninterdisciplinarity.ASIST, Baltimore,\nMD.\nNi, C., &amp; Sugimoto, C. R. (2013).\nAcademic genealogy as an indicator\nof interdisciplinarity: a preliminary\nexamination of sociology doctoral\ndissertations. iConference 2013.\nNi, C., Sugimoto, C. R., &amp; Jiang, J.\n(2013). Venue-Author-Coupling: A\nNovel Measure of Identifying\nDisciplines through Author\nCommunities. Journal of the\nAmerican Society for Information\nScience and Technology. 64(2), 265–\n279.\n\n1981\n\nSchummer,J.(2004).Multidisciplinarity,i\nnterdisciplinarityand patterns of\nresearch collaboration in\nnanoscience and nanotechnology.\nScientometrics, 59(3), 425-465.\nSugimoto, C. R., Ni, C., Russell, T. G.,\n&amp; Bychowski, B. (2011). Academic\n\n1982\n\ngenealogy as an indicator of\ninterdisciplinarity: An examination\nof dissertation networks in Library\nand Information Science. Journal of\nthe American Society for Information\nScience and Technology.\n62(9),1808-1828.\n\nFEATURES OF INDEX TERMS AND NATURAL\nLANGUAGE WORDS FROM THE PERSPECTIVE\nOF EXTRACTED TOPICS\nRitsuko Nakajima1 and Nobuyuki Midorikawa2\n1\n\nnakajima@u.tsukuba.ac.jp\nGraduate School of Library, Information and Media Studies,\nUniversity of Tsukuba, 1-2 Kasuga, 305-8550 Tsukuba (Japan)\n2\n\nmidorika@slis.tsukuba.ac.jp\nFaculty of Library, Information and Media Science,\nUniversity of Tsukuba, 1-2 Kasuga, 305-8550 Tsukuba (Japan)\nIntroduction\nImportant databases are equipped with\ncontrolled indexes, which are essentially\ncontrolled vocabularies based on a\nthesaurus. Controlled indexing is a\nhighly reputed system as it has many\nadvantages such as enabling high recall\nand precision in search. However, it also\nhas some drawbacks; for instance, it\nrequires experts, which increases the\ncost, and it hinders quick reporting.\nRecently, many database services have\nintroduced automatic indexing to solve\nthese problems. According to Abdou &amp;\nSavoy (2008), only a few studies have\ndirectly compared the performances of\nmanual\nand\nautomatic\nindexing\nmethods. In this study, we extracted the\ninformation on research topics from\nnatural language words and manually\nindexed terms and compared the\nfeatures of each from the viewpoint of\ntopic extraction.\nMethod\nTo understand the difference between\nthe features of natural language and\ncontrolled vocabulary, we extracted\ninformation from a bibliographic\ndatabase to perceive that research topics\nemerge, develop, and decline. For data\n\nsources, we used abstracts and index\nterms. Among previous studies on the\nanalyses of research trends obtained\nfrom bibliographic databases, recent\nworks based on index terms use\nclustering\nmethods\nto\ngain\ncomprehensive trends in each research\nfield (Tseng et al., 2008; Ohniwa et al.,\n2010). In this study, we focused on\nunderstanding features of manually\nindexed terms through comparison with\nnatural language words. We tried to\nextract more specific information within\na relatively limited research area, which\nwe chose as “high temperature\nsuperconductor” (HTS) and “phonon”;\nthis is because it is clear when research\nin these areas began and because the\nliterature is rich in reviews and\ndocumentation on its history, which is\nhelpful to understand the research topics\nfrom the extracted words.\nExperiment\nData\nWe used the CAplus data of 2,259\narticles by searching the keywords “high\ntemperature\nsuperconductor”\nand\n“phonon.” Figure 1 shows the number of\npublications by year.\n\n1983\n\nFigure 1. Number of publications\ncontaining “high temperature\nsuperconductor” and “phonon.”\n\nThe number of publications repetitively\nincreased and decreased several times,\nand this variation can be presumably\nlinked with the changes in popularity of\ncertain research fields. For the research\ntopic extraction from abstracts as natural\nlanguage and for index terms as\ncontrolled vocabulary, we considered\nthe period from 1995 to 2012, focusing\non the increase in publications after one\ndecrease around 1998.\nIn CAplus, subjects are indexed in the\nIndex Term and Supplementary Term\nfields. Controlled (uncontrolled) terms\nare contained in Index Term as\n“controlled vocabulary (uncontrolled\nvocabulary).”\nTopic extraction from abstracts (natural\nlanguage)\nTo clarify the features of topics, we used\ngroups of two words (bigrams) as units\nfor analysis. The bigrams were ranked\nby frequency of articles. Next, the\nfollowing processing was performed to\nextract new topics that were remarkable\nduring the period.\n(a) During 1995-2000, a word contained\nin a bigram, which appeared more\nthan twice a year was defined as a\n“base word.” It was regarded as a\nconventional word generally used in\nthe research field and which did not\nexpress a certain research topic.\n1984\n\nFor bigrams appearing in and after 2001,\nif both words in the bigrams are base\nwords, the bigram was deleted.\nBigrams containing one or two new\nwords were ranked by frequency of\narticles. (Figure 2)\n(b) A different method was used for\nchoosing the base words in (a). For\nbigrams appearing in and after 2001,\nany new words in the bigram were\nadded to the base words every year.\nThen, bigrams were ranked by\nfrequency of articles.\n(c) Step (a) was repeated, with the\naddition of stemming.\n\nFigure 2. Outline of processing(a).\n\nTopic extraction from Index Terms\n(controlled vocabulary)\nNext, controlled vocabulary was\nemployed in the field of Index Term.\nBoth a word and a compound word were\nused as they were. As in the case of\nabstracts, index terms that appeared\nmore than twice for the first time in and\nafter 2001 were ranked by frequency.\nResults\nFrom the abstracts, terms related to the\nfollowing topics were extracted.\n(T1) Superconductor MgB2\n- first appearance in 2001 data\n- (background)\nA\nmetallic\nsuperconductor was discovered\nin 2001.\n(T2) Angle resolved photoemission\nspectroscopy (ARPES)\n- first appearance in 2001 data\n- (background) The role of\nphonons in superconductivity\ncame to the fore by experiments\nusing ARPES in 2001.\n\n(T3) Iron-based superconductor\n- first appearance in 2008 data\n- (background) A superconductor\nwas discovered in 2008.\nFigure 3 shows an example of the\nextracted terms. The number in\nparenthesis\ndenotes\nthe\narticle\nfrequency. The step (b) was effective in\ndetecting new topics, whereas new\ntopics in 2001 and subsequent\ndevelopments were found by step (a).\nNo significant difference was found by\nstep (c).\n\nnew materials is not detectable from\nindex terms. Therefore, we focus on the\ntopic of ARPES. From natural language\nwords, the emergence of the topic was\ndetected in time when other evidence\nwas taken into consideration. The trend\nthat this technology was subsequently\nimplemented frequently in this field was\nalso observed.\nAs regards controlled terms, words\nrelated to ARPES appeared in 2004 for\nthe first time. This was later than 2001,\nwhen the study on phonons in HTS,\nmeasured by ARPES, was reported and\nthe related works increased. This is\nconsidered to correspond to the\ncharacteristics that controlled terms\ncannot express new topics.\n\nFigure 3. Top 10 terms between\n2001 and 2002.\n\nReferences\nAbdou, S., &amp; Savoy, J. (2008).\nSearching in MEDLINE: Query\nexpansion and manual indexing\nevaluation. Information Processing\n&amp; Management, 44(2), 781-789.\nKordyuk, A. A.; et al. (2010). An\nARPES view on the high-Tc\nproblem: Phonons vs. spinfluctuations (Review Article) The\nEuropean Physical Journal Special\nTopics 188: 153-162\nOhniwa, R., Hibino, A., &amp; Takeyasu, K.\n(2010). Trends in research foci in\nlife science fields over the last 30\nyears monitored by emerging topics.\nScientometrics, 85, 1–17.\nTseng, Y., Lin, Y., Lee, Y., Hung, W.,\n&amp; Lee, C. (2009). A comparison of\nmethods for detecting hot topics.\nScientometrics, 81(1), 73–90.\n\nFrom\nindex\nterms\n(controlled\nvocabulary), terms related to the\nfollowing topics were extracted.\n(T2) ARPES\nfirst appearance in 2004 data\nHowever, there are records where\nappropriate words are indexed as\nuncontrolled terms.\nTo confirm the association between the\nterms and the background, information\nfrom other resources was used. The\nnumber of citations to articles on MgB2\nand Fe-based superconductors is the\nhighest each year, and there are many\nreviews on phonon measurement using\nARPES (e.g. Kordyuk et al., 2010).\nConclusions\nOwing to the characteristics of\ncontrolled vocabulary, information on\n\n1985\n\nFROM CATEGORICAL TO RELATIONAL\nDIVERSITY – EXPLORING NEW APPROACHES\nTO MEASURING SCIENTIFIC DIVERSITY\nMarco Schmitt1\n1\n\nmschmit4@gwdg.de\nGöttingen Centre for Digital Humanities at Georg-August-University Göttingen,\nPapendiek 16, D-37073 Göttingen (Germany)\nIntroduction\nThe measurement of diversity in the\nsciences is a research area of crucial\nimportance and great difficulty at the\nsame time. The reason for this is that\nresearch diversity is a multifaceted and\nmultidimensional concept. We will try\nto differentiate some of these\ndimensions\nand\ntheir\ninterconnectedness. Special emphasis is\nput on concepts of relational diversity,\nwhich has a higher measurability than\ncategorical diversity and is a good\nindicator of publication and citation\nstyles in the sciences. We will discuss\nthe different forms of relational diversity\nin their relation to specific scientific\nproduction fields.\nThe Problem of Diversity\nThe\nproblem of diversity for\nScientometrics and the Sociology of\nScience has three important dimensions.\nOne dimension is concerned with\nassessing the relevance of diversity for\nthe scientific enterprise. The second is\nconcerned with the plasticity of the\nconcept and the different forms it\nentails. And the third is concerned with\nthe difficulty of measuring scientific\ndiversity.\n\n1986\n\nBalance of Originality and Relevance\nGoing back to the institutionalist\nanalysis of science from Merton (1973)\nthere is the theme of a tradeoff between\nOriginality and Relevance in science.\nSuccessful science has to achieve a\nbalance where one of the two does not\ndrain out the other.. Diversity plays a\nbig role in this balance, because too\nmuch diversity leads to a fragmentation\nwith a lot of originality but less and less\nrelevance of publications, whereas too\nlittle diversity does not provide enough\noriginality to move forward and leads to\na\nrelevance\nlock-in.\nTherefore\nresearchers in the Sociology of Science\nand Scientometrics should care about\nthe implications of technologies or\nmodes of governance on scientific\ndiversity.\nDifferent Forms of Diversity\nA central problem is to identify the main\nfeatures of scientific diversity because it\nis a concept with a lot of dimensions and\nan enormous plasticity. There is the\ndiversity of access to scientific\ninformation or scientific positions,\nbroadly speaking the theme of Diversity\nStudies. Then we have the epistemic\ndiversity of scientific concepts, methods\nor “citational fingerprints”. And we\nhave – and we will follow this\nthoroughly in our approach – the\ndiversity of the publication networks\n\nthemselves. Lastly we also have a\ntechnical diversity of instruments used\nto gather relevant scientific information.\nAll these forms of diversity may vary\naccording to personal features of the\nscientists, community-related features of\nthe epistemic cultures, and overall\nsocietal developments. The question\nthen is how to evaluate these different\nforms of diversity.\nProblems of Measuring Diversity\nThe plasticity of the concept leads to\nsevere problems of measuring scientific\ndiversity (Havemann et al. 2007 and\nHeinz et al 2009). Debates on measuring\nbiodiversity\ncentred\non\nthree\ndimensions: variety, balance and\ndisparity (Stirling 2007). In the case of\nthe epistemic diversity of a scientific\nfield, it is really difficult to discern the\nunit of measurement. The knowledgebase of such a field is not only entailed\nin the publications, but also in\nmachinery and work processes. So\npublications can only be an indicator of\nepistemic diversity. But even the\ndiversity of publications is not easy to\nevaluate, because they combine a lot of\nconcepts and make a lot of different\nreferences to other publications. Just to\ncompute the disparity between different\npublications seems to be a hard task.\nFrom all these reasons the Sociology of\nScience and Scientometrics have to\nexplore new ways to address the\nproblem of diversity in science.\nFrom Categorical to Relational\nDiversity\nHere, we will explore what a shift from\nmeasuring categorical diversity to\nmeasuring relational diversity can\nachieve. While categorical diversity\nrests on the assumption that we can\ndistinguish units on the basis of there\ninherent differences, relational diversity\nrefers to the notion that the similarity or\n\ndissimilarity of these units rests on their\nstructural relationships with other units\n(White et al 1976). Developing\nrelational diversity based on that idea,\nwe can go straight to measuring\ndiversity in citation networks. In the\nfollowing we will outline two possible\napproaches to doing that:\nNetwork centralization\nMeasuring the centrality of nodes is one\nof the most common approaches to\nanalysing networks (Borgatti &amp; Everett\n2005). There are a variety of centrality\nmeasures: degree, closeness, betweeness\nand more. Each of these single-node\nmethods can be applied to measure the\noverall centralization of the whole\nnetwork. All are related to the overall\ncohesiveness of the network and all can\nbe easily measured. The question then is\non the relation of network centralization\nand relational diversity? One can argue\nthat a strong centralization and therefore\na harsh core-periphery structure will\ninhibit diversity and should result in a\nlow\nrelational\ndiversity.\nBut\ncohesiveness is not always detrimental\nto diversity, because the flow of\ninformation between the different units\nis important. Strong single core\nnetworks entail a low relational\ndiversity, they are very cohesive but\nperipheral information is omitted often.\nA less pronounced core produces a bit\nmore relational diversity and multiple\ncores coupled with strong betweeness\ncentralization are an indicator of high\nrelational diversity in the field.\nEquivalence and blockmodels\nAnother way to look at the problem is\nby applying the tools of network\nanalysis to reduce the redundant\ninformation from networks. Structural\nequivalence says that every node that\nhas the same relations to other nodes is\ninformationally redundant and can be\n1987\n\nviewed as having an exactly similar\nposition (White et al 1976). We can\neven generalize this finding and say that\na node that shares the same structural\nrelations with another node is in the\nsame position and reduce the network to\nthe different positions it entails. The\nrelational diversity of a network will\nthen resemble the different positions for\npublications it entails. Their share of the\nwhole network can account for the\nbalance dimension in diversity and we\ncan even calculate disparity based on the\nrelations that differ. The reduction of the\nnetwork complexity helps to identify\nways to see a citation network as more\nor less relationally diverse.\nHow Relational Diversity captures\nResearch Styles?\nWe will show how different research\nfields’ exhibit vastly different relational\ndiversity in the senses developed here.\nThe cores and positions in their citation\nnetworks are a sign for different\nscientific publications styles. It is our\ncontention that such profiles of\nrelational\ndiversity\ncaptures\nthe\npublication-related styles of scientific\nfields.\nStyle is a concept developed by\nHarrison White (White 2008) that\ncombines insights from the network\nresearch on structural equivalence and\nsensitivity for qualitative data on\nselection criteria and the production of\nsocial\nidentities.\nFor\nscientific\nproduction fields, this means that we\nhave a network profile of cores and\npositions and criteria from the scientists\nin a scientific field to interpret what that\nmeans for their diversity.\nWe will show a variety of fields and\ntheir profiles and some preliminary\nresults on the relevant criteria.\n\n1988\n\nReferences\nBorgatti, S. P., &amp; Everett, M. G. (2006).\nA graph-theoretic perspective on\ncentrality. Social networks, 28(4),\n466-484.\nHavemann, F., M. Heinz, M. Schmidt &amp;\nJ. Gläser (2007): Measuring\ndiversity of research in\nbibliographic-coupling networks. In:\nD. Torres-Salinas und H. Moed\n(Hrsg.), Proceedings of ISSI 2007, 2,\nMadrid, 860–861.\nHeinz, M., O. Mitesser, J. Gläser &amp; F.\nHavemann (2009), Ist die Vielfalt\nder Forschung in Gefahr?\nMethodische Ansätze für die\nbibliometrische Messung\nthematischer Diversität von\nFachbibliographien. In: Werner\nEbeling &amp; Heinrich Parthey (Hg.):\nSelbstorganisation in Wissenschaft\nund Technik,\nWissenschaftsforschung Jahrbuch\n2008, Berlin: Gesellschaft für\nWissenschaftsforschung, 107-119.\nMerton, R. K. (1973), The Sociology of\nScience. Chicago: Chicago\nUniversity Press.\nStirling, A. (2007). A general\nframework for analysing diversity in\nscience, technology and society.\nJournal of The Royal Society\nInterface 4(15), 707–719.\nWhite, H. C. (2008), Identity &amp; Control.\nHow Social Formations Emerge.\nCambridge (MA): Harvard\nUniversity Press.\nWhite, H.C., Boorman, S. &amp; Breiger, R.\n(1976), Social structure from\nmultiple networks. I. Blockmodels of\nroles and positions. American\nJournal of Sociology 81, 730-779.\n\nFULLERENE AND COLD FUSION: BIBLIOMETRIC\nDISCRIMINATION BETWEEN NORMAL AND\nPATHOLOGICAL SCIENCE\nMarcus John1 and Frank Fritsche2\n1\n\nMarcus.John@int.fraunhofer.de\nFraunhofer Institute for Technological Trend Analysis INT, Appelsgarten 2,\n53879 Euskirchen (Germany)\n2\n\nFrank.Fritsche@int.fraunhofer.de\nFraunhofer Institute for Technological Trend Analysis INT, Appelsgarten 2,\n53879 Euskirchen (Germany)\nIntroduction\nResearch activities on fullerenes were\ninitiated by the discovery of this carbon\nallotrope by Kroto et al. (1985), which\nfinally lead to a whole new research\narea. On the contrary, the fusion of\nhydrogen atoms at room temperature\nallegedly observed by Fleischmann &amp;\nPons (1989), proved to be false within a\nfew years. Today the research on this\nphenomena, sometimes referred to as\ncold fusion, is generally considered as a\nprototypical example of pathological\nscience.\nThis\ncontribution\npresents\na\ncomprehensive comparison of these two\nscientific themes from a bibliometric\npoint of view. We aim to look for\npatterns, which might allow to\ndistinguish between normal and\npathological science by means of\nbibliometric observables.\nMethod\nTo this end, we establish a bibliometric\nworkflow, which consists of three\ndifferent phases. The first phase\ncomprises the formulation of a suitable\nsearch query, which aims to delineate\nthe scientific theme of interest as\n\naccurately as possible. This step is of\ncrucial importance for the workflow,\nsince we want to include only those\npublications into the analyses, which are\nrelevant for the specific scientific field.\nSubsequently, the bibliometric data\nobtained with the ascertained search\nquery are processed. The aim of this\nphase is to structure the data in a way,\nthat they can be handled by an\nappropriate computer program and\nfurther information can be extracted,\ne.g. about the publishing countries.\nFurthermore, we try to correct potential\nerrors (e.g. possible spelling errors\nwithin the address field).\nThese processed data are further\nanalysed by calculating and visualizing\na number of bibliometric observables\nand their time-dependent behaviour.\nConsidered bibliometric observables\nFor each of the two themes a number of\nbibliometric quantities are considered in\norder to elucidate the differences\nbetween them. In doing so we try to\ndistinguish between normal and\npathological science. Among others we\nanalyse the following quantities:\n\n1989\n\n1. The publication dynamics, viz. the\nnumber of papers published per year.\nIn order to compare these data with\nthe general trend of growing\npublication activities, we normalized\nthem to a suitable reference year (see\nFigure 1 and 2).\n2. The document types of the analysed\npublications.\n3. The temporal evolution of the giant\ncomponent’s size of the co-author\nnetwork (Bettencourt, Kaiser, &amp;\nKaur, 2009).\nEach of these observables can be related\nto certain aspects of the process of\nscientific communication. While the\npublication dynamics obviously relates\nto the general interest in a scientific\ntheme, the document types elucidate the\nscientist’s preferred communication\nchannel. Finally, the giant component\nreflects the process of formation of a\nscientific community.\nResults\nThe results for the publication dynamics\npresented in Figure 1 (for the research\non fullerenes) and Figure 2 (for the\nresearch on cold fusion) demonstrate,\nthat these analyses allow a clear\ndistinction between both themes. While\nthe research on fullerenes follows after a\nshort initial phase the general trend of\ngrowing publication activities, the\nresearch on cold fusion has almost\ndisappeared from the scientific scene.\nIntriguingly the analyses of the\ndocument types reveal considerable\ndifferences between the two themes.\nThe researchers on fullerenes follow an\nexpected pattern by mainly using\narticles and later on proceedings for\ntheir publication activities. On the\ncontrary, the communication on cold\nfusion and the experiment of\nFleischmann &amp; Pons (1989) relies to a\nconsiderable extent on the publication of\n1990\n\nnotes. This aspect might be interpreted\nas an indication of urgency or\ntentativeness in the presentation of the\nscientific results.\n\nFigure 1. Relative publication numbers\nfor the theme fullerene. The publication\nnumbers for the research on fullerene and\nthose for all publications within the data\nbase are normalized to the year 1996, the\nyear the Nobel Prize for chemistry was\nawarded to Kroto and colleagues.\n\nFigure 2. Relative publication numbers\nfor the theme cold fusion. In this case the\npublication numbers have been\nnormalized to the year 1993.\n\nFinally, the results for the temporal\nevolution of the giant component of the\nco-author network reveal the most\nprominent difference between the two\nscientific themes. In case of the research\non fullerenes a rather dense co-author\nnetwork has emerged over time, where\nalmost all authors are at least connected\n\nindirectly. Thus, one clearly observes\nthe formation of a scientific community.\nContrarily, in case on the research on\ncold fusion, no such community has\nemerged and the co-author network\nremains rather disconnected.\nConclusion &amp; Outlook\nThe aim of this contribution is a\ntwofold. First of all we try to elucidate\nthe differences between normal and\n(potentially) pathological science by\nbibliometric means. To this end, we\ncombine the discussion of bibliometric\nobservables with some small remarks on\nthe scientific content of the analysed\npublications. It will be demonstrated,\nthat a clear distinction between normal\nand pathological science seems to be\npossible from a bibliometric point of\nview. Furthermore, it will be discussed,\nwhether or not it is possible to establish\na kind of classification scheme for\nemerging topics, which might even\n\nserve as a kind of early-warning system.\nOf course such a scheme would have to\nbe based on a larger number of\nconsidered themes.\nReferences\nBettencourt, L. M. A., Kaiser, D. I., &amp;\nKaur, J. (2009). Scientific discovery\nand topological transitions in\ncollaboration networks. Journal of\nInformetrics, 3(3), 210–221, from\ndoi:10.1016/j.joi.2009.03.001.\nFleischmann, M., &amp; Pons, S. (1989).\nElectrochemically induced nuclear\nfusion of deuterium. Journal of\nElectroanalytical Chemistry and\nInterfacial Electrochemistry, 261(2,\nPart 1), 301–308.\nKroto, H. W., Heath, J. R., O&#x27;Brien, S.\nC., Curl, R. F., &amp; Smalley, R. E.\n(1985). C60: Buckminsterfullerene.\nNature, 318, 162–163, from\ndoi:10.1038/318162a0.\n\n1991\n\nGEOGRAPHICAL ORIENTATION AND IMPACT\nOF FINLAND’S INTERNATIONAL COPUBLICATIONS\nReetta Muhonen1, Hanna-Mari Puuska2 and Yrjö Leino3\n1\n\nreetta.muhonen@uta.fi\nUniversity of Tampere, Research Centre for Knowledge, Science, Technology and\nInnovation Studies, FI-33014 University of Tampere, (Finland)\n2\n\nhanna-mari.puuska@uta.fi\nUniversity of Tampere, Research Centre for Knowledge, Science, Technology and\nInnovation Studies, FI-33014 University of Tampere, (Finland)\nCSC – IT Center for Science P.O. Box 405, FI-02101 Espoo (Finland)\n3\n\nyrjo.leino@csc.fi\nCSC – IT Center for Science P.O. Box 405, FI-02101 Espoo (Finland)\nIntroduction\nSeveral\nstudies\nindicate\nthat\ninternational\nco-publications\nhave\nincreased steadily in almost all\ncountries. International co-publications\nare also cited more often than other\npublications. (e. g. Narin et al. 1991;\nKatz &amp; Hicks 1997; Glänzel &amp; Schubert\n2001.) Similar results have been\nobtained in the Finnish context\n(NordForsk 2010, Muhonen et. al.\n2012). This study extends the\nunderstanding of Finland’s international\nresearch collaboration by scrutinizing its\ngeographical orientation. We explore the\ntrends and citation impact of Finland’s\nco-publishing with various country\ngroups by addressing the following\nquestions:\n1. How has international co-publishing\ndeveloped in Finland in 1990–2009\nwith different country groups:\nNordic\ncountries,\nEU15+\n\n1992\n\ncountries181, Baltic countries, Russia,\nother European countries182, Africa,\nAsia, North America, Central and\nSouth America, and Australia and\nOceania?\n2. Have Finland’s international copublications with different country\ngroups received more citations than\nFinnish publications on average?\nData and methods\nThe results presented in this study are\nbased on the Thomson Reuters Web of\n181\n\nEU15 states excluding the Nordic\ncountries + Switzerland, that is: Austria,\nBelgium, France, Germany, Greece, Ireland,\nItaly,\nLuxembourg,\nPortugal,\nthe\nNetherlands, Spain, Switzerland, and the\nUnited Kingdom.\n182\nAlbania, Andorra, Belarus, BosniaHerzegovina, Bulgaria, Czech Republic,\nCroatia, Cyprus, Hungary, Kosovo ,\nLiechtenstein, Macedonia, Malta, Monaco,\nMoldova, Montenegro, Poland, Romania,\nSan Marino, Serbia, Slovakia, Slovenia,\nUkraine, the Vatican, and the former\nYugoslavia.\n\nScience database (WoS). Whole\ncounting of publications is applied: if a\npublication includes authors from\nseveral country groups it is counted into\neach group. When calculating the\ncitation scores, the publications are,\nhowever,\nfractionalized\nbetween\ncountries.\nCitation counts of Finnish publications\nwith various country groups are\ncompared to the world average by using\nthe field normalized citation score. The\nnumber of citations cumulated by each\npublication is normalised to the average\ncitation counts of all WoS publications\nin the relevant subject field which were\npublished in that year and which\nrepresent the same WoS article type\n(Article, Review or Letter). Citation\nscores are calculated for publications in\nthe latest studied period 2006–2008 (the\nyear 2009 was excluded since its\npublications have not had time to\ncumulate an adequate amount of\ncitations).\nWe apply open citation\nwindow and exclude self-citations.\n\nResults\nThe share of international copublications in all Finland’s WoS\npublications increased steadily from 25\npercent 1990–1993 to almost one half\n(49%) in 2006–2009.\nThe\nco-authors\nof\nFinland’s\ninternational\nco-publications\nmost\ntypically came from the EU15+\ncountries (Table 1). North America was\nthe second and the Nordic countries the\nthird most frequently co-publishing\ncountry group with Finland. No change\ntook place in the order of the three most\ncommon country groups involved in copublications, although their shares in\nFinland’s international co-authorship\nhave undergone different development\npatterns during 1990–2009.\n\nTable 1. Shares of country groups in\nFinland’s international co-publications\n(WoS, 1990-2009).\n19901993\n38.0%\n35.4%\n\n19941997\n39.8%\n36.5%\n\n19982001\n46.7%\n32.8%\n\n20022005\n50.1%\n31.3%\n\nEU15+\nNorth\nAmerica\nNordic\n23.6% 25.2% 25.5% 25.0%\ncountries\nOther\n10.9% 10.8% 10.8% 9.9%\nEuropean\nAsia\n7.8% 9.7% 10.1% 11.2%\nRussia\n9.3% 9.5% 9.1% 7.8%\nAustralia\n2.1% 2.5% 3.3% 3.5%\n, Oceania\nBaltic\n0.7% 3.2% 3.2% 3.3%\ncountries\nSouth &amp;\n2.2% 3.0% 2.3% 2.5%\nCentral\nAmerica\nAfrica\n1.6% 1.3% 1.2% 1.3%\nNote. The sum of percentages of all\nexceeds 100 since a single publication can\nto several groups.\n\n20062009\n53.8%\n30.3%\n26.1%\n12.3%\n14.3%\n8.2%\n4.9%\n3.6%\n2.6%\n1.6%\ngroups\nbelong\n\nFigure 1. Field normalized citation score\nof 1) Finland’s all publications 2)\nFinland’s co-publications with the country\ngroups, 3) all publications of the highest\nranking country (i. e. the country with the\nhighest citations score in the particular\ncountry group with minimum of 500\npublications) (WoS, 2006-2008).\n\n1993\n\nFigure 1 shows that the order of\nFinland’s most impactful co-publishing\ncountry groups is well in line with the\ncitation impact of the highest ranking\ncountries in these groups. However, the\nhighest citation score were displayed by\nFinland’s co-publications with Australia\n&amp; Oceania and South &amp; Central\nAmerica. They received 95 and 70\npercent more citations than the world’s\npublications on average. Exceptionally,\nthe highest ranking countries in these\ncountry groups, Australia and especially\nPeru have much lower citation scores\nthan corresponding countries in the\nother country groups.\nCompared to all publications produced\nby Finnish scholars, the co-publications\nwith all country groups are on average\nmore frequently cited with one\nexception: The citation count of\nFinland’s co-publications with Russia\nare lower than that of Finnish\npublications on average. Compared to\nRussia’s own publications, however,\nthese co-publications have cumulated\nconsiderably higher numbers of\ncitations.\nDiscussion\nThe results of this study indicate that\nFinnish research has become more\ninternationalized and the international\ncollaboration benefits the impact of\npublications. Furthermore, collaboration\nwith Finland has also been lucrative for\nother countries. The position of the\nUnited States as a hub of science is\nreflected as a high average citation score\nof North America’s co-publications with\nFinland, but on the other way around,\n\n1994\n\ncooperation with Finland is also\nbeneficial for the North America.\nTo be able to explain the high citation\nrates of the co-publications with\nAustralia &amp; Oceania and South &amp;\nCentral America a further analysis\nwould be needed on the research fields\nin which Finland collaborates with\ndifferent country groups. The further\nstudies should also consider the possible\nvariation in citation impact within the\ncountry groups.\nReferences\nGlänzel, W, Schubert, A. &amp; Czerwon,\nH.-J. (1999). A bibliometric analysis\nof international scientific\ncooperation of the European Union\n(1985-1995). Scientometrics 45 (2),\n185–202.\nKatz, J. Sylvan &amp; Hicks, Diana (1997).\nHow much is a collaboration worth?\nA Calibrated bibliometric model.\nScientometrics, 40 (3), 541–554.\nMuhonen, R., Puuska, H.-M. &amp; Leino,\nY. (2012). International copublishing in Finland. Helsinki:\nReports of the Ministry of Education\nand Culture, Finland 2012:19.\nNarin, F., Stevens, K., &amp; Whitlow, E. S.\n(1991). Scientific cooperation in\nEurope and the citation of\nmultinationally authored papers.\nScientometrics, 21 (3), 313–323.\nNordForsk (2010). Bibliometric\nresearch performance indicators for\nthe Nordic countries. A Publication\nfrom the NORIA-net “The Use of\nbibliometrics in research policy and\nevaluation activities”.\n\nGLOBAL RESEARCH STATUS IN LEADING\nNUCLEAR SCIENCE AND TECHNOLOGY\nJOURNALS DURING 2001–2010: A BIBLIOMETRIC\nANALYSIS BASED ON ISI WEB OF SCIENCE\nAmir Hossein Mardani1 and Fereshteh Didegah2 and Shahram Abdiazar3\n1\n\nMardani3@gmail.com\nTehran University of Medical Sciences, School of Medicine, Ghods Str, Keshavarz Blv\n,Tehran (Iran)\n2\n\nfdidgah@gmail.com\nStatistical Cybermetrics Research Group, School of Technology &amp; Research Institute for\nInformation and Langauge Processing, University of Wolverhampton (UK)\n3 Sh.abdiazar@gmail.com\nUniversity of Maraghe, Madar Sq, Amirkabir Blv, Maraghe (Iran)\nIntroduction\nThe present study will provide an\nassessment of global orientations toward\nvarious disciplines in terms of Nuclear\nScience\nand\nTechnology (NST)\nresearch. This study will try not to\ncontent itself only with a preliminary\nbibliometric performance assessment of\nindividuals, institutions, and countries\nand will attempt to explain the\ndevelopments in this field beyond the\nobserved patterns. Therefore, we tried to\nuse advanced bibliometric measures\nsuch as filed citation scores and\nanalytical methods such as network\nanalysis. At the same time, we measured\na considerable amount of publications\nassociated with NST and offered\nsubstantive arguments for observed\nbibliometric patterns so as to provide\npotential directions for future research.\n\nidentified which were listed under the\nsubject category of NST in the database\nof JCR in 2011. Next, we retrieved all\nthe publications of this journal which\nwere indexed in the WOS during 2001\nto 2012. All types of collaborations were\ncategorized based on the affiliation\naddresses of the authors: “single country\npublication”,\n“internationally\ncollaborative\npublication”,\n“single\ninstitute publication” , and “interinstitutionally\ncollaborative\npublication”. Furthermore, the NetDraw\nsoftware was used to illustrate the\ninternational collaboration network\n(Borgatti,\n2006).\nTo\ndetermine\nperformance of papers across fields, in\nterms of assessing impact of the papers\nacross fields, we calculated the field\nnormalized measured impact ratios\n(CPP/FCSm) of NST publications for\neach field.\n\nMaterial and methods\nThe records used in this study are based\non bibliographic data retrieved from the\nWOS database. First, 35 journals were\n\nResults\nIn general, 85198 records were retrieved\nfrom WOS during 2001 to 2010.\nAlthough the annual number of records\n1995\n\nduring the period has rather increased,\nas can be seen in figure 1, this increase\nhas not been very conspicuous and the\nresearch output does not reveal a\nsignificant growth in NST scientific\nproductions. It even has experienced a\ndownfall in some years such as 2008\nand 2010. The exponential regression\ntest supported that these publications\nhave a 1.3% growth rate. The results\nwere accurate and reliable at a\nconfidence level of 95 percent\n(significance= 0.001).\n\nIMPACT:\nLOW(&lt; 0.8)\nAVERAGE(0.8- 1.2)\n\nHIGH(&gt; 1.2)\n\nFig 2. Research output profile of NST\nacross the top 18 fields, 2001–2010\n\nFig 1. The growth rate of publications\n\nThe NST publications fall into 18 ISI\nrecognized subject categories. Figure 2\nprovides a spectral analysis of the\nresearch output of NST across those\nfields. Results revealed that of the 18\nfields the largest impact (CPP/FCSm =\n4.2) was for Nuclear Physics, but still\nsubstantial impact level (CPP/FCSm\nabove 1.5) was also observed and\nincluded the fields of Nuclear Science &amp;\nTechnology, Spectroscopy, Analytical\nChemistry, multidisciplinary sciences,\nBiology, and Geosciences. The field\nnormalized citation scores indicated that\npublications in these fields were highly\ninfluential and visible, far exceeding the\nnumber of citations expected for\npublications of the same time period\n(Rosas et al. 2012; Liu et al. 2012; Van\nRaan, 2008).\n\n1996\n\nUsing the NetDraw software, we were\nable to illustrate the international\ncollaboration network which consists of\n25 countries (Figure 3). As can be\nobserved in Figure 3, the USA is at the\ncenter of the NST research cluster which\nindicates that the USA plays an\nimportant role in the network. The USA\nis in the central part of the international\ncollaboration network; hence, it is the\nmain partner for many research prolific\ncountries such as Germany, Japan, and\nItaly. However, the network suggests the\nstrongest relationship between the USA\nand Germany (with 1174 counts of coauthored records).\nWe recorded the publication indicators\nfor twenty five countries which were\nprolific in NST scientific productions.\nThe\ndata\nindicate\ngeographical\ninequalities in the publications. From\nthe 82738 remaining records, 61753 one\nof them (74.6%) were published\nindependently\nand\nwithout\nany\ncollaboration from another country.\n\n20985 records (25.4%) were published\nwith international collaboration of more\nthan one country.\n\nFig 3. International collaboration network\nof 25 most central countries in Nuclear\nScience &amp; Technology research\n\nThe USA comes first in the rankings of\ncountries that are prolific in NST\nresearch. Accounting for one fifth of\nscientific productions, the USA also\nranks\nfirst\nin\ninternationally\ncollaborative publications (20% in all)\nand as a single country ( 22% in all).\nAfter that, Japan has published the\nhighest number of records (11471).\nGermany (10119), France (6793), Italy\n(6561), and Russia (5796) come right\nafterward. Even though internationally\ncollaborative publications comprise 23%\n\nof all the publications in the USA, they\nare exceeded by in some countries.\nAlthough ranking sixth in the number of\npublications, Russia contributes to 41%\nof\ninternationally\ncollaborative\npublications. Therefore, based on the\ncollaboration pattern, it can be implied\nthat some countries like Russia tend to\ncollaborate with researchers from other\ncountries. It is while most countries like\nUkraine are more limited with regard to\ninternational\ncollaborations\nthan\ndomestic ones.\nReferences\nBorgatti, Steve. (2006). Netdraw:\nNetwork Visualization. Analytic\nTechnologies, Inc.\nLiu, X., Zhan, F., Hong; S., Niu; B.\n&amp;Liu, Y. (2012). A bibliometric\nstudy of earthquake research: 1900–\n2010. Scientometrics. DOI\n10.1007/s11192-011-0599-z\nRosas ,S., Kagan .J., Schouten, J., Slack,\nP.&amp; Trochim, W. (2011) Evaluating\nResearch and Impact: A Bibliometric\nAnalysis of Research by the\nNIH/NIAID HIV/AIDS Clinical\nTrials Networks. PLoS ONE, 6(3).\nVan Raan , A. (2008). R &amp; D evaluation\nat the beginning of a new century.\nResearch Evaluation, 8, 81–6.\n\n1997\n\nGROUPS OF HIGHLY CITED PUBLICATIONS:\nSTABILITY IN CONTENT WITH CITATION\nWINDOW LENGTH\nNadine Rons1\n1\n\nNadine.Rons@vub.ac.be\nVrije Universiteit Brussel, Research Coordination Unit and Centre for R&amp;D Monitoring\n(ECOOM), Pleinlaan 2, B-1050 Brussels (Belgium)\nIntroduction\nThe growing focus in research policy\nworldwide on top scientists makes it\nincreasingly important to define\nadequate supporting measures to help\nidentify excellent scientists. Highly cited\npublications have since long been\nassociated to research excellence. At the\nsame time, the analysis of the high-end\nof citation distributions still is a\nchallenging\ntopic\nin\nevaluative\nbibliometrics. Evaluations typically\nrequire\nindicators\nthat\ngenerate\nsufficiently stable results when applied\nto recent publication records of limited\nsize. Highly cited publications have\nbeen identified using two techniques in\nparticular: pre-set percentiles, and the\nparameter free Characteristic Scores and\nScales (CSS) (Glänzel &amp; Schubert,\n1988). The stability required in\nassessments\nof\nrelatively\nsmall\npublication records, concerns size as\nwell as content of groups of highly cited\npublications. Influencing factors include\ndomain delineation and citation window\nlength. Stability in size is evident for the\npre-set percentiles, and has been\ndemonstrated for the CSS-methodology\nbeyond an initial citation period of about\nthree years (Glänzel, 2007). Stability in\ncontent\nis\nless\nstraightforward,\nconsidering for instance that more\nhighly cited publications can have a\nlater citation peak, as observed by Abt\n1998\n\n(1981) for astronomical papers. This\npaper investigates the stability in content\nof groups of highly cited publications,\ni.e. the extent to which individual\npublications enter and leave the group as\nthe citation window is enlarged.\nData and methodology\nDatabase, document type and time\nframe\nThe bibliometric data were obtained\nfrom the online Web of Science. This\nstudy focuses on articles as primary\nvehicles for new research results\n(reviews, less frequent and typically\nmore highly cited, are in itself related to\nhigh esteem). Results were calculated\nfor articles published in 2004. Citations\nwere collected up to 7 years after\npublication, until 2011.\nAggregation level\nThe group of top-cited publications is\nhighly dependent on the level of\naggregation at which these are\ndetermined (Zitt, Ramanana-Rahary &amp;\nBassecoulard, 2005). In this paper, the\nreference sets within which highly cited\npublications are identified are the\npartition cells formed by the structure of\noverlapping subject categories (Rons,\n2012). These partition cells are an\naggregation level of intermediate size,\nsituated between journals and entire\nsubject categories, proposed particularly\n\nfor usage at the level of individual\nscientists.\nDomains\nData were collected from a domain with\nfast citation characteristics (a subdomain of physics), and from a domain\nwith slow citation characteristics\n(mathematics). In both domains, three\nadjacent partition cells are observed,\ncontaining all journals assigned to a\nparticular combination of subject\ncategories:\n- &#x27;Astronomy Astrophysics&#x27; only (A),\n&#x27;Physics Particles Fields&#x27; only (P),\nand both &#x27;Astronomy Astrophysics&#x27;\nand &#x27;Physics Particles Fields&#x27; (A&amp;P),\nwith 8047, 1977 and 2440 articles\nrespectively.\n- &#x27;Mathematics&#x27;\nonly\n(M),\n&#x27;Mathematics Applied&#x27; only (MA),\nand\nboth\n&#x27;Mathematics&#x27;\nand\n&#x27;Mathematics Applied&#x27; (M&amp;MA),\nwith 10022, 3938 and 3286 articles\nrespectively.\nGroups of highly cited publications\nGroups of highly cited publications were\nidentified using both the technique of\npre-set percentiles (5% and 1%), and the\nCSS-methodology (at least &#x27;remarkably&#x27;\nand &#x27;outstandingly&#x27; cited publications,\nstabilizing in size towards 8 to 11%, and\n2 to 3% respectively in the largest\ncitation windows).\nResults and discussion\nThe citation distributions vary with\ndomain and highly cited level. Peak\ncitation years tend to fall later for more\nhighly cited publications. Differences\ndepend on the domain, with in the\nphysics cells 0 to 3 years between the\ntop-1% or outstandingly cited and the\nless cited publications, and in the\nmathematics cells 1 tot 2 years between\nthe top-5% or at least remarkably cited\nand the less cited publications. In\n\nparticular for publications below the\ntop-1% and outstandingly cited, peak\ncitation years in the slow mathematics\ndomain fall later than in the fast physics\ndomain (3 to 6, and 1 to 2 years after the\npublication year respectively). Figure 1\nshows how groups of highly cited\npublications converge in content with\nincreasing citation window length, in a\nsimilar way for both methodologies\nused. A yearly fluctuation in content\nremains between the larger consecutive\ncitation windows.\n\nFigure 1. Intersection of groups of highly\ncited publications for consecutive citation\nwindow lengths.\n\nConvergence in content varies with\ndomain in particular, and also with\nhighly cited level. From a citation\nwindow of 3 years, groups of highly\ncited\npublications\nidentified\nin\nconsecutive citation windows have a\nmajority of publications in common.\nThis finding is in accordance with\ncitation distribution models reflecting\nthe conjecture that for most papers the\ninitial pulse of citations determines its\nfuture citation history (Price, 1976). To\nhave at least 80% of highly cited\n1999\n\npublications in common with the\nsubsequent citation window requires 3\nto 4 years for the physics cells, and 5 or\nmore years for the mathematics cells.\nChanges in status for 1 out of 5 highly\ncited publications over the years might\nhowever still significantly influence a\ncomparison of publication records of\nindividual scientists. In practice citations\nare often collected in about the same\nperiod as the observed publications, for\ninstance extended with one year. The\nresults shown in Figure 1 indicate that in\nparticular the potential error induced by\na citation window as short as two years\nwould need to be considered in the\ndesign of an approach for the\nidentification\nof\nhighly\ncited\npublications.\nConclusions\nThe results of the present study show\nhow, in stable size groups of highly\ncited publications, the content of\nindividual publications converges with\nan extending citation window. To the\nauthor&#x27;s\nknowledge,\nno\nsimilar\ninvestigations of the extent to which\nindividual publications enter and leave\nthe group of highly cited publications as\nthe citation window is enlarged, figure\nin scientific literature. The process\nevolves towards a limited remaining\nyearly fluctuation and depends on\ndomain and highly cited level.\nAdditional factors outside the scope of\nthis paper may also exert an influence,\nsuch as the structure within which the\nhighly cited publications are identified,\nincluding subject category as well as\npublication based structures. Stability in\ncontent of groups of highly cited\npublications is relevant in particular in a\ncontext of publication records of limited\nsize, such as those of individual\nscientists. The studied domains with\ndifferent bibliometric characteristics\nindicate that a same stability in content\n2000\n\ncan require citation windows of different\nlengths depending on the domain.\nWhether a sufficient stability in content\ncan be attained for successful general\nand comparative applications at the\nmicro-level, with citation windows of\nacceptable size in an evaluative context,\nrequires further investigation.\nAcknowledgments\nThis paper is related to research on\nindividual excellence carried out at the\nFlemish Centre for R&amp;D Monitoring\n(ECOOM).\nReferences\nAbt, H.A. (1981). Long-term citation\nhistories of astronomical papers.\nPublications of the Astronomical\nSociety of the Pacific, 93(552), 207210.\nGlänzel, W. (2007). Characteristic\nscores and scales: A bibliometric\nanalysis of subject characteristics\nbased on long-term citation\nobservation. Journal of Informetrics,\n1(1), 92-102.\nGlänzel, W. &amp; Schubert, A. (1988).\nCharacteristic scores and scales in\nassessing citation impact. Journal of\nInformation Science, 14(2), 123-127.\nPrice, D. de S. (1976). A general theory\nof bibliometric and other cumulative\nadvantage processes. Journal of the\nAmerican Society for Information\nScience, 27(5-6), 292-306.\nRons, N. (2012). Partition-based field\nnormalization: An approach to\nhighly specialized publication\nrecords. Journal of Informetrics,\n6(1), 1-10.\nZitt, M., Ramanana-Rahary, S. &amp;\nBassecoulard, E. (2005). Relativity\nof citation performance and\nexcellence measures: from crossfield to cross-scale effects of fieldnormalization. Scientometrics, 63(2),\n373-401.\n\nHEAPS’ LAW: A DYNAMIC PERSPECTIVE FROM\nSIMON’S MODEL\nYiFei Zhang1,Shi Shan2,JunPing Qiu3 and ChunNing Yan1\n1\n\nzhangyifei@shu.edu.cn\nShanghai University, School of Management, 99 Shangda Road, 200444 Shanghai\n(China)\n2\n\nshanshihill@126.com\nShanghai University, Center for Information Studies, 99 Shangda Road, 200444 Shanghai\n(China)\n3\n\njpqiu@whu.edu.cn\nWuhan University, Research Center for Chinia Science Evaluation, Luojia Hill, 430072\nWuhan (China)\nIntroduction\nThis papers focuses on the growth of\nvocabulary in actual texts. Here we\nexamine how the macroscopic text\nproperties, like word occurrence and\ntext densification change as the text\ngrows. This work had influence on\nthinking about fundamental structure\nproperties of texts varying with their\nlength. For example, to date, it was\ncommonly believed that the average\nword occurrence of texts remains\nconstant as the number of texts\nincreases. In fact texts densify with the\nnumber of texts as the total number of\nwords in m texts K (m) increasing as\nK (m)  N (m)1 (   0 ) with the total\nnumber of different words in m texts\nN (m) , where   0 . We use e(m) to\ndenote the average word occurrence in\nm texts, then e(m)  K (m)  N (m)  .\nN (m)\n\nObviously, the average word occurrence\ngrows with the number of samples (i.e.,\ntexts). Two models describing the\ngrowth of vocabulary are worth\nmentioning. The first one, a stochastic\n\nprocess put forward by Simon (Simon,\n1955), simulates the dynamics of text\ngeneration as multiplicative process that\nleads to power law distributions of word\nfrequencies. The second model is due to\nHeaps (Heaps, 1978), who developed a\npower-law relation between the text\nlength k and the number n(k ) of\ndifferent words in a text, i.e.,\nn(k )  ck 1 ( c  0 ,   (0,1) ), which is\nusually referred to as Heaps’ law.\nSimon’s model intend to capture the\nessential features of real text generation\nby specifying how words are added to a\ntext, as follows. The probability that the\n(k  1) st word added to a text will be a\nword that has already occurred i times\n( i  1 ) is proportional to if (i, k ) , where\nf (i, k ) is the number of distinct words\n(types) that have occurred exactly i\ntimes each in the first k words of text.\nThe probability that the (k  1) st word\nadded to a text will be a word that has\nnot occurred before is   (0,1) . Simon\ndeveloped the following model.\nf (1, k  1)  f (1, k )   \n\n1 \nf (1, k )\nk\n\n2001\n\nand\n\n1 \nf (i, k  1)  f (i, k ) \n((i  1) f (i  1, k )  if (i, k ))\nk\n\n( i  2,3,, k  1).\n\nf (1, k  1)  f (1, k )   (k  1)  K (k ) f (1, k ) ,\n\nf (i, k  1)  f (i, k )  K (k )((i  1) f (i 1, k )  if (i, k ))\n\n, ( i  2,3,, k  1),\n\nwhere 1   (k  1) \n\nIn the Simon model, the rate at which\nnew words appear is a constant, such\nthat the vocabulary size N (k ) for a text\n\ncontaining k words, on the average, is\nObviously,\nN (k )  k .\nN (k )  N (k  1)  N (k )   , which is the\nrate at which new words enter. Heaps’\nlaw shows that the growth of vocabulary\nin actual texts is typically sublinear, i.e.,\nN (k )  ck 1 with c  0 and   (0,1) ,\nand\nN (k )  N (k  1)  N (k )  (1   )ck  (1  o(1)) .\nThe latter means that the rate at which\nnew words appear is not a constant but a\ngradually decreasing function of k .\nAn Extension of the Simon Model\nWe will consider an extension of the\nSimon model.\nLet k be the text length. f (i, k ) is the\nexpected number of distinct words that\noccur i times each in a text with length\nk . N (k )  k f (i, k ) .  (k ) is the rate at\n\n\n\nk\n\n K (k )if (i, k ) .\ni 1\n\nNext, we assume that\nk\n\n if (i, k ) ~ k\n\n.\n\ni 1\n\nFrom this assumption, it follows that\nf (1, k  1)  f (1, k )   (k  1) \n\n1   (k  1)\nf (1, k )\nk (1  o(1))\n\n(2.1)\n\nf (i, k  1)  f (i, k ) \n\n1   (k  1)\n((i  1) f (i  1, k )  if (i, k ))\nk (1  o(1))\n\n( i  2,3,, k  1), (2.2)\n\nWe obtain the following results.\nTheorem 1 Suppose that (2.1) and (2.2)\nhold and  (k  1)    (0,1) (as k  \n), then\n(1)\n\nlim\n\nf (i, k )\n\nk  k\n\n f ( j, k )\n\n\n\n(  1)(k ) ,\n(k    1)\n\nj 1\n\nwhere   1  1 , and\n1 \n(\n)\n~\nk .\nN\nk\n(2)\n\ni i\n\nk\n\nwhich new words enter. M (k )   (i) .\n\ni 1\n\nN   {1,2,} . A positive function  (k )\non N  varies gradually, if and only if\nk\n1 .\n (k  1)\nf ( j, k )\n 1  o( ) p(i)  lim f (i, k ) /\n (k )\n\nk\n\nk \n\n\n\nTheorem 2 Suppose that (2.1) and (2.2)\nhold,  (k )  0 (as k   ),\nk (k  1)\n   (0,1)\nM (k )\n\nlim\n\ni  N  ),\nf (i, k )\n q(i ) (\nM (k )\n\nand\n\nj 1\n\nis called the steady-state distribution, if\nthe limit exists. () is the usual gamma\nfunction. We use “~” to mean that the\nratio of the quantities on either side of\nthe symbol converges to one.\nWe extent the Simon model in the\nfollowing way.\n\nlim\n\nk \n\nk \n\nthen\n(1)\n\nlim\n\nk \n\nf (i, k )\nk\n\n f ( j, k )\n\n\n\n(   1)(k )\n q(i)\n(k    1)\n\nj 1\n\nwith   (0,1) , and\n\n(2) N (k ) ~  (k )k (   (0,1) ),\n (k ) varies gradually.\n\n2002\n\nwhere\n\nRemark Theorem 2 shows that (under\nsome conditions) when the rate at which\nnew words enter gradually approaches\nzero a general form of Heaps’ law will\nemerge.\nReferences\nEgghe, L. (2007). Untangling Herdan’s\nlaw and Heaps’ law: mathematical\nand informetric arguments. Journal\nof the American Society for\nInformation Science and\nTechnology, 58, 702-709.\nHeaps, H. S. (1978). Information\nRetrieval, Computational and\nTheoretical Aspects. New York:\nAcademic Press.\nLansey, J. C. &amp; Bukiet, B. (2009).\nInternet search result probabilities:\nHeaps’ law and word associativity.\nJournal of Quantitative Linguistics,\n16, 40-66.\nLeijenhorst, D. &amp; Weide, T. (2005). A\nformal derivation of Heaps’ law.\nInformation Science, 170, 263-272.\n\nLu, L., Zhang, Z.-K. &amp; Zhou, T. (2010).\nZipf&#x27;s Law Leads to Heaps&#x27; Law:\nAnalyzing Their Relation in FiniteSize Systems. PLoS ONE, 5, e14139.\nShi, D. H. (2011). Theory of Network\nDegree Distributions (in Chinese).\nBeijing: Higher Education Press.\nSimon, H. (1955). On a class of skew\ndistribution functions. Biometrika,\n42, 425-440.\nZanette, D. &amp; Montemurro M. (2005).\nDynamics of text generation with\nrealistic Zipf’s distribution. Journal\nof Quantitative Linguistics, 12, 2940.\nZhang, Z.-K. et al. (2008). Empirical\nanalysis on a keyword-based\nsemantic system. European Physical\nJournal B, 66, 557-561.\nZipf, G. K. (1936). The Psycho-Biology\nof Language. An Introduction to\nDynamic Philology. London:\nRoutledge.\n\n2003\n\nHOW EFFECTIVE IS THE KNOWLEDGE\nTRANSFER OF A PUBLIC RESEARCH\nORGANIZATION (PRO)? FIRST EMPIRICAL\nEVIDENCE FROM THE SPANISH NATIONAL\nRESEARCH COUNCIL\nElba Mauleón1, Gian Carlo Cainarca2 and Cinzia Daraio3\n1\n\nelba114@hotmail.com\nPostdoctoral Fellowship supported by the Spanish Ministry of Education through FECYT\n2\n\ncainarca@dist.unige.it\nDIST, University of Genoa (Italy)\n3\n\ndaraio@dis.uniroma1.it\nDepartment of Computer, Control and Management Engineering Antonio Ruberti\nUniversity of Rome La Sapienza, Rome (Italy)\nIntroduction\nScientific research is fundamental for\ncountries to progress, but increasingly\nrequires greater economic investment\n(Van Raan, 1996). Thus, some issues of\nconcern for governments are raising\nfunds through international calls, the\nproper distribution of funds, and the\nestablishment\nof procedures\nfor\nassessing the activity of groups and\nresearch institutes, to ensure proper use\nof limited resources (Bornmann, Mutz\nand Daniel; 2008). In this sense, to\nachieve the efficiency in the use of these\nresources is a goal of science policy, and\nthe improvement of the instruments that\nmeasure the efficiency in organizations\nis a staple.\nObjectives\nIn this paper we analyse the efficiency\nof knowledge production of a PRO and\nwe investigate also on the much less\nexplored issue of the “effectiveness” of\nthe knowledge production, i.e. the\n2004\n\nknowledge transfer activity and its\nimpact at territorial level. At this\npurpose, the Spanish National Research\nCouncil\n(Consejo\nSuperior\nde\nInvestigaciones Cientificas - CSIC)\noffers a unique opportunity to analyse a\ncomplex state-owned, multisectoral,\nmultidisciplinary, public research body,\narticulated into different research areas\nspread at territorial level all over Spain.\nThe process of knowledge transfer may\nbe articulated in:\na) technology transfer in the narrow\nsense: based on codified knowledge\nand measured by quantitative\nindicators (such as patents and so on)\nthat impacts on firms and the\ninnovation system of the economy;\nand\nb) technology transfer in the broad\nsense: based on non codified\nknowledge\nmore\ndifficult\nto\nmeasure, that affects the general\npublic and the society.\nSo, we provide a comparative analysis\nof CSIC research institutes to investigate\n\non their efficiency in the production of\nknowledge, and to analyse the\neffectiveness of their production i.e.\nhow the knowledge produced is\ntransferred to the society.\nMethodology\nAs a result of the transformation of the\nSpanish National Research Council\n(CSIC) into a state agency, strategic\nplans (Plan de Actuación, 2006-2009)\nhave been implemented to prepare the\ninstitution’s activities and establish a set\nof indicators to monitor its activity. The\nimplementation of this action plan has\ngenerated a wealth of qualitative and\nquantitative information and data has\nbeen provided by the centres and\ninstitutes on how they operate. We used\nthe following data, which is available\nfor every centre and institute:\na) Human resources: the number of\nresearchers.\nb) Budget\nc) Funding obtained through contracts\nand agreements signed with R &amp; D\ncompanies, with the public sector\n(ministries or agencies, regional\ngovernments,)\nand\nnon-profit\ninstitutions.\nd) Funds allocated to research: funded\nresearch projects are considered by\nsource (competitive national and\nregional calls and EU Framework\nProgramme call).\ne) Number of international scientific\npublications.\nf) Impact factor of research journals.\ng) Training activities: including the\nnumber of theses that have been\npresented, and the participation of\nresearchers in master&#x27;s and doctoral\ncourses.\nTo consider the importance and\ninfluence of the environment (economic,\nsocial and political) the following\nvariables relative o the region in which\n\nthe institutes are located are included in\nthe study: a) GDP per capita= Gross\nDomestic Product per capita (Euros); b)\nR&amp;D\nIntensity=\nResearch\n&amp;\nDevelopment expenditure as % gross\ndomestic product; c) BERD= % of R&amp;D\nexpenditure financed by the business\nenterprise sector.; e) Patent/inhabitant:\nnumber of patents per million\ninhabitants (due to the small number of\nannual patents in some regions, a threeyear average (2002-2004) is considered\nto reduce year-to-year variability).\nWe assess the efficiency of CSIC as a\nwhole measuring the relative efficiency\nof each research institutes by using a\nData Envelopment Analysis approach\n(DEA, Farrell, 1957, Charnes Cooper\nand Rhodes, 1978). After that we study\nthe determinants of the efficiency of the\nCSIC institutes by using a two stage\nbootstrap\nbased\napproach\nin\nnonparametric\nefficiency\nanalysis\n(Simar and Wilson, 2007).\nTable 1. Distribution of centres analyzed\nby area.\nN. % centres\ncentres analyzed\nBiology and Biomedicine\n21\n76.19\nNatural Resources\n19\n73.68\nPhysical Sciences and Tech. 24\n66.67\nMaterial Science and Tech.\n9\n100.00\nChemical Sciences and Tech. 14\n64.29\nFood Science\n6\n50.00\nAgriculture Science\n12\n83.33\nResearch area\n\nResults\nThe CSIC is the main research\ninstitution\nin\nSpain.\nIt\nis\nmultidisciplinary and it is organized into\neight scientific areas. The CSIC\nemploys around 2,200 researchers (3%\nof human resources related to research\nin Spain) and contributes 20% of\nSpanish output to the international\ndatabase Web of Science, just behind\n2005\n\nUniversities (63%) and the Health\nSector (23%) (Gómez et al, 2010). The\ntable 1 shows the scientific areas and\nbrief summary about the number of\ncentres/institutes analyzed in each\nresearch area.\nIn particular we will analyse partial\nmodels of knowledge production,\nincluding only scientific production (i.e.\ninternational and national production)\nand a comprehensive model including\nboth technological (i.e. patents) and\nscientific activities.\nTable 2 illustrates the specifications of\nthe models that we empirically estimate\nin this first empirical effort.\nInputs specification\nOutputs specification\nMODEL 1-Scientific production\n- Total scientists\n- N. of ISI papers\n- Post-doctoral\n- N. of non ISI papers\nresearchers\n- Other publications\n- Funds from research\nprojects\nMODEL 2-Technological and Scientif\nProduction\n- Total scientists\n- Number of patents\n- Post-doctoral\n- N. of ISI papers\nresearchers\n- N. of non ISI papers\n- Funds from research\n- Other publications\nprojects\nMODEL 3-Knowledge transfer\n- Gross Domestic\n- N. of PhD students\nProduct\n- N. of post graduate\n- Agglomeration Index\ncourses\n- Efficiency level of\n- N. of contracts with\nknowledge production\nthird parties\n\nWe will then model how knowledge\ntransfer activities are carried out by\nCSIC institutes.\nIn modelling knowledge transfer we\nconsider the efficiency of knowledge\nproduction as one input that contributes\nto the knowledge transfer activity. Of\ncourse this input has to be combined\nwith the other inputs that affect the\nknowledge transfer, that we proxy with\nthe Gross Domestic Product (GDP) and\nthe Agglomeration Index. We use the\nGDP as an input to proxy the lively and\nrichness of the regional context in terms\n2006\n\nof knowledge activities and knowledge\ntransfer channels (both formal and\ninformal ones); see at this purpose,\nBishop, D’Este and Neely (2011). Our\nchoice of the Agglomeration Index as an\ninput is consistent with previous\nliterature that found the existence of\nagglomeration economies - related to\nlabor market pooling, input sharing and\nknowledge spillovers- that attenuate\nwith distance (see e.g. Rosenthal and\nStrange, 2004).\nDiscussion\nIn this research we provide some first\npreliminary investigation on issues that\nare not very explored in the literature,\nrelated to the evaluation of the\neffectiveness of knowledge transfer that\ngenerates from the knowledge produced\nby the Spanish CSIC. From the first\ninvestigations we conducted the\nfollowing policy implications seem to\nemerge:\n1. The evaluation of Public Research\nOrganizations should relate not only the\nformal scientific and technological\nactivities carried out (which relays on\npublications and patents) but should also\nbe based on teaching, contracts with\nthird entities and in general other third\nmission activity indicators;\n2. The localization of research institutes\nshould be planned not only in\nagglomerated\nand concentrated big\nareas with other research centres but\nshould take also into account the\nspecificities of the territory and the\nmatch between research activities\ncarried out and territorial devotion.\nFurther investigations will be directed to\ncheck if the preliminary results we\nfound in this paper are consistent by\napplying\nthe\nrecent\ndeveloped\nnonparametric conditional methodology\n(Daraio and Simar, 2007; Daraio, Simar\n\nand Wilson, 2010; Badin, Daraio and\nSimar, 2012).\nAcknowledgments\nThis study has been carried out by Elba\nMauleón during her Postdoctoral\nProgram supported by the Spanish\nEducation Ministry and FECYT.\nReferences\nDaraio, C., Simar L. (2007), Advanced\nRobust and Nonparametric Methods\nin Efficiency Analysis. Methodology\nand Applications, Springer, New\nYork.\nBadin, L., Daraio, C. and L. Simar\n(2012), How to measure the impact\nof environmental factors in a\nnonparametric production model,\nEuropean Journal of Operational\nResearch.\nCharnes, A., Cooper, W., and Rhodes,\nE. (1978), Measuring the efficiency\nof decision making units, European\n\nJournal of Operational Research,\nVolume 2, pp. 429-444.\nFarrell, M.J. (1957), The measurement\nof productive efficiency, Journal of\nthe Royal Statistical Society, Series\nA 1, 20, 253-281.\nGómez, I.; Bordons, M.; Morillo, F.;\nGonzález-albo, B.; Candelario, A.;\nHerrero, A. (2010). La actividad\ncientífica del CSIC a través del Web\nof Science. Estudio bibliométrico del\nperiodo 2004-2008. Madrid,\nIEDCYT, CCHS, CSIC, 2010. 1.039\npág.\nhttp://hdl.handle.net/10261/22941\nPlan de Actuación, 2006-2009. (2006).\nConsejo Superior de Investigaciones\nCientíficas.\nSimar, L and P. W. Wilson (2007),\nEstimation and Inference in TwoStage, Semi-Parametric Models of\nProduction Processes, Journal of\nEconometrics, 136(1), 3164.\n\n2007\n\nHOW MUCH MATHEMATICS IS IN THE BIG TWO\nAND WHERE IS IT LOCATED?\nGunar Maiwald1\n1\n\nmaiwald@zib,de\nKonrad-Zuse-Zentrum für Informationstechnik Berlin (ZIB), Takustrasse 7,\n14195 Berlin (Germany)\nIntroduction\nScopus and Web of Science (WoS) are\nthe two major and relevant citation\ndatabases. Both are multidisciplinary\nand base on own journal-based\nclassification systems. The variety of\njournals in both databases depends on\ndifferent selection criteria. Therefore not\nall scientific journals of a specific\ndiscipline are indexed. In recent studies\nthe coverage of different disciplines was\ninvestigated, e.g. Oncology (LópezIllescas, De Moya-Anegón &amp; Moed,\n2008) and Library and Information\nScience (Abrizah, Zainab, Kiran &amp; Raj,\n2012). The present paper addresses\nsome issues of Mathematics and its\nrepresentation and classification in WoS\nand Scopus.\nMathematics is a broad subject which\nranges from Pure Mathematics such as\nAlgebra, Analysis or Topology to\nApplied\nMathematics\nsuch\nas\nComputing, Numerical Analysis and\nMathematical Physics. This spectrum is\nreflected\nby\nthe\nMathematical\nClassification System (MSC). The\nrecent version from 2010 lists more than\n5000 classes, hierarchically nested\nwithin 63 top-level classes. Compared to\nMSC, the categories of both databases\nare less specific. Scopus lists 15 explicit\nMathematics classes. WoS does without,\nbut other studies assume five categories\n(Bensman, Smolinsky &amp; Pudovkin,\n2010)\n\n2008\n\nMathematics comes with two major\nreviewing databases, Mathematical\nReviews and Zentralblatt MATH (ZB).\nBoth declare its deep coverage of\nMathematics literature and each can be\nseen as comprehensive evidence of\nMathematics literature. According to its\npolicies not all subject-related content is\nindexed by Scopus and WoS.\nThis paper addresses the following\nquestions: (a) To what extent are\nMathematics related journals indexed in\nWoS and Scopus? (b) Which subject\ncategories in Scopus and WoS are\ndominated by Mathematics journals? (c)\nHow do WoS and Scopus subject\ncategories relate to MSC?\nMethods\nIn order to answer the present questions,\nthe following methods refer to the order\nof questions above. (a) The analysis\nbases upon the journals indexed in ZB.\nThis list is available with a web\ninterface (FIZ Karlsruhe GmbH, 2012).\nRecords without ISSN were eliminated,\nand those with identical ISSN were\naggregated to a single record. The\nintersection between ZB, Scopus and\nWoS was determined by pairwise\ncomparison of ISSN. (b) The result was\nbreaken down to the subject categories\nof Scopus and WoS. Per each category\nthe fraction of journals indexed in ZB\nwas determined to all journals of this\ncategory. (c) In contrast to WoS and\nScopus the MSC in ZB is assigned per\n\narticle. Articles have up to five classes\nassigned. To derive a relation between\nMSC and Scopus- and WoS-categories a\npairwise matching of journal articles\nwas done. Because literature indexed in\nScopus is limited to recent articles, the\nconsidered period is 1996-2011. In\nfurther processing the 63 top-level\nclasses was taken in focus. To determine\nthe intersection efficiently, all datasets\nwere partitioned into subsets of ISSN\nand year. Therefore the pairwise\ncomparison of two datasets is limited to\nthe\npairwise\ncomparison\nof\ncorresponding subsets. Two articles in\ncorresponding subsets are considered to\nbe equal if normalized titles are equal or\nrelevant metadata (volume, issue, first\npage, last page) match. Per each\ncategory in WoS and Scopus the\nfraction of each top-level MSC was\ncalculated by pairwise article-matching.\nResults\nThe results presented refer to the order\nof questions above. (a) At the time of\ninquiry were 3.841 journals indexed in\nZB, 27.630 in Scopus and 18.247 in\nWoS. About 43% of journals indexed in\nZB could be detected in WoS or Scopus.\nFrom those detected ones two-third are\nlisted in both databases. Looking at the\nremaining journals, again\n\nFigure 1. Journals from Zentralblatt\nMATH indexed in Scopus and Web of\nScience\n\ntwo-third are indexed in Scopus and\none-third in WoS (Figure 1).\n(b) The journals indexed in ZB are\nassigned to nearly all categories in\nScopus and WoS, but as expected, with\na skewed distribution (Table 1).\nFourteen subject categories of Scopus\nhave a share of 60% and more of\nMathematics journals, among them a\ncategory for publications in the field of\nPhysics (Statistical and Nonlinear\nPhysics). At the same level there are six\nWoS-categories, two among them\n(Logic, Statistics &amp; Probability) are not\nidentified as Mathematics categories in\nother studies (Bensman et al., 2010).\nFraction of\nMathematics\njournals\n&gt;= 80%\n&gt;= 60%\n&gt;= 40%\n&gt;= 20%\n\nNumber of\ncategories\nin Scopus\n7\n14\n21\n30\n\nNumber of\ncategories\nin WoS\n5\n6\n16\n31\n\nTable 1. Number of Subject Categories in\nScopus and Web of Science and their\nfraction of Mathematics journals\n\n(c) As a basis for the analysis 1.1 Mio\narticles indexed in ZB and published\nbetween 1996 and 2011 were drawn\nfrom sample. About two-third of them\ncould match with articles in Scopus or\nWoS, and more than 50% matched with\nrecords in both databases. The subject\ncategories in Scopus and WoS show\ndifferent behaviour to MSC-classes.\nThe big categories in Scopus (Applied\nMathematics, Mathematics (all)) are\nspread over a big number of MSCclasses. Some of the narrower categories\n(Statistics and Probability, Logic) are\ndominated by only few MSC-classes\n(Figure 2).\nSimilar conduct can be seen in WoS: the\nbig categories are covered almost evenly\nby a big number of MSC-classes. Some\n\n2009\n\nof the narrower categories are located\nmainly in only few MSC-classes.\n\nFigure 2. Minimal number of MSC-classes\nthat cover 20%, 40% and 60% of a\nsubject category – the 14 ScopusCategories with a fraction of at least 60%\nof Mathematics journals\n\nDiscussion\nFuture research might investigate\ndynamic aspects between MSC and the\nsubject categories in Scopus and WoS.\nAcknowledgments\nCertain data included herein is derived\nfrom the “Science Citation Index\nExpanded (SCIE) - Tagged Data”\nprepared\nby\nThomson\nReuters\n(Scientific) Inc. (TR®), Philadelphia,\nPennsylvania, USA: © Copyright\n\n2010\n\nThomson Reuters (Scientific) 2012, the\nScopus® Custom Data datasets, Elsevier\nB.V., Amsterdam, The Netherlands and\nthe “Zentralblatt MATH”, © FIZ\nKarlsruhe GmbH, 2012. All rights\nreserved.\nReferences\nAbrizah, A., Zainab, A. N., Kiran, K., &amp;\nRaj, R. G. (2012). LIS journals\nscientific impact and subject\ncategorization: a comparison\nbetween Web of Science and\nScopus. Scientometrics, 94(2), 721–\n740. doi:10.1007/s11192-012-08137\nBensman, S. J., Smolinsky, L. J., &amp;\nPudovkin, A. I. (2010). Mean\nCitation Rate per Article in\nMathematics Journals: Differences\nFrom the Scientific Model. World,\n61(7), 1440–1463.\ndoi:10.1002/asi.21332\nFIZ Karlsruhe GmbH. (2012).\nZentralblatt MATH - Serials and\nJournals. Retrieved December 18,\n2012, from http://www.zentralblattmath.org/zbmath/journals\nLópez-Illescas, C., De Moya-Anegón,\nF., &amp; Moed, H. F. (2008). Coverage\nand citation impact of oncological\njournals in the Web of Science and\nScopus. Journal of Informetrics,\n2(4), 304–316.\ndoi:10.1016/j.joi.2008.08.001\n\nIDENTIFICATION METHOD ON LOW QUALITY\nPATENTS AND APPLICATION IN CHINA\nZhang Mier1, Hu Suya2 and Guo Wei3\n1\n\nZHMILL@dlut.edu.cn, 2HUSUYAY@hotmail.com, 3GUOWI@hotmail.com\nDalian University of Technology, School of Business Management, 116023 Dalian\n(China)\nIntroduction\nIn the past decade, China has\nexperienced rapid growth in science,\ntechnology and economy. It has also\nmade remarkable progress in the field of\npatents. China on doubt became the\nfastest growing country. In 2011, the\nState Intellectual Property Office (SIPO)\nreceived 526,412 invention patent\napplications and China surpassed the\nU.S. and Japan in patent application for\nthe first time.\nMeanwhile, low quality patents are\nspringing up. The negative effects are\nshowing up. Fu (2009) suggests that\nteachers are accustomed to regard patent\nfiling as means of fulfilling assessment\nrequirements. Zheng et al. (2009) deem\nthat patent system makes applicants to\nimplement the strategy of high quantity\nand low quality. However, relevant\nquantitative research is rather rare. It is\nan urgent task to identify low quality\npatents.\nIdentification method of low quality\npatents\nPrinciples of index selection\nWhen choosing index, we should\nconsider some indicators are influenced\nby technical features easily. This would\naffect the applicability of study. Next,\nthe study relies on patent data, but\npatent documentations vary in different\ncountry and database. We should utilize\n\ncommon\ninformation.\nBesides,\nconfronted with big data, we’d better\nchoose some simple and direct indexes.\nThis could enable us to filter out low\nquality patents precisely.\nBased on above analysis, three\nprinciples should be satisfied. Firstly\nuniversality, the research method should\nbe applied to different fields, different\nregions and different countries, so as to\ndo\nin-depth\nanalysis.\nSecondly\ncalculability, the index should be\nobtained directly or by calculating.\nThirdly feasibility, because of the large\nscale of patent data, we should choose\nsimple and direct index as much as\npossible.\nIndex selection\nOn the basis of these principles, we\nshould\ntake\nmutual\npatent\ndocumentation information of main\neconomic entity into consideration.\nThen citation index could be ruled out.\nOnly U.S. patent documentations\ncontain integrated information of\ncitation. China has no citation\ninformation.\nPatentees know best about their patent\nquality. Griliches (1990) claims\npatentees would choose to maintain\npatent only when prospective earnings\nare greater than maintenance fee.\nGronqvist (2009) considers the longer\nmaintenance time of a patent, the more\nworthy it is. Barney (2003) stresses high\nmaintenance rate is in accordance with\n\n2011\n\nhigh quality. Harhoff et al. (1999) shows\nthat expiration patents are of higher\nquality than early termination patents.\nSo, the index of maintenance could be\nused to exclude low quality patents.\nThe threshold\nAfter index selection, there should be\nappropriate threshold to work as\nscreening standard. It is the lowest time\nthat identifies low quality patents.\nPatent maintenance fee is one of the key\nfactors to determine the threshold. Qiao\n(2011) holds the view that the ratio of\nexpiration is proportional to patent\nquality. According to patent laws in\nChina,\nthe\namount\nof\npatent\nmaintenance fee goes up one stair\ntriennially in the first fifteen years and\nthen only one stair at the last five years.\nTab.1 Patent Maintenance Fee\nPeriod\n(year)\n1-3\n4-6\n7-9\n10-12\n13-15\n16-20\n\nAnnual fee\n(CNY)\n900\n1200\n2000\n4000\n6000\n8000\n\ntotal fee\n(CNY)\n2700\n6300\n12300\n24300\n42300\n82300\n\nIn order to determine the threshold, we\nshould consider the upper limit time of\ninvention\npatents,\nthe\naverage\nmaintenance time of Chinese patents,\nand the stepped feature of patent\nmaintenance fee. So, we set 6 years as\nthe threshold.\nApplication example: low quality\npatents in telecommunication\nResearch sample\nWe rely on Chinese patent database and\nchoose\ninvention\npatents\nin\ntelecommunication as research sample.\nAccording to the IPC code, its class is\nH04, including 11 subclasses.\n\n2012\n\nBased on the nationality of applicants,\nChinese patents could be divided into\ntwo categories: domestic patents and\nforeign patents. It will be conducive to\nanalyze the formation and variation\ntendency about low quality patents via\ncomparing the domestic and foreign low\nquality patents.\nTab.2 The Quantity of Invention Patents\nand Low Quality Patents\nInvention\nLow quality\npatents\npatents(T&lt;6)\nA\nB\nA\nB\n1990\n23\n143\n21\n31\n1991\n26\n119\n18\n19\n1992\n27\n156\n20\n47\n1993\n30\n87\n25\n16\n1994\n16\n106\n15\n25\n1995\n16\n91\n14\n14\n1996\n22\n92\n15\n11\n1997\n23\n111\n16\n20\n1998\n20\n144\n10\n25\n1999\n31\n248\n22\n52\n2000\n149\n360\n70\n65\n2001\n159\n660\n66\n187\n2002\n109\n1607\n37\n394\n2003\n511\n3351\n129\n719\n2004\n1280\n4844\n309\n1019\n2005\n1188\n3963\n248\n893\n(A=domestic patents, B= foreign patents)\nYear\n\nData processing\nWe choose PIAS V3.0 as data source.\nIt’s a platform instrument combining\ninformation\nretrieval,\npatent\nmanagement and analysis. Aiming at\nChinese patents, we need to utilize\npatent\ninformation\nof\ninvention\nauthorization. So, we choose CNIPR\ndatabase to download data.\nSample data would trace back to 1990 in\norder to get longer time series and put\nforward to 2005 because of the\nthreshold. Use the search engine to\ngather information of the invalid date of\npatents. Calculate maintenance time of\neach invalid patent. Figure out the\npatents which maintenance time less\nthan 6 years.\n\nThe results show the number of patents\nand low quality patents are growing\nrapidly, especially after 2000. In view of\nthe fast increases in patent authorization,\nfurther analysis about the proportion of\nlow quality patents would be necessary.\n\nFig.1 The Trend of Low Quality Patents\n\nData analysis\nWith the rapid increase in patent\nauthorization, massive low quality\npatents are springing up in China. The\ngrowing number of low quality patents\nshows the trend of accelerating. The\naverage annual growth rate in 1990s and\n2000s is 10.01% and 53.25%\naccordingly. Not only are the domestic\nin vigorous growth, but also the foreign\npatents.\nThe ratio of low quality patents\nfluctuates at 25%. Domestic and foreign\nratio of low quality patents approach in\n2000s. This illustrates Chinese domestic\npatent quality is gradually improving.\nThe analysis of patentees shows that\nleading companies, such as Huawei\nTechnologies Co. Ltd and ZTE\nCorporation, turning into dominating\npatentees.\nConclusion\nWith the rapid growth of patents, patent\nfoam burst in China. Based on the\nanalysis of patent quality and patent\nmaintenance, an identification method\nand index are proposed. Taking\ntelecommunication patents in China as\n\nresearch samples, this method is\nemployed to identify low quality\npatents. The results demonstrate that\nthere are large numbers of low quality\npatents in this field.\nAcknowledgments\nThis research is supported by National\nNatural Science Foundation of China\n(71210307037, 71172138) and Natural\nScience Foundation of Liaoning\nProvince (201202038).\nReferences\nBarney, J. A. &amp; Barney, J. R. (2003).\nMethod and System for Rating\nPatents and other Intangible Assets:\nUS, 6556992.\nFu, Y., Ma, Q. &amp; Sheng, P. Z. (2009).\nAn Analysis on the Status-Quo of\nValid Patent in Universi-ties.\nScience of Science and Management\nof Science&amp; Technology, 8:45-49.\nGriliches, Z. (1990). Patent Statistics as\nEconomic Indicators: a Survey.\nJournal of Economic Literature,\n28(4):1661-1707.\nGronqvist, C. (2009).The Private Value\nof Patent Characteristics: Evidence\nfrom Finland. The Journal of\nTechnology Transfer, 34(2):159-168.\nHarhoff, D., Narin, F., Scherer, F. &amp;\nVopel, K. (1999). Citation\nFrequency and the Value of Patented\nInventions. The Review of\nEconomics and Statistics, 81:511515.\nQiao, Y. Z. (2011). The Research of the\nAnnual Fee Mechanism of Patent\nMaintenance. Studies in Science of\nScience, 29(10):1490-1494.\nZheng, Y. P., Dang, X. M. &amp; Yu, l. F.\n(2009). Study on the Radical Causes\nin Developing Status of University’s\nPatent Quality Based on the Change\nof Patent Status in Research Projects.\nScience&amp; Technology Progress and\nPolicy, 26(19):183-186.\n2013\n\nIMPACT AND VISIBILITY OF SA’S RESEARCH\nJOURNALS: ASSESSING THE 2008 EXPANSION IN\nCOVERAGE OF THE THOMSON REUTERS\nDATABASES\nAndroniki Pouris1, Anastassios Pouris2\n1\n\nandronikip@hotmail.com\nFaculty of Science, Tshwane University of Technology, Pretoria (South Africa)\n2\n\napouris@icon.co.za\nInstitute for Technological Innovation, University of Pretoria, Pretoria (South Africa)\nIntroduction\nIn South Africa journal evaluation has a\nlong history (POURIS 1986; POURIS\nAND RICHTER 2000; POURIS\n2005).During 2006 the Academy of\nScience of South Africa produced a new\nstrategic framework for South Africa’s\nresearch journals (ASSAf 2006). The\nframework recommends the periodic\npeer review of the country’s journals\nand a move into an open access system.\nDuring 2008 (Thomson-Reuters 2008)\nadded 700 regional journals in the Web\nof Science focusing on particular topics\nof regional interest. The number of\nSouth Africa set increased by 19\njournals. South Africa with 29 journals\nin the scientific domain is above New\nZealand, Ireland, Mexico and Israel. In\nthe social sciences South Africa is even\nabove countries like Japan and China\nprobably because of language issues.\nThis article aims to answer two\nquestions. First, we aim to compare the\nperformance of the journals indexed by\nthe JCR during 2002 with their\nperformance during 2009 and 2010 and\nsecondly to identify whether the newly\nadded SA journals in the JCR are of\nsimilar quality as the pre-existing\n2014\n\njournals. Both findings are of policy\ninterest\nand\nwe\ndiscuss\nthe\nconsequences of our findings.\nMethodology\nTwo approaches are used for the\ncomparison and assessment of journals –\nexpert opinion (Zhou et al 2002) and\ncitation analysis (Ren and Rousseau\n2002).\nIn order to facilitate comparisons\namong journals belonging to different\nscientific disciplines we identify the\nquartile in which the various journals\nbelong within the disciplines in which\nthe journals are classified in JCR. So if a\nscientific\ndiscipline\ncovers\n20\ninternational journals we rank them in a\ndescending order according to their\nimpact factor and we classify them in\nfour quartiles. The top quartile includes\nthe five journals with the highest impact\nfactors.\nThe Performance of South African\nJournals\nTable 1 shows that out of the 17 journals\nfive journals lost ground in terms of\nquartiles during the 2002-2009 period.\nTwo of them recovered during\n2010.Only one journal improved its\nperformance and moved from the third\n\nquartile to second one – the African\nJournal of Marine Science. Examination\nof the impact factors indicates that 12\njournals increased their impact factors.\nHowever,\nthese\nincreases\nwere\ninsufficient to move them into higher\nquartiles.\nTable 1: Impact factors&amp; Quartiles of\nPre-existing SA Journals in JCR-SCI2002, 2009 &amp; 2010\nIF\nIF\nQuart Quart Quart\n2002 2009 2002\n2009\n2010\nAFR ENTOMOL 0.455 0.42\n3\n4\n4\nAFR J MAR SCI 0.754 1.52\n3\n2\n3\nAFR ZOOL\n0.516 0.746\n3\n3\n2\nBOTHALIA\n0.358 0.242\n2\n4\n3\n4\n4\nJ S AFR I MIN\n0.052 0.216\n4\nMETAL\n3\nJ S AFR VET\n0.366 0.224\n3\n4\n3\nASSOC\nONDERSTEP J\n0.506 0.43\n3\n3\n3\nVET\nOSTRICH\n0.149 0.25\n4\n4\n4\nS AFR J ANIM\n0.381 0.412\n3\n3\n3\nSCI\nS AFR J BOT\n0.394 1.08\n2\n3\n4\nS AFR J CHEM 0.265 0.429\n4\n4\n4\nSAT\nS AFR J GEOL 0.659 1.013\n4\n2\n4\nS AFR J SCI\n0.7 0.506\n2\n3\n2\nS AFR J SURG 0.25 0.429\n4\n4\n4\nS AFR J WILDL\n0.224 0.562\n4\n4\n4\nRES\nSAMJ S AFR\n1.019 1.325\n2\n2\n2\nMED J\nWATER SA\n0.481 0.911\n3\n3\n3\nJournal\n\nTable 2: Impact factors &amp; quartiles of new\nSA journals added in JCR-SCI\nJournals\n\nIF 2009\n\nQuartile\n\nAFR INVER\nAFR J HERPET\nAJAR -A J AIDS\nINT SPORTM J\nJ S AFR IN C EN\nQUAEST MATH\nS AFR J ENO V\nS AFR J HIV M\nS AFR J IND E\nSAJOG - A J OB\nSAJP - S A J PS\n\n1.216\n0.455\n0.569\n0.171\n0.125\n0.267\n0.314\n0.457\n0.093\n0\n0.409\n\n2\n4\n4\n4\n4\n4\n4\n4\n4\n4\n\nS FORESTS\n\n0.5\n\n4\n\nQuartile\n2010\n3\n4\n4\n4\n4\n4\n3\n4\n4\n4\n4\n\n3\n\nreports. With the exception of the\nAfrican Invertebrate which is positioned\nin the second quartile of the relevant\njournals with impact factor 1.2, all other\njournals fall within the fourth quartile of\ntheir categories\nIn order to compare the quality of the\npre-existing journals with that of the\nnew journals as it is manifested in their\nimpact factors we undertook a twosample t-test. The test identified that we\ncannot reject the null hypothesis that the\ntwo sets of journals come from the same\npopulation.\nTable 3 shows the SA journals in the\nJCR social sciences citation index. The\n* indicate the journals which were\nindexed during 2002. South Africa is\nrepresented by 16 journals during 2009\n(4 during 2002). A two-sample t-test in\nthe two sets of journals again indicates\nthat all journals are coming from the\nsame population as far as their impact\nfactors are concerned.\nTable 3: Impact factors and quartiles of\nSA journals in JCR-SSCI\nJournal Name\nAJAR - AFR J AIDS\nRES\nANTHROPOL S AFR\nEDUC CHANGE\nLEXIKOS\nPERSPECT EDUC*\nPOLITIKON - UK\nS AFR GEOGR J\nS AFR J BUS MANAG\nS AFR J ECON*\nS AFR ECON MANAG\nS\nS AFR J EDUC\nS AFR J HUM RIGHTS\nS AFR J PSYCHOL*\nSAJP - S AFR J PSYCHI\nSO AFR LINGUIST\nAPPL\nSOC DYNAMICS*\n\nImpact\nFactor\n2009\n\nQuart\n2009\n\nQuart\n2010\n\n0.569\n\n4\n\n4\n\n0.222\n0.17\n0.667\n0.387\n0.216\n0.207\n0.146\n0.248\n\n4\n4\n3\n3\n4\n4\n4\n4\n\n4\n4\n2\n4\n4\n4\n4\n4\n\n0.082\n\n4\n\n4\n\n0.308\n0.692\n0.347\n0.409\n\n4\n3\n4\n4\n\n3\n4\n4\n\n0.066\n\n4\n\n4\n\n0.237\n\n3\n\n4\n\nTable 2 shows the new South African\njournals added in the journal citation\n2015\n\nReferences\nASSAf (2006) Report on a strategic\napproach to research publishing in\nSouth Africa, Pretoria\nPOURIS A. (1986). The South African\nJournal of Science: A Bibliometric\nEvaluation” South African Journal of\nScience 82(August): 401-2\nPOURIS A and RICHTER L. (2000)\nInvestigation into state funded\nresearch journals in South Africa,\nSouth African Journal of Science 96\n(March) 98-104\nPOURIS A. (2005). An assessment of\nthe impact and visibility of South\n\n2016\n\nAfrican journals, Scientometrics 62\n(2): 213-222\nREN S, ROUSSEAU R, International\nvisibility of Chinese scientific\njournals, Scientometrics, 53 (3)\n(2002) 389–405.\nTHOMSON REUTERS PRESS\nRELEASE (2008)\nhttp://science.thomsonreuters.com/pr\ness/2008/\nD. ZHOU, J. MA, E. TURBAN, N.\nBOLLOJU, A fuzzy set approach to\nthe evaluation of journal\ngrades, Fuzzy Sets and Systems, 131\n(2002): 63–74\n\nIMPACT OF BRAIN DRAIN ON SCIENCE\nPRODUCTION: A CASE STUDY OF IRANIAN\nEDUCATED MIGRANTS IN THE CONTEXT OF\nSCIENCE PRODUCTION IN CANADA\nKayvan Kousha1 , Ashraf Maleki, Mahdieh Hatami, Mahsa Ganji, Sheida\nVanoiee, Hamideh Asadi, Razieh Mehdizadeh-Maraghi, Alireza Badrloo, Samira\nGoodarzi, Shadi Moshtagh, Parisa Sepehr-Ara, Nima Gholami, Akram Siyahi,\nMohsen Tavakoli2\n1\n\nk.kousha@wlv.ac.uk\nStatistical Cybermetrics Research Group, School of Technology, University of\nWolverhampton, Wulfruna Street, Wolverhampton WV1 1LY (UK) and Scientometrics\nDepartment, University of Tehran (Iran)\n2\n\nmalekiashraf@ut.ac.ir\nMaster Students of Scientometrics, Library and Information Science Department,\nUniversity of Tehran, Enghelab sq., Tehran (Iran)\nIntroduction\nEmigration of highly educated people\nfrom developing to developed countries\nhas surged during the last decade\n(Lowell and Findlay, 2001). Canada is\nalso one of the countries that permits a\nlarge amount of immigrations from\ndifferent nations. According to the\nCitizenship and Immigration of Canada\n(CIC), Iran has been one of the top 10\ncountries in terms of immigration rate\nover the past decade and about 64,570\nIranians, mostly highly skilled, have\nbeen granted permanent residence of\nCanada during 2002-2011 (CIC, 2012).\nOther statistics of CIC also show that\ntotal entries of Iranian students to\nCanada have increased from 445\nstudents in 2002 to 1,252 in 2011.\nSeveral investigations have studied\nreasons for Iranians&#x27; migration to\ndeveloped countries (e.g., Garousi,\n2003;\nEntezarkheir,\n2005).\nNevertheless, it is not fully known how\n\nthis\nmay\ninfluence\nscientific\nproductivity of destination countries.\nReviewing scientific publications of\nCanada in engineering, we noticed many\nPersian authors’ names with Canadian\naffiliations. Having said that a huge\nnumber of highly educated Iranians have\nmigrated to Canada during the past\ndecade (CIC, 2012), the objective of this\nresearch is to determine the share of\nIranian authors&#x27; contribution in scientific\npublications of Canada. As a case study,\nwe limited our study to scientific\npublications of Canada in engineering\n(2005-2011). We also manually checked\na sample of Web CVs for Canadianaffiliated\nauthors\n(corresponding\nauthors, see below) with Persian names\nto assess their educational or\noccupational backgrounds.\nMethodology\nWe used Elsevier&#x27;s Scopus database to\nextract engineering articles published in\n2005-2011 by Canada.\nUltimately,\n39,493\narticles\nwith\nCanadian\n2017\n\ncorresponding authors were collected\nfor the purpose of the study.\nIdentifying Persian names\nTo assess Iranians’ contribution in\nscientific publications of Canada, 13\nmaster students went through an\nextensive human labour task and\nmanually checked 39,493 articles for\ncorresponding authors with Persian\nnames. We used corresponding authors\n(CA) as a better indicator for the\npurpose of study. Generally Iranian\nnames have some special characteristics\nand could be easily identified by native\nPersian people. For instance, suffixes\nlike -pour, -ni(y)a, -zadeh, -far, -nejad in\nIranian last names helped us to identify\nIranian authors. However, as the authors&#x27;\nlast names were not always enough to\nrecognize Iranian names, we also\nchecked the first names of the authors\neither as recorded in Scopus outputs or\nthrough online CVs, if necessary. Note\nthat we visited web CVs of a sample of\n320 (16.7%, α = 0.05) authors to\ndetermine the accuracy of method,\nfinding that there is only 1.6% error in\nidentification of Persian authors’ names,\nwhich proves it is reliable.\n\nFigure 1. Number(%) of Scopus\npublications with Persian names and\nCanadian affiliation in engineering (20052011)\n\n2018\n\nResults\nFigure 1 and 2 summarise main results\nof the study. The overall result indicates\nthat almost 1,908 unique corresponding\nauthors with Iranian names have\ncontributed to 4,614 scientific articles of\nCanada in engineering during 20052011. Most importantly, according to\nFigure 1 we can estimate that the\nproportion of articles with Canadianaffiliated Iranian CA to all the articles\nwith Canadian CA is 12% (4,614\narticles). It also suggests a constant\nincrease\nin\nthe\nproportion\nof\npublications with Iranian corresponding\nauthors and Canadian affiliation from\n8% in 2005 to 16% in 2011.\n\nFigure 2. Canadian-affiliated Iranian\nauthors&#x27; educational destination country\nin various levels.- Unknown:\nunavailability of information.\n\nFigure 2 gives more details about the\neducational\nbackgrounds\nof\ncorresponding authors with Persian\nnames based on manual checking of 315\nsampled online CVs. It indicates that\nabout 87% (274 authors) of the sampled\nauthors have received their BS degrees\nin the Iranian universities, whereas this\nis only 4% (12 authors) for other nonIranian countries (including Canada\nwith 2%). Note that 9% of CVs did not\ninclude\nany\ninformation\nabout\neducational backgrounds of authors.\nThis confirms that many Iranian highly\neducated human capitals have migrated\n\nto Canada after undergraduate education\nand could substantially have a\nsignificant impact on Canadian research\nproductivity. Figure 2 also reports that\nabout 83% of authors have received\ntheir PhD in the Canadian universities.\nFurther analysis of CVs revealed that\n67% and about 50% Iranian authors\nreceived their BS and MS degrees\nrespectively\nfrom\ntop\nIranian\nuniversities in engineering such as\nSharif University of Technology,\nUniversity of Tehran, Isfahan University\nof Technology, Amirkabir University of\nTechnology, and Iran University of\nScience and Technology.\n\nAs shown in Table 1, content\nanalysis of sampled CVs disclosed\nthat 76% of authors have\noccupations\nat organizations or\nuniversities abroad (mostly in\nCanada) and only 6% mentioned\npositions in Iran (return of migrates\nto the native land). This suggests\nhuge brain drain rate rather than\nother\npatterns\nof\nscientific\ncommunication such as mobility, or\nbrain exchange.\nTable 1. Current occupational position of\ntested sample\nCurrent occupational\nposition\nOccupied at organizations\nor universities abroad\nStudents at universities\nabroad\nOccupied at organizations\nor universities in Iran\nUnknown\nTotal\n\nNo. (%) of\ntested sample\n240 (76%)\n48 (15%)\n18 (6%)\n9 (3%)\n315 (100%)\n\nConclusions\nAlthough, scientific migration has\nbenefits for science and research\ncommunication,\nan\nextensive\noutgoing of skilled migrants and human\ncapitals from developing to developed\ncountries may have negative and\nsometimes damaging impact on\nexporting nations. The method here was\nuseful to assess how migration of\nIranian scholars to other countries can\nplay a major role in scientific production\nof hosting country and could be helpful\nfor the future research policy decision\nmaking in both sides. Bibliometric\nmethods can help to explore who is\nwinner and loser and what are the\nscientific and economic consequences\nfor developing countries in losing highly\nskilled human capital assets.\nReferences\nCIC (2012). Canada facts and figures.\nOntario. Retrieved from\nwww.cic.gc.ca/english/resources/stat\nistics/menu-fact.asp\nEntezarkheir, M. (2005). Why is Iran\nexperiencing migration and brain\ndrain to Canada? 34th annual\nconference of the Atlantic Canada\nEconomic Association, papers &amp;\nproceedings (pp. 1–30).\nGarousi,V. (2003). A survey on the\nimmigration of Iranian experts and\nthe elite: reasons, losses and possible\nsolutions. Scientific seminar on the\ndiscourse of overseas Iranian youth.\nTehran, Iran.\nLowell, BL and Findlay, AM.\n(2001). Migration of highly skilled\npersons from developing countries:\nimpact and policy responses.\nGeneva: International Labour Office,\nwww.ilo.org/public/english/protectio\nn/migrant/download/skmig-sr.pdf\n\n2019\n\nAN INDEX TO QUALIFY HUMAN RESOURCES OF\nAN ENTERPRISES CLUSTER\nYu Liu1 and Kun Ding1\n1\n\nrachelliuyu@hotmail.com, dingk@dlut.edu.cn\nWISElab, Dalian University of Technology, No.2 Linggong Road, Ganjingzi\nDistrict,116024, Dalian (China)\nIntroduction\nSince it was firstly and officially\nproposed by Hirsch (2005), the h-index\nand then the g-index by Egghe (2006)\nare gaining continuous focus and\nconstantly studies both theoretical and\nempirical.\nThe\nh-index\ncan\nsimultaneously represent the qualitative\nand quantitative meanings for scientific\nindicators such as patents, authors,\npublications, journals. Studies on hindex have seen some theoretical\nadvances (Egghe &amp; Rousseau, 2006;\nGlanzel, 2006; Hirsch, 2010), but they\nare still confined in qualifying the S&amp;T\nimpact or outputs of researchers\n(Oppenheim, 2007), journals (Braun,\nGlanzel &amp; Schubert, 2006), institutions\n(Molinari &amp; Molinari, 2008) or groups\n(Van Raan, 2006). Seldom study or\nextension of h-index was developed in\nother aspects or subjects.\nInspirited by the mechanism of h-index,\nwe presented l-index for the first time to\ndemonstrate\nhuman\nresources\ndistribution (HRD) in a set of\nenterprises, and initially defined 11 lindexes corresponding to 11 types of\nstaffs. The set of enterprises are sharing\none or more identities, for instance, the\nmajor industries. We aim to describe\nand\nevaluate\nthe\nintegrative\ntechnological innovative capacities of an\nenterprise cluster from human resources\nperspective, to describe the innovative\nresources of enterprises using a more\n\n2020\n\nvisual, simple but meaningful alternative\nrather than using mass data. Inheriting\nthe identities of h-index that both\nqualitative and quantitative, l-index is\nnot so obscure to be understood. The\nconception of l-index combines the\nbibliometrics&#x27; thinking and approaches\nwith the studies on enterprises, making\nbibliometrics&#x27; thinking be of more\npractical significance in enterprises\nresearch and contributing to the\ndevelopment of cross-disciplines.\nTheoretical and practical definitions\nDefinition\nIn a set of enterprises sharing one or\nmore identities, if at least x% ones of all\nmeet a condition that each of them owns\na certain type of staffs by x% or larger,\nthe l-index for this type of staffs of the\nenterprises&#x27; set equal to x.\n11 l-indexes\nWe initially developed 11 l-indexes,\neach of them corresponded to a type of\nstaffs: foreign experts, researchers,\nmanagers, other function staffs, staffs\nwith PhD degree, staffs with master\ndegree, staffs with bachelor degree,\nstaffs with degree below bachelor, staffs\nwith senior professional title, staffs with\nmedium-degree professional title, and\nstaffs with junior professional title. We\nsequentially remarked them by T1 to\nT11. All the 11 l-indexes -l1 to l11-could\ncompose an integral description for the\n\nstaffs&#x27; distribution of the enterprises\ncluster.\nFor example, if there are no less than 60\nout of 100 software R&amp;D enterprises,\nthe ratio of researchers for all the 60\nones is 60% or larger, then the value of\nthe researcher l-index of these 100\nsoftware R&amp;D enterprises is equal to 60,\ni.e. l2 of these 100 software R&amp;D\nenterprises is equal to 60. It is notable\nthat the l-indexes are explored and\nexploited to evaluating the overall HRD\nin a set of enterprises rather than in the\nindividual.\nFeasibility analysis\n3 variables\nWe defined the general proportion, the\naverage proportion, and the l-index as\nVar1, Var2 and Var3 respectively, all of\nthem are referring to a certain type of\nstaffs distributing in a set of enterprises\nwith varied populations. Var1 represents\nthe proportion that all the staffs of the\ntype account for of whole population,\nVar2 stands for mean value of the\nproportions that the staffs of the type\naccount for of every population, Var3\nrepresents l-index for the staffs of the\ntype. Variables&#x27; values of T1-T11\n(values of l1-l11) of 23 clusters (1\nrepresenting all the 256 Dalian\nenterprises183, and 7/6/9 respectively\nrepresenting attributions/ certifications/\nmajor industries) were calculated and\nillustrated in Fig.1- Fig.3.\nMethods\nTo testify the validities and accuracies\nof the l-indexes, methods were adopted,\ne.g. correlation analysis and variances\ncomparisons.\n\n183\n\nYear of data collecting: 2012.\n\nProcesses and results\nTo begin with, we analyzed relations\nbetween the 3 variables and found out\nthat each one was significantly related to\nanother with values all close to 1, and\nVar3 was more related to Var2, proving\nthat (1) l-indexes can surely replace\ntraditional evaluating indicators, and\nthat (2) Var3 can be represented by Var2\nbetter than by Var1, implying Var3 can\nprecisely reflect the average level of\nHRD rather than roughly represent an\napproximate value. Then we compared\nvariances of the 3 variables and every\ncouples. It turned out that the variance\nof Var2-3 couple was generally smaller\nthan that of Var1-3 couple for most\nstaffs&#x27; types, assistant proving l-indexes&#x27;\ncredibility. Meanwhile\nwe\nhave\nabstracted some interesting conclusion\nfrom the outcomes that R and BAC were\nthe most significant human resources\ncomponents of all clusters, and that\nBBAC and staffs with a professional\ntitle were not generally distributing in\nthese enterprises.\nEmpirical studies\nWhen we testified the feasibilities of lindexes, we made all the values of 11 lindexes worked out as well (Fig.1Fig.3). Not only we made an overview\nof HRD by l-indexes, we also testified 5\nhypothesizes about HRD regulations\nthat (1) T2 are much more than any\nother while T3 are to the contrary; (2)\nT7\noccupy\nthe\nmajor\nstatus\naccompanying with smaller but stable\nT5 and T6 proportions; (3) T1, T2 and\nT3 are generally better educated than\nT4; (4) the grades of professional titles\nare positively related to the educational\nbackground; (5) staffs with professional\ntitles are not commonly distributing in\nany enterprises type. They were once\nproved by Var1 and Var2 and testified\nagain by l-indexes. At last, it was proved\nthat T1-T11 composed an maximum\n2021\n\nindependent group by each of the 3\nvariables.\nConclusion and prospection\nTheoretical principles and empirical\nstudies of l-indexes were worked out.\nThough more testing and moderating\nwould still be needed, this series of lindexes for human and the hiding\nthinking would absolutely benefit our\nfurther study. We&#x27;re hoping and working\nto develop other indexes following the\nmechanism of h-index such as leaders in\nenterprises.\nAcknowledgments\nThere are loads of people I want to give\nthanks to. Thanks Prof. Ding for\nkeeping giving tutorial to me, thanks my\nfamily for they always mentally support\nme, and thanks Doc. Gao as well as\nother\ncolleagues\nof\nmine\nfor\nconstructively advising and inspiring\nme.\n\nFigure 1. Var1&#x27;s values of T1-T11 of 23\nclusters\n\nFigure 2. Var2&#x27;s values of T1-T11 of 23\nclusters\n\n2022\n\nFigure 3. Values of l1-l11 of 23 clusters\n\nReferences\nBraun, T., Glanzel, W., &amp; Schubert A.\n(2006). A Hirsch-type Index for\nJournals. Scientometrics, 69(1),\n169-173.\nEgghe, L. &amp; Rousseau, R. (2006). An\ninformetric model for the Hirschindex. Scientometrics, 69(1), 121129.\nEgghe, L. (2006). Theory and practice\nof the g-index. Scientometrics, 69(1),\n131-152.\nGlanzel, W.(2006). On the h-index - a\nmathematical approach to a new\nmeasure of publication activity and\ncitation impact. Scientometics, 67(2),\n315-321.\nHirsch, J.E. (2005). An index to\nquantify an individual&#x27;s scientific\nresearch output. Proceedings of the\nNational Academy of Sciences,\n102(46), 16569-16572.\nHirsch, J. E. (2010). An index to\nquantify an individual&#x27;s scientific\nresearch output that takes into\naccount the effect of multiple coauthorship. Scientometrics, 85, 741754.\nMolinari, J. F. &amp; Molinari, A. (2008). A\nNew Methodology for Ranking\nScientific Institutions.\nScientometrics, 75(1), 163-174.\nOppenheim, C. (2007). Using the hIndex to rank influential British\nresearchers in information science\nand librarianship. Journal of the\nAmerican Society for Information\nScience and Technology, 58(2),\n297-301.\n\nVan Raan, AFJ. (2006). Comparison of\nthe Hirsch-index with standard\nbibliometric indicators and with peer\n\njudgment for 147 chemistry research\ngroups. Scientometrics, 67(3), 491502.\n\n2023\n\nAN INTERPRETABLE AXIOMATIZATION OF THE\nHIRSCH-INDEX\nDenis Bouyssou1 and Thierry Marchant2\n1\n\nbouyssou@lamsade.dauphine.fr\nUniversité Paris Dauphine - CNRS, Place du Maréchal de Lattre de Tassigny, F-75775\nParis Cedex 16 (France)\n2\n\nthierry.marchant@ugent.be\nGhent University, H. Dunantlaan 1, 9000 Ghent (Belgium)\nIntroduction\nIn the last ten years, many bibliometric\nindices have been proposed for\ncomparing and/or evaluating scientists.\nAmong theses indices, the Hirsch-index\n(or h-index) is probably the most\npopular one. Since it is not clear which\nindex is best, some researchers have\ntried to enrich the debate by analyzing\nvarious indices from an axiomatic\nperspective. This stream of research has\ndelivered six184 axiomatizations of the hindex: Woeginger (2008a,b), Quesada\n(2009), Quesada (2010), Quesada\n(2011), Miroiu (2013). They pave the\nway towards a better understanding of\nthe h-index, but they are not completely\nsatisfactory. That is why we propose a\nnew axiomatization.\nExisting axiomatizations and their\nshortcomings\nConsider an index h&#x27; defined as 100\ntimes the h-index. Is it worse or better\nthan the h-index? This question is\n184\n\nNotice that Marchant (2009) does not\nbelong to this list because it does not\naxiomatize the h-index, but the ranking\ninduced by the h-index. Burgos (2010) and\nGagolewski (2011) do also not belong to the\nlist because they do not axiomatize the hindex but a family of indices containing the\nh-index.\n2024\n\nobviously irrelevant, just like asking\nwhether measuring distances in meter is\nbetter\nthan\nin\ncentimeters.\nUnfortunately,\nall\naforementioned\npapers axiomatize the h-index instead of\nconsidering the family of all indices h&#x27;\nsuch that h&#x27; is equal to k times h. The\naxioms in these papers are therefore\nstronger then needed: they implicitely,\nor sometimes explicitely, state that the\nh-index of a scientist with one\npublication and one citation is one,\nwhile this actually does not matter.\n\nWe now discuss some specific\nproblems.\n\nWoeginger (2008a)\nTheorem 4.1 in Woeginger (2008)\ncharacterizes the h-index by three\naxioms called A1, B and D. Axiom A1\nis stated as follows: “If the (n+1)dimensional vector y results from the ndimensional vector x by adding a new\narticle with f(x) citations, then f(y) ≤\nf(x).” Although this axiom is\nmathematically fine, we claim that it is\nnot interpretable. Indeed, an axiom is a\ncondition imposed on the index f, where\nf is any index, not necessarily the hindex. So, when we read this condition,\nwe may not suppose that f is the h-index.\nIt could be the square of the number of\npapers or the logarithm of the total\nnumber of citations, ... It does therefore\n\nnot make sense to say “if we add a new\npaper with f(x) citations, then ...” Why\nwould we find such a condition\n(normatively) appealing if we do not\nknow what f(x) represents? Axiom D\nhas the same problem.\nWoeginger (2008b)\nThis paper assumes that a bibliometric\nindex must be a non-negative integer.\nThis is very restrictive and difficult to\nmotivate. It also uses axiom A1 as in\nWoeginger (2008a).\nQuesada (2009)\nHere, Axiom A1 imposes that f(x) lies\nbetween (a) the minimum of the number\nof cited papers and the smallest number\nof citations (not taking uncited papers\ninto account), and (b) the minimum of\nthe number of papers and the largest\nnumber of papers. This is a complex\ncondition. Actually, it combines several\nconditions.\nMiroiu (2013)\nThis paper also assumes that a\nbibliometric index must be a nonnegative integer. Besides, it uses some\naxioms (CPI, PR, CCI and CJ) that\nsuffer the same problem as axiom A1 in\nWoeginger (2008a): they compare an\nunspecified index to a number of\ncitations. This is not interpretable as\nlong as we do not know which index is\nconsidered.\nA new axiomatization\nAmong the aforementioned axiomatizations, those of Quesada seem most\npromising. We propose hereunder a list\nof axioms, inspired from those of\nQuesada, and we use them to axiomatize\nthe family of all indices h&#x27; such that h&#x27; is\nequal to k times h.\n\nNon-Triviality: there are scientists x, y\nsuch that f(x) ≠ f(y).\nZero: scientists with no paper or only\nuncited papers have an index equal to 0.\nTail Independence: suppose x and y\nhave the same number of papers and f(x)\n= f(y). Suppose both publish an\nadditional paper, with the same number\nof citations, at most equal to the number\nof citations of the least cited paper of x\nand y. Then f(x&#x27;) = f(y&#x27;).\nSquare Upwards: suppose x has m\npapers, each with m citations. Suppose x\ngets some additional citations. Then f(x&#x27;)\n= f(x).\nSquare Rightwards: suppose x has m\npapers, each with m citations. Suppose x\npublishes some additional papers with at\nmost m citations. Then f(x&#x27;) = f(x).\nHomothety: suppose x has m papers,\neach with m citations, and y has one\npaper, with one citation. Then f(x) = m\nf(y).\nTheorem : an index f satisfies NonTriviality, Zero, A2 (Quesada), Tail\nIndependence, Square Upwards, Square\nRightwards and Homothety iff f is the hindex multiplied by some positive real\nnumber.\nCompared to Theorem 3.1 in Woeginger\n(2009), our Theorem is more interesting\nbecause it axiomatizes the family of all\nh-indices. Moreover, it uses simpler\naxioms. For instance, A1 has been\nsplitted into Square Upwards and Square\nRightwards.\nReferences\nBurgos, A. (2010). Ranking scientists.\nUMUFAE Economics Working\nPapers, Universidad de Murcia, 2.\nGagolewski, M. (2011). Possibilistic\nanalysis of arity-monotonic\naggregation operators and its relation\n2025\n\nto bibliometric impact assessment of\nindividuals. International Journal of\nApproximate Reasoning, 52, 13121324.\nMarchant, T. (2009). An axiomatic\ncharacterization of the ranking based\non the h-index and some other\nbibliometric rankings of authors.\nScientometrics, 80, 325-342.\nMiroiu, A. (2013). Axiomatizing the\nHirsch index: Quantity and quality\ndisjoined. Journal of Informetrics, 7,\n10-15.\nQuesada, A. (2009). Monotonicity and\nthe Hirsch-index. Journal of\nInformetrics, 3, 158-160.\n\n2026\n\nQuesada, A. (2010). Further\ncharacterizations of the Hirsch\nindex. Scientometrics, 87, 107-114.\nQuesada, A. (2011). More axiomatics\nfor the Hirsch index. Scientometrics,\n82, 413-418.\nWoeginger, G. H. (2008a). An\naxiomatic characterization for the\nHirsch-index. Mathematical Social\nSciences, 56, 224-232.\nWoeginger, G. H. (2008b). A symmetry\naxiom for scientific impact indices.\nMathematical Social Sciences, 2,\n298-303.\n\nINTERPRETING EPISTEMIC AND SOCIAL\nCULTURAL IDENTITIES OF DISCIPLINES WITH\nMACHINE LEARNING MODELS OF\nMETADISCOURSE\nBradford Demarest 1 and Cassidy R. Sugimoto 2\n1\n\nbdemares@indiana.edu\n\n2\n\nsugimoto@indiana.edu\n\nIndiana University, School of Library and Information Science, 1320 East 10th\nStreet, LI 011; Bloomington, IN 47405-3907 (United States)\nIntroduction\nScholars of academic disciplinary\ndifferences note that these differences\nencompass not only differences in topic,\nbut also in “sanctioned social\nbehaviours, epistemic beliefs, and\ninstitutional structures of academic\ncommunities” (Hyland, 2004, p.2).\nDiscerning these disciplinary differences\nthrough text analysis has been mostly\nlimited to qualitative or corpus methods,\nand has mostly excluded machine\nlearning based\nmethods\n(except\nArgamon, Dodick, and Chase [2008]).\nFurther, the research of disciplinary\nbeliefs and behaviors as reflected in\ndiscourse has almost entirely focused on\nresearch articles, despite genre scholars’\ncontention that writing patterns can vary\nwidely among genres (Hyland, 2004).\nThe current study seeks to address both\nof these gaps in the literature by\nmodeling\nsocial\nand\nepistemic\ndifferences through a machine-learning\napproach\namong\nphilosophy,\npsychology, and physics based on\nmetadiscourse (words or phrases in a\ntext that position the author, the text\nitself, and the reader in relation to one\nanother [Hyland, 2005]) used in\ndissertation abstracts. A previous study\n\nof dissertation abstracts (Demarest &amp;\nSugimoto,\n2013)\nexplored\nthe\nmetadiscourse use of disciplines in\ncontrast to multiple other disciplines,\nbut left aside contrasts between specific\ndisciplines, which the current study\nundertakes. The findings of both studies\nsupport previous qualitative and corpusbased studies (Becher, 1987; Hyland,\n2008),\nwhich\nestablished\nepistemological and social differences\namong hard sciences, social sciences,\nand humanities. The current study asks\ntwo research questions: 1) Can\nmetadiscourse be used via a machine\nlearning approach to model disciplinary\ndifferences in the dissertation abstract\ngenre in ways that can empirically test\nexisting theories of disciplinary culture?\n2) How could such a model offer a way\nto position disciplines in relation to one\nanother in a network of metadiscursive\n(and thus social and epistemic)\nproximity?\nMethods\nDissertation abstracts from 1990-2008\nin a subject category containing one of\nthe strings “physics”, “psychology”, or\n“philosophy” were taken from the\nProQuest database (excluding abstracts\ncontaining two or more identifying\n2027\n\nstrings). The data set was then balanced\nfor discipline frequencies: the discipline\nwith the lowest number of abstracts was\nfound (philosophy) and abstracts were\nrandomly sampled from the other two\ndisciplines at a frequency based on the\nproportion of each larger discipline’s\nabstract count to philosophy’s, yielding\n49746\nabstracts\n(16602\nfrom\nphilosophy, 16592 from physics, and\n16552 from psychology).\nFor the set of features, 316 words and\nphrases expressing interaction from\nHyland (2005) were collected; removing\n13 cross-category duplicates and adding\nfour Americanized spellings for terms\n(“analyse”,\n“realize”,\n“realizes”,\n“realized”) yielded 307 features. After\ncollecting relative frequencies for each\nfeature for each abstract in the sample,\nthe WEKA machine-learning program\n(Hall et al., 2009) version 3.6.6 was\nused to create a multi-class sequential\nminimal optimization (SMO) support\nvector model (Platt, 1998), which\ncombines models of the three pairwise\ncombinations of disciplines. The\nPolyKernel kernel was used with default\nsettings and, based on results from the\nCVParameterSelection\noptimization\nalgorithm, a complexity parameter value\nof 10. The resulting model was then\ntested using ten-fold cross-validation for\nclassification accuracy.\nTable 1. Accuracy rates identifying\ndisciplines across pairwise models, and\noverall average.\nDiscipline\nPhilosophy\nPsychology\nPhysics\nAverage\n\nAccuracy (%)\n81.9\n77.2\n80.5\n79.9\n\nResults\nTable 1 presents the accuracy rate by\npercentage for each discipline, as well as\n\n2028\n\nthe accuracy percentage averaged across\nall three disciplines.\nTable 2 contains a confusion matrix\npresenting counts of correct and\nincorrect\nclassifications\nof each\ndiscipline.\nThe leftmost column\ndesignates\nactual\ndisciplines\nof\nabstracts, with other columns containing\nthe numbers of abstracts classified as the\ncolumn’s discipline.\nTable 2. Confusion matrix of disciplines.\nDiscipline\nPhilosophy\nPsychology\nPhysics\n\nPhilosophy Psychology\n13289\n1395\n1696\n12242\n853\n1519\n\nPhysics\n1918\n2614\n14220\n\nFeatures with weights having absolute\nvalues greater than 10 are discussed\nbelow as indicators of disciplinary\ndifferences..\nDiscussion and Conclusions\nThe first research question asks, “Can\nmetadiscourse be used via a machine\nlearning approach to model disciplinary\ndifferences in the dissertation abstract\ngenre in ways that can empirically test\nexisting theories\nof disciplinary\nculture?”\nThe psychology-philosophy model\nfound features indicating philosophy,\nsuch as “argue”, “claim”, and “my”,\nsuggest philosophy to be per Becher\n(1987) interpretive and humanistic.\nTerms such as “measure”, “indicate”,\nand “observe” most strongly indicate\npsychology, suggesting that it is\ncomparatively quantitative, per Becher’s\n(1987) description of pure sciences.\nFeature weights in the physicsphilosophy model also indicate that\nphilosophy is person-oriented (“my”,\n“the author”, and “one’s”) subjective\nand interpretive (“think”, “claim”,\n“know”, “feel”), while physics is\nquantitative, explanatory, and empirical\n(“observe”, “measure”, “sure”).\n\nThe physics-psychology model feature\nweights suggest physics to be relatively\nquantitative (“calculate”), cumulative\n(“known”), and empiricist orientation\n(“observe”, “show”), while psychology\nis relatively subjective (e.g. “assess”,\n“claim”, “you”, and “mine”), or\nstudying a subjective phenomenon\n(“feel”).\nRegarding the second research question\n(“How could such a model offer a way\nto position disciplines in relation to one\nanother in a network of metadiscursive\n[and thus social and epistemic cultural]\nproximity?”),\nTable\n3\nprovides\nproximity measures between disciplines,\nderived from Table 2 by translating\ncounts\ninto\nnormalized\ninverse\nindicators of distance. Table 3 reveals\nthe greatest distance from physics to\nphilosophy, and the shortest distance\nfrom psychology to physics. These\ndistances suggest the relative ability of\neach discipline to incorporate the\nepistemic and social terminology of\nother disciplines, either instrumentally\n(e.g., in a quantitatively inclined wing of\npsychology) or topically (e.g., in the\nphilosophy of science).\nTable 3. Normalized inverse values of\nconfusion matrix\nDiscipline\nPhilosophy\nPsychology\nPhysics\n\nPhilosophy\n1.25\n9.76\n19.45\n\nPsychology\n11.90\n1.35\n10.92\n\nPhysics\n8.66\n6.33\n1.17\n\nFuture Research\nThe scientometric community has\nhistorically analyzed differences and\nsimilarities among disciplines, but at the\ndisciplinary level has relied on the\nanalysis of concepts, producers, and\nartefacts to expose the intra- and interdisciplinary terrain (Borgman, 1989).\nThe study of metadiscourse patterns\nadds a new object of analysis to this list,\nand can be used to investigate questions\n\nabout the basis, structure, and evolution\nof scientific communities.\nAcknowledgements\nWe would like to thank the National\nScience Foundation (Grant No. SMA1208804) for financial support, as well\nas ProQuest for sharing dissertation data\nwith us for research purposes.\nReferences\nArgamon, S., Dodick, J., &amp; Chase, P.\n(2008). Language use reflects\nscientific methodology: A corpusbased study of peer-reviewed journal\narticles. Scientometrics, 75(2), 203–\n238. doi:10.1007/s11192-007-1768y\nBecher, T. (1987). Disciplinary\ndiscourse. Studies in Higher\nEducation, 12(3), 261–274.\nBorgman, C. L. (1989). Bibliometrics\nand Scholarly Communication\nEditor’s Introduction.\nCommunication Research, 16(5),\n583–599.\ndoi:10.1177/009365089016005002\nDemarest, B. &amp; Sugimoto, C.R. (2013).\nUsing machine learning models to\ninterpret disciplinary styles of\nmetadiscourse in dissertation\nabstracts. Poster presented at\niConference 2013: Scholarship in\nAction, Forth Worth, TX.\nHall, M., Frank, E., Holmes, G.,\nPfahringer, B., Reutemann, P., &amp;\nWitten, I.H. (2009). The WEKA data\nmining software: An update.\nSIGKDD Explorations 11(1), 10-18.\nHyland, K. (2004). Disciplinary\nDiscourses: Social Interactions in\nAcademic Writing. Ann Arbor, MI:\nUniversity of Michigan Press/ELT.\nHyland, K. (2005). Metadiscourse:\nExploring Interaction in Writing.\nNew York, NY: Continuum.\nHyland, K. (2008). Disciplinary voices:\nInteractions in research writing.\n2029\n\nEnglish Text Construction, 1(1), 5–\n22. doi:10.1075/etc.1.1.03hyl\nPlatt, J. (1998). Fast training of support\nvector machines using sequential\nminimal optimization. In B.\n\n2030\n\nSchoelkopf, C. Burges, and A.\nSmola (Eds.), Advances in Kernel\nMethods - Support Vector Learning.\nCambridge, MA: MIT Press.\n\nAN INVESTIGATION OF SCIENTIFIC\nCOLLABORATION BETWEEN IRAN AND OTHER\nMENA COUNTRIES AND ITS RELATIONSHIP\nWITH ECONOMIC INDICATORS\nMaryam Fayazi1\n1\n\nmfayazi@alumni.ut.ac.ir\nUniversity of Tehran, Faculty of library and Information Science, Enghelab St., Tehran\n(Iran)\nIntroduction\nIt seems that the effect of collaboration\non citation rate maybe depend on the\ncooperating country (Kim, 2001; ) or on\nthe discipline (Frederiksen, 2004).\nScholars have differing opinions about\nthe factors can drive researchers to\ncollaborate. (Wagner, Brahmakulam,\nJackson, Wong &amp; Yoda, 2001) found\nthat geographic proximity, history,\ncommon language, economic factors,\nresearch equipment, databases, and\nlaboratories are factors influencing\ninternational collaboration. On the one\nhand Price (1963, p. 168) claimed that\ncollaborative authorship reflects more\neconomic than intellectual dependence.\nOthers have argued that co-authorship\nreflects mutual intellectual and social\ninfluence (Edge, 1979; Stokes &amp;\nHartley, 1989). Kim&#x27;s (2005) research\nhas shown that the expenditure on R&amp;D\ncorrelates\nnegatively\nwith\ninternationally\ncollaborative\npublications in Korea Acosta, Coronado,\nFerrandiz &amp; Leon (2011) found that\ndifferences in scientific resources\nbetween regions are relevant in\nexplaining\nacademic\nscientific\ncollaborations. Iran has political and\neconomic interaction and common\nculture and religion with Middle East\nand North Africa (MENA) countries.\n\nObjectives\nThe objectives of this study are: (a) to\ninvestigate the extent of scientific\ncollaboration between researchers from\nIran and other MENA countries as\nreflected in the WOS database during\n1999-2009; (b) to analyse the\nrelationship between the number of\nauthors and the number of times an\narticle is cited for the period of study;\nand (c) to examine the relationship\nbetween (i) the per capita GDP and (ii)\nthe GERD/GDP ratio of each country\nand its co-authorship with Iran.\nMethods\nThe definition of the MENA region\nfollows the World Bank delineation\nwhich includes: Algeria, Bahrain, Egypt,\nIran, Iraq, Jordan, Kuwait, Lebanon,\nLibya, Morocco, Oman, Qatar, Saudi\nArabia, Syria, Tunisia, Turkey, United\nArab Emirates (UAE) and Gaza, &amp;\nYemen (World bank, 2011). We added\nto this definition Turkey and removed it\nDjibouti, Israel and West Bank. The\nscientific\nproduction,\nco-authored\npublications, and citation, for 19992009, were retrieved from the WOS\ndatabase (SCI, SSCI, Conference\nProceedings CI–Science, Conference\nProceedings CI-Social Science and\nHumanities). Scientific productions\n2031\n\nwere retrieved by the formula CU=* in\nadvanced search. The star can be each of\nthe MENA countries. Iranian coauthored publications with each of the\nMENA countries was retrieved by the\nformula CU=Iran AND CU=* and then\nwe used Boolean OR to combine the\nsearch results. We used Subject category\nof Essential Science Indicator. The\nGross domestic product (GDP) based on\npurchasing-power-parity per capita\n(units Current international dollar) of\neach countries were retrieved from\nWorld Economic Outlook Databases\n(WEO,\nSeptember\n2011)\nof\nInternational Monetary Fund for 19992009. The Gross domestic expenditure\non\nresearch\nand\ndevelopment\n(GERD)/GDP ratio retrieved from\nUNESCO Institute for Statistics for\n1999-2009. All data were retrieved in\nNovember 2011.\nTable 1. MENA countries scientific\nproductions and rate of its collaboration\nwith Iran during 1999-2009\nScientific\nproduction\nTurkey\n175689\nKuwait\n7739\nUAE\n8279\nLebanon\n7174\nEgypt*\n43425\nSaudi Arabia\n21852\nSyria\n2003\nJordan\n8846\nQatar\n1769\nMorocco\n14141\nAlgeria\n11864\nOman\n3821\nTunisia\n18000\nIraq\n1683\nBahrain\n1277\nLibya\n1161\nYemen\n659\nGaza/Palestine\n0\nCountry\n\nco-authored\npublications\n299 (0.17)\n50 (0.646)\n49 (0.592)\n41 (0.572)\n39 a(0.09)\n32 (0.146)\n29 (1.448)\n22 (0.249)\n22 (1.244)\n21 (0.149)\n19 (0.16)\n19 (0.497)\n16 (0.089)\n11 (0.654\n6 (0.470)\n6 (0.517)\n2 (0.303)\n0\n\n* Iran as a membership of some international\norganization has scientific collaboration with other\ncountries, e.g. Iran has scientific collaboration\nwith Egypt through ICARDA.\n2032\n\nResults and discussion\nThere\nwere\n637\nco-authored\npublications in WOS for 1999-2009 (see\ntable 1).\nAnalysis of data indicated that there is a\nsignificant and moderate (N=18,\nSing.=0.004, Level=0.01, rho=0.637**)\nrelationship\nbetween\nscientific\nproductions of each MENA countries\nand the rate of its collaboration with\nIran. It suggests that Iranian researchers\nare more eager to collaborate with\ncountries that have high scientific\npotential.\nThe nonparametric tests revealed a\nsignificant\nand\nweak\n(N=637,\nSing.=0.000, Level=0.01, rho=0.213 **)\nrelationship between the number of\nauthors and the numbers of times an coauthored paper is cited in other papers.\nTable 2. Correlation test between GDP\nper capita of each country and its coauthorship with Iran\nCorrelation\ncoefficient\nLebanon\nPearson\nTurkey\nSpearman\nOman\nSpearman\nSyria\nSpearman\nEgypt\nSpearman\nKuwait\nPearson\nUAE\nSpearman\nBahrain\nSpearman\nAlgeria\nPearson\nMorocco\nSpearman\nTunisia\nSpearman\nJordan\nSpearman\nSaudiArabia Pearson\nLibya\nSpearman\nQatar\nSpearman\nCountry\n\nSign.\n0.000\n0.000\n0.000\n0.000\n0.001\n0.001\n0.002\n0.004\n0.005\n0.007\n0.01\n0.013\n0.13\n0.085\n0.596\n\nCorrelation\nr value\n0.951**\n0.909**\n0.908**\n0.871**\n0.869**\n0.863**\n0.823**\n0.787**\n0.777**\n0.761**\n0.732*\n0.719*\n0.715*\n0.543\n0.18\n\nMost of co-authored publications were\nin the fields of physics (123 records),\nclinical medicine (98), chemistry (90).\nAs Kim (2005) mentioned in his\nresearch, fields of physics, chemistry,\nand clinical medicine need very costly\n\nresearch laboratories that are exceeding\nthe budgeting of single countries.\nThe relationship between GDP and the\nGERD/GDP ratio of each country and\nits co-authorship with Iran, have been\ninvestigated for countries which their\nGDP and GERD/GDP ratio data were\navailable. If the frequency distribution\nof data was normal, we used Pearson\notherwise we used Spearman. The **\nand * show that there is a correlation in\nthe level of (0/01) and (0/05) (see table\n2) and (see table 3).\nTable 3. Correlation test between\nGERD/GDP ratio of each country and its\nco-authorship with Iran\nCorrelation\ncoefficient\nTurkey\nSpearman\nTunisia\nSpearman\nKuwait\nPearson\nEgypt\nSpearman\nSaudiArabia Spearman\nCountry\n\nSign.\n0.002\n0.01\n0.013\n0.408\n0.52\n\nCoefficient\nr value\n0.827**\n0.732**\n-0.719*\n0.342\n0.342\n\nConclusion\nWith respect to the result of this study, it\nseems that the cultural common interests\nplay few roles in creation of co-authored\npublications and economic factors and\npolitical relationship between countries\nare more effective in it. In MENA area\nTurkey and Saudi Arabia have a high\nscientific potential and scientific\ncollaboration with them may be useful\nfor Iran. The results of the study showed\nthat although Iran and Turkey are\nneighbour countries, the rate of their\nscientific cooperation was very low.\nFollowing the result of this research,\nscientific policymakers should invest in\nthe top scientific fields and common\nscientific productions of each of MENA\ncountries in the future, special with\ncountries that have high scientific\npotential and have strong positive\nrelationship between the amount of their\n\nscientific collaboration with Iran and\ntheir GPD or GEDR/GDP ratio.\nReferences\nAcosta, M., Coronado, D., Ferrandiz, E,\n&amp; Leon, M. (2011). Factors affecting\ninter-regional academic scientific\ncollaboration within Europe: The\nrole of economic distance.\nScientometrics, 78(1), 63-74.\nEdge, D. (1979). Quantitative measures\nof communication in science: a\ncritical review. History of Science,\n17, 102–134.\nFrederiksen, L. (2004). Disciplinary\ndeterminants of bibliometric impact\nin Danish industrial research:\nCollaboration and visibility.\nScientometrics, 61(2), 253-270.\nKim, M. (2001). A bibliometric analysis\nof physics publications in Korea,\n1994–1998. Scientometrics, 50(3),\n503-521.\n____ . (2005). Korean science and\ninternational collaboration, 1995–\n2000. Scientometrics, 63, 321–339.\nPrice, D. (1963). Little Science, Big\nScience. New York: Columbia\nUniversity press.\nStokes, T.D., &amp; Hartley, J.A. (1989).\nCoauthorship, social structure, and\ninfluence with specialties, Social\nStudies of Science, 19, 101–125.\nWagner, C., Brahmakulam, I., Jackson,\nB., Wong, A., &amp; Yoda, T. (2001).\nScience and Technology\nCollaboration: Building Capacity in\nDeveloping Countries. Callibornia:\nRAND.\nWorld Bank (2011). Middle East and\nNorth Africa. Retrieved April 6,\n2012, from\nhttp://web.worldbank.org/WBSITE/\nEXTERNAL/COUNTRIES/MENA\nEXT/0,,menuPK:247619~pagePK:1\n46748~piPK:146812~theSitePK:256\n299,00.html\n\n2033\n\nKEYWORD-QUERY EXPANSION USING\nCITATION CLUSTERS FOR PAPER\nINFORMATION RETRIEVAL\nKiyohiro Yamaguchi1, Junichiro Mori2, and Yuya Kajikawa3\n1\n\nkiyoya@gmail.com\nThe University of Tokyo, Innovation Policy Research Centre, Yayoi 2-11-16, Bunkyo-ku,\nTokyo (Japan)\n2\n\njmori@platinum.u-tokyo.ac.jp\nThe University of Tokyo, Presidential Endowed Chair for “Platinum Society”, Hongo 7-31, Bunkyo-ku, Tokyo (Japan)\n3\n\nkajikawa@mot.titech.ac.jp\nTokyo Institute University, Graduate School of Innovation Management, Shibaura 3-3-6,\nMinato-ku, Tokyo (Japan)\nIntroduction\nQuery expansion is an old but still active\nresearch topic to improve the\nperformance of information retrieval\nsystems by automatically modifying the\ninitial user query. There are some\nsophisticated approaches using a latent\nvariable model that represents a\ndocument as mixtures of topics\nincluding Latent semantic analysis\n(LSA) (Deerwester, et al., 1990),\nprobabilistic LSA (pLSA) (Hofmann,\n1999), latent dirichlet allocation (LDA)\n(Blei et al., 2003). However, because\npLSA’s generative semantics are not\nwell-defined (Blei et al., 2003), one\ncannot naturally handle an unseen\ndocument. And the number of\nparameters is affected linearly by the\nnumber of seen documents. It has been\nclaimed that these approaches are\noverfitting the model into the training\ndata. In this paper, we propose a query\nexpansion technique for paper retrieval\nto integrate topic model and citation\nnetwork analysis. Citation network\n\n2034\n\nanalysis is expected to cause moderate\ntopic drift to avoid overfitting.\nData and Methods\nData\nWe conducted a case study with the\ndataset of semantic web. We collected\ndata from the Science Citation Index\nand the Social Sciences Citation Index\ncompiled by the Thomson Reuters\n(formerly Institute for Scientific\nInformation). Because the whole data is\ntoo big, we made small test collections\nto carry out the experiments. The test\ncollection consists of papers that have\nthe terms semantic and/or web in the\nkeywords. It means that all collected\npapers have a relation to semantic web\nto a greater of lesser. We used semantic\nweb as the first query in the\nexperiments. A total of 26,633 papers is\ncounted and the number of citations is\n92,441. Only papers published before\n2004 (16,638 papers) were used as the\ntraining data set, and the other papers\npublished after 2005 were used as the\ntest data set.\n\nMethods\nWe propose a query expansion for paper\ninformation retrieval using not only\npaper keywords but citation networks to\nexpand a user query. We use a latent\nsemantic space with paper keywords.\nWhen we used the latent semantic space\nderived from the all retrieved data, it\ntends to be weighted with major terms,\nwhich hampers topic expansion and\nmakes expanded corpus similar to the\noriginal one. Our main strategy is to\ndivided the dataset into citation clusters\nand\nweight\nthe\ntopic\nmodel\ncomprehending term features of each\ncluster. By doing so, it is expected that\nglobally minor but locally important\ntopic can be detected.\n\nFirst, we built a latent semantic\nspace and obtain an approximation\nof keyword-paper matrix using\nLDA. We used lemmatized tokens\nextracted from paper title and\nabstract as paper keywords. Next,\nwe built a citation network of the\npapers and detected clusters from the\nnetwork\nusing\nmodularity\nmaximization (Newman and Girvan,\n2004; Newman, 2004). Then, we\nobtained the coordinate vectors for\neach clusters (cluster vectors) using\ncoordinate vectors of their member\npapers. We use a centroid\n(arithmetic mean) of vectors as a\ncluster vector here. The obtained\ncluster vectors are thought to\nrepresent the clusters in the latent\nsemantic space. In this way, we are\nable to refine the retrieval results in\nthe latent semantic space using\ndetected small research areas\nextracted by clustering. We used the\nobtained cluster vectors as a new\nquery and do the same, overall paper\nretrieval again. This operation, it can\nbe regarded as query expansion, will\n\nretrieve other papers in the research\nareas relevant to the user query. We\ncan repeat this operation if the\nperformance of retrieval increases.\n\nIn this paper, we compared two\napproaches of syntheses; naïve and\naverage syntheses. We call an\nexpansion using naive synthesis as naive\nexpansion, and an expansion using\naverage synthesis as average expansion.\nIn naive synthesis, we calculate every\ncosine between a paper and the cluster\nvectors first. And the highest one is\nhired as a new similarity of the paper. In\nthe case of average synthesis, we weight\ncosines between the paper and the\ncluster vectors by the number of papers\nin the cluster; multiply by a number of\npapers in the cluster and divide by the\ntotal number of papers. Then, we sum\nup all of weighted cosines and use it as a\nnew similarity of the paper. We\ncompared these two query expansion\napproaches to integrate topic model and\ncitation network analysis.\nIn the experiment, we evaluated how the\nproposed query expansion technique is\ncapable of retrieving papers in emerging\nareas related to a query. Here, we built a\nsemantic latent space using the past\npaper data and did information retrieval\nand query expansion in the space. If an\nexpanded query is more similar to\ncoordinates of future papers, we can\ndefine a coordinate of a future paper in\nthe space built using the past paper data,\nit means that the query is more relevant\nto emerging areas. And an area relevant\nto the expanded query is also relevant to\nthe first query, so these emerging areas\nare relevant research area to the first\nquery. We build a latent semantic space\nusing a train data set in the collection by\nLSA and LDA, and evaluate the\nperformance how expanded queries are\nmore similar to papers in a test data set\nthan the first not expanded, only\nkeywords based query.\n2035\n\nResults and Discussion\nTable 1 shows the R-precision changes\nof retrieval results at each expansion.\nWe cannot show the all results because\nof space limitations, we pick up\nthreshold of 0.3 and 0.5 for LDA.\nExpansion 0 means the result of the\noriginal query without expansion, and\nR-precision of 0 expansion, i.e., the\noriginal query, is 49.57%. At the first\nexpansion, the R-precision of average\napproach of LDA increase than that of\nthe original query. It means that an\nexpansion by the proposed method\nbrings better results than without\nexpansion, while LDA with naïve one\nhave the worth result than the original\nquery. And iterations of the expansion\ncause topic drift having noisy queries\nand the performance becomes worse.\nOne can obtain higher performances by\nonly a few naive expansions, but it has a\ntendency to cause a kind of topic drift to\nnon-relevant papers,\nwhich was\nimproved by average approach with\ncitation network analysis.\nConclusion\nIn the paper, we have proposed the\nquery expansion for paper information\nretrieval using not only paper keywords\nbut citation networks to expand a query,\nand evaluated the method using the\ndataset of semantic web. We showed\nthat the expanded queries have higher\nsimilarity to some future papers in that\nknowledge domain than an original\nquery; the proposed method has the\nability to retrieve papers in emerging\nareas related to the user query. By the\nexperiment results, we conclude that our\napproach to use both of paper keywords\nand citation networks works well for\npaper information retrieval. While we\nused centroids as representatives in this\nwork, some other methods are known\nand used as a representative of clusters.\n\n2036\n\nIn the future work, more experiments\nwith such representatives are necessary.\nWe also need to ensure that retrieval\nresults actually converge after the\nappropriate number of expansions, or\nneed to find some kind of a stop\ncriterion of expansions.\nTable 1. R-Precision (%) changes with the\nnumber of query expansion iterations. () is\nthreshold for LDA.\nTable\nNaïve (0.3)\nAverage (0.3)\nNaïve (0.5)\nAverage (0.5)\n\n1\n48.04\n52.17\n49.01\n51.78\n\n2\n30.76\n52.15\n44.49\n51.51\n\n3\n30.89\n52.16\n31.61\n51.40\n\nAcknowledgments\nWe thank Nozomi Nori (Yamaguchi) for\nher help in the research.\nReferences\nBlei D.M., Ng A.Y., and Jordan M.I.\n(2003) Latent dirichlet allocation.\nJournal of Machine Learning\nResearch, 3, 993–1022.\nDeerwester S., Dumais S.T., Furnas\nG.W., Landauer T.K., and Harshman\nR. (1990) Indexing by latent\nsemantic analysis. Journal of the\nAmerican Society for Information\nScience, 41, 391-407.\nHofmann T. (1999) Probabilistic latent\nsemantic indexing. Proceedings of\nthe 22nd Annual International SIGIR\nConference on Research and\nDevelopment in Information\nRetrieval, pp. 50-57.\nNewman M.E.J (2004) Fast algorithm\nfor detecting community structure in\nnetworks. Physical Review E, 69,\n066133.\nNewman M.E.J. &amp; Girvan M. (2004)\nFinding and evaluating community\nstructure in networks, Physical\nReview E, 69, 026133.\n\nKNOWLEDGE COMBINATION FORECASTING\nBETWEEN DIFFERENT TECHNOLOGICAL\nFIELDS\nHiroko Nakamura1, Yuya Kajikawa2, Ichiro Sakata3 and Shinji Suzuki4\n1\n\ntechhn@mail.ecc.u-tokyo.ac.jp\nUniversity of Tokyo, Center for Aviation Innovation Research, Hongo 7-3-1, 113-8656,\nTokyo (Japan)\n2\n\nkajikawa@mot.titech.ac.jp\nTokyo Institute University, Graduate School of Innovation Management, Shibaura 3-3-6,\n805N, Tokyo (Japan)\n3\n\nisakata@ipr-ctr.t.u-tokyo.ac.jp\nUniversity of Tokyo, Innovation Policy Research Centre, Yayoi 2-11-16, 113-8656,\nTokyo (Japan)\n4\n\ntshinji@mail.ecc.u-tokyo.ac.jp\nUniversity of Tokyo, Dept of Aeronautics and Astronautics, Hongo 7-3-1, 113-8656,\nTokyo (Japan)\nIntroduction\nIt is said that innovation is\nrecombination of knowledge and that\ncombining own knowledge to that of\ndifferent\nindustry\nand\ndifferent\ntechnology fields have possibility to\nbring new knowledge creation (ex. Dosi,\n1982).\nIn order to lower the cost of collecting\nbreadth technology knowledge and to\naccelerate knowledge recombination in\na complex technology industry, focusing\non one side of breadth activities,\nsearching\ntechnologies\nof\nother\nindustries,\nthis\npaper\nproposes\nknowledge combination model and\ndiscuss how to effectively get the\ntechnology field overview of industry\nand how to identify pairs of technology\nfields that can be combined between the\ntwo industries.\n\nMethodologies\nDepth\nand\nBreadth\nKnowledge\nCombination Model\nThis paper proposes a knowledge\ncombination model between two\ntechnological domains, named the D-BCombination model (Fig. 1) at research\nand engineering level and considers two\nindustries of complex system such as\nautomobile and aircraft industries.\nFigure 1 considers the similarity of any\npairs of sub-domains of each\ntechnological domain; industry A and of\nindustry B, in the horizon. We assume\nthat similarity of sub-domains can be\nmeasured from various sides of\ncharacteristics\nof\ntechnological\nknowledge (ex. problems that the\ntechnological knowledge aim to solve,\nprocess\nthat\nthe\ntechnological\nknowledge takes to solve a problem)\nand we also assume that the successful\n2037\n\nknowledge combination and the type of\nrecombination\nbetween\ndifferent\nindustries depend on the similarity\nbetween the fields.\nSharing knowledge between very\nsimilar pair of sub-domains such as the\npair of DB-D in Fig. 1 is considered to\nbe\nimportant\nto\nhelp\ndeeper\nunderstanding and improvement of the\ntechnological fields. On the contrary,\nknowledge export/import of unique\ntechnologies from one technology\ndomain to another (pair of DB-T) or\nknowledge sharing between different\ntechnology sub-domains (DB-T) with\nweak similarity is important to broaden\nresearch scope and provides chance of\nnew knowledge creation or transfer/\nreplacement.\n\nstructuring to obtain sub-domains of\nindustries and similarity measurements\nbetween sub-domains of two different\nindustries. A1 and A2 take citation\nanalysis approach and A3 takes\nInternational Patent Classification (IPC)\nanalysis approach for data structuring.\nAt the citation analysis, the patent and\ncitation data are converted into a nonweighted, non-directed network in\nwhich a patent is represented as a node\nand backward citations to patents as\nlinks.\nThe\nmaximum\nconnected\ncomponent (MC) of the network is\nextracted and divided into clusters\ndepending on the density of links, using\na\ntopological\nclustering\nmethod\n(Newman, 2004).\nFor similarity\nmeasurement, A1 takes cosine similarity\nmeasurement approach, A2 takes\nexisting intra-industrial citation tracing\napproach and A3 takes IPC share\nsimilarity comparison approach\nTable 1. A1, A2 and A3 result coverage\nDataset\n\nFigure 1. D-B-Combination Model for\nknowledge integration between two\ntechnological domains in depth and\nbreadth\n\nWe propose methodologies to measures\nthe similarity of sub-domains of\ndifferent industries, using patents. And\nin this paper, as a case study, patents of\napplicants of major automobile and\naircraft makers and suppliers (detail will\nbe at Poster) are analysed. Patent data\nwere retrieved from Thomson Reuters’\nThomson Innovation with Derwent\nWorld Patents Index (DWPI).\nMethodologies\nWe take three approaches, A1, A2 and\nA3 and compare the results. Our D-BCombination model requires data\n2038\n\nA1\n\nAutomobile:\n27,989\nStructured\nAutomobile\nPatent\nMC:60,458\nNumbers\nAircraft\n(% over the MC:8,281\ntotal)\n(25.4%)\nIdentified\nAutomobile:\nCluster\n303\nAircraft: 104\nSimilarity\nAutomobile:\nAnalyzed\n35\nCluster\nAircraft: 25\nNumbers\n(20.6%)\nHighlighted 48 pairs of\nSimilarity\nclusters\n\nA2\n\nA3\n\nCombined\nMC:\n69,281\n(25.6%)\n\n270,294\n(100%)\n\n420\n\n676\n\n35\n(20.5%)\n\n62\n(85%)\n\n6 clusters\n\n19 subclasses\n\n243,305,\n\nAircraft:\n\nResults &amp; Discussion\nWe discussed, with two senior engineers\nat Toyota Central R&amp;D Labs, INC. and\nvarious level of aeronautic researchers at\nJapan Aerospace Exploration Agency\n(JAXA), whether highlighted areas in\nA1, A2 and A3 identified possible\nknowledge combination pairs and\n\nprovided useful information that support\npractitioners to create new knowledge.\nTable 1 compares A1, A2 and A3\nresults. For approaches of structuring\npatents into technology sub-domains,\nthe citation analysis approach limited\nthe structure to the MC so that the\ncoverage of data were much inferior to\nIPC approach. If comprehensive\noverview of technological sub-domains\nin other industries are needed, the IPC\napproach can satisfy the needs as a list\nof the technological knowledge better\nand moreover the overview of the IPC\napproach can be obtained easily with\nMicrosoft Excel or similar daily\nsoftware. On the other hand, the citation\nanalysis\napproach\ncan\nprovide\ninformation of technological trend, core\nknowledge of each field and overview\nof technological systems.\nFor measuring similarities between\nfields (Fig. 2), compared to other two\napproaches, A1 approach had more\npossibility\nto\nhighlight\nDB-C\ncombinations. It highlighted similarity\neither in functions (ex. control system)\nor properties (ex. heat resistance). While\nit seemed difficult to combine\nknowledge of same functions but\ndifferent\nphilosophy,\nbringing\nknowledge with different functions but\nsame property or same type of problems\ntogether can have possibility of success\nin knowledge recombination in breadth.\nAutomobile\nengineers\nfound\nhighlighting such similarity of problems\nis very useful for them to transfer their\ntechnology to other industries and vice\nversa.\nOn the other hand, A2 approach\nhighlighted\npast\nand\nemerging\nknowledge transfer from an industry to\nanother (DB-T combination) such as\nAvionics, Composite Materials and Fuel\nCell and knowledge exchanges in very\nsimilar processes (DB-D combination)\nsuch as Assembly. The citation analysis\nenables to structure technology sub-\n\ndomains as associated parts of systems\nso that it can support engineers to obtain\nbreadth knowledge related to the\ntechnology\nsub-domains\nbeing\ntransferred from or to. It can accelerate\nbroadening scope of projects and\nadoption of technology.\nAbout A3 approach for measuring\nsimilarities,\nAutomobile\nengineers\ncommented that, even though this\napproach was simple, some of\nhighlighted areas were interesting to\nlook at.\n•\n•\n\nA2 Approach for DB-T\nIntegration in Breadth\nComposite\n\nWeakly\nW\neakly Similar\nSimilar\nNot\nSimilar\not S\nimilar\n\nExhaust Emission\n\nVery\nV\nery Similar\nSimilar\n\n•\n\nPossible to highlight past and current DB-T\ntransfer.\nPossible to provide technologies information\naround the transferring technologies.\nAnalysis of highlighted DB-T may give\nunderstanding of technology transfer\nmechanism\n\nCFRP\nNavigation\nBrake System\nFuel Cell\n\nA1 Approach for DB-C\nExhaust Emission\n• Possible to highlight DB-C combination\nPurifier\n• Limiting text to analyze the cosine\nCeramic\nsimilarity will improve the result.\nNot Similar\n\nMeasurement\nSordeling\n\nIntegration\nion iin\nn Depth\n\nA3 Approach for DB-D\n\n• Possible to highlight DB-D similarities in\nfunction and mechanism\n• Analysis of co-occurrence of IPC\ncategories may add more value on this\napproach\n\nTorsion Measurement\nSemiconductor\nCooling\n\nFigure 2. Three methodologies on the D-BCombination Model\n\nSummary\nWhile it is still needed to improve\nmethodologies, the D-B-Combination\nmodel with integration of A1, A2 and\nA3 methodologies can become an\neffective\ninnovation\ndesigning\nmethodology that allows engineers and\nproduct managers to find useful\ntechnological knowledge from different\nindustries and explore chances of\ntechnological breakthrough in depth or\nbreadth.\nReferences\nDosi G. (1982) Technological\nParadigms and Technological\nTrajectories – a Suggested\nInterpretation of the Determinants\nand Directions of Technical Change.\nResearch Policy, 11, 147–162.\nNewman M.E.J (2004) Fast algorithm\nfor detecting community structure in\nnetworks. Physical Review, 69,\n066133.\n2039\n\nLANGUAGE PREFERENCE IN SOCIOLOGICAL\nRESEARCH PUBLISHED BY VARIOUS\nEUROPEAN NATIONALITIES\nMoshe Yitzhaki, Yifat Keidar and Nava Rotchild\nDept. of Information Studies; Bar-Ilan University; Ramat-Gan, Israel 52900\nIntroduction\nRecent studies have indicated that\nscholars of different nationalities are\noften biased towards their own mothertongue when using and citing sources\n(Wood,\n1967;\nHutchins,\n1971;\nHolmstrom, 1973; Finison-Whittmore,\n1975; Chan, 1976; Morgan, 1977;\nMichel, 1982; Ralph, 1982; Large,\n1983; Thorp, 1989; Regaunt, 1994) .\nHowever, little research has addressed\nlanguage preference among nonEnglish-speaking scholars, as compared\nto their English-speaking colleagues,\nusing additional measures besides the\nmere percentage of languages cited.\nPurpose of the study\nThe objective of the present study was\nto assess language self-citation (or\nlanguage preference) in the field of\nsociology, gathering empirical data to\ndetermine its extent among various\nnationalities.\nMethodology\nForty regular original research articles\nwere drawn from the 1990 and 2010\nvolumes of 10 sociology journals\npublished in the US, UK, Germany,\nFrance, Italy and Spain. Samples\nincluded only articles written originally\nin the language of the journal&#x27;s\npublication country and by authors\naffiliated with institutions there. The\n2040\n\nreferences appended to the selected 780\narticles were sorted by language,\nyielding a total of about 25,000\nreferences.\nMEASURES USED\nLanguage analysis of cited references in\njournals of diverse languages reveals the\nrelative use of each language by various\nnationalities, thus eliciting the &#x27;language\nself-citation&#x27; rate of each group. Clearly,\na high rate of self-citation indicates low\nuse of foreign language research\nliterature.\n\nBesides the raw figures of &#x27;language\nself-citation&#x27;, two more refined\nmeasures were employed: the\n&#x27;relative\nown-language\npreference’(ROLP) indicator and the\n&#x27;Odds Ratio&#x27; (Yitzhaki, 1998; Egghe,\nRousseau &amp; Yitzhaki, 1999;\nBookstein &amp; Yitzhaki, 1999).\nTable 1. Frequency Distribution (in %) of\nlanguages of cited references in ten\nsociology journals in 1990\n\nCount. and\nlang. of citing\njournals\nUS\nUK\nGerm.\nFrance\nSpain\nItaly\n\nPercentage of cited\nreferences in\nEng.\n\nGer. French Span. Ital.\n\n98.1\n89.4\n38.0\n38.7\n40.5\n30.3\n\n0.8\n6.6\n59.7\n1.3\n0.9\n3.0\n\n0.3\n0.5\n2.2\n57.0\n10.3\n23.0\n\n0.1\n0.2\n0.2\n0.6\n43.2\n4.4\n\n0\n0.1\n0\n0.7\n5.1\n39.1\n\nOther Total\n0.7\n3.2\n0\n1.7\n0\n0.2\n\n100%\n100%\n100%\n100%\n100%\n100%\n\nFindings and discussion\nTables 1 and 2 present the frequency\ndistribution in % of cited languages in\narticles published in the ten journals,\ngrouped by language.\nTable 2. Frequency Distribution (in %) of\nlanguages of cited references in same ten\nsociology journals in 2010\n\nCount. and\nlang. of citing\njournals\nUS\nUK\nGermany\nFrance\nSpain\nItaly\n\nPercentage of cited\nreferences in\nEng.\n\nGer. French Span.\n\nItal.\n\nOther\n\nTotal\n\n98.6\n95.0\n49.5\n47.3\n47.4\n29.4\n\n0.5\n1.9\n50.2\n0.1\n0.7\n1.2\n\n0.1\n0\n0\n2.7\n3.6\n56.5\n\n0.3\n2.7\n0\n0\n0\n0\n\n100%\n100%\n100%\n100%\n100%\n100%\n\n0.5\n0.5\n0.4\n48.4\n2.1\n12.6\n\n0.1\n0\n0\n1.6\n46.2\n0.4\n\nThe tables reveal strong &#x27;own-language\npreference&#x27; (OLP) in both periods,\nvarying from one country to another:\nhighest (over 95%) among American\nand British sociologists, lower among\nSpanish and Italians ones and lowest\namong German and French. Besides\ntheir own language, German, French and\nSpanish sociologists heavily cited\nsources in English, with an increase\n(10%) in 2010 at the expense of their\nown language. Spanish sociologists in\n1990 still cited sources in French (10%)\nand Italian (5%) but less in 2010. The\nItalians had 23% French references in\n1990, decreasing to 12.6% in 2010 in\nfavor of their own language. To sum up,\namong all four non-English nationalities\nthe bulk of cited sources was in English,\nincreasing in 2010, strengthening its\nposition as the &#x27;Lingua Franca&#x27; of the\nnew century.\nTable 3 estimates the research literature\nexisting worldwide in sociology in both\nyears. To compensate for the English\nbias in the WOS database, figures of\nnon-English items were doubled. Table\n4 displays the calculated ROLP\nindicators and Odds Ratios for each\nlanguage, assuming that the higher the\n\nratio above 1, the higher the degree of\n&#x27;self-language preference&#x27;.\nTable 3. Estimated distribution of\nlanguages of sociology reseearch literature\n(in %) *\nLanguage\nEnglish\nFrench\nGerman\nSpanish\nItalian\nOthers\nTotal\n\n1990\n75.7\n11.6\n6.6\n0.3\n0.4\n5.4\n100%\n\n2010\n74.6\n8.3\n6.1\n0.6\n0.2\n10.2\n100%\n\nSource: Web of Science.\n* Assuming that only 50% of the non-English\nitems are included in this database.\n\nTable 4. Measures of ROLP and &#x27;Odds\nRatio&#x27; in 1990 and 2010\nCountry\nof citing\njournals\nUS\nUK\nGermany\nFrance\nSpain\nItaly\nUS\n\nROLP\n\nOdds Ratio\n\n1990\n\n2010\n\n1990\n\n2010\n\n1.3\n1.2\n9.0\n4.9\n144.0\n97.7\n1.3\n\n1.3\n1.3\n8.2\n5.8\n77.0\n282.5\n1.3\n\n16.6\n2.7\n21.0\n10.1\n252.8\n159.9\n16.6\n\n24.0\n6.5\n15.5\n10.4\n142.3\n648.1\n24.0\n\nBoth measures indicate that in both\nperiods Spanish and Italian sociologists\nwere much more biased towards their\nmother-tongue than others. Regarding\nother nationalities, the two measures\ndiffer: according to the ROLP\nindicators, German authors displayed a\nhigher bias than the French ones,\nalthough improving slightly in 2010,\nwhile the US and UK scholars had the\nlowest OLP.\nAccording to the Odds Ratios, however,\nAmerican and\nGerman\nscholars\ndisplayed a higher bias in both periods,\ncompared to British and French ones.\nThe second period shows a slight drop\nin bias among Germans and rise among\nthe US and UK ones.\n\n2041\n\nPossible Explanations\n Greater availability and accessibility\nof certain publications than others is\nprobably one reason for OLP, thus\nenhancing use and citation of ownlanguage material which is usually\neasier to obtain.\n Most academic libraries in the US\nand UK do not carry the full array of\nFrench and German scholarly\njournals and monographs, and the\nsame is true for French and German\nacademic institutions regarding\nEnglish.\n Presumably,\nleading\n&#x27;foreign&#x27;\njournals and important monographs\nare carried by academic libraries in\nthese countries, and most others may\nbe obtained via inter-library loan.\nThus, in view of the abovementioned\nfigures, a language barrier or\npreference may exist alongside the\n‘immediate\navailability’\nfactor.\nMany scholars prefer own-language\npublications, avoiding the effort of\nobtaining foreign language material\nfrom distant libraries.\n Some of the topics discussed in\nsociology journals deal with local\nissues, for which most sources are\nwritten in the local language.\nConclusions\n1. To determine the extent of the\n‘relative own-language preference’\namong scholars in certain fields, one\nmay relate the &#x27;language self-citation&#x27;\nrate of a each language-group, to some\nestimate of this language share in the\nfield research literature.\n2. In sociology both of the measures\nused revealed a similar state for Spanish\nand Italian sociologists, a differing one\nfor other nationalities and the lowest\ndegree of mother-tongue bias among the\nBritish scholars.\n\n2042\n\nReferences\nBookstein, A and Yitzhaki, M. (1999).\nOwn-language preference: a new\nmeasure of ‘relative language selfcitation’. Scientometrics, 46, 337348.\nChan, G.K.L. (1976). The foreign\nlanguage barrier in science and\ntechnology. International Library\nReview 8, 317-325.\nEgghe, L, Rousseau, Yitzhaki, M.\n(1999). The ‘own-language\npreference’: measures of relative\nlanguage self-citation”.\nScientometrics 45, 217-232.\nFinison, L.J. and Whittemore, C.L.\n(1975). Linguistic isolation of\nAmerican social psychology.\nAmerican Psychologist 30, 513-516.\nHolmstrom, J.E. (1973). The foreign\nlanguage barrier. In J. Sherrod, &amp; A.\nHodina (Eds.). Reader in Science\nInformation. Washington, D.C.:\nMicrocard, 94-103.\nHutchins, W.J. a.o. (1971). The\nLanguage Barrier. University of\nSheffield.\nLarge, J.A. (1983). The ForeignLanguage Barrier; Problems in\nScientific Communication. London:\nAndre Deutsch.\nMichel, J. (1982). Linguistic and\npolitical barriers in the international\ntransfer of information in science\nand technology. Journal of\nInformation Science 5, 131-135.\nMorgan, B.A. (1977). National bias in\nreference citation in English\nlanguage agricultural engineering\njournals. IAALD Quarterly Bulletin,\n22(3-4), 60-64.\nRalph, A. (1982). Language and\ninformation retrieval in the social\nsciences. Aslib Proceedings 34, 394405.\nRegaunt, S. (1994). English as lingua\nfranca in geological scientific\n\nresearch; a bibliometric study.\nScientometrics 29, 335-351.\nThorp, R.G. a.o. (1989). The foreign\nlanguage barrier: a study among\npharmaceutical research workers.\nJournal of Information Science. 14,\n17-24.\nWood, D.N. (1967). The foreignlanguage problem facing scientists\nand technologists in the UK-report\nof a recent survey. Journal of\nDocumentation. 23, 117-130.\n\nYitzhaki, M. (1988). The language\nbarrier in the humanities: the case of\nbiblical studies. INFORMETRICS\n87/88. Amsterdam: Elsevier, 301314.\nYitzhaki, M. (1998). The ‘language\npreference’ in sociology: Measures\nof ‘language self-citation’, &#x27;relative\nown-language preference indicator’\nand ‘mutual use of languages’.\nScientometrics, 41, 243-254.\n\n2043\n\nLEADERS AND PARTNERS IN INTERNATIONAL\nCOLLABORATION AND THEIR INFLUENCE ON\nRESEARCH IMPACT\nBorja González-Albo, Javier Aparicio, Luz Moreno, María Bordons\nborja.gonzalezalbo@cchs.csic.es\nIEDCYT, CCHS, Spanish National Research Council (CSIC), Albasanz 26-28, Madrid\n(Spain)\nIntroduction\nA positive influence of international\ncollaboration on the impact of research\nhas been extensively described (see for\nexample, Glänzel 2001). Different\nunderlying reasons may interact. On the\none hand, the higher number of authors\nand institutions described for this type\nof collaboration can be a key issue,\nsince it may include higher variety of\npoints of view which may lead to higher\ncreativity and innovation (Reagans and\nZuckerman 2001). On the other hand,\nteams can benefit especially from the\nknowledge, infrastructures and prestige\nof scientifically advanced partners.\nFocusing on Spain, a higher impact for\ninternationally co-authored articles as\ncompared to the total output of the\ncountry has been reported in the\nliterature (Bordons, Aparicio and\nCostas, 2013). The interest of\nconsidering additional factors such as\nthe type of collaborating country (Gazni\net al. 2012) and which partner takes the\nlead in the research (Van Leeuwen and\nTijssen, 2007) has also been suggested,\nbut as far as we know it has not been\nglobally addressed before.\nObjectives\nThis paper analyses the internationally\nco-authored papers of Spain to explore\nto what extent the type of partner (high\nor low R&amp;D intensive country) and its\n2044\n\nrole in the collaboration (leadership as\nmeasured by first authorship) may\ninfluence the impact of research.\nThe following questions are addressed:\na) In which proportion does Spain\ncollaborate with high and low R&amp;D\nintensive countries? Are there any\ndifferences by fields? b) Is there any\nrelationship between type of partner and\nimpact of research? Specifically, are\npapers co-authored with high R&amp;D\nintensive countries published in more\nprestigious journals? Do they receive\nmore citations? c) Are papers leaded by\nhigh R&amp;D intensive countries more\nheavily rewarded through citations?\n\nThese questions are studied in the\ntotal production of Spain during a\ntwo year period and differences by\nfields are explored.\nMethods\nScientific publications of Spain in 20082009 as covered by the Web of Science\ndatabase are analyzed. Only articles,\nproceedings papers and reviews are\nconsidered (“articles”).\nThe study focuses on bilateral\ncollaboration. Only publications with 2\naddresses, one from Spain and the other\nfrom another country are taken into\naccount, to avoid potential confusion\nderived from papers with multi-lateral\ncollaboration.\n\nCountries are classified in three classes\naccording to their level of commitment\nwith research and development activities\nas measured by their gross domestic\nexpenditures in R&amp;D as a percentage of\ntheir\ngross\ndomestic\nproduct\n(%GERD/GDP) (source: World Bank\n2012). Spain devoted 1.35% of its GDP\nto R&amp;D in year 2008. Countries are\nclassified as high RD (%GERD/GDP\nhigher\nthan\n1.55);\nlow\nRD\n(%GERD/GDP below 1.15) and similar\nto Spain (1.15&gt;%GERD/GDP&gt;1.55).\nThe impact of research is measured\nthrough: a) journal normalized position\n(JNP), which is a measure of the\nprestige of journals, since it takes into\naccount the position of a journal in its\nfield considering all journals in\ndescending order of impact factor\n(Journal Citation Reports); b) citations\nper paper, which consider citations\nreceived by publications within a 3-year\ncitation window. To make inter-field\ncomparisons possible the citation counts\nof papers are normalized with respect to\nthe average citation rate of Spain in the\ndiscipline of the corresponding journal\nand in the same period of time (RCR).\n\nsmall differences by broad areas are\nobserved. Spain is in the first address in\n56% of the publications, but this\npercentage ranges from 53% in Clinical\nMedicine to 60% in Agriculture.\nPapers co-authored with high RD\ncountries obtain higher impact (JNP and\nrelative citation rate) than those coauthored with low RD countries for the\ntotal country and in all areas -although\nin Mathematics the differences are\nlimited to JNP- (Figure 1). Moreover,\namong the most cited papers (21% of\nthe papers which obtained a RCR equal\nor higher than 1.5), high RD partners are\nover-represented. This holds for the total\nproduction and also for each of the\nbroad areas except for Mathematics.\nDo Spanish articles obtain higher impact\nwhen a high RD country leads the\nresearch (first-authorship)? This is\nconfirmed only in Physics, while in the\nrest of the areas no significant\ndifferences in impact (JNP or relative\ncitation rate) are observed according to\nthe position of the Spanish centre in the\naddress.\n\n“First authorship” is considered as\nan indication of scientific leadership\n(Van Leeuwen and Tijssen, 2007).\nPublications are assigned to disciplines\naccording to the Web of Science\nclassification of journals into subfields.\nDisciplines are grouped into ten broad\nareas.\nResults\nThe scientific output of Spain in WoS\nduring 2008-2009 accounts for 84,366\narticles; and 41% of them includes at\nleast one foreign address. Bilateral\ncollaboration is present in 9,800 articles\n(28.3 % of internationally co-authored\narticles). Collaboration with high RD\ncountries (60%) predominates over that\nwith low RD countries (25%), although\n\nFigure 1. RCR by type of partner and\nbroad area\n\nFocusing\non\nSpanish\narticles\ninternationally co-authored with low RD\ncountries, a higher impact is observed\nfor articles with a Spanish first address\n2045\n\nin Agriculture, Biomedicine and\nChemistry (higher JNP and RCR); in\nEngineering (higher JNP) and in\nMultidisciplinary (higher RCR).\n\nAcknowledgments\nThis research has been supported by the\nSpanish National Plan R&amp;D (Research\nproject CSO2008-06310).\n\nConclusions\nThe fact that Spain collaborates more\noften with high than with low RD\ncountries is not surprising, since\nscientifically advanced countries are\nmore attractive partners (Gazni,\nSugimoto and Didegah, 2012) and this\ntype of collaboration is supposed to\nyield higher benefits for research teams.\nOur results confirm this assumption,\nsince Spanish papers co-authored with\nhigh RD countries are published in more\nprestigious journals, receive more\ncitations and are more likely to be\namongst the most cited papers than\nthose co-authored with low RD\ncountries. Similar results were described\nfor a particular discipline in Spain\n(Bordons, Aparicio and Costas, 2013)\nand for different areas in LatinAmerican countries (De Filippo,\nAparicio and Gómez, 2009).\nHowever, an interesting result is that\nwhen collaborating with a high RD\ncountry, Spain may lead the research as\noften –or in some areas more often–\nthan the other country and no\ndifferences in impact according to the\nposition of partners in the address field\nare observed, that is, foreign leadership\ndoes not originate higher impact. On the\ncontrary, in the set of papers coauthored with low RD countries, the\nresearch leaded by Spain shows a higher\nimpact in four areas. A possible\nexplanation is that the collaboration with\nhigh RD countries is more symmetric\n(Kim, 2006) while a more asymmetric\nnature may characterise the one\nconducted with low RD countries, in\nwhich Spain might participate as a\n“strong” partner. Finally, the special\nbehaviour of Mathematics is discussed.\n\nReferences\nBordons, M.; Aparicio, J.; Costas, R.\n(2013). Heterogeneity of\ncollaboration and its relationship\nwith research impact in a biomedical\nfield. Scientometrics. DOI\n10.1007/s11192-012-0890-7.\nDe Filippo, D.; Aparicio, J.; Gómez, I.\n(2009). Measuring the benefits of\nInternational collaboration. A case\nstudy of the relationship between\nLatin-American and European\ncountries. B.Larsen and J.Leta, Eds.\nProceedings of the 12th\nInternational Conference of the ISSI.\nBrasil: BIREMEPPAHO/WHO and\nFederal University of Rio de Janeiro,\n2009. Pp. 920-921.\nGazni, A.; Sugimoto, C.R.; Didegah, F.\n(2012). Mapping world scientific\ncollaboration: authors, institutions\nand countries. Journal of the\nAmerican Society for Information\nScience and Technolog,y 63(2): 323335.\nGlänzel, W. (2001). National\ncharacteristics in international\nscientific co-authorship relations.\nScientometrics, 51 (1), 69–115.\nGorraiz, J.; Reimann, R.;\nGumpenberger, C. (2012). The\nimportance of bilateral and\nmultilateral differentiation in the\nassessment of international\ncollaboration -a case study for\nAustria and six countries.\nScientometrics, 91(2):417-433.\nReagans, R.; Zuckerman, E.W. (2001).\nDiversity and productivity: the social\ncapital of corporate R&amp;D teams.\nOrganization Science, 12(4): 502517.\n\n2046\n\nVan Leeuwen, T.N.; Tijssen, R. (2007).\nStrength and weakness of national\nscience systems. A bibliometric\nanalysis through cooperation\npatterns. In: Torres-Salinas, D. and\n\nMoed, H.F. Ed. Proceedings of the\n11th International Conference of the\nISSI. Madrid: CINDOC-CSIC. Pp.\n469-479.\n\n2047\n\nMEASURING INTERDISCIPLINARITY OF\nRESEARCH GRANT APPLICATIONS. AN\nINDICATOR DEVELOPED TO MODEL THIS\nSELECTION CRITERION IN THE ERC’S PEERREVIEW PROCESS\nIvana Roche1, Dominique Besagni1, Claire François1, Marianne Hörlesberger2,\nEdgar Schiebel2, Dirk Holste2\n1\n\nivana.roche@inist.fr; dominique.besagni@inist.fr; claire.francois@inist.fr\nCNRS, Institut de l’Information Scientifique et Technique, UPS 76, 2 allée du Parc de\nBrabois, Vandœuvre-lès-Nancy, F-54519 Cedex (France)\n2\n\nmarianne.hoerlesberger@ait.ac.at; edgar.schiebel@ait.ac.at; dirk.holste@ait.ac.at\nAIT Austrian Institute of Technology GmbH, Donau-City-Strasse 1, 1220 Vienna\n(Austria)\n\nIntroduction\nScientific experts having to evaluate the\ninterest of research projects submitted\nfor grant to the European Research\nCouncil (ERC) must lean on the four\n“frontier research” criteria among\nwhich: “... it pursues questions\nirrespective of established disciplinary\nboundaries, involves multi-, inter- or\ntrans-disciplinary research that brings\ntogether researchers from different\ndisciplinary backgrounds, with different\ntheoretical and conceptual approaches,\ntechniques,\nmethodologies\nand\ninstrumentation, perhaps even different\ngoals and motivations”, according to the\nEC’s High Level Expert Group report\n(2005) assertions and that we defined in\nour DBF project (Hörlesberger et al.,\n2013) as interdisciplinarity.\nBackground\nInterdisciplinarity is used as a proxy to\ninfer self-consistently the presence and\n\n2048\n\nproportions\nof\ncharacteristic\nterminology associated with individual\nERC panels, thereby revealing the intra\nor inter-panel character of a proposal. It\nwas built upon a previously successfully\ntested approach that the frequency of\noccurrence and distribution of research\nfield specific keywords can classify and\ncharacterize research fields. While the\ncore of the approach has been retained,\nthe computation has been adopted and\nfine-tuned to the grant scheme under\nstudy. The underlying basic hypothesis\nis that the larger the proportion of interpanel\nkeywords,\nthe\nmore\ninterdisciplinary is the proposal. To this\nend, each keyword is labeled according\nto its statistical frequency across all\npanels, filters are applied to distinguish\nrelevant from irrelevant keywords, and\nthe tallying of keywords with their\nassigned panels is assessed to classify\neach proposal with respect to its share of\ninter-panel keywords.\n\nFigure 1. Methodological schema of the evaluation process of the\ninterdisciplinarity of research grant applications\nData and Methodology\nPrimary data are directly obtained from\nthe documents supplied by the\nresearcher. Each project proposal is\nindexed by keywords (KW) extracted\nfrom its textual information. After\nvalidation, we apply the diffusion model\napproach. First, the so-called Home\nPanel (H-P) terms are defined. We\nassumed KW which are specific for a\npanel occurred with a higher probability\nin that panel rather than in others. This\nprobability is defined by the frequency\nof one KW in a panel divided by the\nnumber of proposals in this panel,\nnamely the relative term frequency\n(rtfKW/panel). Then, for a KW, we\ncalculate its rtfKW/panel in each panel and\nthe panel with the highest probability is\ndeclared to be its H-P. So, we obtain for\neach H-P the list of its H-P terms.\nTherefore the complete terminology\nassociated to a panel consists of the\n\nunion of its H-P term list and the set of\nterms imported from the other panels\nand we refer to as “abroad terms”.\nIn order to make the lists of H-P terms\nmore consistent, we use the Gini index,\na measure of the inequality of a\ndistribution, varying from 0 to 1, a value\nof 0 expressing total equality and a\nvalue of 1 maximal inequality. It is\ncommonly used in economics as a\nmeasure of inequality of the income or\nwealth. It is, in this study, employed as a\nmeasure of the dispersion of a KW. A\nGini index of 1 tells us that the KW is\nvery specifically limited to only one\npanel. Conversely, a Gini index equal to\n0 means a completely uniform\ndistribution and indicates that the term\noccurs in all the considered panels. We\ndefine a cut-off threshold to discard KW\nwhich dispersion will be considered\nexcessive.\nFinally, the tallying of KW with their\nnewly assigned H-P is assessed to\n2049\n\ncalculate an index for the share of\nabroad terms in the list of KW\nrepresenting the content of each project\nproposal. The underlying assumption is\nthat the larger the proportion of abroad\nterms, the more interdisciplinary a\nproject proposal is.\nThe Case Study\nWe applied our methodology to a case\nstudy coming from project proposals\nsubmitted to the ERC 2009 Starting\nGrant Call.\nTable 1. Distribution of successful and\nnon-successful proposals submitted to the\nERC 2009 Starting Grant Call\n\nProposals\nSuccessful\nNon-successful\n\nERC StG\n2009\n2.503\n244\n2.259\n\nDataset\n(6 panels)\n198\n41\n157\n\nAmong the 19 ERC panels representing\nLife Sciences (LS) and Mathematics,\nPhysics, Chemistry, Engineering\n&amp;\nEarth Sciences (PE), we chose 6 panels\nwith a balance between LS and PE as\nwell as between basic and applied fields.\nThe analysis shows the results for ERC\npanel\nPE1\n(Mathematics\nand\nMathematical\nfoundations)\nwhich\nreceived 39 submissions, 11 of them\nsuccessful.\nThe\nvalue\nof\nInterdisciplinarity in this example is the\nshare of abroad terms calculated with a\nGini index cut-off threshold of 0.1.\nIn the DBF project, we introduced a\nstatistical discrete choice model (DCM)\nto estimate the decision probability for a\nproposal to be accepted on the basis of\nmeasured\nattributes\nof\n“frontier\nresearch” (Scherngell et al., 2013).\n\n2050\n\nWe studied in a proof-of-concept\napproach the influence of those\nattributes on the success probability and\nconducted an initial analysis of the expost comparison between the indicatorbased scientometric evaluation and the\nempirical\npeer-review\nprocess.\nInterdisciplinarity is one of the five\nindicators we developed in the context\nof this project and it is an element that\nproves to influence significantly the\nselection probability of the projects.\nThe\nresults\nobtained\nwith\nInterdisciplinarity are encouraging and\nwe are experimenting with it on a\ndifferent dataset from e-Corda.\nWe also have to introduce another\ndimension to that indicator: the diversity\nof the sources (H-P) of abroad terms, on\ntop of just counting them.\nAcknowledgments\nWork accomplished in the context of the\nDBF (Development and Verification of\na Bibliometric Model for the\nIdentification of Frontier Research)\nproject within the European Research\nCouncil’s CSA of the EU’s 7th\nFramework Programme.\nReferences\nHörlesberger M., Roche I., Besagni D.,\nScherngell T., Francois C., Cuxac P.,\nSchiebel E., Zitt M., and Holste D.\n(2013). A concept for inferring\n“frontier research” in grant\nproposals, Scientometrics (to\nappear).\nScherngell T., Roche I., Hörlesberger\nM., Besagni D., Züger M.-E., and\nHolste D. (2013). Initial comparative\nanalysis of model and peer-review\nprocess for ERC starting grant\nproposals, Research Evaluation\n(submitted).\n\nMEASURING THE QUALITY OF ACADEMIC\nMENTORING\nJongwook Lee\njl12b@my.fsu.edu\nFlorida State University, College of Communication and Information, Tallahassee, FL\n32306 (United States)\nIntroduction\nA mentor is a critical factor for the\ncareer and psychosocial development of\na mentee (Kram, 1983). In academic\ncontext, faculty members may be\nmentors to their students. Sugimoto\n(2012a) confirmed that faculty advisors\n(i.e., dissertation advisors) can be\nmentors to their doctoral students in\nlibrary and information science (LIS).\nShe also applied Kram’s mentoring\nframework to LIS doctoral education\nand identified the importance of the\nrelationships between advisors and their\ndoctoral students for successful doctoral\nstudies (Sugimoto, 2012b). Despite the\nsignificance of academic mentoring in\ndoctoral education, there has been little\nresearch on measuring the quality and\nimpact of academic mentoring. Several\nattempts have been made to measure the\nacademic\nmentoring\nof\nfaculty\nquantitatively based on the number of\ndoctoral\nmentorship\npairings\n(Marchionini, Solomon, Davis, &amp;\nRussell, 2006; Sugimoto, 2006). This\nstudy aims to propose a method of\nmeasuring the quality of academic\nmentoring.\nBackground\nMarchionini, Solomon, Davis, and\nRussell (2006) describe academic\nmentoring as an activity that covers the\nresearch, teaching, and service activities\nof faculty. Their study operationalizes\n\nmentoring as “service as doctoral\nadvisor and service on doctoral\ndissertation committees” (p. 481). They\npresent the MPACT indicators for\nmentors based on this operational\ndefinition. Sugimoto (2012a) supports\nthis study by examining the features of\nacademic mentoring in LIS. She\nsurveyed 354 tenured professors in LIS\nprograms that grant a doctoral degree\nand 294 assistant professors from the\nALA-accredited LIS programs. Of the\nrespondents to the questionnaires, 33\nadvisors and 23 advisees were\ninterviewed. The research found that\nadvisors could be regarded as mentors.\nFurthermore, Sugimoto et al. (2008)\nfound a statistically insignificant\ncorrelation between the MPACT values\nand faculty citation counts and claimed\nthat the MPACT values (i.e., sum of the\nnumber of doctoral student advising as\nchairs and as committee members) can\nshow a different aspect of faculty\nscholarship. The limitation of MPACT\nscore is, however, that it shows only the\nquantitative aspect of mentoring, rather\nthan the quality of mentoring.\nSome research has attempted to examine\nthe effect of mentoring in graduate\neducation on the research productivity\nof mentees. Paglis, Green, and Bauer\n(2006) measured research productivity\nof doctoral students for five and half\nyears as they began their doctoral\nstudies. The findings show that research\ncollaboration with advisers influences\n2051\n\nthe research productivity of advisees\npositively,\nand\n“psychological\nmentoring” improved the research selfefficacy of advisees. That is, the positive\nrelationship between advisees’ research\nproductivity and advisors’ mentoring\nwas observable. Tenenbaum, Crosby,\nand Gliner (2001) studied the\nrelationship of mentoring, student\nsatisfaction, and scholarly productivity\nin graduate school. This study\ndemonstrates\nthat\n“instrumental\nmentoring” can improve advisees’\nresearch productivity, and “psychosocial\nhelp” can increase the satisfaction of\nadvisees with their advisors. In a more\nrecent study, Muschallik and Pull (2012)\nshowed that effective mentoring\nfacilitates the transfer of knowledge and\nskills from mentors and mentees, which\nwill result in increasing the research\nproductivity of mentees.\nMethod\nGiven that the research productivity of\ndoctoral students is influenced by the\nacademic mentoring provided by faculty\nadvisors, this study used advisees’\nresearch productivity (i.e., publication\nand citation count) for assessing\nmentoring quality of advisors.\nPopulation\nThe population of this pilot study is\ntwelve\ntenure-track\nLIS\nfaculty\nmembers (i.e., full and associate) who\nare employed by the Florida State\nUniversity as of January 2013. Assistant\nprofessors are not included in this\npopulation because they have not had\nmany opportunities to advise students.\nTwo full faculty members whose\nbackgrounds are not LIS were also\nexcluded because the MPACT database\nused for collecting doctoral mentorship\ninformation does not cover all\ndisciplines completely while it has the\ncomplete information of LIS.\n2052\n\nData Collection\nThe faculty list is collected from the LIS\nwebsite. Advisee lists of faculty\nmembers are gathered from the MPACT\nsite\n(http://www.ibiblio.org/mpact/).\nOnce the lists of advisees are made,\npublication and citation data of each\nadvisee were manually collected from\nWeb of Science by searching with their\nnames. The author initially searched\nSSCI\ndatabase\nand\ncollected\nbibliographic and affiliation information\nof advisees. After that, the author used\n“Author Search” function in order to\nexpand the scope of database to SCI and\nA&amp;HCI using affiliation information of\nadvisees.\nTable 1. Faculty rankings based on the\nquantity and quality of academic\nmentoring\nFaculty\n#1\n#2\n#3\nR1\nR2\nR3\nA1\n29\n96\n354\n1\n2\n2\nA2\n25\n80\n344\n2\n3\n3\nA3\n15\n304 1995\n3\n1\n1\nA4\n10\n17\n114\n4\n5\n4\nA5\n6\n5\n19\n5\n7\n6\nA6\n6\n6\n11\n5\n6\n7\nA7\n5\n19\n45\n7\n4\n5\nA8\n4\n3\n1\n8\n8\n8\nA9\n3\n0\n0\n9\n10\n10\nA10\n3\n1\n0\n9\n9\n9\nA11\n2\n0\n0\n11\n11\n11\nA12\n0\n0\n0\n12\n12\n12\n#1: Number of doctoral dissertation advising as\nchair and committee (MPACT values)\n#2: Publication count of mentees\n#3: Citation count of mentees\nR1: Ranking by #1\nR2: Ranking by #2\nR3: Ranking by #3\n\nFindings\nFaculty members are ranked by three\ncriteria: (a) number of advisees; (b)\npublication count of advisees; (c)\ncitation count of advisees (see Table 1).\nThe ranking changes were found among\nthree measures. For example, the\nranking of A3 is improved from 3 to 1\nas the publication and citation counts of\n\nadvisees were considered. In addition,\nA7 is ranked 7th, 4th and 5th by three\ncriteria respectively.\nLimitations and Future Work\nThis pilot study implies the need for\nassessing both the quantity and quality\nof academic mentoring. However, this\nstudy has limitations in several aspects.\nFirst, the size of population is too small\nto discover meaningful patterns that can\nbe generalized. To deal with this\nlimitation, future research will include\nfaculty members from other LIS schools\nin the United States. In addition,\nalthough some studies demonstrated the\nimportance of using multiple databases\nin evaluative bibliometric studies (Meho\n&amp; Yang, 2007), this study is limited to\nthe Web of Science in collecting\npublication and citation data. The future\nstudy will attempt to analyse the data\ngathered from Web of Science and\nScope. Finally, other variables such as\nresearch areas or prior research skills of\nadvisees may influence their research\nproductivity. To strengthen these\nlimitations, research interests of advisors\nand advisees as well as the\ncharacteristics of advisees need to be\nidentified.\nAcknowledgments\nI would like to thank to my mentors, Dr.\nKathy Burnett and Dr. Kiduk Yang, for\ngiving me valuable advice.\nReferences\nKram, K. E. (1983). Phases of the\nmentor relationship. Academy of\nManagement Journal, 26(4), 608625.\nMarchionini, G., Solomon, P., Davis, C.,\n&amp; Russell, T. (2006). Information\n\nand library science MPACT: A\npreliminary analysis. Library &amp;\nInformation Science Research,\n28(4), 480-500. doi:\n10.1016/j.lisr.2006.04.001\nMeho, L. I., &amp; Yang, K. (2007). Impact\nof data sources on citation counts\nand rankings of LIS faculty: Web of\nScience versus Scopus and Google\nScholar. Journal of the American\nSociety for Information Science and\nTechnology, 58(13), 2105-2125.\nPaglis, L. L., Green, S. G., &amp; Bauer, T.\nN. (2006). Does adviser mentoring\nadd value? A longitudinal study of\nmentoring and doctoral student\noutcomes. Research in Higher\nEducation, 47(4), 451-476.\nSugimoto, C. R., Russell, T. G., Meho,\nL. I., &amp; Marchionini, G. (2008).\nMPACT and citation impact: Two\nsides of the same scholarly coin?\nLibrary &amp; Information Science\nResearch, 30(4), 273-281. doi:\n10.1016/j.lisr.2008.04.005\nSugimoto, C. R. (2012a). Are you my\nmentor? Identifying mentors and\ntheir roles in LIS doctoral education.\nJournal of Education for Library\nand Information Science, 53(1), 219.\nSugimoto, C. R. (2012b). Initiation,\ncultivation, separation and\nredefinition: Application of Kram’s\nmentoring framework to doctoral\neducation in information and library\nscience. Journal of Education for\nLibrary and Information Science,\n53(2), 98-114.\nTenenbaum, H. R., Crosby, F. J., &amp;\nGliner, M. D. (2001). Mentoring\nrelationships in graduate school.\nJournal of Vocational Behavior, 59,\n326-341.\n\n2053\n\nA MODEL BASED ON BIBLIOMETRIC\nINDICATORS: THE PREDICTIVE POWER\nElizabeth S. Vieira1, José A. S. Cabral2, José A.N.F. Gomes1\n1\n\njfgomes@fc.up.pt\nREQUIMTE/Departamento de Química e Bioquímica, Faculdade de Ciências,\nUniversidade do Porto, Rua do Campo Alegre, 687, 4169-007 Porto, Portugal\n2\n\njacabral@fe.up.pt\nINESC-TEC, Faculdade de Engenharia, Universidade do Porto, Rua Dr. Roberto Frias,\ns/n, 4200-465 Porto, Portugal\nIntroduction\nBibliometric indicators have been\nwidely used for assessing the scientific\nperformance of a given research body.\nThe design of indicators has attracted a\nlot of attention in the last few years as\nnational authorities, funding bodies or\ninstitutional leaders show a growing\ninterest in indicators that can rate the\nperformance of their institutions.\nNowadays, several countries use a\ncombination of peer review and\nbibliometric indicators to assess the\nresearch\nperformance\nof\nhigher\neducation institutions and to allocate\nfunding. Peer review is still the gold\nstandard of research evaluation but the\npressure for more frequent and extensive\nassessment of the performance of\nresearchers, research groups and\nresearch institutions makes bibliometry\nattractive. It is therefore very important\nto benchmark bibliometric indicators\nagainst traditional peer assessment in\nreal situations. Some studies have been\ncarried out in recent years with the main\ngoal of finding a correlation between the\ntwo methodologies. These studies\nconsidered the judgments of peer-review\nat several levels: 1) national level\n(Franceschet and Costantini 2011); 2)\nresearch programs, research groups,\n2054\n\ndepartments (Aksnes and Taxt 2004;\nVan Raan 2006) and 3) at individual\nlevel (Bornmann and Daniel 2006,\n2007; Bornmann, Wallon and Ledin\n2008). At the individual level the\napplication of bibliometric indicators is\nmore complex and more care is needed\nin the data treatment. However, the\napplication of such indicators is feasible\nas a few studies made in the last few\nyears (Bornmann et al. 2006, 2007;\nBornmann et al. 2008) suggest.\nHere we consider the peer decisions in a\ncollection of academic job openings in\nPortuguese universities and look for\nways to design a model based on\nbibliometric indicators that may follow\nthese results. Considering the high\nweight that the scientific performance\nhas in these selection processes, we\nlooked for a set of indicators that we\nsuggest may be thought to be implicit in\nthe judgment by the peers. We are not\nsuggesting that the ranking of candidates\nin this type of job openings can be made\nwithout recourse to peers. However, we\nconsider that if a definition of a model\nbased on bibliometric indicators is\nfeasible, this complementary instrument\ncan help peers in the evaluation of the\napplicants and the formulation of the\nfinal decisions. The predictive power of\nthe model was explored aiming at\nfinding how far the model can predict\n\nthe peer decisions on the academic\nopenings.\nMethodology\nThe data set consists of 27 contests with\na total of 171 researchers. The number\nof applicants varies among contests (211). A set of 12 indicators were\nconsidered based on the list of the\ncandidates’ publications indexed in the\nISI Web of Science. The indicators used\nwere:\nNDF – Number of documents. Each\ndocument was divided by the number of\nauthors, (1/N, N being the total number\nof authors in each document).\nNIR – The normalized impact indicator\nfor researchers. This indicator gives the\nmean number of normalized citations\nper document taking into account the\ndifferent culture of citation of each\nsubject category.\nhnf – This indicator is calculated in a\nway similar to the h index, but considers\nthe different cultures of citation of each\nsubject category and the number of\nauthors per publication.\nHCD – Percentage of highly cited\ndocuments. This indicator considers the\npercentage of documents of a given\nresearcher that are in the Top 10% most\ncited Portuguese documents.\nDIC – Percentage of documents with\ncollaboration. This indicator refers to\ndocuments\nwith\nat\nleast\none\ninternational collaboration.\nCD - Percentage of citing documents.\nThis indicator does not consider those\nciting documents that belong to the\nresearcher.\nDNC – Percentage of documents not\ncited.\nSNIP – Source normalized impact\nindicator (Moed 2010).\nSJR – SCImago journal rank (GonzalezPereira, Guerrero-Bote and MoyaAnegon 2010).\n\nQ1 – High prestige journals (SCImago\nInstitutions Rankings).\nNI – Normalized impact (SCImago\nInstitutions Rankings).\nNAm – Number of normalized authors\nper document.\nThe rank ordered logistic regression\n(ROLR) was applied to our data in order\nto define the model. After defining the\nmodel, the predictive power was\nstudied. Initially this was done\ndetermining the number of times the\ncandidate placed in the first position by\npeers was that with the highest\nprobability of being chosen first. Then\nwe have studied the model forecasts and\nthe peer selection using all pairs of\napplicants.\nResults\nThe application of the ROLR lead to the\nfollowing model:\n\n∑\nwhere Pi is the probability of the\napplicant i to be selected in first place\nby peers.\nTable 1. First place, correctly, predicted\nby the model.\n\nCorrect prediction of\nthe first place\n\nModel\n\nRandom\nestimate\n\n52%\n\n23%\n\nOnce we have the model defined, we\ndetermined the percentage of cases\nwhere the predictions given by the\nmodel are coincident with the peer\njudgments. For the set of openings\nconsidered, it was determined the\nnumber of times the candidate placed in\nthe first position by peers was that with\nthe highest probability of being chosen\nfirst. The result is compared with a\n2055\n\nsituation without information about the\napplicants. The results are presented in\nTable 1.\nThe model defined allows us to go\nfurther in the assessment of the\npredictive power. It is possible to\nevaluate the predictions given by the\nmodel using pairs of applicants. In the\ndata set considered, 426 pairs are\navailable and the model predicts,\ncorrectly, 75% of the pairs. The Monte\nCarlo’s simulator was used to obtain the\nprobability distribution function as\npresented in Figure 1.\nThe fitting of a normal distribution to\nthe data gives a probability distribution\nfunction that is skewed and platykurtic\n(-0.047 and -0.029 respectively). The\nresults of the fit suggest that the model,\non average, predicts correctly 72%±2%\nof the pairs. The percentage predicted by\nthe model (75%) is in the range [μ+2σ].\nThe probability of predicting correctly\nmore than 75% of the pairs is just\n7.35%.\n\nFigure 1. Probability distribution function\nobtained using Monte Carlo’s simulation.\n\nAcknowledgments\nElizabeth Vieira wishes to acknowledge\nthe financial support from FCT,\nPortugal,\nthrough\na\ngrant\nNo\nSFRH/BD/75190/2010.\n\n2056\n\nReferences\nAksnes, D. W. &amp; Taxt, R. E. (2004).\nPeer reviews and bibliometric\nindicators: A comparative study at a\nNorwegian university. Research\nEvaluation, 13(1), 33-41.\nBornmann, L. &amp; Daniel, H. D. (2006).\nSelecting scientific excellence\nthrough committee peer review - a\ncitation analysis of publications\npreviously published to approval or\nrejection of post-doctoral research\nfellowship applicants.\nScientometrics, 68(3), 427-440.\nBornmann, L. &amp; Daniel, H. D. (2007).\nConvergent validation of peer review\ndecisions using the h index - extent\nof and reasons for type i and type ii\nerrors. Journal of Informetrics, 1(3),\n204-213.\nBornmann, L. Wallon, G. &amp; Ledin, A.\n(2008). Does the committee peer\nreview select the best applicants for\nfunding? An investigation of the\nselection process for two european\nmolecular biology organization\nprogrammes. Plos One, 3(10).\nFranceschet, M. &amp; Costantini, A.\n(2011). The first italian research\nassessment exercise: A bibliometric\nperspective. Journal of Informetrics,\n5(2), 275-291.\nGonzalez-Pereira, B. Guerrero-Bote, V.\nP. &amp; Moya-Anegon, F. (2010). A\nnew approach to the metric of\njournals&#x27; scientific prestige: The sjr\nindicator. Journal of Informetrics,\n4(3), 379-391.\nMoed, H. F. (2010). Measuring\ncontextual citation impact of\nscientific journals. Journal of\nInformetrics, 4(3), 265-277.\nVan Raan, A. F. J. (2006). Comparison\nof the hirsch-index with standard\nbibliometric indicators and with peer\njudgment for 147 chemistry research\ngroups. Scientometrics, 67(3), 491502.\n\nMONITORING OF INDIAN RESEARCH PAPERS:\nON THE BASIS OF MAJOR GLOBAL SECONDARY\nSERVICES\nDivya Srivastava1, Arvind Singh Kushwah2, Mona Gupta3\ndrdivya.srivastava@gmail.com1 , arvindsinghmca@yahoo.com 2, Gmona7@gmail.com 3\nScientist, Indian Council of Medical Research, Ansari Nagar, New Delhi 110029, India\nBackground\nScience and technology pursuit has been\na major planning objective of the\ncountry, identified on purpose to initiate,\nadvance and accelerate national\ndevelopment in all sectors of the\neconomy. Consequent upon this policy\ninitiative, India has been able to usher\nsignificant growth in its capacity and\ncapability in basic, applied, and\ndevelopmental research in science and\ntechnology. Its S&amp;T infrastructure has\ngrown large, comprising of more than\n300\nuniversities,\n400\nresearch\nlaboratories, 13 institutes of national\nimportance. It is desirable that India\ncomes out with a program to measure\nand monitor its performance in S&amp;T on\na regular basis. This task inevitably\nrequires building appropriate indicators\nof\nS&amp;T\nperformance.\nBesides,\nindicators are required for depicting how\nIndian science is being covered by\nmajor secondary services. It is within\nsuch a context that the present study has\nbeen done. India has the third largest\npool of researchers in the world, after\nthe USA and the CIS (Commonwealth\nof Independent States). However, the\nquality of research output does not\nreflect this numerical strength. The\nliterature has pointed that that in the\npresent situation a lot of papers gets\nmissed out and visibility and impact of\nIndian research efforts gets affected\nadversely. There are studies depicting\n\nthat the total Indian share in world\nscientific output appearing in a scholarly\njournal covered by the Science Citation\nIndex (SCI) between 1981 and 1995 has\ndeclined by 32%, almost double the\n17% decline estimated in World Science\nReport, on the basis of SCI data\ncollected for 1982 and 1993. Indian\nscientists were responsible for close to\nhalf of the third world’s publication\noutput in 1973 and India with 7888\npapers was the eighth largest publishing\nnation in the world. Now India’s rank\nhas slid to fifteenth in 1998 and 2000.\nThe number of papers published (as\nseen from SCI) over two decades shows\nsimilar trend. The number of papers\npublished in 1980, 1985, 1990, 1995,\n2000, 2005 was 14,983, 11,222, 10,103,\n11,084, 12,127 and 25,102 respectively.\nThis clearly indicates that number of\nresearch papers published by Indian\nscientists is around 10,000-25,102+\nduring the last two decades. To test this\nhypothesis we have downloaded the\npapers having ‘India’ in its address field\nand appeared in a journal covered by\nSCI for the period of 2005-2009. There\nwere total 1,74,403 papers indexed in\nSCI being published by the over 40\nCSIR affiliated labs, 31 ICMR\nInstitutes, Institutes belonging to DST,\nICAR and the rest were from the\nuniversity/ colleges sectors. The\npercentage contribution was 1.78, 26.42\nand 29.25 from Colleges, Universities\nand the research Institutions.\n2057\n\nMost of the institutions publish their\npapers in non SCI journals, therefore,\nthere is a need that, total Indian research\npapers should be computed on the basis\nof papers from major global services\nalong with papers published by Indian\nauthors in foreign journals to generate\nneed based Indian National Science\nIndicators/ reports for the national, and\ngeographical productivity as well as\nsubject wise productivity depicting the\ntrend of research papers. With this\nbackground, the present study would\nprovide\na\nconsolidated\nand\ncomprehensive sound database on\namount of work/research done in the\nfield in India and will facilitate a quick\naccess to various Indicators.\nMethodology\nIn the present study, the papers have\nbeen extracted from selected global\nsecondary services eg, INSPEC,\nTropical Diseases Bulletin (Online\nService), CABI, AGRIS and Indian\nScience Abstracts by Indian authors.\nThe data has been analyzed separately\nfor each database for computing trend of\npapers being covered by that particular\nsecondary service along with the trend\nof coverage of journals and the pattern\nof subject area over the years (20052009). A study has also been done to\ncompute total publications during the\nperiod of the study which are coming\nout from different cities and states of\nIndia.\nObservations &amp; Findings\nThe objectives of the study are\nthreefold: assessing the contribution of\ndifferent cities and states to mainstream\nscientific\nliterature\nin\ndifferent\ndisciplines of science and technology\nduring 2005-2009; identifying most\nprolific City, Institutions and their\ncontribution\nin\ndifferent\nbroad\ndisciplines of science and technology.\n2058\n\nThese outputs are used to understand\ngrowing Indian capacities and potential\nin different fields of science and\ntechnology. In the period 2005 - 2009,\nthe Indian S&amp;T output as reflected in all\nthe databases, is skewed. In the year of\n2007 a significant growth has been\nobserved. The Graph 1 shows the\npercentage of papers produced by Indian\nscientists in the five years, which has\nbeen covered by all the three databases.\nDespite the limitations in funding for\nscience and technology, the contribution\nof Indian scientists to the world’s\nscientific output increased during the\nlast five years. India established a large\nnumber of institutions in the recent\nperiod which is yielding currently large\nnumber of research papers.\n\nFigure 1. Year wise Total Papers covered\nby ISA, CABI &amp; INSPEC.\n\nAn analysis has been done to compute\nthe productivity of Indian cities and the\nIndian States also on the basis of papers\nindexed in the secondary services viz\nISA, INSPEC and CABI. A total of 666\nIndian Cities contributed all these\npapers. The top most city was Delhi\nfollowed by Hyderbad, Chennai,\nCoimbatore and Mumbai.\n\nThe data was analyzed to compute the\nproductivity of Indian States also. All\nthe 30 Indian States produced papers\nwhich were covered by the services\nunder study. The top most state with\n(more than 1000 Papers) maximum\nindexed paper was Uttar Pradesh\nfollowed by Tamil Nadu, Maharashtra,\nDelhi, Karnataka, Andhra Pradesh, West\nBengal, Haryana, Rajasthan, Punjab,\nMadhya\nPradesh,\nGujarat\nand\nUttarakhand.\nCoverage of Science and Technology\nJournals by Secondary Services:\nMost Productive Journals: There were\ntotal 967 journals covered by all the\nthree indexing service viz ISA, CABI\nand INSPEC, during the whole study\nperiod (2005-2009). The first 50%\npapers (around 47611) were indexed in\nfirst two years. The top most 5 journals\npublishing Indian Papers were Environ\nEcol followed by Asian J Chem , Acta\nCienc Indica – Math and Curr Sci .\n\nThe data indicates that the Average\nGrowth of the Papers and the Indexed\nJournals by the services viz. ISA, CABI\n&amp; INSPEC are adversely proportional to\neach other. The data has been analysed\nto compute the percentage of Indexed\nJournals by all the three Indexing\nServices individually also.\n\nFigure 5. Top 10 Journals of ISA during\n2005-09\n\nFigure 6. Average Growth Rate of Top 10\nJournals of ISA during 2005-09\n\nFigure 3. Top 20 Journals during 2005-09\n\nFigure 7. Top 10 Journals of INSPEC\nduring 2005-09\n\nFigure 4. Average Growth of Indexed\nJournals having Indian Papers\n\nThere were total 72 Journals (publishing\nIndian papers) covered by INSPEC\nduring 2005-09. The year wise coverage\nof the Journals was 50, 59, 54, 46 and\n21 during the period of 2005-09\nrespectively.\n\n2059\n\nThe trend of ‘Average Growth’ of\nIndian Papers and the Journals covered\nin CABI, indicates that during the period\nof 2006-2007, it has gone into a\nnegative value, which calls for\nimmediate attention of the authorities to\nlook into the matter.\nFigure 8. Average Growth Rate of\nTop 10 Journals of INSPEC during\n2005-09\nThe graph of ‘Average Growth Rate’ of\nINSPEC, indicates that over the years ,\nthe coverage of journals having Indian\npapers have increased.\n\nFigure 9. Top 10 Journals of CABI during\n2005-09 According to the Publication\n\nThere were total 72 Journals (publishing\nIndian papers) covered by CABI during\n2005-09.\n\nFigure 10. Average Growth Rate of Top\n10 Journals of CABI during 2005-09\n\n2060\n\nISA being only Indian Indexing Service\nhas covered maximum Indian Papers,\nwhereas the coverage by other two\nGlobal Secondary Services indicates\nthat over the years the coverage of the\nIndian Papers are not up to the mark.\nPeer Review: The most important\nmeasure to ensure quality of a journal is\nthe peer review system. It has been\ncriticized that many Indian journals do\nnot have peer review system. Therefore,\nin the current initiative, the peer review\nsystem followed by Indian journals is\nbeing investigated. To understand the\npeer review system, the following\npractice is followed.\nConclusion\nWe are concerned with poor peer\nreviewing practice of Indian journals.\nUnless the institutions insist their\nscientists to opt for publications in the\npeer reviewed journals and to consider\nthe publications in the peer reviewed\njournals only, the Indian journals will\ncontinue to be in the vicious circle.\nFunding agencies should try to allocate\nfunds in the less accessible geographical\nareas to encourage scientist of those\nparticular Cities/States to come forward\nand carry out research activity followed\nby publications.\n\nNANOSCIENCE AND NANOTECHNOLOGY IN\nSCOPUS: JOURNAL IDENTIFICATION AND\nVISUALIZATION\nTeresa Munoz-Ecija, Benjamín Vargas-Quesada, Zaida Chinchilla-Rodríguez,\nAntonio J. Gómez-Nuñez and Félix de Moya-Anegón\n1\n\nteresamunyozecija@gmail.com\nSCImago Research Group Associated Unit, Granada (Spain)\n2\n\nbenjamin@ugr.es\nUniversity of Granada – Information &amp; Communication Department (Spain)\n3\n\nzaida.chinchilla@cchs.csic.es\nCSIC – Institute of Public Goods and Policies (IPP), Madrid (Spain)\n4\n\nanxusgo@gmail.com\nSCImago Research Group Associated Unit, Granada (Spain)\n5\n\nfelix.demoya@cchs.csic.es\nCSIC – Institute of Public Goods and Policies (IPP), Madrid (Spain)\nIntroduction\nThis document presents a new query for\nthe retrieval of information about\nNanoscience &amp; Nanotechnology (N&amp;N)\nbased on the combination of previously\npublished search strategies, contrasted\nby the scientific community. It led us to\nidentify 80 core journals of N&amp;N in\nScopus, then map and analyze the\nunderlying structure of N&amp;N output\nusing visualization techniques. N&amp;N is\nestablished as a productive young\ndiscipline, crosscutting other fields in its\nrapid evolution, for which reason it has\npoorly defined limits to date, and needs\nsome time to consolidate its identity as a\ndiscipline.\nMaterials &amp; Methods\nOn 06/11/2012 we launched a search\nagainst the Scopus database using the\ncombination of different queries\n\nproposed previously. Query 1 included\nterms with the root nano*, while\nexcluding any terms containing the root\nnano* yet not related with N&amp;N. To this\nend, we referred to the combination of\nproposals made by Noyons et al., 2003;\nGlänzel et al., 2003; Huang et al., 2003;\nand Meyer, Debackere and Glänzel,\n2010. In turn, query 2 combined\ninstruments and processes utilized in\nN&amp;N with different types of materials,\nfunctions and other terms, in the wake\nof proposals by Noyons et al., 2003,\nGlänzel et al., 2003, Kostoff, Koytcheff\nand Lau, 2007 and Porter et al., 2008.\nFinally, query 3 included a series of\nterms related with N&amp;N and was based\non the work of Noyons et al., 2003;\nGlänzel et al., 2003; Huang et al., 2003;\nKostoff, Koytcheff and Lau, 2006;\nPorter et al., 2008; and Lv et al., 2011.\nThe combination of these three searches\nled to a new query which we believe can\nbe\nperfectly\nadopted\nfor\nthe\n2061\n\nidentification of N&amp;N documents in any\nspecialized or multidisciplinary database\n(Annex). It is available too in Scopus\nformat\nat:\nhttp://www.scimago.es/\nbenjamin/nanoquery.pdf\nResults\nThe total number of retrieved documents\nwas 142,102: 70,726 articles, 30,314\nconference papers and 4,062 reviews.\nThe total number of references was\n2,903,543. To identify the core journals,\nwe selected those that reflected over 1%\nof\ntotal\ncitation,\neliminating\nmultidisciplinary journals such as\nNature, Science and PNAS. We\naggregated all journals covered by\nScopus that had the term “nano” in their\ntitles and that had been cited at least\nonce in 2010, with the understanding\nthat the term “nano” in a title indicates\nthat the journal pertains to the discipline\nof N&amp;N and has been previously\nreviewed and validated by the scientific\ncommunity (Schummer, 2004). The core\njournals of N&amp;N identified amount to\n80 (Table 1). Its visualization was\nachieved by means of Vosviewer (Van\nEck &amp; Waltman, 2010). It draws\ntogether the journals in four clusters\n(Figure 1). The correspondence between\ncolors and journals is indicated in Table\n1: red is 1, green is 2, blue is 3 and\nyellow is 4.\n\nFigure 1. Scopus core journals in N&amp;N\n\nDiscussion\nThe 80 journals indicated constitute the\ncore group of N&amp;N publications.\nHowever, for future reference, we ought\n2062\n\nto include in brackets the other 11 that\nalso had the term “nano” in their title,\nsince they will eventually be cited as\nwell. Indeed, three of them appear as\ncited in the year 2010 in the SCImago\nJournal &amp; Country Rank (Scimago,\n2007), but not with reference to the\ndocuments we downloaded as the basis\nof our study. For a more complete view\nof core N&amp;N journals, the listing and\ndisplay offered here should be compared\nwith a future contribution that also takes\ninto account information from the Web\nof Science. One might expect a clearly\noutlined map of N&amp;N journals in\nScopus, given that core journals\nconfigure the basis of the map.\nSurprisingly, this is not the case. At first\nglance, there appears a fragmentation of\njournals revealing two major groups:\nPhysics, condensed matter on the one\nhand, and Chemistry multidisciplinary\non the other. This depiction implies that\nN&amp;N is a highly transversal discipline,\nand that its borderlines are not well\nestablished.\nConclusions\nN&amp;N configure a highly transversal\ndiscipline, whose borders appear to defy\ndelimitation.\nWhile\nmost\nN&amp;N\ndocuments are published in Physics and\nChemistry journals, they may also be\nincluded in journals specializing in\nMaterials Science or other slippery\nsubject areas that may include the term\n“nano” in their title, and by virtue of this\nprefix, come to form the ranks of this\ndiscipline in high gear. Just 50 years old,\nit can be seen as a field in constant\nevolution, in parallel with the growth of\njournals who divulge its findings. It is a\nmatter of time, and space, but N&amp;N will\neventually have its own profile in\nScientometric mappings, That is, it will\nconsolidate an identity as a distinctive\nscientific discipline, and be delimited as\na separate category in databases such as\n\nScopus. Our analysis ventured into\nmultidisciplinary databases by different\nmeans, recovering more documents than\nother attempts reported previously. To\nour knowledge, this is the first research\nstudy to combine all the approaches to\nN&amp;N published to date, and discarding\nduplications. The sensitivity of this new\ntype of query makes it adaptable to any\ndatabase, as long as the syntax and\noperators are adjusted accordingly.\nReferences\nGlänzel, W., Meyer, M., Du Plessis, M.,\nThijs, B., Magerman, T.,\nSchlemmer, B., Debackere, K.,\nVeugelers, R. (2003) Domain Study\n‘Nanotechnology: Analysis of an\nEmerging Domain. Steunpunt O&amp;O\nStatistieken.\nHuang, Z., Chen, H., Yip, A., Ng, G.,\nGuo, F., Chen, Z.K., Roco, M.C.\n(2003). Longitudinal patent analysis\nfor nanoscale science and\nengineering: Country, institution and\ntechnology field. Journal of\nNanoparticle Research, 5(3-4), 333363.\nKostoff, R.N., Koytcheff, R.G, LAU,\nC.G.Y. (2007). Structure of the\nGlobal Nanoscience and\nNanotechnology Research\nLiterature. Journal of Nanoparticle\nResearch, 9, 701-724.\nKostoff, R.N., Murday, J.S., Lau,\nC.G.Y., Tolles, W. M. (2006). The\nseminal literature of nanotechnology\nresearch. Journal of Nanoparticle\nResearch, 8(2), 193-213.\nLv, P.H., Wang, G.F., Wan, Y., Liu, J.,\nLiu, Q., Ma, F.C. (2011).\nBibliometric trend analysis on global\nresearch. Scientometrics, 88(2),399419.\nMeyer, M., Debackere, K., Glänzel, W.\n(2010). Can applied science be ‘good\nscience’? Exploring the relationship\nbetween patent citations and citation\n\nimpact in\nnanoscience.Scientometrics, 85(2),\n527-539.\nNoyons, E.C.M., Buter, R.K., Van Raan,\nA.F.J. (2003). Mapping Excellence\nin Science and Technology across\nEurope: Nanoscience and\nNanotechnology: Final Report.\nEuropean Commission. Retrieved\nMarch 2, 2012 from\nftp://ftp.cordis.europa.eu/pub/nanote\nchnology/docs/ec_mapex_nano_final\n_report.pdf\nPorter, A.L., Joutie, J., Shapira, P.,\nSchoeneck, D.J. (2008). Refining\nsearch terms for nanotechnology.\nJournal of Nanoparticle Research,\n10(5), 715-728.\nSchummer, J. (2004).\nMultidisciplinarity, interdisciplinary\nand patterns of research\ncollaboration in nanoscience and\nnanotech-nology. Scientometrics,\n59(3), 425-465.\nSCImago. (2007). SJR — SCImago\nJournal &amp; Country Rank.\nRetrieved January 11, 2013 from\nhttp://www.scimagojr.com\nVan Eck, N.J. and Waltman, L. (2010).\nSoftware survey: VOSviewer, a\ncomputer program for bibliometric\nmapping, Scientometrics, Vol. 84 No\n2, pp. 523-538.\n\n2063\n\nAnnex\nQuery: ((nano* AND NOT (nano2 OR\nnano3 OR nano4 OR nano5 OR\nnanosecon* OR nano-secon* OR\nnanogram* OR nano-gram* OR\nnanomol* OR nanophtalm* OR\nnanomeli* OR nanogeterotroph* OR\nnanoplankton* OR nanokelvin* OR\nnanocurie OR nano-curie OR nanos OR\nnanos1 OR nanoproto* OR nanophyto*\nOR nanoflagel* OR wnanomol* OR\nwnano-curie* OR wnanocurie* OR\nanos1 OR nanobacter* OR nano-bacter*\nOR nanospray* OR nano-spray* OR\nplankton*\nOR\nn*plankton\nOR\nm*plankton OR b*plankton OR\np*plankton\nOR\nz*plankton\nOR\nnanoalga* OR\nnanoprotist* OR\nnanofauna* OR nano*aryote* OR\nnanoheterotroph* OR &#x27;&#x27;nanook of the\nnorth&#x27;&#x27; OR nano-bible)) OR ((atomicforce-microscop*\nOR\nafm\nOR\ntransmission-electron-microscop* OR\ntem OR scanning-tunneling-microscop*\nOR tunnel*-microscop* OR stm OR\nscanning-electron-microscop* OR sem\nOR self-assembl* OR selfassembl* OR\nself-organiz* OR edx OR energydispersive-x-ray OR energy-dispersivex-ray-spectroscop* OR scanning-probemicroscop* OR electron-energy-lossspectroscop* OR eels OR highresolution-tem OR high-resolutiontransmission-electron-microscop* OR\nuv-vis OR x-ray-photoelectron* OR xray-photoelectron* OR xps OR uvvisible-spectroscop* OR Ultravioletvisible-spectroscop* OR hrtem OR\nChemical-force-microscop* OR CFM\nOR scanning-force-microscop* OR\nSFM OR NSOM OR NEAR-FIELDSCANNING-OPTICAL-MICROSCOP*\nOR SNOM OR &quot;chemical vapor\ndeposition&quot; OR CVD OR &quot; chemical\nvapour deposition &quot; OR XRD OR &quot; xray diffraction &quot; OR &quot; differential\nscanning calorimetry &quot; OR DSC OR &quot;\nmolecular beam epitaxy &quot; OR &quot;mbe&quot;))\n2064\n\nAND (surface* OR film* OR layer* OR\nsubstrate*\nOR\nroughness\nOR\nmonolayer* OR mono-layer* OR\nmolecul* OR structure* OR resolution\nOR etch* OR grow* OR silicon OR si\nOR silicium OR &quot;silicon oxide&quot; OR sio2\nOR deposit* OR particle* OR formation\nOR tip OR atom* OR gold OR au OR\npolymer* OR copolymer* OR copolymer* OR gaas OR inas OR\nsuperlattice* OR adsorption OR absorb*\nOR island* OR size OR powder* OR\nresolution\nOR\nquantum*\nOR\nmultilayer* OR multi-layer* OR array*\nOR mater* OR supramolecular* OR\nbiolog*)) OR (quantum-dot* OR\nquantum-wire* OR quantum-well* OR\nquantum-effect*\nOR\n&quot;quantum\ncomputing&quot; OR coulomb-blockade* OR\ncoulomb-staircase*\nOR\nmolecul*motor* OR molecul*-ruler* OR\nmolecul*-device*\nOR\n&quot;molecular\nbeacon&quot; OR molecular-sensor* OR\n&quot;molecular engineering&quot; OR molecularelectronic* OR molecular-manufact*\nOR\n&quot;molecular\nmodeling&quot;\nOR\n&quot;molecular simulation&quot; OR molecul*wire* OR molecular-sieve* OR\nbiosensor* OR bionano* OR hipco OR\nmolecular-template* OR carbon-tub*\nOR carbontub* OR bucky-tub* OR\nbuckytub* OR fulleren* OR biochip*\nOR dna-cmos* OR graphen* OR\ngraphit* OR single-molecul* OR\nlangmuir-blodgett OR pdms-stamp* OR\npebbles OR nems OR quasicrystal* OR\nquasi-crystral* OR sol-gel* OR solgel*\nOR dendrimer* OR soft-lithograph* )).\nWe limited the documents of interest to\nthose published within the year 2010\nand to articles, conference papers and\nreviews.\n\nTable 1. Scopus core journals in N&amp;N\nAbbreviated\njournal title\nphys rev b\nphys rev lett\nappl phys lett\nj am chem soc\nnano lett\nLangmuir\nj appl phys\nj phys chem b\nAngew chem int edit\nadv mater\nj chem phys\nmacromolecules\nj phys chem c\nChem. Mater\nbiomaterials\nanal chem..\nj phys-condens mat\nChem. Commun\nPolymer\nNanotechnology\nChem. Rev\nnat mater\nj mater chem.\nphysica e\nCarbon\nthin solid films\nChem. phys lett\nnat nanotechnol\nAcs nano\nj nanosci nanotechno\nj nanopart res\nNanomedicine\nieee t nanotech\nnano today\nNanoscale res lett\nnano res\nmicrofluid nanofluid\nInt j nanomed\nj comput theor nanos\nNanomed-nanotechnol\nj biomed nanotechnol\nj. nanobiotechnology\nNano\ncurr nanosci\nNanoscale\nNanotoxicology\nieee t nanobiosci\nDig j nanomater bios\n\nCites\n\n%\nClusters\nCites\n184,370 13.879\n3\n81,585 6.141\n3\n75,445\n5.68\n2\n74,126\n5.58\n1\n60,151 4.528\n2\n42,982 3.236\n1\n42,849 3.226\n2\n35,639 2.683\n4\n35,435\n2.67\n1\n32,163\n2.42\n1\n31,114 2.342\n3\n28,069 2.113\n1\n27,568 2.075\n4\n24,481\n1.84\n1\n21,191\n1.6\n1\n19,287\n1.45\n1\n17,648 1.328\n3\n16,912\n1.27\n1\n16,692 1.257\n1\n16,346\n1.23\n1\n15,008\n1.13\n1\n14,218\n1.07\n4\n13,431 1.011\n1\n12,658 1.008\n3\n12,150 1.006\n1\n12,006 1.001\n1\n11,836\n1\n1\n7,697\n0.579\n1\n6,242\n0.47\n1\n3,799\n0.286\n1\n1,800\n0.135\n1\n1,605\n0.121\n1\n968\n0.073\n1\n820\n0.062\n1\n700\n0.053\n1\n643\n0.048\n1\n564\n0.042\n2\n548\n0.041\n1\n435\n0.033\n1\n352\n0.026\n1\n328\n0.025\n1\n299\n0.023\n1\n293\n0.022\n1\n272\n0.02\n1\n266\n0.02\n1\n251\n0.019\n1\n232\n0.017\n1\n211\n0.02\n1\n\nInt j nanotechnol\nj nanomater\nj nanophotonics\nInt. j. nanosci.\nSynth react inorg m\nWires nanomed\nnanobi\nMicro nano lett\nphotonic nanostruct\nnanosc and nanotech –\nasia\nj exp nanosci\nFuller nanotub car n\nj nanoelectron optoe\nnanosc microsc therm\nNanoethics\nj micro-nanolith mem\nrecent pat nanotech\nNami jishu yu jingmi\ngongcheng\nj laser micro nanoen\nj nano res\nnano biomed. eng.\nInt. j.\nnanomanufacturing\nNanotechnology law\n&amp; business\nIet nanobiotechnol\ne-j. surf. sci. nanotech.\nieee nanotechnol.\nmag.\nInt. j. nanoparticles\nnanotechnol. russ.\nnanosci nanotech let\nj. bionanosci.\nj. nanostruct. polym.\nNanocomp.\nnanotechnol. sci. appl.\nproc. Inst mech eng\npart nj n&amp;n.\n\n198\n147\n133\n127\n121\n75\n\n0.015\n0.011\n0.01\n0.01\n0.009\n0.006\n\n1\n1\n4\n2\n1\n1\n\n74\n71\n68\n\n0.006\n0.005\n0.005\n\n2\n4\n1\n\n66\n63\n53\n51\n48\n47\n36\n33\n\n0.005\n0.005\n0.004\n0.004\n0.004\n0.004\n0.003\n0.002\n\n1\n1\n2\n2\n1\n2\n1\n1\n\n30\n25\n23\n21\n\n0.002\n0.002\n0.002\n0.002\n\n2\n1\n1\n1\n\n20\n\n0.002\n\n1\n\n18\n16\n16\n\n0.001\n0.001\n0.001\n\n1\n1\n1\n\n15\n14\n12\n11\n9\n\n0.001\n0.001\n0.001\n0.001\n0.001\n\n2\n4\n1\n2\n1\n\n6\n5\n\n0.001\n0.001\n\n1\n1\n\n2065\n\nA NEW APPROACH FOR AUTOMATED AUTHOR\nDISCIPLINE CATEGORIZATION AND\nEVALUATION OF CROSS-DISCIPLINARY\nCOLLABORATIONS FOR GRANT PROGRAMS\nIlya Ponomarev1, Pawel Sulima1, Jodi Basner1, Unni Jensen1, Joshua Schnell1,\nKaren Jo2, Larry A. Nagahara2, Jerry S.H. Lee2, and Nicole M. Moore2\n*\n\n1\n\nilya.ponomarev@thomsonreuters.com\nThomson Reuters, 1455 Research Blvd, Rockville, MD (USA)\n\n2\n\nOffice of Physical Sciences – Oncology, Center for Strategic Scientific Initiatives, Office\nof the Director, National Cancer Institute, Bethesda Maryland, 20892 (USA)\n\nIntroduction\nIntegration of new knowledge often\noccurs at the interface of wellestablished research disciplines where\ncross-disciplinary thinking is rapidly\nbecoming an integral feature of\nresearch. Many government programs\nfund research with the specific goal of\nbringing two fields together and the\nenhancement\nof\ncross-disciplinary\nresearch\n(CDR)\ncollaboration.\nEvaluating the impact of these programs\non collaborations and subsequent field\nconvergence remains one of the leastunderstood aspects due to lack of\nindicators (Klein, 2008).\nDevelopment of a proper science\nclassification scheme, suitable to a\nparticular evaluation, is a necessary first\nstep. There are several science\nclassifications\nschemes\nin\nscientometrics, each targeted to different\nlevels of research field aggregation. The\nmost commonly used classification\nscheme is the Web of Science (WoS)\nsubject category (SC) classification that\nconsists of 265 SCs. In this scheme, a\njournal is assigned to one or more\nresearch areas. Publications are not\n2066\n\ndirectly assigned to research areas.\nInstead, the journal in which an article\npublished determines the subject\ndiscipline(s) to which the publication\nbelongs. Other classifications range\nfrom fine keyword/co-citation clustering\ninto 500 plus disciplines (Boyak, 2009)\nto aggregation into broad research fields\n(22 in the Thomson Reuters Essential\nScience Indicators (ESI) or 13 used by\nthe US National Science Foundation).\nChallenges to measuring the impact of\ncross-disciplinary collaborations stem\nfrom an inability to detect convergent\nshifts within one standard science\nclassification scheme. To spot these\nsubtle changes one often needs to\ncompare research categories at different\nlevels of aggregation: from very broad\n(like “Life Sciences”) to very narrow\n(like “Remote Sensing”). Another\nproblem is in the heterogeneity of\nsubject categories themselves: some of\nthem are narrowly focused while others,\nparticularly those related to emerging\nfields, already have a more crossdisciplinary origin.\nTo address these problems and capture\nthe uniqueness of CDR programs, we\n\ndeveloped an automated approach for\nassignment of scientific publications\ninto disciplinary categories tailored for a\nspecific grant program. In this case\nstudy, the approach was used to evaluate\ncross-disciplinary collaborations within\nthe National Cancer Institute’s (NCI)\nPhysical Sciences – Oncology Centres\n(PS-OC) program. The program,\nestablished in September 2009, supports\na network of twelve cross-disciplinary\ncentres. The PS-OC network brings\ntogether\nover\n150\ninvestigators\nstemming from disparate fields of\nphysics,\nmathematics,\nchemistry,\nengineering, cancer biology and clinical\noncology with the primary goal of\nuniting the fields of physical science\nwith cancer research to better\nunderstand the physical and chemical\nforces that shape and govern the\nemergence and behaviour of cancer at\nall levels.\nData and Methodology\nResearch advances, scientific outputs,\nand collaborative activities of PS-OC\nCentres\nare\nmonitored\nthrough\ncomprehensive semi-annual progress\nreports (60-80 pages). Data were\ncollected from 166 active PS-OC\ninvestigators whose specialization was\nknown prior to grant by self-nomination.\n601 publications reported in the semiannual progress reports (Fall 2009 2012) were verified and compiled for\nsubsequent analysis. For a comparison,\nan additional list of 3,367 “baseline\npublications” was generated from WoS\nfor PS-OC investigators prior to the PSOC program (2006-2008). For both lists,\nmore than 202,000 references were\ncollected from 4,199 different journal\ntitles.\nOur goal was to automatically assign\nresearch field interest(s) to each\ninvestigator based on the research\n\ncontent of a person’s publications\nduring a certain period of time. Then, by\nmonitoring new publications, we could\ntrace how investigator research\ninterests and CDR collaboration shifts\nwith time.\nWe developed a three-step automatic\nassignment of investigators’ scientific\ninterests to two or three PS-OC program\nspecific research fields (Physical\nSciences, Oncology, and Life Sciences).\nStage 1: Mapping of SCs to 6\nIntermediate fields\n265 standard journal SCs were manually\ndivided into six intermediate broad\ncategories (IBCs) relating to the PS-OC\ncross-disciplinary research program\n(physical sciences (PS), life sciences\n(LS), medicine (MED), oncology (OC),\nmultidisciplinary (MU), and other\n(OTH)).\nSuch\nan\nintermediate\nclassification is needed for proper\nweighting\nof\npublications\nfrom\nmultidisciplinary journals and for\nadditional renormalization of LS and PS\ndisciplines.\nStage 2: Calculate IBC weights for each\npublication and aggregate weights at\nauthor level\nIBC relevance weights for each\npublication were calculated based on the\njournal SC mapping of the publication\nitself and references in the publication.\nWe assumed that if a paper published in\njournal A has n research fields, then the\ntopic of this paper is equally distributed\nbetween these n IBCs. Thus each of\nthese n fields will receive a weight equal\nto 1/n, and the remaining fields are\nassigned a zero weight. For example,\nthe journal “Radiation Research” is\nassigned\nthree\nWOS\ncategories\n(“Biology”,\n“Biophysics”,\nand\n“Radiology, NM and MI”). These three\nSCs were mapped to two distinct IBCs\n2067\n\n(LS, PS). Therefore, the weights of the\njournal are W(PS)=1/2, W(LS)=1/2,\nW(OC)=W(MED)=W(MU)=W(OTH)=0\n. Such an assignment gives normalized\nweights. For each paper, journal weights\nand weights of references were first\ncalculated separately, and then a\ncombined weight was calculated. These\nweights were then aggregated for all\nauthor’s papers and normalized. The\nsame procedure is repeated for all\nreferences in an author’s publications.\nStage 3: Ranking and category\nassignments\nWe ordered IBC weights in descending\norder. For the final assignment of a\nperson’s discipline (either the two or\nthree classification scheme) weights of\nMED,\nMU,\nand\nOTH\nwere\nproportionally redistributed into OC, PS\nand LS weights. Then the three (or two)\nweights were renormalized. For\nexample, if a researcher had a weight\ndistribution of OC=0.4, PS=0.2, LS=0.1,\nand MED=0.3 then after redistribution\nand renormalization the final weights\nwere OC=0.57, PS=0.29, and LS=0.14.\nValidation and Evaluation\nAt the beginning of the grant program\nall investigators identified themselves as\nan oncologist or physical scientist, and\nthis information was used to validate the\nautomated\ndiscipline\nassignment.\nResults were analysed using standard\nstatistical precision/recall methods and\nare shown in Table 1. Both the precision\nand recall have very high values for the\n2 discipline classification which\nvalidates\nthe\nmethodology.\nThe\nprecision and recall for the 3 discipline\nscheme have a lower but still acceptable\nlevel. It was identified that major\ndiscrepancies came from investigators\n\n2068\n\nwho already had cross-disciplinary\nresearch interests before the PS-OC\nprogram started.\nTable 1. Analysis of precision and recall\nfor 3- and 2 disciplines schema.\n3 discipline\n2 discipline\nclassifications\nclassifications\n2006- 2006- 2006- 200620062008 2008 2008- 2008\n2008\nCategories OC LS PS\n(LS+OC) (PS)\nNCI\nclassifications 52\n31\n83\n78\n88\nPredicted\n29\n83\n54\n76\n90\nresearchers\nCorrectly\n24\n26\n52\n71\n83\npredicted\nIncorrectly\n5\n57\n2\n5\n7\npredicted\n0.83 0.31 0.96\n0.92 0.93\nPrecision\n0.46 0.84 0.63\n0.94 0.91\nRecall\nF-Measure 0.59 0.46 0.76\n0.93 0.92\n\nSuccessful\nvalidation\nof\nour\nmethodology helped us assess intra- and\ncross-disciplinary collaborations before\nand during program participation. Future\ndirections aim to monitor changes in\ninvestigator research outputs after\nreceiving funding.\nAcknowledgments\nWe thank Julia DiCarlo and Yvette\nSeger for help with manuscript editing.\nReferences\nBoyack, K. W. (2009). Using detailed\nmaps of science to identify potential\ncollaborations. Scientometrics,\n79(1), 27–44.\nKlein, J.T. (2008), Evaluation of\ninterdisciplinary and\ntransdisciplinary research: a\nliterature review. American Journal\nof Preventive Medicine, 35(2 Suppl),\nS116-23.\n\nNORMALIZED INDICATORS OF THE\nINTERNATIONAL BRAZILIAN RESEARCH: A\nSCIENTOMETRIC STUDY OF THE PERIOD\nBETWEEN 1996 AND 2011\nMaria Cláudia Cabrini Grácio1 and Ely Francina Tannuri de Oliveira2\n1\n\ncabrini@marilia.unesp.br\nUNESP – Univ Estadual Paulista, 737 Hygino Muzzi Filho Avenue, 17525-900 Marília\n(Brazil)\n2\n\netannuri@gmail.com\nUNESP – Univ Estadual Paulista, 737 Hygino Muzzi Filho Avenue, 17525-900 Marília\n(Brazil)\nIntroduction\nThe Brazilian science has grown\ncomprehensively, particularly in the last\n25 years (Glänzel, Leta &amp; Thijs, 2006;\nLeite, Mugnaini &amp; Leta, 2011). Within\nthis context, to assess scientific\nproduction issues, the bibliometric\nstudies constitute an objective approach,\nwhich offer a real comprehensive and\ntrue diagnosis about the scientific\nproduction of a specific area, of a group,\nof institutions or countries, producers of\nscience and technology.\nA country’s scientific production\nanalysis involves a broad group of\nbibliometric indicators which group\nthemselves in production indicators,\ncitation indicators and link indicators\n(Narin et al., 1994; Callon et al., 1993).\nDespite the importance of the indicators\nfor the analysis and the understanding of\nthe contribution, insertion, and impact of\na researcher or country for a knowledge\narea, a common problem in bibliometric\nanalyses occurs when it’s intended to\nhold comparative studies, given the\nspecificities and peculiarities of each\nknowledge area. In this context, we\nfocus on the relevance of the normalized\n\nindicators, which work as basis and\nenable comparative evaluations, either\namong areas or levels of aggregation,\nonce they standardize the measurement\nunits (Glänzel et al., 2009).\nA normalized indicator may be defined\nas the quotient between the analyzed\nindicator, taken in its original value,\ndivided by the indicator average in the\nstudied scientific area (Moed, 2009). As\nresult, this indicator standardizes the\nbehavior of an individual, in a way that\nit situates it comparing it to the global\ntendency (average) observed in the area.\nIn this research, individuals refer to\ncountries. Value above 1 point that the\nindividual (in this research, Brazil)\npresents a performance above what’s\nexpected for the group (in this research,\ncountries).\nIn this research, we aim at\ncomparatively analyzing the normalized\nscientometric indicators of production\nand citation of the Brazilian research, in\nthe 27 areas of knowledge, from the data\npresented in the Scimago Journal &amp;\nCountry Rank gate, in the period\nbetween 1996 and 2011. Besides, we\naim at grouping the areas by means of\nthe similarities of the indicators\nanalyzed.\n2069\n\nMethodological procedures\nThe data were raised in the Scimago\nJournal &amp; Country, by means of the\nfollowing procedures: for each one of\nthe 27 areas of knowledge, the total\nnumber of existing and Brazilian\njournals was taken in each one of them.\nWe calculated the percentage of journals\nfrom Brazil compared to the existing\ntotal in the different areas. Next, for\neach area, the average of citable\ndocuments, citations per document and\nindex h were calculated. Considering\nthese values, for each area, the\nnormalized Brazilian index was\ncalculated for the indicators mentioned\nabove.\nFinally, we held a hierarchical cluster\nanalysis, by Ward’s method, in order to\ngroup the 27 areas analyzed, according\nto their similarities compared to the\nnormalized indexes, considered together\nand simultaneously. The visualization of\nthe clusters was achieved by means of\nthe dendrogram.\nPresentation and analysis of data\nTable 1 shows that the performance of\nthe Brazilian science is always above 1,\nindicating that Brazil has a position\nabove the expected for the group of\nproducing countries, for all the\nnormalized indexes. We add that the\nnormalized index h is the indicator with\nthe smallest variation in the Brazilian\nperformance.\nWe point out that, in average, the\npercentage of Brazilian indexed journals\nis 1.5% of the total of journals.\nDentistry, Veterinary and “Agricultural\nand Biological Science” are the areas\nthat present the greatest participation in\nBrazilian journals.\nRegarding the normalized index of total\nof documents, the average of the areas is\n3.2 times above the expected for\nproducing\ncountries.\nVeterinary,\n“Agricultural and Biological Sciences”\n2070\n\nand “Immunology and Microbiology”\nstand out as those which present\nscientific production much higher than\nthe expected.\nTable 1. Normalized indicators of\nproduction and of citation of the 27 areas\nrelated to Brazil.\n% of total Cit index\njourn docu per\nh\nals ments doc\nArea\nAgricultural &amp; Bio Scie 3.5 7.6 0.9 2.9\nArts and Humanities\n0.8 2.1 1.1 2.0\nBiochem.Gen&amp;Mol\n0.8 2.9 1.0 2.5\nBiol\nBusiness. Manag &amp;Acc 0.5 1.2 1.5 1.9\nChemical Engineering 1.2 2.8 1.2 2.7\nChemistry\n1.1 2.8 1.1 2.6\nComputer Science\n0.2 2.1 0.9 2.6\nDecision Sciences\n0.6\n2\n1.3 2.3\nDentistry\n5.7 2.3 1.4 3.9\nEarth &amp; Planet Sci\n1.5 2.6 1.1 2.7\nEcon. Econometr&amp; Fin 1.2 1.5 1.9 2.0\nEnergy\n0.0 2.3 0.9 2.5\nEngineering\n0.8 1.9 1.0 2.8\nEnvironmental Sci\n1.8 3.4 1.3 3.1\nHealth Professions\n2.0 2.6 1.2 2.1\nImmun &amp; Microbiol\n1.1 4.9 1.0 2.6\nMaterials Science\n1.3 2.3 1.1 2.3\nMathematics\n0.3 2.9 1.3 2.7\nMedicine\n1.3 3.9 0.9 2.8\nMultidisciplinary\n1.4 1.8 0.7 2.5\nNeuroscience\n1.6 3.5 0.4 2.9\nNursing\n1.9 4.3 1.9 2.9\nPharmacology.\n0.9 3.8 1.1 2.7\nToxicology and\nPharmaceutics\nPhysics and Astronomy 0.4 2.8 1.1 2.8\nPsychology\n2.5 2.3 1.3 2.5\nSocial Sciences\n1.8 2.9 1.2 2.3\nVeterinary\n4.7 10.4 0.9 3.0\nMean\n1.5 3.2 1.1 2.6\nSource: authors’ elaboration, from the ScimagoJr.\n\nConcerning the normalized index of\ncitation per document, it reached the\naverage 1.1, value which is very close to\nthe expected average (global) of the\nrespective areas. Besides, this average is\nthe lowest obtained among indicators\nanalyzed in Brazil, aligning with the\nresults found by Glänzel, Leta &amp; Thijs\n(2006), which point to a visibility of the\n\nBrazilian research lower than the\naverage and an impact of citation\nrelatively low.\nThe normalized index h presented\naverage 2.6 times above the global\naverage. We highlight the areas\nDentistry, “Environmental Science” and\nVeterinary with the highest normalized\nindexes.\nWe present in Figure 1, the cluster of the\n27 areas, grouped according to the\nsimilarities of the indicators of the\nBrazilian science, in which 6 groups are\nhighlighted by color.\nIn relation to first group, the averages of\nevery normalized indexes do not stand\nout in compared to the averages of the\nother 5 groups. Group 2, although\npresenting a less significant production,\nhas an outstanding impact in compared\nto the other 5 groups. The group of\nDentistry stands out from the others\nbecause it presents highest values of\njournals percentage indexed and index\nh. The group 4 presents the lowest\naverage of percentage of journals\nindexed among constructed groups. The\nfifth group presents low index of\ncitation per documents.\n\nThe sixth group presents the highest\nindexes of total of documents produced.\nFinal considerations\nWe point out that Brazil ranks above\naverage in the group of producing\ncountries, for all the normalized indexes\nunder analysis. We observe that for the\nnormalized index of total of documents,\nin all\nareas, Brazil presents its\nproduction above the global average of\nthe respective areas.\nReferences\nCALLON, M., COURTIAL, J.P. &amp;\nPENAN, H. (1995). Cienciometría:\nla medición de la atividad científica:\nde la bibliometría a la vigilancia\ntecnológica. Astúrias: Ediciones\nTrea.\nGLÄNZEL, W., LETA, J. &amp; THIJS, B.\n(2006). Science in Brazil. Part 1: A\nmacro-level comparative study.\nScientometrics, 67(1),67–86.\nGLÄNZEL, W., et al. (2009). Subfieldspecific normalized relative\nindicators and a new generation of\nrelational charts: Methodological\nfoundations illustrated on the\nassessment of institutional research\nperformance. Scientometrics, 78 (1),\n165–188.\nLEITE, P., MUGNAINI, R. &amp; LETA, J.\n(2011). A new indicator for\ninternational visibility: exploring\nBrazilian scientific community.\nScientometrics, 88, 311 – 319.\nMOED, H.F. (2009). New developments\nin the use of citation analysis in\nresearch evaluation. Scientometrics,\n57, 13 –18.\nNARIN, F., OLIVASTRO, D. &amp;\nSTEVENS, K. S. (1994).\nBibliometric theory. practice and\nproblem. Evaluation Review, 18, 65\n– 76.\n\n2071\n\nON THE DEFINITION OF A REVIEW, AND DOES\nIT MATTER?\nRobert Colebunders 1 and Ronald Rousseau2\n1\n\nbcoleb@itg.be\nInstitute for Tropical Diseases, Antwerp, Belgium &amp; University of Antwerp (UA),\nBelgium\n2\n\nronald.rousseau@ua.ac.be\nUniversity of Antwerp (UA), IBW, Venusstraat 35, Antwerp, Belgium\nIntroduction\nIn a previous paper (Colebunders et al.,\n2013) we investigated if the relative\nnumber of reviews in some medical\nfields is increasing and answered this\nquestion affirmatively, at least for the\nsubfields Tropical Medicine, Infectious\nDiseases and Oncology. In that\ninvestigation we simply used the\nThomson Reuters (WoS) definition of a\nreview. According to http://thomson\nreuters.com/products_services/science/fr\nee/essays/impact_factor/ any article\ncontaining more than 100 references is\ncoded as a review. Articles in &quot;review&quot;\nsections of research or clinical journals\nare also coded as reviews, as are articles\nwhose titles contain the word &quot;review&quot;\nor &quot;overview.&quot; Yet, it is well known\n(Harzing, 2013) that Thomson Reuters’\ndefinition of a review is contested. In\nthis contribution we consider two other\ndefinitions and check if using the other\ntwo definitions still leads to an increase\nin the relative numbers of reviews.\nMethods\nData were collected during the first half\nof the month November 2012. Three\ndefinitions of a review publication were\nconsidered and results compared. The\nfirst definition is the Thomson Reuters\nor WoS definition of a review. The\n2072\n\nsimplest\nalternative\nconsists\nof\nretrieving all publications, classified by\nthe WoS as an article or a review\n(eliminating in particular editorial\nmaterial and meeting abstracts), that\nhave either the word review or the word\noverview in the title. Finally, a third and\nbroader alternative consists of all\npublications retrieved by a topic search\n(TS=) for the words review or reviews\n(we note that we did not use\nTS=review* as this would result in a\nnumber of false positives). The\nunderlying idea of the third approach is\nthat even if a review article does not\nhave the word review in the title then it\nhas sentences such as “This paper\nreviews ... “ or “We present a review\nof ...” in its abstract. These three\ndefinitions were used to see if they lead\nto a significant difference.\nFor the determination of a possible\nincreasing trend in the absolute and\nrelative numbers of review publications\nwe collected for each year over the\nperiod [1990, 2011] the total number of\npublications assigned to each of the\nthree medical fields, and for each field\nand each year the number of reviews\n(according to the WoS definition), the\nnumber of (normal) articles (according\nto the WoS definition), the number of\nreviews according to our second\ndefinition and according to our third\ndefinition.\n\nResults\nAbsolute and relative number of reviews\nand the definition of a review\nWe found an increase in the absolute\nnumber of publications in each of the\nthree fields and a corresponding increase\nin the number of reviews, whatever the\ndefinition of a review. It is also clear\nthat, in terms of publications, Oncology\nis the largest field and Tropical\nMedicine the smallest. When collecting\nthe data we noticed the rather strange\nfact that a large number of publications\n(normal articles or reviews) that have\nthe word review or overview in the title\nare not considered as reviews by the\nWoS, contrary to Thomson Reuters’\nwebsite definition. Exact data are shown\nin Table 1. Surprisingly more than 40%\nare not considered to be reviews in the\nWoS. The fact that publications that are\nconsidered to be reviews by their\nauthors are not considered as reviews by\nSCI and vice versa was already\nobserved in (Aksnes, 2006).\nAbsolute and relative numbers of\nreviews differ depending on which of\nthe three definitions are used. Most of\nthe time definition 3 (topic search)\nyields the largest amount of publications\nwhile definition 2 (title words) yields\nthe smallest. To save space we only\nshow result for the field of Oncology\n(Table 2).\nIncreasing trends in the relative number\nof reviews\nNow we come to the most interesting\nquestion, namely: is the relative number\nof reviews increasing over the latest\ntwenty years? Considering the period\n[2000 – 2011] the percentage of reviews\namong all articles and reviews (WoS\ndefinition, not taking meeting abstracts,\neditorial material, and other items into\nconsideration) is on average 10.2% in\nOncology, 6.5% per year in Infectious\n\nDiseases and 3.6% in Tropical\nMedicine. These percentages are much\nhigher than the 2.5% suggested by Price\n(1965). Yet, it is much more interesting\nto see if there really is an increasing\ntrend over the period [1990, 2011]. As\ndata are rather irregular we consider\nthree-year moving averages (Fig.1).\nTable 1. Publications having the word\nreview or overview in the title. Period\n1990-2011\nSubject\narea\nTropical\nMedicine\nInfectious\ndiseases\nOncology\n\nClassified\nas review\n\nClassified\n%\nas article reviews\n\n349\n\n237\n\n59.9\n\n1533\n\n1509\n\n50.4\n\n4697\n\n3468\n\n57.5\n\nTable 2. A: Number of publications\nclassified as Oncology; B: Number of\nreviews Thomson Reuters definition); C:\nNumber of reviews (def. 2: based on title);\nD: Number of reviews (def.3: based on\ntopic search); E: Relative number of\nreviews (WoS definition); F: Relative\nnumber of reviews (based on title); G:\nRelative number of reviews (based on\ntopic search).\nYear\n1990\n1991\n1992\n1993\n1994\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n\nA\n13703\n14014\n14276\n16204\n16559\n18677\n18520\n21829\n24180\n25452\n22924\n24579\n27795\n28099\n39254\n44166\n44563\n46371\n51735\n52985\n50291\n49260\n\nB\n488\n500\n436\n567\n690\n735\n872\n1070\n1204\n1209\n1413\n1542\n1648\n1904\n2036\n2266\n2702\n2791\n3085\n3206\n3322\n3433\n\nC\n152\n137\n163\n185\n209\n201\n240\n323\n339\n294\n280\n299\n290\n342\n399\n456\n495\n577\n599\n666\n728\n791\n\nD\n176\n540\n670\n843\n937\n1019\n1103\n1324\n1525\n1595\n1653\n1837\n1842\n2059\n2408\n2736\n3152\n3453\n3815\n4127\n4422\n4490\n\nE\n0.036\n0.036\n0.031\n0.035\n0.042\n0.039\n0.047\n0.049\n0.050\n0.048\n0.062\n0.063\n0.059\n0.068\n0.052\n0.051\n0.061\n0.060\n0.060\n0.061\n0.066\n0.070\n\nF\n0.011\n0.010\n0.011\n0.011\n0.013\n0.011\n0.013\n0.015\n0.014\n0.012\n0.012\n0.012\n0.010\n0.012\n0.010\n0.010\n0.011\n0.012\n0.012\n0.013\n0.014\n0.016\n\nG\n0.013\n0.039\n0.047\n0.052\n0.057\n0.055\n0.060\n0.061\n0.063\n0.063\n0.072\n0.075\n0.066\n0.073\n0.061\n0.062\n0.071\n0.074\n0.074\n0.078\n0.088\n0.091\n\n2073\n\nTable 3 shows the Pearson correlation\ncoefficient and the slope of the\nregression line. According to the\nThomson Reuters and the topic-based\ndefinitions there is always a clear\nincreasing trend in the relative number\nof reviews. This trend is less clear or\nnon-existing\nfor\nthe\ntitle-based\ndefinition.\n\nFigure 1. Percentages of reviews in the\nfield of Oncology; TR: Thomson Reuters\ndefinition; Topic: results of Topic search;\nTitle: results of Title word search\n\nDiscussion and conclusion\nWe have shown that, for the three\nmedical fields we investigated, an\nincreasing proportion of published\nscientific papers are review papers. This\nconclusion holds when using the\nThomson Reuters definition of a review\nand for publications that are reviews\naccording to a topic search. Remarkably\nthe proportion of articles with the terms\n‘review’ or ‘overview’ in the title shows\nlittle increase, at least in these three\nmedical fields. As mentioned in\n(Colebunders et al., 2013) we consider\nthis increase a disturbing trend and\nsuggest that it is a consequence of the\ncriteria used for evaluating scientists,\ndepartments and universities. To\n\n2074\n\nadvance science we need more\ninnovative research resulting in original\nresearch publications.\nTable 3. Trends\nField\nOncology\nWoS def.\nTitle words\nTopic\nInfectious diseases\nWoS def.\nTitle words\nTopic\nTropical medicine\nWoS def.\nTitle words\nTopic\n\nR (correlation\ncoefficient)\n\nSlope\n\n0.91\n0.18\n0.90\n\n0.0016\n3*10-5\n0.0018\n\n0.89\n0.10\n0.97\n\n0.0013\n3*10-5\n0.0023\n\n0.88\n0.63\n0.78\n\n0.0012\n0.0003\n0.0011\n\nReferences\nAksnes, D.W. (2006). Citation rates and\nperceptions of scientific\ncontribution. Journal of the\nAmerican Society for Information\nScience and Technology, 57(2), 169185.\nColebunders, R., Kenyon, C., &amp;\nRousseau, R. (2013). Increase in\nnumbers and proportions of review\narticles in Tropical Medicine,\nInfectious diseases and Oncology.\nSubmitted.\nHarzing, A.-W. (2013). Document\ncategories in the ISI Web of\nKnowledge: Misunderstanding the\nsocial sciences? Scientometrics,\n94(1), 23-34.\nPrice, D.J. de Solla (1965). Networks of\nscientific papers. Science, 149, 510515.\n\nAN ONLINE SYSTEM FOR MANAGEMENT AND\nMONITORING OF EXTRAMURAL PROPOSALS\nFOR FUNDING BY ICMR – A CASE STUDY\nDivya Srivastava1, Vijai Kumar Srivastava2, Aparna Govind Raj3\n1\n\ndrdivya.srivastava@gmail.com,\nDivision of Publications &amp; Information, Indian Council of Medical Research, New Delhi\n110029, India\n2\n\nvijaiksri@yahoo.com\nDivision of Publications &amp; Information, Indian Council of Medical Research, New Delhi\n110029, India\n3\n\nCDAC, Noida, India\n\nIntroduction\nManagement and monitoring of\nsubmitted proposals is a highly\nintellectual\nactivity\ninvolving\nmanagerial and complex scientific\nactivity. Submitted proposals often go\nthrough a process of scrutiny, getting\nreviewed at multiple levels by multiple\npeople. Compiling these reviews and\ntaking a decision on the proposal based\non reviews is a very important process\nwhich requires skill and utmost care.\nOnce accepted for funds, further\nmonitoring &amp; management of the\nresearch units and the individual\nresearchers is an important task, which\nis basic to better decisions regarding\nfuture research management for policy\ndecisions. The proposals are to be\nevaluated (both retrospective and\nprospective). This is reflected in the\nassessment criteria for past performance\nand future plans that reflect the main\nquestions that need to be answered by\nthe researchers / evaluators. Proposal\nsubmission, processing and management\nsystem helps perform all these tasks\nseamlessly and with ease. It helps better\n\nmanagement of the entire process and\naids better management of records. The\nsystem thus developed is unique for any\nIndian funding agency for processing\nand management of Research Proposals\nin the area of S&amp;T including Medicine.\nImprovement, reducing the time lag,\nease of approach, transparency and\naccountability are the main objectives of\nthis system of quality assessment. Public\naccountability is both a requirement for\npublicly funded research and an inherent\nelement in the improvement cycle in\nwhich this scheme of evaluation plays a\ndominant role. With regard to the\nobjective of improvement, the system is\ndirected toward both the research and its\nmanagement. Evaluators are explicitly\nasked to judge not only the performance\nof an institute’s research and\nresearchers, but also its leadership,\nstrategy and policy, and research\norganization. If applicable, the quality\nquestions also may refer to the socioeconomic impact of research and to\nmulti- and interdisciplinary research. So\nfar the system is running for last one\nyear and a total of 1187 proposals have\nbeen received for funding. Out of these,\n2075\n\nthe evaluation committee has cleared a\ntotal of 902 proposals for further step.\nAn analysis of the Major Discipline,\nInstitute, City and the State indicates the\ntrend of research activity in that\nparticular geographical area. The data is\nbeing compared with the disease burden\n(categorized under different States) to\ninfer that, if the research activity\ncompliments the disease burden or not.\nAs ICMR is the apex body for\nformulation, funding, coordination and\nmanagement of Medical Research in\nIndia, this kind of conclusive results are\nvery important for an ‘Informed\nDecision Making’ by the policy makers.\nBackground\nThere has been a tremendous growth in\nInformation\nand\nCommunication\nTechnologies (ICT) in the last few\nyears. ICT solutions provide better\nmanagement and control to many\nbusiness workflows thus enabling\norganizations to reap the benefits of\nmore sophisticated tools that are used to\nperform their day to day operations The\nIndian Council of Medical Research\n(ICMR) also wanted to computerize\ntheir\nproposal\nprocessing\nand\nmanagement workflow. ICMR is the\napex body in India for formulation,\ncoordination\nand\npromotion\nof\nbiomedical research . One of the tasks it\nundertakes is to provide funds to\norganizations for carrying out research.\nFor this purpose organizations across\nIndia submit their research proposals to\nICMR. If ICMR approves of a research\nidea then it funds the corresponding\norganization to carry out the research\nwork. Traditionally this entire workflow\nused to be performed manually. So\nICMR was getting proposals as hardcopies, these are then posted to experts\nfor their comments. The comments are\nreceived and a notification is sent back\n\n2076\n\nto authors. This approach has many\ndrawbacks, a few listed below:\n Maintaining all received is a\ncumbersome task and the data is\noften prone to natural calamities and\nphysical wear and tear. Also, the\nproposals require large amount of\nphysical space for storage.\n Many a times proposals are lost or\nmisplaced, thereby causing all the\nassociated\ndata\nto\nbecome\ncompletely inaccessible.\n Managing\nindividual\nexpert\ncomments\nbecomes\nvery\ncumbersome.\n Searching for individual proposals is\noften a slow and cumbersome\nprocess.\n Performing any statistical analyses\non the received proposals is an\nextremely difficult task, subject to a\nlot of errors since it is a manual\nprocess.\nIn order to improve efficiency of\nprocessing of its Extramural Research\nProgram and to save efforts of the\nInvestigators, ICMR has decided to\nadopt two stage processing of\nextramural projects. In this direction,\nICMR has recently shifted from manual\nreceipt and processing of extramural\nprojects to on-line interactive system.\nThe system has started functioning and\nall new projects w.e.f. 1.1.2012 are\nbeing received online. It may be\nmentioned that all further processing\nrelating to reviews by experts, sanction\nand release of funds, report submission\nand final closure of the project would be\nthrough this on-line system only. All\nstake holders (PIs, experts, program\nofficers, ICMR management disbursing\nofficers) in the new system are\ninteracting through this on-line system\n(available through the link in ICMR’s\nwebsite).\n\nThe system thus developed is unique for\nany Indian funding agency for\nprocessing and management of Research\nProposals in the area of S&amp;T including\nMedicine. Improvement, reducing the\ntime lag, ease of approach, transparency\nand accountability are the main\nobjectives of this system of quality\nassessment. Public accountability is both\na requirement for publicly funded\nresearch and an inherent element in the\nimprovement cycle in which this scheme\nof evaluation plays a dominant role.\nWith regard to the objective of\nimprovement, the system is directed\ntoward both the research and its\nmanagement.\nMethodology\nEvery stakeholder is expected to log into\nthe system after registering by providing\nsome basic information about himself or\nherself. Furthermore, the access to\nsenior officers of ICMR, Heads of\nDivisions, Program officers, experts and\ndisbursing officers is being provided\nafter proper registration into the system\nby everyone. Necessary assistance is\nbeing provided in this respect by ICMR\nExtramural Team. To make the system\nfully\noperational,\nthe\nfollowing\nprocedure for ad-hoc extra-mural\nprojects are being followed:\n The project proposals received in the\nAdHoc category is reviewed in two\nstages – first a concept proposal is\nasked from the Principal investigator\nand once this is approved a detailed\nproposal is asked for. Now in the\nnew system, the concept proposal is\nsubmitted online. The detailed\nproject is being accepted from the\ninvestigators whose first stage\nconcept proposal has been accepted\nand conveyed to the investigator,\nagain online.\n\n Each project submitted belongs to a\nBroad Area and a Major Discipline\nin the Broad Area. The list of Broad\nAreas is identified by ICMR based\non the current trends in biomedical\nsciences.\n The identification of experts is done\nby Program officers. The Program\nOfficers are members of ICMR who\nhave expertise in specific major\nDisciplines in specific Broad Areas.\n The experts review the proposals and\nsend back their comments. The\ncomments are then reviewed and\naccordingly decisions are taken on\neach proposal. The decisions are\nthen communicated to the respective\nPIs again on-line.\nObservations and Salient Findings\nThe sophisticated value of online\ninformation provision is not to use the\ndatabases only for finding facts and\naccessing documents, but to tap the\nunique items of useful information, the\nnuggets of knowledge and (by synthesis\nand/or analysis) extract the “searched\npattern” in the raw data. So far the\nsystem is running for last one year and\nthe data has been extracted from the\nsystem, by generating need based\nreports on set parameters for analysis.\nIn the present study an analysis of the\nin-house ‘On-line System of Extramural\nProposals’ have been made to identify\ncomparative upcoming subject areas as\nwell as scientific hubs in India, in the\nfield of Biomedical Sciences for the\nperiod of 2012 January- December\n2012. The basic data for the study has\nbeen culled out from the system, related\nto the scope of the study only for ‘adhoc’ proposals being submitted from the\ndifferent parts of India. The findings\nhave clearly indicated change of\nproductive institutions, subject areas\nbeing covered by investigators and the\npattern of Cities and the ‘Major\n2077\n\nDiscipline’\nbeing\nchosen\nby\nInvestigators.\nA total of 1316 proposals have been\nreceived for funding. An analysis of the\nMajor Discipline, Institute, City and the\nState indicates the trend of research\nactivity in that particular geographical\narea. The results include distribution of\nnumbers of ‘Investigators’, demonstrate\nthe presence of clustering in the\n‘networks’, and highlight a number of\napparent differences in the patterns of\n‘Selected Major Disciplines vis-à-vis\naffiliated Cities’, Top most institutes in\nterms of share of proposals during the\nYear were: All India Institute of\nMedical Sciences (70), Post Graduate\nInstitute of Medical Education and\nResearch (62), CSM Medical University\n(40), Jawaharlal Institute of PostGraduate\nMedical\nEducation\n&amp;\nResearch (22), Indian Institute of\nTechnology (20), Annamalai University\n(19), Manipal Univeristy,(18), Kasturba\nMedical College (16), Amity University\n(13), National Institute of Mental Health\nand Neurosciences (13), Panjab\nUniversity (12), Narayana Medical\nCollege (11), National Institute of\nNutrition (11), Maulana Azad Medical\nCollege (10) and Sanjay Gandhi Post\nGraduate Institute of Medical Sciences\n(10).\nAll the proposals were distributed in a\ntotal of 63 ‘Major Subject Disciplines’.\nThese major disciplines were assigned\non the basis of the ‘Title’ of the research\nproposals submitted by the individual\ninvestigators. Main subject areas\ncovered by Investigators have also been\nanalyzed.\nPercentage\nof\npapers\npublished in top 10 major disciplines\nwas 53.52 for the whole study period\n(Jan.-Dec. 2012). The top 15 major\ndiscipline of the submitted proposals\nwere:\nOncology, Medicinal Plant,\nPharmacology, Nutrition, Microbiology,\nEndocrinology, Nanomedicine , Health\nSystem Research, Virus Disease,\n2078\n\nBioinformatics, Neurological Science,\nCardiovascular Disease, Social &amp;\nBehavioral Research, Maternal Health\nand Cellular &amp; Molecular Biology.\nThe\nGeographical\nLocations\nof\nInstitutes were also analyzed. For the\npurpose the Cities were grouped under\nthree main categories – Big Cities with\nfull infrastructural Facilities, Medium\nCities with developing stage and are upcoming with Institutions and Medical\nColleges the last Category was of\nSmaller Cities, which lack proper\ninfrastructure, funding, access to proper\ninformation etc.\nDuring, the whole period, around 50%\nof the proposals were confined to Bigger\nCities. The 10 topmost Cities were:\nDelhi (174), Chennai (93), Lucknow\n(88), Chandigarh (80), Kolkata ( 48),\nBangaluru (42), Hyderabad (39),\nManipal (36), Pune (34), Puducherry\n(33) and Mumbai with 29 proposals.\nMost of these Cities have contributed\nproposals in selected few areas.\nThe data is being compared with the\ndisease burden to infer that, if the\nresearch activity compliments the\ndisease burden or not. As ICMR is the\napex body for formulation, funding,\ncoordination and management of\nMedical Research in India, this kind of\nconclusive results are very important for\nan ‘Informed Decision Making’ by the\npolicy makers.\nThe main findings from the analysis\nindicate\n There is a distinct relationship\nbetween institutional ‘size and\nstanding’ and the number and\ndistribution of major areas being\nstudied by the investigators from that\nparticular institute. On average,\ninstitutional\nanalysis\nclearly\nindicated\na\nstrong\ninvisible\nrelationship with ‘Major Disciplines\nSelected’ and the size of the\n\ninstitutions\nalong\nwith\nits\ngeographical location.\n A greater proportion of proposals\nfrom smaller institutions than from\nlarger institutions are concentrating\nin the ‘Major Disciplines’ associated\nwith the ‘Diseases &amp; Health Issues’\nprevailing in those particular\ngeographical locations.\nConclusion\nThe participation of the significant\nnumber of the scientists is evidence of a\ncritical mass of researcher working on\nthe related topics. The existence of the\ngroup has been considered as indicators\nof the maturity of research community.\nDue to the researchers&#x27; primary\n\nscientific orientation in their own\ndiscipline, their interests often are\nstrongly related to their specialty.\nResearchers\nand\ninformation\nprofessionals in co-operation with\ndomain specialists are often involved\nhere in the studies of research frontiers;\ntrends, gaps and similarities in research\nefforts at institutional, national, and\ninternational levels. Apart from this,\nthese studies can be useful for science\npolicy also. This is the smallest but\nfinancially the most potent group. Their\nstudies are at the miso- and macro-level\nwhere the national, regional and\ninstitutional structures of science and\ntheir comparative presentation are in the\nforeground.\n\n2079\n\nPAPERS PUBLISHED IN PNAS REFLECT THE\nHIERARCHY OF THE SCIENCES\nDaniele Fanelli1 and Wolfgang Glänzel2\n1\n\ndfanelli@staffmail.ed.ac.uk\nSTIS-The University of Edinburgh, Old Surgeons’ Hall, Edinburgh, EH1 1LZ, UK\n2\n\nWolfgang.Glanzel@econ.kuleuven.be\nCentre for R&amp;D Monitoring (ECOOM) and Dept. MSI, KU Leuven, Leuven, Belgium\nDept. Science Policy &amp; Scientometrics, LHAS, Budapest, Hungary\nIntroduction\nA long-standing controversy surrounds\nthe idea that disciplines form a hierarchy\nin which, moving from physical to\nsocial sciences, studies become on\naverage “softer” (e.g. Cole 1983,\nSimonton 2006). Several studies have\nproposed possible measures of scholarly\nconsensus (e.g. Varga 2011) – a concept\nclosely related to that of scientific\n“hardness”.\nWe recently showed that many such\nconsensus-related parameters support\nthe hierarchy hypothesis, in a large\nrandom sample of papers published in\n12 disciplines (Fanelli and Glänzel 2013,\n2012). This latter study excluded\nmultidisciplinary, high-impact journals\nlike Nature, Science or Proceedings of\nthe National Academy of Sciences\n(PNAS), so we wondered how papers in\nthese latter journals would compare to\nthe rest. In this poster we report\npreliminary results of a comparison with\nPNAS.\nMaterials and Methods\nAnalyses\nreplicated\nexactly\nthe\nprocedure established in previous\nstudies(Fanelli and Glänzel 2013, 2012),\nexcept for how papers were sampled.\nSample\n\n2080\n\nWe searched the PNAS archive for all\npapers classified by the journal in\nmathematics,\nastronomy,\nphysics,\nchemistry,\nbiochemistry,\ngenetics,\nevolution, ecology, plant sciences,\npsychology, economic sciences, political\nsciences, anthropology and social\nsciences. We excluded papers that were\nclassified in more than one category,\nand those that the Web of Science\ndatabase classified as anything other\nthan Article. Astronomy, physics and\nchemistry were grouped as physical\nsciences; genetics and evolution were\nconsidered “hard” biological sciences;\nthe other biological disciplines as “soft”\nbiological sciences; the remaining\ndisciplines were classified as social\nsciences. The final sample consisted of\nN=2,008 papers.\nParameters\nWe measured the following parameters,\nidentified as most relevant by previous\nanalyses (Fanelli and Glänzel 2013, 2012):\n1. Number\nof\nauthors\n(logtransformed)\n2. Length of article (total number of\npages, log-transformed).\n3. Number of references (total number\nof cited references, square-root\ntransformed)\n4. Proportion of cited monographs\n(books were identified by searching\n\neach title and author in GoogleBooks).\n5. Price’s index (calculated on all\nreferences)\n6. Diversity of cited sources (Shannon\ndiversity\nof\njournal\nname,\nconference or book title)\n7. Relative title length (total number\nof words in the title, divided by\nnumber of pages)\n8. First\nperson\nuse\n-singular\n(proportion of singular personal\npronouns – “I”, “my”, etc. – on the\ntotal words in the abstract)\n9. First person use -plural (same as\nabove, but with plural personal\npronouns – “we”, “our”, etc.)\n10. Sharing of references - degree\n(number of other papers with which\nat least one reference is shared,\nmeasured in a bibliographic coupling\nnetwork).\n11. Sharing of references – average\nintensity (average weight of links\nfor each node, measured in the same\nbibliographic coupling network as\nabove).\nAnalysis\nThe number of references shared\nbetween any two papers in the sample\nwas counted by standard bibliographic\ncoupling (Fanelli and Glänzel 2013)\nThe ability of each parameter to predict\nthe hypothesised rank of a paper’s\ndiscipline or domain was tested in a\nmultiple ordinal regression model. In\nanalogy with previous analyses, the\nnumber of references was excluded from\nmain effects, to avoid collinearity, but\nwas retained in the model as a weighting\nfactor.\nResults\nTable 1 reports the main analysis on the\nPNAS sample, Table 2 reports results of\nthe previous study, on specialized\njournals, and values obtained dividing\n\nthe effect size estimates obtained of the\ntwo studies.\nTable 1. Multiple ordinal regression, with\ndomain rank as dependent variable. Bold\nhighlights statistically significant effects\n(P&lt;0.05) [Data sourced from Thomson\nReuters Web of Knowledge]\nPNAS (this study) N=2,008\npredictor\nb±se\nln(n. authors)\n0.039±0.027\nPrice&#x27;s index\n0.123±0.115\nsqrt(Shannon, sources)\n1.963±0.163\nproportion of monographs 4.443±0.224\nln(1+n. pages)\n-0.149±0.119\nln(relative title length)\n0.191±0.053\n1st pers. singular\n-23.31±14.89\n1st pers. plural\n-20.14±7.576\nSingle vs. multi-author\n-0.092±0.078\ndummy\nlog(1+sharing degree)\n0.228±0.018\nlog(1+sharing intensity)\n-0.055±0.052\n1st pers. singular *(sing\n23.39±14.87\nvs. multi author)\n\n1st pers. plural*(sing 18.70±7.5\nvs. multi author)\n7\n\nz\n1.420\n1.071\n12.031\n19.835\n-1.253\n3.612\n-1.565\n-2.659\n-1.178\n12.786\n-1.068\n1.573\n\n2.47\n1\n\nEffect estimates obtained on PNAS\narticles are remarkably similar to those\nobtained previously in specialized\njournals. Moreover, even though the\nsample size was much smaller, the effect\nof most predictors passed formal\nstatistical significance thresholds (0.05).\nThe Shannon-diversity of sources had a\nremarkably stronger effect in PNAS\npapers compared to other journals, but\nin most other cases effects measured in\nthe PNAS sample were weaker, as\nshown by the ratio values in Table 2,\nwhich are mostly smaller than 1. The\neffect of four predictors had opposite\nsign in the PNAS sample: number of\nauthors, Price’s index, length of articles,\nand frequency of use of first person\nsingular. These effects, however, were\nall relatively small and their confidence\nintervals overlapped with zero, so it is\nunclear whether such divergence reflects\ngenuine differences between the two\nsamples rather than just random\n2081\n\nfluctuations. Overall, in any case, the\ndirection and relative magnitude of\neffects measured in the two samples are\nvery similar, as revealed by the high\ncorrelation of their z-scores (Pearson&#x27;s\nr=0.796(95%CI: 0.436-0.936), t = 4.36,\ndf = 11, P = 0.001).\nTable 2 Multiple ordinal regression results\nfrom a previous study on specialised\njournals (Fanelli and Glänzel 2013), and\nratio of regression estimates obtained in\nthe PNAS sample and in the previous\nstudy. Bold highlights effects that have\nopposite sign in the two studies (i.e.\nnegative ratio value). [Data sourced from\nThomson Reuters Web of Knowledge]\nOther journals (previous study)\nb(PNAS)\nN=28,477\n/ b(other)\nPredictor\nb±se\nz\nln(n. authors)\n-0.088±0.01 -9.508\n-0.438\nPrice&#x27;s index\n-0.069±0.03 -2.655\n-1.782\nsq.rt(Shannon,\nsources)\n0.110±0.00 63.688\n17.849\nproportion\n165.22\nmonographs\n7.505±0.05\n3\n0.592\nln(1+n. pages)\n0.596±0.02 30.991\n-0.249\nln(relative title\nlength)\n0.218±0.01 15.561\n0.875\n1st pers. singular 12.32±1.6\n7.854\n-1.892\n1st pers. plural\n-67.44±0.77 -87.429\n0.299\nSingle vs. multiauthor dummy\n-0.303±0.01 -26.895\n0.303\nlog(1+sharing\ndegree)\n0.252±0.00 70.329\n0.904\nlog(1+sharing\nintensity)\n-0.382±0.02 -21.786\n0.145\n1st pers. singular\n*(sing vs. multi\nauthor)\n-17.74±1.57 -11.312\n-1.318\n1st pers.\nplural*(sing vs.\nmulti author)\n41.14±0.76 54.340\n0.454\n\nConclusions\nThese results suggest\npublished\nin\na\n\n2082\n\nthat papers\nhigh-ranking\n\nmultidisciplinary journal like PNAS\nmaintain most bibliometric properties\nhypothesised to reflect levels of\nconsensus and/or “softness”, although\ntheir values are shifted towards those of\n“harder” sciences.\nAcknowledgments\nGoogle-Books kindly increased its\nsearch limits to allow automatic\nsearches. DF was funded by a\nLeverhulme Early-Career fellowship.\nReferences\nCole, S. (1983), The hierarchy of the\nsciences? American Journal of\nSociology, 89(1), 111-139.\nFanelli, D., &amp; Glänzel, W. A\nBibliometric test of the Hierarchy of\nthe Sciences: Preliminary results. In\nIn: Eric Archambault, Yves Gingras\n&amp; Vincent Lariviere (eds.)\nProceedings of the 17th International\nConference on Science and\nTechnology Indicators, Montréal,\nCA, 2012 (pp. 452-453): ScienceMetrix and OST\nFanelli, D., &amp; Glänzel, W. (2013).\nBibliometric evidence for a\nHierarchy of the Sciences. PLoS\nONE, in press.\nSimonton, D.K. (2006), Scientific status\nof disciplines, individuals, and ideas:\nEmpirical analyses of the potential\nimpact of theory. Review of General\nPsychology, 10(2), 98-112.\nVarga, A. V. (2011). Measuring the\nsemantic integrity of scientific fields:\na method and a study of sociology,\neconomics and biophysics.\nScientometrics, 88(1), 163-177,\ndoi:10.1007/s11192-011-0342-9.\n\nA RESEARCH PROFILE FOR A PROMISING\nEMERGING INDUSTRY – NANO-ENABLED DRUG\nDELIVERY\nXiao Zhou,1 Alan L. Porter,2 Douglas K.R. Robinson3 and Ying Guo4\n1\n\nbelinda1214@126.com\nSchool of Management and Economics, Beijing Institute of Technology, Beijing (China)\n2\n\nalan.porter@isye.gatech.edu\nSchool of Public Policy, Georgia Institute of Technology, Atlanta (USA), and\nSearch Technology, Inc., Norcross GA (USA)\n3\n\ndouglas.robinson@teqnode.com\nteQnode Limited, Paris (France), and Université Paris-Est, LATTS-IFRIS, France\n4\n\nviolet7376@gmail.com\nSchool of Management and Economics, Beijing Institute of Technology, Beijing (China)\nBackground\nWith the global emphasis on the\ndevelopment\nof\nnanotechnology\n(“nano”), Nano-Enabled Drug Delivery\n(“NEDD”) systems are rapidly emerging\nas a key nano application area. NEDD\noffers\npromise\nin\naddressing\npharmaceutical industry challenges\nconcerning solubility, cost-reduction,\ndisease &amp; organ targeting, and patent\nlifecycle extension. A combination of\nfactors promotes nanoparticle-enhanced\nand other nano-facilitated drug and gene\ndelivery systems.\nApproach &amp; Research Questions\nPublications and patents can provide\ndifferent (and complementary) insights\nfor the same field of interest. We devise\na multi-component search strategy to\nconstruct an NEDD dataset from the\nWeb of Science (WOS), Medline, and\nthe Derwent Innovation Index (DII).\n\nWe also attempt to address other\nresearch issues, like generating an\ninductive approach to figure out the\nsubsystems; identifying the linkage\namong countries or top organizations;\nseeking the hot topics and estimate their\nfuture prospects. The details can be seen\nin figure 1.\n\nFigure 1. Approach &amp; Research questions\n\nWe advanced a conceptual framework to\napproach NEDD, informed by various\nreviews and “foresight” pieces. This\nled us toward categorization to frame\nour current NEDD search (Table 1).\nTo retrieve a representative set of\nNEDD research records, the terms must\nbe used in combination. We balance\n2083\n\nretrieval (i.e., capturing a high\npercentage of the relevant records) with\nprecision (i.e., without undue noise).\nAfter\nconsiderable\nprobing\nand\nconsultation, we key on two general\nsearch strategies:\n(1) D + P + N; (2) D + T + N.\nWe apply these terms in Web of Science\n(WOS), Medline, and the Derwent\nInnovation Index (DII) . The total results\ncan be seen in Table 2.\n\nFigure 3 shows four subsystems for\nNEDD.\n\nTable 1. Nano-Enabled Drug Delivery:\nRelated Terms\n\nFigure 4 shows the trends for four\nsubsystems.\n\nFigure 3. NEDD Subsystems\n\nFigure 4. Trends for each NEDD\nSubsystem (WOS)\nTable 2. Total NEDD dataset\n\nSubsystems\nWe combine content in title, abstract,\nkeywords (authors) and Keywords Plus\nfields and consolidate term and phrase\nvariations. Drawing upon co-occurrence,\nwe\nuse\nVantagePoint’s\n(www.theVantagePoint.com) Principal\nComponents Analysis (PCA) routine to\ngroup 585 frequently occurring and\ninteresting terms. This factoring (PCA)\nyielded 19 topical groups of related\nterms. Colleagues knowledgeable about\nNEDD helped tune these to 21 major\ntopics.We\nseparate\nfour\nmajor\nsubsystems\nfor\nNEDD:\ndrug,\nnanocarrier, delivery outcome, and\ndisease based on literature study\n(reviews) and text mining results. The\nwe put 21 topics into four subsystems.\n2084\n\nTop Organizations and Leading\nCountries Analysis\nFigure 5 shows similarities among the\n20 top research organizations based on\nrelative emphases on 585 key terms. Ten\nof the top 20 organizations are in the\nUS, with 6 in China. All six Chinese\nresearch organizations form one big\ngroup. CAS is the leader. This group\nfocus on micelles and bio-copolymers.\nUS research organizations can be\ndistinguished into two small groups.\nThey focus gene transfer, DNA and viral\nvector.\nIn\naddition,\nwe\nchoose\nthree\nrepresentative countries or region-China, US and Europe Union(EU) to\ncompare. The total publication trends\nfor them look similar. Figure 6 shows\nthe trends\n\nFigure 5. Cross-relationships among\nOrganizations\n\nFigure 6. The total SCI trends for China,\nUS and EU\n\nHot topics and their future prospects\nThere are four hot topics in recent years:\nRNAi,\nCytotoxicity,\nmagnetic\nnanoparticles, and gold nanoparticles.\nFigure 7 shows the trends. RNAi\nresearch has increased sharply since\n2002. US, China, and Japan lead in this\narea.\nCytotoxicity,\nmagnetic\nnanoparticles, and gold nanoparticles\nincrease sharply from 2007.\n\nAcknowledgements\nThis research draws on support from the\nNational Science Foundation (NSF)\nScience of Science Policy Program –\n“Revealing\nInnovation\nPathways”\n(Award No. 1064146) to Georgia Tech,\nand also NSF support through the\nCenter for Nanotechnology in Society\n(Arizona State University; Award No.\n0531194).\nThe\nfindings\nand\nobservations contained in this paper are\nthose of the authors and do not\nnecessarily reflect the views of the\nNational Science Foundation.\nReference\nZhou, X., Porter, A.L., Robinson,\nD.K.R., and Guo, Y. (2013),\nAnalyzing Research Publication\nPatterns to Gauge Future Innovation\nPathways for Nano-Enabled Drug\nDelivery, Portland International\nConference on Management and\nEngineering Technology (PICMET),\nSan Jose, California, 2013.\nGuo,Y., Zhou, X., Porter, A.L.,\nRobinson, D.K.R. (2013), A\ncomparative analysis of China vs.\nUS: Two important players in the\nNano-enhanced drug Drug delivery\nDelivery (NEDD) Race. Portland\nInternational Conference on\nManagement of Engineering and\nTechnology (PICMET), San Jose,\nCA.\n\nFigure 7. The Developmental Trend for\nHot Topics\n\n2085\n\nTHE P-INDEX: HIRSCH INDEX OF INDIVIDUAL\nPUBLICATIONS\nIstván Papp1, Mária Ercsey-Ravasz2, Dávid Deritei3, Róbert Sumi4, Ferenc JáraiSzabó5, Răzvan V. Florian6, Alexandru I. Căbuz7, Zsolt I. Lázár8\n1\n\nsteve.prst@gmail.com, 2 ercsey.ravasz@phys.ubbcluj.ro, 3deriteidavid@yahoo.com,\n4\nrobert.sumi@phys.ubbcluj.ro, 5ferenc.jarai@phys.ubbcluj.ro,\n8\nzsolt.lazar@phys.ubbcluj.ro\nFaculty of Physics, Babeş-Bolyai University, str. M. Kogălniceanu nr. 1, 400084 ClujNapoca, Romania\n6\n\nflorian@epistemio.com, 7cabuz@epistemio.com\nEpistemio Systems SRL, str. Cireşilor nr. 29, 400487 Cluj-Napoca, Romania\n\nEpistemio LTD, 145-157 St. John Street, London EC1V 4PW, UK\n\nIntroduction\nEvaluation of science is typically\nperformed through peer review by\nexperts in the field. However, evaluation\nis also performed through the use of\nbibliometric indicators, as a complement\nto peer review or as a replacement when\nthere is a lack of resources to perform a\nproper peer review. The journal impact\nfactor, eigenfactor (Bergstrom, West &amp;\nWiseman 2008, Davis 2008), article\ninfluence score (Bollen, Rodriguez &amp;\nVan de Sompel 2006) or h-index\n(Hirsch 2005) are frequently utilized.\nOne of the major shortcomings of these\nindicators is that they are not applicable\nacross different disciplines (Seglen\n1997, Bollen et al. 2009, Davis 2008,\nFersht 2009).\nFor characterizing individual articles the\nmost used indicator is simply the\nnumber of citations. Both the average\nnumber of references per article and the\naverage time needed for an article to be\ncited differ widely between disciplines.\nThis can cause extreme differences in\nthe number of citations received by\narticles in different fields, hampering the\nuse of this indicator for evaluations\n2086\n\nacross domains. Also, the raw number\nof citations does not reflect the quality\nof these citations.\nHere we show that a measure similar to\nthe h-index could be used for the\nevaluation of individual publications.\nWe used a citation network extracted\nfrom a large database of bibliographic\ninformation, including over 11 million\nscientific publications. The nodes of the\nnetwork represent publications and\ndirected links correspond to citations.\nThe publication-level h-index, which we\ncall the p-index, correlates with the\nlogarithm of the number of citations,\nthus reducing the large differences\nbetween domains. We show in seven\nscientific fields that the distribution of\nthe p-index features relatively small\ndifferences between the domains.\nResults\nArticle-level h-index\nThe original Hirsch index (h-index) has\nbeen defined for the evaluation of\nscientists (Hirsch 2005) or scientific\ngroups, such as departments. The hindex of a scientist is the maximal\nnumber h such that he/she has at least h\n\npublications, which have at least h\ncitations each. On Fig.1 we show how\nwe adapted this definition to the case of\nindividual publications. The p-index of a\npublication A is the maximal number p\nsuch that the publication is cited by at\nleast p publications (B,C,D), which have\nat least p citations each. The central\nnode A on Fig. 1 has p-index=3.\nIt is important that when counting the\ncitations of B,C,D,E,F we do not include\ncitations coming from nodes which\nalready cite the main paper A. The link\nCB on Fig.1 is not considered when\ncounting the citations of B. When a\nsmall group of authors cite each other\nvery frequently, the number of citations\nof papers can be large, however the pindex will not increase significantly\nunless their influence goes beyond their\nsmall inner circle.\n\nand 37,616,131 citations at the moment)\nand is unbiased with regard to scientific\ndomain or publication date. The\nidentified links (citations) give us a part\nof the real network, which can be\nconsidered as a random sampling and\ncan already give us information about\nsome statistical properties of the actual\ncitation network. It is not easy to\nidentify scientific domains to which the\npapers belong, because many journals\nare publishing papers from several\ndifferent domains. However, based on\nthe names of journals we identified\nseven smaller subsets of nodes (in total\naround 500,000 papers), which can be\nclearly associated with seven scientific\ndomains: Physics (164,763 papers),\nChemistry (40,173 papers), Engineering\n(38,261), Biology (109,158 papers),\nMedical Sciences (96,013) Mathematics\n(30,014) and Computer Science (2,241).\nOn Fig. 2 we plot the distribution of the\np-index of papers in these seven\ndomains. The probability distribution\nshows an exponential decay and the\ndifferences between distributions for\ndifferent domains are relatively small.\n\nprobability distribution\n\n1\n\nFigure 1. Article A has p-index 3 because\nit is cited by 3 articles (B,C,D) which\nthemselves have at least 3 citations each.\n\nDatabase\nOur database was provided by\nEpistemio (www.epistemio.com) and\nincludes scientific publications as well\nas a subset of their references. This\nsubset is determined by the current\navailability of data (11,010,882 papers\n\nPhysics\nChemistry\nEngineering\nBiology\nMedical Sciences\nMathematics\nComputer Science\n\n0.1\n0.01\n0.001\n0.0001\n1e-05\n1e-06\n0\n\n5\n\n10\n\n15\n\np-index\n\n20\n\n25\n\n30\n\nFigure 2. Probability distribution of the pindex of articles in the 7 different\nsubgraphs associated with scientific\ndomains.\n\nRelation between p-index and number of\ncitations\nThe most used indicator for evaluation\nof articles is the number of citations they\nreceived. In our graph this is given by\n2087\n\nthe p-index could reduce the differences\nin the evaluation of different scientific\nfields, while offering a better estimation\nof the publications’ real impact.\n\nthe in-degree (kin) of the node: the\nnumber of incoming links. On Fig. 3 the\ncolormap shows the correlation between\nthe p-index and number of citations.\nFrom the definition itself it follows that\na large p-index cannot be achieved with\na small number of citations: on Fig. 3\nwe notice a line below which the\nnumber of articles is zero. The reverse,\nhowever, is not true: there are many\narticles having a lot of citations but a\nlow p-index. This might indicate that\narticles farther from that separation line\nhave citation number with less relevance\nto their actual impact.\n100\n\n10\n\n5\n\n80\n\n10\n\n4\n\n60\n\n10\n\n3\n\n10\n\n2\n\nln(kin+1)\n\n5\n4\n3\n\n40\n\n2\n\n0\n\n10\n\n20\n\n1\n0\n\n5\n\n10\n\np-index\n\n0\n\nnr.$of$ar( cles$\n\n7\n6\n\n1\n\n15\n0.6\n\n0.8\n\n1\n\n1.2\n\nFigure 3. The colormap indicates the\nnumber of articles (on log-scale) with a\ngiven p-index and in-degree, kin. Because\nkin changes over several orders of\nmagnitude, the y-axes shows its logarithm.\n\nConclusion\nWe have shown how the h-index can be\nadapted\nto\nevaluate\nindividual\npublications. We used a citation network\nextracted from a large database to\ncompute the p-index, an indicator that\nreflects not only the number of citations\nreceived by a paper but also their\nquality. While our database needs to be\nfurther improved the statistical results\nare already promising, indicating that\n\n2088\n\nAcknowledgments\nThis work was supported by a grant of\nthe Romanian National Authority for\nScientific Research, CNDI–UEFISCDI,\nproject number PN-II-PT-PCCA-20113.2-0895.\n\n1.4\n\nReferences\nBergstrom, C.T., West, J.D. &amp;\nWiseman, M.A. (2008). The\neigenfactor metrics. J. of\nNeuroscience, 28, 11433-11434.\nBollen, J., Rodriguez, M.A. &amp; Van de\nSompel, H. (2006). Journal status.\nScientometrics, 69, 669-687.\nBollen, J., Van de Sompel, H., Hagberg\nA. &amp; Chute, R. (2009) A Principal\nComponent Analysis of 39 Scientific\nImpact Measures. PLoS ONE, 4,\ne6022.\nDavis, P.M. (2008). Eigenfactor: Does\nthe Principle of Repeated\nImprovement Results in Better\nEstimates than Raw Citation Counts.\nJASIST, 59, 2186-2188.\nFersht, A. (2009) The most influential\njournals: impact factor and\neigenfactor. PNAS, 106, 6883-6884.\nHirsch, J.E. (2005). An index to\nquantify an inidividual’s scientific\nresearch output. PNAS, 102, 1656916572\nSeglen, P.O. (1997). Why the impact\nfactor of journals should not be used\nfor evaluating research. BMJ, 314,\n498-502.\n1.6\n\n1.8\n\n2\n\nPRELIMINARY ANALYSIS OF THE FINANCIAL\nASSISTANCE TO NON-ICMR BIOMEDICAL\nSCIENTISTS BY INDIAN COUNCIL OF MEDICAL\nRESEARCH (ICMR)\nSandhya Diwakar1 and Keshari K. Singh2\n1\n\nsandhyadiwakar@gmail.com, 2 singhkeshari@yahoo.com\nIndian Council of Medical Research, Ansari Nagar, New Delhi - 110029 (India)\nIntroduction\nHealth research is the key to a wellfunctioning and effective health sector\nin the country. Major scientific\nbreakthroughs hold the promise for\nmore effective prevention, management\nand treatment for an array of critical\nhealth problems. The research to be\nundertaken should be on country\nspecific health problems essential for the\nformulation of sound policies and plans\nfor field action. Medical research in the\ncountry needs to be focused on new\ntherapeutic drugs/vaccines for tropical\ndiseases, normally neglected by\nmultinational pharmaceutical companies\non account of their limited profitability\npotential. In the Government sector,\nsuch research has been confined to the\nresearch institutions under the Indian\nCouncil of Medical Research, and other\ninstitutions funded by the Central/ State\nGovernments.\nSince its establishment, the ICMR has\nbeen making concerted efforts to\naddress the health needs of the nation.\nThe Council has discharged its national\nobligations through its network of 31\nnational institutes including Six regional\nmedical research centres, over 100 field\nstations and a strong and vibrant\nextramural research in medical colleges\nand other institutes.\n\nTo provide an opportunity to academic\nscientists and trainees and to provide a\nstimulus for those working or\ncontemplating working in the field of\nmedical science, ICMR initiated an\nInternational Travel Grants Program in\n2009 for Indian scientists to participate\nin international conferences, seminars,\nworkshops and symposiums. The\napplicants should be Bio-medical\nscientist engaged in R&amp;D work. Senior\nScientists (above 35 yrs of age) working\nin academic institutions and research\nlaboratories and young scientists (below\n35 yrs of age) including medical\ngraduates, post-graduates and research\nscholars are eligible to apply to\ninternational scientific events.\nThe budget sanctioned for the program\nwas INR 3.0 Crores (about USD 550K),\nout of which the amount disbursed was\nINR 2.60 Crores (about USD 500K).\nDuring that period 1505 travel grant\napplications were received out of which\n771 applications were approved for\nfunding and 420 applicants finally\navailed the grant. Travel grants went to\nindividuals at many institutions in the\ncountry and provided support for a wide\nrange of biomedical research activities.\nAn outcomes survey can be conducted\nto enhance the overall value and utility\nof the travel grant program.\n\n2089\n\nMethodology\nData for the three year period during\n2009-2012 was collected. Data points\nincluded name of the scientist,\ninstitution, designation, age, gender,\nstate, conference title, venue, area of\nmedical\nscience,\namount\nsanctioned/released and whether the\napplication was approved, availed or\nrejected. The collated data was studied\nto identify the distribution of\napplications by state, area of medicine,\ndesignation;\ninstitution\netc\nand\ninferences have been drawn from the\nstudy.\nObservations\nZone-wise Status\nA zone-wise analysis indicates that\nNorth Zone is the most active with\nhighest number of applications for\ngrants received, approved and availed.\n\nFigure 1. Zone wise distribution of\napplications received, approved, availed\n\nNew Delhi led all other states in terms\nof the applications submitted with a\nmaximum number of 422. Karnataka\nranked second with the 191 applications\nsubmitted followed by Uttar Pradesh\n(182), Tamil Nadu (120), Maharashtra\n(113) and Union territory of Chandigarh\n(106). These states accounted for threefourth of the total applications received\nby ICMR.\n\n2090\n\nLeading Research Institutions\nPresence of top institutions in the states\nmay explain why the some states have\nled other states. New Delhi is home to\nAll India Institute of Medical Sciences\n(AIIMS), Maulana Azad Medical\nCollege, Jawaharlal Nehru University.\nNational Institute of Mental Health and\nNeurosciences (NIMHANS) and Indian\nInstitute of Science (IISc) are based in\nBangalore in the southern state of\nKarnataka while Banaras Hindu\nUniversity (BHU) is in the northern\nstate of Uttar Pradesh. These institutions\nare amongst the top-tier research\ninstitutions of India. Further, out of the\napplicants who availed grants, those\nfrom AIIMS had a share of 14.8%\nfollowed by PGIMER, Chandigarh and\nNIMHANS, Bangalore at 7.1% each.\n\nFigure 2. Top 10 institutes which availed\ngrants, Total availed grants = 420\n\nResearch Areas\nIn terms of the bio-medical science\ndiscipline, it was noted that the\napplications were received in wide range\nof areas such as pneumonia, molecular\noncology, cardiology, asthma, AIDs and\nso on. There were 206 unique areas\nunder which scientists had submitted\napplications of which Oncology\nemerged as the top-most area for which\nthis scheme was availed followed by\nDrug Development and Pharmacology.\n\nFigure 3. Top 16 research areas of availed\nscheme grants\n\nResearchers Profile\nDesignation-wise analysis of the\napplicants who availed travel grants\nshows that the Research Fellows (JRFSRF) had the highest share of 40.2%.\nThe other major section of researchers\nbenefitted from the scheme was that of\nAssistant Professors, which accounted\nfor 10.3% of the availed grants.\n\nFigure 4. Designation-wise breakup of\navailed applications\n\nSummary\nSome general insights based on the\nsample data during the period 20092012 shows that out of the 420 selected\nproposals:\n New Delhi led all other states in\nterms of the applications submitted\n(422) and grants availed (133)\nfollowed by Karnataka with 191\n\napplications submitted and 60\navailed.\n AIIMS led the institutions availing\ngrants and had a share of 14.8%\nfollowed by PGIMER, Chandigarh\nand NIMHANS, Bangalore at 7.1%\neach.\n Oncology emerged as the top-most\narea for which this scheme was\navailed\nfollowed\nby\nDrug\nDevelopment and Pharmacology\n The Research Fellows (JRF-SRF)\nhad the highest share of 40.3%\nfollowed by Assistant Professors\nwho accounted for 10.3% of the\navailed grants.\nFuture directions\n Comparison of ICMR’s funding\nprogram with similar programmes by\nother agencies domestically and\ninternationally.\n Study Indian disease burden vis-avis financial support given to\nresearchers for health research and\ncollaboration.\nReferences\nReport of the Working Group on Health\nResearch for XII Five Year Plan\n(September 2011). Department of\nHealth Research and Family\nWelfare, 1-2.\nBurroughs Wellcome Fund,\nwww.bwfund.org\nNational Commission on\nMacroeconomic and Health\nHealth Information of India\n2004,Government of India, Central\nBureau of Health Intelligence,\nDGHS, MOH &amp; FW, Nirman\nBhavan, New Delhi-11 website:\nwww.cbhidghs.nic.in\n\n2091\n\nTHE PRODUCTIVITY AND IMPACT OF\nASTRONOMICAL TELESCOPES – A\nBIBLIOMETRIC STUDY FOR 2007 – 2011\nDennis R. Crabtree\nDennis.Crabtree@nrc-cnrc.gc.ca\nNational Research Council Canada, 5071 West Saanich Road, Victoria, BC (Canada)\nIntroduction\nSince the telescope was invented in the\nearly 17th century, astronomers have\nrelied on increasingly complex and\nexpensive instruments to further their\nstudies of the Universe. The next\ngeneration of telescopes, with apertures\nof approximately 30-m, will cost more\nthan $1B to construct.\nThe main\nproduct of modern observatories are the\npublications in refereed journals based\non\ndata\nobtained\nusing\ntheir\ntelescope(s).\nIncreasingly, bibliometric techniques are\nbeing applied to the refereed papers\nproduced by modern observatories.\nObservatory\ndirectors\nstudiously\ncompare their telescopes’ performance\nwith that of similar telescopes and the\nfunding agencies anxiously wait for the\nreturn on their massive investment in\nthese expensive facilities.\nIn this paper I will examine and\ncompare the productivity and impact of\neighteen telescopes using the basic\nbibliometric tools of paper and citation\ncounts.\nInput Data\nObservatories carefully track the\nrefereed papers that utilize data from\ntheir telescopes. Most observatories\npublish their list of observatory\npublications on the Web. The input data\n2092\n\nfor this study is comprised of the list of\nobservatory publications for nineteen of\nthe largest optical/sub-mm telescopes\nused for astronomical research. The lists\nof papers published between 2007 and\n2011 were gathered from the Web in\nmost cases, but for some telescopes the\nlists were sent to me by observatory\nstaff. These lists were incorporated into\na custom designed Microsoft Access\ndatabase/\nBibliometric Data\nThe international astronomy community\nis fortunate to have access to the NASA\nAstrophysics Data System (NASA\nADS) (Kurtz, et al. 2000). The ADS\nprovides bibliometric information that is\nused by all professional astronomers.\nThe NASA ADS database includes full\npublication information for each article\n(title, authors, journal, volume, page and\nyear), as well as current citation counts.\nEach article in the system is assigned a\nunique bibliometric identifier (bibcode).\nThis bibcode can be used to extract all\nthe relevant information on that article\nfrom the ADS database.\nFor the work described in this paper, the\ncorrect bibcode was generated for each\nobservatory publication and then the\nNASA ADS was queried to extract the\npublication information and the number\nof citations for that paper.\n\nProductivity\nThe productivity of a telescope is the\nnumber of refereed papers published\nduring a certain time period. Figure 1\nshows the total publications per\ntelescope for the 2007-2011 period. One\ncan see that the productivity varies\nsignificantly between the telescopes.\nThe main reason for the very low\nproductivity of the LBT is that it only\nrecently began operations and it takes up\nto 10 years of operation for a telescope\nto achieve full productivity (Crabtree\nand Bryson 2001)\n\nFigure 1. The total number of refereed\npapers published per telescope for the\nperiod 2007-2011\n\nImpact\nCitation counts are the most frequently\nused metric for measuring the impact, or\nrelevance, of a refereed publication. A\npublication gathers citations over time\nso one can’t really compare the raw\ncitation counts of a paper published in\n2007 with one published in 2011.\nOne approach to addressing this\nproblem is to normalize the raw citation\ncounts by a standard measure that\nincreases with time similar to raw\ncitation counts. I have used the citation\ncount of the median paper published in\nthe Astronomical Journal (AJ) as a\nstandard measuring stick to normalize\nthe raw citation counts. If there are 301\npapers published in a given year, then\nthe citation count of the 150th paper\n\n(ranked in descending citation count\norder) is the normalization factor all\npapers published in that year, regardless\nof the journal in which they are\npublished.\nI define the impact of a paper to be the\nnumber of citations to that paper divided\nby the citation count of the median AJ\npaper as defined above. This approach is\nvery successful and allows papers of\ndifferent publication years to be\ncompared, and to compute aggregate\nimpact metrics of papers published over\na range of years.\nOne important measure of performance\nof a telescope’s publications is the\naverage impact per paper (AIPP). Since\nthe impact distribution of a telescope’s\npaper is very non-normal (very long\nhigh-impact tail), the median impact per\npaper (MIPP) is also of interest. The\ndifference of these two metrics between\nthe telescopes is a good measure of the\nrelative impact performance.\n\nFigure 2. AIPP and MIPP of each\ntelescope for the period 2007-2011\n\nThe AIPP and MIPP are shown in\nFigure 2 and the AIPP is significantly\nhigher than the MIPP due to long tail of\nvery high impact papers. The AIPP\ndiffers by a factor of approximately two\nbetween\nthe\nlower\nperforming\ntelescopes and the higher performing\nones.\n\n2093\n\nA truly high performing telescope will\ncombine high productively and a high\naverage impact per paper, which is\nequivalent to a high total impact. The\ntotal impact of telescope’s papers is\nsimply the sum of the impacts of all the\nindividual impacts of the papers\npublished using data from that\ntelescope.\nThe total impact of each telescope is\ndisplayed in Figure 3. The best\nperforming telescope, Keck, combines a\nvery high productivity with a very high\nAIPP. While the HET has the highest\nAIPP its low productivity means that it\nis one of the lowest performers.\n\nFigure 3. Total impact of each telescope\nfor the period 2007-2011\n\n2094\n\nConclusions\nA standard bibliometric approach\nprovides a good measure of the\ncomparative performance of modern\ntelescopes. Normalizing the raw citation\ncounts of papers to a standard measuring\nrod provides an age independent metric\nthat can be used to compare publications\nof different ages. This approach should\nbe used in any study that utilizes\nbibliometrics to study publications over\na range of years.\nAcknowledgments\nThis research has made use of NASA&#x27;s\nAstrophysics Data System..\nReferences\nCrabtree, D.R. &amp; Bryson, E.P. (2001).\nThe Effectiveness of the CanadaFrance-Hawaii Telescope. The\nJournal of the Royal Astronomical\nSociety of Canada, 95, 259-265.\nKurtz, M.J., Eichhorn, G., Accomazzi,\nA., Grant, C.S., Murray, S.S.,\nWatson, J.M. (2000). The NASA\nAstrophysics Data System\nOverview. Astronomy and\nAstrophysics, 143, 41-59.\n\nPROFILES OF PRODUCTION, IMPACT,\nVISIBILITY AND COLLABORATION OF THE\nSPANISH UNIVERSITY SYSTEM IN SOCIAL\nSCIENCES AND HUMANITIES\nDaniela De Filippo1; Carlos García-Zorita2; Sergio Marugan3 and Elías SanzCasado4\n1\n\ndfilippo@bib.uc3m.es; 2 czorita@bib.uc3m.es; 3smarugan@pa.uc3m.es;\n4\nelias@bib.uc3m.es\nDepartment of Library and Information Sciences, Carlos III University of Madrid, 126\nMadrid Street, Getafe 28903, Madrid(Spain)\nIntroduction\nDespite the widespread use of\ninternational databases, the scarcity of\npublications from non-English speaking\ncountries, as well as the lack of journals\nin Social Sciences and Humanities, has\nbeen highly criticized (Gómez and\nBordons: 1996). This situation has\ncreated an absence of information on a\nproduction sector that is gradually\ngaining more and more visibility.\nBetween 2002 and 2011, Spanish\npublications in WoS increased from\n30,088\nto\n61,364\ndocuments,\nrepresenting a 203% increase. In the\nsame period, Spanish publications in\nSocial Sciences and Humanities\nincreased from a 7% of the country&#x27;s\ntotal production to 15%, constituting an\noverall growth of 397,9%.\nThese data show the increasing\nsignificance of publications within these\ndisciplines in WoS. This reality may be\ndue either to the implementation of a\nspecific dissemination strategy by\nresearchers in order to increase their\nvisibility, or to the fact that the\nrequirements from the assessment\nagencies focus on the relevance of\npapers as key elements within the\nevaluation process..\n\nFurther evidence of the increasing\nvisibility of these disciplines in WoS is\nshown by the number of journals. JCR\ndata show that, in 2002, Spain had 26\nSCI journals and only 2 SSCI journals,\nwhile in 2011 there were 78 SCI\njournals and 55 SSCI journals.\nThis increase can also be seen as a result\nof both the application of different\nprojects such as REHS; MIAR and INRECs, which aim at analyzing and\nimproving the quality of Spanish\njournals, and the efforts carry out by the\npublishers of Spanish journals to meet\nthe requirements of international\ndatabases (Gimenez-Toledo: 2011).\nTo analyze in detail the evolution of\nSpanish publications in the Social\nSciences and Humanities, we will study\nthe production of the university system,\nwhich represents 67% of Spain’s overall\nproduction. The main aims are:\n- To identify activity profiles in these\nareas in terms of production,\nproductivity, visibility, impact and\ncollaboration.\n- To analyze the annual evolution of\neach indicator.\n- To compare the relationship between\nthe intensity of activity in these areas\nand the specialization for each\nuniversity.\n\n2095\n\n-\n\nTo analyze activity profiles in these\nareas vs. those defining the Spanish\nUniversity\nSystem’s\ntotal\nproduction.\n\nSources and Methodology\nData from the IUNE Observatory were\nused as source (Sanz-Casado et al:\n2011). This Observatory (created for our\nresearch team) presents 42 indicators\ngrouped in 6 dimensions with the aim of\nanalyzing the activity of the Spanish\nUniversity System (www.iune.es). In its\ncurrent\nversion,\nit\nprovides\ndisaggregated data by scientific areas.\nThe assignment of areas was carried out\ntaking into account the WoS disciplinary\nclassification of the journals, which\nhave been grouped into six broad areas:\nArts and Humanities; Life Sciences;\nExperimental Sciences; Architecture,\nEngineering and Computing; Medicine\nand Pharmacy and Social Sciences.\nPublications from 49 public universities\nand 25 private institutions were\nidentified through the use of a\nstandardized normalization system,\nwhich has been developed by the\nLaboratory of Metrics Studies of\nInformation (LEMI).\nScientific production from the Spanish\nUniversity System for the period 20022011 was obtained. The following\nindicators for Social Sciences and\nHumanities versus the total System were\ncalculated:\n- Annual evolution of the number of\npublications.\n- Publications per university.\n- Annual evolution of the coauthorship rate.\n- Annual\nevolution\nof\nthe\ncollaboration profiles.\n- Citations received per university.\n- Percentage of non-cited documents.\n- Percentage of documents in Q1.\n- Percentage of documents in TOP3\njournals.\n2096\n\nResults\nBetween 2002 and 2011, the Spanish\nUniversity System has shown an\nimportant increase, from just over\n20,000 publications in Web of Science\nto 41316. The area with the highest\nproduction was Experimental Science\nwith 40% of the total (Fig.1).\n\nFigure 1. Distribution of Spanish\nUniversities’ Publications by Thematic\nArea\n\nThe data show that in the period being\nanalyzed, the Spanish university system\nhas had a total increase of 203% in its\nnumber of publications (similar to that\nof the entire country. Despite the fact\nthat the area of Experimental Sci. has a\nhigher production in absolute values, the\ngreatest increase has taken place in the\nareas of Social Sci. and Humanities,\nwith 274% and 227% respectively (Fig\n2).\n\nFigure 2. Annual Evolution of the Number\nof Publications in the Spanish University\nSystem by Thematic Areas\n\nThe production within the area of Social\nSciences represents, on average, 11.4%\nof all Spanish universities’ publications,\nwhile documents within the field of\nHumanities reach 5.2%. Figure 3 shows\nthe distribution of production in each\narea for the 10 universities with the\nlargest volume of documents. In these\ninstitutions,\nthe\npercentage\nof\npublications in the Social Sciences and\nHumanities is lower than the system’s\naverage, as other smaller universities are\nthe most important in these fields. At\ninstitutional level, the most relevant\nuniversities in the field of Social\nSciences are: the National Distance\nEducation University; Pablo Olavide\nUniversity; Carlos III University of\nMadrid and Pompeu Fabra University\nwith more than 20% of their total\nproduction. The most productive in\nHumanities are the National Distance\nEducation University, the Complutense\nUniversity of Madrid, Salamanca\nUniversity and Alcala de Henares\nUniversity.\n\nOn the contrary, the percentage of non\ncited documents is higher than the area\naverage, particularly in Humanities.\nTaking into account indicators such as\nthe collaboration profile, the Social\nSciences show similar values to all\nareas, although Humanities have a\ndifferent behavior than the rest of\ndisciplines (Table 1).\nTable 1. Activity Profiles in Social\nSciences and Humanities versus All Areas\nIndicator\nAll areas\n% Domestic\nCollaboration\n% International\nCollaboration\nHumanities\n% Domestic\nCollaboration\n% International\nCollaboration\nSocial Sciences\n% Domestic\nCollaboration\n% International\nCollaboration\n\n2002\n\n2011\n\nIncrease\n\n29.5\n\n34.30\n\n16.27\n\n34.2\n\n39.80\n\n16.37\n\n19.34\n\n22.55\n\n16.60\n\n16.38\n\n24.09\n\n47.07\n\n30.72\n\n32.02\n\n4.23\n\n28.79\n\n32.14\n\n11.64\n\nDiscussion\nThroughout this paper, we show in\ndetail each of the indicators analyzed.\nThe activity profiles for each institution\nwill be defined accordingly.\n\nFigure 3. Distribution of Publications by\nThematic Area in the Top10 Universities.\n\nIn the Spanish University System, the\nco-authorship rate was on average 5.3\nauthor/doc in 2002, while it went up to\n15.54 author/doc in 2011. However,\nthese values are lower for the production\nlevels in the Social Sciences and\nHumanities. The situation is the same in\nthe case of documents in the first Quartil\nand for documents in the TOP3 journals.\n\nReferences\nGiménez Toledo, E (2011). The Opinion\nof the Experts About Spanish\nCommunication Journals and Other\nQuality Indicators. First National\nConvention on Communication\nResearch Methodology (AE-IC and\nRey Juan Carlos University).\nFuenlabrada (Madrid), april 13th and\n14th.\nGómez, I. and Bordons, M. (1996).\nLimitations in the Use of\nBibliometric Indicators for Scientific\nEvaluation. Política Científica, 46:\n21-16\n2097\n\nSanz Casado, E; De Filippo, D; García\nZorita, C; Efraín-García, P. (2011).\nThe IUNE Observatory: A New Tool\nfor the Evaluation of Research\n\n2098\n\nActivity within the Spanish\nUniversity System. Revista\nBORDON, 63 (2): 101-115\n\nPROTOTYPICAL STRATEGY FOR HIGH-LEVEL\nCITATION-ANALYSES: A CASE STUDY ON THE\nRECEPTION OF ENGLISH-LANGUAGE JOURNAL\nARTICLES FROM PSYCHOLOGY IN THE\nGERMAN-SPEAKING COUNTRIES\nGünter Krampen1, Gabriel Schui2 and Hans P.W. Bauer3\n1\n\nkrampen@uni-trier.de\nLeibniz Institute for Psychology Information and Documentation (ZPID) and University\nof Trier, Department of Psychology, D 54286 Trier (Germany)\n2\n\nschui@zpid.de\nLeibniz Institute for Psychology Information and Documentation (ZPID), D 54286 Trier\n(Germany)\n3\n\nbauer@zpid.de\nLeibniz Institute for Psychology Information and Documentation (ZPID), D 54286 Trier\n(Germany)\n1 Introduction\nThe Web of Sciences (WoS) is\nfrequently and increasingly used in\nevaluations of scientific productivity\nand of the international reception of\npublications (Garfield, 1979). However,\ncitation-analyses done with this database\nare sensitive to problems and some\ndangers of misinterpretations, which\nresult from the features of this database.\nSome of these problems refer to the\nlimited representation of journal\npublications (because not all journals are\ndocumented in the WoS) and to name\nhomonymy, i.e., identical names of\ndifferent authors. Therefore, firstly,\nhigh-level citation-analyses should test\nthe completeness of the papers\ndocumented in the WoS, secondly,\ncitation-analyses must be implemented\npublication-based and not name-based.\nA prototypical strategy for high-level\ncitation-analyses\nconsidering\nand\nomitting both problems is presented in\n\nthe following. The analyses refer to a\ncase study on the international reception\nof English-language journal publications\nfrom psychology in the Germanspeaking countries (Austria, Germany,\nparts of Switzerland), which were\npublished in three decades, 1981-2010.\nThis prototypical strategy of citationanalysis includes five steps of data\ngathering, data management (including\ncorrection of data defects), and data\nanalyses.\n2 Five Steps of Data Gathering and\nData Management\nFirst Step: Identification of all Relevant\nPublications\nFor the identification of all relevant\nEnglish-language journal publications\nfrom psychology in the Germanspeaking countries the exhaustive\ndatabase for psychology publications\nfrom the German-speaking countries\n\n2099\n\nPSYNDEX\nis\nused\n(http://psyndexdirect.zpid.de).\nThe source database PSYNDEXE\nincludes in total 28,845 documentations\nof English-language psychology journal\narticles from the German-speaking\ncountries for the publication years 19772011. PSYNDEX and STAR Record\nidentification number (ID), author(s),\npublication year, title of the paper and of\nthe\njournal,\nISSN,\nvolume,\npages/number of paper, and DOI are\nregistered for each of these articles.\nEight faulty documentations in the\ndatabase were eliminated (six doublets\nand two not identifiable documents),\nwhich led to a total of 28,837 articles.\nSecond\nStep:\nAssignment\nof\nPublications to WoS-UTs\nTo assure high precision the bijective\nassignments of PSYNDEX-IDs to WoSUTs were carried out in three ways\nusing the APIs of the WoS. Firstly, a\nquery (API of the WoS Web Services,\nL1.02)\nincluding\nauthor\nnames,\npublication year, and the three longest\nwords of the title, resulted in the\nidentification of 24,374 WoS-UTs of the\n28,837\nPSYNDEX-IDs\n(84,5%).\nSecondly, a query (WoS Links Article\nMatch Retrieval, 1.4) including ISSN,\nvolume and first page number or article\nnumber or author names resulted in the\nidentification of 22,459 WoS-UTs\n(77,9%). Thirdly, the search for DOIs\n(documented in PSYNDEX) in the WoS\nresulted in 9,396 bijective assignments\nto WoS-UTs (32,6%). Different WoSUTs were registered for 41 articles at\nleast in two of the three assignment\nstrategies. These cases were corrected\nmanually without any problem. The\nsmall number of such assignment\nproblems (0,2%) confirms the high\nreliability of the assignments by crossvalidation.\n\n2100\n\nTo sum up, bijective (one-to-one)\nassignments to WoS-UTs were possible\nfor 25,747 papers documented in\nPSYNDEX. This results in a WoS\ncoverage of English-language journal\npublications from psychology in the\nGerman-speaking countries of 89,3%.\nThus, approximately 10% of the articles\ndocumented\nin\nPSYNDEX\nare\nunconsidered in the WoS.\nThird Step: General Citation-Analysis\nOn the basis of the WoS-UTs distinct\ncitation frequencies of the 25,747\narticles were gathered (July, 2012).\nCitation-Analyses referred to WoS\nsegments SCI-E and SSCI, which\nallow—in the next step—analyses of\ncitations per year (Garfield, 1979).\nFourth Step: Analyses of Citations per\nYear\nFrequencies of citations per year were\ndetermined for all publications using\nWoS Web Services API. In addition to\nthe registration of all citations received,\nthe numbers of self-citations of authors\nwere determined. This is significant\nbecause the number of self-citations\nvaries strongly, i.e., it ranges from 0%\nup to 100%.\nFifth Step: Analyses of Features of the\nArticles Receiving Citations by Others\nTo get information about some\ncharacteristics\nof\nhighly\nversus\nmoderately versus rarely or not at all\ncited journal articles formal features of\nall 25,747 articles included in citationanalyses were determined with reference\nto PSYNDEX. These features include\nthe sub-discipline of psychology,\ndescriptors, and study type (e.g.,\nmethodological\nstudy,\nempirical/experimental\nstudy,\ntheoretical study, literature review,\noverview etc.).\n\n3 Results\nResults refer to the English-language\njournal articles from psychology in the\nGerman-speaking countries, which were\npublished between 1981 and 2010.\nPSYNDEX includes 28,388 article\ndocumentations for these three decades.\nBijective (one-to-one) assignments to\nWoS-UTs were possible for 25,461 of\nthe papers documented in PSYNDEX\n(89,7%). This points at the fact that\nWoS coverage of English-language\njournal publications from psychology in\nthe German-speaking countries is\nrelatively satisfying, but not exhaustive.\nApproximately 10% of the articles are\nnot considered in the WoS and therefore\nare excluded completely from citationanalyses. This can cause distinct biases\nin evaluations of the reception of the\npublications of authors and institutions.\nThe distributions of the absolute\nfrequencies of citations of articles and of\nthe frequencies of citations per year are\nstrongly skewed to the right and\nresemble Pareto probability functions\n(Bauer et al., 2013; Seglen, 1992). Fiveyear impact factors (IF) increase\ncontinuously from 1980ties (IF = 1) to\n2010 (IF = 3,5). This increase is\nobserved for the reception of journal\narticles in all psychological subdisciplines. However, the slope is\ndifferent between the sub-disciplines\nbeing most steeply for neuropsychology\nand biopsychology.\nSelf-citations range between 0% and\n100%. On average there are 17% selfcitations with a slight decrease from the\n1980ties (20%) to 2010 (16%).\nHighest citation frequencies are\nregistered on average for journal\npublications in clinical psychology and\ncognitive (experimental) psychology. It\nmust be considered that both subdisciplines are comparably large\nresearch community giving authors a\ngreater chance of being cited.\n\nHighest citation frequencies are\nregistered on average for literature\nreviews and overviews, less for\nempirical and experimental studies, and\nfewest for methodological studies.\n4 Conclusions\nWoS coverage of English-language\njournal publication from psychological\nresearch in the German-speaking\ncountries is relatively satisfying, but\ncertainly not exhaustive. Approximately\n10% of the publications are not included\nin the WoS, which can cause a serious\nselection bias in evaluative applications\nof citation-analyses.\nCitation frequencies and five-year\nimpact factors increase continuously\nfrom the 1980ties to 2010 showing\ndistinct differences between the subdisciplines of psychology. This is\nconnected to the size of the research\ncommunity in the sub-discipline.\nSelf-citations should be generally\nomitted in citation-analyses because of\nthe large differences between authors\nand between publication years.\nLiterature reviews and overviews\nreceive—on\naverage—the\nhighest\ncitation numbers, empirical studies less,\nand methodological studies the lowest.\nReferences\nBauer, H. P. W. Schui, G., von Eye, A.,\n&amp; Krampen, G. (2013). How does\nscientific success relate to individual\nand organizational characteristics?\nScientometrics, 94, 523-539.\nGarfield, E. (1979). Citation indexing:\nIts theory and application in science,\ntechnology, and humanities. New\nYork: Sage.\nSeglen, P. O. (1992). The skewness of\nscience. Journal of the American\nSociety for Information Science, 43,\n628-638.\n\n2101\n\nA QUANTITATIVE ANALYSIS OF ANTARCTIC\nRELATED ARTICLES IN HUMANITIES AND\nSOCIAL SCIENCES APPEARING IN THE WORLD\nCORE JOURNALS\nWeina Hua1 and Yu Li2\n1\n\nhuawn@nju.edu.cn\nSchool of Information Management,Nanjing University, Nanjing 210093 (P. R. China)\n2\n\nbaihe2010801@163.com\nSchool of Information Management,Nanjing University, Nanjing 210093 (P. R. China)\nIntroduction\nThe end of the earth south is the South\nPole, Antarctica. As an underdeveloped,\nuncontaminated\nclean\ncontinent, it is the only natural\nlaboratory for scientific research. Now,\nthere are 100 and more Antarctic\nStations established by more than 40\ncountries carrying out multi-disciplinary\ninvestigation, like life sciences, earth\nsciences, marine science, physic. Thus,\nit is of importance to have a good idea\nof the academic situation of Antarctic\nrelated research. In this contribution we\nfocus on research in the humanities and\nsocial sciences, such as political\nsciences, geography and economics.\nMethodology\nAntarctic research focusing on the\nhumanities and social sciences covers\nmany disciplines. In order to have a\nbetter understanding and to evaluate the\ntypes of Antarctic research historically\nand to see current trends, a detailed\nanalysis of Antarctic related articles\nappearing in the world core journals\npublished between 1900-2011 was\nmade. The data originate from the SSCI\n(Social Sciences Citation Index) and the\nA&amp;HCI (Art &amp; Humanities Citation\n2102\n\nIndex), subfiles of the Web of Science\n(referred to WoS), collected from\ndifferent aspects. Data was gathered by\nsearching for Antarctic related subject\nheadings in the title field including\nvariant names such as Antarctic or\nSouth Pole or subantarctic. Antarctic\nPolar Regions such as King George\nIsland, Alexander Island, Victoria Land,\nSouth George Island, Wedell Sea, Ross\nSea. The names of Antarctic Stations\nsuch as McMurdo, Mawson, Halley\nwere also included and organizations\ntitled with Antarctica or South Pole\nwere also in searching process. Search\noperators “and” ”or” “not” were used in\nthe main search strategy. The study\ncovers the time period from 18982012185. Data collection work ended on\n1st of March 2013. After manual\nadjustment we got a total of 2121 hits.\nYearly Published Papers\nThe earliest papers in the world core\njournals relating to Antarctic retrieved\nfrom SSCI and A&amp;HCI dated back to\n1900. 2121 papers have been found out\n185\n\nThe database chosen for this research\ncovers the data retrospectively from early\n1898, but the data meeting the topics of this\npaper begins from 1900.\n\nfrom 1900 to 2012 on Antarctic research\nin humanities and social sciences. The\ndata in details are shown in Table 1.\nTable 1. Number of articles each year\nYear\n2012\n2011\n2010\n2009\n2008\n2007\n2006\n2005\n2004\n2003\n2002\n2001\n2000\n1999\n1998\n1997\n1996\n1995\n1994\n1993\n1992\n1991\n1990\n1989\n1988\n1987\n1986\n1985\n1984\n1954\n1953\n1952\n1951\n1950\n1949\n1948\n1947\n1946\n1945\n1944\n1943\n1942\n1941\n1940\n\nNo. of\narticles\n45\n37\n39\n27\n45\n37\n31\n25\n27\n23\n27\n37\n44\n28\n25\n16\n28\n27\n46\n34\n26\n40\n48\n48\n38\n34\n47\n37\n49\n10\n5\n10\n4\n10\n2\n8\n8\n1\n2\n4\n3\n1\n4\n12\n\nYear\n1983\n1982\n1981\n1980\n1979\n1978\n1977\n1976\n1975\n1974\n1973\n1972\n1971\n1970\n1969\n1968\n1967\n1966\n1965\n1964\n1963\n1962\n1961\n1960\n1959\n1958\n1957\n1956\n1955\n1926\n1925\n1924\n1923\n1922\n1921\n1920\n1919\n1918\n1917\n1916\n1915\n1914\n1913\n1912\n\nNo. of\narticles\n51\n20\n17\n17\n28\n23\n26\n23\n12\n10\n10\n7\n14\n27\n9\n15\n17\n21\n13\n18\n22\n19\n15\n26\n22\n25\n21\n14\n4\n7\n13\n4\n6\n3\n5\n4\n2\n2\n5\n8\n16\n17\n31\n19\n\n1939\n1938\n1937\n1936\n1935\n1934\n1933\n1932\n1931\n1930\n1929\n1928\n1927\n\n15\n8\n10\n9\n9\n7\n12\n12\n9\n16\n12\n5\n8\n\n1911\n1910\n1909\n1908\n1907\n1906\n1905\n1904\n1903\n1902\n1901\n1900\n\n20\n31\n23\n3\n8\n11\n23\n18\n20\n20\n21\n6\n\nFig 1 shows that in the first 20 years\nfrom 1900 to 1919 the research on\nAntarctic was relatively much more\nactive than several decades years\nfollowed. Most of the works were on the\ncategory of geography. Document type\nas book review got much more shares\ncompared with other years in this data\ncollection. South Pole Expedition or\nexploration was the main theme of those\nyears’ research,such as British\nAntarctic Expedition 1898-1900; British\nAntarctic Expedition 1907-1909; British\nAntarctic Expedition 1910-13; German\nSouth Polar Expedition 1901-1903;\nGerman Antarctic Expedition 19111912; French Antarctic Expedition\n1903-1905; French expeditions to the\nAntarctic\n1908-10;\nAustralasian\nAntarctic\nExpedition\n1911-1914;\nNorwegian Antarctic Expedition 19101912; Swedish South Pole Expedition\n1901-1903; Scottish National Antarctic\nExpedition during the Years 1902, 1903,\nand\n1904;\nBelgian\nAntarctica\nExpedition; Bellingshausen&#x27;s Expedition\nin Antarctica 1819-1821; Shackleton\nAntarctic\nExpedition;\nAmundsen&#x27;s\nAntarctic Explorations. And some\nstations were also discussed at those\nearly years, such as Argentine Antarctic\nStation and Kerguelen-Station.\nNo greater leap has been found during\nthe following over 60 years from 1920\nto 1982 when the yearly numbers of\n2103\n\narticles on Antarctica was relatively\nsmall (less than 20 in most of the years).\nOf course polar expedition was still the\ntopic during these years, but not the\nmain theme then. The research scale was\nenlarged from geography to especially\nhistory, politics, economics, anthology,\nand so on. Naming, international\ncooperation, heroes, solitary were also\ntaken into consideration. Antarctic\nTreaty was one of the topics emerged\nmore often. The methodology was also\nenriched. Britain presented many\nexamples of survey and investigation on\nAntarctic social issues. Not only the\ntheoretical review but also the applied\nengineering or practical research was\ntaken on, such as whaling, sailing,\nmapping, sight seeing, polar travel and\nso on, focusing on social factors since\nthe data for this paper was limited in\nsocial sciences field. Review works,\nbibliographies, libraries, even Antarctic\nonline databases have been mentioned\nduring this period.\n\nFig 1. Growth curves for Antarctic studies\nin the humanities and social sciences\n\nFrom 1983 to 2011 it took about one\nfourth of the time period, but produced\n\n2104\n\nmore than half of the research papers\nshowing more enthusiasm on Antarctic\nsocial science study by scientific\nscholars. Resource policy, Antarctic\nwarming,\nenvironment\nprotection,\nsecurity issues, health problems were\ndiscussed. Research topics on ecology,\npsychology, psychiatry, law, became\nmore attracting. Database systems of\nAntarctic information, budget for\nAntarctic has been mentioned several\ntimes. Tourism is also a topic coming in\ngreat numbers during this period.\nAcknowledgments\nResearch for this article is funded by the\nChinese\nArctic\nand\nAntarctic\nAdministration (Grants CHINARE201204-05-03-04).\nReferences\nWeb of Science, available at:\nhttp://www.isiproducts.com\nQu, Tanzhou(2010). The history,\nPresent situation, and future\ndevelopment. available at:\nhttp://www.szlib.gov.cn/newsshow.jsp?i\ntemid=3114\nGuo, Peiqing(2013). Polar regions in the\nfuture influences China a lot.\navailable at:\nhttp://express.cetin.net.cn/cetin2/serv\nlet/cetin/action/HtmlDocumentActio\nn?baseid=1&amp;docno=325689\n\nTHE RELATIONSHIP BETWEEN A TOPIC’S\nINTERDISCIPLINARITY AND ITS\nINNOVATIVENESS\nCarolin Michels\ncarolin.michels@isi.fraunhofer.de\nFraunhofer Institute for Systems and Innovation Research, Breslauer Straße 48, 76139\nKarlsruhe (Germany)\nIntroduction\nThere have been various attempts in the\npast to identify innovative or high\nimpact topics in science semi or fully\nautomatically. Many studies do this in\nretrospective and with the help of\ncitations (see e.g. de Solla Price 1965) –\na method that demands a time span of at\nleast 2 years to give the scientific\ncommunity enough time to discover,\nreact and cite the topic in question. In\nthat case, the identification of an\ninnovative topic relies – on its basis fully on the “wisdom of the crowd”, i.e.\nthe ability of the fellow researchers to\ndiscover and communicate the novel\nfindings.\nThe goal of this study is to find out\nwhether the interdisciplinarity of a topic\nmight be used as an indicator to find\ntopics that have a high innovation\npotential. Interdisciplinarity was defined\nas the combination of different fields or\neven topics in a field. The only other\nnecessary condition in the case of topic\ncombination is that the topics should\ndeveloped so far independently and that\ntherefore the combination of the topics\nis a novelty. We would argue that even\nthough differences exist between multi-,\ninter- and transdisciplinarity (see e.g.\nRussel et al. 2008) the implications hold\nfor all three kinds of combinations of\nknowledge across former boundaries.\n\nThe assumption that interdisciplinarity\nmight be used as an indicator for\ninnovation derives originally from\nKuhn’s definition of paradigm shifts\n(Kuhn 1970). The transfer or adoption\nof knowledge across boundaries can\nhelp to turn the corner in a crisis\n(Thompson-Klein 2004). For example,\ngenetic algorithms use the basic\nbiological principles of recreation and\nevolutionary survival of the fittest to\nfacilitate\ncomplex\nmathematical\ncalculations.\nThe combination of knowledge in turn\ncan result in independent topics or fields\n(see e.g. Shafique 2013, Alvargonzalez\n2011) that can evolve in an independent\nway. Sometimes, this might lead again\nto a diminishing multidisciplinarity,\nwhich might “hinder tapping the full\npotential of research“ in severe cases\n(Shafique 2013).\nSome findings already suggest that an\ninterdisciplinary approach has more\nimpact than monodisciplinary work. The\nimpact (measured in whatever form) is a\nreasonable indicator for innovativeness.\nFor instance, it has been shown that\nmulti- or\ninterdisciplinary work\nenhances the citedness (Leimu and\nKoricheva 2005, Levitt 2008) or the\nsuccess rate (Sigelman 2009) and thus\nthe impact of a paper. Albright argues\nthat according to Adams (2006),\ncreativity is a product of “the\nconvergence of knowledge, creative\n2105\n\nthinking, and motivation” (Albright\n2010) and since these factors are\npromoted by multidisciplinary work,\nmultidisciplinarity leads to creativity\nwhich in turn causes innovation.\nData and Methodology\nThe document set was extracted from an\nin-house implementation of Elsevier’s\nScopus database. All articles in the\ncategory AI (category 1702) that had a\ntitle and an abstract, at least 5 references\nand at least 2 citations were collected\nand 1,000 documents per year were\nselected randomly. Because of the lower\ndata coverage in the years 2010 and\nlater, we restricted our data analysis to\nthe years 2000 to 2009. Only nonComputer Science citations were\nclassified as interdisciplinary citations.\nLatent Dirichlet Allocation (LDA) was\nused to generate the topic clusters in the\nbeginning (Blei et. al 2003). We\nextended the LDA model to take into\naccount references, as has been done in\nsimilar studies before (Erosheva et al.\n2004, Nallapati et al. 2008).\nInterdisciplinarity was measured via\ncitations and references for the\ndocuments. For the disciplines, we\nanalyzed those clusters for which more\nthan 50% of the citations were emitted\nby documents in other disciplines or that\ncited at least in 50% of the cases\ndocuments\nin\nother\ndisciplines.\nConcerning the topics, we analysed\nthose clusters that cited two clusters\nwhich had never been cited together\nbefore.\nResults\nDisciplines\nThere were many clusters that had a\nhigh citation rate of other disciplines\nbecause the respective documents\nactually belonged to these other\ndisciplines. This was particularly the\n2106\n\ncase for high citation rates of Chemistry.\nHowever, there were also some topics\nthat cited other disciplines extensively\nbecause they adopt or transfer\nknowledge, e.g. aspects that are\ntransferred from human behaviour to AI.\nIn addition, some clusters refer to\nBiochemistry or Medicine because AI is\napplied to model biological processes.\nThus, the interdisciplinarity of the\nreference list (rather than the citation\nlist) might indicate a high level of\ninnovativeness. However, this indicator\nmight be misleading as in the examples\nshown above.\nTable 1. Triples of cluster, where the\nciting cluster is the first to cite the two\nclusters together.\n\n1a\n\n1b\n2\n\n3\n4\n\n5\n\nCluster\n(Year)\n“robust”\noutput\ncontrol/\nperformance,\nnonlinear\nsystems\n(2009)\nSparse\n(Bayesian)\nmodeling,\ndimensional\nreduction\n(2009)\nClassifier\nensembles\n(2007)\nRobot\nnavigation,\npath\nplanning\n(2008)\nGenetic\nalgorithms\n(2008)\n\nCited\nCluster 1\nStability\nanalysis\n\nCited\nCluster 2\nTeleoperations\nand\nautonomous\nvehicles\nFuzzy/feed- Identification\nforward\nof dynamic\ncontrol\nsystems\nSampling/\nIndependent\nexperiment\ncomponent\nselection for\nanalysis\nface/object/\nimage\nrecognition\nFace\nInconsistencies\nrecognition/ in structured\nclassification\ntext\nTarget\nFuzzy\ntracking with behaviour\nrobots\nrobots and\nmultiple object\ntracking\nDimensional\nImage\nknowledge transformation\nreduction\n\nContexts\nTable 1 shows the 6 triples of citing and\ncited clusters where the citing cluster\nconnected so far unconnected clusters.\n\nWe cannot discuss the details of the\nclusters here, but just summarize that in\nterms of innovativeness, all but triple 4\nseem to be highly innovative. Even if\nthe aspects of a cluster are not new\nthemselves, the approach of combining\nso far unrelated topics for the old task\nmight be innovative (as for example\ndone in triple 3 or 5).\nConclusion\nIn previous work, the relationship\nbetween field dynamics, innovation and\ninterdisciplinarity has been studied in\none direction, i.e. it was shown that high\ninnovative topics had a high interdisciplinarity. In this work, we tried to\nfind topics with a high innovativeness\nvia their interdisciplinarity and use of\nother topics. The results suggested that\nthe topics that were cited by different\nother topics were highly volatile,\nambiguous or dynamic but not\nnecessarily innovative. Being cited by\nother fields did not necessarily indicate\na high innovativeness. However, the\nmanual assessment of the clusters citing\nnew combinations of topics showed that\nindeed these clusters were in most cases\nhigh impact clusters.\nReferences\nAdams, K. (2006): The sources of\ninnovation and creativity.\nWashington, DC: National Center on\nEducation and the Economy.\nAlbright, Kendra (2010):\nMultidisciplinarity in Information\nBehavior: Expanding Boundaries or\nFragmentation of the Field? In: Libri\n60 (2).\nAlvargonzález, David (2011):\nMultidisciplinarity,\nInterdisciplinarity,\nTransdisciplinarity, and the\nSciences. In: International Studies in\nthe Philosophy of Science 25 (4), pp.\n387–403.\n\nBlei, David M.; Ng, Andrew Y.; Jordan,\nMichael J. (2003): Latent Dirichlet\nAllocation. In: Journal of Machine\nLearning Research (3), pp. 993–\n1022.\nde Solla Price, Derek J. (1965):\nNetworks of Scientific Papers:The\npattern of bibliographic references\nindicates the nature of the scientific\nresearch front. In: Science\nCommunication 149 (3683), pp.\n510–515.\nErosheva, Elena; Fienberg, Stephen;\nLafferty, John (2004): Mixed\nMembership Models of Scientific\nPublications. In: Proceedings of the\nNational Academy of Sciences of the\nUnited States of America, 101 (Suppl\n1), pp. 5229 - 5227.\nKuhn, Thomas S. (1970): The Structure\nof Scientific Revolutions. Second\nEdition, Enlarged: The University of\nChicago Press.\nLeimu, Roosa; Koricheva, Julia (2005):\nDoes Scientific Collaboration\nIncrease the Impact of Ecological\nArticles? In: BioScience 55 (5), pp.\n438–443.\nLevitt, Jonathan M.; Thelwall, Mike\n(2008): Is multidisciplinary research\nmore highly cited? A macrolevel\nstudy. In: J. Am. Soc. Inf. Sci. 59\n(12), pp. 1973–1984.\nNallapati, Ramesh; Ahmed, Amr; Xing,\nEric P.; Cohen, William W. (2008):\nJoint Latent Topic Models for Text\nand Citations. In: KDD’08, pp. 542–\n550.\nRussell, A. Wendy; Wickson, Fern;\nCarew, Anna L. (2008):\nTransdisciplinarity: Context,\ncontradictions and capacity. In:\nFutures 40 (5), pp. 460–472.\nShafique, Muhammad (2013): Thinking\ninside the box? Intellectual structure\nof the knowledge base of innovation\nresearch (1988-2008). In: Strat.\nMgmt. J. 34 (1), pp. 62–93.\n\n2107\n\nSigelman, Lee (2009): Are Two (or\nThree or Four ... or Nine) Heads\nBetter than One? Collaboration,\nMultidisciplinarity, and\n\n2108\n\nPublishability. In: PS: Political\nScience &amp; Politics 42 (03), pp. 507.\n\nThompson-Klein, Julie (2004):\nProspects for transdisciplinarity. In:\nFutures 36 (4), pp. 515–526.\n\nHIERARCHICAL CLUSTERING PHRASED IN\nGRAPH THEORY: MINIMUM SPANNING TREES,\nREGIONS OF INFLUENCE, AND DIRECTED\nTREES.\nXavier Polanco\nxavier.polanco@gmail.com\nIU Independent Unit, 11 rue Meslay, 75003 Paris (France)\nIntroduction\nThe clustering presented in this\ndocument includes algorithms based on\ngraph theory, such as the Minimum\nSpanning Tree, and its extension that\ninvolves Regions of Influence, and also\nDirected Trees.\nThe question is how to do clusters with\ngraphs. In the first section, the simplest\ncase is considered; the second section\ndeals with a more elaborated issue\ndemanding a combination of methods;\nthe last section refers to the example of\ndirected graphs.\nMinimum Spanning Trees\nA Spanning Tree (ST) is a connected\nsubgraph that is a tree containing all the\nvertices of the graph and having no\nloops, i.e., there exists only one path\nconnecting two pairs of nodes in the\ngraph. If the edges of the graph are\nweighted, the weight of the spanning\ntree is defined as the sum of the weights\nof its edges. A single graph can have\nmany different spanning trees. In\naddition, a spanning tree as any graph\ncan be labelled making the assumption\nthat the semantic meanings of interest\ncan be represented as such.\nA Minimum Spanning Tree (MST) is\nthe spanning tree with the smallest\nweight among all spanning trees\nconnecting the nodes of the graph. There\n\nmay be more than one minimum\nspanning tree for a given graph.\nAlgorithms to define the MST of a\ngraph: Florek et al (1951), Kruskal\n(1956) and Prim (1957).\nSuppose a data matrix X of n cases or\nobservations and p variables or\nattributes or patterns, and we desire\nobtain a clustering. For this, a proximity\nmatrix is defined, P(X), which is n × n,\nthat is, a squared and symmetric matrix.\nFrom P(X) is induced a graph G(X),\nwith V = n vertices and a set E of edges\nwith a weight w which is defined by the\nmetric of P(X). The next step is\ndetermining the MST of the G(X).\nFinally, the clusters are the connected\ncomponents of the MST, after the\nremoval of the edges with the largest\nlengths compared with their neighboring\nedges.\n2.5\n4\n\n(2.5)\n\n1\n\n(1.7)\n\n(0.6)\n5\n\n(0.2)\n\n3\n\n1.7\n0.6\n\n2\n\n0.2\n0.0\n1\n\n(a)\n\n3\n\n2\n\n4\n\n5\n\n(b)\n\nFigure 1. (a) The MST derived from a\ndissimilarity matrix. (b) The dissimilarity\ndendrogram obtained with the MST\nalgorithm.\n\n2109\n\nOnce the MST has been determined\nusing any suitable algorithm, we may\nidentify a hierarchy of clusters, which is\nidentical to the one defined by the single\nlink algorithm, at least for the case in\nwhich all distances between any two\nvectors of X are different from each\nother. Thus, this MST may be viewed as\nan alternative implementation of the\nsingle link algorithm.\nObserve that a MST uniquely specifies\nthe dendrogram of the single link\nalgorithm.\nFor the use of the MST for the cases of\ntouching clusters, or clusters with\ndifferent densities, see Zahn (1971).\nRegions of Influence\nAn extension of the MST involves\nRegions of Influence (ROIs), noted\nR(xi,xj). The algorithms for clustering\napplications are known as Gabriel Graph\n(GG) (Gabriel &amp; Sokal, 1969; see also\nMatula &amp; Sokal, 1980) and Relative\nNeighborhood Graph (RNG) (Toussaint,\n1980; see also Urquhart, 1982, and\nJaromczyk, &amp; Toussaint, 1992). The\nidea of ROIs has been used in order to\novercome the problems associated with\nthe MST algorithms.\nx\n\n),\ncondition among the distances (\n(\n), and (\n) Different choices\nof cond give rise to different shapes of\nregions of influence. In Gabriel &amp; Sokal\n(1969) and Toussaint (1980), the\nfollowing two choices are proposed:\n) (\n{ (\n)}\n(\n); and\n(\n)\n(\n)\n(\n).\nGG and RNG are similar in that the\nMinimal Spanning Tree is a subgraph of\neach. Thus, from the GG we can\ncompute its RNG, and from the RNG\nwe can compute its Minimum Spanning\nTree (MST). Previously a Delaunay\ntriangulation (DT) is applied in\n(Jaromczyk, &amp; Toussaint, 1992). For\nany finite set X of points the following\nrelations hold:\n( )\n( )\n( )\n( )\nThe process to follow when the MST\ncannot be directly induced from a graph\nG(X) is: DT(X) → GG(X) → RNG(X)\n→ MST(X). For an example, see Stout\net al (2009), the authors apply this\nprocess in a domain of bioinformatics.\nIn this way we can unravel a tangled\ngraph as frequently occurs when X is a\nbig data matrix.\n\nx\nd(x,xj)\n\nd(x,xi)\nxi\n\nd(x,xj)\nd(x,xi)\nxi\n\nxj\n\nd(xi,xj)\n\nd(xi,xj)\n\nxj\n\nFigure 2. (a) Diagram of the Gabriel\nGraph. (b) Diagram of the Relative\nNeighborhood Graph.\nA Region of Influence is defined as:\n(\n)\n( (\n\n{\n\n) (\n\n) (\n\n))\n\n}\nWhere\n( (\n\n2110\n\n) (\n\n) (\n\n)) is a\n\nDirected Trees\nMany relations are directional, i.e. the\nties are oriented from one actor to\nanother. The citation composed by\nciting/cited is an example of a\ndirectional relation. In these cases, the\ngraph is e directed graph or digraph.\nThus, the cluster analysis consists to\nidentify the directed trees of a digraph\nso that each directed tree corresponds to\na cluster. A clustering algorithm is\nproposed in (Koontz et al, 1976). The\nresulting clusters are unimodal sets.\nFor each point xi its neighborhood is\ndefined:\n( ) {\n(\n)\n}\n\nWhere\ndetermines the size of the\nneighborhood and\n(\n) is the\ndistance between the corresponding\n( ) be the\npoints of X. Let\nnumber of points of X lying in ( );\nand\n(\n)⁄ (\n) will be\nused to determine the position of the\npoint xi in a directed tree.\nThe root xi of a directed tree has the\nlargest ni among the points lying in\n( ); xi is the point with the most\ndense neighborhood. It should be\npointed out that this algorithm is\nsensitive to the order in which the\nvectors are processed.\nConclusion\nThe agglomerative single-link cluster\nanalysis based on graph theory may then\nbe phrased according to Minimal\nSpanning Tree model (Gower &amp; Ross\n1969; Dubes &amp; Jain 1980; Hartigan\n1985; Lebart et al, 1995) and its\nextension called Regions of Influence,\ni.e. Gabriel Graph and Relative\nNeighborhood Graph. When the graph is\na directed graph the idea is the\nidentification of directed trees in a\ndigraph.\nThis document proposes to translate\nthese techniques to scientometrics\ndomain. The road was open long time\nago in scientometrics by Okubo et al\n(1992) associating Correspondence\nFactorial Analysis and Minimum\nSpanning Tree (see also Miquel &amp;\nOkubo 1994).\nReferences\nDubes, R. &amp; Jain, A. (1980). Clustering\nmethodologies in exploratory data\nanalysis. Advances in Computers,\n19, 113-228.\nFlorek, K., Lukaszewicz, J., Perkal, J. &amp;\nSteinhaus J. (1951). Sur la liaison et\nla division des points d’un ensemble\nfini. Colloquium Mathematicum, 2,\n282-285.\n\nGabriel, K. R. &amp; Sokal, R. R. (1969), A\nnew statistical approach to\ngeographic variation analysis,\nSystematic Zoology (Society of\nSystematic Biologists), 18 (3), 259–\n270.\nGower, J.C. &amp; Ross, G.J.S. (1969).\nMinimum spanning trees and single\nlinkage cluster analysis. Journal of\nthe Royal Statistical Society. Series\nC (Applied Statistics), 18 (1), 54-64.\nHartigan, J.A. (1985). Statistical theory\nin clustering. Journal of\nClassification, 2, 63-76.\nJaromczyk, J.W. &amp; Toussaint, G.T .\n(1992). Relative neighborhood\ngraphs and their relatives.\nProceedings of the IEEE, 80 (5),\n1502-1517.\nKoontz, W.L.G., Narendra, P.M. &amp;\nFukunaga, K. (1976). A graph\ntheoretic approach to nonparametric\ncluster analysis. IEEE Transactions\non Computer, 25 (9), 936-944.\nKruskal, J.B. (1956). On the shortest\nspanning subtree of a graph and the\ntraveling salesman. Proceedings of\nthe American Mathematical Society,\n7 (1), 48-50.\nLebart, L., Morineau, A. &amp; Piron, M.\n(1995). Statistique exploratoire\nmultidimensionnelle. Paris,\nDUNOD.\nMatula, D. W. &amp; Sokal, R. R. (1980).\nProperties of Gabriel graphs relevant\nto geographic variation research and\nclustering of points in the plane.\nGeographical Analysis. 12 (3), 205–\n222.\nMiquel, J.F. &amp; Okubo, Y. (1994).\nStructure of international\ncollaboration in science. 2.\nComparison of profiles in countries\nusing a link indicator.\nScientometrics, 29 (2), 271-297.\nOkubo, Y., Miquel, J.F., Frigoleto, O.,\n&amp; Doré, J.C. (1992). Structure of\ninternational collaboration in\nscience: topology of countries\n2111\n\nthrough multivariate techniques\nusing a link indicator.\nScientometrics, 25 (2), 321-351.\nPrim, R.C. (1957). Shortest connection\nmatrix network and some\ngeneralizatios. Bell System Technical\nJournal., 36, 1389-1401.\nStout, M., Bacardit, J., Hirst, J.D.,\nSmith, R.E., &amp; Krasnogor, N. (2009)\nPrediction of topological contacts in\nproteins using learning classifier\nsystems. Soft Computing, 13 (3),\n245-258.\n\n2112\n\nToussaint, G.T. (1980). The relative\nneighborhood graph of a finite\nplanar set. Pattern Recognition, 12\n(4), 261-268.\nUrquhart, R. (1982). Graph theoretical\nclustering based on limited\nneighborhood sets. Pattern\nRecognition, 15 (3), 173-187.\nZahn, C.T. (1971). Graph-theoretical\nmethods for detecting and describing\ngestalt clusters. IEEE Transactions\non Computers, 20 (1), 68-86.\n\nRESEARCH SECTORS INVOLVED IN CUBAN\nSCIENTIFIC OUTPUT 2003-2007\nRicardo Arencibia-Jorge1, Elena Corera-Alvarez2, Zaida Chinchilla-Rodríguez2\nand Félix de Moya-Anegón2\n1\n\nricardo.arencibia@cnic.edu.cu\nNational Center for Scientific Research, 25 Avenue and 158 Street, Cubanacan, Playa, AP\n6414, Havana (Cuba)\n2\n\nfelix.demoya@scimago.es\nSCImago Research Group, Institute of Public Policies and Goods, CCHS-CSIC, Albasánz\n26-28, Madrid (Spain)\nIntroduction\nThe analysis of scientific output and\nrelationships of the different research\nsectors involved in Science and\nTechnology policies using bibliometric\nmethods is always a complex task.\nCountries and regions have their own\nparticular characteristics. The inclusion\nof any kind of institution in a specific\nsector requires the previous study of\nnational science systems, and it depends\non the objectives and functions of each\ninstitution in the national or regional\nenvironment. On the other hand, the\nbehavior of inter-sector relationships is\nalso strongly related with principles and\nnorms of national science policies.\nResearch sectors involved in Cuban\nscientific activity are not yet fully\nstudied. A previous paper of the authors\nexplores the Cuban output at macro\nlevel (Arencibia-Jorge &amp; Moya-Anegón,\n2010). The current work analyzes the\nscientific activity and impact of the\ndifferent Cuban research sectors during\nthe period 2003-2007.\nMethod\nScopus was chosen as data source. A\nsearch\nstrategy\nbased\non\nthe\nidentification of the word “Cuba” in\n\nAuthor Address and Affiliation Country\nfields was used. The retrieved items\nwere downloaded to an ad hoc database,\nwith the aim to eliminate false items and\nnormalize affiliation data. Cuban\nresearch sectors were the most important\naspect identified in each register from\nthe database.\nData was collected in January 2010. The\nScopus retrospective coverage process\ndoes not significantly affect the\ncomparison between data obtained in the\ncurrent work and those obtained from\nthe earlier paper based on the same\nperiod.\nThe\nscientific\nproduction\nwas\ndistributed in six sectors: Higher\nEducation (HEd), Health, Science &amp;\nTechnology\n(S&amp;T),\nGovernment\nAdministration (GAd), Enterprises (EPr)\nand Others.\nTotal publication output (A) and annual\npercentages were the indicators selected\nto show the quantitative dimension of\nthe scientific production.\nThe qualitative dimension was studied\nthrough a set of impact indicators: Total\nof cited articles (AC), percentage of\ncited articles, average of citations per\narticle (Ave) and H index (H). Each of\nthese impact indicators were calculated\nby sector.\n\n2113\n\nSocial Network Analysis (SNA)\ntechniques were employed to visualize\nthe inter-sector collaboration.\nResults and Discussion\nThe Cuban scientific output is mainly\ndistributed in three of the six sectors\nanalyzed (table 1). Higher Education is\nthe most productive sector (55.4 %),\nwhich has been observed in previous\nstudies (Sancho et al., 1993; AraujoRuíz et al., 2005).\nIn terms of visibility, Higher Education\nis the sector with the highest H-index,\nalthough their proportion of cited\narticles and the average of citations per\narticle are below the national mean. The\ncause of this behavior is the big amount\nof papers published in less cited national\njournals, an aspect that involves the\noutput of higher institutes of Medical\nSciences belonging to the Higher\nEducation\nsector,\nand\nhospitals\nbelonging to the Health Sector.\nOnly 43 % of articles published by\nuniversities, and 31 % of articles\npublished by hospitals were cited during\nthe period, in contrast to the citation\nactivity of Science and Technology (54\n%) and Government Administration (55\n%).\nGovernment Administration comprised\nonly 3.3 % of the national output, but\nshowed the highest average of citations\nper article. Meanwhile, the sector\nEnterprises only published 71 articles\nduring the period, with no role for any\nparticular institution, and poor visibility.\nTable 1. Scientific output and impact by\nsector.\nSector\nHEd\nHealth\nS&amp;T\nGAd\nEPr\nOthers\nCuba\n2114\n\nA\n3199\n2270\n1864\n190\n71\n51\n5778\n\n%\n55.4\n39.3\n32.3\n3.3\n1.2\n0.9\n100\n\nCA\n1384\n708\n1012\n105\n19\n6\n2582\n\n%\nC\n43.3 7680\n31.2 4237\n54.3 5521\n55.3\n777\n26.8\n62\n11.8\n16\n44.7 14727\n\nAve\n2.40\n1.87\n2.96\n4.09\n0.87\n0.31\n2.55\n\nH\n29\n24\n25\n17\n4\n2\n34\n\nInstitutions belonging to the scientific\npark from the west of Havana were the\nleaders of the sector Science and\nTechnology. This group of institutions is\nresponsible for an increasing amount of\ncash income that has made Cuba&#x27;s\nbiotechnology industry the third motor\nof the country&#x27;s economy at the end of\nthe decade.\nThe growth of Higher Education and\nHealth Sector determines practically the\nnation&#x27;s growth in global terms.\nThe scientific collaboration expressed in\nthe different sectors analyzed can be\napproached from multiple perspectives.\nOn the one hand, the collaboration\namong sectors offered an important\nview of the national scientific activity.\nOn the other one, the establishment of\nstrong networks of international\ncollaboration was a very important\nstrategy with the aim to achieving a high\nvisibility or impact.\n\nFigure 1. Inter-sector collaboration\n(UCINET 6.123; NetDraw 2.38).\n\nOn the figure 1, the size of the nodes\nidentifies the volume of the sector ́s\noutput, the node ring represents the\nproportion\nof\ninternational\ncollaboration, the lines imply the\nexistence of collaboration among\nsectors, and the thickness of links\nexpresses the intensity of those\nrelations. Thus, the structural dimension\nof the national scientific output from the\n\ncharacterization of its strategic sectors\nwas objectively represented.\nThere are some problems that can be\ninferred from the presented map. First,\nthere is a weak linkage between\nuniversities and institutions of science\nand technological innovation, and also\nreduced relationships between scientific\nresearch centers and health institutions\nin the country; second, the international\ncollaboration is not representative in the\nhealth sector, taking into account the\nmany Cuban health experiences and\nmissions throughout the world; and\nthird, there is a divorce between R&amp;D\nunits of enterprises and the institutions\nbelonging to Higher Education and\nScience and Technology, given by the\nstill insufficient research activity\ngenerated by Cuban enterprises.\nThe causes of these problems have a\nmultifactorial nature. Despite the\nadvanced research policy of higher\neducation in Cuba, it is evident that still\nare low the level of actions developed\nby scientific institutions with the aim to\nattract the interest of students and\nresearch teams from universities. In this\nsense, the necessary link between the\nacademy and institutions of science and\ntechnological innovation must be more\nevident.\nOn the other hand, taking into account\nthe wide biomedical scope of Cuban\nscientific activity, there is no reason to\navoid the collaboration between\nhospitals, health care centers and\nresearch\ninstitutions\nin\nresearch\nprocesses. An important number of\nCuban products developed by scientific\nresearch centers are introduced in\nhospitals and distributed by the national\nnetwork of pharmacies. Therefore, a\nmore active role of physicians and\nprofessors from hospitals and health\ninstitutions, especially in research lines\nrelated to the use of these products by\nCuban population, is necessary. Finally,\nit is clear that the absence of incentives\n\nis the main cause of a low international\ncollaboration in the health sector, as\nwell as the complete divorce between\nCuban enterprises and institutions\nbelonging to Higher Education and\nScience and Technology. In this sense,\nthe recent creation of a biotech company\n(BioCubaFarma) that involve the most\nimportant research centers from the west\nof Havana, is a decisive step of the\ncountry in order to change the current\nstatus.\nConclusions\nCuban scientific output has experienced\nincreasing growth during the first\ndecade of the new millennium. The\ncountry ́s efforts and expenditures in\nResearch and Development activities\nhad positive implications for the Cuban\nscience system evolution, and total\noutput of the country is led by the\nresearch developed in institutions\nbelonging to the most relevant sectors\ninvolved in scientific activities: Higher\nEducation, Health, and Science &amp;\nTechnology. Inter-sector relationships\nreveal some weaknesses in the national\nscientific macro-structure. Therefore, a\ndeep analysis of the science and\ntechnology policies in each of the\nsectors studied is still necessary.\nAcknowledgments\nTo the staff of SCImago Research\nGroup, for the support, research advices\nand unconditional friendship.\nReferences\nArencibia-Jorge, R. &amp; Moya-Anegón, F.\n(2010). Challenges in the study of\nCuban scientific output.\nScientometrics, 83, 723-737.\nSancho, R., Bernal, G., &amp; Gálvez, L.\n(1993). Approach to the Cuban\nScientific Activity by Using\nPublication Based Quantitative\n\n2115\n\nIndicators (1985-1989).\nScientometrics. 28, 297-312.\nAraújo-Ruiz, J.Á., Torricella-Morales,\nR.G., Van Hooydonk, G., &amp;\nArencibia-Jorge, R. (2005). Cuban\n\n2116\n\nscientific articles in ISI citation\nindexes and CubaCiencias databases\n(1988-2003). Scientometrics. 65,\n161-171.\n\nRESEARCH TRENDS IN GENETICS:\nSCIENTOMETRIC PROFILE OF SELECTED ASIAN\nCOUNTRIES\nShivappa L. Sangam1, Uma B. Arali1, Chandrashekhar G. Patil2 and Srishail Gani3\n1\n\nslsangam@yahoo.com\nDepartment of Library and Information Science, Karnatak University, Dharwad-580003.\nIndia.\n2\nDepartment of Applied Genetics, Karnatak University, Dharwad-580 003. India\n3\nDepartment of Statistics, Karnatak College, Dharwad-580 001. India\n\nIntroduction\nGenetics a discipline of biology is the\nscience of genes, heredity, and variation\nin living organisms. It is one of the\nyoungest and the fastest growing\ndisciplines of science. Now-a-days, it is\na multidisciplinary subject as genes are\nuniversal to living organisms and\ngenetics can be applied to the study of\nall living systems, from viruses and\nbacteria, through plants and domestic\nanimals to humans. Knowledge of\ngenetics being basic to progress in\nbiology,\nagriculture,\nmedicine,\nbiotechnology, forensic sciences and\nmany other fields, results of such studies\nare found highly useful. Research plays\na vital role for the development or\ngrowth of subject(s) both qualitatively\nand quantitatively. This change in the\ntrend can be traced by generating\nnumerical data on the basis of the\nempirical evidence available in the\nprocess of identifying the trends in\nresearch priorities in a field. In the\nrecent past, studies dealing with the\nassessment of scientific research in\ngenetics by different nations have been\nreported in literature.\nMethodology\nFor the present study, the data has been\ncollected from PubMed database. It is\n\none of the popular source of information\navailable with NCBI (National Centre\nfor Biotechnology Information) on the\nwebsite\naddressed\nhttp://www.ncbi.nlm.nil.gov/pubmed/.\nThe study compares the research\npriorities of 16 sub-specialities of\ngenetics in 10 countries for two timespans; 1992-2001 and 2002-2011.\n1. Publication output of World in 16\nsub-specialities of Genetics\nFrom the table 1 and fig.1 it is evident\nthat, Molecular Genetics and Human\nGenetics accounts for 68% of the total\noutput in 1992-2001 and 60% in 20022011. Molecular Genetics accounts for\nthe largest output 38% in 1992-2001 and\nHuman Genetics 30% in 2002-2011\nblock periods. Ecological Genetics\naccounts for the smallest output of 0.1%\nin 1992-2001 and Genetics of\nIntelligence 0.2% in 2002-2011. The\ntable clearly indicates the importance of\ntrends in all the 16 branches which has\nincreased or decreased over a period of\ntwenty years.\n2. Publication output and share of\npublications of major Asian countries\nThe publication output and share of\npublications of major nations of Asian\ncontinent is shown in table 2 and also is\nrepresented in form of graph in figure 2.\n2117\n\nAmong fifty Asian countries, Japan\nalone accounts for about 66% among\nAsian output in 1992-2001 and Japan\nand China 65% in 2002-2011.\n\nKorea(6498); Hong Kong(5968); and\nRussia(5832).\n\nTable-1 Publication output of world in 16\nsub-specialities of genetics\nNumber of Publications\nBranches\nBG\nCl G\nDG\nCG\nEG\nEv G\nGE\nGI\nG\nHG\nMG\nMi G\nMo G\nPG\nPs G\nQG\nTotal\n\n1992-2001\n2002-2011\nWorld\n%\nWorld\n%\n5836\n0.63\n14224\n0.84\n6128\n0.66\n12821\n0.76\n30800 3.32\n62457\n3.7\n6458\n0.7\n12854\n0.76\n1000\n0.11\n6775\n0.4\n9861\n1.06\n31090\n1.84\n54710\n5.9\n88720\n5.26\n1420\n0.15\n3067\n0.18\n8928\n0.96\n59080\n3.5\n277028 29.88 498481 29.56\n109206 11.78 198939 11.8\n12787 1.38\n33730\n2\n350537 37.81 506201 30.02\n35015 3.78\n91761\n5.44\n2790\n0.3\n6916\n0.41\n14632 1.58\n59160\n3.51\n927136 100 1686276 100\n\nNote: B G-Behavioural Genetics, Cl G-Classical\nGenetics, D G- Developmental Genetics, C GConservation Genetics, E G-Ecological Genetics,\nEv G-Evolutionary Genetics, G E-Genetic\nEngineering, G I-Genetics of Intelligence, H GHuman Genetics, M G-Medical Genetics, Mi GMicrobial Genetics, Mo G-Molecular Genetics, P\nG-Population Genetics, Ps G-Psychiatric Genetics,\nQ G- Quantitative Genetics.\n\n3. Publication performance of Major\ncountries\nThe data in table 4 reveals articles\npublished in 16 branches, represented in\ndifferent columns and 10 countries in\nrows during 2002-2011. In the present\nblock period also, it is Japan which has\nmaximum number of articles published\n(130060) however, it is followed by\nChina (115689); India (26456); Israel\n(22033); Taiwan (21970); Georgia\n(9421);\nTurkey(7412);\nSouth\n2118\n\nFig. 1. Growth comparison between subspecialities of Genetics\n\n4. Priority profiles of Major\ncountries:\nThe raw count alone does not convey\nmuch information as these figures are\nconfounded by the size of the countries\nand the size of the subject specialities.\nHence, an index called Relative\nPriority Index (PI) is computed for\ncross national comparison using formula\nas suggested by Nagpaul and Pant 6.\n\n( )(\n\n)\n\nThe profile of research priorities of\nmajor countries are presented in Table 5\nand 6 for two time-spans- 1992-2001\nand 2002-2011. These tables indicate\nthe differences in the priority accorded\nto different sub-specialities by different\ncountries.\nFrom the values of PI, we can compare:\ni) The research priorities of a country\nfor different sub-specialities of\ngenetics in a given time span;\n\nii) The research priorities of different\ncountries for a given sub-speciality\nin a given time span; and\niii) The research priorities of a country\nfor a given sub-speciality at different\ntime span.\nIn table 5 and 6, the PI value for each\nvariable in the table 3 and 4 is computed\nusing PI formula i.e. for both the block\nperiod 1992-2001 and 2002-2011. The\npriority index of different countries is\narranged again in the form of a matrix\nwhere the rows represent the countries\nand columns the sub-specialities. So, the\nrow vector represents the priority\nprofiles of countries, whereas the\ncolumn vectors geographical profiles of\nsub-specialities.\nConclusion:\nGenetics, the most rapidly growing area\nof research has relevance to many\naspects of human life and society,\nincluding health, behaviour, food\nproduction, forensics and even politics.\nIf used wisely, the new information\npromises to enhance our quality of life.\nScience indicators are used for both\ndescriptive as well as analytical\npurposes to identify trends, make\ncomparisons and as an aid for\ntheoretical understanding of casual\nstructure related to science and\ntechnology systems.\nOn the basis of the analysis the\nfollowing conclusions may be drawn -.\n1. Among the 10 major Asian\ncountries, Japan accounts for the\nlargest output of genetics literature.\nIt alone accounts for 66% of the\nAsian output in 1992-2001 and 38%\nin 2002-2011.\n2. Among fifty Asian countries, India\noccupies\nthird\nposition\nin\ncontributing to the genetics research.\n3. Among sub-specialities, Molecular\ngenetics accounts for the largest\n\noutput of 38% in 1992-2001and 30%\nin 2002-2011.\n4. The sub-speciality, Genetics of\nIntelligence accounts for the lowest\noutput of 0.2% during both block\nperiods.\n5. PCA analysis indicates three groups\nof\nsub-specialities\nbased\non\ncorrelation among them.\nReferences\nGarag,K.C. at el. Scientometric profile\nof genetics and heredity research in\nIndia.Annals of Library and\nInformation Studies.57, 2010,196 206.\nGarg, K. C. at el. Plant Genetics and\nbreeding research: Scientometric\nprofile of selected countries with\nspecial reference to India. Annals of\nLibrary and Information Studies. 58,\n2011, 184-197.\nVaraprasad, S. J. D. and Ramesh, D. B.\nActivity and growth of chemical\nresearch in India during 1987-2007.\nDECIDOC Journal of Library and\nInformation Technology, 31 (5),\n2011.\nSangam, S. L. at el. Indicators for\nDemographic Research: A Crossnational Assessment. Journal of\nLibrary and Information Science. 30,\n2005, 1-19.\nSangam, S. L., Arali, U. B., Patil, C. G.\nand Mageri, M. N. Scientometric\nAnalysis of Genetic Literature.\nProceedings of 8th International\nConference on Webometrics,\nInformatics and Scientometrics &amp;\n13th COLLNET Meeting, October\n23-26, 2012, Seoul, South Korea.\nNagpaul, P.S. and Pant, Nagaraj.\nResearch priorities of major\ncountries in artificial intelligence.\nProceedings of International\nCongress on Cybernetics and\nSystems. NewDelhi. Tata McGraw\nHill, 1993.\n2119\n\nTHE RISE AND FALL OF GREECE’S RESEARCH\nPUBLICATION RECORD: THE LAST 30 YEARS\nOlga Koukliati1 Anastassios Pouris2\n1\n\njulieparos@yahoo.gr\nInstitute for Technological Innovation, University of Pretoria, Pretoria (South Africa)\n2\n\napouris@icon.co.za\nInstitute for Technological Innovation, University of Pretoria, Pretoria (South Africa)\n\nIntroduction\nMonitoring the performance of national\nscientific and technological systems\nbecame a preoccupation of policy\nauthorities internationally in the 1990s.\n(Pouris A, 2003). This poster identifies\nGreece’s research publication record\nacross major disciplines to the year 2010\nand traces the various policies that\naffected the country’s research system.\nThe indicators covered are number of\npublications, citations received and their\ndistribution across scientific fields and\ninstitutions. Bibliometric indicators are\nused internationally to monitor the\noutputs of scientific systems, they are\nclearly defined and unambiguous and\nallow categorization in particular\nscientific fields and disciplines (Pouris\nA, 2012). Such categorization is useful\nfor judging the performance of national\nscientific systems and their component\nparts in a global context (Pouris A,\n2003). Scientometric indicators are used\nwidely as an indispensable part of\nscience\nand\ntechnology\npolicy\nmonitoring and assessment studies\n(Jeenah M &amp; Pouris A, 2008) related to\nthe structure and dynamics of science,\nimpact assessments and others (King\nD.A, 2004). Such indicators allow\ncomparisons of different disciplines\nbetween countries and other metrics\nwhich are not possible through other\n2120\n\nmethods. (Pouris A, 22012). The\nfollowing approach is based on data\nprovided\nby\nThe\nNational\nDocumentation Centre of Greece\n(NDC/EKT-2012) and summarizes the\ninformation available in the databases of\nthe National Science Indicators (NSI)\nand NCR of Thomson Reuters, with\nregard to Greece’s number and share of\nthe world’s publications.\nFindings:\nGreece’s\nResearch\nPerformance\nGreek publications, regarding the\nappeal, originality, quality and name\nrecognition were better positioned\ninternationaly in recent years: the\naggregate indices and Greece&#x27;s position\ninternationally upgraded, impact of\npublications increased and performance\nof organizations improved. Growth was\ncontinuous until 2008, while in 20092010 the number of Greek papers\ndownturned. In 2009 the continuous\nupward trend stopped. Greece follows\nthe average performance of OECD and\nEU countries and records an almost zero\ncoefficient of variation. In 2010 the\ndecline in the number of publications in\nOECD and EU countries includes\nGreece.\nFigure 1 shows the number of Greece’s\npublications for the period 1981-2011.\nAccording to the NSI database, there\n\nwere 10.219 Greek publications in\ninternational\nscientific\njournals\nregistered in the Web of Science in\n2010. Greece’s yield of research\npublications shows decreasing trends\nand slipped from 10.625 publications in\n2008 to 10.579 in 2009 and 10.219 in\n2010.\n\nFigure 1: Number of Greece&#x27;s overall\npublications\n\nBased on 2010 figures, Greece\nparticipates in 2.4% of scientific\npublications in the EU and 1.14% in the\nOECD, doubling the units compared\nwith 1996, and is in 24th among the 34\nOECD countries.\nIn 2010 most Greek publications\n(48.9%) are classified in the scientific\nfields of Physical Sciences, Medical &amp;\nHealth Sc. (39.4%), Engineering and\nTechnology (23.6%), Social Sc. (6.3%),\nAgricultural Sc. (3.3%) and Humanities\n(1.5%). (Greek Scientific Publications,\n1996-2010).\nThe majority of Greek scientific\npublications\nwere\nproduced\nby\nUniversities,\nResearch\nCenters\nsupervised by GSRT, Public and\nPrivate\nHealth\nInstitutions,\nTechnological Educational Institutes,\nOther Public Research Centers and\nOther Public and Private Institutions.\n(Greek Scientific Publications, 19962010)\nData shows the wide use of English\n(99,66%) in Greek publications, as\n\nnational and international collaboration\nof the scientific community allows the\nauthors to increase the visibility, number\nof citations and the impact of their\npublications. Other common languages\nused: French (0.110%), German\n(0.103%), Spanish (0.032%) and Italian\n(0.014%).\nTable 1 indicates the research\ncollaboration between Greece and other\ncountries. The evolution over the period\n1996-2010 showed an increasing trend\nin a national and international level. In\n2010\nco-publications\nby\nGreek\nresearchers accounted for 67.2% of the\ntotal publications output (49.3% in\n1996). During 2006-2010 Greece\ncooperated with scientists from 154\ncountries. The main publishing partners\nwere USA, UK, Germany, France and\nItaly. (Greek Scientific Publications,\n1996 -2010)\nTable 1: Scientific collaboration between\nGreece and other countries\nCountries/Territories\nGREECE\nUSA\nENGLAND\nGERMANY\nFRANCE\nITALY\n\nRecord\ncount\n65237\n7601\n5518\n4557\n3552\n3347\n\n% of\n65.237\n100.000%\n11.651%\n8.458%\n6.985%\n5.445%\n5.131%\n\nDuring 1996-2010, Greece exhibits a\nremarkable growth rate in its publishing\nvolumes and is ranked 8th among the\nOECD-34 countries. Featuring 10,219\npublications in 2010 compared to 3,729\nin 1996, Greece presents a rate of\nchange equal to 2.74, above the average\nrate of change for the EU (1.54) and the\nOECD countries (1.41) The number of\nGreek publications displayed a steady\nincrease from 1996 to 2008. However,\nthis positive trend reversed in 2009; the\nrate of change in Greek publications was\n2121\n\nalmost zero that year. The situation\ndeteriorates in 2010 with a decline\nhigher than that observed in EU and\nOECD countries.\nFactors affecting the growth and the\nrecession of Greece’s publication\nprofile\nGreece&#x27;s entry to the European Union\n(EU) had a very positive impact on the\ndevelopment of the research component\nof Greek universities mainly, but also on\nthe sustainability and development of\nGreek\nResearch\nCenters\n(RCs).\nSignificant inflows from structural and\ncompetitive programs of the Union\noxygenated research. Meanwhile, a\nnumber of structural changes in the\nacademic legislation radically changed\npositively the landscape of higher\neducation: In 1983 (Law 1404/83)\nTechnological Educational Institutes\n(TEI) were founded and in 1984 three\nnew universities: University of the\nAegean, based in Mytilene, Ionian based\nin Corfu and Thessaly based in Volos\n(Presidential Decree (83/84) 31/A/2003-1984). In 1985 (Law 1514/85) the\nNational Council for Research and\nTechnology (ESET) along with the\nFoundation\nfor\nResearch\nand\nTechnology (FORTH) in Crete, the\nAcademic RCs and Postgraduate\nInstitutes were established.\nPeriod 1985-1992 and the decade that\nfollows are characterized by dense flow\nof resources through the structural and\ncompetitive programs in the EU. In\n1992 the Greek Open University was\nfounded.\nThe main sources of funding for\nresearch in Greece are: Grants from\nregular state budgets, From the public\ninvestment program of GSRT (it\nincludes EU Structural Funds (eg.\nNSRF) for 2007–2013 and constitutes\nthe reference document for the\nprogramming of EU Funds at national\n2122\n\nlevel)\nand\nFunds\nfrom\nother\ninternational collaborative programs\n(NSRF, 2007-2013: What is the\nNational\nStrategic\nReference\nFramework).\nIn recent years reports of abuses,\nunderfunding,\neconomic\nmismanagement, interventions in the\nevaluation of research programs and\ndelays by the Ministry of Education,\naffected negatively Greece’s research\nproductivity in publications. Voices of\nacademics proliferate, complaining to\nthe Ministry of Education in order to\nexpedite the process of evaluating\nresearch programs of the NSRF, or\nprecious funds from the EU will be lost\n(Federation of Traning Personal of TEI,\n2011).\nToday, Greece is going through difficult\ntimes in the context of the economic\ncrisis that plagues the whole of Europe.\nThe great achievements of Greek\nresearchers in recent years seem to\nspend a period of recession. However, &quot;\nSmall countries with no oil or diamonds,\nhave the power of human capital. Our\nstrength is the heads [of researchers]&quot;\n(Diamantopoulou A, 2011)\nReferences\nNational Documentation Centre of\nGreece, (2012). [online]. Retrieved\nSeptember 20, 2012 from:\nwww.ekt.gr/content/display?ses_mo\nde=rnd&amp;ses_lang=el&amp;prnbr=84879&gt;\nGreek Scientific Publications, (19962010. Retrieved 20/09/2012 from:\nhttp://metrics.ekt.gr/en/report02/inde\nx\nDiamantopoulou, A. (2011). Extract\ninterview on NET TV, 27/5/2011.\nRetrieved 30/09/2012 from:\nhttp://www.diamantopoulou.gr\nJeenah, M., &amp; Pouris, A. (2008). S.\nAfrican research in the context of\nAfrica and globally. S. African\n\nJourn. of Science, 104 (9/10), 351354\nKing, D. A. (2004). The scientific\nimpact of nations: What different\ncountries get for their research\nspending. Nature, 430, 311–316\nPouris, A. 1(2012). Science in S. Africa:\nThe dawn of a renaissance? S Afr J\nSci. 108(7/8): 66-71\nPouris, A. 2(2012). Scientometric\nresearch in S.A. and successful\npolicy instruments. Scientometrics\n91: 317–325\n\nPouris, A. (2003). S. As publication\nrecord: the last ten years. S. A.\nJournal of Science 99, 425-428\nNSRF, (2007-2013): What is the\nNational Strategic Reference\nFramework [online] Retrieved\n20/09/2012 from:\nhttp://www.espa.gr/en/Pages/staticW\nhatIsESPA.aspx\nFEDERATION of TRAINING\nPERSONAL of TEI :press release,\n07/01/2011. Retrieved 4/09/2012\nfrom:\nhttp://www.teiath.gr/verwalt/syllogoi\n_foreis/osep_tei/\n\n2123\n\nTHE ROLE OF COGNITIVE DISTINCTIVENESS ON\nCO-AUTHOR SELECTION AND THE INFLUENCE\nOF CO-AUTHORING ON COGNITIVE\nSTRUCTURE: A MULTI-AGENT SIMULATION\nAPPROACH\nBulent Ozel1 and Ahmet Suerdem2\n1\n\nbulent.ozel@bilgi.edu.tr\nIstanbul Bilgi University, Dolapdere Kampusu, Beyoglu, 34440 Istanbul\n(Turkey)\n1\n\nahmet.suerdem@bilgi.edu.tr\nIstanbul Bilgi University, Kustepe Kampusu, , 34440 Istanbul\n(Turkey)\nMotivation\nAnalysis of co-authorship relations is a\ntangible and reliable way of tracking\nscientific\ncollaboration\nnetworks.\nParticularly, they give important\ninformation about knowledge diffusion.\nHabitually,\nbibliometric\nnetwork\nanalyses focus on the effects of author\nattributes on author interactions such as\nhomophily or compositional measures.\nHowever, the interaction between\ncollaboration networks and cognitive\nstructures is a relatively less studied\narea. Particularly, how co-authors may\ninfluence each other’s knowledge\nstructures and the role of cognitive\nhomophily or heterogeneity for the\nselection of potential co-authors is\nessential to understand knowledge\ndiffusion within an academic domain.\nStudies up to now show how author\nattributes affect whom to collaborate\nwhile underplaying how this interaction\ninfluences the cognitive structures of the\ncollaborating authors. Our objective is\nto analyse not only how collaboration\nnetwork changes as a function of itself\nand author attributes but also how the\n2124\n\nauthor cognitive structures change as a\nfunction of themselves and of the\nnetwork.\nMethodology\nWe use a stochastic actor-based model\nto test the effects of cognitive structures\non network change and the effects of\nnetwork change on cognitive structures.\nOur model is an actor driven model\nwhere each author is capable of\nselecting its co-author and his/her\ninterest area. We operationalize\ncognitive structures of individual actors\nas semantic networks. Cognitive\nsimilarities are calculated according to\nthe co-occurrence of the subject\nkeywords within the articles. We test the\nhypothesis that authors would choose to\ncollaborate with authors cognitively\ndistinct from them since there would be\nmore possibilities for cross-fertilization\ncompared to cognitive homophily.\nFindings\nResults from our initial experiments hint\nthat in scenarios where agents are\ninclined to collaborate with cognitively\n\ndissimilar agents, then resulting\ncollaboration structure rather mimics\nco-authorship relations seen within a\nresearch center. On the other hand,\nwhen cognitive similarity leads the\nincentives to pick a collaborator, then\nresulting co-authorship rather mimics\nnetwork structures observed within\ndomain of a journal in a field.\nA large set of experiments are to be\nconducted to fully verify and validate\nour initial results as well as to discuss\nchallenges addressed above.\nThere\nare a set of additional implementation\nchallenges, which will be addressed and\nattempted. They are (i) how to model\n\nwhen and in what circumstances\nmultiple co-authorship occurs; (ii) and\nhow to specify knowledge content of\ncollaboration. Cognitive structures of\ninteracting dyads will be studied while\naddressing these questions. Besides,\n(iii) at each run, not only new\nknowledge pieces but also new agents\nwill be injected to the simulation.\nKnowledge base of those new agents\nwill be composed of partially by a\nsubset of keywords that is already in the\ncurrent set\nand partially by new\nkeywords that is not in the set. This\napproach will mimic arrival of new\nscientists in a field.\n\n2125\n\nSCIENTIFIC PRODUCTION AND\nINTERNATIONAL COLLABORATION ON SOLAR\nENERGY IN SPAIN AND GERMANY (1995-2009)\nElías Sanz-Casado1; Maria-Luisa Lascurain-Sánchez1; J. Carlos García-Zorita1;\nAntonio Eleazar Serrano-López1; Birger Larsen 2 and Peter Ingwersen 1,2,3\n1\n\nelias@bib.uc3m.es; mlascura@bib.uc3m.es; czorita@bib.uc3m.es;\naeserran@bib.uc3m.es; 3blar@iva.dk : 2,3 PI@iva.dk\n1\nUniversidad Carlos III de Madrid, Department of Library Science and Documentation,\nLaboratorio de Estudios Metricos de Informacion (LEMI), C/Madrid 126, Getafe 28903,\nMadrid, Spain.\n2\nRoyal School of Library and Information Science, Biketinget 6, DK 2300 Copenhagen,S,\nDenmark\n3\nOslo University College, St. Olavs plass, 0130 Oslo, Norway\nIntroduction\nRenewable energies carry political and\nfinancial significance in all EU\ncountries. Their importance is translated\ninto a major research and innovation\ntrend, particularly in relation to the\nachievement of sustainable resources\n(Walz; Schleich &amp; Ragwitz, 2011).\nSolar and Wind Energies offer the\nbiggest potential for energy production,\nas it has been highlighted in the last\ndecade (Sanz-Casado; García-Zorita;\nSerrano-López; Larsen &amp; Ingwersen,\n2012). Within he overall conglomerate\nof renewable energies, Germany has a\nbigger production than Spain, although\nthe increase is higher for Spain in the\ncase of Solar Energy production (2560\nversus 2734 of increment), measured in\ntonnes of oil equivalent (during 19952009).\nObjectives\nThe overall objective of this research is\nto identify if the public interest in Solar\nenergy is reflected in Spanish and\nGerman research publications, so that\nwe can establish a profile in the\n\n2126\n\nevolution of publications and in their\ninternational scientific collaboration\npatterns overtime.\nMethodology\nWe have used the databases contained\nwithin the Web of Science as source. A\nsearch strategy was designed to be able\nto retrieve publications on Solar energy\nfrom a wider collection of documents on\nrenewable energies. The timeframe goes\nfrom 1995 to 2009, while the\ngeographical framework focused on\ndocuments by authors from Spanish and\nGerman institutions.\nThe obtained records were downloaded\nonto a text file, using a set of scripts\nwith Perl programming language for\ntheir treatment in a referential database\nmanaged by MySQL.\nResults\nTable 2 shows the distribution of\nscientific production on Solar Energy by\ncountry (Top-10) (WoS, 2012), with a\nremarkable raise of China to second\nposition and a decrease of USA and EU\ncountries who produce more articles but\nrepresent a lower percent over the global\n\nproduction on Solar energy against that\nwas found on Wind power research\npatterns (Sanz-Casado; García-Zorita;\nSerrano-López; Larsen &amp; Ingwersen,\n2012). For instance, DEU gains in\npublications but decreases in percentage.\nThe same occurs for France but not for\nItaly that increases its percentage. Spain\nincreases both in number of publications\nand in percentage (to 4.14 from 2.89).\nTable 1. Supply, Transformation and\nConsumption - Renewable and Wastes\n(total, solar heat, biomass, geothermal,\nwastes) - Annual Data. (EUROSTAT\n2012)\nRenewable Energies\nEU\nGermany\n82,631\n6,095\n86,139\n6,278\n89,754\n7,228\n92,353\n7,795\n92,681\n8,069\n96,650\n9,094\n99,637\n9,747\n97,505\n10,898\n103,906\n12,969\n111,843\n15,780\n115,891\n17,502\n123,507\n21,678\n134,057\n27,964\n142,037\n27,968\n148,776\n27,777\nSolar Energy\nYEAR\nEU\nGermany\n1995\n282 (0.34%) 38 ( 0.62%)\n1996\n305 (0.35%) 48 ( 0.76%)\n1997\n329 (0.37%) 61 ( 0.84%)\n1998\n362 (0.39%) 77 ( 0.99%)\n1999\n391 (0.42%) 92 ( 1.14%)\n2000\n430 (0.44%) 115 (1.26%)\n2001\n482 (0.48%) 150 (1.54%)\n2002\n533 (0.55%) 184 (1.69%)\n2003\n594 (0.57%) 216 (1.67%)\n2004\n683 (0.61%) 262 (1.66%)\n2005\n806 (0.7%) 353 (2.02%)\n2006\n988 (0.8%) 472 (2.18%)\n2007 1264 (0.94%) 580 (2.07%)\n2008 1,730 (1,22%) 735 (2.63%)\n2009 2,498 (1,68%) 973 (3,5%)\nYEAR\n1995\n1996\n1997\n1998\n1999\n2000\n2001\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n\nSpain\n5,510\n6,986\n6,646\n6,783\n6,031\n6,928\n8,169\n7,040\n9,245\n8,866\n8,353\n9,158\n9,996\n10,334\n12,158\nSpain\n26 ( 0.47%)\n26 ( 0.37%)\n24 ( 0.36%)\n27 ( 0.4%)\n29 ( 0.48%)\n33 ( 0.48%)\n38 ( 0.47%)\n43 ( 0.61%)\n48 ( 0.52%)\n58 (0.65%)\n65 ( 0.78%)\n83 ( 0.91%)\n137 (1.37%)\n352 (3.41%)\n711 (5,85%)\n\nTable 2. Top-10 Countries Producing\nResearch on Solar Energy- 1995/2009\n(WoS, 2012)\n1995-1999\nPublications\n2,580\nUSA\n(28.63%)\n1,006\nDEU\n(11.16%)\n849\nJPN\n(9.42%)\n484\nIND\n(5.37%)\n450\nENG\n(4.99%)\n420\nFRA\n(4.66%)\n343\nAUS\n(3.81%)\n260\nSPA\n(2.89%)\n259\nCAN\n(2.87%)\n249\nITA\n(2.76%)\n129 countries\n9,011\ndocs in total\n\n2000-2004\nPublications\n3,096\nUSA\n(23.79%)\n1,669\nDEU\n(12.83%)\n1,650\nJPN\n(12.68%)\n643\nCHN\n(4.94%)\n612\nENG\n(4.7%)\n579\nFRA\n(4.45%)\n510\nIND\n(3.92%)\n505\nSPA\n(3.88%)\n464\nNLD\n(3.57%)\n445\nAUS\n(3.42%)\n131 countries\n13,012\ndocs in total\n\n2005-2009\nPublications\n6,038\nUSA\n(22.25%)\n3,535\nCHN\n(13.03%)\n2,643\nJPN\n(9.74%)\n2,500\nDEU\n(9.21%)\n1,241\nKOR\n(4.57%)\n1,217\nIND\n(4.48%)\n1,123\nSPA\n(4.14%)\n1,080\nFRA\n(3.98%)\n1,031\nENG\n(3.8%)\n828\nITA\n(3.05%)\n144 countries\n27,138\ndocs in total\n\nInternational Scientific Collaboration\nFigures 1 and 2 show the international\nresearch collaboration patterns for both\ncountries with regard to the percentage\nof publications that present this\ncollaboration, as well as the number of\nauthors from different institutions by\ncountry.\n\nFigure 1. Collaboration Patterns in Solar\nEnergy (Germany). WoS, 2012\n2127\n\nFigure 2. Collaboration Patterns in Solar\nEnergy (Spain). WoS, 2012\n\nTable 3 shows the countries that\ncollaborate in Spain and Germany\npublications. For Spanish researchers,\nGermany is the first country with they\ncollaborate, then USA. USA is the main\npartner of Germany in this area, while\nSpain ranks fourth.\nTable 3. Top-10 countries collaborating\nwith Spain and Germany on Solar Energy\nresearch -1995/2009 (WoS, 2012).\nSPAIN\nNo. of\nNo. of\nCountries\nDocs.\n61\n1,716\nCountry\nDocs.\nDEU\n163\nUSA\n97\nGBR\n77\nFRA\n76\nCHE\n43\nITA\n42\nPRT\n31\nMEX\n28\nISR\n24\nNLD\n24\n\nGERMANY\nNo. of\nNo. of\nCountries\nDocs.\n81\n4,793\nCountry\nDocs.\nUSA\n369\nGBR\n176\nFRA\n171\nSPA\n163\nCHE\n141\nNLD\n139\nJPN\n121\nITA\n98\nAUS\n97\nAUT\n88\n\nConclusions\nGermany represents the top EU\ncountries in the three different periods\nanalysed,\nalthough\nits\npresence\ndecreases in percentages. The case for\nSpain is the opposite, as the percentage\n\n2128\n\nof publications increases during the third\nperiod and it goes up one position to be\namong the Top-10 countries.\nThe collaboration profiles for both\ncountries are very similar, despite the\nfact that the percentage of international\ncollaboration for Spain decreases during\nthe third period.\nGermany is the top country regarding\ncollaboration with Spain, followed by\nthe USA, while the USA is the top\ncountry regarding collaboration with\nGermany, with Spain coming into fourth\nplace in this context.\nAcknowledgments\nThis research was funded by the Spanish\nMinistry\nof\nEconomy\nand\nCompetitiveness under the project\nCSO2010-21759-C02-01\nentitled,\n“Análisis de las capacidades científicas\ny tecnológicas de la eco-economía en\nEspaña a partir de indicadores\ncuantitativos y cualitativos de I+D+i”,\ncarried out by the Carlos III University\nof Madrid.\nReferences\nSanz-Casado, E., García-Zorita, J. C.,\nSerrano-López, A. E., Larsen, B., &amp;\nIngwersen, P. (2012). Renewable\nenergy research 1995–2009: a case\nstudy of wind power research in EU,\nSpain, Germany and Denmark.\nScientometrics, 95 (1), pp 197-224.\nWalz, R., Schleich, J., &amp; Ragwitz, M.\n(2011). Regulation, Innovation and\nWind Power Technologies–An\nempirical analysis for OECD\ncountries. Paper presented at the\nDIME Final Conference.\nWeb of Science. Available at:\n[http://thomsonreuters.com/products\n_services/science/science_products/a\n-z/web_of_science/].\n\nSCIENTIFIC PRODUCTION OF TOP BRAZILIAN\nRESEARCHERS IN BIOCHEMISTRY,\nPHYSIOLOGY, PHARMACOLOGY AND\nBIOPHYSICS\nDaniel Henrique Roos; Luciana Calabró; João Batista Teixeira da Rocha; Diogo\nO. G. de Souza.\ndaniel_varzeano@hotmail.com; luciana.calabro.berti@gmail.com; diogo@ufrgs.br;\njbtrocha@yahoo.com.br\nFederal University of Rio Grande do Sul, Departamento de Bioquímica, Rua Ramiro\nBarcelos, 2600 – anexo, Porto Alegre, RS (Brazil)\nIntroduction\nIn many developing countries, including\nBrazil, there has been an increasing\nawareness of the need to develop\nscience. In Brazil institutionalization of\nscience is recent, when compared to\nEurope and USA [1]. In recent decades,\nan expressive expansion of scientific\nproduction in Brazil has occurred in\nbiological sciences. Currently, the\ncountry accounts for 46.6% of the\nscientific production in Latin America\nand 1.75% of world production. About\ntwo decades ago the country accounted\nfor 0.5% of world production [2]. Main\nreasons for this increase are the stability\nof the investment in research and\nchanges in the policies of the main\nfunding agencies [1].\nThe National Council for Scientific and\nTechnological Development (CNPq)\nsupports monetarily researchers with\nhigh scientific productivity. The\nfinancial support is for particular use (all\ngrades of researchers, i.e., PQ-2 (the\nlowest level), PQ 1D, 1C, 1B and 1A\n(the highest) and for the use in the lab\n(for level 1 researchers). There is also a\nfinancial support to senior researchers\n(normally retired ones) to be used in\nresearch related activities (PQ-Sr). This\n\nwork aims determine and compare the\nprofile of publication in scientific\njournals of researchers in the level 1 (PQ\n1C-A) in order to get a picture of the\npublications by the top investigators in\nbiochemistry, pharmacology, biophysic,\nphysiology and basic neuroscience\n(which is called BF in CNPq and\ncomprises the biological sciences II in\nthe Coordination for postgraduate\npersonnel improvement, CAPES). The\nresults presented here can inform CNPq\nand CAPES about the productivity of\nPQ-1 of Biological Sciences II and thus\npartially contribute to determine the\neffectiveness of funding science in\nBrazil.\nMethodology\nThe present study analyzed the scientific\nproduction of senior researchers’\nfellows from CNPq in the subareas of\nPhysiology\n(including\nbasic\nneurosciences),\nBiochemistry,\nPharmacology and Biophysic (which is\ncalled BF). The scientific production of\nresearchers was analyzed during all\nproductive live of researchers.\nThe data were obtained for all\nresearchers’ fellows included in the\nCNPq category of PQ-1 (1A, 1B, 1C).\nThe total number of PQ-1 in BF area of\n2129\n\nCNPq is 228. The analysis included:\nnumber of articles published; authoring\ntype (publication as first author or as last\nauthor), number of citations; h-index.\nThese data were obtained from the\ndatabase of Scival - Scopus).\n\nFig. 1 Number of article published by\nresearcher fellows; circle 1A; square 1B;\ntriangle 1C; n= 76.\n\nFig. 2 Number of citation by researcher\n2A; number of citation by researcher\nwithout self-citations of all authors of the\narticle 2B; circle 1A; square 1B; triangle\n1C; n= 76.\n\n2130\n\nResults\nAs expected the number of articles\npublished\nby\nresearcher\nfellow\ndecreased gradually with researcher\nlevel (1A, 1B, 1C respectively; Fig. 1).\nThe results also demonstrated that the\nsome of these researches have published\nmore than 300 articles in journals\nevaluated by scopus (www.scopus.com)\nduring their career .\nThe average of citations by researchers\ngroup is shown in Fig. 2A. In order to\nanalyze the influence of articles in the\nliterature, the data were evaluated\nwithout the self citations of all authors\n(Fig. 2B). The results indicated that the\nnumber of citation decrease ≈ 32%\nwhen self citations of all authors were\nexcluded (Fig 2 A and B). Similarly, the\nh-index of researchers decrease ≈ 23%\nwhen self citations were excluded.\n\nFig. 3 h-Index of researchers 3A; h-Index\nof researchers without the self-citations of\nall authors of the article 3B; circle 1A;\nsquare 1B; triangle 1C; n= 76.\n\nThe Figure 4 exhibit the number of\narticles as first and last author published\nin the last 10 years. This figure shows\nthe autonomy of research, since the\nlast/first author is expected to answer\nquestions of reviewers and interacts with\nthe\njournal\nand\nthe\nscientific\ncommunity.\n\nquantitative/qualitative\nparameters\nevaluated within the sublevels 1A, 1B,\n1C. However, it is possible to observe\nthat the mean of quantitative parameters\nanalyzed varies in accordance with the\nresearcher level. However, the reasons\nfor the overlapping between the research\nlevels deserve a more detailed analysis.\nAcknowledgements\nThis work was supported by grants\nfrom, UFSM; UFRGS; FAPERGS;\nCAPES; CNPq; FINEP (IBN-Net) and\nINCT-EM.\n\nFig. 4 The number of articles by\nresearcher fellows as first and last author\npublished in last 10 years; circle 1A;\nsquare 1B; triangle 1C; n= 76.\n\nConclusions\nThe performance of top Brazilian\nresearchers (PQ-1) in the BF area of\nCNPq reveals that there no was\nhomogeneity\nin\nthe\n\nReferences\n[1] Zorzetto R., Razzouk D., Dubugras\nM.T.B.,\nGerolin J., Schor N., Guimarães J.A.\nMari J.J. (2006) The scientific\nproduction in health and biological\nsciences of the top 20 Brazilian\nuniversities. Br. J. Medic and Biol.\nRes. 39: 1513-20\n[2] De Meis, L. Arruda, A.P Guimarães,\nJ. (2007). The Impact of Science in\nBrazil. IUBM Life, 59(4), 227-234.\n\n2131\n\nA SIMPLE METHOD TO ASSESS THE QUALITY\nOF ANY UNIFICATION PROCESS\nMendez-Vasquez Raul Isaac1*; Vila Domènech Joan Salvador2;\nSuñén-Pinyol Eduard3*; Olivé Vázquez Gerbert4\n1\n\nrmendez@prbb.org and 3esunen@prbb.org\nBibliometrics Unit, Barcelona Biomedical Research Park Foundation (FPRBB). C/ Doctor\nAiguader, 88 E08003 Barcelona, (Spain)\n2\n\njvila@imim.es and 4jolive@imim.es\nStatistical Unit, Computing resources, IMIM-Institut Hospital del Mar d&#x27;Investigacions\nMèdiques. C/ Doctor Aiguader, 88 E08003 Barcelona, (Spain)\n\n2\n\n4\n\n*Present address: 1raul.mendez@fundaciorecerca.cat and\n3\neduard.sunen@fundaciorecerca.cat\nFundació Catalana per a la Recerca i la Innovació (FCRI). Psg. Lluís Companys, 23\nE08010 Barcelona, (Spain)\nIntroduction\nAccording to Van Raan (2005) the\nattribution\nof\npublications\nto\norganizations is one of the most\nimportant technical problems to solve\nwhen building reliable bibliometric\nreports.\nAttributing publications to a specific\norganization based on the data in\naddress field is not trivial, and doing it\nright may be problematic and time\nconsuming, especially when the focus of\nstudies moves below the national (Butler\n1999).\nThe presence of variants of names of\norganizations, and of locations, in\ncitation indexes has been reported as\none of the main sources of troubles\n(Anderson 1998), (Leydesdorff 1988),\nand (Bourke1996). Added, a number of\nsituations increase the complexity of this\nprocess: 1) structural and name changes\nin organizations (Van Raan 2005), 2)\nmulti-located institutions (de Bruin\n1990), 3) presence of multi-affiliated\nresearchers (Butler 1999), 4) missing\n2132\n\npieces of information about “mother”\norganizations in addresses (de Bruin\n1990), or 5) interactions with other\ninstitutions. Further, these factors may\nalso show regional peculiarities.\nOn the one hand, it is very likely that\nauthors will continue to enlarge the list\nof variants of names and locations in\ncitation indexes. On the other,\nacknowledging that there is certain level\nof error in every measure might be of\nhelp in finding better ways to deal with\nthis problem. From this perspective the\nmain challenge in producing reliable\nreports would be achieving a reasonably\nhigh level of precision (admitting that\nerror will always be present) in a\nreasonably short period of time which\nmay be more interesting to final users.\nThe aim of the present study is to show\na simple method to ensure an “at most”\npercentage of error in any unification\nprocess.\nMethods\nModeling the problem. The number of\naddresses\ncorrectly\nmapped\nto\n\nrespective organizations can be used as\nindicator of the quality of an unification\nprocess. Thus, assessing its quality\nwould only require examining addresses\nto classify each case as either\n“correctly” or “wrongly” attributed.\nSuch type of experiments are Bernoulli\ntrials, as only one of the two outcomes is\npossible, and a series of experiments\nhave a binomial distribution X~B(n,p).\nApparently the binomial function would\nsolve\nour\nchallenge.\nHowever,\nexamining a fixed number of addresses\ncould lead to the analysis of nonrepresentative samples of address, and\nexamining all addresses is simply not\nfeasible because their large number.\nFortunately, a series of independent\nBernoulli trials also have negative\nbinomial distributions X~NB(r,p), which\nprovide the probability distribution of\nthe number of successes before a\nspecified number of failures “r” occur.\nIn our case a success corresponds to a\nwrongly attributed address and failures\nto the number of correctly attributed.\nThe probability of success p is 0.03 in\nthe case of a maximum percentage of\nerror of 3% and 0,05 for a maximum of\n5%.\nResults\nImplementing the solution. Using a NB\nenable setting in advance an upper\nthreshold to 1) the percentage of error\nthat we “tolerate” p, and 2) the statistical\nconfidence of the test. In Table 1 the\nsizes of the samples and the maximum\nnumber of errors are calculated using\nthe pnbinom() function in R for maximal\nlevels of error of 3% and 5%, with 95%\nand\n99%\nstatistical\nconfidence\nrespectively.\nThus\nfor\nexample,\nassuming that addresses have been\nattributed with a 3% error, there are\n95% chances that a wrong case occurs in\na random sample of 99 addresses. So, if\nthe examination delivers no wrong case,\n\nwe can ensure, with a 95% confidence,\nthat the error is less than 3%.\nThe result of performing theses phases\niteratively (sampling, examination and\ncorrection) is a quality assessment (QA)\nmethod for achieving a particular level\nof accuracy in any unification process.\nDiscussion\nThe presence of variants of names and\nlocations in citation indexes causes\ntroubles during the unification of\naddresses, a problem known for quite\nlong time now (Butler 1999), (de Bruin\n1990).\nTable 1. Sizes of the random samples and\nmaximum number of errors tolerated\n95% conf. error\n&lt; 3%\n#trials1\n#errors2\n99\n0\n157\n1\n208\n2\n257\n3\n303\n4\n348\n5\n99% conf. error\n&lt; 3%\n#trials1\n#errors2\n152\n0\n219\n1\n277\n2\n332\n3\n383\n4\n433\n5\n\n95% conf. error\n&lt; 5%\n#trials1\n#errors2\n59\n0\n93\n1\n124\n2\n153\n3\n181\n4\n208\n5\n99% conf. error\n&lt; 5%\n#trials1\n#errors2\n90\n0\n130\n1\n165\n2\n198\n3\n229\n4\n259\n5\n\n1, size of the random sample of addresses; 2,\nmaximum number of errors (“wrongly” attributed\naddresses) allowed in the sample.\n\nSurprisingly, to our knowledge there are\nno publications describing methods to\nassess the accuracy of this process.\nThe present method allows ensuring, by\nstatistical means, a specific level of\naccuracy of any unification process\nwhen applied iteratively. The benefits of\nits application include: 1) ensuring a\nspecific level of accuracy independently\nof the level of the study (macro, meso or\n2133\n\nmicro), 2) enables assessing the quality\nof unifications of locations, 3) enables\naligning “delivery time” and client\nneeds, since early previews or “reports\non trends” may be provided based on\ndata unified at different levels of\naccuracy, 4) enables identifying “big”\nerrors caused by recent changes in the\nstructure of organizations and also rare\nvariants, both of which improves the\nefficiency and the quality of the\nunification.\nThe results of the application of the\npresent method will depend on the\ndefinition of the “wrong case”, which\nmay vary on a study base.\nIn our opinion, a less than pleasant\nscenario lies ahead for our community\nin the next years. It is likely that errors\nin addresses will continue to occur even\nin greater number in citation indexes,\nand the “press the button” attitude is\nvery likely to spread even more among\nfinal users of bibliometric reports. The\ncombination of these trends will\nincrease the pressure on practitioners\ncommitted to working with scientific\nrigor. We hope that this method\nprovides a new perspective for dealing\nwith errors.\nLimitations\nThe present method does not address the\nissue of missing addresses; it is based on\nexisting data. As for not fully\ninformative address, they are equally\nprobable of being sampled during the\nQA. It depends on both, reviewers to\nunify them, and on experts to tag them\nas “correct” or “wrongly” attributed\naccording to the aim of studies. Future\nstudies should address the issue of\nmissing addresses in order to estimate\nthe size and the effect of this\nphenomenon\non\nbibliometrics\nindicators.\n\n2134\n\nConclusion\nThe present method provides a new\napproach to producing reliable reports\nwith a reasonably high level of precision\nin a reasonably short period of time.\nMeasuring the magnitude of “error” and\neventually its effect on indicators,\ninstead of neglecting its presence in\nreports, is a scientific attitude that will\nprobably benefit all practitioners.\nHopefully this approach will also lead to\nnew ways of interpreting bibliometric\nreports more cautiously and responsibly,\nwhich in turn will probably improve the\nacceptance of bibliometric methods\ninside and outside our community.\nHowever, a widely agreed-upon\nrecommendation for best practice in\nnormalizing addresses is absolutely\nnecessary to improve comparability of\nbibliometric reports.\nReferences\nAnderson J., Collins, P. M. D., Irvine, J.,\nIsard, P. A., Martin, B. R., Narin, B.\nR., Stevens, K. (1988). On-line\napproaches to measuring national\nscientific output: A cautionary tale,\nScience and Public Policy, 15,153–\n161.\nBourke, P., Butler, L. (1996). Standards\nissues in a national bibliometric\ndatabase: The Australian case.\nScientometrics, 35,199–207.\nButler L. (1999). ‘Who ‘Owns’ this\nPublication?’, in Proceedings of the\nSeventh Conference of the\nInternational Society for\nScientometrics and Informetrics\n(ISSI ‘99) (pp. 87-96).\nde Bruin R.E., Moed H.F. (1990). The\nunification of addresses in scientific\npublications. In: Egghe L., Rousseau\nR. (editors.), Informetrics, (pp 6578) Elsevier Science Publichers B.V.\nLeydesdorff, L. (1988). Problems with\nthe ‘measurement’ of national\n\nscientific performance. Science and\nPublic Policy, 15,149–152.\nVan Raan A. F. J. (2005). Fatal\nattraction: Conceptual and\n\nmethodological problems in the\nranking of universities by\nbibliometric methods.\nScientometrics, 62(1),133-143\n\n2135\n\nSTRUCTURE ANALYSIS OF SMALL PATENT\nCITATION NETWORK AND MAPPING\nTECHNOLOGICAL TRAJECTORIES\nYanling Wang1,2\n1\n\nviolin@whu.edu.cn\nInformation Management School, Wuhan University, 430072, Hubei Province,\nP.R.China\n2\nWuhan Institute for Science of Science, 430023, Hubei Province, P.R.China\n\nIntroduction\nThe theory of technological trajectories\nargues that the development of a\ntechnology is along some specific\ntechnology trajectories. The technology\ntrajectories can be used to explore the\nhistory of a technology area or to predict\nthe technological future or discovery a\nnew technology opportunities. Past\nresearches on mapping technologies as\npatent citation networks mostly based on\nthe large network, such as the fuel cell\npatent citation network (Verspagen\n2007)which is composed of 15506\nnodes and more than one million\nrelations. The patent citation network of\ncoronary artery disease was composed\nof 5,136 patent documents that granted\nbetween 1979 and 2003 (Mina,\nRamlogan et al. 2007). There are 22,095\nnodes in the network.\nHowever, as we know some patent\nnetworks of specific technology area are\nnot as large as those networks I\nmentioned before. There are maybe only\nhundreds of nodes in the network, and\nthe scale of the citation matrix mostly is\nnot more than 100,000. If the research\nlocates at these technology areas, the\nmethod to discover or identify the\ntrajectories is not as same as that applied\nin large networks.\nRadical technological breakthroughs and\nincremental technological innovations\n2136\n\nare considered as the different\ntechnology evolution paradigm. No\nmatter radical or incremental technology\ninnovations are specific technological\ntrajectories. And the critical technology\n(or patent) just like a chain of pearls,\ncomposes the track of the development\nof\na\ntechnology.\nTechnological\ntrajectory theory argued that there must\nbe a method to identify the trajectory no\nmatter the area is broad or just narrow.\nThis paper explored the method to\ndiscover the key technology nodes or\ntechnology trajectories of narrow area.\nWith the thorough analysis of the\nstructures of two small patent citation\nnetworks, the characteristics of a small\nnetwork have been concluded.\nData\nPatent data this paper used come from\nthe BASICBIB database and USCITES\ndatabase (Bhaven, 2011), which were\nconstructed by Bhaven N. Sampat\nprofessor from Columbia University.\nThe database BASICBIB includes basic\n&quot;front page&quot; data for patents issued from\nJanuary 1, 1975 to December 31, 2010.\nThe database USCITES includes U.S.\npatent citations in utility patents issued\nfrom1/1/1975 to 12/31/2010. Each\nobservation is a citing-cited pair. These\ntwo database are based mainly on\ninformation from a custom extract DVD\ngenerated by the Electronic Information\n\nMain Paths Analysis\nThe Main Path algorithm identifies the\nmost important papers and streams of\ngrowth or development in a citation\nnetwork.187 ( Critical Path Method,\nCPM)\n186\n\nThe environmentally sound technologies\n(EST) concordance was issued by USPTO in\n2010.\nhttp://www.uspto.gov/web/patents\n/classification/international/est_concordance.\nhtm\n187\nHummon and Doreian (1989) devised\nthree indices or weights ofedges to\ncomputationally\nidentify\nthe\n(most)\nimportant part of a citationnetwork—its main\npath. Batagelj (2002) developed algorithms\ntoefficiently compute the Hummon and\n\nSubnetwork Extraction\nComponents of a graph are sub-graphs\nthat are connected within, but\ndisconnected between sub-graphs. In\naddition to identifying the members of\nthe components, UCINET calculates a\nnumber of statistical measures of graph\nfragmentation.\n\n19791995\n19792002\n19792003\n19792008\n19792009\n19792010\n\nDistance-based cohesion\n(&quot;Compactness&quot;)\n\nEntropy\n\nNormalized\nheterogeneity\n\nComponents\n\nNo. of Ties\n\nTable1 Index of Network Structure of\nPhotovoltaic Field (1979-2010)\n\nDensity\n\nMethods\nHummon and Doreian(Hummon 1989)\nassign a weight to each citation link on\nthe basis of its position in the overall\nstructure of the network. The method is\nbased on the examination of the\ndifferent ‘search paths’ existing in the\nnetwork. Search paths are sequences of\nlinks that connect the vertices of the\nnetwork.\n\n“The main paths should be viewed as\nthe main flow of ideas characterizing the\nstructure\nof\nthe\nnetwork\nin\nquestion.”(Roberto Fontana 2008)\n\nPeriod\n\nProducts Division of the USPTO on\n4/29/2011. Two of the variables\n(application number and application\ndate) were extracted from the USPTO&#x27;s\nCassisBIB Patents DVD.\nWe use the BASICBIB and USCITES\ndatabase to map patent citation network\nof photovoltaic technology. The USPC\nclass of the field of photovoltaic\ntechnology is defined in the USPTO\nEST Concordance186, and the USPC is\n“136/243+”.\nWe\nsearched\nin\nBASICBIB, there are 36 patents of this\nfield. We search the patent citation data\nin USCITES joined with BASICBIB,\nthere are 462 patent backward citations\nduring 1979-2010. We use UCINET to\nconstruct patent citation network of\n482*482.\n\n0.0619\n\n13\n\n2\n\n0.248 0.145\n\n0.062\n\n0.0244\n\n29\n\n6\n\n0.795 0.458\n\n0.024\n\n0.0117\n\n70\n\n8\n\n0.803 0.409\n\n0.012\n\n0.0064\n\n129 13\n\n0.893 0.471\n\n0.006\n\n0.0030\n\n308 15\n\n0.696 0.316\n\n0.003\n\n0.0020\n\n462 25\n\n0.765 0.354\n\n0.002\n\nResults and Discussion\nIn order to find the reason of the failure,\nwe conclude the index of the network\nstructure of different period, which is\nillustrated in Table 1. All the index of\nnetwork structure is calculated by\nUCINET.\n\nDoreian’s indices so that they canbe used for\nthe analysis of very large citation networks\nwith severalthousands of vertices.\n2137\n\nAlthough the network grows up\ngradually and the nodes in the net\nbecome more and more, the whole net is\nvery loose. The characteristics of small\npatent citation network:low density,\nhigh Fragmentation, more and more\ncomponents, short distance.\nThe network of developer field is also\ncharacterized by the four characteristics.\nFigure 9-Figure13 are the patent maps\nof networks of developer field in\ndifferent period. Table 1 is the index of\nnetwork structure of developer field.\nFrom the analysis, we find that the low\ndensity, high fragmentation, scattered\ncomponents and short distance cause the\nmethods to extract main path of\nHummon and Doreian fail. However, we\ncan search the nodes with high degree\ncentrality or betweeness centrality.\nThese nodes which represent the patents\nthat have dense connectivity with other\npatents are the main technology in the\nfield. Table 2 is the list nodes with high\ncentrality of different network.\nWe select the index of network\nstructure:\nNetwork\nCentralization,\nHeterogeneity,\nNormalized\nHeterogeneity, mean of degree and\nstandard deviation to analyze the\nstructure of the network of components.\nFrom the patent maps of the\ncomponents, only the figure 16 and\nfigure 17 are completely centered, and\nfrom the patent in the core to the other\npatents, there are at least 20 or 30 ways,\nthis kind of network only have one step\nof path. We defined this kind of network\nas unable to be extracted a path from it.\nThe component can be used to represent\nthe trajectory of technology is\ncharacterized:\nLow network centralization. The\ncentralization of the network cannot be\ntoo high. If the centralization is very\nhigh, the network always has star-like\nstructure. There is only one way from\none patent to the patent in the core, and\n2138\n\nother patent is isolated with each other.\nFor this kind of network, the main path\nis equal with the net and in other words\nthat there is no main path or trajectory in\nthis kind of network. In figure 14 and\nfigure 15, the centralization of network\nis 60.6%.In figure 18 and figure 19, the\ncentralization of network is 84.86% and\n98.22%, and the longest path in those\nnetworks is 4-step or 5-step. In figure\n23, the centralization of network is\n33.31%, and the longest path is 13-step.\nAnd in other figures of patent map of\nmain components, the path is only onestep.\nLong path between start node to end\nnode. As we analyzed in the network\ncentralization. The structure of network\nis not star-like, but long and narrow with\nlong path.\nLow Heterogeneity. The heterogeneity\nof the network that figure23 illustrate is\n5.92%, and figure 14 and figure 15 is\n16.32%, figure 18 is 19.11%, figure 19\nis no more than 25%.\nConclusion\nThe past researches on mapping\ntechnologies as patent citation networks\nmostly based on the large network, This\npaper explored the method to discover\nthe key technology nodes or technology\ntrajectories of narrow area. With the\nthorough analysis of the structures of\ntwo small patent citation networks, the\ncharacteristics of a small patent citation\nnetwork and main component of those\nnets have been concluded.\nThe characteristics of small patent\ncitation network: (1) Low density;\n(2) High Fragmentation; (3) More and\nmore components; (4) Short distance.\nThe component can be used to represent\nthe trajectory of technology is\ncharacterized:\n(1)\nLow network\n\ncentralization.; (2) Long path between\nstart node to end node; (3) Low\nHeterogeneity.\nReferences\nBatagelj, V., Mrvar, A., 2003. Pajek:\nanalysis and visualization oflarge\nnetworks’. Department of\nTheoretical Computer\nScience,University of Ljubljana,\nPreprint series, Vol. 41, p. 871.\nBHAVEN, &quot;USPTO Patent and Citation\nData&quot;,\nhttp://hdl.handle.net/1902.1/16412\nUNF:5:ERqPZ7enbwBRimghqDD4\ngQ== Bhaven Sampat [Distributor]\nV4 [Version]\nMina, A., R. Ramlogan, G. Tampubolon\nand J. S. Metcalfe (2007). &quot;Mapping\nevolutionary trajectories:\nApplications to the growth and\n\ntransformation of medical\nknowledge.&quot; Research Policy 36(5):\n789-806.\nRoberto Fontana, A. N., Bart Verspagen\n(2008). &quot;Mapping Technological\nTrajectories as Patent Citation\nNetworks. AN Appllication to Data\nCommunication Standards.&quot; SPRU\nElectronic Working Paper Series No.\n166.\nVerspagen, B. (2007). &quot;Mapping\ntechnological trajectories as patent\ncitation networks: A study on the\nhistory of fuel cell research.&quot;\nAdvances in Complex Systems\n10(1): 93-115.\nBorgatti, S.P., M.G. Everett, and L.C.\nFreeman. 1999. UCINET 6.0\nVersion 1.00. Natick:Analytic\nTechnologies.\n\n2139\n\nSTRUCTURE OF INTERDISCIPLINARY\nRESEARCH: COMPARING LM AND LDA\nQi Wang1 and Ulf Sandström2\n1\n\nqiwang@kth.se\nINDEK, KTH-Royal Institute of Technology, Lindstedtsvägen 30\n100 44 Stockholm, Stockholm (Sweden)\n2\n\nulf.sandstrom@indek.kth.se\nINDEK, KTH-Royal Institute of Technology, Lindstedtsvägen 30\n100 44 Stockholm, Stockholm (Sweden)\nIntroduction\nInterdisciplinary research (IDR) is\nbecoming increasingly important in\ncurrent academic research. It is widely\nrecognized that IDR is related to\nprogress, creativity, and innovation.\nBuilding upon recent literatures,\ndiscussions on IDR focus on different\ntopics. That makes it far more\nchallenging to discern the discussions on\nIDR.\nThis study intends to solve two\nquestions:\n1. From what perspectives current\ninterdisciplinary\nresearch\nare\ndiscussed when researchers refer to\ninterdisciplinary research in their\narticles?\n2. Which method is best for detecting\nsimilarity?\nMethods\nLiterature data analysed in this study\nwere retrieved from Web of Science.\nWe\nselected\narticles\nthat\nuse\n“interdiscipl*”, “multidiscipl*”, and\n“transdiscipl*” as the topic word. The\nreason we selected multidisciplinary and\ntransdisciplinary as research subject is,\nin a broad sense, that those three terms,\nare highly related. They all indicate the\nintegration of “information, data,\n2140\n\ntechniques,\ntools,\nperspectives,\nconcepts, and/or theories from two or\nmore disciplines or bodies of specialized\nknowledge” (Committee on Facilitating\nInterdisciplinary\nResearch\nand\nCommittee on Science, 2005). However,\nthe difference among them lies in the\ndegree of integration (Rosenfield, 1992;\nWickson et al., 2006). However, we do\nnot intend to discuss this difference,\ntherefore\nthe\nterminology\n“interdisciplinary research” is used to\nrepresent all research associated with\ninterdisciplinary, multidisciplinary and\ntransdisciplinary activities. In this\nmanner, 47,631 articles including\nproceeding\npapers\nhave\nbeen\ndownloaded from the year 2002 to 2011.\nIn order to filter noise data, first, we\naggregate the articles by Louvain\nMethod (LM), and 1,196 clusters are\nidentified. Through scanning through\nabstracts of articles, we found that some\nclusters are not associated with IDR;\nespecially most of the clusters were\narticles asking for more interdisciplinary\nteamwork in medicine, but did not\ncontribute to the discussion on IDR in\nitself. That might hide some categories\nwith small number of articles, and thus\nour judgment would be affected. To\ndelete those clusters, we analysed\nabstracts of the two most cited papers in\neach cluster as we assumed that, the\n\nmost cited paper could better represent\nthe category it belongs to. Then, if in\nour judgment abstracts were not\ndiscussing IDR, articles in these\ncategories that were deleted. To make\nthe database as accurate as possible, we\nrepeated the previous step and obtained\n2,930 articles finally. Therefore, we\nhave good reason to believe that the left\n2,930 articles are associated with\ninterdisciplinary discourses.\nLM and Latent Dirichlet Allocation\n(LDA) are applied to identify topics on\nIDR. LM is a modularity-based\nclustering method; in this case,\nsimilarity matrix generated from\nbibliographic coupling (Kessler, 1963)\nis used as input value. The reason we\nchoose bibliographic coupling is that,\nprevious\nstudies\nfound\nthat\nbibliographic\ncoupling\nmethod\ngenerated the most accurate cluster\ncomparing to direct citation method, cocitation method, and co-word analysis\n(Boyack &amp; Klavans, 2010; Ahlgren &amp;\nJarneving, 2008). LDA is a text mining\nmethod based on the Bayesian statistics.\nLatent research topics are identified by\nextracting\nterms\nwith\nsemantic\nsimilarity. As a relatively new method in\nscientometric, LDA and its extended\nmethods like author-topic model have\nbeen used to analyse research similarity\n(Lu &amp; Wolfram, 2012). Due to the\ndifference in analysis objects, citations\nand abstracts of articles, we are\ninterested in comparing the research\ntopics that could be extracted from the\ntwo methods, and try to distinguish\nwhich method performs better. Experts’\nopinions are always used for evaluating\nthe cluster quality; however in this case,\ndiscussions on IDR probably scatter in\nmany research areas. Therefore, it would\nbecome the challenge for this study.\n\nResults\nFirst, we analyse the topics identified by\neach algorithm, and merge the\ncategories with similar themes. Around\n15 clusters discussing IDR have been\nidentified from each method. They\ninclude discussing IDR from the aspect\nof history of science and philosophy of\nscience, interdisciplinary medicine,\ninterdisciplinary education, evaluating\non interdisciplinary from the perspective\nof scientometrics and bibliometrics,\nknowledge management. We consider\nthe remaining categories as general\ninterdisciplinary research, which implies\nthat they promote the use the IDR ideas\nor methods solving such problems as\nimmigration and cultural propagation;\nsustainable\ndevelopment\nand\nenvironment, and ecological problem;\ngeneral business management problems\nlike design and service; juvenile\ndelinquency; complex network problem\netc.\nWe found that topics generated from\neach algorithm are basically unanimous,\nonly with one exception that knowledge\nmanagement are classified as a\nperspective of IDR by Louvain method,\nwhile LDA method does not identify\nthis topic. That may due to LDA defines\nthe term “knowledge” as a stop word\nautomatically,\nwhich\nimplies\nit\nconsiders “knowledge” as a common\nword and cannot provide any\nmeaningful\ninformation\nfor\nthe\ninvestigation.\nSecond, although this finding reveals\nus the discussions on current\ninterdisciplinary research, it does not\nshed light on more detailed information\ncontained in each cluster. To explore\ncharacteristics of the cluster more\ndeeply, we re-examine the frequent\nauthors and frequent references of the\ncluster to provide a more precise and\npowerful interpretation. Due to restrict\nof specialty, we could not give detailed\n2141\n\nanalyse on each cluster. In this case, we\ntake the topic about measurement and\nevaluation on IDR generated form LM\nalgorithm as an example. From most\nfrequent references, it seems that some\npublications are not relevant to IDR like\nSocial network analysis, Introduction to\nmodern information retrieval. We think\nthis happens because knowledge related\nto network analysis and informetrics are\napplied to measure and evaluate the\ninterdisciplinary research. Therefore,\nsome publications about network\nanalysis and information retrieval study\nwere frequently cited by articles in this\ncluster.\nPublications written by Leydesdorff L.,\nPorter A.L. and Morillo F. are widely\ncited in this cluster. And researchers like\nLeydesdorff L., Porter A.L. and Rafols,\nI. are the top 3 active authors. That is in\naccordance with our understanding of\nthis cluster.\nTable 1. Most frequent references and\nauthors\nMost frequent references\nWasserman S, 1994, Social\nnetwork analysis: Methods\nand applications\nSalton G, 1983,\nIntroduction to modern\ninformation retrieval\nBoyack KW, 2005,\nMapping the backbone of\nscience\nAhlgren P, 2003,\nRequirement for a\ncocitation similarity\nmeasure, with special\nreference to Pearson’s\ncorrelation coefficient.\nMorillo F, 2003,\nInterdisciplinarity in\nscience: A tentative\ntypology of disciplines and\nresearch areas.\n\n2142\n\nMost\nfrequent\nauthors\nLeydesdorff,\nL\nPorter, AL\nRafols, I\nFegert, JM\n\nZiegenhain, U\n\nThird, to compare which method\nperforms better, we dig deeper on the\ntopic about measurement and evaluation\non IDR. According to LM, 61 articles\nare included in this cluster. However,\nafter reading abstracts of each article,\nwe found around 20 articles are not\nabout this topic. Then, we sorted the\narticles according to their probabilities\nof measurement and evaluation on IDR.\nThrough analysing abstracts of the 61\ntop articles, we found that 55 of these\narticles are certainly associated with\nmeasurement and evaluation on IDR.\nMore systematically comparisons will\nbe conducted in future research.\nReference\nBlondel, V.D., Guillaume, J.-L.,\nLambiotte, R. &amp; Boyack, K.W. &amp;\nKlavans, R. (2010). Co-Citation\nAnalysis, Bibliographic Coupling,\nand Direct Citation: Which Citation\nApproach Represents the Research\nFront Most Accurately? Journal of\nthe American Society for Information\nScience and Technology, 61(12),\n2389-2404.\nCommittee on Facilitating\nInterdisciplinary Research and\nCommittee on Science. (2005)\nEngineering, and public policy,\nfacilitating interdisciplinary\nresearch, the national academies.\nWashington, DC: The national\nacademies press.\nKessler M.M. (1963). Bibliographic\ncoupling between scientific papers.\nAmerican Documentation, 14(1), 1025.\nLu K. &amp; Wolfram D. (2012). Measuring\nAuthor Research Relatedness: a\ncomparison of Word-Based, TopicBased, and Author Cocitation\nApproaches. Journal of the\nAmerican Society for Information\nScience and Technology, 63(10),\n1973-1986.\n\nTHE STUDY AND ASSESSMENT OF RESEARCH\nPERFORMANCE AT THE MICRO LEVEL: THE\nAGE PHASE DYNAMICS APPROACH\nVictor Rybachuk1* and Galena Quist2\n1\n\nvnyugvpr@yandex.ru; rybachuk.v.p@nas.gov.ua; *corresponding author\nThe National Academy of Sciences of Ukraine, G.M. Dobrov Center for Science &amp;\nTechnology Potential and Science History Studies, 60 Blvd T. Shevchenko, 01032 Kyiv\n(Ukraine)\n2\n\ngvqr@live.com\nGhent University, Salisburylaan 133, B-9820 Merelbeke, Ghent (Belgium)\nIntroduction\nOne of the central problems in micro\nlevel evaluation of scientific activity\neffectiveness is the relationship of\nproductivity and quality of scientific\npublications to the age of the scientist.\nDespite the progress achieved in this\nfield, the topic still remains actively\nresearched and debated (see for example\nBonaccorsi &amp; Daraio, 2003; Costas, van\nLeeuwen &amp; Bordos, 2010; Hörlesberger,\nHolste, Schiebel et all, 2011;\nReijnhould, Costas, Noyons, Boerner &amp;\nSharnhorst, 2013). In the present study,\ninvestigations of the relationship\nbetween scientist’s age and their\npublication activity are discussed in the\ncontext of Age Phase Dynamics (APhD)\nmodel of scientific performance (Pelz &amp;\nAndrews, 1966; Malitsky, 1988;\nRybachuk, 2005).\nMethodology\nPelz &amp; Andrews (1966) found a bimodal\ndependence between productivity and\nage of the scientists. They divided the\nlife cycle of scientific performance into\nindividual phases and highlighted the\nmain factors responsible for the wavelike age dynamics of the scientist’s\npublication activity. Fox\n(1983)\n\ninterpreted the discovered wave-like\npattern to be a consequence of authors’\nconsidering not only the selected major\nworks of the scientist, but a wider\nspectrum of publications, including\narticles, patents, presentations, as well\nas manuscripts. Later, Malitsky (1988)\ndefined the basis of the model proposed\nby Pelz and Andrews, reformulated and\nfurther developed it to become a\n“principle\nof\nphase\ndynamic\ndevelopment of researcher&#x27;s scientific\nactivity”. In our opinion, the age phase\ndynamics approach integrates the\nelements of econometric models and\nmodels of human capital, in terms of the\nsociology of science.\nMethod\nThe main criteria for selection of\nbibliographies for analysis were allinclusive coverage of publications and\nthe availability of their bibliometric\ndata. Unpublished materials, electronic\nand media publications were not\nincluded. References in analyzed\nbibliographies (not shown) were\nconfirmed in Scopus and Google\nScholar scientometric databases.\n\n2143\n\nResults and Discussion\nThis poster presents some preliminary\nresults of age phase dynamics analysis\n(APhD-analysis) of the scientific\nbibliographies\nof\n14\nrenowned\nscientists. The selected scientists\nconducted research in a different field\nfrom each other and during different\nhistorical periods. APhD-analysis of\nbibliographies of four representative\nscientists are shown in Figures 1 and 2.\n\nTypes of\nKnowledge\nMovement\nAccumulation\nProduction\nTransmission\n\nPhases of Development of\nScientific Activity\nI\nIIa\nIIb\nIIIa IIIb\n+\n+\n+\n+\n+\n+\n+\n+\n+\n\nFigure 1. Age dynamics of publications of\nT.S. West (Kalyane &amp; Munnolli, 1995) (A)\nin comparison with productivity obtained\nfor groups of scientists by B. Malitsky\n(1988, p. 95, Fig. 11) (B) and by D. Pelz\nand F. Andrews (1973, Rus. Ed., p. 285,\nFig. 57) (C). (The scientific productivity\nindicator axis is approximate).\n\nFigure 1 shows the curve of a British\nchemist, Thomas S. West (1927-2010)\nas compared to those of other scientists\npublished by Malitsky (1988) and Pelz\n&amp; Andrews (1966). Figure 2 shows the\ncurves of an American, 2001 Nobel\nLaureate\nin\nPhysiology/Medicine,\nLeland H. Hartwell (born 1939); a\nFrench 1991 Nobel Prize laureate in\nPhysics, Pierre-Gilles de Gennes (19322007); and a Ukrainian economist,\nGennady Dobrov (1929-1989). The\n2144\n\nproductivity curves in each phase of\nscientific performance life-cycle clearly\nindicate the most common type of\nscientific activity (movement of\nknowledge), and the nature of scientific\nand organizational functions of the\nscientists (performing, guiding, training,\nconsulting) in the corresponding period\nof their career (see table in Fig. 1).\nNotable is that Phase 1 in the\npublication activity of many authors is\nusually unremarkable.\nThe indicated general pattern of APhD\nof scientific activity (Fig. 1) may be\ncomplicated by the influence of various\nnon-systemic factors that reflect\nsubjective circumstances and external\nconditions during the scientist’s career.\nIn particular, the nature of the research\n(theoretical or experimental), the field of\nscience, the change of scientific focus,\nfollowing the principle of &quot;Publish or\nPerish&quot;, and so forth may alter the\npattern.\nFig. 2 illustrates the differences in the\ntypes of APhD as related to the\nresearcher’s field of science: Physics\n(G), Molecular Biology and Genetics\n(H), and Economics and Sociology of\nScience (D).\n\nFigure 2. APhD of publications of G.M.\nDobrov (curve D), L.H. Hartwell (H) and\nP.-G. de Gennes (G). Graphs are shown in\nthe form of trends of linear filtration\nmethod with a period of 3 years.\n\nWe attempted to establish classification\ncriteria for individual APhD-profiles\nand considered their further integration\nwithin the publication profiles of small\nresearch groups and laboratories as well\nas large groups of scientists (meso\nlevel),\nalso\nincorporating\nthe\ninterrelationship with citation indices\n(data not shown). Encouraging in this\nrespect, are the data recently published\nby Costas, van Leeuwen, &amp; Bordons\n(2010). Age profiles of a total number of\npublications\nand\ncitations\nper\npublication (Fig. 6 and Fig. 7 in\nreferenced article) that they obtained at\nmeso level are in good agreement with\nthe typical individual APhD-profiles at\nmicro level, presented in this work.\nFurther Research\nThis work was carried by G.M. Dobrov\nCenter for S&amp;T Potential and Science\nHistory Studies of Ukrainian NAS, as\npart of the BILAT-UKRAINA project\nwithin the European Commission FP7INCO-2012-2.2\ngrant\nagreement\n311839. As part of this project, we plan\nto evaluate the effect of international\nscientific cooperation, in particular that\nof Ukraine and the EU, on the APhDprofiles of scientific activity.\nReferences\nBonaccorsi, A., &amp; Daraio, C. (2003).\nAge effects in scientific productivity.\nScientometrics, 58(1), 49-90.\nCostas, R., van Leeuwen, T. N., &amp;\nBordons, M. (2010). A bibliometric\nclassificatory approach for the study\nand assessment of research\nperformance at the individual level:\nThe effects of age on productivity\nand impact. Journal of the American\nSociety for Information Science and\nTechnology, 61(8), 1564-1581.\nFox, M. F. (1983). Publication\nproductivity among scientists: A\n\ncritical review. Social Studies of\nScience, 13(2), 285-305.\nHörlesberger, M., Holste, D., Schiebel,\nE., Roche, I., Francois, C., Besagni,\nD., &amp; Cuxac, P. Measuring the\nPreferences of the Scientific\nOrientation of Authors from their\nProfiles of Published References. In\nEuropean Network of Indicator\nDisigners (7-11September, 2011).\nRome, ENID.\nKalyane, V. L., &amp; Munnolli, S. S.\n(1995). Scientometric portrait of T.S.\nWest. Scientometrics, 33(2), 233256.\nMalitsky, B.A. (1987). Phase dynamics\nof scientific activity and impact of\nscientist’s efforts / In V.E. Tonkal &amp;\nG.M. Dobrov Eds., Scientific and\ntechnical potential: Structure,\ndynamics, efficiency (pp. 88-101).\nKiev: Naukova Dumka.\nPelz, D. C., &amp; Andrews, F. M. (1966).\nScientists in organization:\nProductive climates for research and\ndevelopment. J. Wiley.\nPelz, D., &amp; Andrews, F. (1973).\nScientists in organizations: Optimal\nconditions for research and\ndevelopment (471 pp.). Ed. in\nRussian, Moscow: Progress.\nReijnhoudt, L., Costas, R., Noyons, E.,\nBoerner, K., &amp; Scharnhorst, A.\n(2013). &quot; Seed+ Expand&quot;: A\nvalidated methodology for creating\nhigh quality publication oeuvres of\nindividual researchers. arXiv\npreprint arXiv:1301.5177.\nRybachuk, V.P., Grachev, O.A.,\nKukhtenko, T.A. &amp; Videnina, N.G.\n(2005). Defining the general and\nspecific bibliometric characteristics\nof research activities of scientists.\nNauka ta Naukoznavstvo (Science\nand Science of Science), 4\n(Addendum), 105-112.\n\n2145\n\nTHE SUBJECT CATEGORIES NORMALIZED\nIMPACT FACTOR\nPablo Dorta-González1 and María-Isabel Dorta-González2\n1\n\npdorta@dmc.ulpgc.es\nUniversidad de Las Palmas de Gran Canaria (Spain)\n2\n\nisadorta@ull.es\nUniversidad de La Laguna (Spain)\n\n2146\n\nImpact per Paper (Leydesdorff &amp;\nOpthof, 2010).\nIn addition to the average number of\nreferences, there exist some other\nsources of variance. In this work we\ndecompose the aggregated impact factor\ninto five main sources of variance and\ncalculate them in all the categories of\nthe JCR. Furthermore, a normalization\nprocess considering all journals in the\nindexing categories is proposed.\n10\n\n8\nAggregate\nImpact Factor\n\nIntroduction\nDuring decades, the journal impact\nfactor (IF) has been an accepted\nindicator in ranking journals. However,\nthere are increasing arguments against\nthe fairness of using the IF as the sole\nranking criteria (Dorta-González &amp;\nDorta-González, 2010, 2011, 2013).\nThese indicators are not comparable\namong fields of science for two reasons:\n(i) each field has a different impact\nmaturity time, and (ii) because of\nsystematic differences in publication\nand\ncitation\nbehaviour\nacross\ndisciplines. Therefore, citation-based\nindicators need to be normalized for\nsuch differences.\nThere are statistical patterns which are\nfield-specific\nand\nallow\nthe\nnormalization of the IF. Garfield\nproposes the term ‘citation potential’ for\nsystematic differences based on the\naverage number of references per paper.\nThe fractionally counted IF corrects\nthese differences in terms of the sources\nof the citations. Zitt &amp; Small (2008)\npropose the Audience Factor using the\nmean of the fractionally counted\ncitations to a journal. Similarly, Moed\n(2010) divides a modified IF by the\nmedian number of references in the\nScopus database. He proposes the\nresulting ratio as the Source Normalized\n\n6\n\n4\n\n2\n\n0\n1\n\n21\n\n41\n\n61\n\n81\n\n101\n\n121\n\n141\n\n161\n\nJCR Subject Categories\nScience\n\nSocial Science\n\nFigure 1. Aggregate Impact Factor of the\nJCR subject categories\n\nDecomposing the Aggregate Impact\nFactor\nLet F be the set of all journals in a\nspecific field. Then, the Aggregate\nImpact Factor (AIF) is the ratio between\nthe citations in year t to citable items in\nany journal of field F in years t-1 and t2, and the number of citable items\npublished in those years.\nIt is possible to decompose the AIF into\nfive main variables: field growth rate,\naverage number of references, ratio of\n\nreferences to JCR items, ratio of JCR\nreferences to the target window, and\nproportion of cited to citing items in the\ntarget window. We prove that these\nvariables are normally distributed and\ndifferent across fields.\nCategories Normalized Impact Factor\n(CNIF)\nLet Ft1 ,Ft 2 ,...,Ft n be the subject\ncategories where journal i is indexed in\nyear t.\nDenoting by Ft j  Ft1 Ft 2\nFt n , then\nAIFt\n\nFt j\n\n\n\ni Ft j\n\nNCitedti\n\niJCR\n\nNCitedti\n\nIn a similar way,\nAIFt JCR\n\n\n\n\n\n\n\ni Ft j\n\nAti1  Ati 2 .\n\niJCR\n\nAti1  Ati2 .\n\nWe define the Categories Normalized\nImpact Factor of journal i in year t as:\n\n\n\ni\nCNIF\n\nIFt i  AIFt JCR AIFt\nt\n\nFt j\n\n.\n\nTherefore, this indicator has an intuitive\ninterpretation, similar to the IF.\nMaterials and Methods\nThe bibliometric data was obtained from\nthe online version of the Journal\nCitation Reports (JCR) during the first\nweek of October 2011. The 2010\nScience edition contains 8,073 journals\nclassified into 174 subject categories,\nand the Social Science edition contains\n2,731 journals classified into 56 subject\ncategories.\nIn the comparative analysis between the\nIF and the CNIF, and the estimation of\nthe gap between rankings across\ncategories, the five selected categories\nare: Business; Business, Finance;\nEconomics; Management; Operations\nResearch &amp; Management Science.\nThese categories contain a total of 590\ndifferent journals (490 in just one\ncategory, 98 in two, and 2 in three).\n\nResults and discussion\nThe AIF in Science is around 58%\nhigher than in Social Science (see\nFigure 1). This is due to the fact that\nalthough on average there are over 30%\nmore references in articles of Social\nScience, an important part of them are\nnon-JCR items. In Social Science\naround 40% of the references are books\nand journals that are not indexed in the\nJCR, while in Science these are around\n20% of the references.\nThe categories with the highest AIF in\nScience are related to biomedicine. The\nlowest values are in engineering and\nmathematics. In Social Science, the\ncategories with the highest values are\nrelated to psychology and some\nspecialties of economics, such as health\npolicy and management. The lowest\nfactors are in categories related to\nhistory.\nA journal from a category of Social\nScience has on average 30% more\nreferences and around 20% more\nreferences to non-JCR items than a\njournal from a Science category. The\nlongest reference lists are produced in\nhistory and the shortest in engineering\nand\nmathematics.\nThe\nhighest\nproportions to non-JCR items are in\nphysics, biology, and chemistry,\nwhereas the lowest are in engineering\nand computer science.\nOne of each five JCR references is on\naverage in the target window. Curiously,\nsome of the categories with the lowest\nproportion of references to JCR items\nhave the highest proportion of citations\nin the target window. This happens, for\nexample, in engineering and history. In\nsome areas, such as mathematics, just\none in eight JCR references is from the\nprevious two years, in comparison to\nhistory where they are one in three.\nWith respect to the Cluster Analysis of\nthe JCR categories, C1 and C7 include,\nin general, those life sciences with an\n2147\n\nimportant social component, as well as\nthose social sciences which use\nmathematical methods in a higher\ndegree (health, psychology, economics,\nand business, for example).\nClusters C2 and C4 contain those social\nsciences which use mathematical\nmethods in a lower degree (education,\nsociology, linguistic, and law, for\nexample). Finally, clusters C5 and C6\ninclude formal, physical, technological,\nand life sciences (mathematics, physics,\nchemistry,\nengineering,\nand\nbiomedicine, for example).\nThe variance in the AIF in Science can\nbe explained to a great degree by three\nmajor components (the ratio of\nreferences to JCR items, the ratio of\nJCR references to the target window,\nand the field growth). In Social Science,\nthe variance can be explained to a great\ndegree by only two major components\n(the ratio of JCR references to the target\nwindow and the proportion of cited to\nciting items in the target window). The\nprincipal components are different\ndepending on the edition of the JCR.\nThis is motivated because in Social\nScience there are many different\ndisciplines in relation to the habits of\npublication and citation (e.g. economics\nand psychology versus history).\nFinally, there are important differences\nbetween the CNIF and the IF for most of\nthe journals analyzed. In the case of the\nCNIF, the maximum gap is reduced in\nmore than half of the journals with\nrespect to the IF. The average gap is also\nreduced by around a 32%.\nConclusions\nA decomposing of the field aggregate\nimpact factor into five normally\ndistributed variables shows that, for the\nJCR subject categories, the variables\nthat to a greater degree explain the\nvariance in the impact factor of a field\ndo not include the average number of\n2148\n\nreferences. However, this is the factor\nthat has most frequently been used in the\nliterature to justify the differences\nbetween fields of science, as well as the\nmost employed in the sourcenormalization (Moed, 2010; Zitt &amp;\nSmall, 2008). Therefore, it is necessary\nto consider some other sources of\nvariance in the normalization process.\nReferences\nDorta-González, P., &amp; Dorta-González,\nM. I. (2010). Indicador bibliométrico\nbasado en el índice h. Revista\nEspañola de Documentación\nCientífica, 33(2), 225–245.\nDorta-González, P., &amp; Dorta-González,\nM. I. (2011). Central indexes to the\ncitation distribution: A complement\nto the h-index. Scientometrics, 88(3),\n729–745.\nDorta-González, P., &amp; Dorta-González,\nM. I. (2013). Comparing journals\nfrom different fields of science and\nsocial science through a JCR subject\ncategories normalized impact factor.\nScientometrics (in press). DOI\n10.1007/s11192-012-0929-9\nLeydesdorff, L., &amp; Opthof, T. (2010).\nScopus&#x27;s source normalized impact\nper paper (SNIP) versus a journal\nimpact factor based on fractional\ncounting of citations. Journal of the\nAmerican Society for Information\nScience and Technology, 61(11),\n2365–2369.\nMoed, H. F. (2010). Measuring\ncontextual citation impact of\nscientific journals. Journal of\nInformetrics, 4(3), 265–277.\nZitt, M., &amp; Small, H. (2008). Modifying\nthe journal impact factor by\nfractional citation weighting: The\naudience factor. Journal of the\nAmerican Society for Information\nScience and Technology, 59(11),\n1856–1860.\n\nSUCCESS DETERMINANTS OF FULL-TIME\nRESEARCHERS AT HOSPITALS. A\nPERCEPTIONS-BASED STUDY\nJesús Rey-Rocha1, Belén Garzón-García1, Irene López-Navarro1 and M. Teresa\nAntonio-García2\n1\n\njesus.rey@csic.es, irene.lopez@cchs.csic.es\nResearch Group on Scientific Evaluation and Transfer. Spanish Council for Scientific\nResearch (CSIC). C/ Albasanz, 26-28. Madrid (Spain)\n2\n\nmantonio@.bio.ucm.es\nResearch Group on Scientific Evaluation and Transfer (CSIC) &amp; Universidad\nComplutense de Madrid. Faculty of Biological Sciences. Ciudad Universitaria. Madrid\n(Spain)\nIntroduction\nDifferent factors affecting performance\nand productivity of researchers have\nbeen described in the literature. Namely\nindividual factors (Bonaccorsi &amp; Daraio,\n2003; Fox, 2005; Leahey , 2006; van\nArensbergen et al., 2012,), contextual\nand organizational factors (Smeby &amp;\nTry, 2005; Seashore et al., 2007), and\npsychological factors (Rey-Rocha et al.,\n2007; Torrisi, 2013).\nMost studies have been carried in an\nacademic environment, mainly in\nlaboratories. But these factors may\naffect researchers activity in a different\nway within the essentially clinical\nhospital environment. In this work we\ninvestigate the extent to which different\nindividual\nand\ninstitutional\ncharacteristics\ncan\ninfluence\nperformance and productivity of\nresearchers within the hospital setting.\nThe Miguel Servet (MS) Research\nContract Programme is one of the most\nimportant strategic actions being\nundertaken by Spanish Administration\nin order to enhance the research activity\nat public hospitals. The Programme is\naimed at incorporating researchers with\n\nexcellent training within the National\nHealth System (NHS) in order to\nimprove its research capacity and to\npromote the creation of stable research\ngroups within the NHS.\nMethodology\nPopulation, sample and research\ninstruments\nThe universe to be studied consisted of\nthe 367 researchers funded by first eigth\ncalls\n(1998-2005)\nof\nthe\nMS\nProgramme, whose contracts ended\nbetween 2005 and 2012.\nWe used a web-based survey to obtain\ndata from the population of MS\nresearchers (72.2% response rate). Data\non research activity and productivity\nwere obtained from the activity reports\nsubmitted by researchers.\nThe present work is based on data from\nthe 174 researchers who finished its sixyear contract and who answered the\nsurvey.\nVariables\nAfter the six-year contract, MS\nresearchers’ activity and results are\n2149\n\nevaluated anew for those who wish to\napply for a further five-year contract\nthrough the Researcher Stabilization\nProgramme. To be evaluated positively,\nresearchers must demonstrate a certain\nproductivity in high impact journals\ntogether with leadership (i.e. leading of\nfunded research projects and first\nauthorship of articles).\nThus, in this work research performance\nof researchers has been assessed through\nthe following indicators:\n- art_N: number of articles in ISI\njournals.\n- art_Q1, %art_Q1: number and\npercentage of articles in first-quartile\nISI journals.\n- art_FL, %art_FL: number and\npercentage of ISI articles as a first or\nlast author.\n- proj_N: number of funded projects.\n- proj_PR, %proj_PR: number and\npercentage of projects as principal\nresearcher.\nResearchers were asked about different\naspect of their research activity and their\nperceptions, judgements, thoughts and\nfeelings about this activity and its\norganizational context. In this paper we\ninvestigate the effect of the following\nfactors:\na) Satisfaction with... (in a 1 to 5\nscale):\n- Scientific quality of the host\ngroup.\n- Scientific quality of the host\ncentre.\n- Research autonomy.\n- Decision-making capacity.\n- Leadership.\n- The conditions of the facilities\nand space available.\n- Job stability expectations.\nb) Satisfaction with the resources at\ntheir disposal (1 to 5):\n- Human resources: technical and\nsupport staff and researchers in\ntraining.\n\n2150\n\n-\n\nMaterial\nresources:\ninfrastructures, equipment and\nresearch materials.\n- Support units.\n- Economic resources.\nc) Creation of new research groups\n(Yes, my incorporation has led to the\ncreation of a new research group I\nlead / No, I stayed in a already\nexisting group).\nd) Self-assessment of their contribution\nto the relationship between clinical\nand basic researchers (1 to 5).\ne) Type of research performed (basic,\nclinical, both).\nData analysis\nIn order to determine whether the means\nfor paired samples were systematically\ndifferent, we applied the Student’s t-test,\nadjusted\nusing\nthe\nBonferroni\ncorrection.\nResults\nProductivity and the capacity to obtain\nresearch projects are related with\nresearchers’ satisfaction with the human\nresources in their groups. Thus, art_N\nincreases by 57% in satisfied versus\nunsatisfied researchers. The capacity to\npublish in top journals is also influenced\nby this satisfaction: art_Q1 increased by\n65% (Figure 1). Likewise, satisfied\nresearchers participated in 44% more\nprojects than those unsatisfied, but did\nnot obtain a significant higher number\nof projects as principal researcher.\nAs expected, leadership of a research\ngroup increases proj_PR and %proj_PR\n(+ 61% and +29% respectively).\nProductivity in ISI journals is also\nrelated with the kind of research\nperformed. Researchers doing clinical\nresearch published more articles (65%\nmore than those doing basic research\nand 21% more than basic+clinical\nresearchers), more art_Q1(+ 70% than\nbasic) and obtained a higher proj_N and\n\nproj_PR (+69% and +98% respectively)\n(Figure 2).\n\nFigure 1\n\nFigure 2\n\nAcknowledgments\nThis work was supported by the Spanish\nMinistry of Health, within the\nframework of the Spanish RDI Plan\n(grant\nnumbers\nPI06/0983\nand\nPI10/00462).\n\nReferences\nBonaccorsi, A. &amp; Daraio, C. (2003) Age\neffects in scientific productivity. The\ncase of the Italian National Research\nCouncil (CNR). Scientometrics,\n58(1), 49-90.\nFox, M.F. (2005). Gender, family\ncharacteristics and publication\nproductivity among scientists. Social\nStudies of Science, 35(1), 131-150.\nLeahey, E. (2006). Gender differences\nin productivity: research\nspecialization as a missing link.\nGender and Society, 20 (6), 754-780\nRey-Rocha, J., Garzón-García, B. &amp;\nMartín-Sempere, M.J. (2007).\nExploring social integration as a\ndeterminant of research activity,\nperformance and prestige of\nscientists. Empirical evidence in the\nBiology and Biomedicine field.\nScientometrics, 72, 59-80.\nSeashore, K., Holdsworth, J.M.,\nAnderson, M.S. &amp; Campbell E.G.\n(2007). Becoming a Scientist: The\neffects of work-group size and\norganizational climate. The Journal\nof Higher Education, 70(3), 311336.\nSmeby, J.C., Try, S. (2005).\nDepartmental contexts and faculty\nresearch activity in Norway.\nResearch in Higher Education, 46\n(6), 593-619.\nTorrisi, B. (2013) Academic\nproductivity correlated with wellbeing at work. Scientometrics, 94,\n801-815.\nVan Arensbergen, P, van der Weijden, I.\n&amp; van den Besselaar, P. (2012).\nGender differences in scientific\nproductivity: a persisting\nphenomenon? Scientometrics ,93,\n857-868.\n\n2151\n\nSURFING THE SEMANTIC WEB\nSojung Yang , Hyosook Jung, and Seongbin Park*\n{cherry089, est0718, hyperspace}@korea.ac.kr\n* corresponding author\nKorea University, Seoul, Korea\nIntroduction\nIn this paper, we address the structural\nissues that can affect how a user can surf\nthe Semantic Web (Antoniou &amp; van\nHarmelen, 2004). Like the Web, the\nstructure of the Semantic Web is a\nhypertext and users still need to follow\nhyperlinks to access the information\n(Goble, Bechhofer, Carr, De Roure, and\nHall, 2001). However, it is not always\neasy to find the desired information in a\nlarge scale hypertext environment by\ntraversing hyperlinks (Zhou, Leung, and\nWinoto, 2007). The motivation of our\nresearch is that certain structures such as\na matroid (Cormen, Leiserson, Rivest,\nand Stein, 2003) and a small world\nnetwork (Watts, 1999) have been proven\nuseful in constructing a navigable Web\nsite, where navigability refers to how\neasy a user can find desired information\nas the user freely moves around at a\nWeb site (Min, Chun, Jang, Jung, and\nPark, 2011).\nTwo structures\nA matroid is a pair (S, I), where S is a\nfinite set and I is a set of subsets of S\nwhich satisfies the following two\nconditions: (1) If A is an element of I\nand B is a subset of A, then B is also an\nelement of I. (2) If A and B are elements\nof I and A contains more elements than\nB, then there exists an element x in A B such that {x} ∪ B is an element of I\n(Cormen et al., 2003). One motivation\nof considering a matroid structure lies in\nthe fact that a computational problem\n2152\n\nthat exhibits a matroid structure can be\nsolved using a greedy algorithm\n(Cormen et al., 2003) and if a network\ncan be constructed as a matroid, greedy\nbrowsing (i.e., each time a user visits a\nweb page, the user visits what looks\nmost relevant to the desired information\nusing the local information only) may\nlead to a shortest path from the current\nlocation to a destination. To demonstrate\nthis idea, let&#x27;s assume that we build a\nweb site about history of painting using\n16 web pages, where each page contains\nthe information about 17C, 18C, 19C,\n20C, Baroque, Rococo, Neoclassicism,\nRealism,\nImpressionism,\nCubism,\nRembrandt, Boucher, David, Millet,\nVan Gogh, and Picasso, respectively.\nWe can build a web site whose structure\nis a slight modification of a matroid\nstructure and reflects ontological\nconstraints,\nwhere\nan\nontology\nrepresents vocabularies and their\nrelationships in a domain of interests\n(Staab &amp; Studer, 2009). We made a\nmodification because if we consider all\nthe conditions in the definition of a\nmatroid, the number of hyperlinks\nbecomes too big.\nLet S be the set of 16 web pages. Then\nwe include subsets of S in I as\nfollows:(1) Include a standard of\nclassification in each element of I. With\nthis criterion, I = {{17C}, {18C},\n{19C}, {20C}}. (2) Associate one\npainting\nmovement\nwith\nthe\ncorresponding standard of classification.\nWith this criterion, I contains elements\n\nsuch as {17C, Baroque}, {18C,\nRococo}, etc. (3) Associate one art\nmovement with one painter. With these\ncriteria, I contains the following\nelements: {17C, Baroque, Rembrandt},\n{18C, Rococo, Boucher}, {19C,\nNeoclassicism, Fuseli, Realism, Millet},\n{20C, Impressionism, Van Gogh,\nCubism, Picasso}. Members in an\nelement of I are connected one another\nby hyperlinks. One interpretation of the\nresulting structure is that it is a\ncollection of subsets of S, where each\nsubset contains some representative\nelement (in our example, 17C, 18C, etc)\nand other representative element\n(Baroque, Rococo, etc) etc. Finally, we\nadd additional hyperlinks that come\nfrom ontological constraints. For\nexample, a link between &quot;Rembrandt&quot;\nand &quot;Van Gogh&quot; can be created if\n&quot;Rembrandt&quot; and &quot;Van Gogh&quot; have the\nsame value of property &quot;is_From&quot; that is\n&quot;The Netherlands&quot; in an ontology.\nSimilarly, Boucher and Millet can be\nlinked if their value of property\n&quot;is_From&quot; is the same (&quot;France&quot;). &quot;Van\nGogh&quot; and &quot;Millet&quot; can be linked as\nwell. With these additional constraints,\ntwo elements which belong to different\nsubsets of S can be connected by\nhyperlinks. Figure 1 shows the resulting\nstructure.\n\nFigure 1. The structure of a web site with\nmatroidal and ontological constraints.\n\nA small world network has a relatively\nsmall average path length compared to\nthe number of nodes in the network\n(Watts, 1999). One motivation of\nconsidering a small world network is\nthat if a network forms a small world,\nefficient routing is possible (Kleinberg,\n2000). Routing in a network is very\nsimilar to traversing hyperlinks that\nconnect web pages in the sense that both\nof them involve following a sequence of\nlinks with only local information\navailable in each step. One way to\nconstruct a small world network is to\narrange the nodes in a lattice and\nconnect two arbitrary nodes with the\nprobability that is proportional to one\nover the square of the lattice distance\nbetween the nodes (Costa &amp; Barros,\n2006). Assuming that we have the same\nset of pages in the previous example, we\nfirst connect the standards of\nclassification according to the order of\nperiods. Each period is connected with a\npainting movement and each painting\nmovement is connected with a painter.\nThen, two nodes are connected based on\nthe following criteria. If the relationship\nbetween two nodes is defined in an\nontology, then connect them. Otherwise,\nconnect them with the probability which\nis inversely proportional to its lattice\ndistance. Figure 2 shows a resulting\nstructure. The probability that there is a\nlink between &quot;Van Gogh&quot; and\n&quot;Rembrandt&quot; is 1/16 because their\nlattice distance is 4. However, a direct\nlink between the nodes can be created if\nthe relationship is defined in an\nontology.\nSemantic Web browser\nOne way to view the Semantic Web is\nthat it consists of logical theories\n(Sipser,\n2006)\nwhere\nsentences\ncorrespond to RDF triples (Klyne &amp;\nCarroll, 2004) and hyperlinks exist\namong the set of sentences. A Semantic\n2153\n\nWeb browser should be able to parse\nand derive new facts while a user is\nsurfing the Semantic Web. Derived facts\ncorrespond to logical consequences of\nthe sentences (i.e., RDF triples) that the\nuser has been visiting. In addition, a\nSemantic Web browser should be able\nto infer implicit relations such as\ntransitivity relation. It is also desirable\nthat a Semantic Web browser provides\nadaptive links based on navigation\nhistory. For example, in figure 3, if a\nuser visits a node &quot;The Netherlands&quot;\nfrom a node &quot;Rembrandt&quot; and then visits\na node “The Netherlands&quot; from a node\n&quot;Van Gogh&quot;, then it can help if the\nbrowser provides hyperlinks (dotted\nlinks in the figure) to a node &quot;Van Eyck&quot;\nand a node &quot;Escher&quot;.\n\nFigure 2. The ontological small world.\n\nFigure 3. The structure of web pages.\n\n2154\n\nConclusion and ongoing works\nIn this paper, we addressed the issue of\nthe navigability of the Semantic Web.\nCurrently, we are working on ways by\nwhich users can exploit structural\nproperties to surf the Semantic Web in a\ngreedy way. We plan to measure the\nnavigability of the structures that reflect\n(1) matroid and ontological constraints\n(2) small world property and ontological\nconstraints.\nReferences\nAntoniou, G. &amp; van Harmelen, F.\n(2004). A Semantic Web Primer,\nThe MIT Press.\nCormen, T. H., Leiserson, C. E., Rivest,\nR. L. &amp; Stein, C. (2003).\nIntroduction to Algorithms, MIT\nPress.\nCosta , A. R. &amp; Barros, J. (2006).\nNetwork information flow in\nnavigable small-world networks,\nProceedings of the 4th international\nsymposium on modeling and\noptimization in mobile, ad hoc and\nwireless networks.\nGoble, C., Bechhofer, S., Carr, L., De\nRoure, D. &amp; Hall, W. (2001).\nConceptual Open Hypermedia = The\nSemantic Web?, Semantic Web\nWorkshop.\nKleinberg, J. M. (2000). Navigation in a\nsmall world, Nature, Vol 406.\nKlyne, G. &amp; Carroll, J. J. (Ed.) (2004).\nResource Description Framework\n(RDF): Concepts and Abstract\nSyntax. Retrieved January 26, 2013\nfrom: http://www.w3.org/TR/rdfconcepts/# section-triples\nMin, K., Chun, S., Jang, G., Jung, H. &amp;\nPark, S. (2011). The structure of a\nweb site and navigability, The\nJournal of Korean Association of\nComputer Education, Vol 14, No 3.\nSipser, M. (2006). Introduction to the\ntheory of computation, 2nd edition,\nThomson Course Technology.\n\nStaab, S. &amp; Studer, R. (2009).\nHandbook on Ontologies, Springer\nPublishing Company.\nWatts, D. J. (1999). Networks,\nDynamics, and the Small-World\nPhenomenon, The American Journal\nof Sociology, Vol 105, No 2\n\nZhou, Y., Leung, H. &amp; Winoto, P.\n(2007). MNav:\nA Markov Model-Based Web Site\nNavigability\nMeasure, Journal of IEEE Transactions\non\nSoftware Engineering, volume 33, issue\n12.\n\n2155\n\nTEMPORAL EVOLUTION, STRUCTURAL\nFEATURES AND IMPACT OF STANDARD\nARTICLES AND PROCEEDINGS PAPERS. A CASE\nSTUDY IN BLENDED LEARNING.\nBarrios, Maite1, González-Teruel, Aurora2, Cosculluela, Antonio1,\nFornieles, Albert3, Ortega, Lidia1, Turbany, Jaume1\n1\n\nmbarrios@ub.edu, acosculluela@ub.edu, lortegca8@gmail.com, jturbany@ub.edu\nDept. of Methodology of Behavioral Sciences. University of Barcelona, Barcelona (Spain)\n2\n\nAurora.Gonzalez@uv.es\nDept. of Science of history and Documentation. University of Valencia. Valencia (Spain)\n3\n\nalbert.fornieles@uab.cat\nDept. of Psychobiology and Methodology of Health Sciences. Autonomus University of\nBarcelona. Barcelona (Spain)\nIntroduction\nInevitably, teaching and learning in\nhigher education have been transformed\nby the arrival of new computer-based\ntechnologies (Newman, Couturier &amp;\nScurry, 2004) and by the opportunities\nthey provide for addressing the needs of\nsociety in the twenty-first century.\nBlended learning emerged in the late\n1990s as a term to refer a new approach\nin education that mixes traditional faceto-face instruction with online learning\n(Garrison &amp; Vaughan, 2008). Since\nthen, the universities that have\nincorporated blended learning into their\ncourses have expanded enormously\n(Arabasz &amp; Baker, 2003).\nThis paper studies the development of\nscientific\nproduction\nsince\nthe\nintroduction of blended learning by\nfocusing on proceedings papers (PP) and\nstandard articles (SA). In the study of\nscientific communication, the role of PP\nmay differ depending on the field (Drott,\n1995, Lisée, Larivière &amp; Archambault,\n2008). In some disciplines (e.g.,\n2156\n\nengineering) they may be substitutes for\njournal papers, while in others they\nrepresent preliminary material that will\nlater be developed into a more rigorous\nmanuscript for publication in a journal\n(Drott, 1995, Glänzel, Schlemmer &amp;\nSchubert, 2006, Lisée, et al., 2008).\nHowever, the presence and the\nrelevance of PP in new emerging fields\nhave not been explored in depth. We\nfeel that the study of blended learning\nsince its origins can provide a picture of\nthe relevance of PP in the evolution and\nconsolidation of a new educational\napproach. In this study we analyse the\npublication rates of SA and PP in a new\nand emerging field in order to compare\nand contrast their temporal evolution,\nstructural features (number of coauthors, number of references and\npages) and impact (assessed by the\nnumber of citations).\n\nMethod\nData collection\nThe documents included in the present\nstudy were identified using the Thomson\nReuters Web of Science (WoS)\ndatabase. In order to retrieve the\nrelevant scientific literature, the search\nwas performed in the topic field (which\nruns the search for titles, keywords and\nabstract) and using the truncated form of\ndifferent synonyms used to refer to\nblended learning methodology (i.e.,\nblended e-learning, b-learning, mlearning, hybrid, flip, mixed-mode, webenhanced,\ntechnology\nmediated),\nsynonyms referring to the learning\nprocess (i.e., learning, instruction,\ncourse, teaching, education) and other\nrelated words (i.e., face to face, distance,\nonline). A total of 6,044 papers were\ninitially retrieved. Titles and abstracts\nwere checked manually to ensure that\nthe paper actually implemented or\nreported a blended learning experience\nin higher education.\nIn order to study a paper’s impact, the\nnumber of citations from its year of\npublication\nuntil\nthe\ndate\nof\ndownloading was also obtained from the\nWoS database.\nData analysis\nDescriptive statistics were used to study\nthe temporal evolution of PP and SA. In\norder to study whether the growth in\nscientific output over time fitted Price’s\nlaw, linear, exponential, logistic and\ncubic\nregression\nmodels\nwere\nperformed. The t-test was applied to\ndetermine whether SA and PP presented\ndifferences regarding structural features.\nAnalysis of covariance (ANCOVA) was\nused to study differences in the number\nof citations corresponding to the two\ntypes of document while controlling for\nthe effects of extraneous variables. As\nsuggested\nby\nBornmann,\nMutz,\n\nNeuhaus, &amp; Daniel (2008), the number\nof authors, pages per document and\nreferences were analyzed as covariates.\nResults\nBetween 1998 and December 2012, a\ntotal of 1,260 documents dealing with\nblended learning in higher education\nwere found in the WoS database. 55.3%\n(n= 697) of the documents were\nclassified as PP and 44.7% (n = 563) as\nSA. Table 1 shows the proportion of\nvariance explained for SA and PP.\nTable 1. Regression fit of SA and PP\nR2 linear\nR2 exponential\nR2 logistic\nR2 cubic\n\nSA\n0.918\n0.946\n0.930\n0.975\n\nPP\n0.687\n0.788\n0.667\n0.917\n\nFigure 1 shows a clear upward trend in\nthe publication rate during the 1990s\nand 2000s in both types of paper. In\nrecent years, however, the publication\nrate of PP shows a clear downward\ntrend.\n\nFigure 1. Temporal evolution in the\nnumber of publications of SA and PP\n\nSignificant differences were found\nbetween SA and PP in all variables\nmeasuring structural features. (Table 2).\nANCOVA showed that SA received a\nsignificantly higher number of citations\nthan PP (SA (mean (SD): 4.50 (12.77),\n\n2157\n\nPP: 0.41 (2.38); F(4, 1255) = 21.486, p\n&lt; .001).\nTable 2. Structural features of SA and PP\nSA\nPP\np\nMean (SD) Mean (SD)\nCo-authors 2.98 (1.87) 2.58 (1.64) &lt;.001\n32.90\n14.07\n&lt;.001\nReferences\n(18.44)\n(9.22)\n11.72\n7.21 (3.26) &lt;.001\nPages\n(5.45)\n\nConclusions\nThe data show the importance of\nconferences and meetings in the\nemergence and consolidation of a new\ntopic, in this case blended learning. In\nthe initial period, PP were the most\nfrequent type of document. As time\npassed, however, they were overtaken\nby SA. As for the differences in\nstructural features, PP had fewer pages\nand references, presumably because\nthese are limited by the conference rules\nor journal guidelines. The fact that the\nnumber of co-authors was higher in SA\nreflected\na\ngreater\ndegree\nof\ncollaboration than in PP. Judging from\nthe number of citations received, SA\nwere considered more relevant than PP.\nThese results corroborate those of\nprevious studies (Goodrum, MacCain,\nLawrence &amp; Giles 2001; Lisée, et al.,\n2008) and suggest that scientists regard\nSA as more elaborate and more mature\nthan PP.\nAcknowledgments\nThis study was supported by the\nresearch program in university teaching\nREDICE-12 (Redice12 1740-01) of the\nUniversity of Barcelona.\nReferences\nArabasz, P., &amp; Baker, M. B. (2003).\nEvolving campus support models for\n\n2158\n\ne-learning courses. Educause Center\nfor Applied Research Bulletin.\nhttp://www.educause.edu/ir/library/p\ndf/ecar\nso/ers/ERS0303/EKF0303.pdf.\nBornmann, L., Mutz, R., Neuhaus, C., &amp;\nDaniel, H. D. (2008). Citation counts\nfor research evaluation: Standards of\ngood practice for analyzing\nbibliometric data and presenting and\ninterpreting results. Ethics in Science\nand Environmental Politics, 8, 93–\n102.\nDrott, C.M. (1995). Reexamining the\nrole of conference papers in\nscholarly communication. Journal of\ntheAmerican Society for Information\nScience, 46(4), 299–305.\nGarrison, D. &amp; Vaughan, N. (2008).\nBlended learning in higher\neducation: Framework, principles,\nand guidelines. San Francisco, CA:\nJohn Wiley &amp; Sons.\nGlänzel, W., Schlemmer, B., Schubert,\nA., &amp; Thijs, B. (2006). Proceedings\nliterature as additional data source\nfor bibliometric analysis.\nScientometrics, 68(3), 457–473.\nGoodrum, A. A., MacCain, K. W.,\nLawrence, S., &amp; Giles, C. L. (2001).\nScholarly publishing in the Internet\nage: A citation analysis of computer\nscience literature. Information\nProcessing and Management, 37(5),\n661–675.\nLisée, C., Larivière, V., &amp; Archambault,\nE. (2008) Conference Proceedings as\na Source of Scientific Information: A\nBibliometric Analysis. Journal of the\nAmerican Society for Information\nScience and Technology, 59(11),\n1776–1784.\nNewman, F., Couturier, L., &amp; Scurry, J.\n(2004). The future of higher\neducation: Rhetoric, reality, and the\nrisks of the marker . San Francisco:\nJossey-Bass.\n\nTESTING COMPOSITE INDICATORS FOR THE\nSCIMAGO INSTITUTIONS RANKING\nIsidro F. Aguillo1\n1\n\nisidro.aguillo@csic.es\nCybermetrics Lab. IPP-CSIC, Albasanz, 26-28, Madrid 28037 (Spain)\nIntroduction\nThe Scimago Institutions Rankings\npublish every year a global ranking of\norganizations all over the world\nperforming scientific research. The last\nedition is the SIR World Report 2012\n(http://www.scimagoir.com/pdf/sir_201\n2_world_report.pdf) that is one of the\nmost prestigious rankings based on\nbibliometric-data.\nAlthough many of the global rankings of\nuniversities use in a way or another\nbibliometric data, there are only a few of\nthem that similarly to the Scimago’s one\nare based solely on this information.\nThese are the Leiden Ranking\n(http://www.leidenranking.com/)\nproduced by CWTS in the Leiden\nUniversity, the National University of\nTaiwan\n(NTU)\nRanking\n(http://nturanking.lis.ntu.edu.tw/Default.\naspx), that was formerly published by\nHEEACT and the University Ranking\nby Academic Performance (URAP)\nedited by the Turkish Middle East\nTechnical\nUniversity\n(http://www.urapcenter.org/).\nContrary to the Scimago Ranking that\ncompiles\ninformation\nfrom\nScopus/Elsevier database, they used\ninstead the WoS/Thomson Reuters\ncitation databases as a source.\nNTU and URAP ranking only provides\na unique classification based on a\ncomposite indicator that combines\ndifferent bibliometric variables. Leiden\nranking allows the end user to choose\n\namong different indicators that can be\ncombined to produce 8 different\nrankings without supporting any of them\nexplicitly. Scimago Ranking declares\nthat is not a league table and in fact the\nranking\nparameter\n(number\nof\npublications) is only for arrangement\npurposes and it is not a true ranking\nproposal. Even more they openly invite\nto use the report to rank institutions or to\nbuild a league table under your own\nresponsibility.\nThe purpose of this contribution is to\naccept that invitation to explore and test\nseveral composite indicators alternatives\nbuilt from the Scimago ranking\npublished information.\nThe test will be performed against other\nranking proposals so comparative\nanalysis can be useful not only from an\nacademic point of view but also in other\napplications of the rankings results.\nMethodology\nOne important unique characteristic of\nthe Scimago ranking is that includes not\nonly universities but also a high number\nof other research - focused organizations\n(hospitals, research centers, private\ncompanies, International organizations,\netc...). In order to make feasible the\ncomparative\nanalysis\nonly\nthe\nuniversities were selected.\nThe public report consists of seven\nindicators, namely Output (number of\ndocuments); International collaboration\n(output ratio with foreign co-authors);\nNormalized impact (normalized ratio\n\n2159\n\nbetween institution&#x27;s average scientific\nimpact and the world average); High\nquality\npublications\n(ratio\nof\npublications in the first quartile\njournals); Specialization Index (thematic\nconcentration / dispersion measured by\nGini index); Excellence Rate (papers\nbelonging to the 10% most cited ones in\neach\ndiscipline)\nand\nScientific\nLeadership (papers with corresponding\nauthor belonging to the institution).\nA first proposed indicator is not really a\ncomposite one as it is possible to rank\nthe institutions multiplying their output\nby their normalized impact (ONI). This\nfirst indicator was used for building the\nlist of top 500 universities that is the\npopulation study used for the analysis.\nFor the true composite ones we\nexcluded international collaboration and\nspecialization Index and considered (a)\nOutput, Leadership and Q1 publications\nas activity related variables while\nExcellence Rate is an impact\nmeasurement, then (b) the ratio between\nactivity and impact indicator should be\n1:1 meaning their weighting parameters\nwill be 50% each and finally (c) prior to\ncombination the raw data will be lognormalized (ln(value+1)/ln(max+1)).\nTable 1. Number of universities by\ncountry represented in the top 500 of the\n2012 editions (2011 for Leiden) of the\nrankings.\nCountry SCIM\nus\n139\nde\n39\nuk\n39\ncn\n36\nit\n26\nca\n22\nfr\n28\njp\n15\nau\n14\nkr\n11\nes\n14\nnl\n12\nse\n10\n2160\n\nLEID\n127\n39\n36\n26\n25\n21\n20\n24\n14\n18\n16\n12\n10\n\nURAP\n129\n40\n35\n34\n25\n20\n15\n18\n16\n16\n14\n12\n10\n\nNTU\n154\n46\n35\n23\n27\n22\n20\n23\n13\n12\n13\n12\n11\n\ntw\nch\nbr\nbe\nfi\nil\nat\npt\nhk\ngr\ndk\nza\nno\nie\ntr\nnz\npl\nin\nsg\ncl\nir\nru\nar\nth\nmx\ncz\nhr\nhu\nrs\nmy\nsi\nsa\neg\nee\n\n8\n7\n7\n7\n6\n5\n6\n5\n5\n4\n5\n3\n3\n3\n1\n2\n2\n3\n2\n1\n3\n1\n1\n\n9\n7\n8\n7\n6\n6\n5\n6\n5\n6\n4\n4\n3\n3\n6\n3\n3\n4\n2\n2\n\n1\n\n2\n2\n2\n1\n1\n1\n2\n1\n\n1\n\n1\n\n1\n1\n1\n\n10\n7\n7\n7\n6\n6\n5\n7\n5\n4\n4\n5\n4\n3\n5\n4\n3\n1\n2\n2\n4\n2\n1\n2\n1\n1\n1\n1\n2\n1\n1\n1\n1\n\n6\n8\n7\n7\n6\n5\n6\n3\n5\n4\n4\n3\n4\n3\n2\n2\n2\n2\n2\n1\n1\n1\n1\n1\n1\n1\n1\n\nResults\nThe population consists of universities\nof 41 different countries (considering\nHong Kong as a separate unit), that it is\nclose to the 40 countries from NTU or\nthe 42 of the Leiden Ranking. Only\nURAP is slightly (46) more diverse.\nTable 1 summarizes the geographical\ndistribution of the Top 500 universities\nin those rankings.\nWe obtained 4 indicators from Scimago\ndata (including three composite ones)\nplus the global rank figures for URAP\nand NTU rankings. The 2012 Leiden\nranking will be published shortly and\n\nthese figures will be incorporated in the\nfinal version.\nThe comparison between individual\ninstitutions were restricted in this short\nversion to 16 different institutions\nrepresentative from different regions as\nshown in Table 2\nTable 2. Ranks of selected universities\naccording to different indicators and\nsources: A: OUT*NC (Scimago); B:\nOUT+EXC (Scimago); C: LEAD+EXC\n(Scimago); D: Q1+EXC (Scimago); E:\nNTU; F: URAP\nDomain\nharvard.edu\nstanford.edu\njhu.edu\nutoronto.ca\nox.ac.uk\ncam.ac.uk\nu-tokyo.ac.jp\nupmc.fr\nethz.ch\nunimelb.edu.au\nuu.nl\ntsinghua.edu.cn\nusp.br\ntau.ac.il\nuct.ac.za\n\nA\n1\n2\n3\n6\n12\n14\n19\n26\n36\n37\n38\n44\n53\n129\n278\n\nB\n1\n6\n5\n2\n11\n13\n8\n20\n40\n39\n42\n27\n35\n109\n287\n\nC\n1\n6\n5\n3\n11\n13\n8\n31\n42\n45\n44\n16\n33\n117\n286\n\nD\n1\n7\n2\n5\n10\n13\n15\n22\n38\n37\n35\n54\n55\n106\n276\n\nE\n1\n3\n2\n7\n9\n15\n17\n48\n49\n35\n39\n94\n53\n116\n280\n\nF\n1\n4\n3\n2\n7\n11\n10\n41\n48\n32\n44\n72\n28\n93\n237\n\nDiscussion\nThere are coverage differences between\nWoS and Scopus databases that can\n\nexplain for example the better\nperformance of the Tsinghua or the\nParis VI universities (see Table 1 also).\nOther intra-Scimago discrepancies are\nmostly due to the factors considered\nwhen building the composite indicators.\nSome of them are very important as in\nthe case of the Chinese university that is\nhighly\nproductive\nbut\nwith\na\ncomparative smaller impact. In any case\nall the results are wildly distinct from\nthose offered in the current output-only\nlist.\nRecommendations\nThe results show that the several\ncombinations can be useful for different\npurposes, providing rankings according\nto the end-users self-defined priorities.\nWe strongly suggests that not only raw\ndata can be provided as currently\nScimago Ranking do, but also a series of\ncandidate combinations are published at\nthe same time. The criteria for\ncombination\nproposed\nhere\nare\nsuggestions, but informed by previous\nexpertise. Using an “a-priori” model\nwith specific weightings and a\nnormalization scheme that reduces\noutliers intends to avoid leaving open\nalternatives that could be meaningless.\n\n2161\n\nA TEXT MINING APPROACH EXPLORING\nACKNOWLEDGEMENTS OF PAPERS\nAdrián A. Díaz-Faes and María Bordons\nadrian.arias@cchs.csic.es, maria.bordons@cchs.csci.es\nInstituto de Estudios Documentales sobre Ciencia y Tecnología (IEDCYT), Spanish\nNational Research Council (CSIC), Albasanz 26-28, Madrid 28037 (Spain)\nIntroduction\nAcknowledgements are an important\naspect of scholarly communication,\nsince they are used to recognize some\nspecial contributions to research that are\nnot sufficient to qualify for authorship\n(Kassirer &amp; Angell, 1991). As stated by\nCronin, acknowledgement is a voluntary\nact that appears following an implicit\ncode of professional conduct (Cronin,\n1995). It has become a constitutive\nfeature of the academic journal article in\nthe 20th century, as well as a potentially\nrich source of insight into subauthorship collaboration in science.\nUntil recently it was very difficult to\ncarry\nout\nstudies\nabout\nacknowledgements (see for instance,\nGiles &amp; Council, 2004) because this\ninformation was not available in\nbibliographic databases. However, the\nWeb of Science (WoS) has been\nincluding funding acknowledgement\ndata since August 2008. This database\nincludes three fields of information on\n‘Funding Acknowledgement” (FA):\n&#x27;Funding Agency&#x27; (FO) contains the\nnames of the agencies that support the\nresearch, &#x27;Grant Number&#x27; (FG) provides\nthe numbers which identify the projects\n–if any- and &#x27;Funding text&#x27; (FT) contains\nthe full text included by the authors in\nthe acknowledgement section of the\npaper. This recent development of the\nWoS database opens up new\n\n2162\n\npossibilities for a wide range of studies\n(Rigby, 2011), although the unstructured\nnature of the field complicates the\nanalyses.\nAcknowledgements can be studied with\ndifferent purposes in science studies\nwhich range from the analysis of the\ninteraction among scientists to their use\nin research evaluation and funding\npolicy. Differences by disciplines in the\nfrequency of acknowledgements and in\nthe type of support acknowledged have\nbeen described (Costas and Van\nLeeuwen, 2012). In this paper we\npresent a novel approach to explore\nacknowledgement\npatterns\nby\ndisciplines and as a resource of subauthorship information combining text\nmining and multidimensional data\ndisplay techniques.\nData and method\nScientific papers published in four\ndisciplines (Cardiac &amp; Cardiovascular\nSystem,\nEconomics,\nEvolutionary\nBiology, and Statistics &amp; Probability) by\nSpain in 2010 were downloaded from\nWoS. The disciplines differ in their\nbroad\narea\nascription,\ntheoretical/experimental orientation and\nbasic/applied nature of research. These\nfeatures are taken into account under the\nassumption that they might have an\ninfluence on the type of information to\nbe included in the FA field. Textual\nanalysis is developed on the information\n\nprovided by FT field. Orthographic\nvariations, spelling variants, acronyms\nand other sources of word variability are\nidentified and handled to achieve text\nnormalization. Correspondence Analysis\n(Benzécri,\n1973)\nand\nWard’s\nHierarchical Clustering are used to\nidentify acknowledgement patterns by\ndisciplines based on similar lexical\nfeatures. Lexico 3 (Lamalle et al., 2003)\nis used to build a lexical table and\nMultiBiplot (Vicente-Villardón, 2010)\nfor the analysis.\nResults and discussion\nThe entire corpus is constituted by\n50,710 word occurrences, of which\n10,936 are different forms. The number\nof papers and main lexical features of\nthe four disciplines selected are shown\nin table 1.\nResults of Correspondence Analysis\nreveal differences in the lexical patterns\nof the disciplines selected (see figure 1).\nThe first two axes absorbed 92.9% of\nthe total inertia. Evolutionary Biology\nstands in the fourth quadrant and the\nsupport acknowledged can be defined as\ntechnical assistance and performing\nexperimental\nwork\n(Cluster\n1).\nEconomics and Statistics &amp; Probability\nare characterized by words that\nrecognize some intellectual debt which\ncontributes to improve the quality of\nresearch,\ni.e.\n‘peer\ninteractive\ncommunications’ (PIC) (Cluster 2).\nCardio &amp; Cardiovascular System is\nplaced in the third quadrant -close to\naxis 1- (Cluster 3). The implication of\ncompanies and the concern on conflict\nof interest’s issues characterise this\ndiscipline.\nConclusions\nText mining constitutes an interesting\napproach\nfor\nthe\nstudy\nof\nacknowledgements in publications.\n\nAlthough only four disciplines are\nstudied, the existence of inter-field\ndifferences in the textual pattern of the\nacknowledgements is confirmed. The\ninformation included in this field goes\nbeyond the financial data and provides\ninteresting data about sub-authorship\ncollaboration.\nAcknowledgements\nThis research was supported\nproject CSO2008-06310 and\npredoctoral grant awarded\nSpanish National Research\n(CSIC).\n\nby the\na JAE\nby the\nCouncil\n\nReferences\nBenzécri, J.P. (1973). L’analyse de\nDonnées. Vol. 2. L&#x27;analyse des\ncorrespondances. Paris: Dunod.\nCostas, R., &amp; Van Leeuwen, T.N.\n(2012). Approaching the “Reward\nTriangle”: general analysis of the\npresence of funding\nacknowledgements and ‘peer\ninteractive communication’ in\nscientific publications. JASIST,\n63(8), 1647-1661.\nCronin, B. (1995). The scholar’s\ncourtesy: The role of\nacknowledgements in the primary\ncommunication process. Los\nAngeles: Taylor Graham.\nGiles, C.L., &amp; Council, I.G. (2004).\nWho gets acknowledged: measuring\nscientific contributions through\nautomatic acknowledgement\nindexing. Proceedings of the\nNational Academy of Sciences of the\nUnited States of America, 101(51),\n17599-17604.\nKassirer, J.P., &amp; Angell, M.A. (1991).\nOn authorship and\nacknowledgements. The New\nEngland Journal of Medicine,\n325(21), 1510-1521.\nLamalle, C., Martínez, W., Fleury, S., &amp;\nSalem, A. (2003). Lexico 3.\n2163\n\nUniversité de la Sorbonne nouvelle,\nParis. http://www.tal.univparis3.fr/lexico/.\nMelin, G., &amp; Persson, O. (1996).\nStudying research collaboration\nusing co-authorships. Scientometrics,\n36(3), 363-377.\nRigby, J. (2011). Systematic grant and\nfunding body acknowledgement data\nfor Publications: new dimensions\n\nand new controversies for research\npolicy and evaluation. Research\nEvaluation, 20(5), 365-375.\nVicente-Villardón, J.L. (2010).\nMultBiplot: A package for\nMultivariate Analysis using Biplots.\nDepartamento de Estadística.\nUniversidad de\nSalamanca.http://biplot.usal.es/Class\nicalBiplot/index.html.\n\nTable 1. Lexical features of the corpus.\nDisciplines\nCardiac &amp; Cardiovascular Systems\nEconomics\nEvolutionary Biology\nStatistics &amp; Probability\n\nNo.\nPapers\n806\n624\n310\n309\n\nHapaxes: words with only one occurrence in the corpus.\n\nWord\noccurrences\n11608\n4734\n23600\n10767\n\nWord\nforms\n2436\n1351\n5104\n2045\n\nMax.\nfrequency\n605\n344\n1287\n755\n\nHapaxes\n1509\n844\n3456\n1315\n\nFigure 1. Correspondence Analysis of the different clusters obtained on the principal factorial\nplane 1-2.\n\n2164\n\nREGULARITY IN THE TIME-DEPENDENT\nDISTRIBUTION OF THE PERCENTAGE OF\nUNCITED ARTICLES: AN EMPIRICAL PILOT\nSTUDY BASED ON THE SIX JOURNALS\nZewen Hu1,2 and Yishan Wu1\n1\n\nhuzewen915@163.com; wuyishan@istic.ac.cn\nInstitute of Scientific &amp; Technical Information of China, No.15 Fuxing Road, 100038\nBeijing (China)\n2\nDepartment of Information Management, Nanjing University, No.22 Hankou Road,\n210093 Nanjing(China)\n\nIntroduction\nIn the scientific community, there exists\nfrequent uncitedness to the mediocre,\nthe low quality, the unintelligible, the\nirrelevant, the valuable but undiscovered\nor forgotten, the par excellence, and the\nwell known documents (Garfield, 1973).\nPrice (1965) estimated that about 35\npercent of all published papers in 1961\nare not cited at all in any given year and\n10 percent is never cited over a period\nof ten years. It is an accepted fact of\nacademic life that some papers, in\nwhatever discipline and wherever\npublished, will never be cited (Burrell,\n2002). Though articles that are less\nfrequently cited in a shorter time\nwindow may be of great value that has\nnot been found and utilized due to\nvarious reasons, if they fail to attract\nattention from the peers over a long\nperiod of time following their\npublication, then they might have\nweakness in relevance, importance,\npopularity, novelty, quality or impact.\nHowever, up to now, there is very scarce\nliterature on the time-dependent pattern\nof non-citation rates of articles, and on\nwhat distribution model can fit their\ntime-dependent pattern, as well as on the\nfactors influencing the non-citation rate.\n\nData and Method\nWe adopt two criteria for our selection\nof sample journals: enough number of\narticles produced per year and high\nenough IFs in two JCR categories:\nInformation Science\nand\nMultidisciplinary Science, Then we draw the\npublication and citation data on 6\nselected\nsample\njournals--Nature,\nScience, Journal of the American\nSociety for Information Science and\nTechnology (JASIST), Scientometrics,\nJournal of Information Processing &amp;\nManagement (JIPM), and Journal of\nDocumentation (JOD) from Web of\nScience. After that, we use a software\nnamed “Origin 8” to draw the timedependent scatter plots of the\npercentages of uncited articles in twelve\ndifferent time windows from one year to\ntwelve years following their publication\nin 1998 and 1999. Simultaneously, we\nuse\na\nthree-parameter\nnegative\nexponential model (Eq.1) to fit them and\nfigure out the corresponding parameters.\nFinally, for exploring how great an\ninfluence the length of articles exerts on\nthe probability that they get cited in the\nfuture, we analyse the percentage of\nuncited articles with different pages in a\nwide time window of twelve years after\n2165\n\ntheir publication in 1992-1999. The\nexpression of Eq.1 is\nP(Xt=0)=K+Ae-t/s\n(1)\nHere, P(Xt=0) represents the percentage\nof uncited articles in a time window of t\nyears after publication, t≥1. The variable\n“K” means the deviation value between\nthe actual percentages of uncited articles\nand the expected percentages according\nto the fitting curve, while “A” is the\namplitude of decrease for the percentage\nof uncited articles along with time. The\nvariable “s” is the rate of obsolescence,\nwhich indicates the probability of\nuncited articles’ staying in the state of\nuncitedness as time elapses. We call this\nstate “sleeping” (until being awaken by\nthe first citation) coefficient.\n\nFigure 1. The time-dependent scatter plots\nand the fitting curves of the percentages of\nuncited articles after their publication in\n1998.\n\nFigure 2. The time-dependent scatter plots\nand the fitting curves of the percentages of\nuncited articles after their publication in\n1999.\n\n2166\n\nResults\nFigures 1-2 show the time-dependent\nscatter plots of the percentages of\nuncited articles in twelve different time\nwindows from one year to twelve years\nfollowing their publication, and the\nfitting curves with Eq.1. In these figures,\nthe different shapes of scatter points\nrepresent different journals, while the\nvertical arrows represent the deviation\ndegree between scatter plots and fitting\ncurves.\nFrom Figures 1-2, we can find some\ncommon patterns on the time-dependent\ndistribution of the percentages of\nuncited articles. (1) The deviation\nbetween scatter plots and fitting curves\nis very low. (2) In the beginning shorter\ntime window, each journal has a higher\npercentage of uncited articles. For\nexample, in a time window of one year\nafter publication, the average percentage\nof uncited articles in JOD is the highest\none, reaching 80.9%, while the average\npercentage of uncited articles in\nSCIENCE is lowest, still reaching\n48.7%. (3) As the time window becomes\nwider and wider, the average percentage\nof uncited articles in each journal begins\nto descend with varying degrees. For\nexample, the average percentage of\nuncited articles in JOD drops from\n80.9% in a time window of one year to\n67.5% in a time window of twelve\nyears, with a total decline of 32.6\npercentiles (relative to the origin 100%),\nwhile the average percentage of uncited\narticles in SCIENCE drops from 48.7%\nin a time window of one year to 31.6%\nin a time window of twelve years, with a\ndecline of 68.4 percentiles. (4) In a time\nwindow of twelve years after\npublication, the average percentage of\nuncited articles in each journal keeps a\nstable value, with very few changes. (5)\nThe Eq. 1 can well fit the timedependent scatter plots of the\npercentages of uncited articles as shown\n\nin Figures 1-2. The average R2 values,\nshowing the goodness of fitting curves\nfor each journal, are all above 97%. (6)\nThe average amplitude value (A) of the\ndecline of non-citation rate along with\ntime for JASIST reaches the highest\nvalue of 64.5, while JOD keeps the\nlowest value of 19.9. (7) JASIST,\nNATURE and SCIENCE keep the lowest\nsleeping coefficient (S) values of 1.5,\n1.6 and 1.7. While the sleeping\ncoefficient\n(S)\nvalues\nfor\nSCIENTOMETRICS, JIPM and JOD are\n2, 2.3 and 2.5, respectively.\nTable 1 shows the number (A) of\narticles with different pages published in\nsix sample journals in 1992-1999, as\nwell as the number (U) and the share (S)\nof uncited articles with different pages\nin a wide time window of twelve years\nafter their publication.\nTable 1. The relation between article\nlength and the probability of getting cited\n3-4\n5-6\n7-8 9-10 &gt;10\n1992- 1-2\npage page page page page\n1999 pages\ns\ns\ns\ns\ns\nA\n32148 12011 3261 905 354 1292\nU\n18682 690\n73\n25\n21\n66\n\nS(%\n)\n\n58.\n1\n\n5.7\n\n2.2\n\n2.8\n\n5.9\n\n5.1\n\nFrom Table 1, we can observe the\nfollowing points. (1) The number (A) of\nthe short articles with 1-2 pages is very\nlarge. For example, there are 32148\nshort articles with 1-2 pages in total\n49971 articles, its share in total reaches\n64.3%, while there are only 5812 long\narticles with 5 and more pages, with a\nshare of 11.6%. (2) The percentage of\nuncitedness in short articles is also very\nhigh. For example, the percentage of\n\nuncitedness in the 32148 short articles\nwith 1-2 pages is 58.1%, while that in\nthe 5812 long articles is only 3.18%,\nwhich may bring us to conclude that the\nprobability of getting cited in the future\nfor current uncited long articles is far\nhigher than that for short articles. It\nseems that the scientific community is\nprone to cite long articles, which are\nmore possible to provide more solid\nargument for their ideas. (3) The length\nof articles has a very great effect on the\nprobability whether they will get cited in\nthe future or not. For example, with the\nincrease of article length, the share (U)\nof uncited articles in all journals drops\nfrom 58.1% in short articles with 1-2\npages to 5.1% in long articles with 11\nand more pages, with a decline of 53\npercentiles.\nAcknowledgments\nThis study is supported by the National\nNatural Science Foundation of China\n(Grant No. 70973118) and the\nInnovation Plan Program of Scientific\nResearch for College Graduate Students\nin Jiangsu Province (Grant No.\nCXZZ12_0075).\nReferences\nGarfield, E.(1973). Uncitedness III-The\nImportance of Not Being Cited.\nCurrent Contents, 8, 5-6.\nPrice, D. J. D. (1965). Networks of\nscientific papers. Science, 145, 510515.\nBurrell, Q.L. (2002). Will This Paper\nEver Be Cited?. Journal of the\nAmerican Society for Information\nScience and Technology, 53(3), 232–\n235.\n\n2167\n\nTOPOLOGICAL TOPIC TRACKING – A\nCOMPARATIVE ANALYSIS\nAlexander Struck1\n1\n\nAlexander.Struck@ibi.hu-berlin.de\nHumboldt-Universitaet zu Berlin, Berlin School of Library and Information Science,\nUnter den Linden 6, 10099 Berlin, Germany\nIntroduction\nTopological methods for identifying and\ntracking community development have\nbeen proposed but not compared yet.\nDue to the heterogeneous nature of\nthresholds, viewpoints and data sets\ntracking results may differ significantly.\nThis may turn into a problem if e. g.\nfunding policy decisions are based on\nhow well a topic &#x27;performed&#x27; over time.\nThe on-going research\ninvestigates\nseveral\napproaches\nand\ntheir\ndependencies.\nData\nAbout 11 per cent of Thomson Reuter’s\nWoS subject categories “Information\nScience &amp; Library Science” and\n“Computer\nScience,\nInformation\nScience” have been downloaded.\nJournals were selected if they had a 5year Impact Factor higher than 1. This\nthreshold has been chosen to achieve a\nmiddle-ground between a broad range of\ntopics and their connection via citations.\nThe resulting journal set was then\nexpanded by the 16 most cited journals\nwith exceptions of ‘Science’ and the\nlike. This levels out the hard cuts made\nby the category borders. Overall 50\nyears of (ca. 64,000) WoS records\nreflecting scientific communication (e.\ng. ‘proceedings paper’) are part of the\ninvestigation.\n\n2168\n\nGraph Partitioning\nThe Louvain algorithm (Blondel, 2008)\nprovides clusters and hierarchy levels\nwithout threshold dependence. It has\nbeen shown that it leads to good results\non benchmark tests (Lancichinetti,\n2009). Similarity is indicated by\nbibliographic coupling and measured by\nSalton’s Cosine index.\nTracking Approaches\nSimilarity\n\n&amp;\n\nCluster\n\nDirect Citation to and from ‘core\ndocuments’\nGlaenzel and Thijs (Glaenzel W. a.,\n2011) suggest the use of ‚core’\ndocuments and look for links from and\nto clusters in adjacent time periods.\n(Schubert, 2009) suggested „Using the\nh-index\nfor\nassessing\nsingle\npublications“ and „define(s) the h-index,\nh, of a publication as the citation hindex of the set of papers citing it [...]“.\n(Glaenzel W. , 2012) genera-lized the\n‚lobby index’ for undirected graphs as:\n“Core nodes are nodes with at least h\ndegrees each, where h is the h-index of\nthe graph.“ This has been used to\nidentify cores and links connecting\nclusters.\nCombined Linkage\n(Small H. , 1997) introduced a „\nmeasure of docu-ment similarity:\nCombined linkage“ to overcome\n\nlimitations of citation-based measures.\nBiblio-graphic coupling, co-citation,\ndirect and indirect links (over a third\nnode) are considered here. The linkage\ncombination promises\nconnections\nbased on more information than\ncurrently used.\n(\n√(\n\n)\n) (\n\nThis measure has been generalized for\ncluster similarity using size-relative\ncounts. It also allows direct comparison\nof methods used to connect clusters over\ntime.\nExperiments\n1740 clusters were compared with each\nother (trailing ‘X’ below) and also just\nwith the adjacent one-year time frame.\nSeveral linkage options have been tested\nand the resulting graphs compared by\nnoting Jaccard similarity to other\ngraphs.\n„AB1“ creates graphs similar to the\noriginal since links between clusters\nappear if at least one direct citation\nexists. „ABcde1“ is a graph that links A\nand B if at least one of the coupling\nmethods is present. The „ABcde“ graph\nhas a link between A and B if the sum of\ndirect citation links and papers ‚c’, ‚d’\nor ‚e’ exceeds the threshold. „AB(X)“\ndenotes direct citation between clusters\nof adjacent (any) years. Co-citation\ncoupling of A and B is present if at least\nthat many papers ‚ci’ are present in\nadjacent (or ‚ciX’ any) years. „di(X)“\ngraphs couple clusters bibliographically\nand „eiX“ covers graphs of longitudinal\ncoupling. And „core“ denotes graphs\nthat are created if at least half the noted\nthreshold is met. This can be justified\ndue to the fact that only a fraction of the\narticles are considered in linking.\n\n)\n\nResults &amp; Discussion\nGraphs resulting from the same\nsimilarity method for clusters but using\neither the next or all timeframes differ.\nThis suggests that the strongest\nconnection does not necessarily exist\nbetween adjacent time frames.\nSince a lot of information is discarded in\ntopological tracking hardly any graph\ncompares to the maximal possible\ngraphs of ‘AB1’ or ‘ABcde1’. A notable\nexception is the sum of possible linkage\n(ABcde/X) which is the least restrictive\nthreshold tested here and includes the\nmost\ninformation.\nBibliographic\ncoupling (di/X) appears most similar\nsince usable citation information is\navailable outside of the data set while\ndirect\ncitation,\nco-citation\nand\nlongitudinal coupling approaches are\nlimited to the 50 years set. One could\nargue that the data set in conjunction\nwith the coupling method used\ninfluences the resulting cluster strings.\nIncreasing the threshold creates graphs\nwith less clusters and less edges\nassuming stronger connections between\nclusters. Here it should be noted that\nbibliographic coupling seems to behave\nmore stable than using ‚core’ links only.\nWhile the ‚core documents linkage’\napproach creates graphs very similar to\n‚direct citation’ (AB) this changes when\ncomparing the threshold 10 and 50\n(resp. 5 and 25 for ‚core’). At the\nincreased threshold ‚core’ is now more\nsimilar to bibliographic coupling\n(di/diX) and also to the less restrictive\n‚ABcde(X)’. At higher threshold of\ndirect citation links it is apparent that\nadjacent years (AB) do not match to\nlonger distances for this approach\n(ABX). Here, the co-citation and\nlongitudinal coupling show interesting\nsimiarities with ABX. That suggests that\ncertain approaches perform differently\ndepending on thresholds like time\ndistance.\n2169\n\nIt does make a difference if one chooses\nco-citation or bibliographic coupling to\nconnect clusters. Co-citation analysis\nmay even that out but hasn’t been\nconsidered here.\nThe combined linkage (ABcde/X)\nperforms stable at different thresholds\nand against many other approaches\nwhich may point to a consensus that will\nbe investigated further.\ncore\neiX\ndiX\ndi\nciX\nci\nABX\nAB\nABcdeX\nABcde\nABcde1\n\neiX\n\ncore\n\ndi\n\ndiX\n\nci\n\nciX\n\nAB\n\nABX\n\nABcde\n\nABcdeX\n\nAB1\n\nABcde1\n\nAB1\n\nFigure 1. Threshold of 10 cluster\nconnections\ncore\neiX\ndiX\ndi\nciX\nci\nABX\nAB\nABcdeX\nABcde\nABcde1\n\neiX\n\ncore\n\ndi\n\ndiX\n\nci\n\nciX\n\nAB\n\nABX\n\nABcde\n\nABcdeX\n\nAB1\n\nABcde1\n\nAB1\n\nFigure 2. Threshold of 50 cluster\nconnections\n\n2170\n\nAn extended version of this paper is\navailable at: http://141.20.126.172/~div\n/downloads/Topological_Topic_Trackin\ng_pt1-Struck.pdf\nReferences\nBlondel, V. a. (2008). Fast unfolding of\ncommunities in large networks.\nJournal of Statistical Mechanics:\nTheory and Experiment , S. P10008.\nFortunato, S. a. (2007). Resolution limit\nin community detection.\nProceedings of the National\nAcademy of Sciences (S. 36).\nNational Acad Sciences.\nGlaenzel, W. a. (2011). Using &#x27;core\ndocuments&#x27; for detecting new\nemerging topics. Proceedings of ISSI\n2011-the 13th International\nConference on Scientometrics and\nInformetrics.\nGlaenzel, W. (2012). The role of core\ndocuments in bibliometric network\nanalysis and their relation with htype indices. Scientometrics .\nGood, B. a. (2010). Performance of\nmodularity maximization in practical\ncontexts. Physical Review E , 81 (4),\nS. 046106.\nLancichinetti, A. a. (2009). Community\ndetection algorithms: A comparative\nanalysis. Physical Review E , 80 (5),\nS. 056117.\nLancichinetti, A. a. (2011). Limits of\nmodularity maximization in\ncommunity detection. Physical\nReview E , 84 (6), S. 066122.\nSchubert, A. (2009). Using the h-index\nfor assessing single publications.\nScientometrics , 78 (3).\nSmall, H. (2006). Tracking and\npredicting growth areas in science.\nScientometrics , 68 (3), S. 595-610.\nSmall, H. (1997). Update on science\nmapping: Creating large document\nspaces. Scientometrics , 38 (2).\n\nTOWARDS AN AUTHOR-TOPIC-TERM-MODEL\nVISUALIZATION OF 100 YEARS OF GERMAN\nSOCIOLOGICAL SOCIETY PROCEEDINGS\nArnim Bleier and Andreas Strotmann\n{arnim.bleier, andreas.strotmann}@gesis.org\nGESIS - Leibniz Institute for the Social Sciences, Unter Sachsenhausen 6-8,\nCologne (Germany)\nIntroduction\nAuthor co-citation studies (Zhao &amp;\nStrotmann, 2008) employ factor analysis\nto reduce high-dimensional co-citation\nmatrices to low dimensional and\npossibly interpretable factors, but these\nstudies do not use any information from\nthe text bodies of publications. We\nhypothesise that term frequencies may\nyield\nuseful\ninformation\nfor\nscientometric analysis. In our work we\nask if word features in combination with\nBayesian analysis allows for wellfounded science mapping studies. This\nwork goes back to the roots of Mosteller\nand Wallace’s (1964) statistical text\nanalysis using word frequency features\nand a Bayesian inference approach,\ntough with different goals. To answer\nour research question we (i) introduce\nthe data set on which the experiments\nare carried out, (ii) describe the\nBayesian model employed for inference\nand (iii) present first results of the\nanalysis.\nThe DGS Dataset\nThe collection of documents D we use\nin the experiment covers ~100 years of\nproceedings (from 1910 to 2006) of\nmeetings of the Deutsche Gesellschaft\nfür Soziologie (DGS), a total of 5,010\ndocuments. Early proceedings had been\nscanned and OCRed, others were used\nin original digital form. Metadata for the\n\ndocuments included 3,661 distinct full\nnames of authors J.\nFrom each document, the 21st-320th\nwords were extracted. After unifying\nword case, we removed stop-words,\nshort and/or rare words (&lt; 4 letters; &gt; 10\noccurrences; mostly OCR fragments)\nand words found in more than half of\nthe documents, resulting in 1,067,128\noccurrences from a vocabulary V with\n12,665 distinct words.\nStatistical Model\nWe now review the statistical model we\nemploy to relate authors and documents\nvia a flexible number of topics.\nFollowing a common notation (RosenZvi, 2004), a document d is modelled as\na vector of\nwords,\n, where the ith\nword\nis chosen from the unique\nterms in vocabulary V. Each document d\nis associated with a set of authors\nfrom the set of all authors, J.\nOur model assumes that documents are\ngenerated in the following steps:\n1. Draw a shared discrete probability\ndistribution from a Dirichlet Process\n(DP) (Teh et al. 2006) with base\nmeasure H and prior concentration\nparameter\nas a global mixture over\ntopics\n(\n)\n2. For author j, draw an author specific\ndistribution over topics from the global\n\n2171\n\ntopic mixture , with prior concentration\nparameter\n( )\n3. For each topic k, draw a topic specific\ndistribution over vocabulary V from the\nsymmetric Dirichlet prior\n( )\nwords in document d, (i)\n4. For all\ndraw an author indicator x from the set\nof document d; (ii) a topic\nof authors\nindicator z from the author specific topic\ndistribution ; (iii) the observed word w\nitself from the respective topic\n( )\n(\n)\n(\n)\n\nare of particular interest. The former\nspan a latent semantic space via\nmeaningful word probabilities for each\ntopic; the latter allow us to position each\nauthor j in this topic space.\nPosterior Analysis and Visualization\nThe generative model is structured as a\ndirected acyclic graph beginning from\ncauses and ending with observed words\nin documents. Bayes’ Rule reverses\ncausality, and parameters of interest can\nbe estimated from observed data and\npriors. We use an MCMC sampler for\nthis posterior analysis. After running the\nsampler for 2,000 steps with priors =.5,\n=.5 and =.2, the model converged to\nand\n89 components. Samples of\nare shown in Figure 1 and Table 1. The\nreader is referred to Rosen-Zvi et al.\n(2004), Teh et al. (2006) and Bleier\n(2012) for an in-depth discussion of this\nmethod.\nTable 1. Most probably words for the\ntopics.\nTopic High probability words\n1\n63\n\nFigure 1. Non-parametric Author-Topic\nmodel.\n85\n\nFigure 1 illustrates the independence\nassumptions made by the generative\nstoryline via plate notation. Circles\nrepresent statistical variables, with\nobserved ones shaded. Arrows represent\nconditional dependence − i.e., the order\nin which variables are drawn. Plates\nindicate repetition, as indicated by\nuniversal quantifiers.\nFor the posterior analysis, the topic\nover terms as well as\ndistributions\nover topics\nthe author distributions\n2172\n\n87\n\nbildung, jugendlichen, schule,\njugendliche, ausbildung, jugendlicher\ntranslation: education, school, youth\nfrauen, männern, männer, geschlecht,\nfrauenforschung, frau\ntranslation: women, men, gender\nresearch\nglobalisierung, welt, globalen, grenzen,\nglobaler, unternehmen\ntranslation: globalization, world,\nenterprize\neuropäischen, europa, integration,\neuropäische, union, ländern\ntranslation: European, integration,\ncountries\n\nDue to space constraints we restrict the\nvisualization in Figure 1 (using Pajek) to\nfour of 89 components. Authors and\ntopics are represented as square and\ncircular nodes, resp. The size of topic\nnodes is proportional to their usage and\nthe strength of the arcs proportional to\n\nthe probability for topic k specific to\nauthor j. We are not constrained to\ninterpreting topics as only having a\ndistinct probability for each author, but\nequally have for each topic k a\ndistribution\nover distinct words in\nthe vocabulary. Table 1 displays the six\nmost probable terms for the sample\ntopics of Figure 1.\nDiscussion\nOur approach to science mapping uses a\nflexible\nversion\nlatent\nDirichlet\nallocation to (i) identify an optimal\nnumber and set of topics for a given set\nof documents based on the words that\noccur in them, (ii) to identify the most\nrelevant words to describe each topic,\nand (iii) to identify weighted links\nbetween authors and the topics of their\nwritings. The statistical model takes into\naccount that documents are written by\nmultiple authors, that authors write on\ndifferent topics to different degrees, and\nthat words pertain to different topics to\nvarying degrees.\nFigure 1 shows a small fragment of a\nmap of German sociological science\nbased on ~100 years of DGS\nproceedings,\ninspired\nby\nthe\nvisualization of results of co-citationbased factor analysis in Zhao &amp;\nStrotmann (2008), but generated fully\nautomatically from the results of\n\napplying this statistical analysis\ntechnique to full texts.\nWhile a full evaluation remains to be\ndone, these results show some promise\nfor the application of these methods in\nscientometric studies.\nReferences\nBleier, A. (2012). A simple nonparametric Topic Mixture for\nAuthors and Documents. Pre-print\narXiv:1211.6248 [cs.LG].\nMosteller, F., &amp; Wallace, D. (1964).\nInference and Disputed Authorship:\nThe Federalists. Addison-Wesley.\nRosen-Zvi, M., Griffiths, T., Steyvers,\nM., &amp; Smyth, P. (2004). The authortopic model for authors and\ndocuments. Proceedings of the 20th\nConference on Uncertainty in\nartificial intelligence (UAI 04) (pp.\n487-494).\nTeh, Y.W., Jordan, M.I., Beal, M.J., &amp;\nBlei, D.M. (2006). Hierarchical\ndirichlet processes. Journal of the\nAmerican Statistical Association,\n101, 1566-1581.\nZhao, D., &amp; Strotmann, A. (2008).\nInformation Science during the first\ndecade of the Web: An enriched\nauthor co-citation analysis. Journal\nof the American Society for\nInformation Science and\nTechnology, 59(6), 916-937\n\nFigure 1: Excerpt of author topic analysis result: visualization of four topics and their main\nauthors\n\n2173\n\nUSE FREQUENCIES OF NOMINALIZATIONS IN\nSCIENTIFIC WRITING IN BRAZILIAN\nPORTUGUESE LANGUAGE AS POLITENESS\nSTRATEGIES AND THEIR INDEX ROLE IN THE\nSUBJECT INDEXING\nVânia Lisboa da Silveira Guedes1; Maria de Fátima Sousa de Oliveira Barbosa2;\nMaria José Veloso da Costa Santos3 and Maria Cecília de Magalhães Mollica4\n1\n\nvanialisboa@facc.ufrj.br; 2fatimma.barbosa@gmail.com; 3msantos1402@gmail.com;\n4\nceciliamollica@terra.com.br\nFederal University of Rio de Janeiro, Av. Pasteur, 250 – Urca CEP 22290-902, Rio de\nJaneiro-RJ – Brazil\n\nIntroduction\nThis study is part of “Scientific and\nTechnological Knowledge Organization\nProject” and analyses the scientific\nwriting in Chemistry subareas in\nBrazilian Portuguese in order to\ninvestigate the regularity in the use\nfrequencies of deverbal nominalizations\nas politeness strategies in the scientific\ncommunication and their index role in\nthe subject indexing. The research is\nsituated in the border of the Linguistics\nwith Information Science and aims to\ncontribute to the understanding of the\nscientific writing with communication\npurposes. The research question is how\na systematic analysis of deverbal\nnominalizations in scientific writing of\npapers can contribute to the semiautomatic subject indexing based on\nBibliometrics, making information\nretrieval electronic systems more\nprecise, intelligent and scientifically\nestablished.\n\nObjectives\nCentral Objective\nThe central aim is to develop the\nlinguistic and bibliometrics comparative\nanalysis of the scientific writing in the\nChemistry subareas: Pharmacology\nIndustry and Food Technology.\nSpecific Objectives\n(a) to analyze the scientific writing\nbased on quantitative models used in\nsemiautomatic\nindexing\nwithin\nBibliometrics;\n(b) to investigate the regularity in the\nuse frequencies of the nominalization in\n–ção, -mento;\n(c) to contribute to the theoretical and\npractical approaches in the knowledge\nfields in discussions.\n(d) to strengthen the interface of the\nDiscourse\nCritical\nAnalysis\nin\nLinguistics\nwith\nScientific\nCommunication and Bibliometrics in\nInformation Science.\nHypothesis\nThe hypothesis is\nfrequencies\nof\n\n2174\n\nthat the use\nnominalization\n\nrepresented by [X] v  [[X] v -ção] N is\npredominant in the semantics fields in\nanalysis. So it is present in the scientific\nwriting of these papers as index terms\nand politeness strategies.\nTheoretical framework\nThe theoretical framework used was the\nsubject indexing, Zipf&#x27;s Laws and\nGoffman Transition Point (Pao, 1978) in\nthe Bibliometrics, as well as the genre\nanalysis theory (Bazerman, 2006;\nHyland, 2009; Swales, 1990), the\nLexical\nTheory\n(Basílio,\n2007;\nChomsky, 1970) and Critical Discourse\nAnalysis (Eggins, 2004; Van Djck,\n2012) within Linguistics. Bibliometrics\nis the science that presents a set of\nempirical\nprinciples\nbased\non\nmathematical and statistical methods to\ninvestigate, assess and quantify the\nwritten communication processes. The\nBibliometrics\nanalysis\nestablishes\nrelevant indicators in a knowledge field\nhighlighting the quantitative aspects of\nproduction, dissemination and use of\nscientific information. Among the more\nused bibliometrics laws there are the\nZipf&#x27;s Laws used for subject indexing\nrelated to words occurrence frequencies\nin a given text, enriched by Goffman\nTransition (T) Point, a method of\nselecting index terms directly suggested\nby Goffman (apud Pao, 1978). This\nmethod indicates a region from the list\nof words used in a scientific text with\nthe highest semantics content. Goffman\nT Point is represented mathematically\nby the expression above, where n\nrepresents the Point T; I1 is the number\nof words that has a frequency 1.\nn\n\n 1  1  8 I1\n2\n\nIn\nLinguistics,\nthe\ndeverbal\nnominalization, (Basilio, 2007), refers to\nthe set of processes that form nouns\nfrom verbs. The author explains that the\nnominalization\ncontains\naspects\n\nsyntactic and semantic textual and play\nfunctions of designation of process,\naction, state etc. Basilio (2007), Swales\n(1990), Hyland (2009), Eggins (2004)\nand other authors emphasize that the use\nof nominalizations characterize heavily\nthe scientific discourse. Guedes (2010)\ndemonstrates the importance of the\nanalysis of the deverbal nominalizations\nin scientific writing about Viniculture\nfor the subject indexing in Information\nScience. Santos (2009) verifies the\npossibility of applying the Zipf’s Laws\nand the Goffman T Point in a scientist\npersonal archive in Zoological area in\norder to find words with a high semantic\ncontent for subject indexing. Barbosa\n(2010) analyses the linguistic processes\nused to represent politeness strategies in\nmessages exchanged among the students\nand the mediators of the Distance\nLearning Courses. Guedes, Barbosa and\nSantos (2012) analyses the productivity\nand the recurrence of nominalized\nstructures with of index terms function\nand politeness strategies in the scientific\nwriting with communication purposes.\nMethodology\nThe methodology consisted of the\nfollowing steps:\n(1) sample definition - The relevant\nperiodical titles were selected in the\nQUALIS evaluation system of the\nCoordenação de Aperfeiçoamento de\nPessoal de Nível Superior (CAPES).\nTherefore,\ntwo\npapers\nabout\nPharmacology Industry and two papers\nabout Food Technology were selected in\nthe Scientific Electronic Library Online\n(Scielo).\n(2) count of words - these papers were\nprocessed by Software Rank Words 2.0;\n(3) listing and ranking of words - the\nsoftware produced a table in 3 columns,\ndistributed as follows: words, order of\ndecreasing frequency and rank of words;\n\n2175\n\n(4) applying Zipf ́s Laws and the\nformula of Goffman T Point - it was\nidentified the frequency where the\ntransition from high frequency words for\nlow frequency occurs;\n(5) defining Goffman T region – it was\nidentified in the ranking the region that\nconcentrates the most content-bearing\nwords that should be used for indexing\nand provide greater precision in\ninformation retrieval systems;\n(6) verification of nominalizations\nrecurrence in –ção and –mento, within\nGoffman T region, and their index terms\nfunctions, as well as the politeness\nstrategies in scientific communication.\nResults\nThe table 1 shows the concentration\nregion of words and the nominalizations\nuse frequencies that represents the\npoliteness strategies and index terms in\nthe text number one.\nTable 1 – Concentration Region\nRank\n29\n35\n36\n38\n40\n43\n44\n45\n47\n49\n\nWord\nprocesso\ncáries\nprodução\nbactérias\ncrescimento\nprodutos\nconcentração\nquantidade\nbucal\nStreptococcus\n\nFrequency\n20\n15\n14\n14\n13\n12\n12\n11\n11\n10\n\nConclusion\nThe results point to recurrence of\nnominalizations in –ção with high\nsemantic content in Goffman T Region\nand\nconfirmed\nthe\nestablished\nhypothesis and the importance of\ntheoretical and descriptive approaches\nof deverbal nominalization for the\nsubject indexing within information\nresearch systems. Finally, the recurrent\npattern in -ção contributes to the\n2176\n\nknowledge of lexical-morphological\nfeatures more productive in texts,\nmaking it of great importance to the\nprocess of identifying the scientific\ninformation content.\nReferences\nBarbosa, M.F. (2010). (Im)polidez em\nEAD. Tese (Doutorado em\nLinguística) - UFRJ, Rio de Janeiro.\nBasílio, M. M. de P. (2007). Teoria\nlexical. 8. ed. revista e atualizada.\nSão Paulo: Ática.\nBazerman, C. (2006). Gêneros textuais,\ntipificação e interação. São Paulo:\nEditora Cortez.\nChomsky, N. (1970). Remarks on\nnominalization. In: R. Jacobs &amp; P.\nRosenbaum (Org). Readings in\nEnglish transformational grammar.\nWaltham, MA: Ginn.\nEggins, S. (2004). An introduction to\nsystemic functional linguistics. 2. ed.\nNova York: Continuum International\nPublishing Group.\nGuedes, V. L. da S. (2010).\nNominalizações deverbais em\nartigos científicos: uma contribuição\npara a análise e a indexação temática\nda informação. Tese (Doutorado em\nLinguística) – UFRJ, Rio de\nJaneiro.\nGuedes, V.; Barbosa, M.F.; Santos, M.J.\n(2012) Recorrência de\nnominalizações deverbais em\nresumos de cartas científicas em\nlíngua portuguesa como estratégia\nlinguística de polidez. Lisboa,\nPortugal: Universidade Aberta.\nHyland, K. (2009) Academic discourse:\nEnglish in a global context. New\nYork: Continuum International\nPublishing Group.\nPao, M. L. (1978). Automatic text\nanalysis based on transition\nphenomena of word occurrences,\nJASIS, 29, p. 121-124.\n\nSantos, M. J. V. da C.(2009)\nCorrespondência científica de Bertha\nLutz: um estudo de aplicação da lei\nde Zipf e Ponto de transição de\nGoffman em um arquivo pessoal.\nPonto de Acesso, .3, p.317-323.\nSwales, J. M. (1990). Genre analysis:\nEnglish in academic and research\n\nsettings. Cambridge: Cambridge\nUniversity Press.\nVan Djck (2012). Discurso e contexto:\numa abordagem sociocognitiva. Trad\n. R. Ilari. São Paulo: Contexto\nZipf, G.K. (1949) Human behavior and\nthe Principle of Least Effort.\nCambridge, MA: Addison-Wesley.\n\n2177\n\nA VISUALIZATION TOOL FOR TOPIC\nEVOLUTION AMONG RESEARCH FIELDS\nKun Lu1, Wei Lu2, Qikai Cheng3, Shengwei Lei4 and Jiangen He5\n1\n\nkunlu@whu.edu.cn, 2reedwhu@gmail.com, 3chengqikai0806@gmail.com,\n4\nleoray1989@gmail.com, 5hejg@vip.qq.com\nSchool of Information Management, Wuhan University, Luojiashan Road No.1, Wuhan,\nHubei, China, 430072\nIntroduction\nLarge amount of scientific productions\nhave posed big challenges to understand\nthe underlying structure. Visualization\ntools can help to unveil the intriguing\nfeatures of the structure in a rather\nintuitive way. Depending on the use of\nthe visualization tool, it may help to\ndelineate the research areas within a\nfield, outline the research interests of a\nspecific author, or present other\nstructures of interests. It is common that\na research topic originated in one field\nspreads to other related fields and\nevolves over time. However, few\nexisting tools are specially designed to\nvisualize the topic evolution among\nresearch fields. The purpose of the\ncurrent study is to propose a new\nvisualization tool that focuses on\nunveiling the topic evolution among\nresearch fields over time.\nProposed method\nOverall Structure\nThe purpose of our tool is to visualize\nthe evolution of a research topic among\ndifferent fields. A research topic could\nbe related to multiple fields so the data\nis multi-dimensional. Temporal data is\nneeded to describe the evolution. We\nproposed a new method to visualize the\ncompound of the types and named it\nVIS-TopicEvo which is short for\n2178\n\n“Visualization for Topic Evolution”. A\nsummary of the overall structure of VISTopicEvo is provided in Figure 1 where\nC represents a research field (or a\nreference point), R represents a research\ntopic (or a data point), H denotes the\nhierarchical structure of the research\nfields, T represents the temporal data\nand M denotes the multi-dimensional\nrelationship between a data point and\nresearch fields. The Gr, which consists\nof R1, R2,...,R5, reflects the evolution of\na research topic over time. The GH\nreflects the hierarchical structure of\nresearch fields. And the GM represents\nthe\nmulti-dimensional\nrelationship\nbetween the research topic and related\nfields.\nT\n\nH\nM\nC3\nC4\nC1\n\nC0\n\nR1\nR2\n\nC5\n\nR3\n\nGT\n\nC6\nC2\n\nR4\n\nC7\n\nR5\n\nC8\n\nGH\n\nGM\n\nFigure 1.The overview of data structure in\nVISTMH\n\nMulti-dimensional Data Projection\nIn VIS-TopicEvo, a data point (i.e. a\nresearch topic at a given time slot) is\nrelated to multiple reference points (i.e.\nresearch fields). The multi-dimensional\ndata needs to be projected onto a 2D or\n\n3D visual space. We use a similar\nmethod as in Olsen (1993): an ndimensional space is represented as a\nregular polygon with n vertices. Each\nvertex serves as a reference point. And\ndata points are plotted as circle icons\nwithin the polygon according to their\nrelatedness with the references points.\nWe use the set C={Ci(c1,c2,...,ci,...,cp)}(i\n= 1,...,p) to denote the reference points.\nFor\neach\nreference\npoint\nCi(c1,c2,...,ci,...,cp), we define ci=1 and\nall the other elements c1,...,ci1,ci+1,...,cp=0. To construct a regular\npolygon, the position of Ci is determined\nby the coordinate Vi(xi, yi) that is\ncalculated as follows:\nP(Ci )  Vi (cos(\n\n2 i\n2 i\n)  radius,sin(\n)  radius)\np\np\n\n(1)\n\nclosely related with that research field at\nthe given time slots, and vice versa.\nTopic Evolution\nThe GT component in Figure 1\nincorporates the temporal data into VISTopicEvo. It consists of a sequence of\ndata points that represent the evolution\nof a research topic over time. To trace\nthe evolution visually, we plotted the\ndata points at different time slots in\ndifferent colours. Then we use cubic\nspline interpolation (Schumaker, 2007)\nto construct a smooth curve to connect\nthe data points. An example is given in\nFigure 2 to illustrate our approach to\nvisualize the topic evolution.\n\nwhere the radius is a parameter to adjust\nthe size of the picture. A data point Rj is\ndefined as Rj=(r1,r2,...,ri,...,rp) where ri\nrepresents the relatedness score between\nthe data point and the ith reference point\nCi. We define ri as follows:\n∑\n(∑\n\n∑\n\n)\n\n(∑\n\n)\n\n(2)\n\nwhere ci is the ith elements of the ith\nreference point, fi is the number of times\na research topic co-occurs with the ith\nreference point. The co-occurrence of a\nresearch topic and a reference point (i.e.\na research field) is defined as an\nobservation of a published research\npaper that covers the research topic and\nis categorized into the research field. In\nthis way, we projected our multidimensional\ndata\nonto\na\ntwo\ndimensional visual space where the\nreference points (i.e. research fields) are\nvertices and the data points (i.e. a\nresearch topic at different time slots) are\nwithin the regular polygon according to\ntheir relatedness with the reference\npoints. If they are plotted close to a\nreference point that indicates they are\n\nFigure 2. An example of topic evolution\nover time\n\nThe four vertices of the rectangle are the\nreference points which represent four\nresearch fields. The colour bar at the\nbottom\nindicates\nthe\ntemporal\ninformation of the data points. And the\nsequence of the data points unveils the\nevolution of the relationship between the\nresearch topic and the four fields over\ntime.\nResults\nIn this section, we will present our\ninitial results. We first manually\nidentified four hot interdisciplinary\nresearch topics from the author keyword\nfield (i.e. “DE” field) of the\nbibliographic records of the publications\n2179\n\nin the top journals of the “information\nscience &amp; library science” category\ndefined by Journal Citation Report 2009\n(the same journals as in Lu &amp; Wolfram,\n2012). The topic we selected is\n“information retrieval”. We then\nconducted subject searches through\nWoS portal using the topics mentioned\nabove and downloaded the results. Only\ntwo types of documents are kept in the\ndata collection: articles and conference\nproceedings. Other types are less likely\nto reflect the original research\ncontributions. The topics, queries and\nthe time ranges we used are summarized\nin Table 1:\n\ninstead of using the one year interval as\nin other pictures. We can see from the\nFigure 3 that the topic of “information\nretrieval” has a closer relationship with\nthe field of Information Science &amp;\nLibrary Science (LIS) in the early years,\nand then moves towards the field of\nComputer Science gradually. From the\nbeginning of this century, Computer\nScience\nbecame\nthe\ndominant\ncontributor to this topic. However, we\ncan also find that the curve has a\ntendency to move back a little bit to LIS\nfield more recently.\n\nTable 1. The queries and time range used\nto collect our data\nTopic\ninformation\nretrieval\n\nQuery\n“information\nretrieval”\n\nTime range\n1956-2011\n\nTo obtain the co-occurrence data (i.e. fi\nin equation 2) of the research topics and\nthe research fields, we counted the\nnumber of times a given WoS category\n(i.e. “WC” field) appears in these\nbibliographic records for each topic. The\nmore frequently a given category\nappears in the records, the closer\nrelationship the topic has with the\ncategory. It is possible for a publication\nto be assigned to more than one\ncategories. In this case, we added the\ncounts to all of them equally.\nWe deliberately selected a longer time\nspan to trace the development of the\ntopic after Mooers first coined the term\nin 1950. However, we did not find any\npublications from WoS in our search\nresults during the time period of 1950 to\n1955. So we eventually set the time\nrange from 1956 to 2011. As the time\nrange is longer, to avoid too many data\npoints that overwhelm the picture we\nadjusted the time interval between the\nneighbouring data points to four years\n2180\n\nFigure 3.Topic evolution of “information\nretrieval”\n\nConclusion\nMany visualization tools have been\ndeveloped to help understand the\nstructure of science. While few existing\ntools are specially designed to visualize\nthe\ntopic\nevolution\nof\nan\ninterdisciplinary research topic among\nrelated research fields. We designed\nVIS-TopicEvo to address this particular\nproblem. Our initial results show the\npromise to trace the development and\nevolution of a research topic among\nrelated research fields visually. The\npictures provide an intuitive way to\nunderstand the trace of a topic and help\nto gain a historical perspective on it.\n\nReferences\nLu, K., &amp; Wolfram, D.\n(2012).Measuring author research\nrelatedness: A comparison of wordbased, topic-based, and author\ncocitation approaches. Journal of the\nAmerican Society for Information\nScience and Technology, 63, 19731986.\n\nOlsen, K. A., Korfhage, R. R., Sochats,\nK. M., Spring, M. B.&amp; Williams, J.\nG. (1993). Visualization of a\ndocument collection: The vibe\nsystem. Information Processing &amp;\nManagement, 29(1), 69-81.\nSchumaker, L. (2007). Spline Functions:\nBasic Theory. London: Cambridge\nUniversity Press.\n\n2181\n\nVISUALIZING THE RESEARCH DOMAIN ON\nSCIENTOMETRICS (1978-2012)\nQiu JunPing1 and Lv Hong2\n1\n\njpqiu@whu.edu.cn\nWuhan University, Research Centre of Science Evaluation, 430072 Wuhan (P. R. China)\n2\n\nlyu@whu.edu.cn\nWuhan University, School of Information Management, 430072 Wuhan (P. R. China)\nIntroduction\nVisualization method has become an\nimportant research method, and has\nbeen used in many fields. By use this\nmethod, the scope of and trends in\ninvestigations, to some extent, their\nresearch level can be objectively\nevaluated. We examined the research\nstatus quo of this discipline by\nvisualization of knowledge map on\nscientometrics in order to learn about its\ndevelopment and evolution process.\nMaterials and methods\nThe data contains all types of documents\npublished in Scientometrics journal from\n1978 to 2012. A full bibliographic\nrecord in Web of Science is used, each\nrecord contains fields such as author,\ntitle, abstract, keywords, and references\nand so on. The retrieval was finally\nupdated on November 14, 2012 (journal\nScientometrics was finally updated on\nOctober 2012). The resultant dataset\ncontains a total of 3,324 records, 1679\n(50.51%) of total set which were\npublished during 2002-2012. By change\nof the number of papers reflects the\nstudy of scientometrics is focus.\nInformation visualization tool with Java\napplication named CiteSpace (Chen,\n2006) was selected as the research tool\nto assist analysis, and version is 3.0.R5.\n\n2182\n\nTable 1. The top 30 most highly cited\nscholars in the author co-citation network\nNo.\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\nScholar\nGARFIELD E\nPRICE DJD\nGLANZEL W\nNARIN F\nMOED HF\nSCHUBERT A\nBraun T\nLEYDESDORFF L\nSMALL H\nVan Raan AFJ\nEGGHE L\nHirsch JE\nROUSSEAU R\nCALLON M\nVINKLER P\nKatz JS\nCronin B\nMERTON RK\nMARTIN BR\nCOLE S\nBornmann L\nZitt M\nWhite HD\nLUUKKONEN T\nMORAVCSIK MJ\nCOLE JR\nMeyer M\nTIJSSEN RJW\nNEDERHOF AJ\nFRAME JD\n\nFrequency\n753\n543\n489\n435\n409\n395\n358\n357\n342\n316\n313\n193\n174\n156\n155\n145\n139\n135\n133\n130\n129\n128\n125\n123\n120\n119\n119\n117\n115\n112\n\nResults\nAnalysis of most highly cited scholars\nAuthor co-citation analysis (ACA)\napproach provides a useful tool for\nidentifying major specialties and\nresearchers and their interrelationships\n(Zhao &amp; Strotmann, 2011). In terms of\ncitations, ACA aims to provide a useful\nglimpse of the dynamic intellectual\nstructure of the contributing research\ncommunity. Generally speaking, authors\nwith most citations tend to be those\nresearchers carrying out the fundamental\nresearch tasks in their subject. Who have\nmade important and fundamental impact\non the development and evolution of\nscientometrics? By analysis of the\nauthor co-citation network, these\nscholars can be found. Tab. 1 lists the\ntop 30 most highly cited scholars in the\nACA network in the field of\nscientometrics.\nAnalysis of document co-citation\nnetwork\nCiteSpace represents the literature in\nterms of a network synthesized from a\nseries of individual networks, and\nintegrates these individual networks and\nform s an overview of how a scientific\nfield has been evolving over time (Chen\net al., 2012). The most cited articles are\nusually regarded as the landmarks due to\ntheir ground-breaking contributions.\nTop 10 most highly cited papers ranked\n10th in Tab. 2, and summarizes their\ncitation\nfrequency,\nbetweenness\ncentrality and source. The table shows\nthe top 10 most highly cited papers in\nthe visualization map are Hirsch’s\n(2005) paper, Price’s (1963) paper,\nLotka’s (1926) paper, Garfield’s (1972)\npaper, Small’s (1973) paper, Schubert’s\n(1986) paper, Price’s (1965) paper,\nGarfield’s (1979c) paper, Schubert’s\n(1989) paper, and Katz’s (1997) paper.\n\nTable 2. The top 10 most cited papers in\nthe scientometrics dataset from 1978 to\n2012\nFrequency\n\nBetweenness\ncentrality\n\n1\n\n189\n\n0.00\n\n2\n\n152\n\n0.22\n\n3\n\n115\n\n0.16\n\n4\n\n99\n\n0.15\n\n5\n\n99\n\n0.28\n\n6\n\n94\n\n0.35\n\n7\n\n93\n\n0.24\n\n8\n\n91\n\n0.16\n\n9\n\n91\n\n0.25\n\n10\n\n82\n\n0.07\n\nNo.\n\nCited\nSource\nrefer(Abbreviations)\nence\nHirsch P NATL ACAD\n(2005)\nSCI USA\nPrice\nNY: Columbia\n(1963) University Press\nJ\nLotka\nWASHINGTO\n(1926)\nN ACADEMY\nGarfield\nSCIENCE\n(1972)\nSmall\nJ AM SOC\n(1973) INFORM SCI\nSchubert SCIENTOMET\n(1986)\nRICS\nPrice\nSCIENCE\n(1965)\nGarfield NY: John Wiley\n(1979c)\nand Sons\nSchubert SCIENTOMET\n(1989)\nRICS\nKatz\nRES POLICY\n(1997)\n\nAnalysis of research hotspots\nGenerally speaking, keywords are the\nprimary content of the article extracted\nby paper authors, and noun phrases with\nhigh frequency from extracted from\ntitles and abstracts are important to a\npaper, thus through analysis of terms\nsuch as keywords and noun phrases can\nhelp us identify hot topics of research on\nscientometrics. Tab. 3 lists the top 26\nterms with co-occurrence frequency of\nover 70 times. Firstly, high-frequency\nterms on scientometrics indicators and\nmodels mainly include indicators with\n252 times, impact with 206 times,\nimpact factor with 137 times, h-index\nwith 80 times, index with 76 times, and\nmodel with 58 times and so on.\nSecondly, high-frequency terms on\nscience communication tools mainly\ninclude journals with 170 times, science\ncitation index with 149 times,\npublications and scientific journals with\n72 times respectively, publication with\n2183\n\n66 times, scientific production with 65\ntimes, and scientific output with 64\ntimes and so on. Thirdly, high-frequency\nterms\non\nbibliometrics\ninclude\nbibliometric analysis with 128 times,\ncitation with 118 times, bibliometrics\nwith 108 times, citations and citation\nanalysis with 102 times respectively,\nand bibliometric indicators with 73\ntimes and so on. Fourthly, Highfrequency terms on include technology\nwith 114 times, collaboration with 101\ntimes, innovation with 90 times,\nperformance with 80 times, research\nperformance with 79 times and\ninternational collaboration with 75 times\nand so on.\nTable 3. Terms with frequency more than\n70 times in the scientometrics dataset\nNo. Frequency Keywords\\noun phrases\n1\n548\nscience\n2\n252\nindicators\n3\n206\nimpact\n4\n170\njournals\n5\n149\nscience citation index\n6\n137\nimpact factor\n7\n128\nbibliometric analysis\n8\n118\ncitation\n9\n114\ntechnology\n10\n108\nbibliometrics\n11\n102\ncitations\n12\n102\ncitation analysis\n13\n101\ncollaboration\n\n2184\n\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n99\n92\n90\n80\n80\n80\n79\n76\n75\n73\n73\n72\n72\n\npatterns\ncitation analysis\ninnovation\nh-index\nsocial sciences\nperformance\nresearch performance\nindex\ninternational collaboration\nbibliometric indicators\nresearch performance\npublications\nscientific journals\n\nReferences\nChen, C. M. (2006). CiteSpace II:\nDetecting and visualizing emerging\ntrends and transient patterns in\nscientific literature. Journal of the\nAmerican Society for Information\nScience and Technology, 57(3), 359377.\nZhao, D. Z. &amp; Strotmann, A. (2011).\nIntellectual structure of stem cell\nresearch: a comprehensive author cocitation analysis of a highly\ncollaborative and multidisciplinary\nfield. Scientometrics, 87(1), 115131.\nChen, C. M., Hu, Z. G., Liu, S. B. &amp;\nTseng, H. (2012). Emerging trends\nin regenerative medicine: a\nscientometric analysis in CiteSpace.\nExpert Opinion on Biological\nTherapy, 12(5), 593-608.\n\nWEB 2.0 TOOLS FOR NETWORK MANAGEMENT\nAND PATENT ANALYSIS FOR HEALTH PUBLIC\nJorge L Magalhães1 and Luc Quoniam2\n1\n\njorgemagalhaes@far.fiocruz.br\nOswaldo Cruz Foundation/Fiocruz, CEP 21041-250, Rio de Janeiro; Capes Fellow\n12.298-3 (Brazil); Aix-Marseille Université (France)\n2\n\nmail@quoniam.info\nUniversité du Sud Toulon-Var; Université Paul Cézanne Aix-Marseille III (France)\nIntroduction\nAccording to the Organization for\nEconomic\nCooperation\nand\nDevelopment (OECD), 55% of global\nwealth is in the knowledge (OECD,\n2008). In the same way Drucker\n(Drucker, 2006) points out that increase\nin the knowledge generation will occur\nwith the increase of the knowledge\nmanagement.\nNew\ntrends\nare\ninfluencing industrial development of\ncountries like knowledge used as main\nresource and the learning as a central\nprocess. In this sense, it is essential\nalways to broaden expertise base in\nhuman resources and hence increasing\nthe innovation potential (Lastres, HMM\n&amp; Sarita, A, 1999).\nForming competencies to innovate\nrequires previously thinking as an\nintelligence\ncooperative\ncan\ntransforming\nthe\nknowledge\nconstruction in collaboration with peers\nat work. This mindset requires\ncollaborative development processes\ncapable of producing high quality\ninformation\nfor\nscientific\nand\ntechnological knowledge. In this\nscenario, experts have unrestricted\naccess to information created by the\nscientific community, collaborative\nreview of the contributions of members,\ngovernance based more on authority\n\nthan on sanctions and involvement in\nintegrated levels and responsibilities\n(Ambrosi, A, Peugeot, V, &amp; Pimenta, D,\n2005). Moreover, within an interactive\nenvironment requires management tools\nto aid in decision making (Vincent &amp;\nSinger, 2010). So, this work aimed to\nevince how Web 2.0 tools can help\ndeveloping and undeveloped nations\nwith network management and patent\nanalysis for health care such as\ntuberculosis – a global threat (figure 1).\n\nFigure 1. Estimated TB incidence rates\n(WHO, 2011).\n\nThus, is important to emphasize that\nintensity in research drugs and\nmedicines has contributed significantly\nfor\nimprove\ninnovation\nand\ntechnological development in the\ncountry&#x27;s health. Likewise, co-relation\nof a lot of experts in the world with\nseveral knowledge bases can contribute\nto generation of new approaches and\nresults as well as assist in better decision\n\n2185\n\nmaking by managers of companies,\ngovernments and organisations.\nMethodological Procedures\nUse of survey databases indexed with\ndata analysis and correlations via Web\n2.0. It was identified and analysed\ncountries and publications across\nresearch networks in tuberculosis\nworldwide. Moreover, it is demonstrated\nalso a specific example of technological\ninnovation\nmanagement\nusing\ntuberculosis patents.\nResults and Discussion\nKnowledgement management\nOn grounds need to better management\nof information from the &quot;Knowledge\nAge&quot; should be considered an\nadaptation to actual conditions of each\nlocal culture and collaboration for\nR,D&amp;I through collaborative networks\nfor dissemination of the knowledge\naiming development and innovation. (Le\nMoigne, Jean-Louis, 1994; Quoniam, L,\nLucien, A, 2010). Like this process is\nincreasingly complex it becomes need\nmultidisciplinary teams for a systemic\nview given that search engines have\nevolved from manual information’s for\nportals or websites dedicated (Web 1.0\nto Web 2.0) - passed for a massive\namount of information in an automated\nmodel (Quoniam, L, Lucien, A, 2010).\nThus, considering the democratization\nof knowledge provided by the Web 2.0\ntools using open access, it is possible to\ndemonstrate the use of indicators for\nnon-specialists democratized.\nPublic health matter\nWHO Constitution enshrines as a\nfundamental right to health of every\nhuman being access to timely,\nacceptable, and affordable health care of\nappropriate quality (“WHO | The right\nto health”, 2012). However, this &quot;health&quot;\n2186\n\ndoes not reached properly to most of the\nworld population (WHO, 2008) of\nwhich 80% live in middle or low income\ncountries. Its worst when there is a lack\nof medicines for neglected diseases\n(ND) which affect mainly populations\nwith low purchasing power – they do\nnot provide sufficient incentive for\npharmaceutical industry to invest in\nR,D&amp;I. WHO estimates that there are\nabout 1 billion people suffering some\nND such as Tuberculosis (TB). Situation\nis best understood when it’s think in\nneglected populations, i.e., include not\nonly new treatments for ND but also\naccess to antimicrobials, affordable\nmedicines for diseases with global\nimpact as diabetes and cancer (Moon,\nBermudez, &amp; ’t Hoen, 2012). Figure 2\nshows a scenario of global disease alert,\namong them TB.\n\nFigure 2. Global health map – Dez/2012.\n\nWHO estimates that it affects two\nbillion people, which means that a third\nof the world’s population is infected\nwith the bacillus Mycobacterium\ntuberculosis (M.tb). TB has no new drug\nfor more than half a century.\nInformation technology\nMapping and location partnerships\nencourage better planning of R,D&amp;I for\nbusinesses and institutions. It’s possible\nto analyse expert information about their\nwork and performance. Info planned and\norganized provides subsidies managers\nto define public policies and stimulate\nresearch. Likewise, in management of\nDN field whether in prevention, control,\ntreatments and new technologies\n\n(Magalhaes, JL, Antunes, AMS, &amp;\nBoechat, N, 2012). Morel et al (2009)\nshows that co-authorship network\nanalysis could become an important tool\nfor international organizations or\npartnerships targeting the elimination or\ndiseases eradication (Morel, Serruya,\nPenna, &amp; Guimarães, 2009).\nBibliometric analysis on dez/2012 in\nPubMed database shows double the\ngrowth compared to publications in the\nearly 21st century, as well as relations\nand co-relations on theme, trends etc –\nabout 190.000. Figure 3 shows local\nR,D&amp;I in TB. There is research intensity\nin the countries with the highest amount\nof points on the map.\n\nFigure 3. Network for TB research.\n\nFinal consideration\n The use Web 2.0 tools for analyse\nR,D&amp;I in technological forecasting\nfor TB is effective. Notwithstanding,\nlocation mapping of network for\npromote knowledge management in\ninstitutions.\n The\ndemocratization\nof\nthe\nindicators serve as tools for decision\nmakers, especially for health care in\nleast developed countries that do not\nhave access to new technologies.\nReferences\nAmbrosi, A, Peugeot, V, &amp; Pimenta, D.\n(2005). Enjeux de mots - Regards\nmulticulturels sur les sociétés de\nl’information. France: C&amp;F Editions.\nRecuperado de\nhttp://www.decitre.fr/livres/enjeuxde-mots-\n\n9782915825039.html#table_of_cont\nent\nDrucker, P. (2006). Desafios Gerenciais\npara o Século XXI. Cengage\nLearning Editores.\nLastres, HMM, &amp; Sarita, A. (1999).\nInformação e Globalização na Era\ndo Conhecimento. Rio de Janeiro:\nEditora Campus Ltda.\nLe Moigne, Jean-Louis. (1994). La\nthéorie du Système Géneral: théorie\nde la modélisation. France.\nMagalhaes, JL, Antunes, AMS, &amp;\nBoechat, N. (2012). Technological\nTrends in the Pharmaceutical\nIndustry: the matter of neglected\ntropical diseases – An overview of\nthe Research, Development &amp;\nInnovation in Brazil. Synergia\nEditora. Recuperado de\nhttp://www.livrariasynergia.com.br/l\nivros/M39700/9788561325732/tende\nncias-tecnologicas-no-setorfarmaceutico-a-questao-das-doencastropicais-negligenciadas-edicaobilingue.html\nMoon, S., Bermudez, J., &amp; ’t Hoen, E.\n(2012). Innovation and Access to\nMedicines for Neglected\nPopulations: Could a Treaty Address\na Broken Pharmaceutical R&amp;D\nSystem? PLoS Med, 9(5), e1001218.\ndoi:10.1371/journal.pmed.1001218\nMorel, C. M., Serruya, S. J., Penna, G.\nO., &amp; Guimarães, R. (2009). Coauthorship Network Analysis: A\nPowerful Tool for Strategic Planning\nof Research, Development and\nCapacity Building Programs on\nNeglected Diseases. (M. Tanner,\nOrg.)PLoS Neglected Tropical\nDiseases, 3(8), e501.\ndoi:10.1371/journal.pntd.0000501\nOECD. (2008). OECD Annual Report\n2008 (p. 118). Paris, France:\nOrganisation for Economic Cooperation and Development.\nRecuperado de\n\n2187\n\nhttp://www.oecd.org/newsroom/405\n56222.pdf\nQuoniam, L, Lucien, A. (2010).\nIntelligence compétitive 2.0 :\norganisation, innovation et\nterritoire. France: Librairie\nLavoisier. Recuperado de\nhttp://www.lavoisier.fr/livre/notice.a\nsp?ouvrage=2139418&amp;pos=8\nVincent, J.-L., &amp; Singer, M. (2010).\nCritical care: advances and future\nperspectives. The Lancet, 376(9749),\n1354–1361. doi:10.1016/S01406736(10)60575-2\n\n2188\n\nWHO. (2008). WHO | Sixty-first World\nHealth Assembly. Recuperado de\nhttp://www.who.int/mediacentre/eve\nnts/2008/wha61/en/index.html\nWHO | The right to health. (2012).\nWHO. Recuperado 18 de janeiro de\n2013, de\nhttp://www.who.int/mediacentre/fact\nsheets/fs323/en/\nAcknowledgments\nThank CAPES Grant and infrastructure\nsupport at Aix-Marseille Université,\nFrance, as well as METICA’s Lab in\nFaculté des Sciences Saint Jerôme.\n\nWEIGHTING CO-CITATION PROXIMITY BASED\nON CITATION CONTEXT\nBo Wang1 , Kun Ding1, Shengbo Liu1\n1\n\nbowang1121@gmail.com, dingk@dlut.edu.cn , liushengbo1121@gmail.com\nWiselab Dalian University of technology, No.2 Linggong Road, Ganjingzi district,\nDalian, 116024 (China)\nIntroduction\nCo-citation is defined as a linkage\nbetween two documents concurrently\ncited by another document (Small,\n1973). Traditional co-citation analysis\ndoes not take into account the proximity\nof references co-cited by an article.\nSome references are cited within the\nsame sentence, whereas other references\nmay be cited in further-apart positions in\nan article. Many studies have confirmed\nthat the co-citation proximity could\naffect the co-citation analysis (Elkiss el\nal, 2008;\nGipp and Beel, 2009 ;\nCallahan et al , 2010; Liu and Chen,\n2011). Some of them tried to set the\nweight\nof\ndifferent\nco-citation\nproximities based on co-citation position\nor distance. The nearest co-citation\ndistance was given the highest weight,\nand the furthest co-citation distance was\ngiven the lowest weight. The setting of\nthe weight values was always depending\non subjective experiences. They set the\nsmaller co-citation proximity with\nhigher weight, because people usually\nthink that papers with smaller cocitation proximity tend to cited by the\nsimilar topic. But in different subject\nareas, the influence of co-citation\nproximity may be different. It is\nimprecise to use a subjective weight of\nco-citation proximity in various fields.\nHow could we set the weight of cocitation proximity that could be suitable\nto all the fields? In this paper, we\n\npropose a weight setting method based\non the similarity of the citation context\nof the cited papers. The citation context\nof a given reference can be defined as\nthe sentences that contain a citation of\nthe reference. For instance, the sentence\n“This comparison is made using\nBLASTX [18]” is the citation context of\nreference [18].\nData and Method\nThe co-citation proximity analysis\nrequires\nnot\nonly\nbibliographic\ninformation, but also the full text of an\narticle. In this research, we utilize the\nPubMed Central database. In particular,\nreferences and full text information from\nBMC Bioinformatics, BMC Systems\nBiology, and BMC Biology are extracted\nand analysed. The numbers of articles in\nthe three journals are 5412, 905 and 638,\nrespectively, from periods of 20012012, 2007-2012 and 2003-2012.\nCo-citation proximity\nCo-citations in a citing paper are\nconsidered at four levels of proximity,\nnamely, the article level, the section\nlevel, the paragraph level and the\nsentence level. If two references are\ncited within the same sentence, the cocitation instance is called a sentencelevel co-citation. If two references are\ncited in different sentences but within\nthe same paragraph, it is called a\nparagraph-level co-citation. Similarly,\ntwo references cited in different\n2189\n\nparagraphs but within the same section\ndefine a section-level co-citation.\nFinally, if two references are cited in\ndifferent sections but within the same\npaper, we have an article-level cocitation.\nThe weight of different co-citation\nproximity\nThe similarity of the co-cited contexts\ninevitable exist some differences when\nthey occurred in different co-citation\nlevels. If two citation contexts contain a\nsame topic word or more, they will be\nmarked as similar. If they do not have\nsame topic words, they will be marked\nas not similar. The similarity of the cocited contexts was calculated by using\nthe following formula.\n1, CA and CB contain the same topic words\nSimilarity(CA, CB)  \n0, CA and CB do not have the same topic words\n\nAssuming there are N co-citation\ninstances in a particular co-citation\nlevel, M of N co-citation instances are\nsimilar. The average similarity of the cocitation instances in this level is M/N,\nwhich means that if two references cocited in this co-citation level, the similar\nprobability of the co-cited references is\nM/N. The probability M/N would be\ntreated as the weight of this co-citation\nlevel.\nCompare the weighted co-citation\nanalysis with traditional co-citation\nanalysis\nCo-citation clustering method was\ncommonly used in co-citation analysis.\nThe co-citation clusters were always\nused to reveal the research fronts of the\nciting papers. After weighting the cocitation strength at different co-citation\nlevels, the co-citation clustering results\nmight have some changes. These\nchanges\nmay\nalso\naffect\nthe\nidentification of the research fronts.\n2190\n\nHierarchical clustering method was\nemployed to cluster the co-citation\npapers. Co-cited papers with co-citation\nfrequency 10 or more will be chosen for\nthis experiment. The similarity of the\nco-cited papers was calculated with the\nfollowing formula.\nSimilarity ( DA, DB ) \n\nFrequencyAB\nFrequencyA  FrequencyB\n\nFor the weighted co-citation clustering,\nthe strength of the co-cited papers was\ncalculated as follows.\nStrength( DA, DB )  i 1 (Weight ( Pi )  FrequencyAB( Pi ))\n4\n\nPi was the i level co-citation. ( i=1:\nsentence level; i=2: paragraph level; i=3:\nsection level; i=4: article level ).\nThe similarity of the co-cited papers was\ncalculated as follows.\nSimilarity ( DA, DB ) \n\nStrength( DA, DB )\nFrequencyA  FrequencyB\n\nThe clusters of the traditional co-citation\nwill have some changes after weighting\nthe co-citation strength. Some of the\ncited papers might move from one\ncluster to another. And then the citing\npapers of the clusters will change\nsubsequently. The changes of the citing\npapers will be traced to reflect the\ninfluences of the moved paper. Figure 1\nshows the changes of citing papers (S1)\nof the cluster (C1) when a cited paper\n(R1) joins to the cluster. When a new\ncited paper R1 joins to C1, papers which\nwere citing both R1 and the papers in\ncluster C1 will compose a new set S2.\nSet S3 was the intersection of S1 and\nS2. The influence of R1 to C1was that\ntopics of citing papers in S3 were\nstrengthened. In other words, the size of\nS3 could reflect the effect of R1 to C1.\n\nS1\n\nS3\n\nC1\n\nS2\n\nR1\n\nFigure 1. The influence of cited paper R1\nto cluster C1\n\nResults\nThe weight of different co-citation levels\nCo-citations with frequency 10 or more\nin three BMC journals were extracted.\nThe number of co-citation instances in\neach co-citation level was shown in\ntable 1. The related rates of four cocitation levels were 1, 0.77, 0.64 and\n0.56.\n\nArticlelevel\n\nSectionlevel\n\nParagraphlevel\n\nSentencelevel\n\nTable 1. The co-citation weight of four cocitation levels\n\nCo-citation\n2131 1146 1150 2359\ninstances\nRelated co-citation 2131\n884\n733 1321\ninstances\nRelated rates\n1\n0.77 0.64 0.56\n\nThe related rates will be treated as the\nweight of the co-citation levels. The\nweights were a little different from the\nweights in the papers of Gipp (Gipp,\n2009b) and Callahan (Callahan, 2010).\nGipp and Callahan gave a very small\nweight to the co-citations occurred in\narticle level, such as 1/4. But in our\nresearch, the article level weight reaches\n0.56.\n\nComparison of the weighted co-citation\nclustering and traditional co-citation\nclustering\nThe co-cited papers with the co-citation\nfrequency 10 or more will still be used.\nThe results of the hierarchical clustering\nshowed two obvious changes between\ntraditional co-citation clustering and\nweighted co-citation clustering. One is\nthe paper “VON MERING C, 2002,\nNATURE, V417, P399” changes from\none cluster to another after weighting\nthe co-citations. The influence of this\npaper on the earlier cluster was 62.1%.\nAnd the influence on the later cluster\nwas 86% which was better than it\nperformed in earlier cluster. Another is\nthe paper “BOECKMANN B, 2003,\nNUCLEIC ACIDS RES, V31, P365”.\nThe influence of this paper on the earlier\ncluster was 16.3% which was very low.\nAnd the influence on the later cluster\nwas 22.2%. These results indicate that\nthe weighted co-citation clustering\nperforms better than the traditional cocitation clustering on identifying the\ntopics of the citing papers.\nConclusion\nWe studied the similarity of the citation\ncontexts of the co-cited papers in each\nco-citation level. The results were used\nas the co-citation weight of the cocitation level. The co-citation weights in\n3 journals were 1, 0.77, 0.64, and 0.56.\nThese weights were used to improve the\nco-citation clustering results. The results\nshowed that the improved clusters were\nbetter in identifying the topic of the\nciting papers than traditional clusters.\nAcknowledgments\nThis research is supported by National\nNatural Science Foundation of China\n(grant\nnumber\n71003011)\nand\nFundamental Research Funds for the\nCentral Universities of China (Grant\n852010).\n2191\n\nReferences\nSmall, H. (1973). Co-citation in the\nscientific literature: A new measure\nof the relationship between two\ndocuments. Journal of the American\nsociety for information science and\ntechnology. 24,265-269.\nGipp, B &amp; Beel, J. (2009). Identifying\nrelated documents for research paper\nrecommender by CPA and COA.\nProceedings of international\nconference on education and\ninformation technology(pp. 636639). Berkeley: International\nAssociation of Engineers\nCallahan, A., Hockema, S. &amp;\nEysenbach, G.(2010). Contextual\n\n2192\n\nCocitation: Augmenting Cocitation\nAnalysis and its Applications.\nJournal of the American Society for\nInformation Science and\nTechnology. 61,1130-1143\nElkiss, A., Shen, S., Fader, A., Erkan,\nG., States, D.&amp; Radev, D. (2008) .\nBlind men and elephants: What do\ncitation summaries tell us about a\nresearch article? Journal of the\nAmerican Society for Information\nScience and Technology. 59, 51-62\nLiu, S., Chen, C.(2012). The proximity\nof co-citation. Scientometrics.\n91,495-511\n\nWHAT MEANS, IN NUMBERS, A GOLD\nSTANDARD BIOCHEMISTRY DEPARTMENT TO\nNATIONAL AGENCIES OF RESEARCH\nFOMENTATION IN BRAZIL?\nSuelen Baggio; Ben Hur M. Mussulini; Diogo Losch de Oliveira; Diogo O.\nSouza; Luciana Calabró.\nsuzy-gfbp@hotmail.com; ben_hurmussulini@yahoo.com.br; diogolosch@gmail.com;\ndiogo@ufrgs.br; luciana.calabro.berti@gmail.com\nUniversidade Federal do Rio Grande do Sul, Departamento de Bioquímica, Rua Ramiro\nBarcelos, 2600 – anexo, Porto Alegre, RS (Brazil)\nIntroduction\nThe postgraduation in Brazil has\nexperienced remarkable growth. It was\nformally established in the mid-60s\n(Velloso, 2004), reaching the 70s with\n500 postgraduate MSc program and 200\nPhD program, according to CAPES\n(Brazilian\nfunding\nagencie\nCoordenação de Aperfeiçoamento de\nPessoal de Nível Superior). Constantly\ngrowing, arrive at the year of 2010 with\n2700 MSc and 1600 PhD programs. In\nthe last global evaluation conducted by\nCAPES, in 2010, it was observed that in\na scale of 1 to 7, with 7 considered the\ninternational standard performance, the\naverage obtained by postgraduate\nprograms (PGP) in Brazil was between\n3 and 4, considered regular.\nIn the period from 1999 to 2003, Brazil\nwas responsible for 1.5% of world\nproduction (going from 23 ° to 17 °\nposition), with the best ranking of Latin\nAmerica (Berti et al., 2010). Among so\nmany areas of scientific knowledge,\nBiochemistry\nhas\nits\nhighlight,\npresenting significant results that can be\ntranslated by the data presented by the\nBiochemistry PGP at UFRGS, with\ngrade 7 (note 7 since 2001). To achieve\n7, some points are needed, such as: good\n\ninfrastructure, training human resources\nand scientific production. By analyzing\nthese factors, the Biochemistry PGP\npresents annual increases in the number\nof scientific articles published and\nformation of masters and doctors.\nIn order to increase the international\nvisibility of the UFRGS, as of the\nBiochemistry Department, and to better\nelucidate in numbers what means a note\n7 by CAPES in our country, it was\nselected the six most productive\nresearchers of this department (scientific\narticles and formation of Human\nResources), and their scientific profiles\nwere\nsubmitted\nto\nclassical\nscientometrics analysis.\nMethods\nTo achieve such goal, it was used the\ndatabases Scopus and Lattes (National\nData Base), extracting the scientific\nprofile of six researchers from the\nUFRGS Biochemistry Department (limit\ndata analysis was 12/31/2012). The\nresearchers were selected by number of\npublications and formation of human\nresources. The scientometric analyses\napplied in this study were: number of\npublished articles; formation of PhD\nstudents; total citation; total selfcitation; h index. In a last point, it was\n2193\n\ndesigned a table summarizing the\njournals in which. often these\nresearchers publish their results. The\ngraphs were obtained by GraphPad\nPrism 5.\nResults\nAs can be seen in Figure 1, the number\nof articles published by the researchers\ngoes from 345 (teacher 1) to 144\n(teacher 6). Concerning the formation of\nPhDs, Figure 2, teacher 1 formed 31\nstudents, while the others formed from\n17 to 11 PhD students.\n\nFigure 3. Number of total citations (white\nbars), self-citations (black bars), and h\nindex of each researcher (grey line).\n\nAmong the journals in which the\nresearchers mainly published their\nresults, the higher impact factor is 3.577\n(Journal of Inherited Metabolic Disease)\nand the smallest is 1.129 (International\nJournal\nOf\nDevelopmental\nNeuroscience) Table 1.\nTable 1. Journals and correspondent\nimpact factor (I.F), in which the\nresearchers mainly published their results.\n\nFigure 1. Number of scientific articles\n\nFigure 2. Number of students\n\nFigure 3 shows the total number of\ncitations, ranging from 5810 to 2268,\nand of self-citations, with values from\n1525 to 288. The h index goes from 33\nto 20.\n\n2194\n\nJournal\nNeurochemical Reserach\nBrain Research\nNeuroreport\nNeurochemistry Internacional\nInternational Journal Of\nDevelopmental Neuroscience\nMetabolic Brain Disease\nBrazilian Journal of Medical and\nBiological Research\nJournal of Inherited Metabolic\nDisease\nMolecular and Cellular Biochemistry\nFree Radical Research\nJournal of Medicinal Food\nToxicology in vitro\nBehavioral and Neural Biology\nProgress in Neuro\nPsychopharmacology and Biological\nPsychiatry\nClinical Biochemistry\nNueroscience Letters\n\nI. F.\n2,24\n2,728\n1,656\n2,857\n1,129\n2,198\n2,418\n3,577\n2,057\n2,878\n1,408\n2,775\n1,984\n3,247\n2,076\n2,105\n\nDiscussion\nThe UFRGS Biochemistry Department\nevolved over its 40 years. Among the\nfactors to this development are the\n\narrival of international consolidated\nresearchers,\nfoundation\nof\na\npostgraduate program, and fomentation\nto research from scientific agencies\n(Gomes et al. 2011). Fomentation\nagencies\nare\nincreasingly\nusing\nscientometric tools invest their limited\nresources. So, it is primordial to know\nwhat a scientific institution means in\nnumbers. Such numerical evaluation\nhelp to better understand where a\nrandom institution should focus to\ndevelop, upgrading their visibility and\ntherefore attracting more investments. In\nthis context, this study elucidates what\nCAPES and other Brazilian institutions\nconsider to perform investments.\nIn\nnumbers,\na\ngold\nstandard\nbiochemistry department in Brazil could\nmean per researcher: formation of 10\nPhD students or higher; at least 150\nscientific articles published; at least\n2200 total citation; self-citation between\n10-25% of total citation; h index 20 or\nhigher; and mean impact factor 2.5.\nThese numbers are based in our analysis\nof the six more productive researchers in\nthe department. It is important to say\nthat a more profound comparison among\nall Biochemistry Departments with note\n7 by CAPES would be better, however\nthe studies involving scientometric\nanalysis of such institutions are scarce,\nmaking such comparison of difficult\naccess.\nBias of such analysis could be negative\ncitation, high degree of self-citation,\ngreat number of articles in low impact\nfactor journals and the dilution of\nunique discoveries in high impact\njournals; nevertheless, analyzing each of\nthis point are very difficult (Hirsch,\n2005).\nWe hope that in light of these results,\nfutures\ncomparison\namong\nour\ndepartment and international institutions\ncould be performed to improve our\n\nscientific level, as well as to show for\nanother\nnational\nbiochemistry\ndepartment what is required to reach\nCAPES note 7.\nAcknowledgments\nThis work was supported by the\nBrazilian funding agencies Conselho\nNacional de Desenvolvimento Científico\ne Tecnológico (CNPq), Coordenação de\nAperfeiçoamento de Pessoal de Nível\nSuperior (CAPES) and Instituto\nNacional de Ciência e Tecnologia em\nExcitoxicidade\ne\nNeuroproteção\n(INCTEN).\nReferences\nVelloso, Jacques. (2004). Mestres e\ndoutores no país: destinos\nprofissionais e políticas de pósgraduação. Cadernos de Pesquisa, v.\n34, n. 123, p. 583-611.\nLuciana C. Berti, Diogo L. Oliveira,\nDiogo O. Souza, Susana T,\nWofchuk. (2010). Produção\ncientífica e formação de recursos\nhumanos na área de Bioquímica em\nInstituições federais do RS: fomento\nestadual. Química Nova, Vol. 33,\nNo. 3, 765-771.\nUrubatã E. Gomes, Diogo L. de\nOliveira, Luciana C. Berti, Olavo\nAmaral, Diogo O. Souza, Susana T.\nWofchuk. (2011). 37 years of\nscientific activity in a Biochemistry\nDepartament in Brazil- patterns of\ngrowth and factors leading to\nincresead productivity. Anais da\nAcademia Brasileira de Ciências,\nVol. 83, no 3, 1121-1130.\nJ. E. HIrsch. (2005). An index to\nquantify an individual ́s scientific\nresearch output. PNAS, vol. 102, no\n46, 16569-16572.\nlattes.cnpq.br\nhttp://www.scopus.com/home.url\n\n2195\n\nWHEN INNOVATION INDICATORS MEET SPINOFF COMPANIES: A BRIEF REVIEW AND\nIMPROVEMENT PROPOSAL\nZhiyu Hu\nhuzy@most.cn\nInstitute of Scientific and Technical Information of China, 15 Fuxing Road, 100038,\nBeijing (China)\nIntroduction\nSpin-off companies play a key role in\ninnovation system, benefited from\nstrong links with academia and industry\n(Locketta et al, 2005). For research and\nmanagement of innovation, it is of high\npriority to measure spin-offs with a set\nof practicable and informational\nindicators. However indicators for spinoffs in most research and statistics are\ninsufficient to provide a panorama for\ninvestigators, policy makers and\ninvestors.\nUp to date, most of the studies on spinoffs are macroscopic qualitative\nanalysis. For example, Elpida et al\n(2010) build the conceptual framework\nof spin-off chain. Clarysse et al (2011)\nperform a comparative study on\ncharacteristics of corporate spin-offs and\nuniversity ones. Furthermore, Finne et al\n(2011) report a composite indicator for\ngeneral knowledge transfer.\nPractically, spin-off companies have\nbeen only generally described in official\nguideline documents as part of the\ntechnology developing small and\nmedium enterprises (SMEs), notably,\nOslo Manual (EC, Eurostat, 2005). In\nthe latest EU Innovation Union\nScoreboard 2011, there are two\nindicators about them, SMEs innovating\nin-house (% of SMEs) and innovative\nSMEs collaborating with others (% of\nSMEs). However, both macro indicators\n2196\n\nare not specifically designed for spinoffs.\nThe Challenges faced by Innovation\nMetrics\nAlthough the pilot qualitative studies\nmake great progress of applying\ninnovation indicators to spin-offs, there\nremains\nsubstantial\nmismatching\nproblems which is attributable to spinoff’s unique characteristics.\nFor spin-off, the process of production\ngenerally equals R&amp;D. Product cost can\nbe estimated by R&amp;D expenses. This\nsimply negates the basis of traditional\nindicator of R&amp;D intensity and\nemphasizes the theoretical demand for a\nmodified indicator system for spin-offs.\nSeveral aspects are to be discussed in\ndetails.\nIn most case, the purpose to establish a\nspin-off is commonly to improve the\nmaturity\nof\ntechnology.\nUnlike\ntraditional industry, there is no tangible\nproduct, nor even new patent in some\ncase,\nfrom\nspin-off\ncompanies.\nTherefore, traditional output indicators\nbased on product data, and integral part\nof innovation index system largely, may\nnot provide an accurate readout for spinoffs.\nFurthermore, in some of current\nindicator systems, 10 employees is set as\nthe bottom line of firm’s minimum size\n(Arundel, 2009), which is not applicable\nto a large part of spin-offs and results a\n\nconsequent loss of valuable data and a\ndistorted macro-level picture.\nProduct, including knowledge, can be\ntangible or intangible. For spin-offs,\nintangible one is more routine and\nvaluable. In this regard, many earlier\ncensuses exhibit a tendency to apply\nindicators to mostly tangible capital,\nwhich prevents their direct application\nto spin-offs. For instance, total factor\nproductivity (TFP), a popular indicator\non macro-level, is apparently not\noptimal for spin-offs.\nIn summary, in spite of many preexisting indicator systems, few of them\nare specifically designed for spin-offs.\nGiven the unique properties of spin-off\nproductivity, a modification of current\ninnovation indicators is required and,\ntherefore, proposed in the present study.\nImprovement proposal for spin-off\nIndicators\nIndicators for capabilities and resources\nInput structure of spin-off can be really\ncomplicate. It’s beneficial to evaluate\ncapabilities or resources, rather than\ninputs.\nInvestment attracted can be a standard\nskill meter, as an indicator for capital.\nThis information is probably available\nfrom survey of venture capitals or from\nassociative organisations, such as\nbusiness angel networks.\nAnother\nimportant\nindicator\nis\nmanagement skills, which covers\nentrepreneurship,\nleadership\nand\nbusiness skill of the core members. Lack\nof experienced managers is one of the\nmost common reasons of spin-offs’\nfailure. The Canadian Survey on the\nCommercialisation of Innovation 2007\nset a good example of application of\nmanagement skill indicator.\n\nIndicators for environment and linkages\nAs nonlinear interaction mode of\ninnovation is generally accepted,\nindicators for linkage should be put in\nthe heart of metrics for spin-offs.\nIn most research and practical works,\nthere are four common indicators, Copublications, Co-patenting, Licenses,\nand finally Contract R&amp;D, even in case\nof relationship among companies. They\nare important but insufficient in the\nabsence of other connections, such as\nbusiness consulting, training, etc.\nLinkage indicators covering commercial\nlinkages are necessary supplements to\ntechnical touch.\nIn addition, traditional indicators don’t\nmeasure connections with business\nangles, or start-up capital. Angle\ninvestment information is likely\navailable in trade publications or\nnewsletters of associations.\nIndicators for growth and potential\nMost traditional surveys obtain outputs\ndata\nfor\nstatistics.\nRecently,\nmethodology switches from static to\ndynamic. It is necessary and valuable to\nmove indicators from outputs (static) to\ngrowth and potential (dynamic) of a\nspin-off.\nEmpirical studies about firm growth\nshould be highly appreciated, such as\nGeroski (2003) using a sample of 147\nUK firms observed continually for more\nthan 30 years. Zhao (2011) classify\ngrowth paths and factors affecting.\nA slightly revised innovation survey\nmetrics should be used to identify fastgrowing spin-off or “gazelles”. Speeds\nof employment changing or virtual\nmarket value growth will be meaningful\nindicators for evaluations.\n\n2197\n\nSummary of all indicators\nThere is a summary of all indicators in\nFigure 1. All elements in three\ndimensions form a sturdy structural\nmodel. In each dimensions, several\ntraditional\ninnovation\nindicators\nintegrate with proposed modified\ninnovation indicators. This model may\nbe\napplying\nto\ncomprehensive\nquantitative evaluation for future\nresearch.\nGrowth and Potential\nOutputs data,\nSpeed of grow up*,\nPaths classified*,\nTechnology maturity*.\n\nCapabilities\nand Resources\nStaff technical skills,\nManagement skills*,\nInvestment got*,\nTotal capital*.\n\nEnvironment\nand Linkages\nTechnical cooperation,\nCommercial cooperative*,\nGeographic information*,\nCompetitive environment*.\n\nFigure 1. Model of Modified Innovation\nIndicators for Spin-offs. Proposed\nmodified indicators marked with“*”.\n\nPotential applications\nI propose that this modified set of\ninnovation indicators for spin-off\ncompanies warrants further validation\nand modification in empirical research.\nThe application of modified innovation\nindicators will potentially increase the\nresolution of national or regional\ninnovation surveys and research.\nMoreover,\nmodified\ninnovation\nindicators can be applied to evaluate a\ngiven spin-off company so as to provide\na more comprehensive spectrum of\ninformation to potential investors and\ninvestigators.\n\n2198\n\nAcknowledgments\nThis work is supported by the National\nNatural Science Foundation of China.\nReferences\nArundel, A., Lorenz, E., Lundvall, B.\nÅ., &amp; Valeyre, A. (2007). How\nEurope&#x27;s economies learn: a\ncomparison of work organization\nand innovation mode for the EU-15.\nIndustrial and Corporate Change,\n16(6), 1175-1210.\nArundel, A., O&#x27;Brien, K. R. (2009).\nInnovation metrics for Australia.\nClarysse, B., Wright, M. and Van de\nVelde, E. (2011). Entrepreneurial\nOrigin, Technological Knowledge,\nand the Growth of Spin-Off\nCompanies. Journal of Management\nStudies, 48(6), 1420–1442.\nElpida, S., Galanakis, K., Bakouros, I.,\n&amp; Platias, S. (2010). The Spin-off\nChain. J. Technol. Manag. Innov.,\n5(3), 51-68.\nEuropean Commission, Eurostat,\n(2005). Oslo Manual: Guidelines for\nCollecting and Interpreting\nInnovation Data, 3rd Edition. Paris:\nOECD Publishing\nEuropean Union, (2012). Innovation\nUnion Scoreboard 2011. Brussel:\nEU Publishing\nFinne, H., Day, A. &amp; Piccaluga, A, etc.\n(2011). A Composite Indicator for\nKnowledge Transfer, Report from\nthe European Commission’s Expert\nGroup on Knowledge Transfer\nIndicators. Trondheim\nGeroski, P. A., Lazarova, S., Urga, G.\netc. (2003), Are differences in firm\nsize transitory or permanent? J.\nAppl. Econ., 18: 47–59.\nLocketta, A., Siegelb, D. &amp; Wrightc,\nM., etc. (2005). The creation of spinoff firms at public research\ninstitutions: Managerial and policy\nimplications. Research Policy, 34(7),\n987-983.\n\nZhao, C., Wang, J., Zhou, Q., (2011),\nResearch oil the enterprise growth\npath from the perspective of\nintellectual capital: A case study of\n\nhigh·tech SMEs. Business\nEconomics and Administration,\n(12):61-69\n\n2199\n\nWHERE NATURAL SCIENCES (PHYSICS) MADE\nIN THE WORLD AND IN RUSSIA: 3-DECADES\nDYNAMICS\nMichael Romanovsky\nslon@kapella.gpi.ru\nA.M.Prokhorov General Physics Institute, Vavilov str., 38, 119991 Moscow (Russia)\nIntroduction\nThere the principal question what form\nof research organization is more\nsuccessful with respect to scientometric\nindicators like the number of publication\nand citation per one researcher, etc. It is\nclear\nthat\nthe\ngeneral\ncrossconsideration among all countries\ninvolved into research process contains\nseveral principal difficulties. The first\none is the language factor. Non-English\nspeaking scientific journals as well as\nnon-English speaking countries are in\nworth conditions with respect to\ncitation. Attempts to equalize these\nconditions have led (in continental\nEurope) to the disappearing of scientific\njournal on national languages like\nNuovo Cimento, etc. Nevertheless, the\nEnglish language of the scientific\njournal does not provide the rise of\nimpact-factor\nof\nthe\njournal\nimmediately. Correspondingly, the\ncountry that starts to publish scientific\npapers in English does not esquire any\npreferences automatically, and newlyAnglicized scientific journals do not\nesquire soon the addition impact-factor.\nAbove that, publication traditions are\nvaried from country to country:\nsomewhere, it is convenient to publish\nscientific results soon, somewhere – not.\nAs a result, leading impact-factor\njournals are publishing in the USA, and\nUK. Scientists form these countries as\nwell as other English-speaking countries\n2200\n\nhave some advantages in comparison\nwith scientists from other countries.\nThe financing of scientific groups is\nanother powerful cause of the difference\nin quantity and “quality” of scientific\npapers. This factor may be strongly\nchanged from country to country and\nnot so strongly from one scientific group\nto another one inside one country. Thus\nthere is big difference in direct\ncomparisons of scientists and scientific\ngroups in different countries. On the\nother hand, this difference goes away if\nscientists and scientific groups of one\ncountry are estimated using above\nscientometric indicators.\nMoreover,\nthey can be estimated directly using\npublication in leading foreign scientific\njournals. For non-English speaking\ncountries it can be leading journal like\nNature, Science, etc. We will analyze\nwhat “part of science” is made in\nuniversities, and in other research\norganizations. Specifically for Russia,\nwe will analyze three types of research\norganizations: Russian Academy of\nSciences, universities, and others.\nMethod of analysis [1]\nWe will analyse the number of\npublications in two scientific journals:\nNature (only the main issue not special\nones), and Physical Review Letters\n(PRL). The choice of these journals was\ndue to the fact that they exist in present\nview during all period of analysis. Three\ndecades: 1981-1990, 1991-2000, and\n\n2001-2010 have been chosen. We use\ndata from ISI Web of Knowledge. Name\nof journals (Nature or Physical Review\nLetters), country name, and the decade\n(for\nexample,\n1981-1990)\nwere\nindicated there. Scientific articles were\nselected only. As a result, the table with\nnames of research organizations,\nnumber of publications of these\norganizations, and the part of these\norganizations was generated.\nThis table contained not only the\ncountry under analysis since ISI Web of\nKnowledge accounts all countries of coauthors. There was the crucial\nassumption to consider research\norganizations from the considered\ncountry and discard all others. The error\nintroduced by this assumption may arise\ndue to various distributions of coauthors number for different research\norganizations. We suppose that this\nerror did not significant. Note that the\nnumber of co-authors may vary with\nrespect to the type of research\norganization. Indeed, such organizations\nlike Max-Plank-Society in Germany,\nNational laboratories in the USA,\nRussian Academy of Sciences are more\nall-sufficient (in facilities, materials,\netc.) in comparison with universities.\nTherefore, scientists from such research\norganizations do not need wide coauthoring of their scientific articles. The\nlast wide co-authoring leads to some\noverstating of articles from universities\nin final results.\nResults\nThe analysis of origin of articles from\nGermany and the USA was done for\njournals Nature and PRL provided the\nanswer “What part of (fundamental)\nphysics is made in universities and other\nresearch organization?” for decades\n1981-1990, 1991-2000, and 2001-2010.\nFigure 1 presents the parts of articles\nfrom the USA in Nature and PRL from\n\nUniversities and other organization (4\ntriples), the dark left column in each\ntriple represents 1981-1990 period, more\nhell central column – 1991-2000, hell\nright column – 2001-2010:\n\nFigure 1. Parts of articles in Nature and\nPRL from the USA Universities and other\norganizations in Nature and PRL (4\ntriples).\n\nIt is seen the drop of publications part of\nother research organizations in time. It\nmay connect with the noted fact of more\nwide co-authoring of papers from\nuniversities since universities are not so\nall-sufficient\nin\nfundamental\ninvestigations. The research facility\nbecame more complicated during last 30\nyears and now is too expensive for the\nmiddle USA university. The drop of\narticles in PRL of part of non-university\nresearch organizations in period of 30\nyears is stronger than in Nature since\nphysics is the most expensive science.\nThe same analysis was done for German\nresearch organizations, results were\nslightly different from USA ones. For all\nnatural sciences published articles in\nNature, the university part became\nlarger than the part of other\norganizations even in this century. Other\nresearch organizations in Germany are\nincluded in societies like Max-PlankSociety, Leibniz Association, etc.\nmostly. From the other hand, large\nnumber of publications from medical\ncentres like “Charite” in Berlin belonged\n\n2201\n\nto universities and accounted in the\nuniversity part (see Figure 2):\n\nthat physics is produced in other\nresearch organizations of Russia mostly\nin a new age in comparison especially\nwith last decade of the USSR: it is\nconnected with the closed character of\nconducted work in other research\norganizations.\n\nFigure 2. Parts of articles in Nature and\nPRL from Universities and other research\norganizations of Germany (the structure is\nthe same that in Figure 1).\n\nThus the answer on the question “Where\nis the fundamental science made in\nGermany?” is not so clear that for the\nUSA. At the same time, German\npublications in PRL clearly drop in time\nas it is in the USA. This drop of physical\npublications\nfrom\nnon-university\nresearch organizations in Germany may\nbe connected with the above speculation\nof widening of co-authoring in German\nuniversities like in the USA.\nThe\nsituation\nwith\nfundamental\ninvestigations in Russia is differed from\nthe same in other countries due to the\nexistence of the strong scientific centre:\nRussian Academy of Sciences (RAS).\nThus the analysis was done for 3 types\nof organizations: RAS, universities, and\nothers (dark, medium, and hell columns\nin each triple of Figure 3). For physics,\nthe last type of organizations is\nrepresented by National Centres like\nKurchatov Institute, National Research\nCentre in Sarov, etc. The left column in\neach triple of Figure 3 represents 19811990 period, the middle column – 19912000, the right column – 2001-2010:\nThe university part and part of other\norganizations are small. It means that\nnatural sciences are made in Russia in\nRAS mostly. For physics, Figure 3 says\n2202\n\nFigure 3. Parts of articles in Nature and\nPRL of RAS, other organizations, and\nUniversities in Russia.\n\nConclusion\nThe most part of fundamental\ninvestigation in natural sciences in the\nUSA is fulfilled in universities, this part\nis rising during the period of observation\n(1980-2010). The same rise in physics is\nmore evident. The same analysis\nfulfilled for Germany demonstrates that\nit is hard to claim that universities are\nleading research organizations for\nnatural sciences in Germany, but their\npart is rising. Natural sciences are\ninvestigated in Russia by RAS and nonuniversity research organizations.\nAcknowledgments\nThe work is supported by RFBR grant\n13-07-00672-a.\nReferences\nRomanovsky, M.Yu. (2010) Publication\nactivity of natural-science research\norganizations in Russia and abroad.\nHerald of the Russian Academy of\nSciences, 80, 475-479.\n\nA UTHOR I NDEX\nAbbasi, Alireza ........................... 328\nAbdiazar, Shahram ................... 1995\nAbdulhayoglu, Mehmet Ali ...... 1151\nAbercrombie, Robert K. ........... 1854\nAbramo, Giovanni .................... 1536\nAcosta, Manuel ............................. 36\nAdams, Jonathan......................... 316\nAguillo, Isidro F. ............ 1966, 2159\nAjiferuke, Isola ........................... 755\nAksnes, Dag W. .......................... 654\nAlbarrán, Pedro........................... 536\nAleixandre-Benavent, Rafael.... 1932\nAmaral, Roniberto M................ 1877\nAmez, Lucy .............................. 1891\nAndersen, Jens Peter ................... 215\nAntonio-García, M. Teresa ....... 2149\nAparicio, Javier......................... 2044\nArali, Uma B. ........................... 2117\nArchambault, Éric..................... 1665\nArencibia-Jorge, Ricardo .......... 2113\nAsadi, Hamideh ........................ 2017\nÅström, Fredrik .......................... 677\nAtanassova, Iana ......................... 591\nAzagra-Caro, Joaquín M. ............. 36\nBabko-Malaya, Olga................... 896\nBadrloo, Alireza ....................... 2017\nBaggio, Suelen.......................... 2193\nBarberio, Vitaliano ..................... 426\nBarbosa, Nilda Vargas .............. 1884\nBar-Ilan, Judit ..................... 468, 604\nBarirani, Ahmad ....................... 1944\nBarrios, Maite ...................................\n.................... 811, 966, 1922, 2156\nBarth, Andreas ............................ 493\nBasner, Jodi .............................. 2066\nBasu, Aparna ............................ 1954\nBatista, Pablo Diniz .................... 796\nBauer, Hans P.W. ..................... 2099\nBenoit, Cyril ............................. 1947\nBertin, Marc................................ 591\nBesagni, Dominique ................. 2048\n\nBharathi, D. Gnana ....................... 58\nBi, Fei ....................................... 1069\nBidanda, Bopaya ...................... 1225\nBleier, Arnim.................... 229, 2171\nBollen, Johan .................................. 3\nBonaccorsi, Andrea .................. 1817\nBongioanni, Irene ..................... 1900\nBordons, María ....... 167, 2044, 2162\nBorges, Elinielle Pinto ............... 796\nBörner, Katy ................... 1342, 1587\nBornmann, Lutz.................. 493, 769\nBouabid, Hamid ......................... 885\nBouyssou, Denis ....................... 2024\nBoyack, Kevin W. .... 361, 928, 1726\nBozeman, Barry........................ 1613\nBucheli, Víctor ......................... 1225\nBuckley, Kevan ........................ 1253\nBüsel, Katharina ......................... 175\nCabezas-Clavijo, Álvaro .... 96, 1237\nCabral, José A. S. ..................... 2054\nCabrini Grácio, Maria Cláudia .........\n.................................... 1908, 2069\nCăbuz, Alexandru I. ................. 2086\nCainarca, Gian Carlo ................ 2004\nCalabró, Luciana .. 1884, 2129, 2193\nCalderón, Juan Pablo ................ 1225\nCambo, Scott Allen .................. 1711\nCárdenas-Osorio, Jenny ........... 1928\nCarley, Stephen J. ..................... 1188\nCassi, Lorenzo .......................... 1270\nCastellano, Claudio .......... 769, 1431\nCastellano-Gómez, Miguel....... 1932\nChang, Chia-Lin ....................... 1871\nChavarro, Diego ....................... 1053\nChen, Bikun................................ 742\nChen, Chaomei .................................\n...................847, 1037, 1114, 1726\nChen, Dar-Zen .................. 941, 1379\nChen, Ssu-Han............................ 941\nChen, Yunwei........................... 1135\nCheng, Qikai .................. 1307, 2178\n2203\n\nCherraj, Mohammed ................... 885\nChi, Pei-Shan .............................. 612\nChinchilla-Rodríguez, Zaida ............\n.................................... 2061, 2113\nChittó Stumpf, Ida Regina ........ 1935\nChmelařová, Zdeňka................. 1874\nChung, Kon Shing Kenneth ........ 328\nCointet, Jean-Philippe................. 285\nColebunders, Robert ................. 2072\nCorera-Alvarez, Elena .............. 2113\nCoronado, Daniel.......................... 36\nCorrigan, James ........................ 1485\nCosculluela, Antonio ................ 2156\nCostas, Rodrigo ................................\n...................... 84, 876, 1401, 1587\nCrabtree, Dennis R. .................. 2092\nCronin, Blaise ................. 1321, 1640\nD’Angelo, Ciriaco Andrea........ 1536\nda Costa Santos, Maria José Veloso\n.............................................. 2174\nda Silveira Guedes, Vânia Lisboa\n.............................................. 2174\nDafang, Tian ............................. 1912\nDalimi, Mohamed ....................... 885\nDamasio, Edilson...................... 1925\nDaraio, Cinzia ....... 1817, 1900, 2004\ndas Neves Machado, Raymundo\n.............................................. 1759\nde Faria, Leandro I. L. .... 1877, 1950\nde Fátima Sousa de Oliveira\nBarbosa, Maria ..................... 2174\nDe Filippo, Daniela ........ 1868, 2095\nde Magalhães Mollica, Maria Cecília\n.............................................. 2174\nde Moya-Anegón, Félix .. 2061, 2113\nde Nooy, Wouter ........................ 769\nde Oliveira, Diogo Losch ......... 2193\nde Souza Vanz, Samile Andréa 1935\nde Souza, Diogo O. G. .............. 2129\nDegelsegger, Alexander ...................\n................................ 175, 177, 183\nDehdarirad, Tahereh ................. 1922\nDekleva Smrekar, Doris ........... 1976\nDemarest, Bradford .................. 2027\n2204\n\nden Besten, Matthijs ................... 484\nDeritei, Dávid ........................... 2086\nDerrick, Gemma Elisabeth ......... 136\nDíaz-Faes, Adrián A................. 2162\nDidegah, Fereshteh ......... 1830, 1995\nDigiampietri, Luciano A. ........... 447\nDiJoseph, Leo........................... 1485\nDing, Jielan .............................. 1177\nDing, Kun ............. 1114, 2020, 2189\nDing, Ying .............. 264, 1030, 1106\nDiwakar, Sandhya .......... 1963, 2089\ndo Amaral, Roniberto M. .................\n.................................... 1363, 1950\nDoleželová, Jana ...................... 1874\nDong, Huei-Ru ......................... 1379\nDong, Ke .................................... 339\nDorta-González, María Isabel ..........\n.................................... 1847, 2146\nDorta-González, Pablo ... 1847, 2146\nDu, Qing ................................... 1528\nDuanyang, Xu .......................... 1938\nEgghe, Leo ............................... 1159\nEngels, Tim C. E. . 1170, 1861, 1894\nErcsey-Ravasz, Mária............... 2086\nEscribano, Alvaro ....................... 978\nFan, Chun-liang .......................... 551\nFanelli, Daniele ........................ 2080\nFang, Shu.................................. 1135\nFaria, Leandro I. L. .................. 1363\nFayazi, Maryam........................ 2031\nFinstad, Samantha .................... 1485\nFlorian, Răzvan V. ................... 2086\nFornieles, Albert ....................... 2156\nFranceschini, Fiorenzo ............... 300\nFrançois, Claire ........................ 2048\nFritsche, Frank.......................... 1989\nGallié, Emilie-Pauline .............. 1270\nGalvis-Restrepo, Marcela ......... 1928\nGani, Srishail ............................ 2117\nGanji, Mahsa ............................ 2017\nGarcia Romero, Antonio ............ 978\nGarcía-Zorita, J. Carlos ....................\n............................ 418, 2095, 2126\nGarzón-García, Belén ............... 2149\n\nGaughan, Monica ..................... 1613\nGetz, Daphne ............................ 1970\nGholami, Nima ......................... 2017\nGiménez-Toledo, Elea .............. 1861\nGingras, Yves ............................. 591\nGlänzel, Wolfgang ............................\n.................... 109, 237, 1864, 2080\nGomes, José A. N. F. ................ 2054\nGomez-Benito, Juana ................. 966\nGómez-Nuñez, Antonio J. ........ 2061\nGómez-Sánchez, Alicia F. ........ 1973\nGomila, Jose M. Vicente ............ 861\nGonzález, Fabio ........................ 1225\nGonzález-Albo, Borja ............... 2044\nGonzález-Teruel, Aurora .......... 2156\nGoodarzi, Samira ...................... 2017\nGornstein, Luba ........................ 1019\nGorraiz, Juan............. 519, 626, 1237\nGorry, Philippe ......................... 1947\nGraffner, Mikael ......................... 677\nGreenspan, Emily J. .................. 1485\nGregolin, Jose A. R. .........................\n.......................... 1363, 1877, 1950\nGuerrero-Bote, Vicente P. ........ 1469\nGuilera, Georgina ....................... 966\nGumpenberger, Christian .................\n.............................. 519, 626, 1237\nGuns, Raf .................. 353, 819, 1409\nGuo, Ying ....................... 1278, 2083\nGuo, Yu .................................... 1069\nGupta, Mona ................... 1963, 2057\nGurney, Karen ............................ 316\nGurney, Thomas ....................... 1090\nGutierres Castanha, Renata Cristina\n.............................................. 1908\nHaddow, Gaby .......................... 1210\nHammarfelt, Björn...................... 720\nHan, Shuguang ......................... 1307\nHan, Yi ....................................... 377\nHatami, Mahdieh ...................... 2017\nHaustein, Stefanie ....................... 468\nHavemann, Frank ..................... 1881\nHayashi, Kazuhiro .................... 1905\nHe, Jiangen ............................... 2178\n\nHeck, Tamara ........................... 1392\nHedenfalk, Ingrid ....................... 677\nHeeffer, Sarah .......................... 1864\nHefetz, Amir ............................. 1970\nHenriksen, Dorte ........................ 152\nHerrera, Francisco .................... 1550\nHo, Yuen-Ping.................. 635, 1622\nHolmberg, Kim .......................... 567\nHolste, Dirk .............................. 2048\nHong, Lv .................................. 2182\nHook, Daniel .............................. 316\nHopkins, Michael ....................... 251\nHörlesberger, Marianne.. 1738, 2048\nHorlings, Edwin ....................... 1090\nHou, Haiyan ................... 1792, 1941\nHou, Jianhua............................. 1941\nHsu, Elizabeth .......................... 1485\nHu, Qing-Hua ............................. 272\nHu, Zewen ................................ 2165\nHu, Zhigang...................... 847, 1941\nHu, Zhiyu ................................. 2196\nHua, Weina............................... 2102\nHuang, Mu-Hsuan ............ 941, 1379\nHui, Xia ...................................... 377\nHunter, Daniel ............................ 896\nIkeuchi, Atsushi.......................... 728\nIngwersen, Peter ..... 418, 1003, 2126\nIsabel-Gómez, Rebeca .............. 1973\nIshtiaque Ahmed, Syed ............ 1711\nItsumura, Hiroshi...................... 1772\nIwami, Shino .............................. 507\nJack, Kris .................................... 626\nJárai-Szabó, Ferenc .................. 2086\nJarneving, Bo.............................. 955\nJensen, Unni ............................. 2066\nJiang, Chunlin .......................... 1941\nJiménez-Contreras, Evaristo.............\n........................................ 96, 1237\nJo, Karen .................................. 2066\nJohn, Marcus ............................ 1989\nJonkers, Koen ............................. 136\nJulian, Keith ............................. 1357\nJung, Hyosook .......................... 2152\nJunpeng, Yuan .......................... 1887\n2205\n\nJunPing, Qiu ............................. 2182\nJuznic, Primoz .......................... 1976\nKajikawa, Yuya ...... 507, 2034, 2037\nKatranidis, Stelios..................... 1334\nKay, Luciano ............................ 1202\nKeidar, Yifat ............................. 2040\nKenekayoro, Patrick ................. 1253\nKhadka, Alla G. .......................... 690\nKitt, Sharon............................... 1746\nKlavans, Richard ...... 361, 928, 1726\nKong, Xiangnan........................ 1030\nKoukliati, Olga ......................... 2120\nKousha, Kayvan ..... 705, 1966, 2017\nKraker, Peter ............................... 626\nKrampen, Günter ...................... 2099\nKreuchauff, Florian .................. 1291\nKumar Srivastava, Vijai ........... 2075\nLagoze, Carl ............................. 1711\nLahatte, Agenor ........................ 1270\nLampert, Dietmar ....................... 175\nLarivière, Vincent .............................\n.................. 591, 1321, 1640, 1897\nLarsen, Birger ...................................\n.................. 418, 1003, 1881, 2126\nLascurain-Sánchez, Maria-Luisa\n.............................................. 2126\nLaurens, Patricia ....................... 1090\nLázár, Zsolt I. ........................... 2086\nLeck, Eran................................. 1970\nLee, Jerry S.H. ................ 1485, 2066\nLee, Jongwook.......................... 2051\nLei, Shengwei ........................... 2178\nLeino, Yrjö ............................... 1992\nLeng, Fuhai ................................. 404\nLepori, Benedetto ....................... 426\nLeta, Jacqueline ................ 796, 1759\nLevitt, Jonathan M. ................... 1461\nLewison, Grant ......................... 1601\nLeydesdorff, Loet .............................\n...................... 251, 316, 769, 1037\nLi, Xiao-xuan.............................. 551\nLi, Xin ...................................... 1857\nLi, Yu........................................ 2102\nLi, Yunrong .............................. 1431\n2206\n\nLietz, Haiko .............................. 1566\nLight, Robert P. ........................ 1342\nLin, Yen-chun .......................... 1918\nLipitakis, Evangelia A. E. C. ........ 22\nLiu, Qing .................................. 1177\nLiu, Shengbo .................. 1114, 2189\nLiu, Wen-bin .............................. 551\nLiu, Xiang .................................. 831\nLiu, Yu ..................................... 2020\nLiu, Yuxian ...................... 819, 1696\nLiu, Zeyuan ................................ 847\nLopez Illescas, Carmen .............. 136\nLópez-Cózar, Emilio Delgado.. 1550\nLópez-Navarro, Irene ............... 2149\nLu, Kun ............................ 755, 2178\nLu, Wei........................... 1307, 2178\nLu, You-min ............................. 1918\nLuan, Chunjuan ........................ 1792\nLyu, Peng-hui ............................. 831\nMa, Fei-cheng ............................ 831\nMa, Jianxia ............................... 1857\nMa, Mingguo ............................ 1857\nMa, Zheng ................................ 1069\nMacaluso, Benoit...................... 1321\nMacedo, Thiago D. ................... 1877\nMagalhães, Jorge L .................. 2185\nMaisano, Domenico ................... 300\nMaissonneuve, Nicolas............... 484\nMaiwald, Gunar........................ 2008\nMaleki, Ashraf.......................... 2017\nMañana-Rodríguez, Jorge ........ 1960\nMaraut, Stéphane........................ 484\nMarchant, Thierry .................... 2024\nMardani, Amir Hossein ............ 1995\nMartinez, Catalina ...................... 484\nMarugan, Sergio ....................... 2095\nMarx, Werner ............................. 493\nMas-Bleda, Amalia .................. 1966\nMastrogiacomo, Luca ................. 300\nMatoh, Robert .......................... 1976\nMauleón, Elba ........ 167, 1868, 2004\nMayr, Philipp............................ 1493\nMcAleer, Michael .................... 1871\nMcCain, Katherine W. ............... 185\n\nMehdizadeh-Maraghi, Razieh .. 2017\nMena-Chalco, Jesús P. ................ 447\nMendez-Vasquez, Raul Isaac ... 2132\nMerindol, Valérie ..................... 1270\nMeyers, Adam ............................ 896\nMichels, Carolin ....................... 2105\nMidorikawa, Nobuyuki............. 1983\nMier, Zhang .............................. 2011\nMikulka, Thomas ...................... 1237\nMilanez, Douglas H. .........................\n.......................... 1363, 1877, 1950\nMilanez, Mateus G. .................. 1950\nMilojević, Staša ...... 264, 1106, 1321\nMingers, John C............................ 22\nMinguillo, David ........................ 985\nMiyairi, Nobuko ....................... 1905\nMohammadi, Ehsan .................... 200\nMongeon, Philippe ................... 1897\nMontalt, Vicent ......................... 1932\nMoore, Nicole M. ..................... 2066\nMoreno, Luz ............................. 2044\nMoreno-Torres, Jose Garcia ..... 1550\nMori, Junichiro ................. 507, 2034\nMoshtagh, Shadi ....................... 2017\nMoya-Anegón, Félix................. 1469\nMugnaini, Rogério............ 447, 1578\nMuhonen, Reetta....................... 1992\nMunoz-Ecija, Teresa................. 2061\nMurugan, M. Anand ................. 1915\nMussulini, Ben Hur M. ............. 2193\nNagahara, Larry A. ................... 2066\nNakajima, Ritsuko .................... 1983\nNakamura, Hiroko .................... 2037\nNi, Chaoqun.............................. 1979\nNilbert, Mef ................................ 677\nNoyons, Ed ..................... 1210, 1587\nOlensky, Marlies....................... 1850\nOlinto, Gilda ............................... 796\nOlivé Vázquez, Gerbert ............ 2132\nOllé, Candela .............................. 811\nOnofre Souza, Diogo ................ 1884\nOrtega, Lidia ..................... 811, 2156\nOssenblok, Truyken L.B........... 1894\nOxley, Les................................. 1871\n\nOzel, Bulent.............................. 2124\nPan, Yuntao .............................. 1069\nPanagiotidis, Theodore ............. 1334\nPapp, István .............................. 2086\nPardo, Daniel ............................ 1090\nPark, Seongbin ......................... 2152\nPatil, Chandrashekhar G........... 2117\nPerianes-Rodriguez, Antonio ..... 536\nPeritz, Bluma C. ....................... 1019\nPero, Mickael ............................. 912\nPeters, Isabella............................ 468\nPinto de Miranda, Elaine Cristina\n.............................................. 1578\nPolanco, Xavier ........................ 2109\nPolley, David E. ....................... 1342\nPonomarev, Ilya ....................... 2066\nPorter, Alan L. ..................................\n...................861, 1188, 1278, 2083\nPouris, Anastassios ......... 2014, 2120\nPouris, Androniki ..................... 2014\nPriem, Jason ............................... 468\nPuuska, Hanna-Mari ................. 1992\nQiu, JunPing ..................... 339, 2001\nQuist, Galena ............................ 2143\nQuoniam, Luc ........................... 2185\nRadicchi, Filippo .............. 769, 1431\nRafols, Ismael ......... 251, 1037, 1053\nRaj, Aparna Govind ................. 2075\nReijnhoudt, Linda ..................... 1587\nRey-Rocha, Jesús ..................... 2149\nRiechert, Mathias ..................... 1566\nRigby, John .............................. 1357\nRimmert, Christine ................... 1957\nRimmert, Edith ......................... 1957\nRivera-Torres, Sandra Carolina 1928\nRobinson, Douglas K.R.. 1278, 2083\nRobinson-García, Nicolás ................\n.............................. 96, 1237, 1550\nRoche, Ivana ............................. 2048\nRoe, Philip ................................ 1601\nRomanovsky, Michael.............. 2200\nRongying, Zhao ............................ 77\nRons, Nadine ............................ 1998\nRoos, Daniel Henrique ... 1884, 2129\n2207\n\nRotchild, Nava .......................... 2040\nRotolo, Daniele ........................... 251\nRousseau, Ronald ........... 1409, 2072\nRuibin, Wei............................... 1912\nRuiz-Castillo, Javier ......... 536, 1431\nRuocco, Giancarlo .................... 1900\nRybachuk, Victor...................... 2143\nSafonova, Maria ......................... 389\nSakata, Ichiro .................... 507, 2037\nSandström, Ulf.................. 664, 2140\nSangam, Shivappa L. ................ 2117\nSanz-Casado, Elias . 418, 2095, 2126\nSchaer, Philipp.......................... 1392\nScharnhorst, Andrea ................. 1587\nSchiebel, Edgar ............... 1419, 2048\nSchlicher, Bob G. ..................... 1854\nSchlögl, Christian ............... 519, 626\nSchmitt, Marco ......................... 1986\nSchneider, Jesper W. .................. 152\nSchnell, Joshua D. .......... 1485, 2066\nSchoen, Antoine ....................... 1090\nSchoeneck, David J. ................. 1188\nSchui, Gabriel ........................... 2099\nSchulz, Jan ................................ 1784\nSchwechheimer, Holger ........... 1957\nSeeber, Marco ............................. 426\nSeger, Yvette R......................... 1485\nSepehr-Ara, Parisa .................... 2017\nSerrano-López, Antonio Eleazar ......\n...................................... 418, 2126\nShan, Shi ......................... 1445, 2001\nShao, Liming ............................ 1938\nSheldon, Frederick T. ............... 1854\nShema, Hadas ..................... 468, 604\nShengnan, Wu............................... 77\nShi, DingHua ............................ 1445\nShirabe, Masashi......................... 123\nSimar, Léopold ......................... 1817\nSimon, Johannes ......................... 175\nSingh Kushwah, Arvind . 1963, 2057\nSingh, Keshari K. ..................... 2089\nSirtes, Daniel .............................. 784\nSivertsen, Gunnar ............. 654, 1861\nSiyahi, Akram ........................... 2017\n2208\n\nSmall, Henry .............................. 928\nSmith, Alastair G ...................... 1806\nSokolov, Mikhail ........................ 389\nSorensen, Aaron A. .................. 1726\nSouza, Diogo O. ....................... 2193\nSrivastav, Ajay Kumar ............. 1915\nSrivastava, Divya . 1963, 2057, 2075\nStark, Abigail R. ......................... 690\nSteenrod, Johanna E. .................. 690\nStrotmann, Andreas 229, 1082, 2171\nStruck, Alexander ..................... 2168\nSuerdem, Ahmet ....................... 2124\nSugimoto, Cassidy R. ...... 264, 1106,\n1321, 1640, 1979, 2027\nSulima, Pawel........................... 2066\nSumi, Róbert ............................ 2086\nSumikura, Koichi ..................... 1090\nSuñén-Pinyol, Eduard .............. 2132\nSuominen, Arho ....................... 1506\nSuya, Hu ................................... 2011\nSuzuki, Shinji ........................... 2037\nSuzuki, Takafumi ....................... 728\nTakei, Chizuko ................. 728, 1772\nTan, Xin.................................... 1528\nTang, Puay................................ 1053\nTannuri de Oliveira, Ely Francina\n.............................................. 2069\nTavakoli, Mohsen ..................... 2017\nTeichert, Nina ........................... 1291\nTeixeira da Rocha, João Batista\n.................................... 1884, 2129\nTerliesner, Jens ........................... 468\nThelwall, Mike .................................\n......200, 567, 604, 705, 985, 1253,\n1321, 1461, 1830, 1966\nThijs, Bart............... 237, 1151, 1864\nThomas, Patrick.......................... 896\nTijssen, Robert J.W. ................... 583\nToivanen, Hannes ..................... 1506\nTong, Ying ................................. 377\nTorres-Salinas, Daniel ......................\n.............................. 96, 1237, 1550\nTribó, Josep A. ........................... 978\nTsay, Ming-yueh ...................... 1918\n\nTschank, Juliet ............................ 175\nTsou, Andrew ............................. 264\nTsuji, Keita ................................. 728\nTurbany, Jaume ........................ 2156\nValderrama-Zurian, Juan Carlos\n.............................................. 1932\nValdivia, Juan Alejandro .......... 1225\nvan den Besselaar, Peter ...................\n.............................. 136, 664, 1090\nvan Eck, Nees Jan ............. 455, 1649\nvan Leeuwen, Thed N........... 66, 654\nVanoiee, Sheida ........................ 2017\nVargas-Quesada, Benjamín ...... 2061\nVelden, Theresa ........................ 1711\nVerhagen, Marc .......................... 896\nVerleysen, Frederik T. .............. 1170\nVieira, Elizabeth S. ................... 2054\nVila Domènech, Joan Salvador ........\n.............................................. 2132\nVillarroya, Anna ............... 811, 1922\nWaaijer, Cathelijn J.F. .................... 7\nWagner, Isabella ......................... 175\nWaltman, Ludo ................. 455, 1649\nWang, Bo ........................ 1114, 2189\nWang, Juan ............................... 1528\nWang, Qi................................... 2140\nWang, Xianwen ........................ 1792\nWang, Xiaoguang ..................... 1307\nWang, Xuemei .......................... 1857\nWang, Yanling.......................... 2136\nWei, Guo................................... 2011\nWei, Wenjie ................................ 819\nWepner, Beatrix........................ 1738\nWernisch, Ambros .................... 1237\nWilliams, Duane E.................... 1485\nWilson, Paul ............................. 1830\nWinnink, Jos J. ........................... 583\nWolfram, Dietmar....................... 755\nWong, Chan-Yuan ...................... 635\nWong, Poh-Kam ............... 635, 1622\nWouters, Paul ............... 66, 455, 876\n\nWu, Yishan............................... 2165\nXu, Kan .................................... 1114\nYamaguchi, Kiyohiro ............... 2034\nYamashita, Yasuhiro ................ 1681\nYan, ChunNing ........................ 2001\nYan, Erjia ....................... 1030, 1106\nYang, Guo-liang ......................... 551\nYang, Liying .................... 551, 1177\nYang, Sojung ............................ 2152\nYang, Yang .............................. 1887\nYegros-Yegros, Alfredo ..... 84, 1401\nYin, Jiahui .................................. 819\nYishan, Wu..................... 1887, 1912\nYitzhaki, Moshe ....................... 2040\nYoshikane, Fuyuki ........... 728, 1772\nYoshinaga, Daisuke.................. 1681\nYoutie, Jan................................ 1613\nYu, Guang .................................. 272\nYu, Tian...................................... 272\nYuan, Junpeng .......................... 1938\nYuntao, Pan .............................. 1887\nZahedi, Zohreh ........................... 876\nZanotto, Sônia Regina .............. 1935\nZarama, Roberto ....................... 1225\nZhai, Lihua ............................... 1069\nZhang , Zhiqiang ...................... 1857\nZhang, Lin .................................. 237\nZhang, Ling .............................. 1528\nZhang, Yanan ........................... 1528\nZhang, Yi.................................... 861\nZhang, YiFei .................. 1445, 2001\nZhao, Dangzhi .......................... 1082\nZhao, Rongying .......................... 742\nZhou, Qiuju ................................ 404\nZhou, Xiao.............. 861, 1278, 2083\nZitt, Michel ................................. 285\nZontanos, Costas ...................... 1334\nZuccala, Alesia ........................... 353\nZüger, Maria-Elisabeth............. 1419\n\n2209\n\nPartners\n\nISBN: 978-3-200-03135-7\nISSN: 2175-1935\n\n","pages":{"startPosition":[0,5001,9992,14994,19997,24998,29996,35000,39998,45000,49984,54999,59998,65001,69998,74997,79996,84999,89999,95001,99995,105001,110000,114992,119993,125000,129989,134997,139994,145000,150001,155000,159995,165001,169996,175000,180001,185000,190000,194997,200000,204997,209998,215000,219997,224992,229996,235000,239998,244998,249996,255001,259999,265000,269995,274998,279997,284991,290000,294994,299991,304995,309999,315000,319994,324999,329990,334992,340001,344997,349991,354997,359999,364998,370001,374995,379999,385000,389989,395000,399995,405001,409997,415000,419994,424999,429999,435000,440000,444992,449998,454994,460001,464992,469999,474988,480001,484998,489999,495000,499999,504992,510000,514986,519996,525000,530001,535001,539996,545000,550000,554999,560000,565001,570000,575001,580000,584988,589995,595000,600000,605000,609996,614995,620000,625000,629999,635001,639992,644983,649997,654991,659993,664995,669997,674998,680000,685001,689999,694993,699996,704999,710000,714987,719996,725001,729996,734998,739995,745000,749996,754999,760001,764999,770000,774998,779990,784982,790001,794990,799992,804995,809997,815000,819995,825000,829994,835000,840001,844999,849996,854996,859998,865000,869997,874993,879999,884995,890000,894993,899991,905000,909998,915000,919999,924997,929992,935001,940001,944989,949992,954999,960001,964997,969997,975001,980000,985000,990001,994999,999996,1004992,1010000,1014998,1019997,1025001,1030000,1035000,1040001,1045000,1049999,1055000,1060000,1064996,1069998,1075001,1079998,1084992,1090000,1094990,1100000,1104991,1110000,1114994,1119987,1125000,1129997,1134999,1139995,1145000,1149993,1154996,1160000,1165001,1169993,1174994,1180001,1184998,1189992,1195000,1199993,1204990,1209998,1214994,1219997,1224996,1229997,1234997,1239997,1244997,1249994,1255000,1259997,1264999,1269999,1275001,1279995,1285000,1290001,1294999,1299995,1305000,1309999,1315000,1320001,1324996,1329996,1335001,1340001,1344990,1350001,1354999,1360001,1365000,1369988,1375000,1379998,1384992,1390000,1394998,1399997,1405000,1410001,1414999,1420000,1425000,1429997,1434991,1439992,1444998,1449995,1455000,1459993,1464994,1470001,1474992,1479996,1484997,1489998,1494996,1500000,1504992,1510000,1514998,1519990,1524996,1530000,1535000,1539999,1545000,1549993,1555000,1560000,1565001,1569996,1574994,1580001,1584992,1589994,1594995,1600000,1604996,1609998,1614995,1619999,1624999,1629993,1634999,1639990,1644997,1649997,1655000,1660001,1664995,1669984,1675000,1679994,1685000,1690000,1694996,1699997,1705001,1710000,1714995,1719990,1724997,1729999,1734997,1739998,1744998,1749996,1754999,1759985,1765000,1769990,1774999,1780001,1784994,1789997,1794998,1800000,1804990,1809997,1814999,1819989,1824990,1829999,1835000,1839993,1844995,1850000,1854996,1860001,1864986,1869992,1875001,1879994,1884987,1889998,1894998,1899999,1905000,1909997,1914999,1919990,1924998,1930001,1935000,1939996,1944996,1949993,1955001,1959999,1965001,1969998,1974996,1979997,1984988,1989991,1994995,1999986,2004982,2009994,2014990,2019996,2025000,2030000,2034991,2040000,2045000,2049999,2054998,2059997,2064999,2070000,2074994,2079999,2084999,2089995,2094984,2099992,2104993,2109998,2115000,2119994,2124999,2130000,2134999,2139999,2144990,2150000,2155000,2160000,2164991,2170001,2174983,2179995,2184996,2189996,2194999,2200000,2204998,2210001,2214998,2219999,2225000,2229994,2235000,2239999,2245000,2249993,2254994,2259987,2264995,2270000,2275001,2280001,2285001,2289998,2294996,2299985,2304997,2309998,2314999,2319992,2324996,2330001,2334993,2339993,2345000,2350001,2354998,2359997,2365000,2369982,2374997,2379993,2385000,2389998,2394993,2400000,2404987,2409998,2414986,2419997,2424991,2429993,2434993,2439998,2444994,2449999,2454989,2459997,2464995,2469995,2475001,2479999,2485000,2490000,2494999,2499997,2504999,2509994,2515001,2520001,2524996,2529999,2535001,2539999,2544986,2549998,2555001,2559990,2564997,2570001,2574990,2580000,2584993,2589997,2594999,2599993,2604984]}},"html":{"comparison":{"identical":{"groupId":[0,0,1],"source":{"chars":{"starts":[73398,73457,104143],"lengths":[55,1,83]},"words":{"starts":[2808,2808,3337],"lengths":[6,6,9]}},"suspected":{"chars":{"starts":[1125896,1125896,1391633],"lengths":[56,56,83]},"words":{"starts":[171749,171749,213382],"lengths":[6,6,9]}}},"minorChanges":{"groupId":[2],"source":{"chars":{"starts":[104227],"lengths":[9]},"words":{"starts":[3347],"lengths":[0]}},"suspected":{"chars":{"starts":[1391717],"lengths":[5]},"words":{"starts":[213392],"lengths":[0]}}},"relatedMeaning":{"groupId":[3,3],"source":{"chars":{"starts":[104270,104282],"lengths":[5,1]},"words":{"starts":[3348,3348],"lengths":[0,0]}},"suspected":{"chars":{"starts":[1391729,1391729],"lengths":[4,4]},"words":{"starts":[213394,213394],"lengths":[0,0]}}}}},"version":3}