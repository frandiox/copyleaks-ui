{"statistics":{"identical":111,"minorChanges":61,"relatedMeaning":37},"text":{"comparison":{"identical":{"source":{"chars":{"starts":[1846,1874,2202,2279,4948,9342,9457,9473,17813,19008,19128,19686,19785,20132,20689],"lengths":[10,74,76,9,78,105,3,3,107,80,45,73,5,55,76]},"words":{"starts":[256,259,304,317,705,1306,1320,1322,2499,2657,2673,2750,2761,2805,2876],"lengths":[0,10,12,0,9,12,0,0,12,11,5,8,0,7,10]}},"suspected":{"chars":{"starts":[72287,72308,72517,72602,81668,118531,118642,118659,466701,427533,427640,460528,460622,421187,421490],"lengths":[10,74,76,9,78,105,3,3,107,80,45,73,5,55,76]},"words":{"starts":[8610,8613,8642,8656,9956,15376,15390,15392,66212,60970,60985,65392,65402,60102,60143],"lengths":[0,10,12,0,9,12,0,0,12,11,5,8,0,7,10]}}},"minorChanges":{"source":{"chars":{"starts":[1867,5027,9461,18987,19000,19089,19119,19174,19603,19620,19632,19681,19760,20580,20594,20630,20677,20766,20783,20822,21417,21433,21437,21453,21542,21694,21732,22032,22046,22201,22216,22799,22863,22901,22973,23351,23373,23479,23635,23696,23855,23952,24035,24388,25473,26533,26611],"lengths":[6,49,11,7,7,12,8,10,7,5,19,4,18,5,6,13,11,4,3,26,8,3,7,13,16,3,26,7,18,11,8,16,11,15,10,9,2,16,10,11,19,12,9,9,10,2,4]},"words":{"starts":[258,715,1321,2654,2656,2669,2672,2679,2737,2739,2741,2749,2759,2863,2865,2869,2875,2887,2890,2894,2971,2973,2974,2976,2990,3009,3013,3052,3054,3074,3076,3155,3164,3168,3178,3223,3226,3239,3257,3266,3285,3295,3305,3347,3491,3630,3640],"lengths":[0,6,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,2,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0]}},"suspected":{"chars":{"starts":[72305,81747,118646,427517,427526,427614,427634,427686,460456,460466,460473,460520,460602,421397,421405,421430,421475,421567,421578,421595,449548,449556,449560,449567,449654,449799,449816,431689,431698,431844,431855,438484,438547,438582,438657,440458,440491,438922,439077,439141,439957,440053,440139,418143,430762,430242,430321],"lengths":[2,52,12,6,6,13,5,9,6,4,17,3,19,4,5,11,10,5,2,21,7,3,6,11,15,2,21,6,16,10,9,15,8,14,11,10,2,15,9,12,18,11,10,10,9,3,5]},"words":{"starts":[8612,9966,15391,60967,60969,60982,60984,60991,65378,65380,65382,65390,65401,60128,60130,60135,60141,60154,60156,60159,63845,63846,63847,63848,63862,63881,63884,61556,61558,61577,61578,62438,62447,62451,62462,62702,62706,62492,62510,62520,62639,62649,62660,59677,61421,61348,61358],"lengths":[0,6,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,2,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0]}}},"relatedMeaning":{"source":{"chars":{"starts":[1857,1955,2194,9477,17921,18995,19108,19611,19626,20114,20586,20601,20623,20771,20796,21707,22040,22992,23361,23721,23728,24045],"lengths":[9,2,7,100,6,4,10,8,5,10,7,21,6,6,9,9,5,6,11,6,8,6]},"words":{"starts":[257,271,303,1323,2512,2655,2671,2738,2740,2803,2864,2866,2868,2888,2892,3011,3053,3180,3224,3268,3269,3306],"lengths":[0,0,0,12,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0]}},"suspected":{"chars":{"starts":[72298,72383,72504,118663,466819,427524,427628,460463,460471,421178,421402,421411,421421,421573,421590,449811,431696,438674,440469,439154,439159,440150],"lengths":[6,6,8,107,3,1,5,2,1,8,2,9,6,4,4,4,1,2,21,4,18,4]},"words":{"starts":[8611,8624,8640,15393,66226,60968,60983,65379,65381,60101,60129,60131,60133,60155,60158,63883,61557,62464,62703,62521,62522,62661],"lengths":[0,0,0,14,0,0,0,0,0,0,0,1,0,0,0,0,0,0,2,0,2,0]}}}},"value":"Citation-based Plagiarism Detection\n\nBela Gipp\n\nCitation-based\nPlagiarism Detection\nDetecting Disguised\nand Cross-language Plagiarism\nusing Citation Pattern Analysis\n\nBela Gipp\nBerkeley, USA\n\nDissertation Otto-von-Guericke University Magdeburg, Germany, 2013\n\nISBN 978-3-658-06393-1\nDOI 10.1007/978-3-658-06394-8\n\nISBN 978-3-658-06394-8 (eBook)\n\nThe Deutsche Nationalbibliothek lists this publication in the Deutsche Nationalbibliografie;\ndetailed bibliographic data are available in the Internet at http://dnb.d-nb.de.\nLibrary of Congress Control Number: 2014944069\nSpringer Vieweg\n© Springer Fachmedien Wiesbaden 2014\nThis work is subject to copyright. All rights are reserved by the Publisher, whether the whole\nor part of the material is concerned, specifically the rights of translation, reprinting, reuse of\nillustrations, recitation, broadcasting, reproduction on microfilms or in any other physical\nway, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed.\nExempted from this legal reservation are brief excerpts in connection with reviews or scholarly analysis or material supplied specifically for the purpose of being entered and executed\non a computer system, for exclusive use by the purchaser of the work. Duplication of this\npublication or parts thereof is permitted only under the provisions of the Copyright Law of\nthe Publisher’s location, in its current version, and permission for use must always be obtained\nfrom Springer. Permissions for use may be obtained through RightsLink at the Copyright\nClearance Center. Violations are liable to prosecution under the respective Copyright Law.\nThe use of general descriptive names, registered names, trademarks, service marks, etc. in this\npublication does not imply, even in the absence of a specific statement, that such names are\nexempt from the relevant protective laws and regulations and therefore free for general use.\nWhile the advice and information in this book are believed to be true and accurate at the date\nof publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions that may be made. The publisher makes no warranty,\nexpress or implied, with respect to the material contained herein.\nPrinted on acid-free paper\nSpringer Vieweg is a brand of Springer DE.\nSpringer DE is part of Springer Science+Business Media.\nwww.springer-vieweg.de\n\nAcknowledgements\nThis doctoral thesis would not have been possible without the collaboration\nand generous support of numerous individuals and institutions. I am especially\ngrateful to my doctoral advisor, Professor Andreas Nürnberger, for his\ndedication to my success in writing this thesis and supporting me in all my\nresearch endeavors. I am thankful to Professor Claus Rautenstrauch for inspiring\nme to pursue a PhD in the first place. Furthermore, I am indebted to the\nprofessors Jim Pitman and Erik Wilde from the University of California,\nBerkeley for inviting me to complete my research at UC Berkeley from 2009–\n2013. Our open exchange of ideas and our collaboration on interesting projects\nsuch as Mr. DLib, led to several joint publications.\nI especially acknowledge my research group at SciPlore: Joeran Beel,\nCorinna Breitinger, Mario Lipinski and Norman Meuschke, with whom it was a\npleasure to work over the years. The close collaboration and joint publications\nwith Norman while overseeing his master thesis, as well as during our\nsubsequent research, have significantly contributed to the development of the\nCbPD approach. I also thank Joeran, Corinna and Mario for our joint projects\nindirectly related to my doctoral research, such as the development of the open\nsource software, SciPlore Mindmapping, now known as Docear, the\ndevelopment of the machine-readable digital library, Mr. DLib, and the research\non Co-citation Proximity Analysis. I wish to thank Christian Hentschel, Juliane\nStiller and my research colleagues as mentioned above, for their valuable\nfeedback and proofreading of the manuscript.\nI wish to thank my past students at the OvGU Magdeburg, Wadi International\nUniversity and the UC Berkeley, as well as my most recent students at the HTW\nBerlin, with whom I developed a web-based CbPD visualization prototype.\nWorking with students in lecture, and supervising bachelor and master projects is\na rewarding experience, which confirmed my desire to pursue a career in\nacademia. I also thank the participants of the CbPD user study for their time.\nI gratefully acknowledge the organizations that provided my colleagues and me\nwith the funding to realize our research. I thank EXIST for a generous grant from\n\nVI\n\nAcknowledgements\n\nthe German Federal Ministry of Economics and Technology. Moreover, I\nthankfully acknowledge a NSF grant that allowed us to work on a related project,\nMr. DLib. I am indebted to the German Academic Exchange Service (DAAD)\nfor their scholarship that allowed me to research at UC Berkeley, as well as my\nemployer, the SAP-sponsored VLBA-lab at the OvGU. I also wish to thank the\nGoogle Scholar team and Bill Schilit for their collaboration, and for inviting me\nto present my citation-based approach to plagiarism detection at Google in\nMountain View. I thank ACM, SIGIR, ECDL and JCDL for their conferencetravel grants and I also gratefully acknowledge the State of Saxony-Anhalt for its\nfinancial support of the patent applications.\nFinally, and most importantly, I thank my loving family and my wonderful\ngirlfriend, for always supporting me in all my endeavors.\n\nContents\nAcknowledgements .............................................................................................. V\nContents .............................................................................................................VII\nList of Tables ...................................................................................................... XI\nList of Figures .................................................................................................. XIII\nGlossary .......................................................................................................... XVII\nAbstract ......................................................................................................... XXIII\nKurzfassung ................................................................................................... XXV\n1 Introduction ..................................................................................................... 1\n1.1 Problem Setting ....................................................................................... 1\n1.2 Motivation ............................................................................................... 3\n1.3 Research Objective ................................................................................. 4\n1.4 Thesis Outline ......................................................................................... 6\n2 Plagiarism Detection ....................................................................................... 9\n2.1 Academic Plagiarism .............................................................................. 9\n2.1.1 Definition ................................................................................... 10\n2.1.2 Forms of Academic Plagiarism.................................................. 11\n2.1.3 Prevalence of Plagiarism in the Academic Environment ........... 13\n2.2 Plagiarism Detection Approaches ......................................................... 17\n2.2.1 Generic Detection Approach ..................................................... 17\n2.2.2 Overview of Plagiarism Detection Approaches ......................... 19\n2.2.3 Fingerprinting ............................................................................ 22\n2.2.4 Term Occurrence Analysis ........................................................ 26\n2.2.5 Stylometry ................................................................................. 30\n2.2.6 Cross-Language Plagiarism Detection ....................................... 32\n2.3 Plagiarism Detection Systems ............................................................... 33\n2.3.1 Evaluations of PDS .................................................................... 34\n2.3.2 Technical Weaknesses of PDS .................................................. 39\n2.4 Conclusion ............................................................................................ 40\n\nVIII\n\nContents\n\n3 Citation-based Document Similarity.............................................................. 43\n3.1 Terminology .......................................................................................... 44\n3.1.1 Citation vs. Reference ................................................................ 44\n3.1.2 Similarity vs. Relatedness .......................................................... 45\n3.1.3 Dimensions of Similarity: Lexical, Semantic, Structural ........... 45\n3.2 Citation-based Similarity Measures ...................................................... 47\n3.2.1 Direct Citation ............................................................................ 47\n3.2.2 Bibliographic Coupling .............................................................. 48\n3.2.3 Co-citation.................................................................................. 50\n3.2.4 Amsler ........................................................................................ 52\n3.2.5 Co-citation Proximity-based Methods ....................................... 52\n3.3 Conclusion............................................................................................. 54\n4 Citation-based Plagiarism Detection.............................................................. 57\n4.1 Concept ................................................................................................. 58\n4.1.1 Citing Behavior .......................................................................... 62\n4.2 Citation Characteristics Considered ...................................................... 64\n4.2.1 Bibliographic Coupling Strength ............................................... 64\n4.2.2 Probability of Citation Co-occurrence ....................................... 64\n4.2.3 Order and Proximity of Citations ............................................... 65\n4.3 Challenges to Citation Pattern Identification ......................................... 66\n4.3.1 Unknown Pattern Constituents ................................................... 66\n4.3.2 Transpositions ............................................................................ 67\n4.3.3 Scaling........................................................................................ 67\n4.3.4 Insertions or Substitutions of Citations ...................................... 68\n4.4 Design of Citation-based Detection Algorithms.................................... 68\n4.4.1 Bibliographic Coupling (BC) ..................................................... 69\n4.4.2 Longest Common Citation Sequence (LCCS) ........................... 70\n4.4.3 Greedy Citation Tiling (GCT) .................................................... 70\n4.4.4 Citation Chunking (Cit-Chunk) .................................................. 73\n4.5 Projected Suitability of CbPD Algorithms for Plagiarism Forms ......... 80\n4.6 Assessment of Identified Citation Patterns ............................................ 83\n4.6.1 Citing Frequency-Score (CF-Score)........................................... 83\n4.6.2 Continuity-Score (Cont.-Score) ................................................. 85\n\nContents\n\nIX\n\n4.7 Conclusion ............................................................................................ 87\n5 Prototype: CitePlag........................................................................................ 89\n5.1 Document Parser ................................................................................... 90\n5.2 Database ................................................................................................ 93\n5.2.1 Consolidation of Reference Identifiers ...................................... 94\n5.3 Detector ................................................................................................. 95\n5.4 Frontend ................................................................................................ 96\n5.5 Conclusion ............................................................................................ 99\n6 Quantitative and Qualitative Evaluation...................................................... 101\n6.1 Methodology ....................................................................................... 102\n6.1.1 Test Collection Requirements .................................................. 104\n6.1.2 Test Collection Challenges ...................................................... 106\n6.1.3 GuttenPlag Wiki ...................................................................... 108\n6.1.4 VroniPlag Wiki ........................................................................ 109\n6.1.5 PubMed Central OAS .............................................................. 111\n6.1.6 Summary and Comparison of Test Collections ....................... 113\n6.2 Evaluation using GuttenPlag Wiki ...................................................... 116\n6.3 Evaluation using VroniPlag Wiki ....................................................... 121\n6.3.1 Evaluation: Random Sample of Sources.................................. 121\n6.3.2 Evaluation: Translated Plagiarism ........................................... 126\n6.3.3 Evaluation: Plagiarism Case Heun........................................... 129\n6.3.4 Conclusion VroniPlag Wiki ..................................................... 135\n6.4 Evaluation using PubMed Central OAS.............................................. 136\n6.4.1 Methodology ............................................................................ 139\n6.4.2 Results ..................................................................................... 157\n6.4.3 Conclusion of PMC OAS Evaluation ...................................... 195\n6.5 Conclusion of Evaluations .................................................................. 198\n7 Summary &amp; Future Work ............................................................................ 203\n7.1 Summary ............................................................................................. 203\n7.2 Contributions ...................................................................................... 207\n7.3 Future Work ........................................................................................ 211\n7.3.1 General Research Need............................................................ 212\n\nX\n\nContents\n\n7.3.2 Improvements to Detection Accuracy ...................................... 213\n7.3.3 Additional Applications ........................................................... 215\n7.3.4 Further Evaluations .................................................................. 219\nReferences ......................................................................................................... 223\nAppendix ........................................................................................................... 265\nA Preliminary PMC OAS Corpus Analysis ..................................................... 266\nA.1 Bibliographic Coupling ....................................................................... 266\nA.2 Longest Common Citation Sequence .................................................. 273\nA.3 Greedy Citation Tiling......................................................................... 278\nA.4 Citation Chunking ............................................................................... 286\nA.5 Character-based PDS Sherlock............................................................ 293\nA.6 Character-based PDS Encoplot ........................................................... 294\nB Technical Details of the CitePlag Prototype ................................................ 296\nB.1 Sentence-Word-Tagger (SW-Tagger) ................................................. 296\nB.2 Data Parser .......................................................................................... 300\nB.3 Consolidation of Reference Identifiers ................................................ 302\nB.4 Database Documentation ..................................................................... 304\nC Data and Source-code Downloads ............................................................... 311\nD Related Publications .................................................................................... 313\nE Patent Application ....................................................................................... 318\nF User Study Feedback ................................................................................... 329\nG Reactions of Contacted Authors .................................................................. 331\nH Empirical Studies on Plagiarism Frequencies .............................................. 336\nI\n\nStudies on Citation-based Similarity Measures ........................................... 339\n\nJ\n\nOverview of Selected PDS .......................................................................... 343\n\nIndex .................................................................................................................. 347\n\nList of Tables\nTable 1: Excerpt from a Plagiarized Section Describing Experimental Results .. 4\nTable 2: Overview of Chunking Units Proposed for Fingerprinting Methods ... 23\nTable 3: Overview of Chunk Sizes Proposed for Fingerprinting Methods ........ 24\nTable 4: Overview of Fixed and Variable-Resolution Fingerprinting Methods . 25\nTable 5: Overview of Chunk Selection Strategies for Fingerprinting Methods . 25\nTable 6: Overview of Local and Global VSM Proposed for Plagiarism\nDetection ............................................................................................................. 28\nTable 7: Overview of the Term Units of VSM Proposed for Plagiarism\nDetection ............................................................................................................. 29\nTable 8: Capabilities of Current Plagiarism Detection Approaches ................... 41\nTable 9: Categorization of Evaluated Similarity Assessments ........................... 69\nTable 10: Overview of CbPD Algorithm Detection Performance...................... 81\nTable 11: Overview CbPD Algorithms .............................................................. 88\nTable 12: Characteristics of Test Collections for PD Evaluation ..................... 114\nTable 13: Detection Categories for Plagiarism ................................................ 115\nTable 14: Comparison of Detection Results ..................................................... 118\nTable 15: Citation Matches between Plagiarism and Source Fragments\nin the VroniPlag Wiki ....................................................................................... 125\nTable 16: Citation Matches for Translated Plagiarism in VroniPlag Wiki....... 127\nTable 17: Excluded Documents ....................................................................... 140\nTable 18: Overview of Corpus Preprocessing Results ..................................... 140\nTable 19: User Study Statistics ........................................................................ 150\nTable 20: Guidelines as Presented to User Study Participants ......................... 152\nTable 21: Average Time for Preprocessing and Comparison per Document ... 177\nTable 22: Examples of Most Common FP Types in PMC OAS ...................... 187\nTable 23: Author Confirmed or Retracted Plagiarism Cases ........................... 193\nTable 24: Capabilities of Current PD Approaches and CbPD .......................... 206\nTable 25: In-text Citation Tile (Example 1) ..................................................... 282\nTable 26: In-text Citation Tile (Example 2) ..................................................... 284\nTable 27: In-text Citation Tile (Example 3) ..................................................... 285\n\nXII\n\nList of Tables\n\nTable 28: In-text Citation Chunk Example ...................................................... 292\nTable 29: Consolidation of Reference Identifiers ............................................ 303\nTable 30: Overview of Detection Algorithms and their\nDatabase-internal IDs ....................................................................................... 308\nTable 31: User Comments on CbPD ............................................................... 329\nTable 32: Original Author Comments on CbPD ............................................. 332\nTable 33: Studies Pertaining to North American Colleges .............................. 336\nTable 34: Studies Pertaining to Colleges Outside of North America .............. 337\nTable 35: Studies Evaluating Citation-based Similarity Measures .................. 340\nTable 36: Studies Primarily Evaluating Citation-based Similarity Measures .. 341\nTable 37: Studies Evaluating Hybrid Measures .............................................. 342\nTable 38: PDS for Document Comparisons within a User-Defined Corpus ... 344\nTable 39: PDS for Document Comparisons with an External Collection ........ 345\n\nList of Figures\nFigure 1: Generic Plagiarism Detection Process ................................................ 18\nFigure 2: Classification of Plagiarism Detection Approaches ........................... 20\nFigure 3: Local vs. Global Document Similarity Analysis ................................ 21\nFigure 4: Concept of Fingerprinting .................................................................. 22\nFigure 5: Plagdet Scores for External PDS in PAN-PC’11................................ 35\nFigure 6: Plagdet Scores for Intrinsic PDS in PAN-PC’11 ................................ 37\nFigure 7: Performance of the Top Five Publicly Available PDS ....................... 39\nFigure 8: Citations and References in Scientific Documents ............................. 45\nFigure 9: Doc A cites Doc B, while Doc B is cited-by Doc A. .......................... 47\nFigure 10: Visualization of a Citation Graph ..................................................... 48\nFigure 11: Bibliographic Coupling between Documents ................................... 49\nFigure 12: Co-citation Relationship between Documents .................................. 51\nFigure 13: Co-citation Proximity Analysis ........................................................ 53\nFigure 14: Depiction of CbPD Concept ............................................................. 60\nFigure 15: Greedy Citation Tiles........................................................................ 71\nFigure 16: Identification of a Match Using Greedy Citation Tiling ................... 72\nFigure 17: Illustration of Chunking Strategy 3 .................................................. 76\nFigure 18: Formation of Citation Chunks .......................................................... 79\nFigure 19: Cont.-Score Computation for Citation Patterns ................................ 87\nFigure 20: CitePlag’s System Architecture ........................................................ 89\nFigure 21: General Document Parser ................................................................. 91\nFigure 22: Two-stage Parsing Process for NXML Documents .......................... 93\nFigure 23: ER Data Model for the CitePlag Database ....................................... 94\nFigure 24: UML Class Diagram for CitePlag Detector ...................................... 96\nFigure 25: CitePlag’s Document Similarity Visualization ................................. 97\nFigure 26: CitePlag’s Document Statistics......................................................... 99\nFigure 27: Plagiarized Pages in zu Guttenberg’s Thesis .................................. 109\nFigure 28: Data Sets and Information Systems Related to the PMC OAS....... 112\nFigure 29: Citation Patterns for Translated Plagiarism .................................... 119\nFigure 30: Citation Patterns for Translated Plagiarism in the VroniPlag Wiki 128\n\nXIV\n\nList of Figures\n\nFigure 31: Citation Pattern Matches in the Dissertation of M. Heun .............. 131\nFigure 32: Strongly Disguised Plagiarism in the Dissertation of M. Heun ..... 134\nFigure 33: PMC OAS Four-step Evaluation Methodology ............................. 139\nFigure 34: Correlation between BC Strength and Enco Score in the\nPMC OAS ........................................................................................................ 146\nFigure 35: Applying Detection Algorithms and Pooling for n:n Evaluation ... 147\nFigure 36: CitePlag Document Visualization for User Study.......................... 154\nFigure 37: Distribution of Ranks for Top-10 Document Pairs for\nCopy &amp; Paste .................................................................................................... 160\nFigure 38: Distribution of Ranks for Top-10 Document Pairs\nfor Shake &amp; Paste ............................................................................................. 162\nFigure 39: Distribution of Ranks for Top-10 Document Pairs for\nParaphrases ....................................................................................................... 164\nFigure 40: Distribution of Ranks for Top-10 Document Pairs for\nStructural and Idea Plagiarism.......................................................................... 165\nFigure 41: Scatter Plots for Top-10 Findings Grouped by Plagiarism Form ... 166\nFigure 42: 11-Point Interpolated Avg. Precision – Rel. Recall Curve\nfor Enco, LCCS Dist. and BC .......................................................................... 170\nFigure 43: Perceived Effectiveness for Verification by Plagiarism Form ....... 173\nFigure 44: Measured Time With and Without Citation Pattern Visualization 175\nFigure 45: Computational Efficiency of PD Approaches for an\nn:n Comparison ................................................................................................ 178\nFigure 46: Non-Scientific / Collection-Specific FP Excluded Prior to\nUser Study ........................................................................................................ 181\nFigure 47: Editorial with High Text Overlap but Unique Citations................. 182\nFigure 48: Text Recycled by Journals over Time ............................................ 183\nFigure 49: True False Positives Identified by User Study Participants ........... 185\nFigure 50: Example of CbPD-detected Paraphrase ......................................... 189\nFigure 51: Example of CbPD-detected Image Similarity ................................ 190\nFigure 52: Document with High Character-based but Low\nSemantic Similarity .......................................................................................... 191\nFigure 53: Citation Pattern Visualization of Confirmed Plagiarism................ 195\n\nList of Figures\n\nXV\n\nFigure 54: CitePlag Plagiarism Detection Prototype ....................................... 204\nFigure 55: Potential to Identify Non-cited Documents .................................... 217\nFigure 56: Retracted Translated Plagiarism from Chinese to English ............. 221\nFigure 57: Bibliographic Coupling Strength among Documents in\nPMC OAS ......................................................................................................... 267\nFigure 58: Distribution of Relative Bibliographic Coupling Strength (rBC ) .. 268\nFigure 59: Document Pairs with High Absolute and Relative BC Strength ..... 269\nFigure 60: Distribution of Documents Sharing ‫ ݎ‬൒ 9 % of References........... 272\nFigure 61: Distribution of Documents with BC Strength ൒ 4.......................... 273\nFigure 62: Document Pairs with High Similarity Scores in\nthe LCCS Assessment ....................................................................................... 275\nFigure 63: LCCS Length Dependent on Bibliographic Coupling Strength ...... 277\nFigure 64: Distribution of Maximum Citation Tile Lengths ............................ 279\nFigure 65: Distribution of Documents with Citation Tiles of Length ݈ ൒ 3 .... 279\nFigure 66: Document Pairs with Highest Similarity Scores in\nGCT Assessment ............................................................................................... 280\nFigure 67: Distribution of Maximum Chunk Lengths...................................... 287\nFigure 68: Distribution of Documents sharing a Cit. Chunk\nLength of l &gt;= 4 .............................................................................................. 289\nFigure 69: Document Pairs Yielding High Similarity Scores\nUsing Cit-Chunk ............................................................................................... 290\nFigure 70: ER Data Model for the CitePlag Database ..................................... 304\n\nGlossary\nAA – Authorship Attribution\nResearch field in computer science dealing with methods and systems to determine or\nverify the authors of a text.\n\nAPI – Application Programming Interface\nSoftware-to-software interface managing the seamless interaction between multiple\napplications.\n\nBC – Bibliographic Coupling\nMeasure of global document similarity indicating the number of references two\ndocuments have in common in their bibliographies. BC considers references in the\nbibliography, but does not take into account the placement or order of citations in the full\ntext, refer to page 48 for details.\n\nc&amp;p – Copy &amp; Paste\nPlagiarism form characterized by verbatim copying of text.\n\nCbPD – Citation-based Plagiarism Detection\nApproach used to identify plagiarism by analyzing citation sequence similarity – term\ncoined by the author, details explained in the thesis.\n\nCF-Score – Citing Frequency-Score\nScoring function taking into account citation frequencies of documents to aid in assessing\na citation pattern’s degree of suspicion for identifying potential plagiarism – term coined\nby the author, refer to page 84 and Equation 4.2 for details.\n\nCit-Chunk – Citation Chunking\nSet of CbPD algorithms designed to identify citation patterns regardless of potential\ntranspositions and/or scaling – term coined by the author, refer to page 73 for details.\n\nXVIII\n\nGlossary\n\nCitePlag – Prototype of a Citation-based Plagiarism Detection System\nPlagiarism Detection System prototype implementing the CbPD algorithms introduced in\nthis thesis, programmed in Java and available under an open source license – refer to page\n89 for details.\n\nCLIR – Cross-Language Information Retrieval\nSubfield of Information Retrieval dealing with data in multiple languages.\n\nCont.-Score – Continuity-Score\nScoring function taking into account the continuity of a citation pattern to aid in assessing\na citation pattern’s degree of suspicion for identifying potential plagiarism – term coined\nby the author, refer to page 85.\n\nCPA – Co-citation Proximity Analysis\nApproach using in-text citation proximities to identify related documents – term coined by\nthe author, refer to page 52 for details.\n\nDOI – Digital Object Identifiers\nSystem for assigning unique character strings to published documents to enable their\nidentification, maintained by the DOI Consortium.\n\nERM – Entity-Relationship Model\nModeling notation used for conceptual models, or more commonly data models.\n\nGCT – Greedy Citation Tiling\nCbPD algorithm adapted from the text string similarity function Greedy String Tiling\n(GST), explicitly for use with citations. GCT permanently links individually longest\ncitation matches in citation sequences and stores them as a tile – term coined by the\nauthor, refer to page 70 for details.\n\nGlossary\n\nXIX\n\nIR – Information Retrieval\nResearch field in computer science dealing with methods for finding material of\nunstructured nature in large collections of data.\n\nLCCS – Longest Common Citation Sequence\nCbPD algorithm identifying the longest contiguous series of citations common to a set of\ndocuments – term coined by the author, refer to page 70 for details.\n\nLSI – Latent Semantic Indexing\nTechnique in natural language processing to identify patterns in the relationships between\nthe terms and concepts contained in text.\n\nMDR – Match Detect Reveal\nPlagiarism Detection System using substring comparisons developed by Monostori et al.\n[233].\n\nMeSH – Medical Subject Headings\nThe U.S. National Library of Medicine&#x27;s controlled vocabulary thesaurus.\n\nNLM – U.S. National Library of Medicine\nOrganizational unit within the U.S. National Institute of Health.\n\nNLP – Natural Language Processing\nResearch field in computer science addressing interactions of humans and machines that\nare related to human language.\n\nNXML – National Library of Medicine XML\nTexts in XML markup conformant to the Journal Archiving and Interchange Tag Suite.\n\nPAN-PC – PAN International Competition on Plagiarism Detection\nAnnual scientific competition evaluating Plagiarism Detection Systems.\n\nPD – Plagiarism Detection\nHypernym for computer based procedures supporting the identification of plagiarism.\n\nXX\n\nGlossary\n\nPDS – Plagiarism Detection Systems\nHypernym for computer-based systems supporting the semi-automatic identification of\nplagiarism – also seen abbreviated as PDSs.\n\nPMC® – PubMed Central\nDigital archive of health and life science publications maintained by the U.S. National\nLibrary of Medicine.\n\nPMCID – PubMed Central® Identifier\nUnique numeric identifier assigned to records in the digital archive PubMed Central®.\n\nPMC OAS – PubMed Central Open Access Subset\nCollection of Open Access publications included in PubMed Central.\n\nPMID – PubMed® Identifier\nUnique numeric identifier assigned to records in the bibliographic database PubMed®.\n\nPOS – Part of Speech\nThe linguistic category of words and other terms that are part of natural language.\n\nRefAuthKey – Reference Author Key\nFixed-length descriptor computed from author names given for references that are\nexamined in the thesis.\n\nRefTitKey – Reference Title Key\nFixed-length descriptor computed from the title given for references that are examined in\nthe thesis.\n\nSAX – Simple API for XML\nJava Application Programming Interface for event-based, strictly sequential processing of\nXML documents.\n\ns&amp;p – Shake &amp; Paste\nPlagiarism form characterized by combining shorter sections of literally copied content\nfrom different sources.\n\nGlossary\n\nXXI\n\nSW-Tagger – Sentence-Word-Tagger\nA subcomponent of CitePlag’s parser, which identifies sentences and words in NXML\ntexts and marks them with delimiters that do not impair the validity of the original XML\nmarkup – introduced by the author, refer to Appendix B.1 for details.\n\nTF-IDF – Term Frequency–Inverse Document Frequency\nMeasure reflecting the importance of a word in a document.\n\nUML – Unified Modeling Language\nModeling notation primarily designed for Object Oriented Software Development\ndeveloped by the Object Management Group.\n\nVSM – Vector Space Model\nDocument model representing textual content using weighted terms.\n\nXML – Extensible Markup Language\nStandard published by the World Wide Web Consortium defining a markup of\ninformation.\n\nAbstract\nThis doctoral thesis addresses a problem in information retrieval, which has\nrecently captured the attention of media – the software-based detection of\ndisguised plagiarism forms. State-of-the-art plagiarism detection approaches are\ncapable of identifying copy &amp; paste, and to some extent, lightly disguised\nplagiarism. However, even today’s best performing systems cannot reliably\nidentify more heavily disguised forms of plagiarism, including paraphrases,\ntranslated plagiarism, or idea plagiarism. This weakness of current systems\nresults in a large percentage of disguised scientific plagiarism going undetected.\nWhile the easily recognizable copy &amp; paste-type plagiarism typically occurs\namong students and has no serious consequences for society, disguised\nplagiarism in the sciences, such as plagiarized medical studies in which results\nare copied without the corresponding experiments having been performed, can\njeopardize patient safety.\nTo address the weakness of plagiarism detection systems, this thesis\nintroduces Citation-based Plagiarism Detection (CbPD). Unlike existing\ncharacter-based approaches, which perform text comparisons, CbPD does not\nconsider text similarity alone, but uses citation patterns within documents as a\nunique, language-independent &quot;semantic fingerprint&quot; to identify potentially\nsuspicious similarity among texts. The idea for CbPD originated from the\nobservation that plagiarists commonly disguise academic misconduct by\nparaphrasing copied text, but typically do not substitute or significantly rearrange\nthe citations. Motivated by these findings, the author developed various CbPD\nalgorithms tailored to the different forms of plagiarism, and implemented them\nin the first citation-based plagiarism detection prototype capable of detecting\nheavily disguised plagiarism.\nThe advantages of the CbPD approach were demonstrated in evaluations\nusing three document collections. CbPD’s applicability for detecting strongly\ndisguised plagiarism was first demonstrated using the plagiarized thesis of\nformer German Minister of Defense, K.-T. zu Guttenberg. While conventional\napproaches failed to detect a single instance of translated plagiarism in this\n\nXXIV\n\nAbstract\n\nthesis, CbPD identified 13 of the 16 translations. The effectiveness of the\napproach was further demonstrated when applied to other authors and plagiarism\nforms in the VroniPlag Wiki.\nThe practicality of the CbPD approach was demonstrated by the successful\nidentification of several plagiarism cases in the biomedical publication collection\nPubMed Central Open Access Subset. As a result of a user study utilizing the\nCbPD prototype, several plagiarism investigations have thus far been initiated.\nOne medical study and a plagiarized medical case report have since been\nretracted. The evaluation also showed CbPD’s visualization of citation pattern\nsimilarities to facilitate the verification of plagiarism. Additionally, it could be\nshown that CbPD has a superior computational efficiency compared to existing\napproaches, and produced significantly fewer false positives. CbPD is not a\nsubstitute for, but rather a complement to existing approaches. A combination of\nCbPD with current approaches into a hybrid system promises to ensure optimal\ndetection of both short literal plagiarism, as well as heavily disguised or\ntranslated plagiarism.\n\nKurzfassung\nDie vorliegende Dissertation adressiert ein Problem des Information Retrieval,\nwelches aktuell viel Beachtung erfährt: Die softwarebasierte Erkennung\nverschleierter Plagiate. Bislang genutzte Erkennungsverfahren können lediglich\nexakte Kopien oder nur geringfügig veränderte Plagiate identifizieren. Selbst die\nleistungsfähigsten Systeme können verschleierte Plagiatsformen, wie z. B.\nParaphrasen, Übersetzungs- oder Ideenplagiate, nicht zuverlässig erkennen,\nwodurch derartige Plagiate oft unentdeckt bleiben. Unverschleierte Plagiate\nwerden zumeist von Schülern begangen und haben keine ernsten Folgen für die\nGesellschaft. Stark verschleierte, nicht maschinell erkennbare Plagiate hingegen\nsind vor allem in wissenschaftlichen Arbeiten zu finden und können z. B. die\noptimale Behandlung von Patienten gefährden, wenn eine plagiierte\nmedizinische Studie in Wirklichkeit nie durchgeführt wurde.\nDurch Vorstellung eines neuartigen Erkennungsansatzes namens Citationbased Plagiarism Detection (CbPD) leistet die vorliegende Arbeit einen Beitrag\nzur Lösung dieses Problems. Im Gegensatz zu existierenden\nErkennungsverfahren berücksichtigt CbPD nicht die zeichenbasierte Ähnlichkeit\nvon Dokumenten, sondern die Position und Reihenfolge der zitierten Quellen\n(Zitationen) im Text. Auf Basis der Zitationen generiert CbPD einen\nsprachunabhängigen „semantischen Fingerabdruck“ und nutzt diesen für einen\nVergleich der zu untersuchenden Dokumente. Die Idee zur Entwicklung der\nzitationsbasierten Plagiatserkennung basiert auf der Beobachtung, dass\nPlagiatoren zwar Texte paraphrasieren um Plagiate zu verschleiern, jedoch die\nZitationen üblicherweise weder ersetzen noch deren Reihenfolge signifikant\nverändern. Auf Basis dieser Erkenntnis wurden auf die unterschiedlichen\nverschleierten Plagiatsformen zugeschnittene CbPD-Algorithmen entwickelt.\nDie Algorithmen erkennen Transpositionen und Mehrfachverwendung (Scaling)\nvon Zitationen und nutzen Heuristiken zur Berücksichtigung der\nWahrscheinlichkeit eines gemeinsamen Auftretens von Zitationen sowie der\nKontinuität von Zitationsmustern. Das CbPD-Konzept wurde in Form eines voll\nfunktionsfähigen Prototyps unter Verwendung von Java und HTML5 realisiert.\n\nXXVI\n\nKurzfassung\n\nDas CbPD-Verfahren wurde mittels dreier Testkollektionen evaluiert und mit\nexistierenden Verfahren verglichen. Die prinzipielle Eignung wurde zuerst\nanhand der bekannten Doktorarbeit von K.-T. zu Guttenberg belegt. CbPD\nerlaubte die Erkennung von 13 der 16 enthaltenen Übersetzungsplagiate,\nwährend existierende Verfahren keines der Übersetzungsplagiate identifizieren\nkonnten. Die Wirksamkeit des CbPD-Verfahrens für Arbeiten weiterer Autoren\nund andere Plagiatsformen konnte mittels der VroniPlag Wiki Kollektion belegt\nwerden. Die Praxistauglichkeit der CbPD konnte bewiesen werden, indem mit\nHilfe einer Nutzerstudie und des entwickelten Prototyps mehrere Plagiate in der\nbiomedizinischen Volltextkollektion PMC OAS aufgespürt wurden. Sechs\nUntersuchungen der entdeckten Fälle wurden bislang eingeleitet und eine weitere\nmedizinische Studie wurde inzwischen zurückgezogen. Die Evaluation zeigte,\ndass CbPD die Verifikation von Plagiaten durch die Visualisierung der\nZitationsähnlichkeiten erleichtert. Ausserdem konnte gezeigt werden, dass CbPD\ngegenüber existierenden Verfahren eine signifikant bessere Laufzeiteffizienz\nsowie eine deutlich geringere Rate falsch-positiver Ergebnisse aufweist. Die\nEvaluation machte deutlich, dass CbPD kein Ersatz für existierende Verfahren\nist, sondern diese komplementiert. Die Kombination von CbPD mit existierenden\nVerfahren zu einem Hybridsystem gewährleistet eine optimale Erkennung von\nsowohl kurzen wörtlichen, als auch stark verschleierten semantischen oder\nübersetzten Plagiaten.\n\n1 Introduction\nThis doctoral thesis addresses an unsolved information retrieval problem: the\nautomatic detection of disguised plagiarism forms, including paraphrases,\ntranslated plagiarism and structural and idea plagiarism.\nSection 1.1 of this chapter introduces the problem setting of currently\nnon-machine-detectable academic plagiarism. Section 1.2 describes my\nmotivation for research, and Section 1.3 presents the resulting research objective\npursued in this thesis. Section 1.4 provides an outline of the thesis.\n\n1.1 Problem Setting\nThe problem of academic plagiarism1 has been present for centuries. Yet the\nwidespread dissemination of information and communication technology,\nincluding the Internet, has greatly contributed to the ease of plagiarizing. Many\nonline services exist to facilitate student plagiarism, including essay databases,\nand text &quot;synonymizer&quot; tools, such as synomizer.com2, which outputs input text\nwith a list of synonyms for each word.\nThe most extensive study on plagiarism surveyed ‫׽‬82,000 students at North\nAmerican colleges. Approximately 40 % of the students admitted having\nplagiarized within the last year [220]. However, students are not the only group\nto plagiarize. In Germany, more than 30 prominent cases of academic dishonesty\namong politicians recently made headlines. The German politicians who\nplagiarized in their doctoral theses include former Minister of Defense,\nKarl-Theodor zu Guttenberg, and even the Federal Minister of Education and\nResearch, Annette Schavan. The question arises why cases of plagiarism, which\nare apparent in hindsight, often remain undiscovered for so long. Why can\nacademic misconduct not be caught much earlier using plagiarism detection\nsoftware?\n1\n2\n\nRefer to Section 2.1.1, page 10, for a definition of plagiarism.\nhttp://www.synomizer.com\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_1, © Springer Fachmedien Wiesbaden 2014\n\n2\n\n1 Introduction\n\nD. Weber-Wulff, who conducts regular performance evaluations for\nPlagiarism Detection Systems (PDS), gives a disillusioning summary regarding\navailable systems:\n“[...] Plagiarism Detection Systems find copies, not plagiarism.”\n([357], p. 6)\nSubstantial research on the approaches and systems aiding in the detection of\nplagiarism has been performed for almost two decades. Currently available PDS\nuse sophisticated and highly efficient character-based text comparisons. These\napproaches are capable of detecting verbatim and moderately disguised copies of\ntext reliably. However, the cleverly veiled and re-structured real-world\nplagiarism more commonly found in research contains insufficient characterbased similarities, making it undetectable by current PDS.\nToday, manual inspection of suspicious documents by experts or through\ncrowd-sourced projects, such as the VroniPlag Wiki [350], an online platform\nused to expose plagiarism cases, represents the only reliable method to detect\nmore heavily disguised plagiarism. However, the time commitment required to\nexamine plagiarism manually is significant. The 48 cases3 in the VroniPlag Wiki\nalone amounted to hundreds of hours, making manual inspection and crowdsourced examination unfeasible for examining lower-profile plagiarism or for\nchecking entire databases.\n\n3\n\nAs of 2013-07-04. The VroniPlag Wiki is an ongoing project.\n\n1.2 Motivation\n\n3\n\n1.2 Motivation\nMy motivation to research new approaches to plagiarism detection grew out of\nmy disillusionment with the state-of-the-art systems. Current software solutions\nlabel themselves &quot;plagiarism detectors&quot;. This is a misnomer because it leads\nusers to believe the software is indeed capable of detecting real-world\nplagiarism, including the disguised plagiarism more common to research. In\nreality, however, this is not the case.\nWhile I believe that plagiarism should not be tolerated in student\nassignments, I find that plagiarism in research – and particularly in the medical\nfield – has far more serious consequences to society. An example of a plagiarized\nmedical study4 [165] in Table 1, illustrates this point. The plagiarism discusses\nthe correct care for patients suffering from acute respiratory distress syndrome.\nThe key difference between the plagiarism and the original study are the\nnumbers stated in the results section. The excerpt from the medical study’s\nresults in Table 1 highlights the differences in reported values between the earlier\nand later publication in red. Both the original and the plagiarism were retrieved\nfrom an openly available subset of PubMed’s medical publication database.\n\n4\n\nThis study was identified because it was retrieved among the top results by the\napproach presented in this thesis. As I later discovered, the study had already been\nretracted by the journal, although at the time of evaluation it was still available in the\ndatabase. Visit http://citeplag.org/compare/5583/117324 for a visual comparison of\nthe plagiarism and the original.\n\n4\n\n1 Introduction\nTable 1: Excerpt from a Plagiarized Section Describing Experimental Results\nOriginal [48]\n\nPlagiarism [281]\n\nPMCID: 1065018\n\nPMCID: 2772258\n\nPEEP had no effect on CO2 gap (median\n[range], baseline: 19 [2–30] mmHg;\nPEEP 10: 19 [0–40] mmHg; PEEP 15: 18\n[0–39] mmHg; PEEP 20: 17 [4–39]\nmmHg; ideal PEEP: 19 [9–39]\nmmHg; P =0.18). Cardiac index also\nremained unchanged (baseline: 4.6 [2.5–\n6.3] l min-1 m-2; PEEP 10: 4.5 [2.5–6.9]\nl min-1 m-2; PEEP 15: 4.3 [2–6.8] l min1 m-2; PEEP 20: 4.7 [2.4–6.2] l min-1 m2; ideal PEEP: 5.1 [2.1–6.3] l min-1 m2; P = 0.08).\n\nPEEP had no effect on CO2 gap (median\n[range], baseline: 18 [2–30] mmHg; PEEP\n10: 18 [0–40] mmHg; PEEP 15: 17 [0–39]\nmmHg; PEEP 20: 16 [4–39] mmHg; ideal\nPEEP: 19 [9–39] mmHg; P =0.19).\nCardiac index also remained unchanged\n(baseline: 4.7 [2.6–6.2] O\u0003 PLQí\u0014 Pí\u0015\u001e\u0003\nPEEP 10: 4.4 [2.5–7] O\u0003PLQí\u0014 Pí\u0015\u001e\u00033((3\u0003\n15: 4.4 [2.2–6.8] O\u0003PLQí\u0014 Pí\u0015\u001e\u00033((3\u0003\u0015\u0013\u001d\u0003\n4.8 [2.4–6.3] O\u0003 PLQí\u0014 Pí\u0015\u001e\u0003 LGHDO\u0003 3((3\u001d\u0003\n4.9 [2.4–6.3] O\u0003PLQí\u0014 Pí\u0015\u001e P = 0.09).\n\nPlagiarized studies typically do not only copy text, but are also more likely to\ncontain fictitious evaluations and results. Such fake medical studies jeopardize\nthe quality of medical research and can prevent patients from receiving optimal\ntreatment5. Furthermore, for the progression of scientific disciplines it is crucial\nthat researchers can trust the outcomes of past research. This motivated me to\ndevelop a plagiarism detection approach better capable of detecting disguised\nplagiarism as it occurs in higher education and in scientific research.\n\n1.3 Research Objective\nMotivated by the limitations of existing plagiarism detection systems, the\nfollowing research objective was defined:\n\n5\n\nFor examples of harmful studies, refer to Section 7.3.4.\n\n1.3 Research Objective\n\nPropose, implement, and evaluate a plagiarism detection approach\ncapable of detecting non-machine-identifiable plagiarism forms, such\nas paraphrases, translated plagiarism, and idea plagiarism.\nTo achieve this objective the following research tasks were derived:\nTask 1:\n\nPerform a comprehensive analysis of the individual\nstrengths and weaknesses of state-of-the-art plagiarism\ndetection approaches and systems.\n\nTask 2:\n\nDevelop a plagiarism detection concept that addresses\nthe identified weaknesses of current plagiarism\ndetection approaches.\n\nTask 3:\n\nDesign detection algorithms that employ the theoretical\nconcept introduced and are fitted to detect the\nplagiarism forms currently not machine-detectable.\n\nTask 4:\n\nImplement a prototype of a plagiarism detection system\nthat employs the developed algorithms to demonstrate\nthe applicability of the approach in real-world scientific\ndocument collections.\n\nTask 5:\n\nEvaluate the proposed concept in identifying strongly\ndisguised plagiarism forms by comparing detection\nperformance, user utility, and computational efficiency\nto state-of-the-art systems. As proof of concept, identify\nunknown and currently non-machine-detectable\nplagiarism instances.\n\n5\n\n6\n\n1 Introduction\n\n1.4 Thesis Outline\nChapter 1 describes the problem setting, the research motivation, and the\ncorresponding research objective. The research objective is divided into five\nresearch tasks pursued in this thesis.\nChapter 2 introduces the reader to the problem of academic plagiarism and\nthe existing research on plagiarism detection. Following a definition of what\nconstitutes plagiarism and the prevalent forms of plagiarism, the scope of\nplagiarism in the academic and scientific environments is discussed. A detailed\nexamination of current plagiarism detection approaches is given, and the\nchallenges of detecting disguised and translated plagiarism are explained. This\nchapter addresses Research Task 1 by reviewing and exposing strengths and\nweaknesses of available plagiarism detection approaches.\nChapter 3 provides background information on citation-based document\nsimilarity measures. After introducing relevant terminology, a review of the\nliterature introduces important measures, including Bibliographic Coupling and\nCo-citation Analysis.\nChapter 4 presents the novel detection approach proposed in this thesis. I\ncoined this approach Citation-based Plagiarism Detection (CbPD). CbPD\naddresses weaknesses of current plagiarism detection approaches. By analyzing\ncitation similarities within documents, CbPD can machine-detect currently nonautomatically detectable disguised forms of plagiarism. Chapter 4 addresses\nResearch Task 2 and Task 3 by proposing CbPD as a plagiarism detection\napproach and designing detection algorithms using the introduced concept.\nChapter 5 describes the implementation of the Citation-based Plagiarism\nDetection approach in a prototype, thus addressing Research Task 4.\nChapter 6 describes the CbPD evaluation framework and presents the\nevaluation results. In the methodology section potential test collections, ground\ntruths and limitations of the evaluation are discussed. Chapter 6 addresses\nResearch Task 5 by evaluating the effectiveness of the proposed approach for\nboth known and yet unknown plagiarism cases.\n\n1.4 Thesis Outline\n\n7\n\nChapter 7 provides a summary, discusses research contributions, and gives an\noutlook on future work. The appendix includes a list of related publications, the\npreliminary corpus analysis, the CPA/CbPD patent application, material related\nto the prototype, and other resources as listed below.\nA Preliminary PMC OAS Corpus Analysis .................................................... 266\nA.1 Bibliographic Coupling ....................................................................... 266\nA.2 Longest Common Citation Sequence .................................................. 273\nA.3 Greedy Citation Tiling ........................................................................ 278\nA.4 Citation Chunking ............................................................................... 286\nA.5 Character-based PDS Sherlock ........................................................... 293\nA.6 Character-based PDS Encoplot ........................................................... 294\nB Technical Details of the CitePlag Prototype ................................................ 296\nB.1 Sentence-Word-Tagger (SW-Tagger) ................................................. 296\nB.2 Data Parser .......................................................................................... 300\nB.3 Consolidation of Reference Identifiers ............................................... 302\nB.4 Database Documentation .................................................................... 304\nC Data and Source-code Downloads ............................................................... 311\nD Related Publications .................................................................................... 313\nE Patent Application ....................................................................................... 318\nF User Study Feedback ................................................................................... 329\nG Reactions of Contacted Authors .................................................................. 331\nH Empirical Studies on Plagiarism Frequencies ............................................. 336\nI\n\nStudies on Citation-based Similarity Measures ........................................... 339\n\nJ\n\nOverview of Selected PDS .......................................................................... 343\n\nI will use &quot;we&quot; rather than &quot;I&quot; in the subsequent chapters of this thesis, since I\npublished and discussed my ideas with others including my advisor and fellow\nresearchers. For more information on joint projects and publications, please refer\nto the acknowledgements in Appendix D.\n\n2 Plagiarism Detection\nThis chapter6 provides a background on academic plagiarism. The rapid\nadvancement of information technology and especially the dissemination of the\nInternet have drastically increased the availability of information – not only for\nlegitimate purposes. Academic plagiarism is one form of undue information use\nsimplified by the abundance of information and ease of information access [161].\nIn academia, plagiarism, i.e. using the words or ideas of another person and\npassing them off as one’s own, has been described by some as a “cardinal sin”\n([249], p. 1), maybe even the “ultimate sin” ([21], p. 57). Plagiarism deprives the\noriginal authors of the benefits of their work, including gaining academic\nreputation or acquiring research funding. Plagiarism may even shift these\nbenefits to the plagiarist. Furthermore, plagiarism distorts the traceability of\nideas, arguments and results within academic literature, and withholds valuable\nresources for discovering related material from the reader [306].\nGiven the volume of available information, detecting plagiarism through\nmanual inspection is time-consuming and hardly feasible ([71], p. 9). Therefore,\nsoftware capable of partially automating plagiarism detection has become\nincreasingly popular. This section reviews the extensive and rapidly growing\nliterature on research in academic plagiarism detection. Section 2.1 provides a\ndefinition, explains the forms of plagiarism, and discusses the prevalence of\nacademic plagiarism. Section 2.2 gives a detailed description of plagiarism\ndetection (PD) approaches currently in use, and an overview of the most\neffective PDS including performance evaluations follows in Section 2.3.\n\n2.1 Academic Plagiarism\nThis section introduces the problem of academic plagiarism. Section 2.1.1\nprovides a definition, Section 2.1.2 characterizes the forms of academic\n6\n\nAn abridged version of the literature review in this chapter has been published with\nNorman Meuschke [228].\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_2, © Springer Fachmedien Wiesbaden 2014\n\n10\n\n2 Plagiarism Detection\n\nplagiarism, and Section 2.1.3 concludes with a summary of the severity of the\nproblem.\n\n2.1.1 Definition\nInspired by the five key characteristics of plagiarism according to Fishman7\n([113], p. 5), we define plagiarism to encompass:\nThe use of ideas, concepts, words, or structures without\nappropriately acknowledging the source to benefit in a setting\nwhere originality is expected.\nOther researchers commonly define academic plagiarism as literary theft, i.e.\nstealing words or ideas from other authors [102, 250]. Theft describes the\ndeliberate appropriation of foreign property without the consent of the rightful\nowner ([120], p. 125). The definition used in this thesis does not necessarily\ncharacterize academic plagiarism as theft for the following reasons.\nFirst, academic plagiarism need not be deliberate. Authors may inadvertently\nfail to properly acknowledge a source, e.g., by forgetting to insert a citation, or\nciting a wrong source; thereby committing plagiarism unintentionally [36, 219].\nAdditionally, a psychological memory bias called cryptomnesia can cause\nhumans to unconsciously attribute foreign ideas to themselves [268].\nSecond, academic plagiarists may act in consent with another author, but still\ncommit plagiarism by not properly acknowledging the original source. The term\ncollusion describes the behavior of authors, who write collaboratively, or copy\nfrom one another, although they are required to work independently [71].\nWe include collusion in the definition of academic plagiarism.\n\n7\n\nNote, the five characteristics of plagiarism as defined by Fishman are: (1) the use of\nwords, ideas, or work products (2) attributable to another identifiable person or\nsource, (3) without attributing the work to the source (4) in a situation where there is a\nlegitimate expectation of original authorship (5) in order to obtain some benefit,\ncredit, or gain which need not be monetary ([113], p. 5).\n\n2.1 Academic Plagiarism\n\n11\n\n2.1.2 Forms of Academic Plagiarism\nReal-world observations of academic plagiarism reveal a variety of commonly\nfound forms.\nLiteral plagiarism describes the undue copying of text with very little or no\ndisguise.\n-\n\nCopy &amp; paste (c&amp;p) is the most common form of literal plagiarism\nand is characterized by adopting text verbatim from another source\n[219, 358].\n\n-\n\nShake &amp; paste (s&amp;p) refers to the copying and merging of text\nsegments with slight adjustments to form a coherent text, e.g., by\nchanging word order, by substituting words with synonyms, or by\nadding or deleting “filler” words [357].\n\nDisguised plagiarism subsumes practices to conceal unduly copied text [185].\nWe identified five forms of disguised plagiarism in the literature on plagiarism.\n-\n\nParaphrasing is the intentional rewriting of foreign thoughts in the\nvocabulary and style of the plagiarist without acknowledging the\nsource [71, 185].\n\n-\n\nTechnical disguise refers to techniques that exploit weaknesses of\ncurrent detection approaches to make plagiarized content nonmachine-detectable. Examples include using homoglyphs, symbols\nthat visually appear similar or identical, or inserting random letters\nin white font [151, 170].\n\n-\n\nTranslated plagiarism is the manual or automated conversion of\ntext from one language to another with the intention of hiding its\norigin [357].\n\n12\n\n2 Plagiarism Detection\n\n-\n\n8\n\nStructural and idea plagiarism8 encompasses the use of\ncompositional elements or a broader concept without due\nacknowledgement of the source. Even if the text is in the author’s\nown words, structural elements, such as outlines or the\npresentation of ideas or content, such as the chosen research\napproach, the experimental setup, the lines of argument or the\nbackground sources used, may be similar on a level that would\nhave warranted acknowledgement [116, 219]. Inherent in its\ndefinition, structural and idea plagiarism is not &quot;obvious&quot; and thus\nit is not necessarily an indicator that a work is unoriginal or must\nbe retracted. Thus, the term &quot;plagiarism&quot; for structural and idea\nsimilarity is justified often only for extreme cases. The presence of\nstructural or idea similarity can rather be a potential quality\nindicator, e.g., to determine if a work qualifies to be published in a\ntop-journal or a mediocre journal, or if a dissertation meets the\nhighest demands or only satisfies the necessary requirement. We\ncombine structural and idea plagiarism into a single plagiarism\nform, since it is extremely difficult for human examiners to judge\nif potential structural plagiarism also copied ideas. Structural and\nidea plagiarism represent one of the most controversial forms of\nplagiarism to verify [362], because the decision on whether\nstructural or topical similarities exceed a legitimate level is highly\nsubjective.\n\nThere is no consensus on whether structural and idea plagiarism should be categorized\nas a form of disguised plagiarism. However, for the definition of disguised plagiarism\nin this thesis, i.e. forms of plagiarism containing little or no verbatim text overlap and\nthus not being reliably detectable by PDS, structural and idea plagiarism can\nreasonably be included in this category. Note that exceptional cases in which\nstructural plagiarism or idea plagiarism also contains paragraphs or sentences copied\nin their entirety exist; however, this holds true for all plagiarism forms, they do not\nhave to be exclusive.\n\n2.1 Academic Plagiarism\n\n13\n\nSelf-plagiarism is the partial or complete reuse of one’s own writings without\nsuch reuse being justified. Presenting updates or providing access to a larger\ncommunity may justify re-publishing one’s own work, but still requires\nappropriate acknowledgement of the previously published work [40]. Unjustified\nreasons include trying to artificially increase one’s citation count [77].\n\n2.1.3 Prevalence of Plagiarism in the Academic Environment\nAcademic plagiarism is not a new phenomenon. Since the 1920s, researchers\nhave analyzed the problem, focusing mainly on North American colleges. The\nfollowing studies give empirical evidence of the problem by providing reviews\non academic dishonesty in general [44, 74], collegiate cheating behavior [82,\n364] and plagiarism in particular [102, 250].\nThe majority of studies use self-report surveys to evaluate plagiarism\nbehavior. The most extensive study on U.S. and Canadian campuses questioned\naround 80,000 students over three years from 2002 to 2005 [220]. McCabe\nreports 38 % of undergraduates and 25 % of graduate students self-reporting to\nhave paraphrased or copied at least a few sentences without indicating the\nwritten source in the 12-month period prior to being questioned [220]. McCabe\nassumes the true numbers to be higher, because students were more concerned\nabout their anonymity in this web-based assessment compared to earlier\npaper-based surveys [221, 222]. We agree with this assumption, since\nself-reports show a tendency to understate misbehavior [284].\nThe self-report studies often did not distinguish between the different forms\nof concealed plagiarism or the degree of plagiarism obfuscation. However, for\nstudies indicating the prevalence of specific plagiarism forms, copy &amp; paste and\nshake &amp; paste plagiarism, a few sentences in length, dominates [176, 220, 222,\n223, 273]. Around 20 % of participants admitted to having plagiarized large\nparts of a document or having obtained texts from fellow students or Internet\nessay banks [176, 220, 273].\nOther studies completed outside of North America that employed plagiarism\ndetection systems consistently found 20 % or more of the inspected documents\nto contain suspicious content [23, 83, 329]. However, the fraction out of total\n\n14\n\n2 Plagiarism Detection\n\nplagiarism represented by the detected plagiarism remains unknown. The\npresented studies only serve as &quot;spotlights&quot; on student plagiarism in different\ncountries. Yet, by reviewing these studies, as well as other extensive research\nand particular cases observed in the literature [74, 82, 102, 250], we conclude\nthat plagiarism among students is a serious problem.\nAssessments of academic dishonesty among post-graduate researchers are\nrare. One large-scale survey of 2,000 doctoral students and their 4,000 associated\nfaculty members reported that 28 % of faculty members witnessed doctoral\nstudents committing plagiarism. Seven percent of doctoral students and 8 % of\nfaculty members reported they had experienced plagiarism by faculty members\n[324]. Another survey of approximately 3,250 scientists asking about personal\nmisbehavior yielded lower admitted incident rates. Only about 1 % of the\nrespondents self-reported having committed plagiarism. Martinson and Anderson\nassess these results as “[...] conservative estimates [...]” of the true frequency\n([215], p. 738). They assume understatements and a response bias from\nplagiarists who refused to participate.\nFröhlich, Martin and Williams, experts in the field of academic plagiarism,\nagreed that persons and institutions that discover academic misbehavior often\ntreat such incidences in a clandestine manor. Therefore, only a small fraction of\nincidences becomes public [116, 214, 366]. The aforementioned experts deduct\nreasons that substantiate this assumption from known cases of misconduct.\nPersonal dependence and the fear of retaliation by the accused, or peers related\nto the accused, may keep researchers from reporting or publicizing academic\nmisbehavior. Aversion of engagement in the laborious and time-consuming\ninquiry needed for verifying misconduct is another obstacle to reporting. Fear of\nlosing credibility and scientific reputation often keeps institutions, including\nuniversities, research centers or conferences, from publicizing cases of\nmisconduct or handling them as rigorously as they should.\nDespite these obstacles, numerous cases of plagiarism in academia have\nbecome public. Price reviews 19 cases of plagiarism, which the U.S. Office of\nResearch Integrity publicized as a result of evaluating medical research projects\nbetween 1992 and 2005 [269]. Gutbrodt reports that the IEEE INFOCOM 2006\n\n2.1 Academic Plagiarism\n\n15\n\nconference, rejected 12 out of about 1,000 submitted papers after a scan using a\nPDS revealed suspicious similarities [145].\nSorokina et al. used a self-developed PDS to scan approximately 285,000\ntexts in the scientific document database arXiv.org [307]. They found more than\n500 documents to contain likely cases of plagiarism and approximately 30,000\ndocuments (20 % of the collection) to likely be duplicates or to contain “[...]\nexcessive self-plagiarism [...]” ([307], p. 12). Sorokina et al. categorized\ndocuments in the excessive self-plagiarism class if their largest contiguous\namount of copy-free text was less than 20 % of total document length. As the\nconsequence of a different investigation, arXiv.org deleted 65 articles from 14\ndifferent authors for containing substantial plagiarism [15].\nThe project Déjà Vu [92, 104, 105, 114, 202, 321] used a text similarity\nscanner [191, 254] to analyze abstracts of bioscience articles in MEDLINE® and\ntheir full-texts in PubMed Central® (PMC) if available. MEDLINE is a\nbibliographic index and PMC a digital full-text archive [335, 338]. The Déjà Vu\nproject identified 79,383 articles with highly similar abstracts. Manual checks of\n4,515 full-texts identified 252 cases of likely plagiarism and 89 likely cases of\nself-plagiarism [92]. Many reviews presented further plagiarism cases committed\nin part by renowned senior scholars [69, 116, 214, 313, 361, 366].\nRecently, the investigations of two crowd-sourcing projects, the GuttenPlag\nWiki and the VroniPlag Wiki exposed plagiarism in the doctoral thesis of former\nGerman Federal Minister of Defense and documented 48 cases of plagiarism,\nrespectively9 [147, 350]. Some cases in the VroniPlag Wiki involve high-ranking\npoliticians, including the dissertations of members of the German Federal\nParliament [348], the European Parliament [64], and the former Vice President\nof the European Parliament [226]. To date, the responsible universities have\nverified and retracted the doctorates of nine offenders10 [350].\n\n9\n10\n\nAs of 2013-07-04. The VroniPlag Wiki investigations began in March 2011 and are\nongoing.\nAs of 2013-07-04. For a complete and up-to-date listing of retractions visit:\nhttp://de.vroniplag.wikia.com/wiki/Übersicht\n\n16\n\n2 Plagiarism Detection\n\nIn a similar case, a Hungarian magazine accused Hungary’s president, Pál\nSchmitt, of having committed substantial plagiarism in his doctoral thesis. The\nresponsible university investigated the allegations, confirmed plagiarism on 197\nof the 215 pages in the dissertation, and rescinded Schmitt’s doctorate [292].\nIronically, even two European ministers of education, were recently found to\nhave plagiarized. The Romanian Minister of Education, Ecaterina Andronescu,\nwas accused of plagiarism and falsification of data in 2012 [163]. The same year\nin Germany, Annette Schavan, the German Federal Minister of Education and\nResearch was accused of plagiarism in her doctoral thesis. The accusations of\nSchavan’s dissertation sparked a lengthy and heated political debate. The final\ndecision on the presence of plagiarism was made almost a year later, in February\n2013, when the Heinrich-Heine University of Düsseldorf rescinded the doctorate\nby a nearly unanimous vote on the grounds of “willful deceit” [153]. A. Schavan\nstepped down from her political position but vowed to take the decision to court\n[309].\nWe conclude that academic plagiarism is a pressing unsolved problem, also\namong graduate and post-graduate researchers, although plagiarism research has\nfocused mainly on undergraduate students. Applying automatic detection\nsystems to student assignments is already common practice at many institutions\n[18]. Scholarly publications, however, are checked far less routinely. By\napplying string matching to the MEDLINE® database, the Déjà Vu project\nidentified numerous likely cases of plagiarism [104, 114]. Investigations like\nthese can only lead to speculations on the quantity of well-disguised plagiarism\nin research that goes undetected. Empirical studies on plagiarism frequencies are\nlisted in Appendix H.\nThe following section describes current plagiarism detection approaches. By\npointing out the strengths and weaknesses of existing systems, we find that a\nsubstantial number of plagiarism incidences are likely to remain undetected.\n\n2.2 Plagiarism Detection Approaches\n\n17\n\n2.2 Plagiarism Detection Approaches\nThis section first gives an overview of the generic mode of operation for all\nplagiarism detection systems (PDS) and second presents technical descriptions of\nthe detection approaches employed by PDS.\n\n2.2.1 Generic Detection Approach\nPlagiarism detection is a hypernym for computer-based approaches, which\nsupport the identification of plagiarism [318]. PD is an information retrieval (IR)\ntask supported by specialized IR systems, called plagiarism detection systems\n(PDS). PDS implement one of two generic detection approaches: external or\nintrinsic.\nExternal PDS compare a suspicious document with a reference collection,\nwhich is a set of genuine documents [318]. The comparison requires a document\nmodel with defined similarity criteria. The task is to retrieve all documents that\ncontain passages that are similar, beyond a chosen threshold, to segments in the\nsuspicious document [319].\nIntrinsic PDS statistically examine linguistic features of a text, a process\nknown as stylometry, without performing comparisons to other documents.\nIntrinsic PDS report changes in writing styles as indicators for potential\nplagiarism [97].\n\n18\n\n2 Plagiarism Detection\n\nReduction of\nretrieval space,\ne.g., by applying\nheuristics\n\nMore restrictive\nexamination\n\nBegin\nyes\n\nKnowledge-based\nphase, e.g.,\nelimination of false\npositives\n\nPotential\nplagiarism\ndetected?\n\nHuman examiner\nrequired\n\nno\nEnd\n\nFigure 1: Generic Plagiarism Detection Process\n\nMost external PDS follow a three-stage retrieval process as illustrated in\nFigure 1. In the first stage, PDS commonly apply computationally inexpensive\nheuristic document models to reduce the retrieval space. The goal of this stage is\nto identify a small fraction of the reference collection as candidate documents\nfrom which the suspicious text could originate. Coarser fingerprinting (see\nSection 2.2.3), string matching (see String Matching, page 26) or vector space\nmodels (see Vector Space Models, page 28) are common detection approaches\nused by PDS for this purpose.\nIn the second stage, candidate documents retrieved in the first stage undergo\na computationally more expensive detailed comparison. PDS usually apply\nfiner-grained variants of the detection approaches we will explain in Sections\n2.2.3–2.2.4. PDS can either rely on a single detection approach, or implement a\ncombination of approaches. For example, a PDS may use a coarser fingerprinting\nmethod or a vector space model for the initial retrieval stage and a more\nfine-grained implementation of the same detection approach for the detailed\ncomparison stage. Likewise, a PDS may employ fingerprinting or vector space\nmodel-based retrieval for the initial retrieval stage and an elaborate\nstring-matching procedure for the detailed comparison stage.\n\n2.2 Plagiarism Detection Approaches\n\n19\n\nIn the third stage, PDS apply domain-specific, knowledge-based,\npost-processing procedures to text segments retrieved in the second stage. The\ngoal of this stage is to eliminate false positives, which the specific detection\nprocedures in the previous stages are prone to produce. Typical cases of false\npositives are correctly cited passages with high character based similarity [317].\nThe design of the procedures applied in the third stage depends highly on the\ncharacteristics of the detection approach in the previous retrieval stages.\nMany plagiarism detection approaches involve the comparison of billions of\nlines of text in large reference collections, which inevitably leads systems to face\na trade-off between computational effort and accepting some degree of\ninformation loss. The computational efficiency of systems, both in terms of time\nand use of storage space, is thus an important consideration.\nThe literature on plagiarism detection emphasizes that no PDS are capable of\nreliably identifying plagiarism without human review. An examiner is always\nrequired to check the results of the automated retrieval and to verify if plagiarism\nis present [185, 218]. Additionally, the perceptions of human assessors regarding\nwhat constitutes plagiarism differ widely [275, 323]. Therefore, PDS cannot\nfully automate the identification of plagiarism. These systems are only the first\nstep in a semi-automated plagiarism detection and verification process, which\nrequires careful consideration on a case-by-case basis [185].\n\n2.2.2 Overview of Plagiarism Detection Approaches\nThis section gives an overview of PD approaches. We classify available\napproaches by the type of similarity assessment they most prominently apply, as\neither performing a local or a global similarity assessment, as shown in Figure 2.\n\n20\n\n2 Plagiarism Detection\nPlagiarism Detection\nlocal similarity assessment\n\nfingerprinting\nfingerprint\nindices\n\nglobal similarity assessment\nterm occurrence\nanalysis\n\nstylometry\n\norder preserving\n\norder neglecting\n\nsuffix data\nstructures\n\nvector space\nmodels\n\nlinguistic\nfeature sets\n\nFigure 2: Classification of Plagiarism Detection Approaches\n\nThe leaves of the tree diagram in Figure 2 show the detection approaches\ntypically used in local and global document similarity assessment. All detection\nmethods require a reference collection to run comparisons, except for stylometry.\nThe stylometry approach analyzes document suspiciousness intrinsically without\nperforming comparisons to other documents.\nLocal similarity assessment approaches analyze matches of confined text\nsegments in suspicious texts [316]. Section 2.2.3 describes fingerprinting, the\nmost common approach in this class of detection approaches.\nGlobal similarity assessment approaches examine characteristics of longer\ntext sections, or the complete document, and express the degree to which two\ndocuments are similar to each other in their entirety [316]. PD approaches that\nemploy term occurrence analysis typically make use of the entire text, i.e.\noperate at the global level. Vector space models (VSM) or suffix data structures\nare commonly used global document similarity assessment methods, as\nexplained in Section 2.2.4.\nFigure 3 visualizes the concept underlying the global versus local similarity\nassessment approach. In the left example, the text is processed according to local\nsimilarity analysis, where all contiguous matching sequences, which share a\nminimum number of words or characters with another document – not shown in\nthe figure – are highlighted. In the right example, the same text is marked up\naccording to a global similarity analysis approach, where only the word stems\n\n2.2 Plagiarism Detection Approaches\n\n21\n\nheld in common with another similar document are used to form global term\nvectors.\nLocal similarity analysis\nAt the first sight ``knowledge over\nsearch&#x27;&#x27; is obvious on the one hand, but\ntoo simple on the other: Among others,\nthe question remains whether or not he\ncould believe the alleged claim.\nHowever, most of us think that it\ndevelops from the search-plussimulation paradigm. This way one\ncould gain the maximum impact for\nautomated diagnosis problem solving,\nsimply by untwining the roles of search\nand simulation.\n\nConcept:\ncontiguous matching word sequences\nanalyzed\n\nGlobal similarity analysis\nAt the first sight ``knowledge over\nsearch&#x27;&#x27; is obvious on the one hand, but\ntoo simple on the other: Among others,\nthe question remains whether or not he\ncould believe the alleged claim.\nHowever, most of us think that it\ndevelops from the search-plussimulation paradigm. This way one\ncould gain the maximum impact for\nautomated diagnosis problem solving,\nsimply by untwining the roles of search\nand simulation.\n\nConcept:\nshared word stems analyzed, stop words\nexcluded\n\nFigure 3: Local vs. Global Document Similarity Analysis\nSource: Stein and Meyer zu Eissen [316]\n\nThe classification in Figure 2 reflects the most common application of the\npresented detection approaches as part of a plagiarism detection system. For\nexample, PDS commonly apply vector space models or string-matching\nprocedures to the entire document. The procedures flag documents as suspicious\nif the detected text matches exceed a certain fraction of the entire document\nlength. However, PDS can also employ vector space models or string-matching\nprocedures to analyze fragments of a text to detect more local similarities. Figure\n2 applies to the monolingual PD setting and omits cross-language PD (CLPD)\nfor simplicity. CLPD approaches partially adapt building blocks from the\nmonolingual setup and partially use specifically designed cross-language\nsimilarity assessments.\n\n22\n\n2 Plagiarism Detection\n\nWe present all detection approaches, including CLPD, in the following sections.\nFor each approach, we present typical characteristics that influence its detection\ncapabilities. However, the detection performance achieved by individual\napproaches depends heavily on their individual implementation and the test\ncollection chosen for evaluation. We highlight characteristic strengths and\nweaknesses of detection approaches by presenting results of impartial PDS\nperformance comparisons in Section 2.3.1.\n\n2.2.3 Fingerprinting\nFingerprinting is currently the most widely applied external plagiarism detection\napproach [97]. Fingerprinting approaches represent a document by segmenting it\ninto substrings and selecting a subset of all the substrings formed. The substring\nset is the fingerprint; its elements are called minutiae [158]. PDS often apply\nhash functions to transform minutiae into space-efficient byte strings. PDS\ncompare a document by computing the document’s fingerprint and querying\neach of the minutiae with a pre-computed index of fingerprints for all documents\nin a reference collection, as Figure 4 shows.\n\nFigure 4: Concept of Fingerprinting\n\nMinutiae that match with other documents indicate shared text segments and\nsuggest potential plagiarism when exceeding the chosen similarity threshold\n[41]. The fingerprinting methods proposed for PD differ in the parameters:\n\n2.2 Plagiarism Detection Approaches\n\n23\n\nchunking unit, chunk size, fingerprint resolution, chunk selection strategy and\nthe similarity function.\nThe chunking unit defines the segments into which a fingerprinting method\ndivides a text, and whether these segments are combined into larger composites,\ncalled chunks. For example, the chunking units used in Figure 4 are sentences.\nTable 2 summarizes chunking units proposed for fingerprinting methods.\nTable 2: Overview of Chunking Units Proposed for Fingerprinting Methods\nChunking Unit\nCharacter n-grams (n consecutive characters)\n\nWords\n\n[51, 57, 142, 154, 245, 285,\n371]\n\nAll words\n\n[33, 42, 111, 172, 203]\n\nStop words removed\n\n[68, 158, 173, 297]\n\nStop words alone\n\n[312]\n\nSentences\n\nHybrid terms\n\nUsed in\n\n[41, 253]\nWord-bound n-grams\n\n[293]\n\nSentence-bound character n-grams\n\n[56, 57]\n\nSentence-bound word n-grams\n\n[307]\n\nThe chunk size determines the granularity of a fingerprint. Larger chunk sizes\nare more restrictive selectors and thus benefit detection accuracy, because the\nprobability that documents share substrings decreases with increasing substring\nlength. Larger chunks are also computationally more efficient, because fewer\nchunks must be stored for each document. Yet, large chunks are susceptible to\nfailure in detecting disguised plagiarism, because changing one character alters\nthe fingerprint of a rather long text segment. Small chunks better deal with\nmodifications, but require higher computational effort and tend to yield false\npositives when matching common substrings that documents share by chance\n\n24\n\n2 Plagiarism Detection\n\n[154, 158]. Due to these trade-offs, chunk sizes differ. Table 3 lists the chunk\nsizes of common fingerprinting methods found in the literature.\nTable 3: Overview of Chunk Sizes Proposed for Fingerprinting Methods\nChunk Size\n\nUsed in\n\n3-4 characters\n\n[57]\n\nsingle content words\n\n[297]\n\n3-5 content words\n\n[158, 172, 203, 298]\n\n7-10 content words\n\n[42, 307]\n\n8-11 stop words\n\n[312]\n\nThe resolution is the number of minutiae, i.e., the number of hashed\nsubstrings a fingerprint contains and can be either fixed or variable. More\nminutiae are equivalent to encoding longer sections of the text. Thus, a higher\nfingerprint resolution is positively correlated with detection accuracy, yet is\ncomputationally more expensive [42, 158, 286].\nFixed-resolution fingerprints are computationally efficient, but yield lower\ndetection accuracy, especially for long documents [154]. When using\nfixed-resolution fingerprints, a book may not share enough minutiae with a\nparagraph copied from it to be detectable [286].\nVariable-resolution fingerprinting methods compute more minutiae the\nlonger the document and thus encode a higher percentage of the text. This\nincreases detection accuracy, but requires higher computational effort. Full\nfingerprinting considers all minutiae. However, the fingerprint index for a fullresolution fingerprinting PDS requires eight or more times the disk space of the\noriginal document collection and significant processing time [33, 286].\nTherefore, full-resolution fingerprinting PDS are not practical for collections\n\n2.2 Plagiarism Detection Approaches\n\n25\n\ncontaining millions of documents. Table 4 lists fixed or variable resolution\nfingerprinting methods.\nTable 4: Overview of Fixed and Variable-Resolution Fingerprinting Methods\nResolution\n\nUsed in\n\nfixed\n\n[154]\n\nvariable\n\n[33, 41, 42, 57, 143, 173, 203,\n208, 285, 297, 307]\n\nThe chunk selection strategy determines which text sections the fingerprint\nencodes and thereby makes them comparable to other documents. A selection of\nchunks is necessary, because the computational requirements of full-resolution\nfingerprinting are too high for most practical use cases. Table 5 lists three\ncommon chunk selection strategies described in the literature.\nTable 5: Overview of Chunk Selection Strategies for Fingerprinting Methods\nChunk Selection\n\nUsed in\n\nCommon substrings\n\n[208]\n\nProbabilistic selection\n\n[41, 42]\n\nFrequency-based selection\n\n[154, 235, 286]\n\nThe similarity function considers the minutiae that a suspicious text shares\nwith a document in the reference collection to calculate a similarity score.\nDocuments of the reference collection that exceed a certain threshold score\nrepresent potential plagiarism sources [158]. One basic similarity function, as\nused by Kasprzak and Brandejs, defines a fixed number of matching minutiae as\nthe threshold [172].\nAnother intuitive similarity function considers the fraction of all minutiae\n‫ )݀(ܯ‬of a suspicious document ݀௦ that overlap with minutiae of a genuine\ndocument ݀௚ . Broder et al. coined this measure containment ܿ(݀௦ , ݀௚ ), see\n\n26\n\n2 Plagiarism Detection\n\nEquation 2.1, because it represents the share of a suspicious document contained\nwithin a source [42]. Broder et al. proposed using containment in conjunction\nwith a measure they termed resemblance, ‫݀(ݎ‬௦ , ݀௚ ), see Equation 2.2.\nܿ൫݀௦ , ݀௚ ൯ =\n‫ݎ‬൫݀௦ , ݀௚ ൯ =\n\nหெ(ௗೞ )‫ת‬ெ൫ௗ೒ ൯ห\n|ெ(ௗೞ )|\nหெ(ௗೞ )‫ת‬ெ൫ௗ೒ ൯ห\nหெ(ௗೞ )‫׫‬ெ൫ௗ೒ ൯ห\n\n(2.1)\n(2.2)\n\nResemblance is the Jaccard coefficient for the sets of minutiae and hence\nexpresses the global similarity of the two sets. Resemblance and containment\nhave found frequent use in PD research along with other similarity measures [33,\n41, 42, 67, 111, 203, 253]. More sophisticated similarity functions use the length\nof documents [33], relative frequencies of minutiae [285], or maximal\ndifferences in minutiae vectors [371].\nThe inherent challenge of all fingerprinting methods is to find a document\nrepresentation that reduces computational effort and limits the information loss\nincurred, in order to achieve acceptable detection accuracy [97]. The parameter\nchoice of fingerprinting methods reflects this challenge. The combinations of\nparameters that perform best depend on the nature and size of the collection, and\non the expected amount and form of plagiarism present.\n\n2.2.4 Term Occurrence Analysis\nChecking documents for verbatim text overlaps is an intuitive approach to\nexternal plagiarism detection. Researchers frequently adopt the classical\ncomputer science concepts of string matching and vector space models to check\nfor verbatim text overlaps. This section explains the principles of both\napproaches and outlines their capabilities and limitations when used in PDS.\n\n2.2.4.1\n\nString Matching\n\nString matching refers to searching for a given character sequence, or &quot;pattern&quot;,\nin a text. PDS employing string-matching approaches commonly use suffix\ndocument models. Suffix data structures store each substring of a text and allow\nfor efficient comparisons. Using string matching for PD requires the computation\n\n2.2 Plagiarism Detection Approaches\n\n27\n\nof suffix document models for the suspicious document and for all documents in\nthe reference collection. Because the pattern to search for is initially unknown in\na PD setting, the detection procedure must select portions of the suspicious text\nand check them against all other suffix models [20].\nBaker was among the first to employ suffix trees for PD [19]. She augmented\nthe trees’ vertices with positional information that allowed detecting all matching\nstrings of maximum length. Baker defined a heuristic similarity threshold and\ntailored her procedure to check source code for plagiarism. She suggested an\nadaption of the algorithms to text plagiarism detection, but did not pursue this\napplication [20]. The Match Detect Reveal (MDR) system also employed string\nmatching for PD [232]. MDR adopted Ukkonen’s algorithm [336], which only\nconsiders suffixes of full words for constructing the tree [234]. MDR used the\nmatching statistics algorithm of Chang and Lawler for overlap computation [63].\nKhmelev et al. constructed a PDS using suffix arrays for document\nrepresentation and the &quot;R-measure&quot;, i.e. the normalized sum of repeated\nsubstrings, for similarity calculation [175]. Goan et al. used String B-Trees and\nsimilarity assessments leveraging “[...] knowledge of common text patterns [...]”\n([137], p. 693) for PD. The authors presented no additional implementation\ndetails.\nThe strength of substring-matching PD approaches is their accuracy in\ndetecting verbatim text overlaps. Suffix document models encode the complete\ncharacter information of a text, which distinguishes them from the document\nmodels that most fingerprinting methods employ. If two documents share\nsubstrings, suffix document models enable the detection of this overlap through\nstring matching.\nThe major drawbacks of string matching in a PD context are the difficulty of\ndetecting disguised plagiarism, which is attributable to the exact matching\napproach, and the high computational effort required. At the time of writing, the\nmost space-efficient suffix tree [183], suffix array [177] and suffix vector [236]\nimplementations allow searching in linear time and require on average\napproximately 8n of storage space, with n being the number of characters in the\noriginal document. String B-Trees allow searching in ܱ(log ݊), but also require\n\n28\n\n2 Plagiarism Detection\n\nmultiple times the storage space of the original documents [183]. Additionally,\npre-computing suffix models is computationally expensive.\nFor very large document collections, the computational requirements prohibit\nthe practical application of elaborate string matching. Therefore, PDS commonly\napply computationally less expensive approaches, such as fingerprinting methods\nto limit the document collection in the heuristic retrieval phase and subsequently\nemploy string matching in the detailed analysis phase (see Figure 1 in Section\n2.2.1).\n\n2.2.4.2\n\nVector Space Models\n\nVector Space Models (VSM) are a standard IR concept. VSMs consider the\nterms of a text as unordered sets, represent the sets as vectors and compare the\nvector representations using vector-based measures ([209], p. 120). We briefly\noutline the basic building blocks of VSMs, their application for PD and the\nstrengths and weaknesses of the approach.\nMost commonly, PDS use only one vector space model to encode the entire\ndocument. However, some PDS employ multiple models that encode paragraphs\nor sentences to perform a more local similarity assessment. This approach\nincreases detection accuracy, but is computationally more expensive. Table 6\nlists publications describing either global or local VSM as part of a PDS.\nTable 6: Overview of Local and Global VSM Proposed for Plagiarism Detection\nScope\n\nUsed in\n\nglobal (document)\n\n[88, 94, 158, 230, 299]\n\nlocal (sentences)\n\n[150, 171, 238]\n\nMost VSM consider words as terms, yet any unit of text can quantify as a\nterm unit. Terms most often undergo preprocessing, i.e. a normalization and\nselection process, prior to constructing the model. Preprocessing may include\nstemming of words, de-capitalization, stop word and punctuation removal,\n\n2.2 Plagiarism Detection Approaches\n\n29\n\nnumber replacement or part-of-speech tagging [67, 150, 238, 252, 299]. Table 7\nlists publications describing VSM for PD purposes using different term units.\nTable 7: Overview of the Term Units of VSM Proposed for Plagiarism Detection\nTerm Unit\n\nUsed in\n\nwords\n\n[94, 230, 299]\n\nword n-grams\n\n[24, 88]\n\nSentences\n\n[150, 171, 238]\n\nA term weighting scheme is a crucial part of all vector space document\nmodels, because it determines the most relevant terms to check. PDS commonly\napply the classic tf-idf scheme, which considers a term’s frequency (tf) in a\ndocument and normalizes it by the term’s inverse frequency in all documents of\nthe collection (idf) [94, 150, 171, 299]. The tf-idf scheme assigns high weights to\nterms that occur frequently within the analyzed document, but infrequently in the\nentire collection. The idea is that such terms are likely specific content words\nthat characterize a topic, which few other documents in the collection address.\nThe similarity function defines how matching terms of documents contribute\nto the calculation of a similarity score. Numerous works use the standard cosine\nsimilarity measure [94, 150, 238, 299]. More complex similarity functions\nincorporate semantic information to increase the probability of identifying\ndisguised plagiarism, for example, by considering word synonyms. Kang et al.\npropose a similarity function that assesses word matches, including synonyms\nand vector overlap on the sentence level [171]. The similarity functions of\nTsatsaronis et al. [333] and Pera and Ng [252] give additional weight to\nco-occurring, semantically related terms. Both works use the WordNet ontology\n[109] to pre-compute the semantic relatedness of terms and the Wikipedia\nencyclopedia [365] to calculate co-occurrence frequencies.\nVSM are well-researched and well-performing approaches for identifying\nverbatim text overlaps. The global similarity assessment on the document level\nthat most VSM perform tends to be detrimental to detection accuracy in PD\n\n30\n\n2 Plagiarism Detection\n\nsettings. This is because verbatim plagiarism more often encompasses smaller,\nconfined segments of a text, which favors local similarity analysis.\n\n2.2.5 Stylometry\nStylometry subsumes statistical methods to quantify and analyze an author’s\nwriting style [160, 169]. Authorship attribution (AA) is the dominant field of\napplication for stylometry and a prolific area of research beyond the scope of this\nthesis. Juola and Stamatatos perform extensive surveys on the state of the art in\nAA [169, 310].\nAuthorship verification is a problem class within AA and related to intrinsic\nand external PD [169, 178, 319]. Authorship verification addresses the binary\ndecision problem of whether an alleged author wrote a given text or not.\nConducting stylometric comparisons in one of three possible categories can\nsolve this problem. According to Koppel and Stein [178, 319], these categories\ninclude:\n\n1. Comparing existing documents from the author in question with\na text doubtfully originating from the same author. This\nrepresents the classical authorship verification problem.\n\n2. Comparing a text of the author in question to other texts written\nby different authors in order to identify similar sections. This\ncorresponds to the problem of external PD.\n\n3. Comparing different text segments allegedly written by the\nauthor in question to other text segments within the same\ndocuments in order to identify suspicious differences. This\nrepresents the intrinsic approach to PD, because it requires no\nexternal sources.\nThe following section outlines the characteristic strengths and weaknesses of\nstylometry and its contribution to intrinsic PD. We identified no applications of\nstylometry for external PD, arguably because other PD approaches achieve a\nbetter detection performance, refer to Section 2.3.1. We do not cover the\n\n2.2 Plagiarism Detection Approaches\n\n31\n\nclassical authorship verification problems, because we cannot assume writing\nsamples from the author in question to be widely available in a PD setting.\n\n2.2.5.1\n\nStylometry for Intrinsic Plagiarism Detection\n\nIntrinsic PD approaches construct and compare models that quantify an author’s\ncharacteristic writing style for individual segments of a text. The goal is to\nidentify sections that are stylistically different from other sections, and thus\npotential indicators of plagiarism [97]. Technically, intrinsic PD approaches\nsolve a one-class classification problem. Genuine text segments that share\ncharacteristic attributes represent the target class, while plagiarized segments\nform outliers with divergent attributes. An automatic classification method must\nlearn the characteristics of the target class and use them for rejecting outliers\n[260, 274, 319]. According to Stein et al., intrinsic plagiarism detection\nprocedures generally contain the following components [319]:\nA decomposition strategy defines the segments compared by the detection\nprocedure. Using fixed-length segments based, for example, on character [311]\nor word counts [97, 144, 319], is a basic strategy [310]. Another common\npractice is structural segmentation, on the sentence [238], paragraph [322] or\nchapter [339] level.\nA style model defines the set of linguistic features analyzed by the detection\nprocedure. Style models generally use a unique combination of features selected\nfrom over 1,000 features proposed for stylometry [144, 279, 319]. The majority\nof features fall into one of the following categories [310, 319]:\n-\n\nLexical features appear on the character level, e.g., n-gram\nfrequency, or on the word level, e.g., average word lengths or\nsyllables per word.\n\n-\n\nSyntactic features include word or part-of-speech frequencies.\n\n-\n\nStructural features include\npunctuation frequency.\n\naverage\n\nparagraph\n\nlength\n\nor\n\n32\n\n2 Plagiarism Detection\n\nAn outlier detection procedure operates on the feature vectors of the segment\nand the overall document to identify significantly different elements. Many\nclassifiers for one-class classification problems are available [319]. Intrinsic PD\napproaches commonly use traditional measures of dispersion, for example,\nstandard deviation or median absolute deviation [322], and vector comparisons\nusing cosine similarity [239]. Meyer zu Eisen et al. demonstrated\nmachine-learning approaches capable of learning the relative differences in\nfeature vectors [98]. Stein et al. applied methods using estimated feature\ndistributions in the target and outlier class [319].\nAn outlier post-processing procedure determines whether multiple outliers\nform a larger section and are suspicious enough to be reported. Heuristic voting\n[322] or meta-learning [319] are two approaches used to solve this task.\nThe advantage of intrinsic PD is its independence from a reference collection.\nThus, in theory, intrinsic PDS can give a quick overview of document segments\nthat need further assessment in a plagiarism investigation. The accuracy and\nreliability of automated stylometric analyses depends on multiple factors,\nincluding the observed linguistic features, genre, volume, and purity of the\nanalyzed text. For instance, quoted text, headings, tables or figures can\nsignificantly skew style statistics [169, 310]. Joint publications are another\nobstacle to text purity. Detecting writing style differences that signal potential\nplagiarism, and not simply multiple authorship, is a challenge for these kinds of\ndocuments [219]. Section 2.3.1 gives an overview of performance for state-ofthe-art intrinsic PDS.\n\n2.2.6 Cross-Language Plagiarism Detection\nCross-language plagiarism detection (CLPD) aims to identify documents\nplagiarized by translation from source documents in another language [259]. To\nscale to large document collections, CLPD approaches should follow the\nthree-stage PD process composed of a heuristic retrieval, a detailed analysis and\na knowledge-based post-processing phase (see Section 2.2.1) [259].\nFor the heuristic retrieval phase, a CLPD approach may construct a\nmonolingual keyword index for the reference collection, extract, and machine-\n\n2.3 Plagiarism Detection Systems\n\n33\n\ntranslate keywords from a suspicious document in another language, and query\nthe index with the translated keywords. Alternatively, a CLPD approach could\nmachine-translate the entire suspicious document prior to extracting keywords\nand querying the index. In the second case, the detection approach could also use\na fingerprint index instead of a keyword index [259, 263].\nFor the detailed analysis phase, detection procedures can apply a number of\nretrieval models from Cross-Language Information Retrieval (CLIR). Such\nmodels can either use pre-computed dictionaries [59, 266, 320], or character\nsimilarities if the languages of the reference collection and the suspicious\ndocument share sufficient syntactical similarities [224]. Dictionaries can be\ntrained by analyzing parallel [58, 257] or comparable corpora [259].\nA detailed review of CLIR models is beyond the scope of this thesis. Potthast\net al. present such a survey and compare three models they regard as promising\nfor CLPD [263]. Both McNamee &amp; Mayfield and Potthast et al., propose\napproaches to cross-language text similarity comparison that are promising for\nthe detailed analysis phase of the CLPD process [224, 259].\nAs Section 2.3 shows, some prototypical PDS [172, 239, 371] machine\ntranslate all documents in the reference collection prior to applying monolingual\nPD approaches. However, this approach is only feasible for smaller local\ncollections [261].\nCurrently, CLPD attracts less attention than monolingual PD and most\nresearch focuses on the similarity assessment in the detailed analysis stage [263].\nWe found no PDS that implements the complete CLPD process. Potthast et al.\nview CLPD research as being “[...] still in its infancy” ([263], p. 15).\n\n2.3 Plagiarism Detection Systems\nThe plagiarism detection software business is large, fast-paced and growing.\nCompanies offer an increasing variety of plagiarism detection systems, but many\ncease to exist after a short life cycle [18, 356]. Available systems perform\nexternal PD. We found no PDS in practical use that performed intrinsic PD. PDS\neither compare documents within a user-defined corpus or check texts against an\n\n34\n\n2 Plagiarism Detection\n\nexternal collection, which usually includes some subset of the Internet. Appendix\nJ contains an overview of widely used systems.\n\n2.3.1 Evaluations of PDS\nComparing the detection performance of PDS is challenging. Authors proposing\nPDS prototypes often use non-standardized evaluation methods. In a review of\n139 publications on PD, Potthast et al. found that 80 % of the papers used\nindividual corpora for evaluation and less than 50 % offered comparisons to\nprior research [262].\nWe found two projects that address this lack of comparability. Both\nbenchmark PDS using standardized collections. The first project is the annual\nPAN International Competition on Plagiarism Detection (PAN-PC), initiated in\n2009 [260]. PAN is an acronym for &quot;Plagiarism Analysis, Authorship\nIdentification, and Near-Duplicate Detection&quot;. Competitors in the PAN-PC\nprimarily present research prototypes. The second project is a comparison of\ncommercial and otherwise publicly available PDS, which a research group at the\nHTW University of Applied Sciences in Berlin performs periodically [356]. We\nwill refer to this test series as the HTW PDS Tests. We will present results from\nthe PAN-PC in 2011 to point out the capabilities of state-of-the-art PDS\nprototypes and subsequently discuss the findings from the latest HTW Test for\nexternal PDS to highlight the strengths and weaknesses of PDS available to the\npublic.\n\n2.3.1.1\n\nResearch Prototypes\n\nThe PAN-PC offers tasks for external and intrinsic plagiarism detection. The\nevaluation corpus of PAN-PC’11 contained 26,939 documents, of which 50 %\nwere suspicious texts, and the remainder formed the reference collection.\nSuspicious documents contained 61,064 artificially plagiarized sections, of\nwhich 82 % were obfuscated by applying the following techniques:\n-\n\nUsing automated or manual English translations of German\nand Spanish text sections;\n\n2.3 Plagiarism Detection Systems\n\n35\n\n-\n\nPerforming random shuffles, insertions, deletions or\nsemantic substitutions of terms;\n\n-\n\nAsking humans to paraphrase sections [264].\n\nno obfuscation\n\nautomatic\ntranslation\n\n0.83\n0.15\n0.13\n0.05\n0.04\n0.01\n\n0.37\n0.12\n0.00\n0.15\n0.03\nn/a\n\n0.00\n\n0.17\n\n0.32\n0.28\n\n0.49\n0.50\n0.47\n\n0.36\n\n0.61\n\n0.80\n\n0.92\n\n0.97\n0.85\n0.91\n0.81\n0.81\n0.95\n\n1.0\n0.9\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0.0\n\n0.28\n\nPlagdet Score\n\nFigure 5 illustrates the results of the PAN-PC’11. The figure shows the\nplagiarism detection (plagdet) scores of the five best performing external PDS\ngrouped by the obfuscation technique applied to the plagiarized text segments.\n\nparaphrasing by\nmanual\nhumans\ntranslation\nObfuscation Technique\n\nautomatic\nparaphrasing\n(multiple)\n\nGrman &amp; Ravas (0.56)\n\nGrozea &amp; Popescu (0.42)\n\nOberreuter et al. (0.35)\n\nCooke et al. (0.25)\n\nTorrejón and Ramos (0.23)\n\nBest PDS in PAN&#x27;10\n\nFigure 5: Plagdet Scores for External PDS in PAN-PC’11\nSource: [264]\n\nThe plagdet score considers the F-measure, which is the equally weighted\nharmonic mean of precision (P) and recall (R), and combines this mean with the\ngranularity (gran) of the detection algorithm. Precision denominates what\npercentage of all instances reported as suspicious by an algorithm are actually\nplagiarism. Recall denotes what percentage of all plagiarized instances in the\ncollection a detection algorithm reports. The granularity reflects whether the\ndetection algorithms identified the plagiarized instance as a whole or in multiple\nparts. The interval of the score is [0,1]. For the computation of the score, refer to\n[261].\n\n36\n\n2 Plagiarism Detection\n\nFor each of the five obfuscation techniques in Figure 5, the rightmost bars\nwith a dashed fill show the plagdet score of the best performing system in the\ncompetition of the previous year: PAN-PC’10. However, these rightmost bars\nmeant for comparison are only a rough indicator of the advancement of detection\nperformance, because the evaluation corpus of PAN-PC’11 included more\nobfuscated segments than the corpus of PAN-PC’10. Moreover, the corpus of\nPAN-PC’11 included manual translations, whereas the corpora of all previous\ncompetitions included only automatic translations. Each legend entry states in\nbrackets the overall plagdet score, which is the mean of the scores in the\nindividual groups.\nGiven the results, we conclude that state-of-the-art PDS can detect copies of\ntext segments with high accuracy. Detection rates for segments plagiarized by\nhumans are substantially lower than for non-obfuscated segments. For example,\nthe system of Grman &amp; Ravas [140], which overall performed best in PANPC’11, achieved a recall of ܴ = 0.33 for manually paraphrased segments [264].\nIn other words, the best performing system failed to identify two-thirds of the\nmanually paraphrased plagiarism instances. There is a notable decrease in the\ndetection performance for automatically obfuscated passages in PAN-PC’11\ncompared to the earlier PAN-PC’10. We attribute this decline to the increased\namount of obfuscated test cases that organizers added to the evaluation corpus of\nPAN-PC’11.\nThe seemingly good detection performance for automatically translated text\nsegments is misleading. The systems that performed well used automated\nservices for translating foreign language documents in the reference collection\ninto English. The employed services, such as Google Translate, are similar or\nidentical to the ones used to construct the translated, plagiarized sections in the\nfirst place [263, 264]. The detection rate for manually translated plagiarism is\nsubstantially lower. For instance, the best performing system of Grman &amp; Ravas\nachieved a recall ܴ = 0.26 for manually translated segments [264]. We\nhypothesize that the translation undertaken by real authors when obfuscating\ntheir plagiarism is more complex and versatile, and hence harder to detect by the\ntested systems.\n\n2.3 Plagiarism Detection Systems\n\n37\n\nPlagdet Score\n\nFigure 6 displays the plagdet scores of the four systems participating in the\nintrinsic detection track of PAN-PC’11. All systems performed significantly\nworse than those in the external track.\n1.0\n0.8\n0.6\n0.4\n0.2\n0.0\n\n0.32\n\n0.17\n\n0.07\n\n0.07\n\n0.18\n\nIntrinsic Plagiarism Detection Systems\nOberreuter et al. (0.33)\nAkiva (0.08)\nBest PDS in PAN&#x27;10\n\nKestemont et al. (0.17)\nRao et al. (0.07)\n\nFigure 6: Plagdet Scores for Intrinsic PDS in PAN-PC’11\nSource: [264]\n\nThe organizers attribute the good relative performance of the system\npresented by Oberreuter et al. to exploiting the artificial way of creating most\nplagiarized sections in the evaluation corpus. Artificial plagiarism in the\nevaluation corpus was created by copying text from source documents regardless\nof topical relatedness. This benefits the system of Oberreuter et al., which\nevaluates the uniqueness of words relative to the rest of the analyzed documents\n[246]. This approach is most likely not reproducible in realistic settings [264].\nThe performance of the remaining systems is in line with earlier PAN\ncompetitions. For comparison, a naïve baseline approach of classifying all\nsegments as plagiarized achieved a recall ܴ = 0.46, precision ܲ = 0.23 and\nplagdet score of 0.24 in 2009 [260].\nIntrinsic PD requires longer texts to work reliably. Stein et al. analyzed a\nsubset of the PAN-PC’09 evaluation corpus. They excluded documents under\n35,000 words from their evaluation for not being reliably analyzable. Stein et al.\nreport precision values ranging from 0.72 െ 0.98 with corresponding recall\nvalues ranging from 0.30 െ 0.60 depending on the used sub-collection [319].\n\n38\n\n2.3.1.2\n\n2 Plagiarism Detection\n\nSystems Available to the Public\n\nThe latest HTW PDS Test for external detection systems in 2010 evaluated 26\npublicly available systems using 40 manually fabricated essays – of which 30\nwere written in German and 10 in English. Most documents contained\ncopy &amp; paste or shake &amp; paste plagiarism in longer sections of the text. The\nsources of plagiarism are available on the Internet, except for one document,\nwhich originated from a DVD encyclopedia. Five plagiarism cases were\nmanually or machine translated from English to German and one from French to\nEnglish [356]. If authors disguised plagiarism, they employed moderate text\nalterations. According to the observations of the evaluators, the obfuscation\nresembles the common plagiarism behavior of students [357]. We view the\nresulting obfuscation to be comparably weaker than the manually rewritten\nsegments contained in the PAN-PC’11.\nThe organizers use a three-class scale to benchmark the reliability of tested\nPDS. The exact scoring criteria depended on the individual test documents. For\ninstance, the organizers judged whether a PDS could identify all sources of a\nplagiarism (3 points), nearly all sources (2 points), some sources (1 point) or no\nsources (0 points) [357].\nFigure 7 displays the number of test cases discovered by the top five systems\nin the HTW PDS Test 2010. Most undetected cases resulted from the six\ntranslations in the corpus. Due to the light obfuscation, the systems identified\nmost other plagiarism cases more or less completely.\n\n2.3 Plagiarism Detection Systems\n\n39\n\nNumber of Test Cases\n\n40\n35\n\n10\n\n30\n\n1\n\n25\n\n11\n\n12\n3\n2\n\n20\n\n8\n\n10\n\n10\n\n6\n\n3\n\n5\n\n9\n\n10\n\n6\n\n17\n\n17\n\n19\n\n15\n10\n\n18\n\n23\n\nmiss (0 pts.)\npartial\ndiscovery (1 pt.)\nnearly complete\ndiscovery (2 pts.)\ncomplete\ndiscovery (3 pts.)\n\n5\n0\nPlagiarisma Urkund\n\nTurnitin\n\nEphorus Plagaware\n\nTested PDS\nFigure 7: Performance of the Top Five Publicly Available PDS\nSource: [356]\n\n2.3.2 Technical Weaknesses of PDS\nTechnical weaknesses can significantly decrease the detection accuracy of PDS.\nThe term technical disguise subsumes techniques to obfuscate plagiarism by\nexploiting technical weaknesses of PDS. Technical disguise solely affects the\nmachine internal representation of text, which the PDS processes, while keeping\nthe text unaltered to the human eye.\nOne example of technical disguise is inserting characters with font color\nidentical to the background into plagiarized text. This renders the text as\nnonsense to the PDS. A similar disguise for plagiarized text is replacing letters\nfrom the original alphabet with letters from foreign alphabets that feature\nvisually identical glyphs [248].\nHeather demonstrated three methods of technical disguise that are especially\nsuitable for altering documents in PDF format [151]. The first two methods both\nalter the mapping between visible glyphs to machine-processable characters.\nPDF files store text as a sequence of numerical character identifiers (CIDs).\nSpecial mappings in the PDF link CIDs to both the visible glyphs, i.e. the\ncharacter shapes, as well as their machine-processable character codes. The first\nmethod Heather describes alters a PDF’s mapping between CIDs and\n\n40\n\n2 Plagiarism Detection\n\nmachine-processable character codes and the second method alters the mapping\nbetween glyphs and CIDs. For example, using either method, a plagiarist can\nchange the mapping so that the glyph representing the letter ‘e’ points to the\ncharacter code for the letter ‘x’. As a result, text will appear normal to the reader,\nbut is uninterpretable by the PDS. The third method converts the plagiarized text\ninto a graphic. To avoid triggering a warning by the PDS for containing no\nanalyzable text, the plagiarist can include genuine but unrelated text. The phony\ntext can then be hidden by formatting it in a background color, or by placing it\nbehind the graphic, or beyond the physical boundaries of the page.\n\n2.4 Conclusion\nIn reviewing the research on plagiarism among students, we showed that the\nissue has been generating concern for decades. Compared to plagiarism among\nstudents, plagiarism among post-graduate scholars received less research\nattention. However, sporadic studies showed that post-graduate scholars do\nengage in plagiarism. Evidence from various cases of plagiarism also suggested\nthat plagiarists in the sciences tend to disguise their misconduct more\nsophisticatedly and therefore are caught less often. In recent years, an increasing\nnumber of journals and conferences have begun to employ plagiarism detection\nsystems to check submitted manuscripts routinely.\nOur review of detection approaches and their performance shows that PD\napproaches face an inevitable tradeoff between detection accuracy and\ncomputational effort. Table 8 summarizes the capabilities of current PD\napproaches in detecting the different forms of plagiarism.\n\n2.4 Conclusion\n\n41\n\nTable 8: Capabilities of Current Plagiarism Detection Approaches\n\nCharacter-based (Char.)\n\nX\n\nDetection rate:\n\n[19, 137, 175, 232]\n[285, 370]\n[57, 142, 245, 293, 307]\n[24, 238, 252, 328, 333]\n[22, 190, 252, 333]\n\nX\n\nX\n\n[172, 239, 263, 371]\n\nX X\n\nGood\n\nReferences\n\nX\n\nExact String Matching\nApproximate String Matching\nFingerprinting\nVector Space Models\nSemantic Enhancements\n\nCross-language (CLPD)\nStylometry (Style)\n\nIdea\n\nTranslated\n\nUndue Paraphrase\n\nShake &amp; Paste\n\nCopies\n\nCross-lingual PD\n\nMono-lingual PD\n\nIntrinsic PD\n\nExtrinsic PD\n\nDetection Approach\n\nNear copies\n\nForm of\nplagiarism\n\nApplication\n\n[97, 238, 319, 322]\n\nFair\n\nPoor\n\nUnfit\n\nWe showed that all external monolingual PD approaches rely on\ncharacter-based similarity between documents. Therefore, the detection accuracy\nof these methods decreases with increasing disguise of plagiarism.\nString-matching methods exhibit the strongest dependence on character-based\nsimilarity. By applying suitable term selection, fingerprinting or vector space\nmodel approaches are more stable against character alterations, but incur\ninformation loss and fail when character-based similarity falls below a certain\nlevel. The lack of textual overlap also makes translations and idea plagiarisms\nimpossible to detect for character-based methods.\nExternal, cross-language plagiarism detection is not mature or reliable at the\ntime of writing [263]. Machine translating all documents in the reference\ncollection not written in the target language, an approach applied by some\nprototypes in the PAN-PC is not scalable in practice [261].\nThe results of the PAN competitions, the HTW PDS Test and other studies\n[157, 170, 218, 282] prove that state-of-the-art PDS, which implement external\n\n42\n\n2 Plagiarism Detection\n\ndetection methods, find incidences of verbatim and slightly modified copying\nwith high accuracy, given the sources are accessible to the PDS. D. Weber-Wulff\nsummarizes the current state of PDS as follows:\n“[...] PDS find copies, not plagiarism.” ([357], p. 6)\n“[...] for translations or heavily edited material, the systems are\npowerless [...]” [360]\nAside from text alterations, technical disguise can fool existing PDS. The\nmajor systems seem to have implemented no countermeasures yet, but we expect\nthat integrating additional checks to reveal technical disguise will present a\nminor challenge to future PDS.\nMany researchers recognize the need to incorporate semantic information\ninto similarity checks to allow detecting disguised plagiarism [22, 190, 252,\n333]. In the experiments of Bao et al., considering synonyms increased detection\nperformance by factor two to three. However, the processing time increased by\nfactor 27 [22]. We regard current character-based PD approaches that include\nsemantic analysis as computationally too expensive for most practical PD tasks.\nIntrinsic plagiarism detection using stylometry is another approach that can\novercome the boundaries of character-based similarity by comparing linguistic\nsimilarity. Given that the stylistic differences between plagiarized and original\ntext are significant, and not due to legitimate multiple authorship, stylometry is a\ncapable aid in identifying disguised plagiarism. When a plagiarist paraphrases\ntext to the point where it resembles the expressions of the plagiarist, stylometry\nfails. The results of PAN-PC 2010, PAN-PC 2011, and the experiments by Stein\net al. [319] indicate that stylometry only works reliably for document lengths of\nat least several thousand words. This restricts the applicability of this method for\nPD. We found no PDS in practical use that performed intrinsic PD.\nIn conclusion, the research on academic plagiarism detection has led to the\ndevelopment of PDS capable of detecting literal plagiarism, for example\ncopy &amp; paste or shake &amp; paste type plagiarism. However, PDS remain unable to\nreliably detect strongly disguised plagiarism forms, such as paraphrases,\ntranslated plagiarism and idea plagiarism.\n\n3 Citation-based Document Similarity\nThis chapter describes related work on citation-based similarity measures and\nrelevant terminology. While Citation-based Plagiarism Detection (CbPD) makes\nuse of citations for similarity computation, the related work section is relatively\nshort for the following reasons:\n-\n\nTo date, citation analysis has been used mainly to identify\nsemantically related documents and not for plagiarism detection\npurposes. Therefore, no directly related prior work is available.\n\n-\n\nTo date, almost all citation-based similarity measures analyze\ncitation relationships on the document level. This global citation\nanalysis is insufficient for the purpose of plagiarism detection,\nwhich requires analyzing intra-document citation relationships,\nincluding the order and proximity of citations to pinpoint local\nsimilarities.\n\n-\n\nCo-citation Proximity Analysis (CPA), an approach proposed by\nthe author of this thesis, presents the first citation-based similarity\nmeasure that considers the relative position of citations within a\ndocument’s full-text to improve the accuracy of Co-citation\nanalysis (see the patent application in E and [126]).\n\nThis chapter is structured as follows. Section 3.1 reviews terminology\nrelevant to citation-based document similarity measures. Section 3.2 introduces\ncitation-based document similarity measures relevant for the development of the\nCbPD approach. As a supplement to Section 3.2, Appendix I gives a summary of\nstudies evaluating the performance of existing citation-based document\nsimilarity measures. This chapter concludes by placing the different similarity\nmeasures in context and explaining their role for the development of the CbPD\nconcept.\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_3, © Springer Fachmedien Wiesbaden 2014\n\n44\n\n3 Citation-based Document Similarity\n\n3.1 Terminology\nThis section introduces relevant terminology for citation-based similarity\ncomputation and places the terms in context of the pursued research.\n\n3.1.1 Citation vs. Reference\nThe terms citation and reference are often used inconsistently, although they\nhave distinct meanings in library and information science as discussed in ([187],\npp. 42-45). Technically speaking, a reference in a document A is a bibliographic\nnote that describes a document B. If document A contains a reference to\ndocument B, then B receives a citation from A ([96], p. 204).\nHowever, authors commonly use the term citation ambiguously to express\n“receiving a citation”, e.g., [168, 187], to express “giving a citation”, e.g., [199,\n330], or to refer to an “in-text citation”, i.e. to refer to the position at which a\nsource is cited in the text, e.g., [99, 106]. An in-text-citation is a short text string\nin the body of academic texts that serves as a marker and points to an entry\n(reference) in the bibliography [155]. Overcoming the ambiguity of the term\ncitation is difficult, because no widely accepted terminology exists to distinguish\nclearly between the different notions of “citation”. As Larsen points out, a clear\nterminological distinction would require coining new terms ([187], p. 43).\nWe abstain from introducing new terms, to avoid confusion for domain\nexperts. Instead, we use the term reference to refer to entries in the bibliography\nand the term citation either to refer to in-text markers, which point to references,\nor to denote the number of times a document is referenced by other documents.\nWe clarify the desired notion by giving appropriate context. If a distinction\nbetween citation and reference is unnecessary, we use the more common\nexpression, citation. For instance, we refer to similarity approaches that use\ncitations, references, or a combination thereof as citation analysis or citationbased approaches. We use the verbs citing and referencing synonymously to\nindicate that a document refers to another work. Similarly, we use being cited\nand being referenced interchangeably to describe works that were credited by\nanother work.\n\n3.1 Terminology\n\n45\n\nFigure 8 illustrates this terminology. There is a 1: 1 relationship between a\ndocument and each of its references and a 1: ݊ relationship between a single\nreference and corresponding in-text citations.\nDoc. B\n\nDoc. B receives citations\nfrom Doc. A and Doc. E\nDoc. A\ncites / references\nDoc. B\n\nDoc. E\n\nDoc. B\nis cited / is referenced\nby Doc. A\n\nDoc. A\n[1]\n[2]\n[3]\n\nin-text citations\n\n[1]\nBibliography\n[1] Doc. B\n[2] Doc. C\n\nreferences\n\n[3] Doc. D\n\nFigure 8: Citations and References in Scientific Documents\n\n3.1.2 Similarity vs. Relatedness\nThe terms similarity and relatedness are used interchangeably in current\nliterature. However, in certain situations, the connotation of these terms can be\nquite different. Similarity in lexical and structural characteristics can point to\npotential plagiarism. This is why text similarity can have a negative connotation\nin the academic community. Text relatedness has no such negative connotation,\nimplying only a content-based, semantic similarity between documents. We find\nthis connotation of the terms significant, although by no means universal. Each\nindividual having his or her own definition of these generically used terms\nfurther challenges a clear definition. For these reasons, we will not dissect the\nnuanced meanings of similarity and relatedness, but rather regard the terms as\nequivalent and use only &quot;similarity&quot;.\n\n3.1.3 Dimensions of Similarity: Lexical, Semantic, Structural\nSimilarities between texts can take on several forms. The majority of current\npublications on information recommendation and retrieval systems simply use\nthe term document similarity without giving much attention to the types of\nsimilarity. For example, many authors use the terms lexical and structural, or\n\n46\n\n3 Citation-based Document Similarity\n\nsubject and topical similarity interchangeably. The distinctions between\nsimilarity forms, however, are of importance for this work.\nFor the purpose of this work, we distinguish between three distinct similarity\ndimensions for documents: lexical, semantic, and structural. These dimensions\nof similarity may occur individually, or in combination.\nLexical similarity measures the degree to which a set of words in two\ndocuments or document sections, e.g., sentences or paragraphs, is similar. For\nexample, if the lexical similarity of two sentences is 1, they exhibit a 100 %\noverlap in their vocabularies and word order.\nSemantic similarity measures the similarity of two or more texts based on their\nconceptual meaning. For example, the statements “the earth is round” and “the\nworld is a globe” are not lexically similar, because they share no words aside\nfrom “the” and “is”. Yet, the statements are semantically similar, because their\nmeaning is synonymous.\nDistinguishing lexical from semantic text similarities is a common problem\nin information retrieval. Tsatsaronis quantified lexical text similarities by using a\nVSM (see Section 2.2.4 on page 26) and similarity measures including Cosine,\nJaccard, Dice and TF-IDF [334]. These approaches solely compare the textual\nrepresentation of words and not their semantic content. Resnik [276], O’Shea\n[247], and Charles [231] discussed different dimensions of semantic similarity.\nWe define two papers as semantically similar if they address the same or a\nsimilar research objective.\nStructural similarity11 in texts is a term we use to describe similarities in the\ncomposition of two or more documents. Structural similarities in text can take on\nvarious forms as discussed in the following chapters. An example of document\nstructural similarity is the occurrence of shared citations in similar order in two\ndocuments.\n11\n\nThe term is unrelated to the structural similarity (SSIM) index; a concept for\nmeasuring similarity between two images, see\nhttp://en.wikipedia.org/wiki/Structural_similarity.\n\n3.2 Citation-based Similarity Measures\n\n47\n\n3.2 Citation-based Similarity Measures\nThis section presents link- and citation-based similarity measures. These\nmeasures are independent of the lexical, syntactical and style characteristics of a\ntext. So far, citation-based measures have not been used for the purpose of\nplagiarism detection. Therefore, no related work using citations for plagiarism\ndetection exists. This section presents citation-based measures that were\nintroduced for general document similarity computation purposes.\nOf the citation-based measures, Bibliographic Coupling, Co-citation, and\nCo-citation Proximity analysis are the measures with most direct relevance to the\nCbPD approach. Although these measures were not developed with the aim to\ndetect plagiarism, reviewing them contributes to the understanding of the CbPD\napproach proposed in this thesis. A summary of studies examining the\napplicability of the citation-based similarity measures introduced in this section\nfor different retrieval tasks is provided in Appendix I.\n\n3.2.1 Direct Citation\nDirect citation is the most intuitive approach to measure citation-based\nsimilarity. Direct citation, also known as intercitation, considers two documents\nsimilar if one cites the other. Each citation relationship is bidirectional as\nillustrated in Figure 9.\n\nDoc A\n\ncites\nis cited-by\n\nDoc B\n\nFigure 9: Doc A cites Doc B, while Doc B is cited-by Doc A.\n\nFigure 10 visualizes the direct citations in a citation graph [17]. The node on\nthe left is a paper from 1986. Nodes to the right represent more recent papers that\neither directly cited the 1986 paper, or that cited the 1986 paper indirectly by\nciting a paper which cited the 1986 paper further down the line. In this way,\n\n48\n\n3 Citation-based Document Similarity\n\ncitation graphs can visualize valuable information about the popularity of\npublications.\n\nFigure 10: Visualization of a Citation Graph\nSource: [17]\n\nSearch engines for scientific documents typically use the cited-by\nrelationship to identify topically related documents or to rank search results.\nTopically related documents that are more recent can be identified by browsing\ncited-by relations, since cited documents are generally published earlier than the\ndocuments that cite it. High cited-by scores indicate higher popularity and\nrelevance of a document [26]. Traversing cite relationships is useful for verifying\ninformation by checking the cited source or to identify further reading.\n\n3.2.2 Bibliographic Coupling\nIn 1956, Fano suggested the grouping of academic papers using citation relations\nrather than on content [108]. Kessler coined this concept Bibliographic Coupling\nand argued for its usefulness as a measure for subject similarity. Documents are\nbibliographically coupled if they both cite at least one identical reference. The\ncoupling strength represents the number of shared references. In Figure 11, the\ncoupling strength of documents A and B equals 2, since both cite documents C\nand D.\n\n3.2 Citation-based Similarity Measures\n\n49\n\ncoupling\nstrength = 2\n\nDoc. A\n\nDoc. B\n\nReferences\n[1] Doc. G\n\n[2] Doc. D\n\n[2] Doc. C\n\n[3] Doc. F\n\n[3] Doc. D\n\nTime\n\nReferences\n[1] Doc. C\n\nDoc. C\n\nDoc. F\n\nDoc. D\n\nDoc. G\n\nFigure 11: Bibliographic Coupling between Documents\n\nBibliographic Coupling strength (BCS) can be expressed as the Jaccard Index\nof the references in two documents, as shown by Equation 3.1:\n‫݀(ܵܥܤ‬ଵ , ݀ଶ ) =\n\nหோ೏భ ‫ ת‬ோ೏మ ห\nหோ೏భ ‫ ׫‬ோ೏మ ห\n\n(3.1)\n\nIn this notation, d denotes a document and R ୢ the set of documents, which\nare cited by d, i.e., the references of d. The more references two documents\ndଵ and dଶ have in common, the more they are related. If the sets R ୢభ and R ୢమ are\nempty, the coupling strength is zero.\nBibliographic Coupling expresses a relationship between documents based on\nearlier documents as established by the authors when choosing their references.\nThis relationship is static and intrinsic to the coupled documents, since it solely\ndepends on the references in the respective works and does not change over time\n[304].\nSeveral researchers questioned the usefulness of Bibliographic Coupling as a\nsimilarity measure. Martyn criticized that Bibliographic Coupling cannot\n\n50\n\n3 Citation-based Document Similarity\n\nguarantee that two authors refer to the same piece of information when citing a\nwork [216]. He concluded that Bibliographic Coupling is merely an indication of\nthere being a probability, with unknown value, of the existence of a relationship\nbetween two documents. Evaluations by Vladutz &amp; Cook support Martyn’s\nconclusion by showing that 15 to 19 % of the bibliographically coupled\ndocuments they analyzed showed no subject similarity [346].\nFurther criticism of Bibliographic Coupling includes that absolute coupling\nstrength cannot guarantee a unit of similarity that is comparable across different\ndocument pairs. Kessler and Weinberg demonstrated that review articles tend to\nhave higher coupling strengths because such articles generally contain more\nreferences [174, 363]. Considering relative Bibliographic Coupling, i.e. the\nfraction of shared and non-shared references in a document, can provide some\nremedy to this problem, but does not eliminate it. Small as well as\nMarshakova-Shaikevich criticized the static nature of Bibliographic Coupling for\nbeing suboptimal in reflecting changes in the perception of concepts and ideas\nexpressed in the respective articles [213, 301]. This can be detrimental to\nmapping emerging trends and the evolution of a research field.\n\n3.2.3 Co-citation\nIn an effort to address the static nature of Bibliographic Coupling, both Small\nand Marshakova-Shaikevich independently published the Co-citation concept in\n1973 [213, 301].\nTwo documents are co-cited if they are jointly cited by at least one later\nwork. The number of documents that jointly cite the two earlier documents\ndetermines the strength of the co-citation relationship and the cardinality of the\nco-citation score. Figure 12 demonstrates Co-citation for the document pair A\nand B Documents A and B are jointly cited by documents C and D, and hence\nhave a co-citation strength of 2.\n\n3.2 Citation-based Similarity Measures\n\n51\n\nDoc. C\nReferences\n[1] Doc. A\n[2] Doc. B\nDoc. D\nTime\n\nReferences\n[1] Doc. A\n[2] Doc. B\nDoc A\n\nDoc B\n\nco-citation strength = 2\nFigure 12: Co-citation Relationship between Documents\n\nAlternatively, co-citation strength (CCS) can be expressed as a fraction, as\nshown in Equation 3.2:\n‫݀(ܵܥܥ‬ଵ , ݀ଶ ) =\n\nห஼೏భ ‫ ת‬஼೏మ ห\nห஼೏భ ‫ ׫‬஼೏మ ห\n\n(3.2)\n\nIn this notation, ‫ܥ‬ௗ౟ stands for the set of “citing” documents, i.e. the pool of\nother documents that cite document ݀௜ . The number of citing documents that\ntwo cited documents ݀ଵ and ݀ଶ have in common determines their subject\nsimilarity.\nA co-citation relationship between two documents is extrinsic to the\ndocuments in question because the co-citation relationship is established using\n“incoming” links. Co-citation strength depends on the frequency with which\nother texts – that is subsequently published works – cite earlier publications. For\nthis reason, co-citation has a tendency to fail for very recent publications. In\ncontrast, Bibliographic Coupling measures the static “outgoing” links shared by\n\n52\n\n3 Citation-based Document Similarity\n\ntwo documents. While the bibliographic coupling strength between two\ndocuments can be established immediately after the documents are published and\nthe strength does not change over time, co-citation reflects changes in the\nrelationship between documents over time depending on how frequently the\nauthors of subsequent papers co-cite the earlier papers [301, 304].\nBibliographic Coupling and Co-citation have received considerable attention\nin research and were rapidly adapted for numerous purposes, including literature\nretrieval [103], research front analysis [270], and mapping science, which\nincludes measuring the impact of scientists, and diverse performance evaluations\nof articles, journals, and research concepts [117, 119, 136, 294, 304].\n\n3.2.4 Amsler\nIn 1972, Amsler fused the concepts of Bibliographic Coupling and Co-citation to\ntake advantage of their individual strengths12 [13]. The measure is normalized by\nthe total number of citations. By definition, relatedness is defined as zero if\nneither ݀ଵ nor ݀ଶ have parents or children. The more citations either the parents\nor children share, the more related they are. Equation 3.3 defines the Amsler\nmeasure:\n‫݀( ݎ݈݁ݏ݉ܣ‬ଵ , ݀ଶ ) =\n\nห(஼೏భ ‫ ׫‬ோ೏భ ) ‫( ת‬஼೏మ ‫ ׫‬ோ೏మ )ห\nห(஼೏భ ‫ ׫‬ோ೏భ ) ‫( ׫‬஼೏మ ‫ ׫‬ோ೏మ )ห\n\n(3.3)\n\nA similar approach proposed in 2010 is Inter-Connection [368]. It also uses\nboth incoming and outgoing citations (links) by transforming them into\nundirected links.\n\n3.2.5 Co-citation Proximity-based Methods\nCo-citation Proximity Analysis (CPA) was proposed in 2006 by the author of this\nthesis [122, 126]. This similarity measure builds on the co-citation analysis\n12\n\nThe definition is based on a paper of Couto [79], because the original technical\nreport of Amsler is neither available in common literature databases, nor\navailable from the department where it was published. We contacted other\nauthors who cited the report, but found that they had not seen the original\npublication either and instead relied on descriptions from other papers.\n\n3.2 Citation-based Similarity Measures\n\n53\n\napproach, but differs in that it exploits the information implied in the placement\nof citations within the full-texts of documents. CPA rests on the assumption that\ndocuments cited in close proximity to each other within a document’s full-text\nalso tend to be more closely related than documents cited farther apart.\nCiting Document\nThis is an example text with references to different documents.\nThis is one reference. This is an example text with references to\ndifferent documents. Two very similar references [1],[2]. This is an\nexample text with references to different documents.This is an\nexample text with references to different documents.Another\nexample. Another example.\nThis is an example text with references to different documents.\nAnother example. This is an example text with references to\ndifferent documents.\nThis is an example text with references to different documents.\nAnother example. This is an example text with references to\ndifferent documents. Another example. This is an example text\nwith references to different documents.Another example. Another\nexample. Another example. This is an example text with\nreferences to different documents.Another example.\nAnother example. This is an example text with references to\ndifferent documents.This is an example text with references to\ndifferent documents. Another example. This is an example text\nwith references to different documents.Another example. Another\nexample. This is an example text with references to different\ndocuments [3]. Another exampleThis is an example text with\nreferences to different documents.\nAnother example. This is an example text with references to\ndifferent documents.Another example. This is another reference.\nAnother example. This is an example text with references to\ndifferent documents.Another example. This is an example text\nwith references to different documents. Example. This is an\nexample text with references to different documents.\n\nDoc B\n\nDoc A\nrelated\n\nDoc C\nstrongly\nrelated\n\nFigure 13: Co-citation Proximity Analysis\n\nFigure 13 illustrates the concept. CPA rates documents B and C as more\nstrongly related than documents B and A, because the citations to B and C are\nwithin the same sentence, while the citations to B and A are separated by several\nparagraphs.\nThe advantage of the CPA measure, compared to Co-Citation, is an\nimprovement in precision [55, 106, 126, 198, 199, 351]. Other widely used\ncitation analysis approaches – Bibliographic Coupling, Co-citation or the Amsler\nmeasure – do not take into account the location or proximity of citations within\ndocuments. The CPA measure allows a more granular automatic classification of\ndocuments and can be used to identify not only related documents, but also the\nspecific sections within texts that are most related.\nThe CPA similarity measure calculates a Citation Proximity Index (CPI) for\neach set of documents cited by an examined document. Cited documents are\nassigned a weight of\n\nଵ\nଶ೙\n\n, where n stands for the number of structural components\n\n54\n\n3 Citation-based Document Similarity\n\nseparating the citations. Structural components can be measured in various\nincrements, depending on the &quot;resolution&quot; of document similarity to be\nexamined, for example, local versus global similarity. We define the smallest\nstructural components for CPI calculation as citation groups, then sentences,\nfollowed by paragraphs and chapters, and at the highest level the entire\ndocument or even all volumes of a journal.\nThere are several variations of the CPA algorithm:\n-\n\nBasic-CPA – the basic form described above\n\n-\n\nExtended-CPA – considers the tree structure and citation\narrangement within citation groups\n\n-\n\nMultidimensional-CPA – uses additional information, including\nthe impact (e.g., measured by citation counts)\n\n-\n\nHybrid-CPA – combines the CPI with other similarity measures,\ne.g., character-based measures. This boosts performance especially\nfor documents with insufficient citation information.\n\n3.3 Conclusion\nVarious citation-based measures for document similarity computation exist.\nCurrently, these measures are used to identify related literature, for example, in\nrecommender systems for academic literature. No citation-based similarity\nmeasure has so far been used for the purpose of plagiarism detection.\nNonetheless, the citation-based approaches presented in this chapter are relevant\nfor the following reasons:\nBibliographic Coupling – In addition to identifying topically similar papers,\nBibliographic Coupling is suitable to be expanded to additionally reflect\nstructural document similarity. We consider this similarity measure suitable as a\nbaseline approach, see Section 4.2.1, to represent a very simple citation-based\n\n3.3 Conclusion\n\n55\n\nplagiarism detection approach, although Bibliographic Coupling was not\ndeveloped, or previously used, for this purpose.\nCo-citation – This similarity measure is only indirectly relevant for the purpose\nof plagiarism detection, since it measures relatedness between two documents on\nthe global document level from the perspective of citing authors. It is suitable to\nidentify documents that address, for example, the same research question, but is\nnot suitable to identify documents that share structural similarity. This measure\nhowever is relevant, since it provides the basis for the CPA measure.\nCo-citation Proximity Analysis (CPA) – The CPA measure is relevant for the\nunderstanding and development of the CbPD approach for two reasons:\n1.\n\nCPA was the first citation-based similarity measure that\nconsidered the position of citations and their proximity to each\nother within the full-text of a document. Given the novelty of the\napproach, the author filled a patent application (see Appendix E).\nThis citation position information allows identifying similar\ncitation patterns between documents, which provide the basis for\nthe CbPD approach proposed in this thesis (see Section 4.1).\n\n2. CPA is used by the CbPD approach to identify citation\nsubstitutions as discussed in Section 7.3.2, page 214.\n\n4 Citation-based Plagiarism Detection\nWhen the author first considered the use of citation information as a method to\ndetect plagiarism, he assumed this concept had already been explored or even\nintegrated into today’s plagiarism detection systems (PDS). After all, citations\nand references of scholarly publications have long been recognized as containing\nvaluable semantic relatedness information for documents, as demonstrated in\nSection 3.2.\nHowever, no publications or available systems considered the use of citation\ninformation for plagiarism detection purposes, despite plagiarism detection being\na well-researched field with hundreds of publications. Given that this application\nof citation information had not yet been explored, the author proposed a citation\npattern analysis approach for plagiarism detection and coined it Citation-based\nPlagiarism Detection (CbPD) [127].\nCitation-based Plagiarism Detection (CbPD) subsumes methods that\nuse citations and references to determine similarities between\ndocuments in order to identify plagiarism.\nThe underlying concept of CbPD is introduced in Section 4.1 and the citation\ncharacteristics analyzed by the CbPD algorithms are described in Section 4.2.\nChallenges to citation pattern identification and the potential transposing and\nscaling of copied citations by plagiarists is addressed in Section 4.3. Section 4.4\nintroduces an adaption of Bibliographic Coupling for plagiarism detection and\ndescribes the design of the CbPD algorithms. Section 4.5 summarizes the\nprojected applicability of each of the introduced algorithms to detect the various\nforms of academic plagiarism and Section 4.6 introduces two additional scores\nfor assessing the degree of suspicion for the citation patterns identified by the\nCbPD algorithms13.\n\n13\n\nParts of these sections have been published with Norman Meuschke [129].\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_4, © Springer Fachmedien Wiesbaden 2014\n\n58\n\n4 Citation-based Plagiarism Detection\n\n4.1 Concept\nIdeally, plagiarism detection systems should detect both lexical and semantic\nsimilarity among documents. The detection capabilities of a PDS heavily depend\non the similarity assessment performed by the PDS, which can be expressed in\nterms of a similarity function. The similarity function defines which\ncharacteristics of which textual markers are to be analyzed and how those\ncharacteristics are to be considered for computing a numeric similarity score.\nEach identifiable element of a text is a potential marker. We distinguish between\ntwo types of markers:\n-\n\nlanguage-dependent markers (e.g., character-n-grams, words, or\nother terms) and\n\n-\n\nlanguage-independent markers (e.g., citations, formulas, or dates).\n\nMarkers with defined characteristics represent a pattern. Commonly used\ncharacteristics to distinguish patterns and quantify the similarity of patterns\ninclude:\n-\n\nmarker overlap, i.e. the percentage of markers that documents\nshare in common\n\n-\n\nmarker distinctiveness, i.e. how common are markers that\ndocuments share within the entire collection\n\n-\n\nmarker order, i.e. how similar is the order of occurrence for shared\nmarkers in the text\n\n-\n\nmarker proximity, i.e. how close to each other do shared markers\noccur in the text\n\nAs discussed in Section 2.3.1, current PD approaches can only reliably\nidentify lexical similarity, i.e. character-based similarity as it is common in\ncopy &amp; paste plagiarism. The reason for this limitation is that current approaches\nconsider only language-dependent markers and a limited set of characteristics for\nsimilarity computation. For instance, vector space models (VSMs) consider the\n\n4.1 Concept\n\n59\n\noverlap and distinctiveness of document terms. These approaches also consider\nthe proximity of terms to some degree by constructing several VSMs for specific\nsections within a document. Fingerprinting methods are specialized index\nretrieval procedures, which consider the overlap, distinctiveness, and order of\nterms within patterns, yet they ignore the order of patterns.\nResearchers initially explored attempts to detect semantic similarity\n(disguised plagiarism) by extending the set of considered language-dependent\nmarkers, for example, through Latent Semantic Indexing (LSI) or by including\nthesauri in the detection procedure to identify synonym replacements. However,\nsuch approaches are currently not practically feasible for plagiarism detection\ndue to their computational complexity (refer to Section 2.3).\nBecause semantic similarity is very difficult to machine-detect, the idea\nmotivating the research presented in this thesis is to measure structural similarity\nas an approximation for semantic similarity. The overarching concept of CbPD,\nwhich the author termed Sequential Pattern Analysis, is to consider a\ncombination of language-independent and language-dependent markers, as well\nas the combination of all four similarity characteristics: overlap, distinctiveness,\norder and proximity for performing a similarity assessment.\nEmploying Sequential Pattern Analysis to detect strongly disguised academic\nplagiarism requires language-independent markers in academic texts. For this\npurpose, we regard using citations, and the citation patterns14 that result, as a\ncoherent approach for the following reasons:\n\n14\n\n-\n\nCitations are widely available in academic texts. Scientific\npublications without citations are rare, because presenting research\nwithout referring to any prior or related work is hardly possible.\n\n-\n\nCitations are language-independent and less ambiguous than\nwords. Paraphrasing or even translating allows expressing the\n\nCitation patterns are sub-sequences of the complete citation sequences, which contain\nshared citations between two documents and potentially intermediate non-shared\ncitations.\n\n60\n\n4 Citation-based Plagiarism Detection\n\nsame content in many different ways. However, the publications\nan author cites to back a given fact are often very specific. Even if\ncitations are substitutable, identifying them will require knowledge\nof existing literature.\n-\n\nCitations allow inferring semantic information. This inferable\ninformation becomes even more rich, if we take into account the\nexact placement of all citations within the full text of a document.\nHowever, even if the positions of citations within a document are\nunknown and only the bibliography is available, it is usually easy\nfor an expert to recognize the research focus of a scientific paper.\n\nDocument A\n\nDocument B\n\nDoc C\n\nSection 1\n\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection. This is a in-text citation [1]. This is\nan example text with references to different documents for illustrating the usage of\ncitation analysis for plagiarism detection. Another example for an in-text citation [2].\n\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection. This is an example text with\nreferences to different documents for illustrating the usage of citation analysis for\nplagiarism detection.\nThis is a in-text citation [1]. This is an example text with references to different\ndocuments for illustrating the usage of citation analysis for plagiarism detection. This\nis an example text with references to different documents for illustrating the usage of\n\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection.\n\ncitation analysis for plagiarism detection.\n\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection. This is an example text with\nreferences to different documents for illustrating the usage of citation analysis for\nplagiarism detection. This is an example text with references to different documents\nfor illustrating the usage of citation analysis for plagiarism detection.\n\nSection 2\nAnother in-text citation [2]. tThis is an example text with references to different\ndocuments for illustrating the usage of citation analysis for plagiarism detection. This\nis an example text with references to different documents for illustrating the usage of\ncitation analysis for plagiarism detection. This is a repeated in-text citation [1].\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection. This is an example text with\nreferences to different documents for illustrating the usage of citation analysis for\nplagiarism detection.\n\nDoc D\n\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection. This is an example text with\nreferences to different documents for illustrating the usage of citation analysis for\nplagiarism detection. Here’s a third in-text citation [3]. This is an example text with\nreferences to different documents for illustrating the usage of citation analysis for\nplagiarism detection.\n\nSetion 3\nA third in-text citation [3]. This is an example text with references to different\ndocuments for illustrating the usage of citation analysis for plagiarism detection. This\nis an example text with references to different documents for illustrating the usage of\ncitation analysis for plagiarism detection. a final in-text-citation[2].\n\nThis is an example text with references to different documents for illustrating the\nusage of citation analysis for plagiarism detection.\n\nReferences\n\nReferences\n[3]\n\nDoc A\n\n[1]\n[2]\n\nDoc E\n\n[1]\n[2]\n\n[3]\n\nCitation Pattern\nC\nD\nE\n\nDoc B\n\nC\n\nCitation Pattern\nD\nC\nE\n\nD\n\nPattern Comparison\nDoc A\n\nC\n\nD\n\nIns.\n\nE\n\nIns.\n\nDoc B\n\nC\n\nD\n\nC\n\nE\n\nD\n\nFigure 14: Depiction of CbPD Concept\n\nFigure 14 depicts the general concept of citation pattern analysis for\nplagiarism detection. Document A and document B are shown as citing the\ndocuments C, D and E. Given their shared references, documents A and B likely\n\n4.1 Concept\n\n61\n\ndiscuss semantically similar content. More interestingly, however, they cite the\nthree sources in a similar order within their full texts. Document B simply scales\nthe citations to document C and D, see dashed lines in Figure 14. When\ncomparing the citation patterns of documents A and B, i.e. their unique\nfingerprints, a citation pattern agreement of length three results, see gray\nhighlights in Figure 14. The concept of CbPD thus allows for a document\nsimilarity computation even in the absence of text-based similarity among\ndocuments.\nThe concept behind CbPD is demonstrated by means of an example in the\nfollowing thought experiment in which the reader may partake.\n\n62\n\n4 Citation-based Plagiarism Detection\n\nExperiment\nRandomly open any set of 2-5 pages from the previous pages in this\nthesis.\n-\n\nFirst, estimate the time it would take to paraphrase these pages to\nmake the text unidentifiable by current PDS.\n\n-\n\nNext, estimate the time it would take to research alternative\nworks for each citation.\n\nWe estimate that paraphrasing a single page would take a plagiarist no\nmore than an hour. However, finding alternative sources, which state\n“x was the first to propose y” or “study a contradicts study b and c”\nrequires either expert knowledge, or time invested into research. Some\nsources are impossible to substitute, since only one source can be\ncited, for example, in the case of well-known theories, a certain\npainting, experiments or mathematical proofs, and initial papers\nintroducing a new concept. Similarly, when plagiarizing content\nsummarized in tables and figures, citations cannot be substituted\nwithout losing informational value.\nIn the case of this thesis, the author assumes that at least half of all\ncitations are not substitutable without major rewriting, or without\nraising suspicion among knowledgeable readers. Certainly, it is\npossible to paraphrase scientific text and to delete all hard-tosubstitute citations, but this significantly lowers the quality, and likely\nraises suspicion among the reviewers, making it difficult to publish an\narticle at a reputable venue.\n\n4.1.1 Citing Behavior\nTo understand the suitability of using citations to identify semantic similarity\nbetween documents, one must consider the reasons why authors cite. Garfield\npioneered the field of author citing behavior, publishing the earliest paper\ndetailing possible motivations for author citation [118], and found that authors\ncite for complex reasons. Garfield’s list is extensive, but can be summarized into\nseven overarching motivations, defined by Brooks as [43]:\n\n4.1 Concept\n\n-\n\npersuasiveness – using references to convince peers of research\nvalidity\n\n-\n\npositive credit – paying homage and giving credit to previous work\n\n-\n\nnegative credit – criticizing, correcting or disputing other works\n\n-\n\ncurrency – the &quot;prestige&quot; factor that is associated with referring to\nthe most current publications in a field\n\n-\n\noperational information – references to the concepts, theories, and\ntechniques borrowed from another author\n\n-\n\nreader alert – providing readers with background information, or\npointing to new findings\n\n-\n\nsocial consensus – references chosen dependent on the author’s\nbelief of accepted norms or consensus in an academic field\n\n63\n\nWe found the research on citation motivations to confirm the assumption that\nacademic citations are carefully considered, independent markers, suitable for\ncreating a digital fingerprint. This naturally makes citations difficult to\nsubstitute. While authors choose their citations for more than a single reason, for\nexample, the scholars questioned by Brooks attributed 70.7 % of their references\nto multiple citation motives [43], Brooks nonetheless found that authors choose\neach citation with very specific goals in mind.\nThe following section explains which citation characteristics the CbPD\nalgorithms analyze to identify suspiciously similar citation patterns for creating a\ndocument’s citation-based fingerprint.\n\n64\n\n4 Citation-based Plagiarism Detection\n\n4.2 Citation Characteristics Considered\nIdentical citations in two documents do not automatically indicate plagiarism.\nThis section outlines the characteristics considered by the CbPD algorithms to\nidentify suspiciously similar citation patterns that may indicate plagiarism.\n\n4.2.1 Bibliographic Coupling Strength\nAs explained in Section 3.2.2, the Bibliographic Coupling (BC) strength, which\nis the absolute number or fraction of references that two academic documents\nhave in common, is a well-known similarity characteristic. A high BC strength\nusually indicates topical similarity in the research described. Because BC is a\ndocument-wide similarity measure, it does not allow pinpointing specific areas\nof highest similarity. Nonetheless, BC is a useful measure for CbPD, since\ndocuments sharing no references (BC strength = 0) can be excluded from a\ncitation-based similarity assessment altogether. Therefore, the CbPD algorithms\nconsider BC strength as one of several characteristics.\n\n4.2.2 Probability of Citation Co-occurrence\nThe probability that two documents share citations depends on multiple factors,\nwhich the CbPD algorithms use to quantify the degree to which matching\ncitation patterns are treated as suspicious.\nExisting citation counts influence future citation counts. If a document is\nalready highly cited, the likelihood of that document gathering additional\ncitations increases. Merton termed this phenomenon the Matthew effect15 in\nscience [227]. Current search engines for academic literature, e.g., Google\nScholar, increase the Matthew effect, because they use the number of citations a\ndocument received as the most important criterion to rank search results, as we\ndemonstrated in [26]. Documents ranked highly by search engines have a higher\nlikelihood of gaining additional citations.\n\n15\n\nThe term refers to the line in the Gospel of Matthew: “Everyone who has will be\ngiven more.” (Matthew 25:29, NIRV).\n\n4.2 Citation Characteristics Considered\n\n65\n\nImagine two documents C and D, where document C is frequently cited by\nothers, while document D is cited more rarely. Assume 500 documents cite C,\nbut only 5 documents cite D. Now, if two independent documents, A and B both\ncite C, this indicates some degree of similarity between them. However, if they\nboth cite D, this is a much stronger indicator of similarity between documents A\nand B, since D is only cited rarely. Thus, higher citation counts indicate a higher\nprobability of co-citation occurrence and this must be taken into account when\nassessing citation pattern suspiciousness.\nTime influences the likelihood of citation co-occurrence because papers tend to\nreceive more citations over time [255, 291]. Increasing citations also increase the\nprobability of documents being co-cited. We ran first experiments on adjusting\nthe CbPD algorithms to compensate this influence on the similarity score, by\ncomparing the expected citations per unit of time if texts A and B were published\nat different times.\nThe topic of research influences the likelihood of two documents sharing\ncitations. Documents addressing the same or very similar topics are more likely\nto contain citations to identical sources. We derived this assumption from\nempirical evaluations using co-citation analysis to identify clusters in academic\ndomains [139, 302].\nAuthor ties are another factor increasing the probability of co-citation. Research\nshows that a document A is more likely to be cited by a document B if the\nauthor(s) of document B is/are connected to the author(s) of document A [225].\nFor example, former co-authors, or researchers who know each other personally,\ntend to cite publications of their colleagues more frequently, a behavior called\ncronyism [225].\n\n4.2.3 Order and Proximity of Citations\nSharing identical citations in close proximity and/or similar order are intuitive\nindicators that the text segments containing the respective citations are\nsemantically similar. Therefore, proximity and similar order of citations are the\nmost important characteristics of citation patterns. Certain document sections\n\n66\n\n4 Citation-based Plagiarism Detection\n\ncommonly contain more citations than others. For example, related work\nsections contain more citations than summaries. Therefore, shared citation\npatterns in document sections other than in the related work section can be\nstronger indicators of potentially suspicious similarities.\n\n4.3 Challenges to Citation Pattern Identification\nThere are several challenges to citation pattern identification, which the\ncitation-based detection algorithms must overcome. Sections 4.3.1–4.3.4 briefly\npresent these factors: unknown pattern constituents, citation transpositions,\ncitation scaling, and insertions and substitutions of citations by the plagiarist as\nchallenges that make accurate citation pattern detection a non-trivial task.\nSection 4.4 describes how the design of the citation-based detection algorithms\naddresses these challenges.\n\n4.3.1 Unknown Pattern Constituents\nUnlike in string matching, the pattern in a CbPD analysis, i.e. the sub-sequence\nof citations in a suspicious text, which the detection algorithm must search for\nwithin the original text, is initially unknown. Individual citations shared by two\ndocuments are comparatively easy to identify. However, it is highly unlikely that\nall shared citations are attributable to plagiarism. As mentioned earlier in this\nsection, the detection algorithms must consider additional characteristics,\nincluding proximity and order of citations, to distinguish potentially suspicious\ncitation patterns from unsuspicious commonly shared citations.\nFor example, assume the documents A and B share eight citations. A\nplagiarized text segment contains three of the shared citations “[1,2,3]” and the\nremaining five shared citations are distributed throughout the document along\nwith non-shared citations and do not represent plagiarism. The citation sequences\nof the two documents might look like this:\nDoc A (Original):\nDoc B (Plagiarism):\n\n123xxx4xx5x6x78\nxx5xxx4x312xx7x8\n\n4.3 Challenges to Citation Pattern Identification\n\n67\n\nThe numbers 1–8 represent shared citations and the x represents non-shared\ncitations. Given only the above sequences, it is initially unclear which subsequences represent a potentially suspicious citation pattern. The detection\nalgorithms must consider the proximity and order of the shared citations 1–3 to\nidentify them as potentially suspicious.\n\n4.3.2 Transpositions\nThe order of citations in the unoriginal text segments may be transposed when\ncompared to the original segment. Causes of citation transpositions are different\ncitation styles, or the rearranging of longer text segments, which is typical in\nshake &amp; paste plagiarism.\nAssume the original sentence:\nStudies show that &lt;finding1&gt;, &lt;finding2&gt; [3,1,2].\nA second author may express the semantically identical content as:\nStudies show that &lt;finding1&gt;, &lt;finding2&gt; [1-3].\n\n4.3.3 Scaling\nScaling denotes the use of the same citation more than once.\nAssume the original text:\nStudy X showed &lt;finding1&gt;, &lt;finding2&gt; and &lt;finding3&gt; [1].\nStudy Y objected &lt;finding1&gt; [2]. Assessment Z proved\n&lt;finding3&gt; [3].\nA second author may paraphrase the text and scale the citation to study X:\nStudy X showed &lt;finding1&gt; [1], which was objected by study Y\n[2]. Study X also found &lt;finding2&gt; [1]. Assessment Z was able to\nprove &lt;finding3&gt; [3], which had already been indicated by study\nX [1].\nSo, in the original text this results in the citation sequence: [1],[2],[3] while in\nthe paraphrase we have the sequence: [1],[2],[1],[3],[1].\n\n68\n\n4 Citation-based Plagiarism Detection\n\n4.3.4 Insertions or Substitutions of Citations\nAuthors may paraphrase text segments and include the citations from other\ndocuments, or they may insert additional non-shared citations or substitute the\nexisting citations with semantically similar non-shared citations.\nThe resulting citation sequences of two documents may equal:\nDoc A (Original):\nDoc B (Paraphrase):\n\n12345678\n12x3xx45x6xx7x8\n\nAs in the earlier examples, numerals represent shared citations and the letter\nx denotes non-shared citations. Paraphrasing in such a manner may not constitute\nplagiarism, yet still represents a similarity between the two documents that may\nbe of interest to a reader, for example, to trace the origin and progression of\nideas.\n\n4.4 Design of Citation-based Detection Algorithms\nNo prior research has examined citation-analyzing algorithms regarding their\nsuitability to detect plagiarism. To fill this empirical knowledge gap, we\ndesigned and evaluated algorithms that focus on different factors when it comes\nto assessing citation-based similarity. We included algorithms that perform\nglobal and local similarity assessments16, as well as algorithms that consider the\norder of citations and algorithms that ignore the order.\nTable 9 displays the categories of similarity assessments, local vs. global and\norder-preserving vs. order-neglecting, according to which we designed the\ndetection algorithms. We first examined whether we could adapt similarity\nfunctions from other areas of application. Since citation sequences of documents\nare equivalent to strings, string processing lent itself to searching for potentially\nsuitable methods. A string refers to any collection of uniquely identifiable\nelements linked in such a way that each element, except for exactly one leftmost\n16\n\nRefer to Figure 3 on page 21 for an explanation of the definition of &quot;global&quot; and\n&quot;local&quot;.\n\n4.4 Design of Citation-based Detection Algorithms\n\n69\n\nand exactly one rightmost element, has one unique predecessor and one unique\nsuccessor [305]. From string processing, we selected the longest common subsequence and Greedy String Tiling (GST) algorithms to be adapted for CbPD.\nConsidering the challenges to citation pattern identification outlined in Section\n4.3, we designed a new class of similarity assessment algorithms termed Citation\nChunking explained in Section 4.4.4. Additionally, we tested Bibliographic\nCoupling on its suitability as a CbPD algorithm.\nTable 9: Categorization of Evaluated Similarity Assessments\nGlobal Similarity\nAssessment\n\nLocal Similarity\nAssessment\n\nOrder\npreserving\n\nLongest Common\nCitation Sequence\n\nGreedy Citation\nTiling\n\nOrder\nneglecting\n\nBibliographic\nCoupling\n\nCitation Chunking\n\n4.4.1 Bibliographic Coupling (BC)\nBibliographic Coupling is one of the oldest and most widespread citation-based\nsimilarity measures for academic texts. The measure, as described in Section\n3.2.2, considers the absolute number or fraction of shared references, but ignores\norder and position of citations for similarity computation. Like all citation-based\napproaches, Bibliographic Coupling has thus far not been used for plagiarism\ndetection. Thus, we tested its applicability for this use case. However, we\nexpected Bibliographic Coupling alone to be an insufficient plagiarism indicator,\nsince it solely considers global document similarity and does not allow\npinpointing the position of plagiarized text segments.\nThe following three sections present the designed CbPD detection\nalgorithms, which in contrast to Bibliographic Coupling, consider the order in\nwhich authors cite sources and the proximity of the citations in the full text to\ncompute document similarity. We hypothesize these approaches to be more\nsuitable for the purpose of plagiarism detection.\n\n70\n\n4 Citation-based Plagiarism Detection\n\n4.4.2 Longest Common Citation Sequence (LCCS)\nThe Longest Common Citation Sequence (LCCS) is a detection algorithm we\ndeveloped by adapting a traditional similarity measure for text strings. The\nLCCS is defined as the maximum number of citations that match in both\ndocuments in the same order, but can be interrupted by non-matching citations.\nEach document pair has either exactly one or no LCCS. For instance, the\nsequence (3, 4, 5) is a sub-sequence of (2, 3, 1, 4, 6, 8, 5, 9) [81].\nThe following example illustrates the LCCS measure, here with a length of\nthree:\nDoc A: 2, 3, 1, 4, 6, 8, 5, 9\nDoc B: 3, 8, 9, 4, 10, 11, 5\nLCCS: 3, 4, 5\nWe adapted LCCS to strictly account for the order of citations, unlike\nBibliographic Coupling, which is order-ignoring. Intuitively, measuring LCCS\nyields high similarity scores if a plagiarist uses longer parts of another text\nwithout alterations or only minor changes of the source’s citations. LCCS is thus\nsuitable for identifying potential plagiarism where text or ideas have been copied\nin the same order, but also allows for arbitrarily sized gaps of non-matching\ncitations. This may be the case for copy&amp;paste plagiarism concealed using basic\nrewording, e.g., through synonym replacements. If a plagiarist performed\nsignificant reordering within plagiarized text segments (shake &amp; paste\nplagiarism) or permuted the sequence of citations, the LCCS approach is\nunsuitable.\n\n4.4.3 Greedy Citation Tiling (GCT)\nGreedy Citation Tiling (GCT) is an adaption of a text string similarity function\nproposed by Wise [367]. Wise designed the original Greedy String Tiling (GST)\nprocedure explicitly for use in PD. Several other researchers successfully applied\nGST in systems for detecting plagiarism of software source code [5, 267].\n\n4.4 Design of Citation-based Detection Algorithms\n\n71\n\nGCT identifies all matches of consecutive shared citations in identical order,\ncalled citation tiles, in two citation sequences. Tiles are substrings of shared\ncitations in both sequences that are not extendable to the right or left without\nencountering a citation that both sequences do not share. GCT permanently links\nthe longest individual matches in both sequences and stores them as a tile. A tile\nis a tuple, ‫ݏ( = ݐ‬ଵ , ‫ݏ‬ଶ , ݈), which consists of the starting position of a match in the\ncitation sequence of the first document (‫ݏ‬ଵ ), its starting position in the citation\nsequence of the second document (‫ݏ‬ଶ ), and the length of the match sequence, (݈).\nAccording to this notation, the first tile for the example in Figure 15 is written as\nI (1,5,3). Matching numbers represent citations to the same work, and extraneous\ncitations are denoted by &quot;x&quot;. Roman numerals are used to mark the matching\ncitation tiles, of which there are three in Figure 15.\n\nDocument 1 (s1) 1\n\n2\n\nDocument 2 (s2) 4\n\n5\nII\n\nI\n3\n\nx\n\nx\n\n4\n\nx\n\nx\n\n1\n\n2\n\nTiles: I (1,5,3)\n\nII (6,1,2)\n\nII\n5\n3\nI\n\nx\n\nIII\n6\n\nx\n\nx\n\nx\n\nx\n\nx\n\nx\n\nx\n\n6\nIII\n\nIII (8,12,1)\n\nFigure 15: Greedy Citation Tiles\n\nAs Figure 15 shows, GCT only identifies substrings of matching citations,\ni.e. matching citations in exactly the same order, if these matches are longer than\na definable minimum length. Yet, the GCT algorithm can cope with\ntranspositions in the order of individual tiles.\nTo illustrate the GCT approach, Figure 16 shows the application of the\nalgorithm for identifying a citation tile assuming a global minimum match length\nof 2. For every citation in the citation sequence of document 1 (denoted as ‫ݏ‬ଵ (in\nthe figure), the algorithm iterates through the citations in the citation sequence of\ndocument 2 (denoted as ‫ݏ‬ଶ in the figure). GCT strictly identifies longer tiles\nbefore shorter tiles by transforming only the longest matches found in the same\niteration into tiles. If, for example, a match of length 3 and a match of length 4\n\n72\n\n4 Citation-based Plagiarism Detection\n\nminimum match length = 2\n1st Iteration:\nno match of\nsequence 1 to\n1st element of\nsequence 2\n\n2nd Iteration:\nmatch [1] with\nlength &lt;\nminimum\nmatch length\n\n3rd Iteration:\nmatch [1,2,3]\nsufficiently\nlong, no other,\nesp. no longer\nmatches\n\n4th Iteration:\nmatch [2,3]\nignored\nbecause of\nprev. markings\n\ns1\ns2\n\ns1\ns2\n\ns1\ns2\n\ns1\ns2\n\na\n\nb\n\nc\n\nd\n\ne\n\nf\n\ng\n\nh\n\ni\n\nj\n\nk\n\n1\n\n2\n\n3\n\n4\n\nx\n\n5\n\nx\n\nx\n\n6\n\n6\n\n7\n\nx\n\n1\n\n1\n\n2\n\n3\n\n3\n\nx\n\n4\n\n5\n\nx\n\na\n\nb\n\nc\n\nd\n\ne\n\nf\n\ng\n\nh\n\ni\n\nj\n\na\n\nb\n\nc\n\nd\n\ne\n\nf\n\ng\n\nh\n\ni\n\nj\n\nk\n\n1\n\n2\n\n3\n\n4\n\nx\n\n5\n\nx\n\nx\n\n6\n\n6\n\n7\n\nx\n\n1\n\n1\n\n2\n\n3\n\n3\n\nx\n\n4\n\n5\n\nx\n\n6\n\n6\n\n7\n\nx\n\na\n\nb\n\nc\n\nd\n\ne\n\nf\n\ng\n\nh\n\ni\n\nj\n\nk\n\nl\n\nm\n\nn\n\na\n1\n\nb\n2\n\nc\n3\n\nd\n4\n\ne\nx\n\nf\n5\n\ng\nx\n\nh\nx\n\ni\n6\n\nj\n6\n\nk\n7\n\nx\na\n\n1\ns\n\n1\nc\n\n2\nd\n\n3\ne\n\n3\nf\n\nx\ng\n\n4\nh\n\n5\ni\n\nx\nj\n\n6\nk\n\n6\nl\n\n7\nm\n\nx\nn\n\na\n1\n\nb\n2\n\nc\n3\n\nd\n4\n\ne\nx\n\nf\n5\n\ng\nx\n\nh\nx\n\ni\n6\n\nj\n6\n\nk\n7\n\nx\na\n\n1\nb\n\n1\nc\n\n2\nd\n\n3\ne\n\n3\nf\n\nx\ng\n\n4\nh\n\n5\ni\n\nx\nj\n\n6\nk\n\n6\nl\n\n7\nm\n\nx\nn\n\nLegend:\nIterator position in sequence 1 or 2 at the beginning of an iteration\nIterator positions during an iteration\nMatch counter in sequence 1 or 2\na\n\nAuxiliary arrays with unmarked position entries\n\na\n\nAuxiliary arrays with „marked“ position entries (part of a prior match)\n\nFigure 16: Identification of a Match Using Greedy Citation Tiling\n\n4.4 Design of Citation-based Detection Algorithms\n\n73\n\nare found in the same iteration, then only the match of length 4 would become a\ntile for that iteration, even if both matches exceed the global minimum match\nlength. Citations that become part of a tile are inserted into auxiliary arrays,\nwhich &quot;marks&quot; them as no longer available for matching, leaving them ignored\nin future iterations. In this way, matching citations cannot contribute to multiple\ntiles. For the next iteration, the algorithm reduces the length of the longest match\nin the previous iteration by one and uses this number as the new maximum\nmatch length. The algorithm thus identifies the next-shorter matches to the\nmatches marked in the previous iteration. The iteration continues until no\nmatches longer than or equal to the global minimum match length remain.\nWise proved that the GST algorithm produces the optimal coverage of\nmatching elements with tiles if the minimum match length is one [367]. The\nworst case complexity of the algorithm is ܱ(݊ଷ ). Wise designed the GST\nalgorithm primarily to identify shake &amp; paste plagiarism. Greedy Citation Tiling\ncan serve the same purpose, but in contrast to the text string-matching approach,\nGCT was developed with the intention to identify paraphrases.\nThe GCT approach focuses on identical order of citations. Finding such exact\nmatches is a strong indicator for text similarity. GCT is able to deal with\ntranspositions in citation patterns that result from rearranging text segments,\nwhich is typical for shake &amp; paste plagiarism. However, the approach is not\ncapable of detecting citation scaling or transpositions of individual citations. To\naddress citation scaling and transpositions, we designed another class of\ndetection algorithms we coined Citation Chunking.\n\n4.4.4 Citation Chunking (Cit-Chunk)\nCitation Chunking (Cit-Chunk) is a set of heuristic detection algorithms, which\nwe developed to identify citation patterns regardless of potential citation\ntranspositions and/or scaling. Cit-Chunk owes its name to a strategy of selecting\ntext fragments, so-called &quot;chunks&quot;, which character-based fingerprinting\nalgorithms commonly employ [41]. A citation chunk is a substring of a\ndocument’s citation sequence with a variable size. The main idea of Cit-Chunk is\nto consider shared citations as textual anchors where local citation patterns are\n\n74\n\n4 Citation-based Plagiarism Detection\n\nlikely to exist. Citation Chunking consists of three steps: formation of chunks,\nthe optional merging of chunks, and the comparison of chunks.\nDue to the novelty of CbPD, there is no empirical data on how citations are to\nbe compared for PD purposes. Therefore, we developed and evaluated (see\nChapter 6) different variations of the algorithm by implementing multiple\napproaches for each of the three steps of Citation Chunking. The following\nsections describe each step of the algorithm in detail.\n\n4.4.4.1\n\nFormation of Chunks\n\nIn this first step, the Cit.-Chunk. algorithm searches for shared citations as\nstarting points for constructing citation chunks. Beginning at shared citations, the\nalgorithm forms chunks by dynamically increasing the considered substring of\nthe document’s citation sequence according to a chunking strategy.\nChoosing a suitable chunking strategy to determine the start- and endpoint of\na citation chunk is tricky, because no solution fits all plagiarism scenarios.\nLarger chunks are better suitable to detect global similarities by compensating\nfor transpositions and scaling. Smaller chunks are better suitable to pinpoint\nlocal areas of high similarity.\nBy modeling the behaviors of plagiarists and the typical citation patterns that\nresult, we derived the following three chunking strategies.\nChunking strategy 1 (consecutively shared strategy) – citations must be\nconsecutively shared to form a chunk. Chunking strategy 1 is the most\nrestrictive. It highlights confined text segments with very high citation-based\nsimilarities. Strategy 1 is ideal for detecting potential cases of copy &amp; paste\nplagiarism, which plagiarists may have concealed by rewording or translation.\nDoc A: x, 1, 2, 3, x, 4, 5, 3, x, x\nDoc B: x, x, 3, 2, 1, x, 5, 3, 4, x\n\n4.4 Design of Citation-based Detection Algorithms\n\n75\n\nChunking strategy 2 (prior citations strategy) – citations form a chunk\ndepending on the previous citations. Chunking strategy 2 includes a citation in\na chunk if the number of non-shared citations separating it from the last shared\ncitation is smaller than the number of shared and non-shared citations that are\nalready included in the chunk currently under construction.\nWe denote the number of non-shared citations separating shared citations as\n݊ and the number of shared and non-shared citations in the chunk under\nconstruction as ‫ݏ‬. A citation is included in the chunk if ݊ ൑ ‫ݏ‬. Therefore,\nchunking strategy 2 allows for sporadic non-shared citations that plagiarists may\nhave inserted to make their text appear more &quot;genuine&quot;. The variable s is a\nthreshold value that determines the sensitivity of the algorithm. The optimal\nvalue of ‫ ݏ‬depends on numerous factors comparable to the threshold length for\ncharacter-based approaches. One factor, for example, is the rate of false positives\nthat is deemed acceptable.\nChunking strategy 2 can detect cases in which plagiarists adopted and\ndisguised longer text segments or logical structures from another text, as well as\ncases of concealed shake &amp; paste plagiarism from different sources.\nDoc A: x, 1, 2, 3, x, x, 4, 5, x, x, x, x, x, x, 6, 7\nDoc B: 3, 2, x, 1, x, x, 4, x, x, x, x, x, 5, 6, 7, x\nChunking strategy 3 (distance threshold strategy) – Citations form a chunk\nif their distance in the text falls below a certain threshold. Chunking strategy\n3 defines a textual range in which plagiarism is deemed likely. Studies showed\nthat plagiarism more frequently affects confined text segments, i.e. only one or\ntwo paragraphs, rather than extended text passages or the entire document [176,\n220, 222, 223, 273]. Building upon this knowledge, chunking strategy 3 only\nconsiders citations within a specified range to form chunks (see Figure 17).\n\n76\n\n4 Citation-based Plagiarism Detection\n\nDocument A\n\n“sliding window” , length\napprox. 1 paragraph\n\nThis is an example text with references to different documents for illustrating the usage\nit ti analysis\nl i ffor plagiarism\nl i i d\nt ti\nThi is\ni a in-text\ni t t citation\nit ti [1].\n[1] This\nThi is\ni an\noff citation\ndetection.\nThis\nexample text with references to different documents for illustrating the usage of citation\nanalysis for plagiarism detection. Another example for an in-text citation [2].\nThis is an example text with references [3] to different documents for illustrating the\nusage of citation analysis for plagiarism detection.\nThis is an example text with references to different documents for illustrating the usage\nof citation analysis for plagiarism detection. This is an example text with references to\ndifferent documents for illustrating the usage of citation analysis for plagiarism\ndetection. This is an example text with references to different documents for illustrating\nthe usage of citation analysis for plagiarism detection.\nThis is an example text with references to different documents for illustrating the usage\nof citation analysis for plagiarism detection. This is an example text with references to\ndifferent documents for illustrating the usage of citation analysis for plagiarism\ndetection. Here’s a third in-text citation [3, 4]. This is an example text with references to\ndifferent documents for illustrating the usage of citation analysis for plagiarism\ndifferent\ndetection.\nThis is an example text with references to different documents for illustrating the usage\nof citation analysis for plagiarism detection.\n\nReferences\n[1]\n[2]\n[3]\n[4]\n\nResult:\nChunk 1: [1,2,3]\nChunk 2: [3,4]\n\nFigure 17: Illustration of Chunking Strategy 3\n\n4.4 Design of Citation-based Detection Algorithms\n\n77\n\nBecause plagiarists may change the segmentation of plagiarized text,\nstrategy 3 analyzes textual proximity in terms of multiple text units, including\ncharacters, words, sentences, and paragraphs. Defining a suitable maximum\ndistance for the proximity of citations in the text is highly dependent on the\nindividual corpus analyzed. If document length is short and individual\ndocuments contain fewer sections and paragraphs, altering the text structure is\nmore difficult for a plagiarist. Therefore, a relatively small maximum distance is\nmost suitable to detect plagiarism in short documents with few sections. In\ncontrast, reordering text usually becomes easier the longer the document.\nTo determine a suitable proximity threshold, we analyzed the average\nnumber of hierarchically subordinate text constituents (e.g., characters and\nwords) contained within hierarchically superordinated text constituents (e.g.,\nparagraphs). For example, in one document, a paragraph may on average contain\n120 words and 720 characters. If less than 120 words separate one shared\ncitation from another shared citation, chunking strategy 3 would include the\nsecond shared citation in the chunk. Using this approach, a CbPD algorithm\nemploying chunking strategy 3 can deal with artificially created paragraph\nsplit-ups.\n\n78\n\n4 Citation-based Plagiarism Detection\n\n4.4.4.2\n\nMerging of Chunks\n\nTo assess the impact of larger chunk sizes, we developed a merging step for\ncitation chunks. The merging procedure iterates through all chunks formed\naccording to one of the chunking strategies described in the previous section.\nThe merging combines chunks to outline longer sections of text with shared\ncitations that could point to, for example, idea plagiarism. The merging\nprocedure combines chunks if the number of non-shared citations ݊ is smaller or\nequal to the number m of shared citations in the previous chunk, (݊ ൑ ݉).\nIteration 1: XXX, x, XX, x, x, XXX, x, x, x, x, x, x, XX\n(merge red and purple? n=1, m=3)\nIteration 2: XXXXX, x, x, XXX, x, x, x, x, x, x, XX\n(merge purple and blue? n=2, m=2)\nIteration 3: XXXXXXXX, x, x, x, x, x, x, XX\n(merge purple and blue? n=6, m=3)\nIn the example above, the merging procedure combines all but the chunk\nfurthest to the right, because the distance of XX to the previous chunk is too\nlarge. The merging step is optional, i.e. the Citation Chunking algorithms can be\napplied with or without the merging of chunks after they have been formed\naccording to one of the chunking strategies.\nFigure 18 summarizes the formation of chunks according to all three\nchunking strategies and the optional merging step in a flow chart.\n\n4.4 Design of Citation-based Detection Algorithms\n\nFigure 18: Formation of Citation Chunks\n\n79\n\n80\n\n4 Citation-based Plagiarism Detection\n\n4.4.4.3\n\nComparison of Chunks\n\nFollowing the formation of chunks, and their optional merging, as described in\nthe previous two sections, the Citation Chunking algorithm compares chunks\nagainst each other regardless of the order of citations in the chunks. In this way,\nthe algorithm accounts for potential transpositions and/or scaling. The number of\nshared citations within the compared chunks is the measure of similarity.\nWe implemented two strategies for comparing citation chunks. The first\nstrategy compares each chunk of the first document with each chunk of the\nsecond. The comparison algorithm stores chunk pairs as matches if these pairs\nhave the highest citation overlap among all pairs. If multiple chunk pairs have an\nequal overlap, the algorithm stores all combinations with maximum overlap.\nThe second method only considers the chunks of a single document and\ncompares them to the unaltered citation sequence of the second document. The\nalgorithm &quot;slides&quot; &quot;each chunk of the first document over the entire citation\nsequence of the second document. The algorithm assigns the chunk to the\nposition in the citation sequence with the maximum citation overlap.\n\n4.5 Projected Suitability of CbPD Algorithms for\nPlagiarism Forms\nThis section classifies the three CbPD algorithms – LCCS, GCT and Cit-Chunk\n– presented in Section 4.4, according to their projected detection performance for\nthe types of citation copying which may occur in the various forms of\nplagiarism.\nTable 10 distinguishes between local and global plagiarism. Local plagiarism\nprimarily affects the sentence level, while global plagiarism encompasses\ndocument-wide plagiarism, see Section 2.2.2. The table makes only a projection\nof algorithm suitability, which we derived by examining a sample of 17 known\ncases of plagiarism identified using the VroniPlag Wiki and Retraction Watch17.\nThe classification should thus be viewed with reservation.\n17\n\nhttp://retractionwatch.wordpress.com/\n\n4.5 Projected Suitability of CbPD Algorithms for Plagiarism Forms\n\n81\n\nLocal and global plagiarism can both contain identical, transposed, scaled, or\na combination of transposed and scaled citation copying. If, for instance, a\nplagiarist translates a text verbatim, the order of citations is unlikely to change\nmuch. In Table 10, such a case falls in the category &quot;identical&quot;. If, however, a\nplagiarist translates a text freely, possibly altering the arrangement of sentences\nor paragraphs, this can result in different citation patterns. Such a case would fall\nin the categories &quot;transposed&quot;, &quot;scaled&quot;, or a combination thereof.\nTable 10: Overview of CbPD Algorithm Detection Performance\n\nLocal\n\nPlagiarism form\n\nLCCS\n\nGCT\n\nCit-Chunk\n\nIdentical (copy &amp; paste,\ntranslations)\n\n-\n\n++\n\n+(+)\n\nTransposed (shake &amp; paste,\ntranslations)\n\n-\n\n-\n\n+\n\nScaled (shake &amp; paste,\nparaphrases)\n\n-\n\n-\n\n+\n\nTransposed &amp; scaled\n(paraphrases)\n\n-\n\n-\n\n+\n\n++\n\n++\n\n+(+)\n\nTransposed (shake &amp; paste,\ntranslations)\n\n+\n\n-\n\n+(+)\n\nScaled (shake &amp; paste,\nparaphrases)\n\n+\n\n-\n\n+(+)\n\nTransposed &amp; scaled\n(paraphrases)\n\n+\n\n-\n\n+(+)\n\nGlobal\n\nIdentical (copy &amp; paste,\ntranslations)\n\nDetection rates: ++ good | + fair | - low | (+) performance depends on chunking\nstrategy\n\nThe LCCS algorithms best indicate suspicious similarity if a document shares\na large fraction of its citations in similar, yet not necessarily identical order, with\nanother document. This algorithm is a global similarity measure, because it\n\n82\n\n4 Citation-based Plagiarism Detection\n\nrepresents the single longest sequence of citations that matches in the same order\nin both documents, when non-matching citations are ignored. Therefore, local\nforms of plagiarism often do not contain enough copied citations to trigger\nsuspicion in an assessment using LCCS. In cases of extensive global plagiarism,\nthe LCCS approach performs quite well, despite potential local re-arrangements\nof citations.\nGreedy Citation Tiling was designed to detect copy &amp; paste plagiarism and\nverbatim translations on both the local sentence level and the global document\nlevel. Such forms of plagiarism often contain citations copied in identical order,\nwhich the exact matching approach of GCT can detect with high accuracy.\nGreedy Citation Tiles with a length of three or greater are typically indicators of\ntext segments with a semantic similarity worth examining. Even slight alterations\nin the citation sequences can prevent the formation of longer citation tiles.\nTherefore, the detection performance of GCT decreases rapidly if text segments\nare paraphrased, freely translated, or reordered, as in shake &amp; paste plagiarism.\nThe detection performance of Citation Chunking depends on the chunking\nstrategy, refer to Section 4.4.4, which is why performance indicators are in\nbrackets in Table 10. Chunking procedure 1 includes only consecutive shared\ncitations; chunking procedure 2 includes shared citations in a certain range\nwithin the citation sequence. Both chunking procedures perform identically to\nGreedy Citation Tiling for local or global plagiarism forms containing identically\ncopied citations. The performance of chunking procedure 3, which includes\nshared citations within a certain range, depends on the split-up of plagiarized text\nsegments in the suspicious document. In general, Citation Chunking is the best\napproach for detecting plagiarism, even in the presence of citation transposition\nor scaling, on both the local and global document level. Depending on the\nplagiarism form, chunking procedures 2 and 3 in particular can detect local and\nglobal plagiarism forms that contain transpositions and/or scaling of shared\ncitations.\nSince all CbPD algorithms require a minimum amount of citations to reliably\ncalculate a citation-based similarity, the citation-based detection approach is not\nsuitable to identify suspicious similarity for short plagiarized fragments.\n\n4.6 Assessment of Identified Citation Patterns\n\n83\n\nTherefore, we consider the CbPD approach as a complement and not as a\nsubstitute to the currently used character-based approaches.\n\n4.6 Assessment of Identified Citation Patterns\nThe citation patterns identified using the CbPD algorithms must subsequently be\nanalyzed and assessed according to their degree of plagiarism suspicion. As\ndescribed in Section 4.2, two main factors influence the degree of suspicion of\nmatching citation patterns. The first is the probability of the shared citations in\nthe matching patterns co-occurring by chance. The second is the number,\nproximity, and order of shared citations in the matching patterns, which we\nsummarized using the term &quot;continuity&quot;.\nIn this section, we describe the design of two scores to evaluate the likelihood\nthat the identified citation patterns represent an instance of suspicious similarity,\nby taking into account these two factors: probability of citation co-occurrence\nand probability of citation pattern continuity. We termed the scores the Citing\nFrequency-Score and the Continuity-Score for a citation pattern.\n\n4.6.1 Citing Frequency-Score (CF-Score)\nTo incorporate the citation frequencies of documents into the assessment of a\ncitation pattern’s degree of suspicion, we devised the Citing Frequency-Score\nheuristic, or CF-Score.\nThe probability of authors citing identical sources independently of each\nother depends on many factors, including similarity of their research objectives,\npopularity of the cited source, relationships among the authors, etc. Most of these\nfactors are hard to quantify. However, citation counts can quantify the\n&quot;popularity&quot; of a source document. Intuitively, two &quot;popular&quot; sources A and B,\nwhich both received 100+ citations, are more likely to appear in a matching\ncitation pattern than two sources C and D, which received only three citations\neach.\nTherefore, we consider citation patterns containing highly cited documents to\nbe less likely a result of undue practices, but rather to represent commonly cited\n\n84\n\n4 Citation-based Plagiarism Detection\n\nstandard literature in a field. Contrarily, we regard citation patterns occurring\nless frequently as a stronger indicator for potentially suspicious document\nsimilarity.\nOne possible method to estimate the probability of co-occurrence of citations\nis to use retrospective citation information to compute a ݊ × ݊-matrix for all ݊\ncitations in a corpus so that each element of the matrix represents the number of\ntimes that two citations co-occur in a document of the corpus. However, we\ndecided not to follow this approach, because it is computationally expensive,\nespecially if not only the co-occurrence of citation pairs, but larger citation\ngroups must be considered.\nTo derive a computationally less expensive estimation of co-occurrence\nprobability, we make the simplified assumption that the occurrence of citations is\nstatistically independent. With this assumption, the probability of a reference r\npointing to a source document X equals the count of all references to document\nX, ‫ݎ‬௫ , in a given corpus divided by the size N of that corpus:\nܲ(‫ݎ‬௫ ) =\n\n௥ೣ\n\n(4.1)\n\nே\n\nBecause rarely cited documents are more predictive and should receive a\nhigher score, we inverse the ratio of the probability to equal\n\nே\n௥ೣ\n\n. We expect that\n\nthe value of frequently cited sources in predicting uncommon, highly specific\ncontent similarities does not decrease in direct proportion to the number of\ncitations these sources gather. Due to a lack of empirical data, we used the square\nroot of the total number of references to a source, ඥ‫ݎ‬௫ , as a starting point for\ndetermining a suitable denominator for the score.\nThe CF-Score for a citation ܿ௜ that links to a reference ‫ݎ‬௝ , which represents\nthe source document X, computes as:\n‫ܨܥ‬൫ܿ௜ (‫ݎ‬௝ )൯ =\n\nே\nඥ௥ೣ\n\n(4.2)\n\nTo compute a CF-Score for a citation pattern ‫݌‬௞ that consists of n citations\nܿଵ ... ܿ௡ that link to m references ‫ݎ‬௝ , we accumulate the CF-Scores of all citations\nin the pattern: ‫݌(ܨܥ‬௞ ) = σ௡ଵ ‫ܿ(ܨܥ‬௜ (‫ݎ‬௝ )).\n\n4.6 Assessment of Identified Citation Patterns\n\n85\n\nAnalogously, we compute the CF-Score for a pair of documents ݀ଵ , ݀ଶ that share\nq matching citation patterns ‫݌‬௞ by accumulating the CF-Scores of the matching\n௤\n\npatterns: ‫݀(ܨܥ‬ଵ , ݀ଶ ) = σଵ ‫݌(ܨܥ‬௞ ).\nTo exemplify the computation of CF-Scores for citation patterns, we assume\na corpus of 1,000 documents. In this corpus four documents A, B, C and D have\nthe\n\nfollowing\n\ncitation\n\n‫ݎ‬஺ = 100, ‫ݎ‬஻ = 50, ‫ݎ‬஼ = 10, ‫ݎ‬஽ = 5.\n\ncounts:\n\nFurthermore, we imagine two document pairs X, Y and X, Z that share the\nfollowing citation patterns: X, Y: (A, B) (A, C) and X, Z: (C, D).\nThe resulting CF-Scores for the document pairs compute as:\n‫ܺ(ܨܥ‬, ܻ) = ‫݌(ܨܥ‬ଵ (‫ܣ‬, ‫ ))ܤ‬+ ‫݌(ܨܥ‬ଶ (‫ܣ‬, ‫))ܥ‬\n=ቀ\n\nଵ,଴଴଴\nξଵ଴଴\n\n+\n\nଵ,଴଴଴\n\nଵ,଴଴଴\n\nξହ଴\n\nξଵ଴଴\n\nቁ+ቀ\n\n+\n\nଵ,଴଴଴\nξଵ଴\n\n‫ܺ(ܨܥ‬, ܼ) = ܲ(‫݌‬ଵ (‫ܥ‬, ‫ = ))ܦ‬ቀ\n\nቁ = 657.65\n\nଵ,଴଴଴\nξଵ଴\n\n+\n\nଵ,଴଴଴\nξହ\n\n(4.3)\n\nቁ = 763.44\n\nThe example shows that although the document pair X, Y shares more citation\npatterns, the single pattern that document X shares with document Z scores\nhigher, because it consists of rarely cited sources.\n\n4.6.2 Continuity-Score (Cont.-Score)\nTo include the continuity of a citation pattern, i.e. the number and proximity of\nmatching citations in the pattern, into the assessment of a pattern’s degree of\nsuspicion, we devised the Continuity-Score.\nWithin a citation pattern, each matching citation that follows another\nmatching citation, after ݊ or less intermediate non-matching citations should\nincrease the Cont.-Score of the pattern. The score increase in this case should be\ngreater than 1 for not reflecting a simple count of matching citations, which we\nrecord separately. Furthermore, the score increase should be larger if fewer nonmatching citations separate two subsequent matching citations.\nLastly, the score should increase in proportion to the number of previous\nmatching citations that fulfill the criterion of having a maximum of ݊\nintermediate, non-matching citations separating them from the preceding\n\n86\n\n4 Citation-based Plagiarism Detection\n\nmatching citation. This characteristic of the equation reflects that the similarity\nof citation patterns increases progressively with the length of sequences of\nmatching citations in the pattern. Equation 4.4 defines the Cont.-Score:\n‫ݐ݊݋ܥ‬. െܵܿ‫ = ݁ݎ݋‬σ௞௜ୀଵ ݉ܽ‫ ݔ‬ቄܽ െ\n\nଵ\n௡ାଵ\n\n௜\n௜ିଵ\nή ൫‫݌‬൫ܿெ\n൯ െ ‫݌‬൫ܿெ\n൯ െ 1൯, 1ቅ\n\n(4.4)\n1\nܽ = ቐܽ +\n1\n\nଵ\nܿெ\n௜\n௜ିଵ\n1ቮ ‫݌‬൫ܿெ ൯ െ ‫݌‬൫ܿெ ൯ ൑ ݊ + 1 , ݅ &gt; 1ቑ\n௜\n௜ିଵ\n൯ െ ‫݌‬൫ܿெ\n൯ &gt; ݊ + 1 ,݅ &gt; 1\n‫݌‬൫ܿெ\n\nThe equation considers a base score a for matching citations. For the first\nଵ\nmatching citation in the pattern ܿெ\nwe set the base score equal to 1. We\n௜\n|݅ &gt; 1 in the\nincrement the base score for each subsequent matching citation ܿெ\n௜\nfrom the previous\npattern if not more than ݊ non-matching citations separate ܿெ\n௜ିଵ\n. We express this condition in terms of the sequential\nmatching citation ܿெ\n\nposition ‫ )ܿ(݌‬of citations.\nTo penalize non-matching citations between matching citations, we subtract a\npenalty value of 1Τ(݊ + 1) for each non-matching citation. If more than ݊\nnon-matching citations separate two matching citations, the base score is set\nback to 1. If ݊ intermittent non-matching citations separate the matching\ncitations, the summand would be 0. If more than ݊ non-matching citations exist\nin between, the summand would be negative. We disallow the Cont.-Score of a\npattern to become less than the count of matching citations in the pattern through\nthe application of the ݉ܽ‫ )(ݔ‬operator. This operator ensures that the minimum\nscore increase for each matching citation is 1. We assume that the suitable\nmaximum threshold for the number of non-matching intermittent citations, ݊, is\ncollection-dependent and identifying this threshold requires a case-by-case\nconsideration. For documents in disciplines that generally cite more references,\ne.g., the life sciences, the threshold should be set higher than in disciplines that\ntypically cite fewer references, e.g., mathematics.\nFigure 19 illustrates the computation of the Cont.-Score for two citation\npatterns assuming an allowed maximum number of intermittent non-matching\n\n4.7 Conclusion\n\n87\n\ncitations ݊ = 3. Arabic numerals represent matching citations and the x denotes\nnon-matching citations. In the figure, both citation patterns contain eight\nmatching citations. This relatively high number of matching citations leads to the\nCont.-Score of both patterns being greater than the length of the pattern. The\nCont.-Score of the second pattern equals about 1.7 times the score of the first\npattern. In this example, the higher score could signal that the second pattern is\nmore likely to be one long match, and hence more suspicious. The first pattern is\nlikely to represent three smaller matches, which are less suspicious.\n5\n1\n\n4\n\nx\n\nx\n\n2-0.25·0\n\nx\n3-0.25ή3\n\nPattern Length = 8\n5\n1\n\n4\n2-0.25·0\n\n2\n\nx\n\n2\n\n3\n\n4-0.25ή0\n\n1\n\nx\n\nx\n\nx\n\nx\n\nx\n\n6\n1\n\n5-0.25ή0\n\n8\n\n7\n\n2-0.25ή0 3-0.25ή0\n\nCont.-Score = 1+2+2.25+4+5+1+2+3 = 20.25\nx\n\n3-0.25ή1\n\nPattern Length = 8\n\n3\n4-0.25ή1\n\nx\n\n1\n5-0.25ή1\n\nx\n\nx\n\n6\n6-0.25ή2\n\nx\n\nx\n\n7\n7-0.25ή2\n\n8\n8-0.25ή0\n\nCont-Score = 1+2+2.75+3.75+4.75+5.5+6.5+8 = 34.25\n\nFigure 19: Cont.-Score Computation for Citation Patterns\n\n4.7 Conclusion\nThe concept of Citation-based Plagiarism Detection for the first time uses the\ninformation on semantic relatedness contained in citations as a method to detect\nplagiarism.\nTo cover four different plagiarism forms and the unique styles of citation\npattern copying which result, we adapted Bibliographic Coupling and developed\nthree algorithms: Longest Common Citation Sequence, Greedy Citation Tiling,\nand Citation Chunking. The algorithms examine citation patterns regarding three\nfactors as shown in Table 12, transpositions, scaling and global vs. local\ncomparison.\n-\n\nTranspositions describe whether the order of shared citations must\nbe identical.\n\n88\n\n4 Citation-based Plagiarism Detection\n\n-\n\nScaling describes whether shared citations may occur multiple\ntimes.\n\n-\n\nGlobal vs. local similarity describes whether the plagiarism occurs\ndocument-wide or only locally.\n\nEach algorithm features unique strengths. By combining the four approaches,\nwe intend to address the various forms of local and global plagiarism.\nTable 11: Overview CbPD Algorithms\n(CbPD)\nAlgorithm\n\nTranspositions\ndetectable?\n\nScaling\ndetectable?\n\nGlobal\nvs.\nlocal\n\nProjected\ncapability to\ndetect\n\nBib. Coup\n\nYes\n\nyes\n\nglobal\n\nLikely to produce\nfalse positives\n\nLCCS\n\nPartially\n\nno\n\nglobal\n\nparaphrases,\ntranslations\n\nGCT\n\nNo\n\nno\n\nlocal\n\nparaphrases,\ntranslations\n\nCit-Chunk\n\nYes\n\ndepends on\nchunking\nstrategy\n\nlocal\n\nstrong\nparaphrases,\nstructural and idea\nplagiarism\n\nIn addition to the CbPD algorithms, we proposed the Citing FrequencyScore, which considers the probability of co-occurrence of identical citations by\nchance, and the Continuity-Score, which reflects the number and proximity of\nmatching citations in a pattern, to assess the probability that a citation pattern\nindicates plagiarism. The next chapter presents the implementation of the CbPD\nalgorithms in a prototypical plagiarism detection system.\n\n5 Prototype: CitePlag\nThis chapter describes the implementation of the Citation-based Plagiarism\nDetection (CbPD) approach in a first prototype: CitePlag. The prototype has a\nJava backend and a HTML5 frontend. CitePlag is available under an open source\nlicense18. Figure 20 illustrates CitePlag’s system architecture, which is composed\nof four components: a document parser, a relational database, a detector, and a\nweb-based frontend.\n\nCitePlag\nDocument\nParser\n\nDetector\n\ncitation &amp; doc. data\n\ndetection\nresults\n\ndetection\nresults\n\nDatabase\n\nFrontend\nwww.citeplag.org\nFigure 20: CitePlag’s System Architecture\n\nThe database stores the document’s bibliographic data as extracted by the\ndocument parser and stores the results of the CbPD and character-based\nalgorithms, which are implemented in the detector. The web-based frontend\nretrieves the detection results from the database and visualizes them for human\ninspection. The following four sections present more details on the components\nof the CitePlag prototype.\n\n18\n\nThe source code is available for download; refer to Appendix C.\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_5, © Springer Fachmedien Wiesbaden 2014\n\n90\n\n5 Prototype: CitePlag\n\n5.1 Document Parser\nThe document parser extracts metadata, citations, and references from the input\ndocuments and stores the data in the database. Parsing citation data and matching\nthis data with the references in the bibliography of documents is essential for\nCbPD. Automatic extraction of citation data is not a trivial task. Hundreds of\ncitation styles exist and the application of these styles is often inconsistent due to\ninadvertent mistakes when citing. Additionally, technical characteristics of\ndifferent file formats, for example, different PDF versions, make the extraction\nprocess error-prone [195].\nWhen we began researching CbPD, the available citation parsers were only\nable to process a document’s bibliography, but could not recognize citations\nwithin the full-text or match these to the entries in the bibliography. To address\nthis weakness, we added to the open source software ParsCit19 the following\ncrucial functionalities:\n-\n\nparsing citations within the document’s full-text including the\nfootnotes\n\n-\n\nmatching these citations with the corresponding entries in the\nbibliography\n\n-\n\nidentifying the exact positions of citations in the document\nincluding chapter, section, paragraph, sentence, word and character\ncount\n\nThese improvements and extensions are now part of the official ParsCit\nrelease. Currently, we are still working on improving the citation extraction\naccuracy:\n\n19\n\n-\n\nfor different file formats (PDF, PS, etc.) and versions thereof\n\n-\n\nfor different citation styles\n\nhttp://aye.comp.nus.edu.sg/parsCit/\n\n5.1 Document Parser\n\n91\n\nFigure 21 illustrates the general parsing procedure for PDF files using\nthe adapted version of ParsCit. Citation extraction performs reliably for\nthe most common citation styles. However, in some academic fields\ncitation styles are inconsistent. In the legal field, for example, footnote\ncitations and in-text citations may be used alternatingly. Such\ndiscrepancies in citation formatting currently leads to unsatisfactory\nparsing results. For the discussion on parsing errors and their\nconsequences, refer to Section 6.4.1 on page 141.\n\nFigure 21: General Document Parser\n\nFor the evaluation of the PubMed Central Open Access Subset (PMC OAS)\npresented in Section 6.4, parsing the references was not necessary, because the\nNational Library of Medicine, which hosts the PMC OAS corpus, offers all\ndocuments in a machine-readable XML format. The National Library of\nMedicine XML format is termed NXML, and includes markup for document\n\n92\n\n5 Prototype: CitePlag\n\nmetadata, citations and references. For the purpose of CbPD, determining the\nexact positions of citations within a document’s full-text is necessary. We\nmeasured the positions of citations in terms of the character, word, sentence,\nparagraph, and section counts. The parser applies Java text processing methods\nto acquire character counts and evaluates the corresponding tags in the NXML\ntexts to obtain the paragraph and section position of citations. NXML texts do\nnot provide markup for sentences and words. Thus, identifying the boundaries of\nthese elements requires a pre-processing step.\nWe developed an independent subcomponent to the parser, the\nSentence-Word-Tagger (SW-Tagger), to perform the pre-processing step of\nidentifying sentence and word boundaries. After the SW-Tagger completes\npre-processing, a second subcomponent, the data parser, extracts all relevant data\nand imports it into the database. Figure 22 illustrates this two-stage parsing\nprocess for NXML documents. Appendix B presents technical details on the\nSW-Tagger and the data parser.\n\n5.2 Database\n\n93\n\nNXML Document Parser\nPMC\nDoc.\n&lt;xml&gt;\n&lt;/xml&gt;\n\nTagged\nDoc.\n&lt;xml&gt;\n&lt;/xml&gt;\n\nSW-Tagger\n1.\n2.\n3.\n4.\n\nSentence and Word Markup:\nSubstitution of XML markup (placeholders)\nInvocation of SPToolkit\nWord markup based on regular expressions\nReinsertion of original XML markup\nData Parser\n\nRecognition and Import of Document Data:\n1. Invocation of SAX parser and content handler\n2. Customized content handler recognizes NXML\ntags and the markup of SW-Tagger\n3. Database update through JDBC\n\nSPToolkit\n\nSAX Paser\n\nContent\nHandler\n\nCitePlag\nDatabase\n\nFigure 22: Two-stage Parsing Process for NXML Documents\n\n5.2 Database\nWe chose the open source software MySQL for database management. Figure 23\ndepicts CitePlag&#x27;s data model using the Entity Relationship Model (ERM)\nnotation. Relationship connectors link the attributes that participate in the\nrelationship. Most table and attribute names are self-explanatory. The size of\ndatabase including all tables is about 530 GB. Appendix B.4 presents a detailed\ndescription of the tables and attributes.\n\n94\n\n5 Prototype: CitePlag\n\nFigure 23: ER Data Model for the CitePlag Database\n\n5.2.1 Consolidation of Reference Identifiers\nIn the process of creating the database, the consolidation of reference identifiers\nwas a challenge to be overcome. The reference strings in documents contained in\nthe PMC OAS often include different document identifiers, e.g., PubMed IDs\n(PMID), Medline IDs (MEDID) or Digital Object Identifiers (DOI). PMIDs and\nMEDIDs are identifiers assigned by the National Library of Medicine to\ndocuments in the PubMed database and the Medline index. Digital Document\nIdentifiers are maintained by the DOI Consortium and can be obtained by\nanybody upon request and payment of an administration fee. In addition to these\nnumerical identifiers, we computed Reference Title Keys (RefTitKeys) and\nReference Author Keys (RefAuthKeys), which represent the first 40 ASCII\ncharacters of the title or of the author names in a reference. We used a\ncombination of the RefTitKey and the RefAuthKey to identify references that\ndid not have numerical identifiers.\nBy examining references manually, we found that all document identifiers\navailable in the PMC OAS were subject to error from incorrect assignments by\nauthors or processing by the NLM. For instance, for some references with a\n\n5.3 Detector\n\n95\n\nPMID and a DOI, the PMID corresponded neither to the document, nor to the\nDOI. Furthermore, authors did not use identifiers consistently for citing sources.\nSome authors stated no identifiers, some used a PMID, and others preferred a\nDOI.\nAccurate identification of matching references is a prerequisite for a CbPD\nanalysis. For this purpose, we consolidated available document identifiers after\nimporting the data into the CitePlag database. Appendix B.3 describes the\napplied consolidation procedure in detail. The current disambiguation methods\nof the CbPD prototype are basic. However, we expect that research on informed\nheuristics and machine learning can improve disambiguation procedures.\n\n5.3 Detector\nThe detector component of the CitePlag prototype implements the CbPD\nalgorithms as described in Section 4.4. Figure 24 outlines the main components\nof the detector using a UML class diagram. We implemented each CbPD\nalgorithm as a stand-alone Java class. The class &quot;CitationPatternChecker&quot; is a\ncentral hub that instantiates the different analysis classes. CitationPatternChecker\nalso bundles functionality, which all CbPD algorithms require, e.g., determining\nthe set of shared references. The other classes are multithreaded implementations\nfor subtasks related to input and output operations on the CitePlag database. The\nsource code is available for download; refer to Appendix C. To determine and\nvisualize the character-based similarities we used the open souce software\nEncoplot (see Appendix J).\n\n96\n\n5 Prototype: CitePlag\n\nFigure 24: UML Class Diagram for CitePlag Detector\n\n5.4 Frontend\nThe CitePlag frontend retrieves detection results from the database and\nvisualizes citation-based and character-based similarities for the PDS user.\nCurrent plagiarism detection software solely visualizes character-based\nsimilarity. For CbPD, however, citation pattern visualization is crucial to help\nusers discover and navigate the sections in documents potentially featuring\nstrongly disguised plagiarism. We believe that numeric similarity scores without\nproper visualization are insufficient for both character-based and citation-based\nPDS. To assist the human examiner, we developed a frontend to visualize the\ncomputed similarities.\n\n5.4 Frontend\n\n97\n\nFigure 25: CitePlag’s Document Similarity Visualization\n\nThe frontend was developed in collaboration with students from the HTW\nBerlin20. Among other features, the CitePlag frontend offers interactive\ndocument navigation, highlighting for matching citations and text segments, as\nwell as statistics summarizing identified similarities, refer to Figure 25. A\nHTML5 compliant browser, such as Chrome, Firefox or Safari, is required.\nCitePlag features a customizable side-by-side document visualization, see #1\nin Figure 25, to efficiently browse academic documents for text and citation\nsimilarities and aid the user in identifying plagiarism. The suspicious document\nis displayed on the left and the potential source document is displayed on the\nright. When clicking on highlighted text or citation similarity in either document,\nthe respective section in the other document is retrieved. The visualization of text\n\n20\n\nI wish to acknowledge the contributions to the frontend by André Gernandt, Leif\nTimm, Markus Bruns, Markus Föllmer, and Rebecca Böttche from the HTW Berlin –\nUniversity of Applied Sciences.\n\n98\n\n5 Prototype: CitePlag\n\nand citation similarities is customizable to the user’s preferences in the menu bar,\nsee #2 in Figure 25, under the ‘settings’ tab.\nA scrollable central document browser, see #3 in Figure 25, enables\ninteractive and quick document navigation. The document browser schematically\ncompares the two documents selected in the ‘documents’ tab using the CbPD\nalgorithm selected by the user, see #4 in Figure 25. The higher the text similarity\namong sections, the darker they are marked in red. By highlighting matching\ncitations and connecting these in the document browser, CitePlag visualizes both\nthe easy to spot global and copy &amp; paste plagiarism instances, as well as the\nlocal and heavily disguised plagiarism instances. A collapsible cluster side tab,\nsee #5 in Figure 25, recommends additional documents with high similarity\nscores, which are selectable for subsequent comparison. The cluster view tab\nalso allows the user to set weighting coefficients for the individual CbPD\nalgorithms thus creating a hybrid CbPD algorithm with customized emphasis.\nIn the documents tab of the menu bar, documents can be selected using\nPubMed or PubMed Central IDs or uploaded from the local file system. The\nmenu bar also features a ‘help’ tab and a document ‘statistics’ tab. Under the\nstatistics tab, the user can view two graphs summarizing the document being\ncompared. The first graph shows the stacked lengths of text overlap per page for\nthe selected document (see Figure 26 for this graph). A second graph, which the\nuser can select, shows the Bibliographic Coupling strength per page.\n\n5.5 Conclusion\n\n99\n\nFigure 26: CitePlag’s Document Statistics\n\n5.5 Conclusion\nThe CitePlag prototype described in this chapter is the first implementation of a\ncitation-based approach to plagiarism detection. The CitePlag system\narchitecture consists of a parser, which extracts the required bibliographic data\nfrom documents and stores them in the database. The database provides this\ndocument data to the detector. The detector runs the CbPD algorithms and stores\nthe results in the database, from where the frontend retrieves the detection results\nand visualizes them for human inspection. CitePlag is accessible at:\nhttp://www.citeplag.org\n\n6 Quantitative and Qualitative Evaluation\nThis chapter21 presents the evaluation framework and the evaluation results of\nthe Citation-based Plagiarism Detection (CbPD) approach. By evaluating the\nperformance of CbPD for both known and currently unknown plagiarism cases,\nthis chapter addresses Research Task 5. Employing the commonly used\nplagiarism evaluation frameworks to gauge the effectiveness of the CbPD\napproach in identifying disguised plagiarism proved challenging for several\nreasons:\n1.\n\nNo existing method is capable of detecting strongly disguised\nplagiarism forms for which the CbPD approach was designed. This\nmakes a meaningful comparison to existing approaches difficult.\n\n2.\n\nDue to the covert nature of disguised plagiarism and the lack of reliable\nmethods for detecting it, the true extent of disguised plagiarism present\nin any non-fabricated collection is unknown, thus a ground-truth can\nonly be approximated.\n\n3.\n\nExisting artificially created test collections are unsuitable, since they do\nnot realistically represent the sophisticatedly disguised real-world\nplagiarism committed by experienced scientists.\n\nFor these reasons, a straightforward CbPD performance evaluation is not\nfeasible. The methodology section addresses the requirements of a suitable test\ncollection and the challenge of deriving a ground truth for heavily disguised\nplagiarism forms. Instead of a single evaluation using only one corpus, we\nperform multiple evaluations using three distinct test collections. This threestage evaluation process pursues the following questions:\n\n21\n\nA journal article containing excerpts from this evaluation chapter, with particular\nfocus on the results obtained from the PMC OAS evaluation, has been accepted for\npublication in the Journal of the American Society for Information Science and\nTechnology [135].\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_6, © Springer Fachmedien Wiesbaden 2014\n\n102\n\n6 Quantitative and Qualitative Evaluation\n\n1.\n\nHow suitable is CbPD for identifying plagiarism, in particular\ntranslated plagiarism, in a collection of identified plagiarism\ninstances, where an extensive manual verification has resulted in\na reliable ground truth? (Refer to the evaluation using the\nGuttenPlag Wiki in Section 6.2.)\n\n2. How suitable is CbPD for identifying plagiarism in a collection\nof identified plagiarism instances from multiple authors featuring\ndiverse plagiarism styles? (Refer to the evaluation using the\nVroniPlag Wiki in Section 6.3.)\n\n3. How suitable is CbPD for identifying plagiarism in a large\ncollection of scientific publications likely featuring strongly\ndisguised and currently undiscovered plagiarism instances?\n(Refer to the evaluation using the PubMed Central Open Access\nSubset in Section 6.4.)\n\n6.1 Methodology\nPlagiarism detection systems are specialized information retrieval (IR) systems22.\nThe evaluation of IR systems is a mature, empirical research discipline for which\nmethodological standards have been established. According to Manning [209],\nthe standard IR systems evaluation framework comprises four components:\n1.\n\na suitable document collection\n\n2. clearly defined information needs\n3. relevance judgments, i.e. assessments about which documents\nfulfill which information needs\n\n4. performance metrics\n22\n\nPD is sometimes considered as a Natural Language Processing (NLP) problem.\n\n6.1 Methodology\n\n103\n\nA single ‘suitable document collection’, was not readily available for an\nevaluation of CbPD. The main challenge is that there is no currently existing\nlarge-scale test collection of academic plagiarism containing non-artificially\ncreated plagiarism, where at the same time all occurrences of plagiarism are\nknown and verified. Therefore, most studies resort to evaluating PDS using\nartificially created plagiarism (see Section 2.3.1). However, using artificial\nplagiarism is not an option for evaluating the capability of PDS to detect heavily\ndisguised, realistic plagiarism.\nThe second component, ‘clearly defined information needs’, at first seems\neasily established. Naturally, the goal when using the CbPD approach is to\nidentify instances of strongly paraphrased text, translated plagiarism, structural\nplagiarism or idea plagiarism. However, upon closer examination, the\nsubjectiveness of human judgment on plagiarism allows no clear definition of\nwhat constitutes plagiarism in a given circumstance. Therefore, we uniformly\ndefined the information need for the user study as:\n“A retrieved document must fulfill the information need of an examiner in a real\nplagiarism detection scenario, i.e. the document features similarities, which the\nexaminer would likely find valuable to be made aware of.”\nThe third component, ‘reliable relevance judgments’, is challenging to obtain,\nbecause the level of document similarity that constitutes plagiarism varies\nwidely, especially for disguised forms of plagiarism. Even for the comparatively\neasy to identify literal text similarities, PDS tend to set varying thresholds,\nbecause examiners’ opinions differ on the level of textual similarity that\nconstitutes plagiarism (see Section 6.1.2). To increase the reliability of human\nrelevance judgments and increase inter examiner agreement in the user study, we\nprovide a set of uniform guidelines for classifying and rating the retrieved\ndocuments.\nThe fourth component, ‘performance metrics’, is only feasible if reliable\nrelevance judgments exist for a document collection.\n\n104\n\n6 Quantitative and Qualitative Evaluation\n\nIn summary, the rigid four-component evaluation framework applied to IR\nsystems is applicable to the evaluation of CbPD only to a limited extent.\nCurrently, no available framework exists where all components are suitable for\nthe goal of our evaluation. Therefore, we evaluated CbPD using three distinct\ndocument collections. Each collection offers unique benefits in terms of the\ncharacteristics making it suitable as a test collection for CbPD evaluation. The\nfollowing section discusses the requirements of an ideal test collection and\nsubsequently describes the three chosen collections.\n\n6.1.1 Test Collection Requirements\nTo evaluate the effectiveness of CbPD in detecting realistic, strongly disguised\nacademic plagiarism, an ideal test collection should contain:\n1.\n\nnon-fabricated plagiarism – to reflect realistic disguise\n\n2.\n\nverified cases of plagiarism – to allow for a ground truth\napproximation and derive performance indicators\n\n3.\n\nacademic citations – within readily accessible full-text\n\n4.\n\na variety of documents – many authors, a variety of academic\ndisciplines and different languages\n\n5.\n\noptional: machine-readable citations\n\nFirst, the test collection must contain non-fabricated cases of plagiarism to\nallow a realistic evaluation of CbPD’s ability to detect strongly disguised\nplagiarism. Academic plagiarists are highly motivated to avoid detection and\nmeet the high quality standards of peer-reviewed journals. Therefore, we assume\nthat only real-world cases of paraphrased, translated, or idea plagiarism\naccurately exemplify the creative disguise tactics employed by plagiarizing\nscientists in order to deceive both their peers and the public. Most plagiarism in\nexisting test collections lacks a sufficiently sophisticated disguise because it was\nartificially fabricated. For example, paraphrases were created using automated\nmethods, or texts were machine translated using Google Translate.\n\n6.1 Methodology\n\n105\n\nTo introduce more realistically disguised plagiarism into the evaluation\ncorpora of the PAN competitions 2010-2013, Potthast et al. contracted human\nwriters using the crowdsourcing platforms Amazon Mechanical Turk (PAN 2010\nand 2011) and oDesk (PAN 2012 and 2013) [262, 264, 265]. The contractors\nwere provided with a web crawl dataset of approximately 1 billion web pages, a\nspecialized search engine and modified word processing software. The writers’\ntask was to use only the dataset and software tools provided to them to produce\nplagiarized articles of approximately 5,000 words by paraphrasing web pages in\nthe given dataset. The modified software tools monitored the writers’ searches\nfor and use of source documents. This approach produced the most realistic test\ncases of disguised plagiarism currently available; however, the articles of the\nPAN collections were unsuitable for an evaluation of CbPD, because they\nincluded no citations. Additionally, it remains doubtful whether articles written\nby contractors without expert knowledge accurately resemble the plagiarism\ndisguise of scientists who often work months or even years on publications.\nSecond, an ideal test collection should contain verified cases of plagiarism to\nallow the derivation of a ground truth to quantify and compare the detection\nperformance of PD approaches. The true amount of plagiarized content in any\nnon-artificially created collection will most likely never be fully known.\nHowever, a thorough manual examination of a document collection can identify\na large fraction of plagiarism instances, hence allowing the establishment of a\nderived ground truth, equivalent to a gold standard data set.\nThird, a test collection used for CbPD evaluation must contain academic\ncitations, and the full-text of the documents must be available.\nFourth, the test collection should ideally comprise a variety of academic\ndocuments from different authors, academic disciplines and languages to reflect\ndiverse, real-world plagiarism styles.\nFifth, the presence of machine-readable citations is a desirable test collection\nfeature; however, it is not a mandatory prerequisite, since we adapted the open\nsource citation parser ParsCit to parse citations within the full-text according to\nour needs (see 7.3.1 for more information).\n\n106\n\n6 Quantitative and Qualitative Evaluation\n\nSince artificially created plagiarism cases are not suitable for the intended\nevaluation, we turned to the use of real plagiarism cases. The unique challenges\nof using real-world plagiarism are discussed in the following section.\n\n6.1.2 Test Collection Challenges\nThere are several challenges associated with using real-world test collections for\nplagiarism detection system evaluations.\nThe most prominent limitation posed by any real-world collection is the\nunavailability of a ground truth. While for fabricated test collections, the precise\namount of plagiarism is known, the true extent of plagiarism in real-world\ncollections remains unknown. Even the most resource-intensive manual\nidentification efforts are likely to miss some instances of plagiarism in large\ncollections. Thus, calculating precision and recall and comparing the results to\nthe results obtained from other collections provides only a limited insight into\nthe true detection performance of the evaluated PDS.\nThe second limitation of real-world plagiarism collections arises from the\ninconsistencies in human judgment regarding plagiarism. Even when assuming\nall plagiarism instances can be identified for a real-world plagiarism case, expert\nexaminers may disagree on whether plagiarism has taken place. Such\ndiscrepancies in opinions could be observed in recent plagiarism investigations\ninvolving the dissertations of high-ranking politicians, e.g., the conflicting\nverdicts reached by plagiarism investigators regarding the dissertation of D.\nDähnert, compared to the dissertation of Mrs. Schavan23. This limitation in the\n23\n\nThe German Technical University Cottbus (BTU) refused to rescind the doctorate\nof D. Dähnert, although investigations by the VroniPlag Wiki identified 44% of total\npages in his thesis to contain at least one instance of plagiarism [350]. The BTU\nCottbus, however, declared the work to contain only “technical weaknesses” but no\n“conscious manipulation of data” or other “deceptive practices” [359]. On the other\nhand, in a plagiarism investigation led by the Heinrich Heine University, the\ndissertation of Annette Schavan was rescinded despite her thesis containing few literal\ntext overlaps, refer to Section 2.1.3, page 16. Dähnert is a director at the energy\ncompany, Vattenfall, which, according to the words of Mr. Kunze is a valuable\nindustry partner of the BTU Cottbus having provided the University with several\nmillion euros in third-party funds [258]. Debora Weber-Wulff, professor for Media\n\n6.1 Methodology\n\n107\n\ninconsistencies in human judgment regarding plagiarism is due in part to three\nmain contributing factors.\n1.\n\nThe definition of plagiarism and what constitutes academic\nplagiarism under certain circumstances, remains subjective.\n\n2.\n\nIn evaluations of real-world plagiarism, examiners are\nsusceptible to be swayed by external factors. For example,\npolitical, economic, and social ties, as well as the context in\nwhich evidence is presented, and the document similarity\nvisualization method used can contribute to volatile human\njudgment.\n\n3.\n\nThe extent of similarity that may be regarded as legitimate\nlargely depends on the scientific field and the document type,\ne.g., case study, literature review, medical standards update, etc.\n\nAdditional concerns associated with real-world document collections for use\nin PD evaluations have been outlined by Potthast and include:\n-\n\nThe distribution of detected real-world plagiarism is skewed\ntowards ease of detectability [262].\n\n-\n\nThe acquisition of real-world plagiarism is resource intensive,\nespecially in the case of concealed plagiarism [262].\n\n-\n\nPublishing real-world cases may require consent of both\nplagiarists and the original author [262]. If a real-world\ncollection does contain plagiarism, then it has usually not yet\nbeen made public or been verified. This is a problem, because\nonce an accusation has been made – be it just or unjust – the\n\nand Computing at the HTW Berlin, comments that zu Guttenberg, who was forced to\nrescind his doctorate, made a mistake in selecting his university, because standards\nseem to vary [359].\n\n108\n\n6 Quantitative and Qualitative Evaluation\n\naccusation can result in serious negative consequences for the\naccused.\nThe next sections introduce the three real-world document collections we\nidentified as promising for an evaluation: the GuttenPlag and VroniPlag Wikis,\nand the PubMed Central OAS collection.\n\n6.1.3 GuttenPlag Wiki\nThe GuttenPlag Wiki [147] is the result of a crowd-sourced project aimed to\nexpose all instances of plagiarism in a single work: the doctoral thesis of former\nGerman Minister of Defense, Karl-Theodor zu Guttenberg. A law professor\nhappened to detect plagiarized sections in Mr. zu Guttenberg’s doctoral thesis by\nchance [146]. After the popular politician repudiated the accusations as\n“abstruse”, volunteers initiated the GuttenPlag Wiki project [147] to investigate\nthe accusations. The project identified 1,218 plagiarized text fragments from 135\nsources24. Zu Guttenberg subsequently retracted his initial claim of a flawless\nthesis; his doctorate was renounced and he eventually stepped down from his\npolitical position. In part due to the widespread media attention, zu Guttenberg’s\nthesis represents one of the most thorough plagiarism investigations to date.\nAs of April 3rd 2011, the joint investigation efforts revealed approximately\n64 % of all lines of text in the thesis to be plagiarized. Of the 393 main text\npages in the thesis, 371 pages, or almost 95 %, contained plagiarism. The\nfollowing barcode-representation of the document illustrates the findings.\n\n24\n\nAs of 2011-04-03.\n\n6.1 Methodology\n\n109\n\nLegend\nRed sections – pages with plagiarism from multiple sources\nBlack sections – pages with plagiarism from one source\nWhite sections – plagiarism-free pages\nBlue sections – table of contents and the bibliography\n\nFigure 27: Plagiarized Pages in zu Guttenberg’s Thesis\nSource: [147]\n\nAlthough no ground truth exists regarding the total amount of plagiarism\npresent in the thesis, we assume that the thousands of person-hours invested by\nvolunteers and experts at the responsible university led to the identification of a\nvery large fraction of the total plagiarism contained in the document.\nIn summary, the key advantages of the GuttenPlag Wiki are:\n-\n\nThe analyzed thesis contains real plagiarism, including\ndisguised paraphrases and translations, which were created\nwith a noticeably high motivation to conceal the misconduct.\n\n-\n\nThe extremely thorough, manual verification of plagiarism\ninstances allows for a ground truth approximation of total\nplagiarism in the thesis.\n\n-\n\nThe thesis is a comprehensive academic work with a sufficient\nnumber of citations.\n\n6.1.4 VroniPlag Wiki\nThe VroniPlag Wiki [350] is an ongoing, crowd-sourced project investigating\nacademic plagiarism allegations. Volunteers manually analyzed 23\n\n110\n\n6 Quantitative and Qualitative Evaluation\n\ndissertations25 of German politicians and scientists and identified ‫׽‬3,600\nplagiarized fragments, which are freely accessible on the web. These real-world\nplagiarism instances from a variety of authors and disciplines represent different\nstyles of plagiarism and diverse citing behavior. As with any real-world\nplagiarism collection, examiners may not have identified all plagiarized\nfragments, thus no ground truth exists. However, the carefully verified cases of\nplagiarism allow for a ground truth approximation.\nThe key advantages of the VroniPlag Wiki are:\n-\n\nThe large collection of manually examined documents from\ndifferent authors and disciplines contains real academic\nplagiarism, representing various forms of plagiarism.\n\n-\n\nThe thorough verification of plagiarism instances allows for a\nground truth approximation of the total amount of plagiarism in\nthe examined documents.\n\n-\n\nThe documents are comprehensive academic works with\nsuitable amounts of citations.\n\nBoth the VroniPlag and the GuttenPlag Wikis are collections of text\nfragments featuring high character-based similarity, since suspicious text overlap\nis typically what led to the plagiarism suspicion in the first place. Thus, many\nplagiarism cases in the VroniPlag and GuttenPlag Wikis could naturally have\nalso been identified using available character-based PDS. This is why we\nadditionally apply CbPD to the large real-world collection PMC OAS, where\nplagiarism, if present, does not necessarily feature high character-based\nsimilarity.\n\n25\n\nThe VroniPlag Wiki is an ongoing project and new plagiarism instances are\ncontinuously identified. At the time of analysis, 2012-05-10, the collection\nconsisted of 23 works containing 3,345 instances of plagiarism in the confirmed\ncategory (the category we considered for an evaluation of CbPD). These\ninstances of plagiarism originated from 636 literature sources.\n\n6.1 Methodology\n\n111\n\n6.1.5 PubMed Central OAS\nThe PubMed Central Open Access Subset (PMC OAS) is a continuously\nexpanding archive of open access (OA) full-text journal articles from the\nbiomedical and life sciences. The OA Subset is part of the full-text archive\nPubMed Central (PMC) and contained 234,591 articles by approximately\n975,000 authors from 1,972 peer-reviewed journals at the time of evaluation26.\nPMC and the PMC OAS are maintained by the National Center for\nBiotechnology Information (NCBI), a sub-unit of the National Library of\nMedicine (NLM).\nGiven its large size and numerous authors, the PMC OAS is representative of\ndiverse citation styles and potentially many different forms of plagiarism. The\nmostly reputable journals in the PMC OAS and their thorough peer-review\nprocess foster the assumption that yet-undiscovered plagiarism instances will be\nsparse. However, if present, they may be more strongly disguised, i.e. cleverly\nparaphrased and modified with less copy &amp; paste or shake &amp; paste plagiarism,\ngiven that they have withstood detection.\n\n26\n\nAs of 2011-04.\n\n112\n\n6 Quantitative and Qualitative Evaluation\n\nOther\nSources\n\nNCBI\nindexes\nand links\n\nPMC OA\nSubset\n\nNLM\n\n.pdf\n\n.nxml\n\nPubMed®\n\nMEDLINE®\n\nPMC®\n\nOA &amp; non-OA\npublication data\nJournal\npublishers\n\nOA\npublications\n\ncomments,\nreviews,\nletters\n\nAuthors\n\nFigure 28: Data Sets and Information Systems Related to the PMC OAS\n\nIn summary, the unique advantages of the PMC OAS are:\n-\n\nThe open-access collection is large and contains scientific\narticles from many authors.\n\n-\n\nThe collection contains peer-reviewed articles from reputable\njournals, and the articles are freely available as open access\nfull-text.\n\n-\n\nThe PMC OAS provides articles in an XML-document format\nthat offers machine-readable markup for metadata and\ncitations.\n\n6.1 Methodology\n\n113\n\n6.1.6 Summary and Comparison of Test Collections\nWe found no single test collection suitable for a plagiarism detection evaluation\nthat fulfilled all five criteria: non-fabricated plagiarism, verified cases of\nplagiarism, available academic citations in the full-text, and a diversity of\nscientific documents (and ideally, but optionally machine-readable citations) as\ndescribed in Section 6.1.1.\nThe PAN-PC collection fulfills none of the outlined criteria, except for\ncontaining verified cases of plagiarism. The collection contains few academic\nworks, and these not in their entirety, meaning availability of full-texts is missing\nand citations – if present – are incomplete. Furthermore, most plagiarism in the\ncollection is artificially fabricated and does not reflect realistically disguised\nplagiarism.\nThe collection used for the HTW PDS Tests does not fulfill the outlined\ncriteria because most texts are artificially plagiarized essays under 1.5 pages,\nwhich contain few or no citations. The few strongly disguised, manually\ntranslated plagiarism cases in the collection are not sufficient to compile a test\ncollection of suitable size. A collection of partially plagiarized short answers\ncompiled by Clough et al. [72] is equally unsuitable, because the texts do not\ncontain citations.\nTable 12 shows the collection properties and the forms of plagiarism\ncontained in available test collections. No collection on its own is ideally suited\nfor an evaluation of the CbPD approach. However, by combining the unique\ncharacteristics of the GuttenPlag Wiki, the VroniPlag Wiki, and the PMC OAS,\nthe performance of CbPD can be evaluated on a combination of the most suitable\ncorpus characteristics.\n\n114\n\n6 Quantitative and Qualitative Evaluation\nTable 12: Characteristics of Test Collections for PD Evaluation\n\nPMC OAS 234,591\nGuttenPlag\n\nReal-world Wiki\n\nVroniPlag\nWiki27\n\nVerified real-world plagiarism\n\nCitations machine\nextractable\n\nCitations avail.\n‡\n\n9\n\nTranslation\n\n42\n\nParaphrase\n\nHTW\n\nShake &amp; paste\n\n26, 939\n\nStrongly\nDisguised\n\nCopy &amp; paste\n\nPAN-PC\n\nReal, non-fabricated\nPlagiarism\n\nCollection size by # of\ndocuments\n\nTest Collection\nFabricated\n\nSlightly\nDisguised\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\nIdea plagiarism\n\nPlagiarism Form\nCollection Properties\n\n?\n\n9\n\n9\n\n1\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n?\n\n23\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n9\n\n?\n\n? unknown\n‡insufficient citations available\n\nThe GuttenPlag Wiki features strongly disguised plagiarism instances and a\nvery thorough manual investigation that allows for one of the most accurate\nground truth approximations of any non-fabricated collection. These\ncharacteristics make it ideal for a primary evaluation of the detection\nperformance of CbPD. However, because all the plagiarism of the GuttenPlag\nWiki stems from a single author28, the results of analyzing this collection should\nnot be generalized. We bridge this weakness by including the VroniPlag Wiki\nplagiarism collection in the CbPD evaluation framework. The VroniPlag Wiki\n27\n28\n\nAs of 2012-05-10.\nAccording to the claims of Karl-Theodor zu Guttenberg.\n\n6.1 Methodology\n\n115\n\ncontains strongly disguised instances of plagiarism originating from many\nauthors, allowing an evaluation of CbPD for diverse plagiarism styles and\nacademic citing behavior.\nBoth the GuttenPlag and VroniPlag Wikis contain only verified instances of\nplagiarism. Therefore, the collections allow the retrieval only of true positives\n(TP), i.e. the actual plagiarism identified by CbPD in a collection of verified\nplagiarism. Detecting false positives (FP), i.e. text erroneously flagged as\nplagiarism, is not possible due to the missing full-texts and the uncertainty as to\nwhether examiners have identified all plagiarized text fragments. Despite the\nextremely thorough manual examinations, a small fraction of all plagiarism may\nnonetheless have escaped detection for both collections. Determining the number\nof false negatives (FN), i.e. plagiarism that remains undetected, and true\nnegatives (TN), i.e. non-plagiarized text rightfully not identified as suspicious, is\nalso not possible for the GuttenPlag and VroniPlag Wikis. Table 13 summarizes\nthe categories into which detection results can fall.\nTable 13: Detection Categories for Plagiarism\nPlagiarism\n\nNon-Plagiarism\n\nIdentified\n\nTrue Positive (TP)\n\nFalse Positive (FP)\n\nNot identified\n\nFalse Negative (FN)\n\nTrue Negative (TN)\n\nThe absence of FP and TN in the GuttenPlag and VroniPlag Wikis prevents\nestablishing a baseline for citation match occurrences, i.e. the rate of citation\nmatches that may legitimately occur among non-plagiarized documents. To\naddress these limitations, the PMC OAS is a valuable addition to the VroniPlag\nand GuttenPlag Wiki collections. Using the PMC OAS, we can test the ability of\nCbPD to identify yet undiscovered plagiarism in a large scientific collection\ncontaining diverse document types. This collection also allows for the\nquantifying of retrieved false positives. The main drawback of the PMC OAS\ncollection is the nonexistence of a ground truth, which must first be established.\n\n116\n\n6 Quantitative and Qualitative Evaluation\n\n6.2 Evaluation using GuttenPlag Wiki\nThe thorough manual investigation of plagiarism in the GuttenPlag Wiki can\nserve as a ground truth approximation, which is necessary for a comparative\nevaluation of available plagiarism detection methods with the CbPD approach.\nFor details on the GuttenPlag Wiki and its suitability as a test collection, please\nrefer to the discussion in Section 6.1.2. Previous evaluations, as presented in\nSection 2.3.1, show that disguised plagiarism is especially difficult to detect\nusing conventional character-based PDS. In the evaluation of CbPD, we\ntherefore examine the translated plagiarism in the GuttenPlag Wiki, because this\nform of plagiarism is one of the most difficult to identify and is not present in the\nlargest evaluation collection; refer to Section 6.4.\nAt the time of investigation29, the GuttenPlag Wiki identified plagiarized\npassages on 31 pages within the thesis, which had been translated from English\ninto German. We analyzed30 these 31 pages for matching citations with their\nidentified sources. To compare CbPD with currently used detection methods, we\nselected three popular character-based PDS:\nEphorus – ranked among the top three performing systems, featuring\n60 % –70 % detection accuracy in the 2010 HTW PDS Test\n[356].\nFerret (v. 4.0) – a free PDS that, like Ephorus, uses fingerprinting\n[203]. We ran the application with default settings, i.e., Ferret\nsearches for matching word tri-grams.\nWCopyFind (v. 3.0) – a free PDS using substring matching [35]. We\nran the application with default settings, except for the\ndetection parameters shortest phrase to match, which we\ndecreased to three words, and fewest matches to report, which\nwe decreased to 50 words.\n29\n30\n\n2011-04-10\nThis analysis has been published [132].\n\n6.2 Evaluation using GuttenPlag Wiki\n\n117\n\nBy choosing these three systems for comparison, we include one of the top\nscoring systems according to the HTW PDS Test, Ephorus, and we include\nsystems employing distinct character-based approaches: fingerprinting and\nsubstring matching. Ephorus requires payment from its users, while the other\ntwo systems are available free of charge. Because Ferret and WCopyFind depend\non local availability of possible source documents, we downloaded all digitally\navailable sources identified by the GuttenPlag Wiki project and provided them to\nthe PDS.\nThe results we obtained when using character-based PDS on the GuttenPlag\nWiki confirmed observations from prior PDS evaluations as discussed in Section\n2.3.1. Manually querying search engines, such as Google, yielded high detection\nrates for copy &amp; paste plagiarism. Depending on the time invested and keywords\nselected, we could even find paraphrased and translated plagiarism through\nmanual web searches.\nThe three PDS, especially Ferret and WCopyfind, which work with local\ndocument comparisons, delivered good results for identifying copy &amp; paste\nplagiarism, given that the sources were available. The performance of Ephorus\nwas disappointing. Despite the large fraction of (almost) verbatim plagiarism in\nthe thesis, the system found only 2 % of the text to match the sources of\nplagiarism. Given the online availability of 77 sources from which text sections\nwere plagiarized, and with only 63 sources not being available for free online\n[147], this result is unsatisfactory.\nAs expected, all three systems failed to identify 90 % or more of more\ncreatively paraphrased sections and could not detect a single instance of\ntranslated plagiarism. Table 14 gives an overview.\n\n118\n\n6 Quantitative and Qualitative Evaluation\nTable 14: Comparison of Detection Results\n\nPlagiarism form\n\nCharacter-based\n\nCitation-based\n\nCopy &amp; paste\n\n‫׽‬70 %\nGood results even for\nshort fragments\n\nUnsuitable\nShort fragments cannot be\ndetected\n\nDisguised plagiarism\n\n&lt; 10 %\n\nDepends on fragment length\n‫׽‬30 %\n\nIdea/structural plagiarism\n\n0%\n\nSome cases could be\nidentified\n\nTranslated plagiarism\n\n&lt;5%\n\n‫׽‬80 %\n13 out of 16 fragments\ncould be identified\n\nThe results should be treated with reservation, since it is uncertain whether\nthe GuttenPlag Wiki examiners identified all plagiarized fragments (see the\nrelated discussion in Section 6.1.2). The detection rates stated may therefore be\ntoo high, especially for the more difficult to detect idea plagiarism.\nFigure 29 shows the citation patterns of all translated plagiarism fragments in\nthe thesis of zu Guttenberg as identified by the GuttenPlag Wiki project. The\ndepicted patterns are the results of applying Citation Chunking according to\nstrategy two (see Section 4.4.4) or LCCS (see Section 4.4.2) to individual\nfragments. Except for pages 44, 226 and 300, all pages that contained translated\nplagiarism shared identical citations in a similar order with the source documents\nof the respective plagiarism. This becomes especially clear after cleaning the\ncitation sequences by removing unshared citations in both documents in their\ncorresponding positions. The last row of Figure 29 exemplifies this ‘cleaning’ of\ncitation sequences for the pages 242–244.\n\n6.2 Evaluation using GuttenPlag Wiki\nPage\n30\n39\n44\n223\n224\n225\n226 f.\n229 231\n232 233\n234\n235\n239\n240\n242\n242\n244\n246\n247\n267\n268\n300\n\n-\n\nSources\nBouton01\nGuttenberg06\nCRS92_Pream.\nGuttenberg06\nTushnet99\nVile91\nGuttenberg06\nCRS92_Art.V\nGuttenberg06\nVile91\nGuttenberg06\nCenturyFnd99\nCRS92_Art.V\nGuttenberg06\nVile91\nCRS92_Art.V\nGuttenberg06\nVile91\nVile91\nGuttenberg06\nCRS92_Art.V\nGuttenberg06\nCRS92_Art.V\nGuttenberg06\nCRS92_Art.V\nGuttenberg06\nVile91\nGuttenberg06\nMurphy00\nGuttenberg06\nBuck1996\n\n242 244\n\nCRS92_Art.V\nGuttenberg06\n\n242 244\n\nCRS92_Art.V\nGuttenberg06\n\n119\nCitation Pattern\n\nno shared citations\n\nno shared citations\n\nno shared citations\n\nLegend:\nBoxes of the same color represent in-text citations to identical\nsources.\nIntermediate blank boxes indicate one or more citations to\nnon-shared sources.\n\nFigure 29: Citation Patterns for Translated Plagiarism\n\n120\n\n6 Quantitative and Qualitative Evaluation\n\nWhile the character-based PDS were unable to detect a single instance of\ntranslated plagiarism, applying the citation-based approach allowed the\nidentification of 13 out of 16 translated plagiarized fragments in zu Guttenberg’s\nthesis. Given the thorough investigation undertaken by hundreds of volunteers,\nthis number provides a reasonably accurate quantification of total translated\nplagiarism detectable by the CbPD approach.\nD. Weber-Wulff and K. Köhler also analyzed the Guttenberg thesis using\nfive commercial character-based PDS and a ground truth derived from the\nGuttenPlag Wiki investigations [361]. Weber-Wulff and Köhler considered the\n20 source documents from which Mr. zu Guttenberg plagiarized the largest\nquantities of text, and measured which fraction of those source documents the\nsystems could identify. This approach is slightly different to ours, because we\nrecorded the percentage of plagiarism that the PDS could detect. Despite these\ndifferences, the results of the study were in line with our analysis. The worst\nperforming systems in the study of Weber-Wulff and Köhler, Ephorus and\nPlagScan, both of which identified only 5 % of the source documents. The best\nperforming PDS, iThenticate, identified 23 %. Of the 20 documents from which\nGuttenberg plagiarized most heavily, one source authored by Vile was in English\nand was the source of six instances of translated plagiarism [344]. Weber-Wulff\nand Köhler classified the article by Vile as “[...] maschinell unauffindbar”,\nmeaning it was “not machine detectable” [361].\nThe zu Guttenberg thesis shows that citations in translated and rearranged\ntext segments often remain in identical order, or in close proximity, which allows\nfor their detection using the proposed CbPD algorithms. Our evaluation of this\nreal-world plagiarism case demonstrates the unique strength of the CbPD\napproach in detecting strongly disguised plagiarism.\nTo view a visualization of a strongly disguised, translated text excerpt from\nthe Guttenberg plagiarism case visit the CitePlag prototype:\nhttp://www.citeplag.org/compare/6861131\n\n6.3 Evaluation using VroniPlag Wiki\n\n121\n\n6.3 Evaluation using VroniPlag Wiki\nThe VroniPlag Wiki collection of plagiarism served to evaluate the performance\nof the CbPD approach for confirmed plagiarism cases from a variety of authors\n[350]. For an overview of the characteristics that make the VroniPlag Wiki a\nsuitable test collection refer to Section 6.1.4.\nIn the VroniPlag Wiki, examiners either categorized plagiarized fragments as\n&quot;confirmed&quot; or as &quot;suspicious&quot; instances. For the purpose of the evaluations in\nSections 6.3.1 and 6.3.2, we only considered the text fragments31 labeled\n&quot;confirmed&quot;, approximately 92 % of total fragments in the collection, with the\nassumption that these instances generated no controversy about the presence of\nplagiarism.\nWe32 performed three distinct evaluations using the VroniPlag Wiki. The first\nexamined what fraction of plagiarism the CbPD approach could identify out of a\nrandom sample of plagiarized fragments containing different plagiarism forms,\nsee Section 6.3.1. The second evaluation tested the ability of CbPD to detect\ntranslated plagiarism, see Section 6.3.2, and the third examined a single\nplagiarism case to test whether sufficient citation-based similarity remains for\nCbPD to be effective for academic texts containing more creatively paraphrased\nor heavily disguised plagiarism, see Section 6.3.3. The results obtained using the\nVroniPlag Wiki collection are available for review and download as an Excel\nfile. See Appendix C for access details.\n\n6.3.1 Evaluation: Random Sample of Sources\nThe first evaluation using the VroniPlag Wiki tested the ability of CbPD to\nidentify confirmed instances of plagiarism regardless of the plagiarism form, i.e.\n\n31\n32\n\nAt the time of analysis: 2012-05-10. The VroniPlag Wiki project is ongoing and\nnew plagiarism instances are continuously added.\nI would like to acknowledge the contributions of all VroniPlag Wiki volunteers and\nthe help of Corinna Breitinger and Norman Meuschke in analyzing the corpus of the\nVroniPlag Wiki.\n\n122\n\n6 Quantitative and Qualitative Evaluation\n\ncopy &amp; paste, shake &amp; paste, paraphrasing, or translated plagiarism. The\nfollowing question was addressed:\nHow capable is the CbPD approach in identifying plagiarized\ndocuments out of a collection containing known plagiarism?\nTo select a random sample of plagiarism regardless of type, we considered\nthe 636 literature sources from which authors were known to have plagiarized31.\nFor the analysis, we only included the 198 source documents from which authors\nplagiarized at least five text fragments. These slightly more extensive instances\nof plagiarism are more likely to contain citations. Yet, the fragments may stem\nfrom any location in the text, e.g., the introduction may contain two plagiarism\ninstances, while the other three instances occur in the conclusion.\nShorter instances of plagiarism are less likely to adopt the citations of the\nsource document, which makes them difficult, if not impossible, to detect using\nCbPD. However, we do not see this as a threat to the value demonstrated by\nCbPD, because plagiarism spanning more than a few sentences is likely to\ncontain citations and thus be exposed using CbPD. Since existing systems\nalready perform well in identifying short copy &amp; paste plagiarism, being able to\nidentify more serious yet disguised plagiarism forms is of importance.\nFrom the 198 qualifying source documents from which at least five text\nfragments were plagiarized, we took a random sample of 25 sources. For each of\nthe 25 sources, we compared the citation patterns in the source to the citation\npattern in the respective fragments that plagiarized from the source.\nThis citation pattern analysis was performed manually. The following\nbarriers prevented an automatic extraction of citations. First, documents in the\nVroniPlag Wiki collection are from diverse disciplines, e.g., law, medicine,\nphilosophy, and engineering. Each discipline has its own unique citation styles,\nmaking automatic citation extraction error-prone. Second, the full-texts for most\nsource documents are not digitally available, making automatic citation\nextraction laborious, because the documents would have to be scanned and\nconverted into machine-readable text. Third, some citations contain errors, for\nexample, misspelled author names or incorrectly cited publication dates, which\n\n6.3 Evaluation using VroniPlag Wiki\n\n123\n\ncan more easily be corrected manually. For real-world document collections, the\npresence of some errors in citation information is unavoidable.\nBy choosing manual citation extraction over an automated extraction\napproach, we could achieve a higher accuracy and minimize extraction errors.\nThe citation information in the VroniPlag Wiki collection is at times incomplete,\nsince plagiarized fragments are presented as short excerpts taken from the fulltext (some only 1 to 3 lines). Additionally, we cannot be certain that all\ninvestigators consistently include citations when preparing the excerpts for\ninclusion in the collection. Whenever a document’s full-text was available\nonline, we accessed it to confirm the citations in the plagiarized fragments and in\nthe source. Yet, most full-texts were unavailable to us, which represents a source\nof error in this evaluation.\n\n6.3.1.1\n\nResults\n\nWe split the results into three categories, as shown in Table 15. The first\ncategory contains sources with five or more matching citations33 in close\nproximity, which is a strong indicator of plagiarism. The second category\nincludes sources with three to four matching citations in close proximity, which\nis a potential indicator of plagiarism. The third category contains sources with\ntwo or fewer matching citations, which is an insufficient indicator for potential\nplagiarism. Of the 25 randomly selected sources, nine sources shared clearly\nsuspicious citation matches with seven dissertations that plagiarized from these\nsources. The documents contained between six and 97 matching citations in\nclose proximity to each other. The dissertations from the authors with initials Dv,\nAwb, Bds, Mh, Ub, each contained suspicious citation matches with one source,\nwhile the works of Lm and Pes contained suspicious citation matches with two\nsources.\nIn addition to identifying seven dissertations as highly likely to contain\nplagiarism, CbPD also identified two dissertations, the works of the authors with\n33\n\nWe use the term “matching citations” for citations of identical sources, which a\nplagiarized document shares with the source document.\n\n124\n\n6 Quantitative and Qualitative Evaluation\n\ninitials Ah and Bds, with three or four matching citations, as possible plagiarism\ncandidates. The dissertations of another seven authors contained no citations, or\nfeatured insufficient citation pattern similarities to be identified as plagiarism\nusing the CbPD approach.\nIt is interesting to note that the plagiarist with initials Mh translated the text\nfrom LeBaron 2005 [188] (highlighted in gray in Table 15) from English to\nGerman. Being a translation, this example of plagiarism shares no literal text\noverlap with its source aside from a copied quote. Despite the low characterbased similarity in the plagiarized fragments, 18 citations are similarly arranged,\nallowing the CbPD approach to reliably detecting such cases of translated\nplagiarism.\nIn summary, we found the CbPD approach capable of reliably identifying a\nsignificant fraction of plagiarism. Of the 15 authors who plagiarized from the\nrandom sample of 25 sources, the CbPD approach could identify the theses of\nseven authors (‫׽‬47 %) as likely to have been plagiarized (green in Table 15).\n\n6.3 Evaluation using VroniPlag Wiki\n\n125\n\nTable 15: Citation Matches between Plagiarism and Source Fragments in the VroniPlag\nWiki\n# fragments\nPlagiarized\nfrom Source\n(൒ ૞)\n\nRand.\nSample\n#ID\n\nSource\nDocument\n(Author, Year)\n\nInitials\nof respective\nPlagiarist\n\n9\n\nRandelzhofer 1991b\n\nDv\n\n31\n\n97\n\n18\n\nVahl 1995\n\nAwb\n\n24\n\n93\n\n17\n\nStelkens 1998\n\nPes\n\n10\n\n24\n\n1\n\nNork 1992\n\nBds\n\n41\n\n21\n\n6\n\nSchurig 1981\n\nLm\n\n9\n\n21\n\n25\n\nLeBaron 2005\n\nMh\n\n6\n\n18\n\n14\n\nRoeser 1988\n\nUb\n\n17\n\n14\n\n13\n\nKropholler 1997\n\nLm\n\n14\n\n6\n\n23\n\nHoppe 1970\n\nPes\n\n5\n\n6\n\n21\n\nMartens 1995\n\nAh\n\n9\n\n4\n\n4\n\nHüffer 1995\n\nAh\n\n6\n\n4\n\n5\n\nKuehn Becker 1999\n\nBds\n\n5\n\n3\n\n3\n\nKrause 1998\n\nGc\n\n17\n\n1\n\n19\n\nLehmann 1984\n\nMw\n\n7\n\n1\n\n10\n\nTavlas 1993\n\nSkm\n\n5\n\n1\n\n7\n\nMathiopoulos 1983\n\nMm\n\n5\n\n1\n\n22\n\nStadtentwicklung 1991*\n\nSh\n\n71\n\n0\n\n15\n\nVeit 1969\n\nSkm\n\n10\n\n0\n\n8\n\nPuhle 1983*\n\nMm\n\n8\n\n0\n\n2\n\nIZMF (web)*\n\nVs\n\n7\n\n0\n\n11\n\nStadtumbau (web)*\n\nJg\n\n7\n\n0\n\n12\n\nHartje 1990\n\nBds\n\n7\n\n0\n\n16\n\nHarpprecht 1982\n\nMm\n\n7\n\n0\n\n20\n\nMathiopoulos 1982\n\nMm\n\n7\n\n0\n\n24\n\nHuber 2001\n\nBds\n\n6\n\n0\n\nCitation\nPattern\nMatches\n\n* no citations present in source document\n\nGreen: 5 or more citation order matches – very strong indication of plagiarism\nOrange: 3-5 citation order matches – likely indication of plagiarism\nRed: 2 or fewer citation order matches – insufficient indication of plagiarism\n\n126\n\n6 Quantitative and Qualitative Evaluation\n\n6.3.2 Evaluation: Translated Plagiarism\nThe second evaluation using the VroniPlag Wiki collection tested the\nperformance of CbPD on instances of translated plagiarism. The following\nquestion was addressed:\nHow many of the seven dissertations containing translated\nplagiarism can the CbPD approach identify?\nDiscovering strongly disguised forms of plagiarism containing little or no\ncharacter similarity is the strength of the CbPD approach. Thus, an evaluation of\nreal-world, heavily disguised plagiarism cases is central to assessing the\nperformance of CbPD. VroniPlag Wiki investigators found seven of the 23\nauthors34 to have engaged in translation plagiarism. These seven dissertations\ncontained a total of 146 translated fragments, of which 95 fragments (65 %)\nfeatured citation information. For the evaluation, we recorded the similarities in\ncitations between these 95 citation-containing translated plagiarism fragments\nand their sources.\n\n6.3.2.1\n\nResults\n\nWe split the results into three groups according to the success in identifying the\nplagiarized document using CbPD. The first group contains plagiarism with five\nor more citation pattern matches with their sources (a strong indicator of\nplagiarism). The second category contains plagiarism with three to four citation\npattern matches with their sources (a likely indicator of plagiarism) and the third\ncategory contains plagiarism with two or fewer citation pattern matches (an\ninsufficient indicator of plagiarism).\nOf the seven dissertations containing translated plagiarism, the dissertations\nof five authors showed a suspicious overlap in their citation order compared with\nthe confirmed sources from which they plagiarized. The translated plagiarism\ncases of the authors with initials Mm (two sources contained suspicious citation\noverlap), Mh (four sources contained suspicious overlap), and Gc, Awb and Skm\n34\n\nAs of 2012-05-10.\n\n6.3 Evaluation using VroniPlag Wiki\n\n127\n\nshowed between four and 24 matching citations in close proximity or in the\nidentical order as their source documents. Table 16 summarizes the findings.\nOf the 28 sources from which authors plagiarized, about one-third of sources\n(nine) contained three or more citations in an order similar to their respective\nplagiarized text. As pointed out in Section 6.3.1, we classified such similarity as\na likely indicator of plagiarism. The two dissertations the CbPD approach was\nunable to identify as suspicious (red in Table 16) featured only five and seven\ncitation-containing plagiarized fragments, while three of the four dissertations\nthat were identified as highly suspicious featured 20 or more citation-containing\nfragments.\nTable 16: Citation Matches for Translated Plagiarism in VroniPlag Wiki\nsource-based\noverview\n\nfragment-based\noverview\nPlagiarist\nInitials\n\nMm\nMh\nGc\nAwb\nSkm\nDv\nCs\nTotals\n\nFragments\nanalyzed\n\nFragments\ncontaining\ncitations\n\n33\n30\n24\n12\n30\n12\n5\n146\n\n26\n23\n20\n4\n10\n7\n5\n95\n\nFragments\ncontaining\nat least 1\nmatching\ncit. with\nsource\n18\n19\n6\n3\n4\n4\n1\n55\n\nSources\nfrom which\nplagiarist\ntransl.\nplagiarized\n4\n7\n3\n1\n6\n5\n2\n28\n\nHighest\ncitation\norder\nmatch\nfrom a\nsingle\nsource\n\nSources\nwith 3 or\nmore\nmatching\ncitations\n2\n4\n1\n1\n1\n0\n0\n9\n\n33\n17\n10\n6\n4\n2\n1\n-\n\nGreen: 5 or more citation order matches – very strong indication of plagiarism (LCCS match)\nOrange: 3-5 citation order matches – likely indication of plagiarism (LCCS match)\nRed: 2 or fewer citation order matches – insufficient indication of plagiarism\n\nFigure 30 visualizes the citation patterns of three translated plagiarism\ninstances compared with their source. Aside from a few insertions (white bars)\nand some minor transpositions in citation order, the citation patterns extending\nover several pages were suspiciously similar.\n\n128\n\n6 Quantitative and Qualitative Evaluation\n\nPage\n180-186\n\n219-252\n\n75-81\n\nSource Document\n\nCitation Patterns\n\nPlagiarism*\nM. Wool dri dge 2002\nHeun, Mi cha el ^\n\nLeBa ron 2005\nHeun, Mi cha el ^\nGuggi s berg 1971\nMa thi opoul os , M.^\n\n^ ful l text una va i l a bl e. Not a l l ci ta ti ons\nouts i de of pl a gi a ri zed fra gement s ecti ons\na re known.\n* Ci ta ti on pa tterns were a na l yzed on a\nfra gment-s ource ba s i s . Due to ful l text\nuna va i l a bi l i ty, the ci ta ti on pa ttern for the\ns um of fra gments gi ven i n Vroni Pl a g ma y\ns l i ghtl y di ffer from the compl ete ci ta ti on\npa ttern i n the ful l text.\n\nLegend\nLi nes of i dentical color represent in-text ci tations\nto the s a me sources.\nWhi te lines indicate one or more citations of nons ha red s ources.\nDi a gonally s tripped lines are inserted\ns pa ceholders. They do not represent citations,\na nd only s erve to better vi sullay a lign the\nma tching ci tations.\n\nFigure 30: Citation Patterns for Translated Plagiarism in the VroniPlag Wiki\n\nIn conclusion, the CbPD approach could identify five of the seven theses\ncontaining translated plagiarism as likely plagiarism, given their suspicious\ncitation pattern matches. The results show that the copying of citations, if present\nin the source, was common behavior among five of the seven plagiarists, even\nwhen the plagiarized text was translated. This observation of plagiarism behavior\nin VroniPlag Wiki indicates that the CbPD approach is promising for detecting\nstrongly disguised translated plagiarism in real-world plagiarism settings.\n\n6.3 Evaluation using VroniPlag Wiki\n\n129\n\n6.3.3 Evaluation: Plagiarism Case Heun\nInvestigations of Michael Heun’s dissertation [156] by VroniPlag Wiki\nexaminers found that the author plagiarized 56 text fragments35 from a single\nsource authored by Matthias Unser [337]. Most of these fragments are extensive\nand run more than a paragraph in length. The unique characteristic of Heun’s\nplagiarism from Unser is that it gives a realistic example of extensive plagiarism,\nin which the plagiarist invested much effort into disguising the plagiarism, e.g.,\nmasking copied text through synonym replacements or paraphrasing, while at the\nsame time copying citations. Both documents were available as full-text.\nAn examination of Heun’s plagiarism from the source document, tested the\nperformance of CbPD in identifying extensive, yet disguised academic\nplagiarism. The evaluation addressed the following question:\nAre fewer citations copied, or is the citation order transposed in\nsuch a way that CbPD may not be effective in a case where an\nauthor copies extensively, yet makes an effort to paraphrase and\ndisguise plagiarism?\nWe randomly selected 15 pages of Heun’s thesis for comparison against the\nsource document by looking up the first entry in the reference list of Heun’s\ndissertation (Aarts H.B.) and beginning the extraction of the 15-page excerpt on\nthe page where this source was first cited, on page 140 [156].\n\n6.3.3.1\n\nResults\n\nThe resulting consecutive 15-page excerpt of Heun’s dissertation contained 301\ncitations. Of these, 192 citations matched the respective citations in the source\ndocument in identical or only slightly transposed order. This represented a\n63.8 % citation overlap in a 15-page excerpt. Such high citation overlap is very\n\n35\n\nAt the time of analysis: 2012-06-10. The Frankfurt School of Finance and\nManagement retracted the doctorate of Michael Heun as of 2012-10-17, refer to\nhttp://de.vroniplag.wikia.com/wiki/Mh.\n\n130\n\n6 Quantitative and Qualitative Evaluation\n\nsuspicious and would be a strong indicator of potential plagiarism even in the\nabsence of character-based similarity.\nFigure 31 visualizes a 2-page excerpt from the 15-page citation pattern\nanalysis. The figure shows the citation patterns for pages 145–146 of Heun’s\nthesis on the left and the arrangement of citations in the source document by M.\nUnser on the right. Identical colors represent the individual matching citations or\nentire matching citation groups. Black lines in the figure separate the citation\ngroups. A citation group is defined as a collection of several references contained\nin a single in-text citation, for example, [author A, author B, author C] is a\ncitation group of size three. Note that for the full 2-page excerpt visualized in\nFigure 31, no non-shared citations were present.\n\n6.3 Evaluation using VroniPlag Wiki\n\n131\n\nPlagiat\n\nQuelle\n\nHehn 2007\n\nUnser 1999\n\nS. 145-146\nDörner (1990)\nDörner (1986)\nForkel (1995)\n,ĂƐƚŝĞ\u0003ĂŶĚ\u0003WĞŶŶŝŶŐƚŽŶ\u0003;ϭεερͿ\nKluwe (1990)\nKluwe (1995)\nKirsch (1988)\nNewell and Simon (1972)\nSeel (1991)\nSchwarz (1982)\nSternberg (1996a)\nBanyard et al. (1995)\nSimon (1979a)\nSlovic et al. (1977a)\nTergan (1986)\nZimbardo (1992)\nPervin (1987)\nKůĚĞŶďƺƌŐĞƌ\u0003;ϭεΘϭͿ\nFürstenau (1994)\nRichter (1996)\nTergan (1986)\nWessels (1984)\nDörner (1987)\nDörner (1988)\nKluwe (1979)\nZimbardo (1992)\nFürstenau (1994)\nDutke (1994)\nKluwe (1990)\nKluwe (1995)\nOpwis (1985)\nReason (1990)\nSeel (1991)\nSimon (1991)\nJohnson-Laird (1983)\nJohnson-Laird (1995)\nGentner und Stevens (1983)\nMcCain (1992)\nAnderson (1986)\nFürstenau (1994)\nSvenson (1988)\nPitz et al. (1976)\nSchneider (1992b)\nDörner (1986)\nHarte, Westenberg and Someren\nHogarth (1981)\nKirsch (1971)\nKozielecki (1975)\nPayne (1980)\nPitz und Sachs (1984)\nvan Raaij (1988)\nShafir, Simonson and Tversky\n\nS. 156-158\nDörner, D. (1990)\nForkel, M. (1995)\nHastie /Pennington (1995)\nKirsch, W. (1988)\nSchwarz, N. (1982)\nDörner, D. (1986)\nKluwe, R. H. (1990)\nKluwe, R. H. (1995)\nNewell, Simon (1972)\nSeel, N. M. (1991)\nSternberg, R. J. (1996a)\nBanyard, P. (1995)\nSimon, H. A. (1979a)\nSlovic, P./Fischhoff,\nTergan, S.-O. (1986)\nZimbardo, P. G. (1992)\nPervin, L. A. (1987)\nOldenbürger, H.-A. (1981)\nWessels, M. G. (1984)\nDörner, D. (1987)\nDörner, D. (1988)\nKluwe, R. (1979)\nZimbardo, P. G. (1992)\nFürstenau, B. (1994)\nRichter, A. (1996)\nTergan, S.-O. (1986)\nFürstenau, B. (1994)\nDutke, S. (1994)\nKluwe, R. H. (1990)\nKluwe, R H (1995)\nOpwis, K. (1985)\nReason, J. (1990)\nSeel, N. M. (1991)\nSimon, H. A. (1991)\nJohnson-Laird, P. N. (1983)\nJohnson-Laird, P. N. (1995)\nGentner, D./Stevens, A. L. (1983)\nMcCain, R. A. (1992)\nAnderson, N. H. (1986)\nFürstenau, B. (1994)\nSvenson, O. (1988)\nPitz, G. F./Leung, L. S. ...(1976)\nSchneider, S. L. (1992)\nCasey, J. T./Delquie, P. (1995)\nDörner, D. (1986)\nHarte, J. M./Westenberg, M. R.\nHogarth, R. M. (1981)\nKirsch, W. (1971)\nKozielecki, J. (1975)\nPayne, J.W. (1980)\nPitz, G. F./Sachs, N. J. (1984)\nRaaij, W. F. v. (1988)\n\nFigure 31: Citation Pattern Matches in the Dissertation of M. Heun\n\n132\n\n6 Quantitative and Qualitative Evaluation\n\nIn analyzing 15 pages of plagiarized text from a single source, we found that\nM. Heun copied citations almost without transpositions. To visualize not only\ncitation patterns, but also the typical text disguise of plagiarism found in Heun’s\nthesis, Figure 32 shows a side-by-side comparison of a plagiarized text excerpt\nand the source. Citations are renumbered from one through seven in both texts,\nsuch that identical numbers represent identical sources with lines drawn between\nthe matches. Although the texts are in German, knowledge of German is not\nrequired to see that sentence structure and word choice are notably different in\nthe plagiarism and source. Heun meticulously paraphrased the copied sentences\nand replaced key words with synonyms. In Figure 32, identical colors highlight\nsemantically identical text sections that have been paraphrased. Character-based\nsimilarity is limited. Only one fragment contains four words in identical order\nand three fragments contain two words in identical order. These character-based\nsimilarities are additionally underlined in Figure 32.\nPlagiarism: Heun 2007 [156]\npp. 139-140\n\nSource: Unser 1999 [337]\npp. 152-153\n\nLegend\nColored Text = semantic similarity (paraphrases/synonym word replacements)\nUnderlined = character-based similarity (two or more words in identical order)\nAus\ndem\nBlickwinkel\nder\nEntscheidungstheorie\nwerden diese\nDaumenregeln (rules of thumb) oft als\nirrational interpretiert [1]. Hingegen\nbetonen Vertreter ... Bewältigung der\nKomplexität der Umwelt [2].\nUntersuchungen zeigen, dass die\nVerwendung\nvon\nHeuristiken\nin\ndynamischen Situation oft effizienter\nsind als die statische klassische\nEntscheidungstheorie [3].\n\nDiese Daumenregeln können zwar auch\nzu einer zielkonformen Entscheidung\nführen, bieten aber keine Gewähr für die\nOptimalität der gefundenen bzw. für die\nExistenz irgendeiner Lösung. Während\naus entscheidungstheoretischer Sicht\neher die „Irrationalität“ dieser Regeln\nbetont wird, [1] stellen Vertreter ... Bewältigung der Umweltkomplexität in den\nVordergrund [2]. Ferner ist zu beachten,\ndaß die klassische Entscheidungstheorie\nstatisch ist und die be-obachteten\nHeuristiken in dynamischen Situationen\noftmals sehr effizient sind. [3]\n\n6.3 Evaluation using VroniPlag Wiki\nAls Folgen dieser simplifizierten\nSelektionsregeln können die folgenden\nPunkte identfiziert werden: [4] ...\n\nDazu\ngehören\ninsbesondere\ndie\nUminterpretation bzw. Vernachlässigung\nvon nicht passend erscheinenden\nInformationen [5], das nicht vollständige\nAufnehmen und suboptimale Verarbeiten\nvon Informationen aufgrund vergangener\nErfahrungen bzw. Gewohnheitsmäßiger\nVerhaltensweisen [6] sowie die\nReihenfolge der Informationsaufnahme\ngemäß dem subjektiven Grad der\nWichtigkeit [7].\n\nReferences\n\n133\nDie Anwendung dieser vereinfachten\nAuswahl-prinzipien führt jedoch auch\ndazu, daß [4] ...\nVorhandene Informationen werden\nzugunsten dieser Alternative interpretiert\nund widers-prüchliche Informationen\nvernachlässigt [5]. Ferner fuhren in der\nVergangenheit gemachte Erfahrungen\nbzw. gewohnheitsmäßige\nVerhaltensweisen dazu, daß\nentscheidungsrelevante Informationen\nnicht im erforderlichen Umfang\naufgenommen und suboptimal\nverarbeitet werden [6]. Der Grad der\nsubjektiven Wichtigkeit der Information\nbestimmt außerdem, welche\nInformationen in welcher Reihenfolge\naufgenommen werden [7]\nReferences\n\n[1] Vgl. Kahneman, Slovic und Tversky\n(1982).\n\n[1] Vgl. Kahneman, D./Slovic,\nP./Tversky, A. (1982)\n\n[2] Vgl. Anderson (1986), S. 83-88;\nBerens (1992); Groner, Groner und\nBischof (1983); Hogarth (1981); Lopes\n(1991); Pitz und Sachs (1984), S. 140;\nvan Raaij (1988), S. 79; Schaefer (1979),\nS. 398 sowie Tversky und Kahneman\n(1974). Die Anwendung von Heuristiken\nführt in (Simulations-) Experimenten\nhäufig zu nahezu optimalen Ergebnissen;\nvgl. Cason (1994); Gigerenzer und\nGoldstein (1996), S. 666; Thorn-gate\n(1980) sowie Schoemaker und Hershey\n(1996), S. 199.\n\n[2] Vgl. Anderson, N. H. (1986) S. 8388; Berens, W. (1992); Groner,\nR./Groner, M./Bischof, W. F. (1983);\nHogarth, R. M. (1981); Lopes, L. L.\n(1991); Pitz, G. F./Sachs, N. J. (1984) S.\n140; Raaij, W. F. v. (1988) S. 79;\nSchaefer, R. E. (1979) S. 398; Tversky,\nA./Kahneman, D. (1974). ln\n(Simulations-) Experimenten konnte\ndarüber hinaus gezeigt werden, daß die\nAnwendung von Heuristiken häufig zu\nnahezu optimalen Ergebnissen fuhrt;\nCason, T. N. (1994); Gigerenzer, G./\nGoldstein, D. G. (1996) S. 666;\nThomgate, W. S. (1980); Schoemaker, P.\n\n134\n\n6 Quantitative and Qualitative Evaluation\nJ. H./Hershey, J. C. (1996) S. 199.\n\n[3] Vgl. etwa Einhorn und Hogarth\n(1981) sowie Klein (1983).\n\n[3] Vgl. Einhorn, H.J./Hogarth, R.M.\n(1981); Klein, N.M. (1983).\n\n[4] Vgl. Aschenbrenner, Böckenholt,\nAlbert und Schmalhofer (1986), S. 68;\nGrunert (1982), S. 38-41 und S. 105;\nTyszka (1986), S. 159; Payne (1976), S.\n384; Unser (1999), S. 152 sowie Wedeil\nund Senter (1997), S. 61.\n\n[4] Vgl. Aschenbrenner, K.\nM./Bökenholt, U./Albert,\nD./Schmalhofer, F. (1986) S. 68;\nGrunert, K. G. (1982) S. 38-41, 105;\nTyszka, T. (1986) S. 159; Payne, J. W.\n(1976) S. 384; Wedell, D. H./Senter, S.\nM. (1997) S. 61\n\n[5] Vgl. Russo et al. (1996), S. 107;\nGilad et al. (1987), S. 67; Gilovich\n(Hrsg.) (1991), S. 62 sowie Hofacker\n(1985), S. 47.\n[6] Vgl. Aarts, Verplanken und van\nKnippenberg (1997).\n[7] Vgl. Ben Zur und Breznitz (1981), S.\n102; Kuß (1991), S. 58 sowie Hofacker\n(1985), S. 47.\n\n[5] Vgl. Russo, J. E./Husted Medvec,\nV./Meloy, M. G. (1996) S.107; Gilad,\nB./Kaish, S./Loeb, P. D. (1987) S.67;\nGilovic, T. (1991) S. 62; Hofacker, T.\n(1985) S. 46.\n[6] Vgl. Aarts, H./Verplanken,\nB./Knippenberg, A. v. (1997)\n[7] Vgl. Ben Zur, H./Breznitz, S. J.\n(1981) S. 102; Kuß, A. (1991) S. 58,\nHofacker, T. (1985) S. 47.\n\nFigure 32: Strongly Disguised Plagiarism in the Dissertation of M. Heun\n\nSeveral sections of Heun’s plagiarized text contain insufficient characterbased similarity to reasonably arouse suspicion using character-based PDS.\nCharacter-based systems generally require at least 15 % of n-grams, each\ncommonly spanning three to four words, to match in the analyzed text [85].\nHeun’s dissertation thus provides examples where character-based PDS would\nfail to identify plagiarism instances that CbPD can detect, e.g., the seven\ncitations in identical order from the short text excerpt in Figure 32 would be a\nstrong indicator of plagiarism.\nHeun’s real-world plagiarism case gives insight into our question of whether\ncitation order may be transposed by a plagiarist in such a way that CbPD\nbecomes unsuitable when an effort to paraphrase and disguise plagiarism is\n\n6.3 Evaluation using VroniPlag Wiki\n\n135\n\nmade. We found no evidence in this examined case of noticeably changed citing\nbehavior in an effort to conceal plagiarism, despite the author having made an\neffort to disguise character-based similarity. This observation is in line with the\nevaluations of the GuttenPlag and VroniPlag Wiki collections, confirming that it\nis common behavior among plagiarists to copy citations with little or no\nmodification. The CbPD approach thus shows promise in identifying even cases\nof heavily disguised academic plagiarism.\n\n6.3.4 Conclusion VroniPlag Wiki\nIn conclusion, all three VroniPlag Wiki evaluations confirmed a high tendency\nof plagiarists to copy citations, whenever these are present in the source\ndocument.\nThe first evaluation demonstrated the ability of the citation-based plagiarism\ndetection approach in identifying a significant percentage of academic plagiarism\nfrom a collection of known plagiarism. Of 15 authors who plagiarized from a\nrandom sample of 25 source documents, using the CbPD approach alone\nidentified seven theses as likely cases of plagiarism. The second evaluation\ndemonstrated that citation copying is common behavior among plagiarists even\nwhen text is translated. The CbPD approach identified five of the seven theses\ncontaining translated plagiarism as likely cases of plagiarism, solely because of\ntheir suspicious citation pattern matches. The third evaluation examined the\ncitation-copying behavior of a single plagiarist who invested considerable effort\ninto disguising his misconduct. Observations collected over a 15-page excerpt\nconfirmed that despite a high degree of textual disguise, citations were not\nsubstituted or transposed sufficiently to render the CbPD algorithms ineffective.\nIn examining the 23 dissertations in the VroniPlag Wiki we found that only\nthe plagiarized fragments contained in two doctoral theses, [149] and [280], did\nnot feature a single copied citation from a least one source document from which\nthey had plagiarized. However, since the VroniPlag Wiki collection of\nplagiarism is fragment based, it is possible that even these theses share some\ncitations with the sources from which they copied at some location within their\nfull-texts.\n\n136\n\n6 Quantitative and Qualitative Evaluation\n\nWe believe one reason why the real-world plagiarism cases of the VroniPlag\nWiki, including the Heun plagiarism case, feature no substitutions, or only very\nfew substitutions of plagiarized citations, is partly due to the individual reasons\nwhy authors choose to cite sources. The reasons for choosing certain citations are\nvery specific and replacing them requires considerable effort, and in some cases\nis impossible. See Section 4.1, for a discussion on author citation motivations\nand a list of common motivations.\n\n6.4 Evaluation using PubMed Central OAS36\nThis section presents an evaluation of the CbPD approach, using the PubMed\nCentral Open Access Subset (PMC OAS). This third and final evaluation\nassesses the practicability, usability, and computational efficiency of the CbPD\nalgorithms in detecting unknown instances of plagiarism in a large, real-world\ndocument collection.\nThe two previously presented evaluations using the GuttenPlag and the\nVroniPlag Wikis provided the following insights. Relying on the plagiarism\nidentified in the GuttenPlag Wiki as a ground truth approximation, the CbPD\napproach capably identified translated plagiarism. In the case of the VroniPlag\nWiki, the CbPD approach also demonstrated good detection performance in a\nmultiple author setting.\nHowever, for both test collections, the number of documents available for\nanalysis was relatively small and the instances of plagiarism had already been\ndetected. The known plagiarism containment of the GuttenPlag and VroniPlag\nWikis was used as a baseline against which we compared CbPD performance.\nWhile practical for evaluation purposes, the characteristic of known plagiarism\noccurrence is non-representative of the typical use case for PDS. The final\nevaluation using the PMC OAS collection is thus the most representative of a\n36\n\nA summary of this evaluation of CbPD using the PMC OAS collection has been\naccepted for publication in the Journal of the American Society for Information\nScience and Technology [135].\n\n6.4 Evaluation using PubMed Central OAS\n\n137\n\nrealistic plagiarism detection setting in that it checks for plagiarism on a largescale in a collection of scientific publications where the true manifestation of\nplagiarism is unknown.\nMost importantly, the PMC OAS collection is suitable for assessing the\neffectiveness and efficiency of CbPD in detecting plagiarism forms that have\nremained undetected using available approaches, such as skillful paraphrases or\nstructural and idea plagiarism, which are plagiarism forms potentially present in\nthe PMC OAS. The PMC OAS consists of 234,591 peer-reviewed articles37, by\napproximately 975,000 authors. Given that the articles in the PMC OAS\nappeared in reputable medical journals and passed the peer-review process, still\nundiscovered instances of plagiarism are likely to be sparse. If present, however,\nwe hypothesize that some instances of plagiarism will be more heavily disguised.\nA large collection is also more likely to offer a high diversity of academic\nwriting styles and various plagiarism forms. Additionally, the large collection\nsize allows testing the algorithms for their computational efficiency.\nThe evaluation approach pursued for the PMC OAS collection will target the\nmost pressing limitations of current PDS:\n1.\n\nDetection effectiveness for the diverse plagiarism forms –\ncurrent approaches are unable to reliably identify heavily\ndisguised plagiarism.\n\n2. The time and resource intensiveness of manual plagiarism\nverification – current approaches only visualize character-based\nsimilarity, not semantic similarity, which leads to an incomplete\ndocument representation for human examiners who must judge\npotential plagiarism.\n\n3. Computational efficiency of document comparisons – current\napproaches cannot perform exhaustive n:n comparisons of very\nlarge collections. They must limit collection size in an initial\n37\n\nAs of 2011-04-15.\n\n138\n\n6 Quantitative and Qualitative Evaluation\n\nheuristic retrieval step, which typically decreases detection\naccuracy; refer to Section 2.2.1.\nTo address these challenges, the following objectives are pursued using the\nPMC OAS collection.\nObjective 1: Assess the effectiveness of CbPD in the two stages of\nplagiarism analysis: the automatic detection phase, which includes\nheuristic retrieval, detailed analysis, and knowledge-based\nprocessing of the results (refer to Section 2.2.1); and the manual\nverification stage. A user study provides the ground truth for\ndocument suspiciousness and serves to measure user utility.\nCbPD effectiveness is measured in:\na.\n\nDetection performance – comparative performance\nevaluation of CbPD and character-based algorithms\n(automatic detection stage). This evaluation is twofold.\nFirst, we analyzed documents in an n:n fashion and\ngauged the ability of detection methods to rank highly\nthe document pairs that users identified as most\nsuspicious for each of the various plagiarism forms. In\na secondary, smaller 1:n evaluation, we analyzed the\nprecision and recall performance of the detection\nmethods that performed best in the n:n evaluation.\n\nb.\n\nUser utility – usefulness and potential time-savings of\nCbPD for the examiner (manual verification stage).\n\nObjective 2: Examine the computational efficiency of CbPD and\ncompare its average case time complexity in theory and in practice\nwith currently used character-based approaches.\nWe do not use the term plagiarism for any documents containing instances of\npotentially suspicious similarity unless the documents have been officially\n\n6.4 Evaluation using PubMed Central OAS\n\n139\n\nconfirmed by the earlier authors, or have already been retracted by the\nresponsible authorities. The following Sections 6.4.1 and 6.4.2 respectively\npresent the evaluation methodology for the PMC OAS collection and the CbPD\nevaluation results.\n\n6.4.1 Methodology\nThis section describes the methodology for the evaluation of CbPD using the\nPMC OAS corpus. At the core of the methodology is a four-step approach, as\nshown in Figure 33. The first three steps of the evaluation methodology will be\npresented in this section, while the final comparison of algorithm rankings to the\nuser-study-derived ground truth will be presented in the results, see Section\n6.4.2.\n\nPMC OAS Corpus\nPreprocessing\n\nApplying Algorithms\nand Pooling\n\nUser Study\n\nComparison of\nAlgorithm Rankings to\nUser-study-derived\nGround Truth\n\nFigure 33: PMC OAS Four-step Evaluation Methodology\n\n6.4.1.1\n\nCorpus Preprocessing\n\nThis section describes the composition of the PubMed Central Open Access\nSubset and the preparation of the corpus for the evaluation of CbPD. We\nexcluded 13,371 documents for being either unprocessable, non-relevant, i.e.\nnon-scientific or duplicates. Such cases included documents missing a text body,\n(e.g., scanned articles in image file formats) documents with multiple text\nbodies, (e.g., summaries of all articles in conference proceedings) and duplicate\nfiles. See Table 17.\n\n140\n\n6 Quantitative and Qualitative Evaluation\nTable 17: Excluded Documents\nCriterion\n\nDocuments\n\nFiles in PMC OAS\n\n234,591\n\nNo text body\n\n12,783\n\nMultiple text bodies\n\n117\n\nDuplicate files\n\n471\n\nProcessable documents\n\n221,220\n\nAfter parsing, we removed an additional 36,050 documents from the set of\nprocessable documents for containing incomplete or erroneous citations, e.g.,\ncitations referring to non-existent references, no citations, or no references. For\nmore details on the results of the data parsing; refer to the overview in Table 18.\nTable 18: Overview of Corpus Preprocessing Results\nCriterion\n\nDocuments\n\nCitations\n\nReferences\n\n221,220\n\n10,976,338\n\n6,921,249\n\nContaining no references\n\n35,369\n\n0\n\n-\n\nContaining no citations\n\n35,980\n\n-\n\n6,447\n\n68\n\n11,405\n\n4,722\n\nReferences without citations\n\n16,866\n\n-\n\n65,588\n\nNon-unique references\n\n10,746\n\n-\n\n32,122\n\n59\n\n474\n\n-\n\n185,170\n\n10,964,933\n\n6,910,080\n\nProcessable documents\n\nInconsistent citation count\n\nCitations without references\nTest collection\n\nSamples indicated that documents without citations and/or references are\ntypically short comments, letters, reviews or editorial notes that do not cite any\nother documents, or give references without in-text citations. Documents with\ninconsistent citation counts are texts in which the document’s internal numbering\nof citations, according to their sequential position in the text, is not strictly\n\n6.4 Evaluation using PubMed Central OAS\n\n141\n\nincreasing. Errors in stating the abbreviated numeric citations in the source\ndocuments are the main cause for this inconsistency.\nAn additional 16,866 documents contained citations and/or references that we\ncould not fully acquire. The reason for this was typically that citations were not\nmarked up properly in the XML source file, for instance, because the original\ntext states citations in figures or figure captions. We retained such documents in\nthe test collection, because retaining as well as excluding them can cause false\nnegatives, i.e. undetected documents with potentially suspicious similarities.\nHowever, the likelihood of false negatives is higher when documents with\nincomplete citations or references are excluded entirely instead of retaining the\ndocuments, and hence including at least the citation information that could be\nacquired.\nWe also retained 10,746 documents that listed the same reference multiple\ntimes in their bibliography. Because non-unique references may cause false\npositives, we checked all documents with high citation-based similarities for\nnon-unique references, and if applicable, determined the influence these\nreferences had on the similarity assessment.\nAn initial concern was that errors in the automated parsing and\ndisambiguation of references and citations might lead to insufficient data quality\nto apply the citation-based approach. However, at least in the case of the\nexamined dataset, the error margin for incorrectly parsed and/or disambiguated\nreferences and citations was approximately 14 %38. We tolerated this error rate,\nbecause comparatively small numbers of erroneously parsed citations are not as\ncritical for CbPD as for other IR tasks. To understand why, let us consider the\ntwo scenarios that arise from erroneously parsed citations.\nThe first scenario is when parsing errors affect one or both citations which do\nnot match in reality. Most likely, the extraction procedure would distort the\nbibliographic data of the two cited documents differently. In this case, the error\nwould have no effect because the detection algorithm would still not recognize\n38\n\nError of margin was calculated for a random sample of 100 manually examined\ncitations from the PMC OAS collection.\n\n142\n\n6 Quantitative and Qualitative Evaluation\n\nthe incorrectly parsed citations as a match. In the other, very unlikely, but\ntheoretically possible case in which the extraction procedure distorts two nonidentical citations in such a way that the detection procedure considers them\nidentical, the procedure could report a false positive. However, extraction errors\nof this sort are extremely rare and even if they do occur, reporting a false positive\nis unlikely, because a single matching citation is not sufficient to trigger\nsuspicion.\nThe second scenario occurs when parsing errors affect one or both citations,\nwhich match in reality. In this case, there is the chance of a false negative, i.e.\nthe detection algorithm does not recognize the match. However, the CbPD\ndetection algorithms require that several matching citations exist to trigger\nsuspicion. Furthermore, a user can lower the suspiciousness threshold to prevent\nerroneous citations from causing false negatives.\nThe final test collection included 185,170 documents. The analyzed test\ncollection represents only a small subset of the approximately 2.5 million fulltext documents available in PMC and an even smaller fraction of the 22 million\ndocuments available in PubMed. The National Library of Medicine, which hosts\nPMC and PubMed, allows bulk processing of full-texts only for the documents\nincluded in the PMC OAS. The restrained accessibility of full-texts is a\nlimitation of our evaluation, because we can only detect plagiarism within\ndocuments included in the PMC OAS and originating from other documents in\nthe PMC OAS. Yet, for the similarity assessment, the CbPD algorithms analyzed\nall identifiable citations and references within the documents. That is, if two\ndocuments being compared have cited identical sources outside the PMC OAS,\nthe CbPD algorithms consider these citations.\n\n6.4.1.2\n\nPreliminary Corpus Analysis\n\nA comprehensive preliminary analysis of the PMC OAS corpus was performed.\nWhile this was a crucial first step in gauging the composition of the corpus to\neffectively design the subsequent evaluation approach, it is not directly related to\nthe methodology described in the remainder of this chapter. Nevertheless, for a\ndeeper technical understanding the reader is encouraged to read the detailed\n\n6.4 Evaluation using PubMed Central OAS\n\n143\n\npreliminary analysis in Appendix A, pages 266–294. No discontinuity occurs if\nreading is resumed in the following section.\n\n6.4.1.3\n\nApplying Detection Algorithms and Pooling\n\nWe used the two character-based methods Encoplot39 (ENCO) and Sherlock40\n(Sher) as a baseline against which we compared the following seven citationbased detection methods:\n1.\n\nAbsolute Bibliographic Coupling strength (BC abs.)\n\n2.\n\nRelative Bibliographic Coupling strength (BC rel.)\n\n3.\n\nLongest Common Citation Sequence (LCCS)\n\n4.\n\nLongest Common Sequence of distinct citations (LCCS dist.)\n\n5.\n\nLongest Greedy Citation Tile (Max. GCT)\n\n6.\n\nLongest Citation Chunk – both documents chunked, considering\nconsecutive shared citations only, no merging step (CC bcn)\n\n7.\n\nLongest Citation Chunk – both documents chunked, considering\nshared citations depending on predecessor, no merging step\n(CC bpn)\n\nDue to limited resources available in the user study, we evaluated the citation\npatterns analysis algorithms, but not the scoring procedures for ranking the\nsuspiciousness of patterns, i.e. CF-Score and Cont.-Score introduced in Section\n4.6. Evaluating the influence of CF-Score and Cont.-Score on the results of each\ndetection algorithm would have required collecting significantly more examiner\njudgments. Because the number of user study participants and the feasible\nworkload for each participant were limited (see the section User Study Design,\npage 149 ff.), performing additional judgments would have required a reduction\n39\n40\n\nEncoplot received the most satisfactory score in the PAN 2009 competition, see\nAppendix A.6.\nSherlock is a popular open source PD software, see Appendix A.5.\n\n144\n\n6 Quantitative and Qualitative Evaluation\n\nof the number of judgments per algorithm, and hence decreased the significance\nof the results for the individual algorithms. For this reason, we limited the\ncurrent evaluation to the detection algorithms, and evaluated the influence of CFScore and Cont.-Score in a subsequent study.\nThe evaluation corpus comprised 185,170 documents from the PMC OAS as\ndescribed in the subsection Corpus Preprocessing, page 139.\nThe lack of known disguised plagiarism cases in the PMC OAS required\nanalyzing the collection in an n:n fashion to identify suspicious documents.\nCharacter-based detection methods, such as Encoplot and Sherlock, do not allow\nlimiting the number of document pairs to be analyzed without decreasing\ndetection accuracy. For optimal accuracy, Encoplot and Sherlock have to\ncompare each document with every other document in the collection, which\n݊\nequals ቀ ቁ comparisons with n being the number of documents in the collection.\n2\nAnalyzing the entire PMC OAS with Encoplot or Sherlock therefore requires\n185170\nቀ\nቁ = 17,143,871,865 comparisons, which are practically infeasible to\n2\nperform. Refer to Comparison of Computational Efficiency in the results section,\npage 176, for an estimation of processing times.\nTo our knowledge, no PDS capable of analyzing a collection in the size range\nof the PMC OAS is publicly available. By drastically limiting the number of\nanalyzed documents, some proprietary commercial PDS may be capable of\nchecking very large collections in an n:n-fashion. To reduce the retrieval space,\nthese systems typically compare heuristically selected text fragments and impose\nminimum amount of shared text as explained in Section 2.2.3. However,\napplying such heuristics has the inherent disadvantage of decreasing detection\naccuracy.\nCitation-based detection methods allow limiting the document collection to\nbe analyzed without compromising detection accuracy. Because documents that\ndo not share references, i.e. are bibliographically coupled, cannot possess\ncitation-based similarities, such documents can be excluded. The PMC OAS\ncontained 39,463,660 document pairs sharing at least one reference, meaning this\nwas the number of document pairs requiring analysis. Refer to Figure 57 in\n\n6.4 Evaluation using PubMed Central OAS\n\n145\n\nAppendix A.1 for a graph of the number of document pairs in the PMC OAS that\nshare 1, 2, 3, ..., etc. references.\nDue to the practical infeasibility of a full character-based n:n analysis, we\napplied Encoplot and Sherlock only to those 6,219,504 document pairs with a\nBibliographic Coupling strength &gt; 1. To our knowledge, Bibliographic Coupling\nstrength has thus far not been used as a criterion for limiting the document\ncollection for plagiarism detection. Although this limitation may lead to the\nexclusion of some true positives, we consider this approach to be an acceptable\ntrade-off given the current infeasibility of a collection-wide character-based n:n\nanalysis for such a large collection.\nWe hypothesize that the loss of detection performance in the n:n setting is\nminimal, given the strong positive correlation between character-based and\ncitation-based similarity. Figure 34 shows this positive correlation between the\nBC strength of documents in the PMC OAS corpus compared to their\ncharacter-based Encoplot similarity score. For each Bibliographic Coupling\nstrength, the Encoplot scores of 20 randomly selected document pairs are plotted\non the vertical axis. The smallest dots represent single occurrences and the\nlargest dots represent up to 20 occurrences.\nFigure 57 in Appendix A.1, on page 267, shows the total number of\ndocuments in the PMC OAS for the various coupling strengths.\n\n146\n\n6 Quantitative and Qualitative Evaluation\n\nFigure 34: Correlation between BC Strength and Enco Score in the PMC OAS\n\nAlternatively, we could have limited the number of documents for the n:n\ncomparison using Encoplot and Sherlock by first applying character-based\nheuristics like fingerprinting, keyword-based clustering, or VSM retrieval. This\napproach may have eliminated fewer true positives than citation-based filtering,\nbut would have required additional implementation effort. Conceptually, both the\ncharacter-based and the citation-based filtering approaches are heuristics, and\nthus the results are collection-specific and hardly predictable.\nTo substantiate our hypothesis that Bibliographic Coupling strength and\nEncoplot score strongly correlate for suspicious documents, we additionally\nperformed an ex post n:n analysis of the top-20 most suspicious documents as\nidentified in the user study (see Section 6.4.2 on page 168). Since we did not\nfilter for Coupling Strength it took several weeks on a quad-core system to\ncompute the Encoplot scores for these 20 documents with all other documents in\nthe PMC OAS corpus. The results supported our hypothesis; the sample did not\n\n6.4 Evaluation using PubMed Central OAS\n\n147\n\ncontain a single publication pair with a high Encoplot score that was not\nbibliographically coupled.\nTo establish a ground truth for the main n:n evaluation, we pooled the top-30\nranked document pairs returned by each of the nine detection algorithms and\npresented the pooled results to human examiners for relevance judgment on\ndocument suspiciousness. Pooling is a common approach for the collection of\nrelevance judgments [209], e.g., applied in IR systems comparisons such as\nTREC, NTCIR, or CLEF [49], because judging all retrieval results is practically\ninfeasible for most IR tasks.\nFigure 35 illustrates the described document selection procedure for the main\nn:n evaluation. The methodology is described in detail in the subsection User\nStudy Design on page 149.\nPMC OAS\nDatabase\nENCO, Sher, BC abs., BC rel.,\nLCCS, LCC dist., GCT, CC bcn, CC bpn\n\ndetection\nalgorithms\n\nTop 30\ndoc. / alg.\n\nPooling\nhuman judgement\n\nuser study\n\nGround truth\nreference collection\n\nFigure 35: Applying Detection Algorithms and Pooling for n:n Evaluation\n\nFor the subsequent, smaller 1:n evaluation, we did not limit the comparisons\nto documents with a BC strength &gt; 1, because the processing time for comparing\nthe chosen query documents to the collection was only two weeks. For this 1:n\n\n148\n\n6 Quantitative and Qualitative Evaluation\n\nevaluation we pooled for each form of plagiarism, the five document pairs users\nrated most suspicious in the n:n evaluation. The subsection Precision-Recall\nCurve for Best Performing Approach, page 168, presents details on the\nmethodology and results of this analysis.\n\n6.4.1.4\n\nAddressing False Positives\n\nThe retrieval of false positives (FP) is a universal problem for PDS. In this\nsection we explain the pre-user study false positive reduction strategy that\naddresses the collection-specific documents prone to being retrieved as false\npositives. In the evaluation of the PMC OAS, two additional factors contributed\nto FP retrieval.\n– The first pooling process was carried out as an n:n document\ncomparison, while the typical PD use case is a 1:n comparison. A\nn:n comparison of a large collection the size of the PMC OAS\n(‫׽‬200,000 documents) naturally also results in the retrieval of a\nhigh number of legitimate document similarities.\n– The peer-review of publications in the PMC OAS yields a\nrelatively low expected ratio of plagiarism, which makes the\nretrieval of a high number of legitimate document similarities\nmore likely.\nIn pooling the top-30 retrieval results of each detection method for user\ninspection, we found that character-based detection methods in particular flagged\nmany documents legitimately sharing text similarity as suspicious. Documents\nwith very high similarity, which happened to be considered as legitimate text\nreuse in the PMC OAS, were most typically editorials and updates.\n– editorials – texts written by journal editors or publishers, which\nprovide publishing guidelines, state the policies of journals on\nsuch matters as publishing fees or open access, etc., are commonly\n&quot;recycled&quot; among journals without citing the source. Our\n\n6.4 Evaluation using PubMed Central OAS\n\n149\n\ndefinition of editorial false positives exclusively contained articles\nof non-scientific nature.\n– updates – corrections, annual medical standards updates, or best\npractices updates for certain fields and medical conditions. The\nsame panel or medical association, e.g., American Diabetes\nAssociation, often publishes annual updates.\nTo avoid punishing character-based algorithms, and to a lesser extent\ncitation-based algorithms, in the performance evaluation for correctly detecting\nthese documents, we manually excluded editorials and updates before presenting\ndocument pairs to user study participants for rating.\nIn addition to the two excluded document types named above, documents\nciting each other – given the citation style was machine-identifiable – were\nexcluded from analysis. This exclusion reduced the number of FP that correctly\nreferenced the source. Articles with shared author sets were also filtered and\nexcluded to reduce the number of FP resulting from legitimate author\ncollaboration. For the purpose of the evaluation, this means potential\nself-plagiarism was not examined.\nDespite applying a strategy for false positive reduction as described,\nadditional false positives were identified in the user study. These user-classified\nfalse positives were caused by different reasons than the ones filtered for here,\nand are presented in detail in the subsection Retrieved False Positives on page\n179.\n\n6.4.1.5\n\nUser Study Design\n\nThe user study addresses the first evaluation objective, the identification and\nverification of document suspiciousness using the CbPD prototype.\nPooling the top-30 results of the nine evaluated detection methods resulted in\n270 document pairs, as described in the subsection Applying Detection\nAlgorithms and Pooling, page 143, of which 181 were unique. We randomized\nand presented the unique pairs to 26 user study participants for a blind, web-\n\n150\n\n6 Quantitative and Qualitative Evaluation\n\nbased evaluation using the CitePlag prototype. Table 19 gives an overview of the\nnumbers pertaining to the design of the user study.\nTable 19: User Study Statistics\nParticipants\nGroup 1: Undergraduates\n\n11\n\nGroup 2: Graduate students\n\n10\n\nGroup 3: Medical experts\n\n5\n\nTotal study participants\n\n26\n\nDocuments\nExamined documents\n41\n\n181\n\nDuplicates\n\n89\n\nTotal top-30 documents\n\n270\n\nTime\nAvg. time participant spent / document pair\n\n6.32 min.\n\nAvg. time participant spent for evaluation\n\n~2.2 hours\n\nTotal time spent by all examiners\n\n~57 hours\n\nStudy participants had three levels of background knowledge in medicine.\nThe first group comprised 11 undergraduate students from non-medical majors,\nthe second group comprised 10 graduate students, and the final group comprised\nfive experts from the medical field. This three-group approach allowed observing\nthe potential influence of expertise on document suspiciousness-rating,\nvisualization preference, or time needed to arrive at a conclusion on document\nsuspiciousness. Rather than labeling documents as plagiarism or non-plagiarism,\n\n41\n\nSome document pairs were among the top-30 results for more than one approach.\nDuplicate pairs were rated only once.\n\n6.4 Evaluation using PubMed Central OAS\n\n151\n\nwe asked participants to conduct the examination of documents with the\nfollowing objective in mind:\n“Consider viewing a retrieved document pair as relevant if\nsimilarities exist that an examiner in a real check for plagiarism\nwould likely find valuable to be made aware of.”\nThis criterion is in line with what we deem to be an examiner’s information\nneed in a real plagiarism detection scenario. For each document pair – if\nexaminers deemed the result to fulfill the above criterion – participants were\nasked to provide the following:\n-\n\nsuspiciousness rating (see Table 20, right column)\n\n-\n\npotential plagiarism form (see Table 20, left column)\n\n-\n\nsimilarity visualization method perceived to be most suitable\n(rated by a sub-group of participants)\n\nAdditionally, we tracked the time participants required to submit each rating.\nTo ensure consistent human judgment, as far as consistency can be expected in a\nsubjective human rating task, an online submission form provided uniform\nguidelines. The guidelines included the definitions of plagiarism forms42 and the\nrating criteria for document suspiciousness, as shown in Table 20. Note that\nthese guidelines are only intended to categorize the level of document similarity,\nwhich may potentially point to suspiciousness.\nNo guidelines can provide a straightforward formula by which a document\ncan be classified as plagiarism. For the definition of plagiarism used in the thesis,\nas well as in this evaluation, refer to Section 2.1.1.\n\n42\n\nRefer to Section 2.1.2 for the full list of plagiarism forms and their definitions. Table\n20 gives an abridged version of plagiarism form definitions, as presented to user study\nparticipants, with the definitions tailored to the characteristics of the PMC OAS.\n\n152\n\n6 Quantitative and Qualitative Evaluation\nTable 20: Guidelines as Presented to User Study Participants\n\nPotential plagiarism form – definition\nguidelines\n\nDocument suspiciousness –\nrating guidelines\n\nConsider viewing a retrieved document pair as relevant if similarities exist that an\nexaminer in a real check for plagiarism would likely find valuable to be made aware of.\nPlease refer to the following definitions\nto categorize the prevailing form of\nsimilarity:\ncopy &amp; paste – verbatim copying, with\nlittle or no re-writing or restructuring\nshake &amp; paste – verbatim copying, with\nsome re-writing, e.g., inserting or\ndeleting words, rearranging text, or\nrestructuring\nparaphrase – copying is disguised by\nsynonym replacements, use of own\nstyle and terminology, or careful\nrewriting and change of syntax\n\nPlease refer to the following guideline\nto rate document suspiciousness:\n1\n\ninteresting similarities in some\ndocument sections – likely to have\nread the older article\n\n2\n\nstrong similarities in some sections\nof document – likely to have read\nand been inspired by the older\narticle\n\n3\n\nsuspiciously strong similarities in\nthe document – extremely likely to\nnot only have read, but also copied\nsome text, citations, ideas or graphs\nand figures\n\n4\n\nvery suspicious similarities with\ncertain signs pointing to plagiarism,\ni.e. high text overlap, copying of\nlong citation patterns; ideas, graphs\nor figures appear copied\n\n5\n\nextremely suspicious similarities\nwith obvious plagiarism intent\n\nstructural and/or idea plagiarism43 –\ndocument structure shows similarity\nor inspiration derived from the earlier\narticle, e.g., many citations are\npresented in the same/similar order,\nauthor may not have independently\nresearched all sources and copied\ncitations instead. Authors may have\nreceived inspiration from ideas,\n43\n\nInstances of shake &amp; paste plagiarism and paraphrases can also simultaneously\ncontain structural and idea plagiarism. However, for the purpose of this user study, we\nreserved structural and/or idea plagiarism specifically for documents without highly\nsuspicious text overlap. Refer to Section 2.1.2 for more definitions of plagiarism\nforms.\n\n6.4 Evaluation using PubMed Central OAS\n\n153\npresent, i.e. clearly unoriginal text,\nideas, methodology, graphs and\nfigures or citations and literature\nreviews, etc.\n\narguments, document methodology,\nresults, conclusions, or reviews of\nliterature without giving credit.\nnon-plagiarism (FP) – document pair\nshows no notable, or no interesting\nsimilarity that could point to\nunoriginal content. If content is\nshared, it is correctly cited\n\n0\n\nfalse positives, e.g., document pair\nis genuinely non-similar,\nunrecognized shared authors, or\nduplicate publications44\n\nNote that documents retrieved by the algorithms, or classified in the user\nstudy, will only be termed plagiarism if they have been officially reviewed and\nconfirmed by either PubMed or the issuing journal.\nTo guarantee identical document representation for all study participants, the\nCitePlag display settings for document representation were set as follows: (1)\nshow text highlights, (2) highlight citations, (3) show connections between\nmatching citations, (4) show document browser, and (5) minimum charactermatch length to be highlighted was set to the value 16.\n\n44\n\nSome instances of document pairs with shared authors, including duplicate\npublications, were falsely retrieved as plagiarism, despite our effort to preprocess the\ndataset and eliminate shared author sets; refer to Corpus Preprocessing on page 139.\nWe asked users to flag these cases and subsequently inspected false positives\nmanually to identify why they failed to be excluded in the preprocessing step and if\nfuture improvements may prevent this. We excluded false positives attributable to\npreprocessing errors from the results so as not to unjustly skew detection\nperformance, see Addressing False Positives on page 148. The objective is to\ndetermine the quality of the detection algorithms, not the quality of the preprocessing\nprocedure.\n\n154\n\n6 Quantitative and Qualitative Evaluation\n\nFigure 36: CitePlag Document Visualization for User Study\n\nIn addition to categorizing the form of document similarity and submitting a\nsuspiciousness rating, users were also asked to indicate whether they viewed text\nsimilarity visualization or citation-visualization as more suitable for arriving at a\nconclusion regarding suspiciousness for each of the four forms of potential\nplagiarism. A subset of examiners participated in a small-scale evaluation of user\nutility for the citation visualization approach, in which we recorded the time\nexaminers spent for document examination, from URL-retrieval in the CitePlag\nprototype to submission of the first identified document similarities.\nExaminers had the opportunity to provide comments on notable document\ncharacteristics or the level of confidence in their judgments. The user study\nconcluded by questioning participants on how useful they perceived the citationbased approach. See Appendix F for a selection of responses.\nPerceptions of plagiarism and its severity vary, especially for disguised\nplagiarism (refer to Section 6.1.2). Therefore, we regarded deriving a binary\nground truth, which categorized documents as either plagiarized or\nnon-plagiarized, as unsuitable for a quantitative analysis of detection rates.\nInstead, we adopted the following evaluation procedure:\n\n6.4 Evaluation using PubMed Central OAS\n\n1.\n\n155\n\nWe selected all documents that were assigned a suspiciousness\nscore, ‫ &gt; ݏ‬0, by at least one user study participant.\n\n2.\n\nThese documents were grouped by plagiarism form, as\nindicated by the expert judge, for each document pair.\n\n3.\n\nFor each document pair, the weighted average of the scores\nassigned by the three groups was calculated as: ‫ݏ‬ҧ =\n(‫ݏ‬௨ + 1.25‫ݏ‬௚ + 1.5‫ݏ‬௘ )Τ3.75, where ‫ݏ‬௨ denotes the score\nassigned by undergraduate students, ‫ݏ‬௚ the score assigned by\nmedical graduate students, and ‫ݏ‬௘ the score assigned by medical\nexperts. The number of scores assigned for each document pair\nwas three (one score from each group).\n\n4.\n\nFor each group of the same plagiarism form, we ordered the\ndocuments by decreasing ‫ݏ‬ҧ .\n\n5.\n\n6.4.1.6\n\nTo obtain the user-study-derived ground truth, we selected the\n10 top-ranked documents.\n\nLimitations of PMC OAS Evaluation\n\nThis section describes the specific challenges unique to the PMC OAS document\ncollection and the limitations inherent to the user study approach. For an\noverview of general challenges to PD evaluations, e.g., establishment of a\nground truth and the inconsistency of human judgment regarding plagiarism, as\nwell as the limitations associated with the use of real-world document\ncollections, refer to Section 6.1.2.\nPMC OAS Collection-Specific Limitations\nAn inherent challenge of the PMC OAS collection for PD evaluations is its\nassumed low level of plagiarized content. The publications originate\npredominantly from peer-reviewed medical journals. Previous studies on the\nnumber of duplicate publications in select medical journals found low rates of\nduplicate text ranging from ‫׽‬0.7 % [95] to ‫׽‬2 % [66]. Errami et al. found only\n\n156\n\n6 Quantitative and Qualitative Evaluation\n\n0.04 % of a sample of abstracts from different authors in Medline to show high\ntext similarity [104]. If we assume a similar rate of duplicate text in the PMC\nOAS, we can estimate the PMC OAS to contain ‫׽‬120 cases of duplicated text, of\nwhich only a fraction thereof may be attributable to plagiarism45 [104]. This\nleads to the assumption that detecting yet undiscovered plagiarism will be more\nchallenging than, for example, detecting plagiarism in a collection of student\nassignments.\nTo gauge the validity of this assumption, we searched the PubMed database\nfor publications that had been retracted for plagiarism, but were still available\nonline. We identified 28 such retraction notices. Of these, only five provided the\nPMCIDs of the sources from which had been plagiarized. None of the sources,\nhowever, were included in the PMC OAS, which means we found no instances\nof known plagiarism for which both document pairs would have been available\nin the Open Access Subset. While we identified only this sparse number of\nretractions due to plagiarism and no cases of retracted plagiarism that were selfcontained in the PMC OAS, it is likely that older retractions remain available\nonline only for a limited time, or that not all retraction notices are published\nonline.\nPlagiarism content in the PMC OAS may also have been reduced by earlier\ndetection using character-based PDS, or as a result of earlier examinations of the\nPMC OAS corpus, for example, the experiments carried out by a team of the\nGarner Lab [202, 321]. Especially non-disguised plagiarism forms are more\nlikely to have been detected and removed, e.g., employing character-based PDS\nin the journals’ submission process. With character-based PDS likely to have\nprevented instances of plagiarism with high character-based similarity from\nentering the collection in the first place, the results of this evaluation are only\nrepresentative of other collections to a limited extent.\n\n45\n\nAddressing False Positives on page 148 explains why high textual overlap among\npublications in the PMC OAS does not necessarily indicate plagiarism.\n\n6.4 Evaluation using PubMed Central OAS\n\n157\n\nUser Study Limitations\nA limitation inherent to the user study is the potential for data presentation bias,\nsince human judgment on plagiarism can vary depending on the visual\nrepresentation of a document’s similarity, for example, red vs. green text\nhighlights, or bold vs. weak lines connecting matching citations.\nThat user study participants come from different backgrounds introduces\nanother bias. The diversity of examiners, however, is representative of real\nplagiarism investigations. In the plagiarism investigation of Annette Schavan, for\nexample, the members from the faculty council who decided the case included\nthree student representatives, and not solely experts in pedagogy, the field in\nwhich Ms. Schavan had received her doctorate [152, 153].\nDue to the challenges of judging whether text similarities truly represent\nundue text use, see Section 6.1.2, we refrain from classifying documents as\nplagiarism if the responsible authorities have not yet confirmed the suspicion.\nPublications in the review process will be referred to only in an anonymized\nform in which the first and last digits of the unique PMCIDs have been removed.\nEvaluation results are made available online on a password-protected website46,\nwhere we encourage interested individuals to arrive at their own judgments.\n\n6.4.2 Results\nThe data collected in the user study and the analysis presented in this section is\navailable for download; refer to Appendix C.\n\n6.4.2.1\n\nComparison of Effectiveness\n\nThis section addresses Evaluation Objective 1, as explained in Section 6.4. The\nretrieval results of the seven citation-based and the two character-based detection\nmethods are evaluated, and their effectiveness in identifying the different forms\nof plagiarism is compared against a user-study-derived ground truth.\n\n46\n\nRefer to Appendix C for access details.\n\n158\n\n6 Quantitative and Qualitative Evaluation\n\nOverview of Retrieval and Ranking Performance\nIn the evaluation using the GuttenPlag Wiki in Section 6.2, we observed\ncitation-based methods to achieve higher detection rates for disguised plagiarism\nin comparison to character-based detection methods. Evaluating the effectiveness\nof the CbPD algorithms using the PMC OAS presents the first evaluation\nassessing whether this observation also holds for a large-scale, realistic\nplagiarism detection setting.\nRanking and presenting documents in decreasing order according to their\nsuspiciousness is crucial to the usefulness of PDS. In the typical use case, a\nmanual inspection is feasible only for the highest ranked documents. Therefore,\nwe consider the rank at which a detection method retrieves a suspicious\ndocument pair as the critical measure of effectiveness. To compare the\neffectiveness of detection methods in this ranked retrieval task, we derived a\nground truth by means of a user study, as described in Section 6.4.1.\nThe analysis of detection effectiveness gauged the precision of each detection\nmethod in identifying and ranking the different plagiarism forms: (1) copy &amp;\npaste, (2) shake &amp; paste, (3) paraphrased and (4) structural and/or idea\nplagiarism. For this purpose, we grouped document pairs by their potential\nplagiarism forms as determined in the user study. From each group, we selected\nthe set of ten document pairs with the highest combined user-assigned\nsuspiciousness scores ignoring order.\nTo confirm the presence of agreement regarding document suspiciousness\namong examiners above the agreement rate that could be expected by chance we\ncalculated Fleiss&#x27; Kappa (݇):\n݇=\n\nܲത െ ܲത௘\n1 െ ܲത௘\n\n(6.1)\n\nIn Equation 6.1, ܲത presents the observed agreement, while ܲത௘ presents the\nhypothetical probability of chance agreement. Thus, ܲത െ ܲത௘ represents the degree\nof agreement actually achieved above chance and 1 െ ܲത௘ represents the degree\nof agreement that is attainable above chance. Inter-rater agreement for all\nplagiarism forms was calculated as 0.65, indicating the presence of substantial\n\n6.4 Evaluation using PubMed Central OAS\n\n159\n\nagreement among examiners on the degree of document suspiciousness. Kappa\nwas highest for copy &amp; paste, ݇ = 0.73, and lowest for structural and idea\nplagiarism, ݇ = 0.59. This observation is in line with the larger discrepancies in\nhuman judgment for the more challenging task of judging disguised plagiarism\nforms.\nFor each of the ten document pairs, we determined if, and at which rank, the\nindividual detection method identified the pair. If detection methods assigned the\nsame score and therefore the same rank ݅ to multiple documents, the mid rank ‫ݎ‬ҧ௜ ,\nwas calculated as ‫ݎ‬ҧ ௜ = ‫ݎ‬௜ିଵ + (|݀௜ | െ 1)Τ2 and assigned to all documents\n݀௜ with initial rank ݅.\nThe four box plots on the following pages show the distributions of ranks;\none plot is given for each form of plagiarism. Each box plot includes a data table\nshowing the values for the minimum rank (Min.), the first quartile (Q1), the\nmedian, the third quartile (Q3), the maximum rank (Max.) and the mean of the\ndistribution.\n\n6 Quantitative and Qualitative Evaluation\n\nCopy &amp; Paste\n2.10\n1.85\n\nCopy &amp; Paste\n\nThird Quartile\nFirst Quartile\nMean\n\n1.65\n1.35\n1.20\n\n1.25\n\n1.20\n1.10\n\nSherlock\n\nEnco\n\nLCCS\ndist.\n\nCC40\n\nLCCS\n\nBC rel.\n\nCC42\n\n1.00\n\nGCT\n\n2.2\n2.1\n2.0\n1.9\n1.8\n1.7\n1.6\n1.5\n1.4\n1.3\n1.2\n1.1\n1.0\n0.9\n\nBC abs.\n\nRank\n\n160\n\nBC\nabs.\n\nBC\nrel.\n\nGCT\n\nCC40\n\nCC42\n\nLCCS\n\nLCCS\ndist.\n\nEnco\n\nSherlock\n\nMin\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\nQ1\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\nMedian 1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\n1.00\n\nQ3\n\n1.25\n\n2.00\n\n1.63\n\n2.00\n\n1.13\n\n1.00\n\n1.25\n\n1.00\n\n1.00\n\nMax\n\n2.00\n\n2.00\n\n2.80\n\n9.00\n\n9.00\n\n2.00\n\n2.00\n\n1.00\n\n3.50\n\nMean\n\n1.20\n\n1.35\n\n1.65\n\n2.10\n\n1.85\n\n1.10\n\n1.20\n\n1.00\n\n1.25\n\nFigure 37: Distribution of Ranks for Top-10 Document Pairs for Copy &amp; Paste\n\nFigure 37 shows the distribution of ranks for copy &amp; paste. The characterbased detection method Encoplot performed best in highly ranking copy &amp; paste,\nfollowed by the citation-based LCCS algorithm and the character-based PDS\nSherlock. The upper quartile of these three best performing methods equals one,\ni.e. for at least 75 % of the examined top-10 document pairs, the methods\nretrieved the source document at rank one.\nThe average rank and the third quartile of ranks at which the other citationbased methods retrieved potentially suspicious document pairs are higher than\n\n6.4 Evaluation using PubMed Central OAS\n\n161\n\nfor the three best-performing methods. The good performance of character-based\ndetection methods for copy &amp; paste is in line with the previous findings using the\nGuttenPlag Wiki, as well as findings from other studies, such as the PAN\ncompetitions and the HTW PDS comparisons (see Section 2.3.1). Characterbased methods are better able to detect literal text matches than CbPD. Yet, the\ncitation-based methods, and especially LCCS, performed better than expected in\nthe analysis of the PMC OAS. The reason is that many of the literal text overlaps\nin the analyzed document pairs are extensive and include many shared citations\nin similar order.\n\n162\n\n6 Quantitative and Qualitative Evaluation\n\n1,85\n\nShake &amp; Paste\n\n1,75\n\n1,85\nThird Quartile\nFirst Quartile\nMean\n\n1,35\n1,2\n1,1\n\n1,1\n\n1,05\n\nGCT\n\nCC40\n\nCC42\n\nLCCS\n\nLCCS\ndist.\n\nSherlock\n\nEnco\n\nLCCS\ndist.\n\nLCCS\n\nCC42\n\nCC40\n\nBC rel.\n\nGCT\n\n1\n\nBC abs.\n\nRank\n\nShake &amp; Paste\n1,9\n1,8\n1,7\n1,6\n1,5\n1,4\n1,3\n1,2\n1,1\n1,0\n0,9\n\nBC\nabs.\n\nBC\nrel.\n\nEnco\n\nSherlock\n\nMin\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\nQ1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\nMedian\n\n1\n\n1\n\n1.25\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\nQ3\n\n1\n\n1.25\n\n1.5\n\n1.625\n\n1.125\n\n1\n\n1\n\n1\n\n1\n\nMax\n\n2\n\n2\n\n7.5\n\n2.5\n\n8\n\n9.5\n\n2\n\n1\n\n1.5\n\nMean\n\n1.1\n\n1.2\n\n1.85\n\n1.35\n\n1.75\n\n1.85\n\n1.1\n\n1\n\n1.05\n\nFigure 38: Distribution of Ranks for Top-10 Document Pairs for Shake &amp; Paste\n\nFigure 38 shows the distribution of ranks for shake &amp; paste similarities.\nEncoplot performed best in retrieving shake &amp; paste similarities at prominent\nranks, followed by Sherlock and the citation-based measures LCCS distinct,\nLCCS and BC absolute. The third quartiles of all five highest performing\nmethods equal one. The remaining citation-based methods demonstrated slightly\nlower retrieval performances, yet could identify the source document for each of\nthe user classified top-10 document pairs. No third quartile of any citation-based\nmethod exceeded rank two; see Q3 in Figure 38.\n\n6.4 Evaluation using PubMed Central OAS\n\n163\n\nThe good performance of Encoplot and Sherlock in identifying shake &amp; paste\nsimilarities is no surprise, given that many of the identified instances have high\nverbatim text overlap. The citation-based measures performed better than\nexpected, which was mainly due to most shake &amp; paste similarities being\nconcentrated in the introduction and background sections, which also included a\nhigh number of shared citations.\n\n164\n\n6 Quantitative and Qualitative Evaluation\n\nThird Quartile\nFirst Quartile\nMean\n\nParaphrases\n\n6,45\n4,75\n\n3,85\n\n3,7\n\nLCCS\ndist.\n\nBC\nabs.\n\nBC\nrel.\n\nGCT\n\nMin\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\nQ1\n\n1\n\n1\n\n1\n\n1\n\n1\n\nMedia\n\n1\n\n1\n\n2.25\n\n1\n\n2.125\n\n2\n\n5.625\n\nMax\n\n6\n\n26\n\nMean\n\n1.75\n\n3.7\n\nQ3\n\nCC40\n\nCC42\n\nLCCS\n\nLCCS\ndist.\n\nSherlock\n\n1,45\n\nEnco\n\n1,35\n\nCC42\n\nCC40\n\nBC rel.\n\nGCT\n\n1,5\n\nLCCS\n\n2,7\n\n1,75\n\nBC abs.\n\nRank\n\nParaphrases\n13\n12\n11\n10\n9\n8\n7\n6\n5\n4\n3\n2\n1\n0\n\nEnco\n\nSherlock\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1\n\n1.375\n\n1\n\n1\n\n1\n\n1.5\n\n5.5\n\n3\n\n1.5\n\n1.25\n\n1.625\n\n7.375\n\n12.75\n\n13\n\n14\n\n4\n\n3.5\n\n4\n\n18\n\n14.5\n\n3.85\n\n2.7\n\n1.5\n\n1.35\n\n1.45\n\n4.75\n\n6.45\n\nFigure 39: Distribution of Ranks for Top-10 Document Pairs for Paraphrases\n\nFigure 39 shows the distributions of ranks for paraphrases. Citation-based\nmethods significantly outperformed character-based methods in retrieving\nparaphrases at prominent ranks. The two variations of Longest Common Citation\nSequence (LCCS and LCCS dist.), and Citation Chunking (CC42) performed\nbest. The results support our hypothesis that citation-based methods are more\nsuitable for identifying paraphrases than character-based methods.\n\n6.4 Evaluation using PubMed Central OAS\n\n165\n\n15,75\nThird Quartile\n\nStructural and Idea\n\n11,85\n\nFirst Quartile\n\nMin\nQ1\nMedian\nQ3\nMax\nMean\n\n1,2\n\n1,15\nLCCS\ndist.\n\nBC rel.\nBC\n\nBC\n\nabs.\n\nrel.\n\n1\n1\n1\n1.25\n2\n1.2\n\n1\n1\n1\n1.625\n2\n1.25\n\nGCT\n\nCC40\n\nCC42\n\nLCCS\n\nLCCS\n\nEnco\n\ndist.\n\n1\n1\n1.25\n2\n5\n1.75\n\n1\n1\n1\n1.5\n2\n1.2\n\n1\n1\n1\n1.25\n3\n1.3\n\n1\n1\n1\n1\n3\n1.2\n\n1\n1\n1\n1.125\n2\n1.15\n\nSherlock\n\n1,3\n\nEnco\n\n1,2\n\nLCCS\n\n1,75\n\n1,25\n\nCC42\n\n1,2\n\nCC40\n\nMean\n\nGCT\n\n18\n16\n14\n12\n10\n8\n6\n4\n2\n0\n\nBC abs.\n\nRank\n\nStructural / Idea\n\nSherlock\n\n1\n1\n4.25\n15.75\n57.5\n11.85\n\n1\n2.25\n8\n18.875\n79.5\n15.75\n\nFigure 40: Distribution of Ranks for Top-10 Document Pairs for Structural and Idea\nPlagiarism\n\nFigure 40 shows the distribution of ranks for documents featuring structural\nand/or idea plagiarism forms. Citation-based methods, especially the two\nvariations of the LCCS (LCCS and LCCS dist.) outperformed character-based\nmethods in prominently ranking structural and/or idea plagiarism.\nDetailed Comparison of Retrieval and Ranking Performance\nThe ranking performance is presented in detail using 16 scatter plots in Figure\n41. The plots compare the two best performing citation-based methods for each\n\n166\n\n6 Quantitative and Qualitative Evaluation\n\nof the four plagiarism forms with the two character-based methods, Encoplot and\nSherlock, without aggregating ranks. Non-aggregated ranks set these scatter plots\napart from the box plots in Figure 37–Figure 40. The rank at which the characterbased methods retrieved each of the top-10 document pairs is plotted on the\nhorizontal axis. The rank for citation-based methods is plotted on the vertical\naxis. Larger dots represent multiple documents retrieved at the same combination\nof ranks.\nCopy and Paste\n\nShake and Paste\n\nParaphrase\n\nStructural and Idea\n\nFigure 41: Scatter Plots for Top-10 Findings Grouped by Plagiarism Form\n\nThe scatter plots for copy &amp; paste and shake &amp; paste plagiarism forms show that\nthe character-based and even the best performing citation-based methods\n\n6.4 Evaluation using PubMed Central OAS\n\n167\n\nprominently ranked these forms of similarities. Of the ten document pairs in the\ncopy &amp; paste category, Encoplot identified all at rank one, LCCS and Sherlock\nretrieved nine at rank one. Similarly, Encoplot identified all ten document pairs\nin the shake &amp; paste category at rank one, Sherlock and the two LCCS measures\neach identified nine pairs at rank one. The results confirm that current detection\nmethods also have no difficulty in identifying verbatim text overlap in real-world\ncollections.\nThe scatter plots for paraphrases and structural and idea plagiarism show that\nthe CbPD algorithms outperform character-based approaches in identifying these\nforms of plagiarism, which typically have very little or no notable text overlap.\nFor paraphrases, the CbPD algorithms CC40 and CC42, identified seven and\neight of the ten document pairs at rank one and ranked none of the document\npairs lower than rank four. Encoplot and Sherlock identified six and eight of the\ndocument pairs below the top rank of one. The lowest ranks at which the two\ncharacter-based approaches retrieved one of the top-10 document pairs were at\nrank 18 for Encoplot and at rank 14.5 for Sherlock. For structural idea\nplagiarism, the advantage of CbPD in ranking effectiveness is even stronger. The\nCbPD algorithms CC42 and CC40 identified eight and seven document pairs at\nrank one and the remaining document pairs no lower than rank 3. Encoplot and\nSherlock ranked six and nine document pairs at rank four or at lower ranks. The\nlowest ranks at which Encoplot and Sherlock retrieved the document pairs were\nat rank 57.5 for Encoplot, and rank 79.5 for Sherlock.\nThe scatter plots reflect the complementary strengths of character-based and\ncitation-based approaches. While the plots show dots mostly on vertical lines for\ncopy &amp; paste and shake &amp; paste, they show dots mostly on horizontal lines for\nparaphrases and for structural and idea plagiarism. These results show that\ncharacter-based approaches excel in identifying copy &amp; paste and shake &amp; paste\nplagiarism, while the CbPD approach more effectively detects semantic\ndocument similarities with little or no textual overlap.\n\n168\n\n6 Quantitative and Qualitative Evaluation\n\nPrecision-Recall Curve for Best Performing Approach\nThe previous evaluation measured the performance of detection approaches in\nprominently ranking a single, already identified document that human examiners\nrated as suspicious and subsequently categorized as containing one of the\npotential forms of plagiarism. In a realistic PD scenario, however, the documents\nto be retrieved are unknown. A detection approach will receive an input\ndocument for which the algorithm must identify all documents with relevant\nsimilarities. To assess the detection performance of character-based and\ncitation-based approaches in such a 1:n setting, we performed an additional\nevaluation.\nDue to the high human effort necessary to judge results in a 1:n evaluation,\nwe only compared the performance of Encoplot, LCCS distinct and\nBibliographic Coupling. We chose Encoplot and LCCS, because they are the\ncharacter-based and the citation-based method that performed best overall in the\nprevious evaluation. Bibliographic Coupling was included as a baseline measure.\nTo derive a ground truth for this 1:n evaluation, we applied the following\npooling procedure. For each of the four plagiarism forms, we selected the five\ndocument pairs rated highest by users in the previous n:n comparison. We used\nthe more recent publication from each of these 20 document pairs as the query\ndocument. For each query document, we collected the documents that each of the\nnine tested detection methods identified as most similar, yet not more than six\ndocuments per method to limit the effort necessary for manual inspection.\nThe resulting document collection contained 160 unique documents, which\nwe presented to six study participants for relevance judgment. Due to the high\nlevel of effort associated with this evaluation, each document pair was only rated\nby one study participant, in contrast to the n:n evaluation, where one participant\nfrom each of the three groups judged each document pair. Study participants\nwere asked to classify a document as relevant if it fulfilled the following\ninformation need:\n“The documents feature similarities, which an examiner in a check\nfor plagiarism would find valuable to be made aware of.”\n\n6.4 Evaluation using PubMed Central OAS\n\n169\n\nTo compare retrieval performance, we plotted the 11-point precision-recall curve\n([209], pp. 158-159) using interpolated average precision and relative recall for\neach of the three methods (see Figure 42). We average the precision achieved by\ndetection methods for each of the 20 query documents and interpolate precision\nif no measured values exist for any of the 11 predefined recall levels. We\nconsider relative recall [70], because determining recall as traditionally defined\nin IR requires collecting relevance judgments for all possible retrieval results,\ni.e. all documents in the PMC OAS. This is unfeasible. Therefore, our evaluation\nis similar to search engine evaluations, in which the set of possible retrieval\nresults is often unbounded or larger than a human can possibly judge [6].\nPooling results and then collecting relevance judgments only for the pooled\nresults is a common approach to dealing with this restriction, e.g., applied in\nTREC [49]. We adopted this pooling approach and calculated relative recall, i.e.\nthe fraction of retrieved relevant documents over the number of documents\njudged relevant among the pooled documents.\n\n170\n\n6 Quantitative and Qualitative Evaluation\n\nPrecision-Recall Curve\n\nAverage Interpola ted Precision\n\n0,9\n\nLCCS dist.\nEnco\nBC\n\n0,8\n\n0,7\n\n0,6\nRelative Recall\n\n0,5\n\n0\n\n0,1\n\n0,2\n\n0,3\n\n0,4\n\n0,5\n\n0,6\n\n0,7\n\n0,8\n\n0,9\n\n1\n\nLCCS dist. 0,83 0,83 0,81 0,81 0,81 0,81 0,80 0,74 0,71 0,70 0,70\nEnco\n\n0,80 0,80 0,80 0,75 0,73 0,70 0,65 0,60 0,55 0,55 0,55\n\nBC\n\n0,80 0,80 0,80 0,80 0,78 0,78 0,72 0,67 0,63 0,58 0,58\n\nFigure 42: 11-Point Interpolated Avg. Precision – Rel. Recall Curve for Enco, LCCS\nDist. and BC\n\nLCCS distinct performed best in this evaluation, i.e. LCCS dist. consistently\nidentified more relevant documents among its top-6 results than BC or Encoplot.\nWith a value of 0.8, the average precision of BC and Encoplot is identical for\nrecall levels ൑ 0.2. For recall levels &gt; 0.2, average precision drops more\nstrongly for Encoplot than for BC.\nThe finding that the crude BC measure performed better than Encoplot may\nbe surprising. We assume this to be attributable to the document selection\nprocedure. Since only five of the 20 query documents were of the copy &amp; paste\nform, the majority of cases contained disguised forms of plagiarism. Encoplot,\nLCCS distinct, and BC rank copy &amp; paste plagiarism at similarly high ranks\n(compare Figure 37). However, in cases of disguised plagiarism forms, LCCS\ndistinct and BC yield significantly higher rankings than Encoplot. For structural\n\n6.4 Evaluation using PubMed Central OAS\n\n171\n\nand or idea plagiarism, the average ranks of BC and LCCS dist. were 1.2,\ncompared to the average rank of Encoplot, which was 11.84 (see Figure 40).\nThe results in Figure 42 show a sample that contains equal shares of all four\nforms of plagiarism. While such a distribution may be typical for submissions to\nreputable journals, it is unlikely to reflect the distribution of plagiarism forms in\nother settings, for example, among assignments written by undergraduates,\nwhere copy &amp; paste plagiarism was shown to be dominant [220]. Therefore, the\nresults obtained from this evaluation using the PMC OAS can only be\ngeneralized to a limited extent.\nUser Utility\nThis section presents the user-perceived and measured effectiveness of the CbPD\napproach in comparison to traditional character-based approaches.\nWe used CitePlag to assess user utility in the following areas:\n1.\n\nSubjective: Which approach, i.e. method of document similarity\nvisualization, text and/or citation visualization, did users identify\nas most suitable for identifying the various forms of plagiarism?\n\n2. Objective: Does citation visualization decrease user effort by\nreducing the time required for manual document inspection and\nverification? If so, what are the mean time-savings for the\nvarious forms of plagiarism?\n\n3. Open-ended comments from users on the perceived utility of the\nCbPD approach are summarized in Table 31 in Appendix F.\n\nUser-Perceived Suitability of Approaches\nThe responses regarding the perceived suitability of the individual approaches\nfor verifying various forms or plagiarism are visualized in Figure 43. The figure\nshows the aggregation of 461 document pair judgments collected for all three\nexaminer groups. Similarity visualization preferences among expert and nonexpert groups did not differ significantly. Traditional text-highlights were\n\n172\n\n6 Quantitative and Qualitative Evaluation\n\nidentified as the most suitable document similarity visualization method for copy\n&amp; paste plagiarism. For disguised forms of plagiarism, the large majority of\nexaminers considered the visualization of citation patterns, or a combination of\ntext-highlights and citation visualization to be most suitable.\nSince the PMC OAS only contains publications in English, we additionally\nasked 13 study participants47 to examine the Guttenberg thesis and indicate the\nsuitability of visualization methods for translated plagiarism. Given that opinions\nfor translated plagiarism were collected only for a single document, the results\ncannot be generalized. Similarly, the user-reported suitability of the visualization\napproaches may not be representative for other collections.\n\n47\n\nA sub-group of total user study participants.\n\n6.4 Evaluation using PubMed Central OAS\n\n173\n\nPerceived effectiveness for verification\ncharacter similarity\n\ncitation similarity\n\ncombination\n\nAverage\n\n47%\n\nTranslated (only\nGuttenberg)\n\nCopy &amp; paste\n36%\n\n54%\n\n51%\n47%\n\n17%\n46%\n\n1%\n1%\n0%\n5%\n13%\n\n6%\n\n27%\n\n32%\nStructural &amp; idea 86%\n\n68%\nShake &amp; paste\n\n62%\n\nParaphrase\n\nFigure 43: Perceived Effectiveness for Verification by Plagiarism Form\n\nMeasured Time-Savings of the Approaches\nEight study participants48 judged documents on their potential suspiciousness\nusing CitePlag, once with text similarity visualized and once with both text and\ncitation pattern similarity visualized. We recorded the time examiners needed to\nidentify the first two instances of suspiciousness in the documents in both cases.\nEach participant rated 25 document pairs49, six document pairs for each of the\nassigned forms of plagiarism, except for translated plagiarism for which only one\ndocument, the Guttenberg thesis, was examined.\nWe formed two groups of four examiners, whom we showed the same\ndocument pairs either with or without citation pattern visualization to assure that\nno documents were viewed by the same examiner using both methods. When\n48\n49\n\nA sub-group of total user study participants.\nA randomly selected sample of the top-30 documents for each of the four forms of\nplagiarism yielded by the pooling approach.\n\n174\n\n6 Quantitative and Qualitative Evaluation\n\npresented with the next document pair, the groups switched roles so that\nexaminers previously shown no citation pattern visualizations now received them\nand vice versa. This approach reduced the one-sided impact of a few users who\nresponded either more quickly or more slowly to a certain visualization method,\nfrom skewing the reported time.\nIn a first evaluation, we attempted to measure the examination time saved\nupon the visualization of citation patterns between documents. We observed,\nhowever, that the mean time for examination before arriving at a final judgment\non document similarity increased upon adding citation visualization. We found\nthat examiners browsed documents more thoroughly and read the text\nsurrounding the citation pattern similarities. We thus switched from measuring\ntime-savings for the open-ended task – &quot;arrive at a final judgment&quot; – to a fixedtask format, in which we asked users only to identify the first two suspicious\ndocument instances for each document pair and timed their response. Our\nassessment of user time-savings is a component of user effort, a recognized\nevaluation metric for IR tasks, although less frequently used [78].\nWe observed a significant difference in the mean times needed to identify the\nfirst two instances of similarity among the groups, depending on whether they\nwere presented with citation pattern visualization or not.\nFigure 44 plots the recorded mean times for all plagiarism forms. The\ndifference in the mean times between the groups was highest for the Guttenberg\ntranslation50 at 49 %, and for structural and idea similarities at 42 %. A slight\nreduction in recorded mean times was also observed for paraphrases, 22 %, and\nshake &amp; paste, 11 %.\nThese measured time-savings were in line with the response from users that\nthe citation pattern visualization of the CbPD approach was the single most\nuseful aid in the manual verification of structural &amp; idea plagiarism forms. For\nplagiarism forms with very high textual similarity, e.g., copy &amp; paste, citation\npattern visualization provided no measurable time-savings, and actually had a\n50\n\nThis result cannot be generalized, having presented examiners only with a single\ntranslated plagiarism case.\n\n6.4 Evaluation using PubMed Central OAS\n\n175\n\nnegative effect, due to some examiners clicking through the sections with high\ncitation pattern similarity more thoroughly and thus taking longer to report the\nfirst two instances of similarity. We found, however, that examiners took little\nnotice of the potentially higher user effort, given that they commented that\ncitation visualization was also useful for copy &amp; paste, since connecting lines\nbetween citations allowed a quick visualization of the potentially most similar\nsections. A more in depth overview of comments and feedback collected during\nthe study is available in Appendix F.\nMeasured time with and without citation pattern visualization\nwithout citation pattern visualization (only text highlights)\nwith citation pattern visualization (hybrid)\nAverage\n300\n\ntime plotted\nin sec.\n\n250\n200\n\nTranslated (only\nGuttenberg)\n\n150\n100\n84\n\n43\n\n96.2\n\n50\n0\n\nCopy &amp; paste\n\n136.4\n\n52\n\n59\n\n74\n83\n280\n\n162\n\n143\n\nStructural &amp; idea\n\nShake &amp; paste\n183\n\nParaphrase\n\nFigure 44: Measured Time With and Without Citation Pattern Visualization\n\nThis evaluation of user utility and user effort reduction as measured by\ntime-savings was small-scale and future evaluations will be needed to assess the\nrelevance of the results. However, in the setting described, CbPD demonstrated a\nmeasurable increase in user utility, both user-reported and objectively measured,\nwhen compared to the traditional text-only document similarity visualization\nmethod.\n\n176\n\n6 Quantitative and Qualitative Evaluation\n\n6.4.2.2\n\nComparison of Computational Efficiency\n\nBy comparing the run-time behavior of character-based and citation-based\ndetection methods for the average-case scenario, this section addresses\nEvaluation Objective 2, as outlined in Section 6.4. We compared the two\ncharacter-based methods, Encoplot and Sherlock, with the seven citation-based\ndetection methods, as described in in the subsection Applying Detection\nAlgorithms and Pooling, page 143. The seven citation-based algorithms have\nsimilar run time behaviors. Therefore, we summarized all seven citation-based\nmeasures under the label &quot;CbPD&quot; and used their mean processing time.\nProcessing time for all plagiarism detection approaches consists of two\ncomponents (1) the time required for preprocessing, and (2) the time required for\ndocument comparison. The time required for preprocessing includes document\ntype conversions, for example converting from PDF or XML format to plain\ntext, as well as file system and/or database operations. To use Encoplot and\nSherlock, we converted PMC OAS’s NXML format to plain text. In addition to\ntext conversions, preprocessing for citation-based methods includes parsing the\ntext to acquire citations, references and document metadata, storing this data in a\ndatabase, as well as data cleaning and disambiguation. Since the BC strength is\nused to limit the scope of comparisons in our evaluation, we added the time\nrequired for computing BC to the preprocessing time of citation-based methods.\nCharacter-based methods require ܱ(݊) time for preprocessing, because ݊\ndocuments must be converted from NXML to plain text. Citation-based detection\nmethods also require ܱ(݊) time for converting and parsing documents and for\ncleaning and disambiguating the parsed data. The additional Bibliographic\nCoupling calculation requires ܱ(݊ ‫ ))݊(݃݋݈ ڄ‬time when using an index that\nallows comparing the references in documents in ܱ(݈‫ ))݊(݃݋‬time. Table 21 lists\nthe preprocessing times for a 3.40GHz quad core processor with 16GB RAM for\nthe three detection approaches used in our evaluation.\n\n6.4 Evaluation using PubMed Central OAS\n\n177\n\nTable 21: Average Time for Preprocessing and Comparison per Document\nOperation performed\n\nEncoplot51\n\nSherlock\n\nCbPD\n\nConversion of NXML documents to\nplain texts\n\n13 ms\n\n13 ms\n\n13 ms\n\nParsing and storing of citation data\n(XML)\n\nNot required\n\nNot required\n\n29 ms\n\nParsing and storing of citation data\n(PDF)\n\nNot required\n\nNot required\n\n246 ms\n\nComputing Bibliographic Coupling\n\noptional\n\noptional\n\n34 ms\n\nDocument comparison (time per\ndocument pair)\n\n153 ms\n\n259 ms\n\n2 ms\n\nThe time required for document comparisons depends foremost on the number of\ncomparisons necessary. This number differs significantly for character-based\ncompared to citation-based detection methods, with 17,143,871,865 comparisons\nneeded for character-based approaches, and only 39,463,660 comparisons\nneeded for citation-based approaches. This means analyzing the PMC OAS using\nthe CbPD approach requires only 0.23 % of the comparisons necessary for a\ncharacter-based analysis. Refer to Applying Detection Algorithms and Pooling,\npage 143, for more details. The last row in Table 21 shows the required average\ntime to compare a single document pair with each of the evaluated detection\napproaches.\n\n51\n\nThe required processing time is dependent on the document collection and computing\nhardware used [142].\n\n178\n\n6 Quantitative and Qualitative Evaluation\n\nComputational efficiency for different approaches dependent on\ncorpus size\n1 billion years\n1.E+13\n\nProcessing time in hours\n\n1.E+12\n1.E+11\n\nENCO\n\n1.E+10\n\nSherlock\n\n1.E+09\n\nCbPD1\n\n1.E+08\n\nCbPD5\n\n606\n6 million\nyears\n\n1.7 million years\n\n18250\n0 years\n\n1.E+07\n\n140 years\n\n1.E+06\n31 years\nars\n\n1.E+05\n\n250\n50 years\ny\n\n1.E+04\nmonths\n7m\n\n1.E+03\n36 hours\nours\n\n1.E+02\n\nGoogle Scholar\n\n1.E+01\nhours\n14.7 h\n1.E-01\n1.E-02\n1.E-03\n1.E-04\n\n12 sec\n\nPubMed\n\nPMC OAS\n\n1.E+00\n\n2.8 sec\n10\n\n100\n\n1000\n\n10000\n\n1.9E-03\n\n2.1E-01\n\n2.1E+01\n\n2.1E+03\n\n7.3E+05\n\n2.1E+07\n\n8.9E+09\n\n2.1E+11\n\n5.3E+12\n\nSherlock 3.3E-03\n\n3.6E-01\n\n3.6E+01\n\n3.6E+03\n\n1.2E+06\n\n3.6E+07\n\n1.5E+10\n\n3.6E+11\n\n9.0E+12\n\nCbPD1\n\n7.8E-04\n\n7.8E-03\n\n7.8E-02\n\n8.4E-01\n\n3.6E+01\n\n7.2E+02\n\n2.7E+05\n\n6.4E+06\n\n1.6E+08\n\nCbPD5\n\n7.8E-04\n\n7.8E-03\n\n7.8E-02\n\n7.8E-01\n\n1.5E+01\n\n8.6E+01\n\n5.2E+03\n\n9.3E+04\n\n2.2E+06\n\nENCO\n\n185170 1.00E+06 2.05E+07 1.00E+08 5.00E+08\n\nThe first row lists the collection size. The rows underneath show processing times\nin hours (partially extrapolated). Processing times are plotted on a log10 scale.\n\nFigure 45: Computational Efficiency of PD Approaches for an n:n Comparison\n\n6.4 Evaluation using PubMed Central OAS\n\n179\n\nFigure 45 shows an extrapolated comparison52 of processing times on a\nlogarithmic scale for the evaluated plagiarism detection methods dependent on\ncorpus size. The horizontal axis shows different corpora sizes where the gray\nshaded regions indicate the size ranges of the PMC OAS, PubMed and Google\nScholar document collections. The vertical axis shows the processing time in\nhours using a logarithmic scale with base 10. The table below the figure shows\nthe processing time in hours. If only one document pair (1:1) is analyzed, the\ncharacter-based methods are comparatively less expensive than the citationbased approaches. The reason for this is that citation parsing is initially more\nexpensive than fingerprint creation for the character-based approaches. However,\nthe break-even point, which depends predominantly on document length and\nnumber of citations, is usually reached at about five documents. Beyond this\nsize, the character-based approaches are more expensive, given that they require\n݊\nቀ ቁ comparisons, while the citation-based approaches only perform a\n2\ncomparison if a document pair is at all bibliographically coupled or if it has a BC\nabove a specified strength.\nFigure 45 shows that at a collection size range comparable to that of the PMC\nOAS, the CbPD5 algorithm53 requires a total processing time of 14.7 hours,\nwhile Sherlock would require 140 years.\n\n6.4.2.3\n\nRetrieved False Positives\n\nThis section describes the causes for the retrieval of false positives (FP). We\ndistinguished between:\n1.\n\n52\n\n53\n\nNon-scientific or collection-specific FP\n\nProcessing times for the character-based approaches were measured for sample sizes\nof 10, 100, and 1,000; the processing times for all values larger than this are\nextrapolated due to the unrealistic time requirement. The values for the citation basedapproaches were calculated up to the size of the PMC OAS dataset; the processing\ntimes for the larger collections were extrapolated.\nCbPD5 represents any citation-based approach that uses a min. coupling strength of\nfive for comparisons.\n\n180\n\n6 Quantitative and Qualitative Evaluation\n\n2.\n\nTrue FP\n\nThe first class of FP represented non-scientific or PMC OAS collection-specific\nfalse positives. These included editorials and updates, as described in\nAddressing False Positives, page 148. This class of FP was excluded to prevent\ninfluencing the algorithm performance evaluation. The second class of FP\nrepresented scientific documents retrieved for their similarity characteristics, but\nviewed as non-suspicious upon manual examination in the user study. This class\nof FP was retained and allowed to influence detection performance.\nNon-scientific and collection-specific false positives\nAs described in Addressing False Positives, non-scientific or collection-specific\nFP were manually excluded prior to presenting the top-ranked results to user\nstudy participants. This step was necessary for a meaningful performance\ncomparison of the approaches, because without these exclusions the\ncharacter-based approaches – in particular Encoplot – would have retrieved\namong its top ranks almost exclusively such legitimately similar documents. This\nwould have resulted in an unwarranted high rate of false positives for the\ncharacter-based approaches, only due to the chosen test collection’s properties.\nFigure 46 shows the percentage of non-scientific or collection-specific FP\nretrieved for each evaluated detection method. For each method, we screened the\nretrieved results ordered by decreasing score and excluded FP caused by\neditorials, updates and parsing errors until 30 true positives remained54. The\nnumber of documents examined to retain 30 true positives varied significantly\nfor each method and is indicated as the denominator over the stacked bars in\nFigure 46.\n\n54\n\nFor an explanation of the categories editorials and updates, see Addressing False\nPositives on page 148. The category other contains document pairs for which author\noverlap or citation relations that should have caused the exclusion of the document\npair were not recognized due to parsing errors.\n\n6.4 Evaluation using PubMed Central OAS\n\n181\n\nNon-scientific / collection-specific false positives\n100%\n\n205 fp / 235\npubl.\n\npercentage of false positives\n\n90%\n\nOther\n\n80%\n\nUpdate\n\n70%\n\nEditorial\n\n60%\n18 fp / 48\npubl.\n\n50%\n40%\n30%\n20%\n10%\n\n3 fp / 33\n1 fp / 31 publ.\npubl.\n\n4 fp / 34\npubl.\n\n3 fp / 33\npubl.\n1 fp / 31\npubl.\n\n4 fp / 34\npubl.\n1 fp / 31\npubl.\nSherlock\n\nEncoplot\n\nLCCS dist.\n\nLCCS\n\nGCT\n\nCC42\n\nCC40\n\nBC rel.\n\nBC abs.\n\n0%\n\nFigure 46: Non-Scientific / Collection-Specific FP Excluded Prior to User Study\n\n31 publications were screened for BC abs., CC42, and LCCS, while 235\npublications had to be examined for Encoplot. Encoplot and Sherlock retrieved\nfar more non-scientific FP, mainly of the editorial type, when compared to the\ncitation-based approaches. The reason for this is that some editorials re-use text\nfrom previously published editorials in other journals, while inserting unique\ncitations that are relevant to their specific field.\n\n182\n\n6 Quantitative and Qualitative Evaluation\n\nFigure 47: Editorial with High Text Overlap but Unique Citations\nSource: http://citeplag.org/compare/43170/120039\n\nFigure 47 shows an excerpt from an editorial, which features the typical high\ntext similarity but low citation-based similarity. The CbPD algorithms retrieved\nno editorials among false positives, since citation patterns tended be\nunsuspicious, pointing to differences in semantic content of individual journals,\neven when text building blocks were borrowed.\n\n6.4 Evaluation using PubMed Central OAS\n\n183\n\nFigure 48: Text Recycled by Journals over Time\n\nFigure 48 shows the common practice of &quot;recycling&quot; text building blocks\nbetween journals over the years. The number pair on the connecting lines, e.g.,\n&quot;49505/101209&quot;, are the document identifiers to be entered at the end of the\nprototype’s URL to visualize the given document pair, e.g.,\nhttp://citeplag.org/compare/49505/101209.\nIn summary, character-based approaches have the inherent problem of\nretrieving documents with almost identical texts at the highest ranks. Yet, such\ndocuments are not always the most interesting or relevant results for a user in a\nplagiarism detection setting. In many cases, there are underlying reasons that\nlegitimize exceptionally high text overlap. Such reasons are filterable with added\n\n184\n\n6 Quantitative and Qualitative Evaluation\n\neffort, yet are highly collection-specific and thus require complete information\non the composition of the corpus.\nTrue false positives\nThe most common causes for the retrieval of true false positives were:\n-\n\nUnsuspicious articles – articles addressing the same topic, or\nsimilar research questions but featuring genuine content and no\nsuspicious similarity.\n\n-\n\nLiterature reviews – articles reviewing literature on similar or\nidentical topics, often over 30+ pages, naturally shared many\ncitations. This led to high, but unproblematic, citation pattern\noverlap and repetition of key words within certain review articles.\n\n-\n\nLegitimate paraphrases – articles with paraphrases, where author\ncontribution was so significant that classifying the new text as\n‘suspicious’ was not warranted\n\n-\n\nCitation lists – articles with long in-text citation lists, for example\nreferencing all relevant studies on a certain topic ordered by\npublication year, are examples of legitimately shared citations\npatterns.\n\nThe user study participants55 rated 22 of the 181 examined document pairs as\ntrue false positives. Figure 49 shows the percentage of total true false positives\neach evaluated detection method retrieved, classified according to the cause of\nfalse positive retrieval, as listed above.\n\n55\n\nFor the description of User Study Design, refer to page 149.\n\n6.4 Evaluation using PubMed Central OAS\n\n185\n\nTrue false positives\n8\nUnsuspicious\nLiterature Review\nLegitimate Paraphrase\nCitation Lists\nTopical Similarity\n\nFalse positives\n\n7\n1\n6\n1\n5\n\n1\n1\n1\n\n4\n3\n5\n2\n\n2\n\n4\n3\n\n1\n\n2\n1\n\n1\n\n1\n\nCC40\n\nCC42\n\n0\n\n0\nBC abs.\n\nBC rel.\n\nGCT\n\nLCCS\n\n0\n\nLCCS dist. Enco.\n\nSherl.\n\nFigure 49: True False Positives Identified by User Study Participants\n\nFigure 49 indicates a systematic weakness shared by global citation-based\napproaches that neglect citation order (the two variations of Bibliographic\nCoupling), and of the global character-based approach Sherlock. These\napproaches retrieved significantly more FP than the other methods. Articles in\nthe life sciences tend to cite more sources than articles in other disciplines [291].\nTherefore, longer articles and especially reviews can legitimately share many\ncitations, causing the two BC approaches to rank them highly. Sherlock, the\nglobal character-based PDS, tended to flag document pairs as suspicious if they\nlegitimately shared many subject-specific phrases and standardized terminology.\nTypical examples of such documents included medical case studies, which\nlegitimately described medical history and patient diagnoses using boilerplate\ntext.\nOrder-observing, global and local citation-based methods yielded fewer false\npositives. Although the two Longest Common Citation Sequence approaches\nalso represent global citation-based measures, their consideration of the order of\ncitations largely prevents these methods from retrieving false positives. LCCS\ndistinct, which counts multiple citations of the same source only once to be\nincluded in the LCCS, retrieved no FP among its top-30 document pairs. The\n\n186\n\n6 Quantitative and Qualitative Evaluation\n\nlocal, order-observing approach of Greedy Citation Tiling retrieved some articles\nthat legitimately contained lists of previous publications in a specific order, e.g.,\nordered chronologically or by author names. Each of the two variations of\nCitation Chunking, which are local, order-neglecting, citation-based approaches,\nretrieved only one FP, a review article, and an article listing previous\npublications, respectively.\nThe local fingerprinting approach of Encoplot performed better than the\nglobal approach of Sherlock and did not retrieve true FP among its final top-30\ndocument pairs. However, one must bear in mind that compiling the set of the\nfinal 30 documents required removing 205 non-scientific and collection-specific\nfalse positives. In a realistic PD setting, Encoplot would retrieve these\ndocuments among its highest ranked results if non-scientific documents were\namong the query documents, e.g., if a journal checked one of its issues against\nthe collection.\n\n6.4 Evaluation using PubMed Central OAS\n\n187\n\nTable 22: Examples of Most Common FP Types in PMC OAS\nType\n\nOlder\narticle\n\nNewer\narticle\n\nCitePlag Link\n\nNon-scientific / collection-specific false positives – excluded prior to user study\nEditorials56\n\n[217]\n\n[1]\n\nhttp://citeplag.org/compare/49505/120039\n\nUpdates\n\n[11]\n\n[12]\n\nhttp://citeplag.org/compare/56236/56684\n\nTrue false positives – identified by user study participants\nUnsuspicious\narticles\n\n[101]\n\n[181]\n\nhttp://citeplag.org/compare/4586/43805\n\nLong literature\nreviews\n\n[110]\n\n[340]\n\nhttp://citeplag.org/compare/44315/48342\n\nLegitimate\nparaphrases\n\n[237]\n\n[331]\n\nhttp://citeplag.org/compare/21031/34941\n\nCitation lists\n\n[73]\n\n[296]\n\nhttp://citeplag.org/compare/50197/50325\n\nCase studies\n\n[325]\n\n[112]\n\nhttp://citeplag.org/compare/13278/92969\n\nTable 22 provides examples for each of the document types prone to false\npositive classification, both collection-specific FP and true FP. The complete\ndataset of findings is available for download; refer to Appendix C.\nIn conclusion, false positives are a problem for character-based as well as\ncitation-based methods. However, our evaluation showed that in the case of the\nPMC OAS, the two approaches retrieved different types of false positives with\ndifferent frequencies. In the case of the PMC OAS, the character-based methods\nyielded significantly more false positives, due to the collection containing many\neditorials, updates, and case studies that share standardized wording or\nboilerplate text.\n56\n\nEditorials represented the bulk of pre-user study false positives retrieved by the\ncharacter-based algorithms. An illustration of the common &quot;recycling&quot; of text by\njournal editors over the years is shown by Figure 48 on page 183.\n\n188\n\n6 Quantitative and Qualitative Evaluation\n\nWe hypothesize that combining more than one metric can increase the\nexplanatory power of suspiciousness scores and help in reducing false positives.\nThe citation-based approach adds an additional layer of semantic document\nuniqueness beyond text, which can give clarity especially for publications on\nniche topics, or narrowly targeted research, where repeated use of the same\nterminology, coined expressions or formulas may be justified. As the retrieved\nfalse positives demonstrated, evaluating the presence and severity of plagiarism\nusing numerical scores alone remains insufficient without the addition of human\njudgment.\nFuture strategies to reduce the number of FP could include targeted heuristics\nto prevent premature classification of editorials, updates, long review articles on\nidentical topics or articles with matching citation lists, especially when citation\nlists occur in the background sections. Additionally, a fuzzy author-namematching method could help avoid minor discrepancies in spelling from\ncontributing to FP.\n\n6.4.2.4\n\nExamples of CbPD-identified Cases\n\nAccusations of plagiarism can have serious consequences. To avoid unjust\naccusations, we publish no unconfirmed plagiarism cases in this thesis. Since\nPubMed has only brought two57 retraction procedures to closure thus far, this\nsection presents the publications confirmed as plagiarism by the earlier authors\nonly in anonymized form. The unconfirmed suspicious cases are available\nthrough a password-protected website. For access information, please refer to\nAppendix C.\nExamples of Strong Disguise\nThe CbPD approach identified similarities among publications when the\ncharacter-based approach detected no notable similarities. Figure 50 shows one\nsuch example. The visualization in CitePlag shows a paraphrase rewritten in the\n57\n\nOnly one retraction procedure was initiated by our contact to earlier authors. Both\npublications were retrieved by the CbPD algorithms.\n\n6.4 Evaluation using PubMed Central OAS\n\n189\n\nauthor’s own words and parallel lines connecting a sequence of matching\ncitations at the location where the paraphrase occurs. This example can be\nexamined using the prototype at: http://citeplag.org/compare/110389/136117. To\nspot the paraphrase, refer to the paragraph beginning “The inflammatory\ncascade... [121]”.\n\nFigure 50: Example of CbPD-detected Paraphrase\nSource: http://citeplag.org/compare/110389/136117\n\nFigure 51 displays two figures where the placement of cell components and\nthe alignment of arrows between the components are noticeably similar. Despite\ninstances of paraphrasing and similarities among figures, the articles share\ninsufficient text overlap to be retrieved using character-based methods.\n\n190\n\n6 Quantitative and Qualitative Evaluation\n\nEarlier document:\n\nLater document:\n\npublished 2006-05-19\nPMCID 16712719 [343]\n\npublished 2010-10\nPMCID 21180461 [121]\n\nFigure 51: Example of CbPD-detected Image Similarity\n\nAlthough the author of this thesis does not categorize the similarities in these\nparticular documents as plagiarism, the more subtle similarities, such as those\npresented in Figure 50 and Figure 51 can be of relevance to examiners when\nevaluating scientific documents. For example, a reviewer evaluating the merits of\na grant proposal may likely be interested in what could be termed &quot;mild forms of\nunoriginality&quot;, i.e. instances of similarity shared with other proposals, patents or\npublished ideas, to cross check the level of uniqueness and originality of the\nindividual proposals. Given this potential use case, one can see that the definition\nof what constitutes a &quot;relevant&quot; retrieval varies.\n\n6.4 Evaluation using PubMed Central OAS\n\n191\n\nExample of High Textual Similarity but low Semantic Similarity\n\nFigure 52: Document with High Character-based but Low Semantic Similarity\nSource: http://citeplag.org/compare/49670/49628\n\nThe articles PMCID 1920590 and PMCID 2396213, which are shown sideby-side in Figure 52, represent an example of a document pair that shares\nsignificant similarity in structure and wording, yet shares no notable\ncitation-based similarity.\nThe authors of the earlier article judged the similarities as follows:\n“Although, there are some similarity for these two papers; however, the\nresearch subject, material and data are different from each other. I do not\nthink it is plagiarism.”\nIt seems that the authors of the later article read the earlier article and\npartially used it as a template for writing their own article. Whether this\nconstitutes plagiarism is controversial. The example illustrates the\ncomplementary strength of the character-based and citation-based detection\napproach. While the character-based approach correctly identified the significant\n\n192\n\n6 Quantitative and Qualitative Evaluation\n\ntextual overlap, the low citation-based score correctly indicated the absence of a\nsignificant semantic similarity in this case.\nExamples of Confirmed Plagiarism Cases\nThis section presents cases we identified using the CbPD approach. We\ncontacted the authors of earlier published articles and asked them whether they\nconsidered the later published article to have plagiarized their work.\nSo far, PubMed has officially retracted three cases [165, 281]. One case\n[281] was retracted upon our correspondence with the earlier authors, while the\nother case identified by the algorithms [165], had already been retracted at the\ntime of analysis. Most recently, an author informed us that the Indian Journal of\nUrology, which had published a medical case report [148] that plagiarized his\nreport plans to release a retraction notice in the next issue. The authors of the\nearlier publications confirmed plagiarism in five additional cases. This thesis\npresents author-confirmed plagiarism cases – those which have not yet been\nretracted – only anonymously to avoid the possibility of false accusation. The\ndirect links to the earlier publications, i.e. the original sources from which the\nlater publications plagiarized are publically available on the http://citeplag.org/\nwebsite. However, we refrain from citing the original sources here. We want to\navoid linking any researcher’s name by citation to a work on the topic of\nplagiarism detection, which alone can possibly negatively affect an author’s\nacademic standing.\nTable 23 lists the five author confirmed plagiarism cases, along with the three\nofficially retracted publications. The PMC IDs of the not yet officially retracted\npublications (both the earlier and later publications) are only given in\nanonymized form, where &quot;X&quot; replaces the last two digits of the PMC IDs. The\nnot yet officially retracted cases are available upon request, however, only\nthrough a password-protected website, as described in C. We will continuously\nupdate http://citeplag.org, where the cases will be published once they have been\nofficially retracted.\n\n6.4 Evaluation using PubMed Central OAS\n\n193\n\nTable 23: Author Confirmed or Retracted Plagiarism Cases\nCase\nID\n\nEarlier\npublication\n\nLater\npublication\n\nDate authors\ncontacted\n\nDate authorconfirmed\n\n1\n\nPMC27651XX\n\nPMC29000XX\n\n2013-05-06\n\n2013-05-06\n\n2\n\nPMC20398XX\n\nPMC27228XX\n\n2013-05-06\n\n2013-05-09\n\n3\n\nPMC22283XX\n\nPMC28819XX\n\n2013-05-06\n\n2013-05-09\n\n4\n\nPMC11494XX\n\nPMC28595XX\n\n2013-05-06\n\n2013-05-07\n\n5\n\nPMC28574XX\n\nPMC26498XX\n\n2013-05-06\n\n2013-05-06\n\nI\n\nPMC1065018\n\nPMC2772258\n\n2012-09-03\n\nretracted58\n\nII\n\nPMC514558\n\nPMC2807707\n\nn/a\n\nretracted59\n\nIII\n\nPMC2740512\n\nPMC2978450\n\n2013-05-06\n\nretracted60\n\nVerifying and proving structural and idea plagiarism is considerably more\ndifficult than the verification of copy &amp; paste plagiarism (see Section 2.1.2 and\nUser Utility on page 171). While in cases of literal plagiarism a much lower risk\nof false accusations exists and verification can be done quickly, it is often nearly\nimpossible to prove if someone &quot;stole&quot; or &quot;copied&quot; an idea or lines of argument.\nThis makes proving plagiarism extremely difficult, especially if the work bears\nno close resemblance, such as copied words, to prove it61.\n\n58\n59\n60\n61\n\nhttp://citeplag.org/compare/4727/43777\nhttp://citeplag.org/compare/5583/117324\nhttp://citeplag.org/compare/18399/13772\nThe author is not aware of any publications that were retracted solely on the basis of\nstolen ideas.\n\n194\n\n6 Quantitative and Qualitative Evaluation\n\nEven in cases where it seems very likely that plagiarism is present, many\nauthors are not willing to initiate a retraction process. For instance, one contacted\nauthor confirmed plagiarism but also wrote:\n“We are not willing to do this job ourselves because this will lead\nto great conflict with the author of the second paper who is living\nin the same country, even though we do not know him personally.”\n(Refer to Appendix G for additional author reactions.)\nMoreover, heavily disguised plagiarism, such as paraphrases and the hard to\nprove structural and idea plagiarism, are often considered &quot;less critical&quot; forms of\nplagiarism. It is therefore not surprising that the author confirmed and the\nretracted cases contain extensive plagiarism, most prominently of the copy &amp;\npaste and shake &amp; paste type. Figure 53 shows the citation pattern visualization\nfor six cases of plagiarism from Table 23 using the CitePlag prototype.\n\n6.4 Evaluation using PubMed Central OAS\n\n195\n\nFigure 53: Citation Pattern Visualization of Confirmed Plagiarism\n\n6.4.3 Conclusion of PMC OAS Evaluation\nThe evaluation using the PubMed Central Open Access Subset (PMC OAS)\npresented the third and final evaluation of both practicability and detection\nperformance of the CbPD algorithms. Utilizing this large-scale, non-fabricated\nscientific collection presented a realistic plagiarism detection setting. The CbPD\nalgorithms capably detected currently unidentified scientific plagiarism and\noutperformed the tested character-based approaches in detecting instances of\n\n196\n\n6 Quantitative and Qualitative Evaluation\n\nstrongly disguised forms of plagiarism. Moreover, it was shown that CbPD\nfacilitates the document verification process for the examiner and has a\nsignificantly higher computational efficiency.\nThe detection effectiveness of seven CbPD algorithms and two proven\ncharacter-based approaches were evaluated using a ground truth derived in a\npooling process followed by human judgment. For each plagiarism form, we\ncompared the top-10 document pairs that user study participants rated as most\nsuspicious with the ranks at which each of the nine detection approaches\nretrieved the ten document pairs. We found that character-based approaches were\nsignificantly more effective in ranking highly those documents containing copy\n&amp; paste and shake &amp; paste plagiarism forms, while the citation-based approaches\noutperformed the traditional approach for ranking the more heavily disguised\nforms, including paraphrases, structural and idea plagiarism.\nFalse positives presented a larger challenge for character-based approaches\nthan for citation-based approaches, because in medical publications the reuse of\nstandardized expressions and boilerplate text can be legitimate in certain\ncircumstances. Case studies and journal editorials thus posed a challenge to the\ncharacter-based detection approach, which prominently retrieved these document\ntypes among its false positives. The citation-based approaches retrieved such\ncases of legitimate text reuse less frequently, because they featured either unique\ncitation patterns, for example, in case studies and editorials, or insufficient\ncitations due to their non-scientific nature. Figure 46 illustrates this observation.\nThe character-based approach Encoplot retrieved 205 false positives out of\n235 documents examined, while the LCCS approach retrieved only one false\npositive out of 31 documents examined. These results may not be applicable to\nother corpora, since every corpus contains diverse document types from different\ndisciplines, and the reuse of citations or text may be considered legitimate by\nsome disciplines or for certain document types, e.g., medical case studies.\nThe evaluation of user utility in the verification process of potential\nplagiarism showed that the citation-based approach offers distinct advantages.\nExaminers rated the citation-based approach as the single most effective\nvisualization method for assisting in the verification of structural and idea\n\n6.4 Evaluation using PubMed Central OAS\n\n197\n\nplagiarism. They perceived a combined visualization approach of text and\ncitations as most effective for detecting paraphrases and shake &amp; paste\nplagiarism. In examining user effort, we recorded a notable reduction in the\nmean times required to identify suspicious similarity once citation patterns were\nvisualized. User time-savings were highest for structural and idea plagiarism,\nparaphrases and translated plagiarism forms.\nComputational efficiency is crucial for PDS, since performing exhaustive n:n\ncomparisons for large document collections quickly becomes unfeasible using\ncurrently available PDS. Character-based approaches require pairwise document\ncomparisons for the entire collection to prevent a reduction in detection\nperformance. The exhaustive n:n examination of the PMC OAS collection could\nnot have been carried out using any of currently and freely available methods,\ndue to the unfeasible runtime requirement. Whether a similar high quality, yet\ncomputationally efficient approach is offered by any proprietary systems remains\nuncertain. The CbPD approach requires fewer resources, since only the\ndocuments with Bibliographic Coupling strength greater or equal to one require\nfurther analysis. A comparison of computational efficiency of the Encoplot and\nSherlock character-based approaches with the CbPD algorithms, using a\nminimum threshold coupling strength of five, showed that for a collection in the\nPMC OAS size range, character-based approaches would require approximately\n100 years of processing, while the CbPD5 algorithm requires only one day on a\ncurrent model quad-core system.\nUsing a non-artificially created corpus allowed the comparison of\neffectiveness of character-based and citation-based detection approaches in\nidentifying currently unidentified real-world plagiarism cases, some of which\nshowed sophisticated plagiarism disguise. The CbPD approach identified several\ninstances that could not be detected by the two baseline approaches that are\nrepresentative of today’s detection approaches.\nAs a result of our contact with authors, one plagiarized medical study and a\nplagiarized case report have already been retracted by the issuing journal.\n\n198\n\n6 Quantitative and Qualitative Evaluation\n\nFurthermore, five publications have been author-confirmed as plagiarism, and\nseveral additional publications are currently under examination62.\n\n6.5 Conclusion of Evaluations\nThe evaluation of Citation-based Plagiarism Detection (CbPD) algorithms for\ntheir practicability, detection effectiveness, user utility, and computational\nefficiency demonstrated promising results. The single largest benefit of CbPD\nwas its potential to identify heavily disguised plagiarism, such as paraphrases,\ntranslated plagiarism, and structural and idea plagiarism. Even for heavily\ndisguised plagiarism, we often observed similarities remaining in the citation\npatterns. The character-based methods currently in use rely on textual similarity\nalone for plagiarism detection and are thus unable to detect strongly disguised\nforms of plagiarism.\nAn obstacle to the evaluation was the nonexistence of a suitable test\ncollection. Test collections used in previous plagiarism detection evaluations\nwere unsuitable for evaluating the performance of CbPD in detecting strongly\ndisguised plagiarism, because previously used collections were either artificially\ncreated or had no ground truth regarding the presence of disguised forms of\nplagiarism. Methods for artificially creating disguised plagiarism include using\ncrowdsourcing services, e.g., Amazon’s Mechanical Turk [262] or oDesk [265],\nfor contracting writers that perform the task. Asking humans to paraphrase text\nproduces more realistic disguise than employing random text alterations.\nNonetheless, such services cannot reproduce the sophisticated disguises\nintegrated into publications that scientists worked on, often over years, with the\ngoal of publishing in a reputable journal.\nThe creation of an ideal test collection would require extensive secret\nmonitoring of scientists’ work, e.g., a Trojan horse, to study which sources they\naccess and how they attribute the work of others. Only such a study would allow\ntracing instances of realistic idea plagiarism with acceptable confidence.\n62\n\nAs of 2013-05-08.\n\n6.5 Conclusion of Evaluations\n\n199\n\nHowever, the creation of such an ideal test collection would be extremely\nresource intensive, not to mention infeasible for ethical reasons. Since no single\nideal test collection exists, or can reasonably be created, we combined three realworld document collections of various sizes and characteristics – the GuttenPlag\nWiki, the VroniPlag Wiki and the PMC OAS – to mitigate limitations of the\nindividual corpora.\nFirst, we used the GuttenPlag Wiki to compare the CbPD approach to\ntraditional character-based PDS in detecting the translated plagiarism present in\nthe doctoral thesis of K.-T. zu Guttenberg. It can be assumed that the extensive\ncrowd-sourced analysis of this real-word plagiarism case identified a very large\nportion of all plagiarism instances in the thesis. This serves as a ground truth for\nperformance comparisons. The CbPD algorithms identified 13 of the 16\ninstances of translated plagiarism in the thesis, while the character-based PDS\nwe tested could not identify any.\nSecond, we used the VroniPlag Wiki. This collection featured confirmed\nplagiarism instances from multiple authors, allowing an evaluation of CbPD on\nvarious writing and plagiarism styles. In an analysis of randomly chosen\nplagiarized fragments from 15 theses, citation analysis alone could identify seven\nof the 15 theses as clearly suspicious. Analyzing translated plagiarism in\nparticular, the CbPD approach identified four of the seven theses that contained\ntranslated plagiarism as clearly suspicious and another thesis as likely suspicious.\nThird, we demonstrated CbPD’s potential to detect plagiarism in the\n‫׽‬234,000 publications of the biomedical collection, PubMed Central Open\nAccess Subset. Some plagiarism cases would have remained undetected using\ncurrent approaches. Since no ground truth exists, we used a pooling approach in\ncombination with human judgment collected in a user study to create a test\ncollection.\nResulting from our contact with authors, one plagiarized medical study and a\nplagiarized case report have already been retracted by the issuing journal.\n\n200\n\n6 Quantitative and Qualitative Evaluation\n\nAdditionally, five publications have been author-confirmed as plagiarism, and\nseveral other publications are currently under examination63.\nA comparison of detection effectiveness against the baselines Encoplot and\nSherlock, two proven character based approaches, confirmed our hypothesis that\nCbPD and character-based approaches complement each other. Character-based\napproaches are ideal for identifying undisguised local forms of plagiarism, while\nthe citation-based approaches are ideal for detecting disguised global forms.\nThe complementary strengths of the character-based and citation-based\napproaches were also reflected in the reports of user utility. While characterbased methods were rated as most helpful in manual verification of copy &amp; paste\nplagiarism, study participants stated the citation visualizations of the CbPD\napproach as the single most useful aid for verifying structural and idea\nplagiarism, and as a valuable addition for paraphrases and shake &amp; paste\nplagiarism. CbPD also reduced user effort, measured in time required to identify\nsuspicious instances, for Guttenberg’s translated plagiarism.\nThe computational efficiency of the citation-based approach was shown to be\nsuitable for the analysis of large corpora and for filtering large datasets prior to\napplying the computationally more expensive character-based approaches. The\nworst-case complexity of performing an n:n comparison is ܱ(݊2) for both\ncharacter-based and citation-based approaches. However, in an average case, a\nCbPD analysis in an n:n fashion requires only a small fraction of the\ncomparisons necessary for a character-based analysis. The reason is that CbPD\nalgorithms only need to analyze documents that are bibliographically coupled. In\nthe case of the PMC OAS, the BC requirement reduced the number of document\npairs to be analyzed by 99.77 %, from approximately 17 billion to approximately\n39 million. Reducing the number of documents to compare is essential when\nanalyzing a collection the size of PMC OAS with character-based approaches.\nAside from excluding documents that are not bibliographically coupled as we\ndid, character-based heuristics, like fingerprinting or keyword-based clustering,\ncould be used to limit collection size. However, to our knowledge, we found no\n63\n\nAs of 2013-05-08.\n\n6.5 Conclusion of Evaluations\n\n201\n\npublically available character-based PDS that allowed analyzing a collection of\nseveral hundred thousand documents in a feasible amount of time.\nIn conclusion, the multiple-collection evaluation of CbPD uniformly showed\nthat citation-based plagiarism detection and character-based plagiarism detection\nhave complementary strengths and weaknesses. Character-based approaches\nexcel at detecting unmodified and local forms of plagiarism, including short\npassages copied verbatim and only moderately paraphrased text. They fail,\nhowever, when it comes to detecting strongly paraphrased text or translated\nplagiarism, which we showed to be the strength of the CbPD approach.\nThe reader is encouraged to explore the citation visualization of the CitePlag\nprototype and view examples at: http://www.citeplag.org/thesis\n\n7 Summary &amp; Future Work\nThis chapter summarizes the thesis in Section 7.1, reviews the contributions of\nthe research presented in Section 7.2, and gives an outlook on future work in\nSection 7.3.\n\n7.1 Summary\nThis doctoral thesis proposed a novel approach to plagiarism detection, thereby\naddressing an information retrieval problem that has so far not been satisfactorily\nsolved – the machine-detection of strongly disguised and translated academic\nplagiarism. State-of-the-art plagiarism detection systems (PDS) employ\ncharacter-based text comparisons, which reliably detect copy &amp; paste plagiarism\nand, to varying degrees, slightly modified plagiarism. Current PDS are unable to\ndetect strongly disguised forms of plagiarism, such as paraphrases, translated\nplagiarism, and idea plagiarism. The concluding remark in the 2012 Collusion\nDetection System Test performed by the HTW Berlin University of Applied\nScience states\n“[...] for translations or heavily edited material, the systems are\npowerless [...]” [360].\nTo address the weakness of current systems, this thesis introduced Citationbased Plagiarism Detection (CbPD), a fundamentally different approach to\nplagiarism detection. Compared to existing approaches, CbPD does not make use\nof character-based similarity, but rather analyzes the citation patterns within\ndocuments to form a language-independent fingerprint representing semantic\nsimilarity between documents. To cover the different forms of plagiarism and the\nresulting citation pattern characteristics, three classes of CbPD algorithms were\nintroduced: Longest Common Citation Sequence, Greedy Citation Tiling and\nCitation Chunking. The algorithms are capable of handling transpositions and\nscaling of citations. Additionally, the algorithms take into account the probability\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8_7, © Springer Fachmedien Wiesbaden 2014\n\n204\n\n7 Summary &amp; Future Work\n\nof co-occurrence of identical citations by chance, as well as the number and\nproximity of matching citations in a pattern.\nAs a proof of concept, and to evaluate the detection performance of the CbPD\napproach in a real plagiarism detection setting, we developed the prototype\nCitePlag. CitePlag is composed of a document parser, a relational database, a\ndetector component, and a frontend. CitePlag produces interactive visualizations\nof both citation and text similarities between documents to aid the human\nexaminer in arriving at a conclusion on potential plagiarism. The CitePlag\nfrontend is web-based and accessible at: http://www.citeplag.org\n\nFigure 54: CitePlag Plagiarism Detection Prototype\nSource: http://citeplag.org/compare/6861131\n\nWe performed a comprehensive evaluation of the CbPD approach using the\nCitePlag prototype to collect human judgment as a ground truth. Three unique\n\n7.1 Summary\n\n205\n\ndocument collections were used for evaluation purposes, since no single\ncollection fulfilled all necessary test-collection criteria:\n-\n\nmust contain scientific publications with citations\n\n-\n\nmust contain real-world plagiarism cases (non-fabricated)\n\n-\n\nthe extent of plagiarism must be known (ground truth exists)\n\nWe chose the GuttenPlag Wiki because it represents one of the most\nthoroughly examined cases of plagiarism. This makes the collection unique in\nthat it allows for a realistic ground truth approximation. The CbPD algorithms\nidentified 13 of the 16 translated plagiarism instances contained in the thesis,\nwhile the three tested PDS could not identify a single instance.\nWe chose the VroniPlag Wiki collection because it contains thoroughly\nexamined academic plagiarism from various authors, thus covering a wider range\nof citation styles and plagiarism forms. Side-by-side comparisons of plagiarized\ntext excerpts from the VroniPlag Wiki showed that the copying of citations – if\npresent in the source – is common behavior among plagiarists. Even when\ntranslating text, or otherwise attempting to disguise textual similarity, authors\nmade little to no effort to disguise the order in which they copied citations. Our\nobservation of plagiarism behavior indicates that the CbPD approach is suitable\nfor detecting strongly disguised forms of plagiarism in real-world settings.\nRelying only upon a comparison of citation patterns, CbPD could identify five of\nthe seven translated plagiarism cases in the VroniPlag Wiki.\nWe chose the PubMed Central Open Access Subset (PMC OAS) to access\nmore strongly disguised scientific plagiarism, which has not yet been identified.\nLimiting our evaluation to identified plagiarism cases would be insufficient.\nIdentified cases tend to feature higher instances of textual similarity, given that\nthese cases were detected either using currently available PDS, or because high\nsimilarity sparked suspicion among human reviewers. The PMC OAS collection\ncontains almost no examples of identified plagiarism cases. This allows an\nevaluation of the practicability of CbPD in a realistic setting and on a large scale,\nusing a test collection of 185,170 medical publications. Comparison of detection\n\n206\n\n7 Summary &amp; Future Work\n\nperformance against two state-of-the-art PDS showed that CbPD was the only\napproach capable of revealing heavily disguised instances of plagiarism. As a\nresult of our investigation, PubMed has already retracted one plagiarized medical\nstudy and one plagiarized case report. Moreover, the evaluation showed that\nplagiarists usually do not substitute citations when disguising the origin of\nplagiarized text, which makes citations suitable language-independent markers\nfor forming a disguise-resistant semantic fingerprint of a publication.\nTable 24: Capabilities of Current PD Approaches and CbPD\nThis table expands on Table 8.\n\nCharacter-based (Char.)\nExact String Matching\nApproximate String Matching\nFingerprinting\nVector Space Models\nSemantic Enhancements\nCross-language (CLPD)\nStylometry (Style)\nCitation-based (CbPD)\n\nX\n\nReferences\nIdea\n\nTranslated\n\nShake &amp; Paste\n\nUndue Paraphrase\n\nNear copies\n\nForm of plagiarism\n\nCopies\n\nCross-lingual PD\n\nMono-lingual PD\n\nDetection Approach\n\nIntrinsic PD\n\nExtrinsic PD\n\nApplication\n\nX\n[19, 137, 175, 232]\n[285, 370]\n[57, 142, 245, 293,\n[24, 238, 252, 328,\n\nX\n\nX\n\nX\n\nX X\nX X\n\n[22, 190, 252, 333]\n[172, 239, 263, 371]\n[97, 238, 319, 322]\n[127, 129, 132]\n\nHybrid: Character-based and citation-based combined\nX\nX X\n[127, 129, 132]\nHybrid (Char./CLPD/Style/CbPD)\n\nDetection rate:\n\nGood\n\nFair\n\nPoor\n\nUnfit\n\nThe strengths and limitations of the different plagiarism detection approaches\nare summarized in Table 24. The table shows that both the character-based and\nthe citation-based approaches have their own unique strengths. While the\ncharacter-based approach capably identifies local forms of plagiarism, such as\n\n7.2 Contributions\n\n207\n\ncopy &amp; paste, the CbPD approach excels in detecting global forms of strong\nparaphrases, translated plagiarism, and idea plagiarism. A hybrid approach that\ncombines CbPD with existing character-based detection approaches significantly\nimproves the detection rates for all forms of plagiarism, as is shown in the final\nrow in Table 24.\nAddressing academic plagiarism by technical means alone remains an\ninsufficient solution in the long-run, since plagiarism is a societal problem and\nmust also be addressed with societal solutions, i.e. providing education,\nguidelines, and policies to prevent plagiarism. At the same time, when\nprevention fails, employing technical means for plagiarism detection is a\npromising complementary approach. Advances in plagiarism detection software\ncan significantly increase the likelihood of discovery and thus decrease the\nbenefits of plagiarizing as perceived by the plagiarist. The CbPD approach\ncontributes to making scientific plagiarism less &quot;worthwhile&quot;, by forcing the\nplagiarist to substitute citations, which requires time and subject expertise.\nAdditionally, CbPD increases the likelihood of machine-identifying even\nheavily disguised plagiarism, including translated plagiarism. In many cases,\ndisguising plagiarism until it contains neither character-based nor citation-based\nsimilarities requires such effort that acquiring content through plagiarism may no\nlonger be an attractive option to a plagiarist over creating genuine content.\n\n7.2 Contributions\nThis section summarizes the contributions of this thesis for each of the research\ntasks presented in Section 1.3.\nTask 1:\n\nPerform a comprehensive analysis of the individual\nstrengths and weaknesses of state-of-the-art plagiarism\ndetection approaches and systems.\n\nWe reviewed the literature and tested available detection approaches and\nsystems. We found that state-of-the-art systems for plagiarism detection are\n\n208\n\n7 Summary &amp; Future Work\n\ncapable of detecting copied or slightly disguised cases of plagiarism, but fail to\ndetect the more heavily disguised forms of plagiarism, such as paraphrases,\ntranslated, and idea plagiarism.\nTask 2:\n\nDevelop a plagiarism detection concept that addresses\nthe identified weaknesses of current plagiarism\ndetection approaches.\n\nTo overcome the deficiency of the current plagiarism detection approaches a\nnovel concept, Citation-based Plagiarism Detection (CbPD), was proposed.\nUnlike currently used detection approaches, which focus solely on textual\noverlap, CbPD uses the placement of in-text citations as a language-independent\nmarker for modeling semantic similarity between documents.\nTask 3:\n\nDesign detection algorithms that employ the theoretical\nconcept introduced and are fitted to detect the\nplagiarism forms currently not machine-detectable.\n\nTo enable effective and efficient detection of the different plagiarism forms,\nwe designed and implemented three classes of detection algorithms: Longest\nCommon Citation Sequence, Greedy Citation Tiling and Citation Chunking.\nEach class considers the citation pattern characteristics unique to the various\nplagiarism forms. The Longest Common Citation Sequence algorithm ignores\nnon-matching citations between matching citations. This algorithm is especially\nsuitable to identify document-wide disguised plagiarism, as well as local\ninstances of plagiarism if sufficient citations are given. The Greedy Citation\nTiling algorithm identifies only identical citation patterns, an approach especially\nsuitable for detecting shake &amp; paste plagiarism. The variations of the Citation\nChunking algorithm check patterns for potential transpositions or scaling of\ncitations, which is useful in detecting locally confined instances of disguised\nplagiarism. Additionally, citation patterns are evaluated taking into account (1)\n\n7.2 Contributions\n\n209\n\nthe probability that the shared citations in the matching patterns co-occur by\nchance, and (2) the number, proximity, and order of shared citations in the\nmatching patterns.\nTask 4:\n\nImplement a prototype of a plagiarism detection system\nthat employs the developed algorithms to demonstrate\nthe applicability of the approach in real-world scientific\ndocument collections.\n\nTo evaluate and demonstrate the proposed concept in real-world conditions\nwe developed CitePlag, a plagiarism detection system prototype capable of\napplying the CbPD approach to a large scientific corpus. The system consists of\na relational database, a parser, a detector, and a web-based user-interface at the\nfrontend. The database stores the bibliographic document data as extracted by the\nparser and stores the results of the CbPD algorithms as implemented in the\ndetector component. The web-based frontend retrieves the detection results from\nthe database and visualizes the suspicious document in an interactive side-byside display for human inspection.\nThe frontend64 is accessible at: http://www.citeplag.org\nTask 5:\n\n64\n\nEvaluate the proposed concept in identifying strongly\ndisguised plagiarism forms by comparing detection\nperformance, user utility, and computational efficiency\nto state-of-the-art systems. As proof of concept, identify\nunknown and currently non-machine-detectable\nplagiarism instances.\n\nThe frontend was developed in collaboration with students from the HTW Berlin. See\nSection 5.4 for details.\n\n210\n\n7 Summary &amp; Future Work\n\nTo validate the effectiveness and efficiency of the CbPD approach, we\nperformed three distinct evaluations using real-world document collections.\n-\n\nAn analysis of the doctoral thesis of zu Guttenberg showed that\nCbPD is considerably more suitable for identifying translated\nplagiarism than currently used approaches. Of the 16 translated\nplagiarism fragments in the thesis, the CbPD approach identified\n13, while the tested PDS were unable to identify a single fragment.\n\n-\n\nAn analysis of the VroniPlag Wiki, which contains plagiarism\nfrom a diverse group of authors, showed promising results\nregarding CbPD’s ability to detect plagiarism and in particular\ntranslated plagiarism.\n\n-\n\nAn analysis of the PMC OAS corpus, containing ‫׽‬200,000\nmedical publications, showed that the CbPD approach is capable\nof identifying cases of plagiarism, which remain undetected by\ncurrent plagiarism detection approaches.\n\nIn addition to demonstrating the practical suitability of CbPD for three\ndistinct test collections, the comprehensive evaluation led to the following\nconclusions:\n-\n\nA high (relative) Bibliographic Coupling strength alone is not a\nsufficient indicator for plagiarism, since it results in many false\npositives. Analyzing the citation patterns in regard to factors, such\nas order and proximity of citations, significantly improves\ndetection performance.\n\n-\n\nThe presented approach is computationally more efficient than\nmost currently used character-based approaches. This makes it\napplicable also to large document collections. While an n:n\ncomparison of the complete PMC OAS corpus using a\ncharacter-based PDS, e.g. Encoplot, would have required ~100\n\n7.3 Future Work\n\n211\n\nyears, performing the CbPD computations required only 14.7\nhours on a current quad-core processor system.\nEvaluating the CbPD approach necessitated the creation of a suitable test\ncollection due to the shortcomings of currently available collections. The\ncollection created using the PMC OAS contains 185,170 scientific publications\nand a user study derived ground truth for 181 unique publications retrieved by\nnine tested detection algorithms among their top-30 ranks. This dataset currently\nrepresents the only scientific document collection suitable for evaluating\nstructural and idea plagiarism on a large scale. The collection is available upon\nrequest. See Appendix C for access details.\nThe dataset includes:\n-\n\nthe full texts of the PMC OAS collection cleaned of duplicates and\nconverted to plain text.\n\n-\n\nextracted data of citations including their positions within the PMC\nOAS full-texts.\n\n-\n\nextracted, disambiguated data of references in the PMC OAS.\n\n-\n\npre-computed similarity scores for documents in the PMC OAS\nusing three character-based similarity measures, Encoplot,\nSherlock and Lucene, as well as 21 citation-based measures,\nincluding Longest Common Citation Sequence, Greedy Citation\nTiling, Citation Chunking, Bibliographic Coupling, Co-Citation.\n\n-\n\nuser-identified suspicious fragments and confirmed cases of\nplagiarism in the PMC OAS corpus.\n\n7.3 Future Work\nThe development and evaluation of a citation-based approach to plagiarism\ndetection (PD) introduced several ideas for future applications and improvements\n\n212\n\n7 Summary &amp; Future Work\n\nto today’s PD technology. This section on future work gives an outlook on the\ngeneral research needed in Section 7.3.1, and proposes strategies to improve\nCbPD detection accuracy in Section 7.3.2. Additional applications of the CbPD\nand the Sequential Pattern Analysis approach are presented in Section 7.3.3, and\nthe need for further evaluations is explained in Section 7.3.4.\n\n7.3.1 General Research Need\n7.3.1.1\n\nDefining Newly Detectable Plagiarism Forms\n\nThe CbPD approach opens up a discussion on the current definition of\nplagiarism and the levels of structural similarity in documents that adequately\nrepresent critical thresholds. Disguised plagiarism forms have not been\naddressed as thoroughly in plagiarism research as the more easily detectable and\nverifiable non-disguised plagiarism forms. No consensus exists on thresholds of\nsimilarity that should be interpreted as disguised plagiarism, or how these more\nsubtle forms of similarity should be dealt with.\nAn example of the type of questions that could arise is if copying numerous\ncarefully selected citations listed in a table constitutes plagiarism. The judgment\nmight depend on factors such as the percentage of identical citations, whether\ncitations have been inserted or deleted, whether the copied citations are highly\nco-cited, or whether the order of copied citations is identical. However, even an\nidentical order can be legitimate if, for example, both authors cite papers\nchronologically or alphabetically by author names. Such a plagiarism form, for\nwhich a fitting term could be citation composition plagiarism, has thus far not\nbeen considered. Thus, a discussion of suitable criteria and similarity thresholds\nfor plagiarism forms newly identifiable with the CbPD approach is of\nimportance. Such a discussion, however, lies beyond the scope of this thesis.\n\n7.3 Future Work\n\n213\n\n7.3.2 Improvements to Detection Accuracy\n7.3.2.1\n\nConsidering Document Sections for Citation Occurrences\n\nWhen analyzing the PMC OAS document collection for plagiarism, we found\nthat high textual and citation similarity often occurs in the introduction and\nrelated work sections. When talking to the authors of the original work, we found\nthat they often do not consider such similarity as plagiarism.\n“...The basic problem is that there are only a limited number of ways to\nprovide the information common to both introductions (mostly the list of\ngenes responsible for inherited cataracts), and if the authors had not\nlisted them in the order taken from our previous manuscript, they would\nsimply have had to shuffle the order a bit, which seems a little silly...”65\nA previous plagiarism investigation of articles in PubMed gathered similar\nfeedback from authors [202]. Authors stated that the repetition of highly similar\ntext in their own manuscripts or the manuscripts of collaborators is a common\npractice and in most cases not considered a violation of academic principles\nwithin their field. Repeating similar or identical text is especially common in\nintroductory sections, for describing experimental settings, or as part of review\narticles [114, 202].\nWe agree that mild forms of &quot;plagiarism&quot; are less serious if they occur in\ncertain document sections, such as in the introduction or in the related work\nsection, than if they occur, for example, in the results section. To reduce false\npositives, the detection algorithms should take into consideration document\nsection when calculating the CbPD score. Additional empirical research will be\nnecessary to determine reasonable weightings for citation matches depending on\ntheir placement in the publication.\n\n65\n\nQuoted from an email exchange with an author who wished to remain anonymous.\n\n214\n\n7.3.2.2\n\n7 Summary &amp; Future Work\n\nAccounting for Citation Substitution\n\nIf CbPD finds widespread use, plagiarists may deliberately substitute references\nwith topically similar references. The CbPD detection algorithms could\ncounteract such obfuscation attempts by also considering related citations as part\nof the similarity assessment. In order to analyze related citations, the detection\nalgorithms would require a set of references viewed as ‘interchangeable’.\nCharacter- and citation-based similarity measures, such as Co-citation Proximity\nAnalysis [126], could be employed to compute the set of related citations.\nIncluding related citations in the analysis will potentially lead to more false\npositives and a higher computational effort. However, we hypothesize that\nincluding these additional checks will have a strong deterrent effect. If authors\nmust sift through large amounts of related literature to re-order all references in a\nunique coherent way, only to avoid detection, the task becomes so time\nconsuming that producing original work becomes the more attractive option.\nThe counter-measure to citation shuffling and substitution could additionally\nbe to analyze not only the order of these markers, but also their proximities. In\nthis way, the character distance fingerprint would remain similar even if all\nmarkers in a document were replaced. So far, however, we have not researched\nthe effectiveness of these counter measures.\n\n7.3.2.3\n\nReducing False Positives Using Co-citation Proximity Analysis\n\nFalse positives are a common problem of PDS. To aid in reducing false\npositives, we are assessing the possibility of using CPA (see Section 3.2.5). One\ncan assume that most authors carefully examine the merits of the documents they\ncite. Thus, in the case of frequently co-cited documents, and especially in the\ncase of documents with a high CPA score, authors are assumed to have read and\nrecognized the validity and contributions of the documents they cited together.\nTherefore, we regard it as unlikely that documents contain plagiarism originating\nfrom documents with which they are frequently co-cited. Furthermore, in the\ncase that plagiarism is present, it is very unlikely that it has not yet been\nidentified and reported in frequently co-cited documents. This consideration may\n\n7.3 Future Work\n\n215\n\nhelp reduce false positives, although we have not yet collected empirical\nevidence for this hypothesis.\n\n7.3.2.4\n\nEvaluating Intrinsic Citation-based PD\n\nWhether intrinsic66 citation-based approaches are suitable in identifying\nplagiarism remains a question to be addressed by future research. Unexpected\ndeviations in the type or style of citations may possibly point to plagiarism. For\nexample, if a certain document section cites only non-open access publications,\nwhile the rest of the document cites only open access publications, this can\npotentially indicate copied sections of another author’s literature review or\ncopied paper structure and ideas. Similarly, if an author abbreviates other\nauthors’ first names, except in a few instances where the authors’ first names are\nwritten out fully, this may be an indicator of unoriginal work. Additionally, if an\nauthor follows the convention of citing the first and last pages from works cited,\nyet in other sections only provides the beginning page number for a citation, the\ncitation information may have been copied.\n\n7.3.2.5\n\nMachine Learning of Similarity Characteristics\n\nIf a larger suitable test collection that features a reliable ground truth should ever\nbecome available, one could consider the use of machine learning methods to\noptimize detection algorithms. Machine learning could improve CbPD by more\naccurately determining the typical combinations of citation-based and characterbased similarity characteristics that cause a document to be suspicious.\n\n7.3.3 Additional Applications\n7.3.3.1\n\nIdentification of Plagiarism Form\n\nAs discussed in Section 4.5, the detection algorithms providing the best results\ndiffer depending on the plagiarism form present. This characteristic of the\n66\n\nSee Stylometry for Intrinsic Plagiarism Detection on page 31 for an explanation of\nintrinsic measures.\n\n216\n\n7 Summary &amp; Future Work\n\nalgorithms allows for the automatic identification of the form of plagiarism. For\nexample, if a citation pattern is identical, yet textual similarity is relatively low,\nthe plagiarism is likely a paraphrase. If citation similarity is high, but the text is\nin another language, it is possibly a translated plagiarism. Depending on the form\nof plagiarism, one could also adjust similarity thresholds.\n\n7.3.3.2\n\nVisualization of Author Inspiration Trail\n\nWhen analyzing citation patterns, it is noticeable that review articles on identical\nor related topics tend to share a great deal of citation patterns. However, despite\nciting much of the same literature, later review articles rarely cite earlier review\narticles. Space limitations and readability concerns can justify why authors do\nnot cite every document involved in the creation process of a paper. Thus, this\nshould not necessarily be considered plagiarism as long as the similarities are\nnot excessive. Nevertheless, identifying such similarities can be interesting to\nother authors.\nAs an example, assume Alice wrote a paper that Bob finds interesting. If Bob\nis especially interested in learning more about the topic in general, he may like to\nknow which other publications Alice consulted while writing her article. Bob\ncould look at the bibliography in Alice’s article. However, the works cited in the\nbibliography are often only the most influential texts, or those addressing\nspecific facts instead of giving a general introduction or literature review on the\ntopic. The hypothesis is that identifying additional, often more general,\npublications aside from those cited becomes possible by running similar\nalgorithms as for Citation-based Plagiarism Detection but using a lower\nsimilarity threshold.\nFigure 55 illustrates the concept of an author inspiration trail. If Bob wrote\nDoc B, he may have also read Doc A, because both Doc B and Doc A cite\ndocuments [1], [2] and [3] in identical order. However, Bob does not cite Alice,\nwho published earlier.\n\n7.3 Future Work\n\n217\n\nnewer\ndocuments\n\n[1]\n[2]\n\ninspired by\n\nDoc B\n[3]\n[1]\n[2]\n\nolder\ndocuments\n\ncites\n\nDoc A\n[3]\n\n[1]\n[2]\n\n[3]\n\nNote: Doc A receives\nno citation from Doc B\n\nFigure 55: Potential to Identify Non-cited Documents\n\nIdentifying and displaying these currently invisible inspiration trails67 is\nanother possible application of CbPD. The goal would be to develop methods\ncapable of identifying earlier papers that significantly affected the creation of\nlater papers, even if the later papers did not cite the earlier ones.\n\n7.3.3.3\n\nSequential Pattern Analysis\n\nThis thesis proposed and evaluated Citation-based Plagiarism Detection as a\nspecialization of the broader approach we termed Sequential Pattern Analysis.\nCbPD applies Sequential Pattern Analysis for a particular use case – plagiarism\ndetection – using a specific type of language-independent markers: academic\ncitations.\nSequential Pattern Analysis using additional language-dependent and\nlanguage-independent markers aside from citations could further increase the\ndetection rates for global68 plagiarism. Current PDS commonly employ a\nheuristic initial retrieval step using some form of vector space models or term\n67\n68\n\nThe author first proposed the idea of inspiration trails at the ECDL doctoral\nconsortium in 2010 [125].\nSee Section 2.2.2, page 19, for an explanation of local vs. global plagiarism.\n\n218\n\n7 Summary &amp; Future Work\n\nindices, see Section 2.2.1. These approaches consider the overlap and partially\nthe distinctiveness of patterns, which equal indexed terms in this case, as the\nmain criteria for identifying similar documents. Depending on the terms used,\nthe order within patterns is also considered, e.g., when several characters,\nmultiple words, or whole sentences represent a term. We hypothesize that\nadditionally analyzing the proximity and order of shared patterns, i.e. matching\ncharacter sequences, words, or longer text fragments, could improve retrieval\naccuracy. For instance, if two documents share technical terms, e.g., stating a\ncertain bacterial culture, specifying a form of DNA sequencing, listing laboratory\nequipment and naming chemicals, the overlap in terms may too small and too\ncommon as to retrieve these documents as potentially suspicious. However, if\nthese terms appear in similar order and proximity within both documents, they\nmay indicate a similar research approach and/or experimental setup that are less\ncommon, thus interesting to an examiner.\nExamples for additional language-independent characteristics used by\nSequential Pattern Analysis include:\n-\n\nFormulas (e.g., chemical formulas such as H2O)\n\n-\n\nNames (e.g., of author names, cities, countries)\n\n-\n\nURIs (e.g., URLs)\n\n-\n\nDates (e.g., June 23, 1912)\n\n-\n\nPatent numbers (e.g., 4,715,820, 3,685,001)\n\nAside from plagiarism detection, considering these and other characteristics\ncould make Sequential Pattern Analysis applicable to further use cases.\nFor instance, considering the order and proximity of keywords, for example,\ndescriptions of medical symptoms, could improve the retrieval accuracy for\nsearches for medical diagnosis or treatment. A simple keyword search for\nsymptoms may generate too many unrelated results, especially for common\nsymptoms such as &quot;headache&quot;. However, a search for symptoms in a specific\n\n7.3 Future Work\n\n219\n\norder, for example, the chronological order in which symptoms of a disease tend\nto occur, or when symptoms are discussed in close proximity within a\nspecialized medical text may result in more relevant search results. Additionally,\nconsidering the distinctiveness of described symptoms could help to rank\ndescriptions or case studies of rare diseases more prominently.\nConsidering the order, proximity and distinctiveness of names and/or dates\ncould for instance improve the retrieval of historical text covering a particular\nevent or period. Similarly, employing Sequential Pattern Analysis for patent\nretrieval could improve the search for specific prior art.\n\n7.3.4 Further Evaluations\nTo date, the largest document collection examined using the citation-based\napproach for plagiarism detection was the PMC OAS. This corpus contained\n&quot;only&quot; ‫׽‬234,000 publications. The CbPD approach, however, can easily be\napplied to much larger collections; refer to the Comparison of Computational\nEfficiency on page 176. We lack the licenses to access the 22 million articles in\nPubMed, of which only 2.8 million are freely available as full-text in PubMed\nCentral [338].\nThe reason for choosing PMC OAS for an initial evaluation, and why we\nplan to re-examine PubMed’s other collection more extensively in the future, is\nthat academic fraud, including plagiarism and the fabrication or falsification of\ndata can have serious negative effects to society, particularly in medicine.\nFraudulent medical studies on the efficacy and safety of pharmaceuticals or\nhealth interventions can lead to serious maltreatment of patients69. An increasing\n\n69\n\nEven without fabricating data, authors can endanger patients by recycling previously\nrecorded data as part of several publications. In systematic reviews, results published\nmore than once can receive an inappropriate weight. Systematic reviews of primary\nresearch are one of the most important instruments in evidence-based medicine to\ndemonstrate the effects of pharmaceuticals, health and public health interventions, and\nsocial interventions [189]. In the worst case, plagiarized studies can distort systematic\nreviews and the conclusions drawn from these meta-analyses [349]. Several studies\nhighlighted that although fraudulent studies make up a small share of all medical\n\n220\n\n7 Summary &amp; Future Work\n\nnumber of scandals related to fraudulent research have been uncovered in the last\ndecade. Prominent examples include a fabricated link between the measles,\nmumps and rubella vaccine and autism [87], falsified data in stem cell research\n[16], or a fabricated positive effect of painkillers on oral cancer [243].\nIdentifying fabricated or falsified data is difficult, especially by means of\nautomatic detection. We found no study on scientific fraud, which analyzes how\nmany studies containing fabricated or falsified data also contain plagiarism.\nHowever, the evaluation of CbPD using the PMC OAS revealed some examples\nof studies that both plagiarized and fabricated data. It seems plausible to assume\nthat if authors intend to fabricate a study, they would not do so from scratch, but\nmay try to resemble the structure of a previous study. In doing so, fabricated\nstudies may resort to copying literature reviews or sections describing\nexperimental setup from prior studies. CbPD can help in identifying such\nfraudulent studies. Further evaluations of the citation-based approach on corpora\ncontaining medical publications are thus a priority for mitigating the potentially\ndamaging effects of plagiarism in medicine.\nFurther large-scale evaluations of the CbPD approach using scientific, multilanguage corpora will be necessary. The evaluation using the PMC OAS corpus,\nwhile large-scale, was not applicable to translated plagiarism. The PMC OAS\ncontains only medical texts in English. Figure 56 shows a retracted translated\nplagiarism [65] published in Neuroscience Letters. The English translation only\ncontains sources that were also cited in the Chinese original. This citation-based\nsimilarity represents the only automatically recognizable similarity characteristic\nremaining in the texts.\n\nresearch papers, they affect and potentially put at risk tens of thousands of patients\n[107, 315, 349].\n\n7.3 Future Work\n\nFigure 56: Retracted Translated Plagiarism from Chinese to English\n\n221\n\nReferences\n1.\n2.\n3.\n\n4.\n\n5.\n\n6.\n\n7.\n\n8.\n\nAblamunits V (2005) The importance of APC. Journal of Autoimmune\nDisease 2:3, doi: 10.1186/1740-2557-2-3, PMC1087870\nACNP Software (2011) Plagiarism Detection Software. Online Source,\nretrieved Oct. 28, 2011 from: http://www.anticutandpaste.com\nAhlgren P, Colliander C (2009) Document–document Similarity\nApproaches and Science Mapping: Experimental Comparison of Five\nApproaches.\nJournal\nof\nInformetrics\n3(1):49–63,\ndoi:\n10.1016/j.joi.2008.11.003\nAhlgren P, Jarneving B (2008) Bibliographic Coupling, Common\nAbstract Stems and Clustering: A Comparison of Two Documentdocument Similarity Approaches in the Context of Science Mapping.\nScientometrics 76:273–290, 10.1007/s11192-007-1935-1\nAhtiainen A, Surakka S, Rahikainen M (2006) Plaggie: Gnu-licensed\nSource Code Plagiarism Detection Engine for Java Exercises. In:\nProceedings of the 6th Baltic Sea Conference on Computing Education\nResearch, pp 141–142, doi: 10.1145/1315803.1315831\nAli R, Beg SMM (2011) An overview of Web search evaluation methods.\nComputers and Electrical Engineering 37(6):835–848, doi:\n10.1016/j.compeleceng.2011.10.005\nAlkureishi LW, Burak Z, Alvarez JA, Ballinger J, Bilde A, Britten AJ,\nCalabrese L, Chiesa C, Chiti A, de Bree R, Gray HW, Hunter K, Kovacs\nAF, Lassmann M, Leemans CR, Mamelle G, McGurk M, Mortensen J,\nPoli T, Shoaib T, Sloan P, Sorensen JA, Stoeckli SJ, Thomsen JB, Trifiro\nG, Werner J, Ross GL (2009) Joint Practice Guidelines for Radionuclide\nLymphoscintigraphy\nfor\nSentinel\nNode\nLocalization\nin\nOral/Oropharyngeal Squamous Cell Carcinoma. Ann Surg Oncol\n16:3190–3210, PMID19795174, PMC2766455\nAlkureishi LW, Burak Z, Alvarez JA, Ballinger J, Bilde A, Britten AJ,\nCalabrese L, Chiesa C, Chiti A, de Bree R, Gray HW, Hunter K, Kovacs\nAF, Lassmann M, Leemans CR, Mamelle G, McGurk M, Mortensen J,\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8, © Springer Fachmedien Wiesbaden 2014\n\n224\n\n9.\n\n10.\n\n11.\n\n12.\n\n13.\n\n14.\n15.\n16.\n\n17.\n\n18.\n\nReferences\n\nPoli T, Shoaib T, Sloan P, Sorensen JA, Stoeckli SJ, Thomsen JB, Trifiro\nG, Werner J, Ross GL (2009) Joint Practice Guidelines for Radionuclide\nLymphoscintigraphy\nfor\nSentinel\nNode\nLocalization\nin\nOral/Oropharyngeal Squamous Cell Carcinoma. Eur J Nucl Med Mol\nImaging 36:1915–1936, PMID19784646, PMC2764079\nAller MA, Arias JL, Arias J (2007) The Mast Cell Integrates the\nSplanchnic and Systemic Inflammatory Response in Portal Hypertension.\nJournal of Translational Medicine 5:44, PMID17892556, PMC2034541\nAller MA, Arias JL, Cruz A, Arias J (2007) Inflammation: a Way to\nUnderstanding the Evolution of Portal Hypertension. Theoretical Biology\nand Medical Modelling 4:44, PMID17999758, PMC2206015\nAmerican Diabetes Association (2009) Diagnosis and classification of\ndiabetes mellitus. Diabetes Care 32(Suppl. 1):62–67, doi: 10.2337/dc09S062\nAmerican Diabetes Association (2010) Diagnosis and classification of\ndiabetes mellitus. Diabetes Care 33(Suppl. 1):9–62, doi: 10.2337/dc10S062\nAmsler RA (1972) Applications of Citation-based Automatic\nClassification. Tech. rep., Linguistics Research Center, University of\nTexas at Austin, Austin, TX\nApache Software Foundation (2010) Apache OpenNLP. Online Source,\nretrieved May 29, 2012 from: http://incubator.apache.org/opennlp/\narXivorg (2007) 65 Admin Withdrawals. Online Source, retrieved Oct.\n28, 2011 from: http://arxiv.org/new/withdrawals.aug.07.html\nAssociated Press (2006) Disgraced Korean Cloning Scientist Indicted.\nThe New York Times, retrieved Oct. 31, 2012 from: http://www.nytimes.com/2006/05/12/world/asia/12korea.html\nAutodesk Research (2012) Citeology: Visualizing Paper Genealogy.\nOnline\nSource,\nretrieved\nOct.\n26,\n2012\nfrom:\nhttp://www.autodeskresearch.com/projects/citeology\nBadge J, Scott J (2009) Dealing with Plagiarism in the Digital Age.\nReport for the Higher Education Academy EvidenceNet, retrieved Jul. 19,\n\nReferences\n\n19.\n\n20.\n\n21.\n\n22.\n\n23.\n\n24.\n\n25.\n\n26.\n\n225\n\n2011 from http://evidencenet.pbworks.com/Dealing-with-plagiarism-inthe-digital-age\nBaker BS (1992) A Program for Identifying Duplicated Code. In:\nProceedings of the 24th Symposium on the Interface, College Station,\nTX, USA, pp 49–57\nBaker BS (1993) On Finding Duplication in Strings and Software. Online\nSource, retrieved Jun. 16, 2010 from: http://cm.bell-labs.com/cm/cs/doc/93/2-bsb-1.ps.gz\nBallard B (1989) Mutual Misconceptions: the Intellectual Problems of\nOverseas Students in Australia. Directions, Journal of Educational Studies\n11(1):48–60\nBao J, Lyon C, Lane PCR, Wei J, Malcolm JA (2007) Comparing\nDifferent Text Similarity Methods. Tech. rep., Technical Report 461,\nScience and Technology Research Institute, University of Hertfordshire\nBarrett R, Malcolm J (2006) Embedding Plagiarism Education in the\nAssessment Process. International Journal for Educational Integrity\n2(1):38–45\nBasile C, Benedetto D, Caglioti E, Cristadoro G, Esposti MD (2009) A\nPlagiarism Detection Procedure in Three Steps: Selection, Matches and\n“Squares”. In: Proceedings of the 3rd PAN Workshop. Uncovering\nPlagiarism, Authorship and Social Software Misuse\nBeel J, Gipp B (2009) Google Scholar’s Ranking Algorithm: An\nIntroductory Overview. In: Larsen B, Leta J (eds) Proceedings of the 12th\nInternational Conference on Scientometrics and Informetrics (ISSI’09),\nInternational Society for Scientometrics and Informetrics, Rio de Janeiro\n(Brazil), vol 1, pp 230–241\nBeel J, Gipp B (2009) Google Scholar’s Ranking Algorithm: The Impact\nof Citation Counts (An Empirical Study). In: Flory A, Collard M (eds)\nProceedings of the 3rd IEEE International Conference on Research\nChallenges in Information Science (RCIS’09), IEEE, Fez, Morocco, pp\n439–446, doi: 10.1109/RCIS.2009.5089308\n\n226\n\nReferences\n\n27.\n\nBeel J, Gipp B (2010) Academic Search Engine Spam and Google\nScholar’s Resilience Against it. Journal of Electronic Publishing 13(3),\ndoi: 10.3998/3336451.0013.305\nBeel J, Gipp B (2010) Detection of a similarity of documents by Citation\nProximity Analysis. Patent Application, wO/2010/078857\nBeel J, Gipp B, Shaker A, Friedrich N (2010) SciPlore Xtract: Extracting\nTitles from Scientific PDF Documents by Analyzing Style Information\n(Font Size). In: Lalmas M, Jose J, Rauber A, Sebastiani F, Frommholz I\n(eds) Research and Advanced Technology for Digital Libraries,\nProceedings of the 14th European Conference on Digital Libraries\n(ECDL’10), Springer, Glasgow (UK), Lecture Notes of Computer\nScience (LNCS), vol 6273, pp 413–416\nBeel J, Gipp B, Wilde E (2010) Academic Search Engine Optimization\n(ASEO): Optimizing Scholarly Literature for Google Scholar and Co.\nJournal\nof\nScholarly\nPublishing\n41(2):176–190,\ndoi:\n10.3138/jsp.41.2.176, university of Toronto Press\nBeel J, Gipp B, Langer S, Genzmehr M, Wilde E, Nürnberger A, Pitman J\n(2011) Introducing Mr. DLib, a Machine-readable Digital Library. In:\nProceedings of the 11th ACM/IEEE Joint Conference on Digital Libraries\n(JCDL’11)\nBeel J, Gipp B, Stiller JO (2011) Method for determining a similarity of\nobjects. Patent Application, wO/2011/044865\nBernstein Y, Zobel J (2004) A Scalable System for Identifying Coderivative Documents. In: String Processing and Information Retrieval,\nLecture Notes in Computer Science, vol 3246, Springer, pp 1–11, doi:\n10.1007/978-3-540-30213-1_6\nBlackboard Inc (2011) Safe Assign. Online Source, retrieved Oct. 28,\n2011 from: http://www.safeassign.com/\nBloomfield LA (2009) Software to detect plagiarism: WCopyfind. Online\nSource, retrieved Oct. 1, 2010 from: http://plagiarism.phys.virginia.edu/Wsoftware.html\nStegemann Boehl S (1994) Fehlverhalten von Forschern. Thieme\n\n28.\n29.\n\n30.\n\n31.\n\n32.\n33.\n\n34.\n35.\n\n36.\n\nReferences\n\n37.\n\n38.\n\n39.\n\n40.\n\n41.\n\n42.\n\n43.\n44.\n\n45.\n46.\n\n227\n\nBoekel MAv, Vossenaar ER, van den Hoogen FH, van Venrooij WJ\n(2002) Autoantibody Systems in Rheumatoid Arthritis: Specificity,\nSensitivity and Diagnostic Value. Arthritis Res 4:87–93, PMID11879544,\nPMC128920\nBoyack KW, Newman D, Duhon RJ, Klavans R, Patek M, Biberstine JR,\nSchijvenaars B, Skupin A, Ma N, Börner K (2011) Clustering More than\nTwo Million Biomedical Publications: Comparing the Accuracies of Nine\nText-Based Similarity Approaches. PLoS ONE 6(3):e18,029, doi:\n10.1371/journal.pone.0018029\nBraam RR, Moed HF, van Raan AFJ (1991) Mapping of Science by\nCombined Co-Citation and Word Analysis. I. Structural Aspects. Journal\nof the American Society for Information Science 42(4):233–251\nBretag T, Mahmud S (2009) Self-Plagiarism or Appropriate Textual Reuse? Journal of Academic Ethics 7:193–205, doi: 10.1007/s10805-0099092-1\nBrin S, Davis J, Garcia Molina H (1995) Copy Detection Mechanisms for\nDigital Documents. In: Proceedings of the 1995 ACM SIGMOD\nInternational Conference on Management of Data, ACM, pp 398–409,\ndoi: 10.1145/223784.223855\nBroder AZ, Glassman SC, Manasse MS, Zweig G (1997) Syntactic\nClustering of the Web. Computer Networks and ISDN Systems 29(813):1157–1166, doi: 10.1016/S0169-7552(97)00031-7\nBrooks T (1986) Evidence of complex citer motivations. Journal of the\nAmerican Society for Information Science 37(1):34–36\nBrown BS (2001) Explaining Variations in the Level of Academic\nDishonesty in Studies of College Students: Some New Evidence. College\nStudent Journal 35(4):529–538\nBrown BS, Abramson J (1999) The Academic Ethics of Undergraduate\nMarketing Majors. Academy of Marketing Studies Journal 3(1):62–71\nBrown BS, Weible R (2006) Changes in Academic Dishonesty among\nMIS Majors between 1999 and 2004. Journal of Computing in Higher\nEducation 18:116–134\n\n228\n\nReferences\n\n47.\n\nBrown KA, Aakre ME, Gorska AE, Price JO, Eltom SE, Pietenpol JA,\nMoses HL (2004) Induction by Transforming Growth Factor-beta1 of\nEpithelial to Mesenchymal Transition is a Rare Event in Vitro. Breast\nCancer Res 6:215–231, PMID11250748, PMC13902\nBruhn A, Hernandez G, Bugedo G, Castillo L (2004) Effects of positive\nend-expiratory pressure on gastric mucosal perfusion in acute respiratory\ndistress syndrome. Critical Care 8(5):306–311, doi: 10.1186/cc2905,\nPMID15469573, PMC1065018\nBuckley C, Dimmick D, Soboroff I, Voorhees E (2007) Bias and the\nLimits of Pooling for Large Collections. Inf Retr 10(6):491–508, doi:\n10.1007/s10791-007-9032-x\nBull J, Colins C, Coughlin E, Sharp D (2000) Technical Review of\nPlagiarism Detection Software Report. Tech. rep., Joint Information\nSystem Committee\nButakov S, Scherbinin V (2009) The Toolbox for Local and Global\nPlagiarism Detection. Computers &amp; Education 52(4):781–788, doi:\n10.1016/j.compedu.2008.12.001\nBuyko E, Wermter J, Poprat M, Hahn U (2006) Automatically Adapting\nan NLP Core Engine to the Biology Domain. In: Proceedings of the Joint\nBioLINK-Bio-Ontologies Meeting. A Joint Meeting of the ISMB Special\nInterest Group on Bio-Ontologies and the BioLINK Special Interest\nGroup on Text Data Mining in Association with ISMB, pp 65–68\nCalado P, Cristo M, Moura E, Ziviani N, Ribeiro Neto B, Gonçalves MA\n(2003) Combining Link-based and Content-based Methods for Web\nDocument Classification. In: Proceedings of the 12th international\nconference on Information and knowledge management, ACM, pp 394–\n401, doi: 10.1145/956863.956938\nCalado P, Cristo M, Gonçalves MA, de Moura ES, Ribeiro Neto B,\nZiviani N (2006) Link-based Similarity Measures for the Classification of\nWeb Documents. Journal of the American Society for Information\nScience and Technology 57:208–221, doi: 10.1002/asi.v57:2\n\n48.\n\n49.\n\n50.\n\n51.\n\n52.\n\n53.\n\n54.\n\nReferences\n\n55.\n\n56.\n\n57.\n\n58.\n\n59.\n\n60.\n61.\n\n62.\n\n63.\n\n229\n\nCallahan A, Hockema S, Eysenbach G (2010) Contextual Cocitation:\nAugmenting Cocitation Analysis and its Applications. Journal of the\nAmerican Society for Information Science and Technology 61:1130–\n1143, doi: 0.1002/asi.21313\nCampbell DM, Chen WR, Smith RD (2000) Copy Detection Systems for\nDigital Documents. In: Tester T, Hubertus Tv (eds) Proceedings of the\nConference on Advances in Digital Libraries, IEEE, Los Alamitos, CA,\nUSA, LNS, vol 64654, pp 78–88, doi: 10.1109/ADL.2000.848372\nBarrón Cedeño A, Rosso P (2009) On Automatic Plagiarism Detection\nBased on n-Grams Comparison. In: Advances in Information Retrieval,\nLecture Notes in Computer Science, vol 5478, Springer, pp 696–700, doi:\n10.1007/978-3-642-00958-7_69\nBarrón Cedeño A, Rosso P, Pinto D, Juan A (2008) On Cross-lingual\nPlagiarism Analysis using a Statistical Model. In: Proceedings of the\nECAI08 Workshop on Uncovering Plagiarism, Authorship and Social\nSoftware Misuse, CEUR-WS.org, CEUR Workshop Proceedings, vol 377\nCeska Z (2008) Plagiarism Detection Based on Singular Value\nDecomposition. In: Advances in Natural Language Processing, Lecture\nNotes in Computer Science, vol 5221, Springer, pp 108–119, doi:\n10.1007/978-3-540-85287-2_11\nCFL Software Ltd (2011) CopyCatch. Online Source, retrieved Oct. 1,\n2011 from: http://cflsoftware.com/\nChan B, Koren G (2003) Pharmacological Treatment for Pregnant\nWomen who Smoke Cigarettes. Tobacco Induced Diseases 1:165–174,\nPMID19570257, PMC2671545\nChan B, Koren G (2003) Pharmacological Treatment for Pregnant\nWomen who Smoke Cigarettes. Tobacco Induced Diseases 1:165–174,\nPMID19570257, PMC2669555\nChang WI, Lawler EL (1994) Sublinear Approximate String Matching\nand Biological Applications. Algorithmica 12:327–344, doi:\n10.1007/BF01185431\n\n230\n\nReferences\n\n64.\n\nChatzimarkakis\nG\n(2000)\nInformationeller\nGlobalismus:\nKooperationsmodell globaler Ordnungspolitik am Beispiel des\nelektronischen Geschäftsverkehrs. Dissertation, Faculty of Philosophy,\nUniversity of Bonn, retracted as plagiarism by the University of Bonn on\nJul. 13, 2011.\nChen Y, Liu C, Xu X, Zhang X, Shen W (2012) Simple Mental\nArithmetic is not so Simple: An ERP Study of the Split and Odd-even\nEffects in Mental Arithmetic. Neuroscience Letters 510, Issue 1:62–66,\nretraction\nnotice:\nhttp://www.sciencedirect.com/science/article/pii/S0304394012000201\nChennagiri RJ, Critchley P, Giele H (2004) Duplicate publication in the\nJournal of Hand Surgery. British Journal of Hand Surgery 29:625–628,\ndoi: 10.1016/j.jhsb.2004.04.005, PMID15542228\nChong M, Specia L, Mitkov R (2010) Using Natural Language\nProcessing for Automatic Detection of Plagiarism. In: Proceedings of the\n4th International Plagiarism Conference 2010, Newcastle upon Tyne, UK\nChowdhury A, Frieder O, Grossman D, McCabe M (2002) Collection\nStatistics for Fast Duplicate Document Detection. ACM Transactions on\nInformation\nSystems\n(TOIS)\n20(2):171–191,\ndoi:\n10.1145/506309.506311\nClarke R (2006) Plagiarism by Academics: More Complex Than It\nSeems. Journal of the Association for Information Systems 7(2):91–121\nClarke SJ, Willett P (1997) Estimating the recall performance of Web\nsearch engines. Aslib Proceedings 49(7):184–189, doi: 10.1108/eb051463\nClough P (2000) Plagiarism in Natural and Programming Languages an\nOverview of Current Tools and Technologies. Tech. rep., Department of\nComputer Science, University of Sheffield\nClough P, Stevenson M (2011) Developing a Corpus of Plagiarised Short\nAnswers. Language Resources and Evaluation 45:5–24, 10.1007/s10579009-9112-1\nCohen MB (2006) The Best in CytoJournal: 2005. Cytojournal\n2006(3:21), doi: 10.1186/1742-6413-3-21, PMC1570476\n\n65.\n\n66.\n\n67.\n\n68.\n\n69.\n70.\n71.\n\n72.\n\n73.\n\nReferences\n\n74.\n\n75.\n\n76.\n\n77.\n\n78.\n\n79.\n\n80.\n\n81.\n82.\n\n231\n\nCole CA (2002) Academic Dishonesty among College Students: Themes\nof the Professional Literature, 1950-1997. Phd. thesis, The University of\nTexas at Austin\nCole SL, Vassar R (2007) The Alzheimer’s Disease Beta-secretase\nEnzyme, BACE1. Mol Neurodegener 2:22, PMID18005427,\nPMC2211305\nCole SL, Vassar R (2007) The Basic Biology of BACE1: a Key\nTherapeutic Target for Alzheimer’s Disease. Current Genomics 8:509–\n530, PMID19415126, PMC2647160\nCollberg C, Kobourov S (2005) Self-plagiarism in Computer Science.\nCommununications\nof\nthe\nACM\n48(4):88–94,\ndoi:\n10.1145/1053291.1053293\nCooper WS (1968) Expected search length: a single measure of retrieval\neffectiveness based on the weak ordering action of retrieval systems.\nJournal of the American Society for Information Science and Technology\n19(1):30–41, doi: 10.1002/asi.5090190108\nCouto T, Cristo M, Gonçalves MA, Calado P, Ziviani N, Moura E,\nRibeiro Neto B (2006) A Comparative Study of Citations and Links in\nDocument Classification. In: Proceedings of the 6th ACM/IEEE-CS Joint\nConference on Digital Libraries, ACM, pp 75–84, doi:\n10.1145/1141753.1141766\nCristo M, Calado P, de Moura E, Ziviani N, Ribeiro Neto B (2003) Link\nInformation as a Similarity Measure in Web Classification. In: String\nProcessing and Information Retrieval, Lecture Notes in Computer\nScience, vol 2857, Springer, pp 43–55\nCrochemore M, Rytter W (2002) Jewels of Stringology. World Scientific\nPublishing\nCrown DF, Spiller MS (1998) Learning from the Literature on Collegiate\nCheating: A Review of Empirical Research. Journal of Business Ethics\n17:683–700, doi: 10.1023/A:1017903001888\n\n232\n\nReferences\n\n83.\n\nCulwin F (2006) An Active Introduction to Academic Misconduct and the\nMeasured Demographics of Misconduct. Assessment &amp; Evaluation in\nHigher Education 31(2):167–182, doi: 10.1080/02602930500262478\nCulwin F (2009) The Efficacy of Turnitin and Google. In: Proceedings of\nthe 10th Annual Conference of the Subject Centre for Information and\nComputer Sciences, HE Academy, Subject Centre for ICS\nCulwin F, Warwick J, Child M (2008) An Empirical Investigation of\nStudent Behaviour when Non-originality Detection is Made Available\nbefore Submission. In: Proceedings of the 3rd International Plagiarism\nConference, Newcastle upon Tyne, UK\nDean J, Henzinger MR (1999) Finding Related Pages in the World Wide\nWeb. Computer Networks 31:1467–1479, doi: 10.1016/S13891286(99)00022-5\nDeer B (2004) Revealed: MMR Research Scandal. The Sunday Times,\nretrieved Oct. 31, 2012 from: http://briandeer.com/mmr/lancet-deer-1.htm\nDevi SL, Rao PRK, Ram VS, Akilandeswari A (2010) External\nPlagiarism Detection - Lab Report for PAN at CLEF 2010. In: Notebook\nPapers of CLEF 2010 LABs and Workshops\nDevlin M (2002) Plagiarism Detection Software: How Effective is it? In:\nAssessing Learning in Australian Universities, Centre for the Study of\nHigher Education, University of Melbourne and the Australian\nUniversities Teaching Committee\nDickinson HO, Hrisos S, Eccles MP, Francis J, Johnston M (2010)\nStatistical Considerations in a Systematic Review of Proxy Measures of\nClinical Behaviour. Implementation Science 5:20, PMID20187923,\nPMC2846869\nDivita G, Browne A, Loane R (2006) dTagger: a POS Tagger. In:\nProceedings of the Annual AMIA Symposium, pp 200–203\nDéjà Vu (2011) A Study of Scientific Publication Ethics. Online Source,\nretrieved May 29, 2012 from: http://dejavu.vbi.vt.edu/dejavu/\nDocoloc UG &amp; Co KG (2011) Docoloc. Online Source, retrieved Aug. 8,\n2011 from: http://www.docoloc.com\n\n84.\n\n85.\n\n86.\n\n87.\n88.\n\n89.\n\n90.\n\n91.\n92.\n93.\n\nReferences\n\n94.\n\n95.\n\n96.\n\n97.\n\n98.\n\n99.\n\n100.\n101.\n102.\n\n103.\n\n233\n\nDreher H (2007) Automatic Conceptual Analysis for Plagiarism\nDetection. Information and Beyond: The Journal of Issues in Informing\nScience and Information Technology 4:601–614\nDurani P (2006) Duplicate publications: redundancy in plastic surgery\nliterature. Journal of Plastic, Reconstructive &amp; Aesthetic Surgery 59:975–\n7, doi: 10.1016/j.bjps.2005.11.039, PMID16920591\nEgghe L, Rousseau R (1990) Introduction to Informetrics : Quantitative\nMethods in Library, Documentation and Information Science. Elsevier\nScience Publishers, http://hdl.handle.net/10760/6011\nMeyer zu Eissen S, Stein B (2006) Intrinsic Plagiarism Detection. In:\nProceedings of the 28th European Conference on IR Research, Springer,\nLondon, UK, Lecture Notes in Computer Science, vol 3936, pp 565–569,\ndoi: 10.1007/11735106_66\nMeyer zu Eissen S, Stein B, Kulig M (2007) Plagiarism Detection without\nReference Collections. In: Proceedings of the 30th Annual Conference of\nthe Gesellschaft für Klassifikation e.V., Springer, Berlin, Germany, pp\n359–366, doi: 10.1007/978-3-540-70981-7_40\nAaron Elkiss, Siwei Shen, Anthony Fader, Günes ̧ Erkan, David States,\nDragomir Radev (2008) Blind Men and Elephants: What Do Citation\nSummaries Tell Us About a Research Article? Journal of the American\nSociety for Information Science and Technology 59(1):51–62, doi:\n10.1002/asi.20707\nEphorus BV (2011) Ephorus. Online Source, retrieved Aug. 8, 2011 from:\nhttps://www.ephorus.com/en/home\nEpstein SK (2004) Extubation failure: an outcome to be avoided. Critical\nCare 8(5):310–312, doi: 10.1186/cc2927, PMID15469587, PMC1065026\nErcegovac Z, Richardson Jr JV (2004) Academic Dishonesty, Plagiarism\nIncluded, in the Digital Age: a Literature Review. College and Research\nLibraries 65(4):301–318\nErnst H (1959) Design and Evaluation of a Literature Retrieval Scheme.\nMaster’s thesis, Massachusetts Institute of Technology, cited according\nto: E. Garfield. Science Citation Index - A New Dimension in Indexing.\n\n234\n\n104.\n\n105.\n\n106.\n107.\n\n108.\n\n109.\n110.\n\n111.\n\n112.\n\nReferences\n\nScience,\n144\n(3619):\n649–654,\nMay\n1964.\ndoi:\n10.1126/science.144.3619.649.\nErrami M, Hicks JM, Fisher W, Trusty D, Wren JD, Long TC, Garner HR\n(2008) Déjà Vu — a Study of Duplicate Citations in Medline.\nBioinformatics 24(2):243–249, doi: 10.1093/bioinformatics/btm574,\nhttp://bioinformatics.oxfordjournals.org/content/24/2/243.full.pdf+html\nErrami M, Sun Z, Long TC, George AC, Garner HR (2009) Déjà Vu: a\nDatabase of Highly Similar Citations in the Scientific Literature. Nucleic\nAcids Research 37(Suppl. 1):D921–D924, doi: 10.1093/nar/gkn546,\nhttp://nar.oxfordjournals.org/content/37/suppl_1/D921.full.pdf+html\nEto M (2012) Evaluations of Context-based Co-Citation Searching.\nScientometrics 94(2):651–673, doi: 10.1007/s11192-012-0756-z\nFang FC, Steen RG, Casadevall A (2012) Misconduct Accounts for the\nMajority of Retracted Scientific Publications. Proceedings of the National\nAcademy\nof\nSciences\n109(42):17,028–17,033,\ndoi:\n10.1073/pnas.1212247109\nFano RM (1956) Documentation in Action, Reinhold Publ. Co., New\nYork, chap Information Theory and the Retrieval of Recorded\nInformation, pp 238–244\nFellbaum C (1998) WordNet: an Electronic Lexical Database (Language,\nSpeech, and Communication). The MIT Press\nFerrini F, Salio C, Lossi L, Merighi A (2009) Ghrelin in central neurons.\nCurrent\nNeuropharmacology\n7(1):37–49,\ndoi:\n10.2174/157015909787602779, PMID19721816, PMC2724662\nFinkel RA, Zaslavsky AB, Monostori K, Schmidt HW (2002) Signature\nExtraction for Overlap Detection in Documents. In: Proceedings of the\n25th Australasian Computer Science Conference, Australian Computer\nSociety Inc., Melbourne, Australia, Conferences in Research and Practice\nin Information Technology, vol 4, pp 59–64\nFiori R, Chiappa R, Gaspari E, Simonetti G (2010) A Rare Case of\nPopliteal Venous Aneurysm. Case Reports in Medicine 2010(Artuicle ID\n579256), doi: 10.1155/2010/579256, PMID20224754, PMC2836132\n\nReferences\n\n113.\n\n114.\n\n115.\n116.\n117.\n118.\n\n119.\n120.\n121.\n\n122.\n\n123.\n\n235\n\nFishman T (2009) “We know it when we see it” is not good enough:\ntoward a standard definition of plagiarism that transcends theft, fraud, and\ncopyright. In: Proceedings of the 4th Asia Pacific Conference on\nEducational Integrity, http://www.bmartin.cc/pubs/09-4apcei/4apceiFishman.pdf\nCouzin Frankel J, Grom J (2009) Plagiarism Sleuths. Science\n324(5930):1004–1007,\ndoi:\n10.1126/science.324_1004,\nhttp://www.sciencemag.org/content/324/5930/1004.full.pdf\nFraser GE, Franke AA, Jaceldo-Siegl K, Bennett H (2010) Reliability of\nSerum and Urinary Isoflavone Estimates. Biomarkers 15:135–139\nFröhlich G (2006) Plagiate und unethische Autorenschaften. Information Wissenschaft &amp; Praxis 57(2):81––89\nGarfield E (1964) Science Citation Index - a New Dimension in Indexing.\nScience 144(3619):649–654, doi: 10.1126/science.144.3619.649\nGarfield E, Sher I (1963) New factors in the evaluation of scientific\nliterature through citation indexing. American Documentation 14(3):195–\n201\nGarfield E, Sher IH, Torpie RJ (1964) The Use of Citation Data in\nWriting the History of Science. Institute for Scientific Information\nGarner BA (2011) Garner’s Dictionary of Legal Usage, 3rd edn. Oxford\nUniversity Press\nGhafouri M, Amini S, Khalili K, Sawaya BE (2006) HIV-1 Associated\nDementia: Symptoms and Causes. Retrovirology 3:28, PMID16712719,\nPMC1513597\nGipp B (2006) (Co-)Citation Proximity Analysis - A Measure to Identify\nRelated Work. Doctoral Proposal, otto-von-Guericke University,\nGermany, Supervisor: Prof. Claus Rautenstrauch\nGipp B (2009) Very Large Business Applications (VLBA):\nSystemlandschaften der Zukunft, Shaker Verlag, Magdeburg, chap\nEntwicklung\nneuer\nVerfahren\nzur\nBestimmung\nvon\nDokumentenähnlichkeiten mittels Referenz- und Zitationsanalyse, pp\n\n236\n\n124.\n\n125.\n\n126.\n\n127.\n\n128.\n\n129.\n\n130.\n\nReferences\n\n163–173. 3. Workshop des Centers for Very Large Business Applications\n(CVLBA)\nGipp B (2010) Measuring Document Relatedness by Citation Proximity\nAnalysis and Citation Order Analysis. In: Lalmas M, Jose J, Rauber A,\nSebastiani F, Frommholz I (eds) Proceedings of the 14th European\nConference on Digital Libraries (ECDL’10): Research and Advanced\nTechnology for Digital Libraries, Springer, Lecture Notes of Computer\nScience (LNCS), vol 6273\nGipp B (2011) Identifying Related Work and Plagiarism by Citation\nAnalysis. Bulletin of IEEE Technical Committee on Digital Libraries\n(TCDL) 7(1)\nGipp B, Beel J (2009) Citation Proximity Analysis (CPA) - A new\napproach for identifying related work based on Co-Citation Analysis. In:\nLarsen B, Leta J (eds) Proceedings of the 12th International Conference\non Scientometrics and Informetrics (ISSI’09), International Society for\nScientometrics and Informetrics, Rio de Janeiro (Brazil), vol 2, pp 571–\n575, iSSN 2175-1935\nGipp B, Beel J (2010) Citation Based Plagiarism Detection - a New\nApproach to Identify Plagiarized Work Language Independently. In:\nProceedings of the 21st ACM Conference on Hypertext and Hypermedia,\nACM, pp 273–274, doi: 10.1145/1810617.1810671\nGipp B, Beel J (2011) Method and System for Detecting a Similarity of\nDocuments. Patent Application, http://www.patentlens.net/patentlens/patent/US_2011_0264672_A1/en/, uS 2011/0264672 A1\nGipp B, Meuschke N (2011) Citation Pattern Matching Algorithms for\nCitation-based Plagiarism Detection: Greedy Citation Tiling, Citation\nChunking and Longest Common Citation Sequence. In: Proceedings of\nthe 11th ACM Symposium on Document Engineering, ACM, Mountain\nView, CA, USA, pp 249–258, doi: 10.1145/2034691.2034741\nGipp B, Beel J, Hentschel C (2009) Scienstein: A Research Paper\nRecommender System. In: Proceedings of the International Conference\non Emerging Trends in Computing (ICETiC’09), Kamaraj College of\n\nReferences\n\n131.\n\n132.\n\n133.\n\n134.\n\n135.\n\n136.\n\n137.\n\n237\n\nEngineering and Technology India, IEEE, Virudhunagar (India), pp 309–\n315\nGipp B, Taylor A, Beel J (2010) Link Proximity Analysis - Clustering\nWebsites by Examining Link Proximity. In: Lalmas M, Jose J, Rauber A,\nSebastiani F, Frommholz I (eds) Proceedings of the 14th European\nConference on Digital Libraries (ECDL’10): Research and Advanced\nTechnology for Digital Libraries, Springer, Lecture Notes of Computer\nScience (LNCS), vol 6273, pp 449–452\nGipp B, Meuschke N, Beel J (2011) Comparative Evaluation of Text- and\nCitation-based Plagiarism Detection Approaches using GuttenPlag. In:\nProceedings of 11th ACM/IEEE-CS Joint Conference on Digital Libraries\n(JCDL’11),\nACM,\nOttawa,\nCanada,\npp\n255–258,\ndoi:\n10.1145/1998076.1998124\nGipp B, Meuschke N, Breitinger C, Lipinski M, Nürnberger A (2013)\nDemonstration of the First Citation-based Plagiarism Detection Prototype.\nIn: Proceedings of the 36th International ACM SIGIR conference on\nresearch and development in Information Retrieval, ACM, Dublin,\nIreland, pp 1119–1120, doi: 10.1145/2484028.2484214\nGipp B, Meuschke N, Lipinski M, Nürnberger A (2013) CITREC: An\nEvaluation Framework for Citation-Based Similarity Measures Based on\nTREC Genomics and PMC, to be published\nGipp B, Meuschke N, Breitinger C (2014) Citation-based Plagiarism\nDetection: Practicability on a Large-scale Scientific Corpus. Journal of\nthe American Society for Information Science and Technology\nGlänzel W (2003) Bibliometrics as a Research Field - a Course on Theory\nand Application of Bibliometric Indicators. Course Handout, retrieved\nJul. 13, 2010 from: http://nsdl.niscair.res.in/bitstream/123456789/968/1/\nGoan T, Fujioka E, Kaneshiro R, Gasch L (2006) Identifying Information\nProvenance in Support of Intelligence Analysis, Sharing, and Protection.\nIn: Intelligence and Security Informatics, Lecture Notes in Computer\nScience, vol 3975, Springer, pp 692–693, doi: 10.1007/11760146_93\n\n238\n\n138.\n\n139.\n\n140.\n\n141.\n\n142.\n\n143.\n\n144.\n\n145.\n\n146.\n\nReferences\n\nGoldbach-Mansky R, Lee J, McCoy A, Hoxworth J, Yarboro C, Smolen\nJS, Steiner G, Rosen A, Zhang C, Ménard HA, Zhou Zhi Jie, Palosuo T,\nVan Venrooij aWR Walther J, Klippel SRH John H, Gabalawy Sani H E\n(2000) Rheumatoid Arthritis Associated Autoantibodies in Patients with\nSynovitis of Recent Onset. Arthritis Research 2:236–243,\nPMID11056669, PMC17811\nGriffith BC, Small HG, Stonehill JA, Dey S (1974) The Structure of\nScientific Literatures II: toward a Macro- and Microstructure for Science.\nScience Studies 4(4):339–365\nGrman J, Ravas R (2011) Improved Implementation for Finding Text\nSimilarities in Large Collections of Data. In: Notebook Papers of CLEF\n2011 LABs and Workshops, Amsterdam, Netherlands\nGrose R (2004) Common Ground in the Transcriptional Profiles of\nWounds and Tumors. Genome Biology 5:228, PMID15186486,\nPMC463068\nGrozea C, Popescu M (2010) Encoplot - Performance in the Second\nInternational Plagiarism Detection Challenge. In: Notebook Papers of\nCLEF 2010 LABs and Workshops, Padua, Italy\nGrozea C, Gehl C, Popescu M (2009) ENCOPLOT: Pairwise Sequence\nMatching in Linear Time Applied to Plagiarism Detection. In:\nProceedings of the 3rd PAN Workshop. Uncovering Plagiarism,\nAuthorship and Social Software Misuse\nGruner S, Naven S (2005) Tool Support for Plagiarism Detection in Text\nDocuments. In: Proceedings of the 2005 ACM Symposium on Applied\nComputing, ACM, pp 776–781, doi: 10.1145/1066677.1066854\nGutbrod MA (2007) Nachhaltiges E-Learning durch Sekundäre Dienste.\nDissertation, Institute of Operating Systems and Computer Networks,\nTechnische Universität Braunschweig\nGuttenberg KTz (2009) Verfassung und Verfassungsvertrag:\nKonstitutionelle Entwicklungsstufen in den USA und der EU.\nDissertation, Faculty of Law, Business Administration and Economics,\n\nReferences\n\n147.\n\n148.\n\n149.\n\n150.\n\n151.\n\n152.\n\n153.\n\n239\n\nUniversity of Bayreuth, retracted as plagiarism by the University of\nBayreuth on May 5, 2011.\nGuttenPlag Wiki (2011) Eine kritische Auseinandersetzung mit der\nDissertation von Karl-Theodor Freiherr zu Guttenberg: Verfassung und\nVerfassungsvertrag. Konstitutionelle Entwicklungsstufen in den USA und\nder EU. Online Source, retrieved Apr. 25, 2012 from: http://de.guttenplag.wikia.com/wiki/GuttenPlag_Wiki\nGyan S, Sushma S, Maneesh S, Rajesh S, Misra M (2010) Successful\nmicrosurgical penile replantation following self amputation in a\nschizophrenic patient. Indian Journal of Urology 26(3):434–437, doi:\n10.4103/0970-1591.70589\nHaller S (2003) Das Sanierungsgebiet Hemshof in Ludwigshafen am\nRhein: Eine Bilanz von 30 Jahren baulicher Erneuerung und sozialer\nVeränderung. Dissertation, Faculty of Philosophy III: Educational\nScience, University of Halle, http://sundoc.bibliothek.uni-halle.de/dissonline/03/06H158/prom.pdf, retracted as plagiarism by the MartinLuther-University Halle-Wittenberg on Apr. 18, 2012.\nHariharan S, Kamal S, Faisal AVM, Azharudheen SM, Raman B (2010)\nDetecting Plagiarism in Text Documents. In: Proceedings of the\nInternational Conference on Recent Trends in Business Administration\nand Information Processing, Springer, Trivandrum, Kerala, India,\nCommunications in Computer and Information Science, vol 70, pp 497–\n500, doi: 10.1007/978-3-642-12214-9_86\nHeather J (2010) Turnitoff: Identifying and Fixing a Hole in Current\nPlagiarism Detection Software. Assessment &amp; Evaluation in Higher\nEducation 35(6):647–660, doi: 10.1080/02602938.2010.486471\nHeinrich-Heine University of Düsseldorf (2013) Der Fakultätsrat der\nPhilosophischen Fakultät. Online, retrieved Apr. 3, 2013 from: http://www.phil-fak.uni-duesseldorf.de/organisation/fakultaetsrat/\nHeinrich-Heine\nUniversity\nof\nDüsseldorf\n(2013)\nPromotionsprüfungsverfahren Prof. Dr. Schavan - Aktuelle Sitzung des\nFakultätsrats der Philosophischen Fakultät und Presseerklärung vom\n\n240\n\n154.\n155.\n\n156.\n\n157.\n\n158.\n\n159.\n\n160.\n\n161.\n162.\n\nReferences\n\n05.02.2013. Press Release, retrieved Feb. 25, 2013 from: http://www.uniduesseldorf.de/home/startseite/news-detailansicht/article/aktuelle-sitzungdes-fakultaetsrats-der-philosophischen-fakultaet-und-presseerklaerungvom-0502.html\nHeintze N (1996) Scalable Document Fingerprinting. In: 1996 USENIX\nWorkshop on Electronic Commerce\nHetzner E (2008) A Simple Method for Citation Metadata Extraction\nusing Hidden Markov Models. In: Proceedings of the 8th ACM/IEEE-CS\nJoint Conference on Digital Libraries, ACM, pp 280–284, doi:\n10.1145/1378889.1378937\nHeun M (2007) Finanzmarktsimulation mit Multiagentensystemen:\nEntwicklung eines methodischen Frameworks. Deutscher UniversitätsVerlag\nHill JD, Page EF (2009) An Empirical Research Study of the Efficacy of\nTwo Plagiarism-Detection Applications. Journal of Web Librarianship\n3(3):169–181, doi: 10.1080/19322900903051011\nHoad TC, Zobel J (2003) Methods for Identifying Versioned and\nPlagiarised Documents. Journal of the American Society for Information\nScience and Technology 54(3):203–215, doi: 10.1002/asi.10170\nHohenester S, Oude Elferink RPJ, Beuers U (2009) Primary Biliary\nCirrhosis. Seminars in Immunopathology 31:283–307, PMID19603170,\nPMC2758170\nHolmes DI (1998) The Evolution of Stylometry in Humanities\nScholarship. Literary and Linguistic Computing 13(3):111–117, doi:\n10.1093/llc/13.3.111,\nhttp://llc.oxfordjournals.org/content/13/3/111.full.pdf+html\nHoward RM (2007) Understanding “Internet plagiarism”. Computers and\nComposition 24(1):3–15, doi: 10.1016/j.compcom.2006.12.005\nHrisos S, Eccles MP, Francis JJ, Dickinson HO, Kaner EF, Beyer F,\nJohnston M (2009) Are There Valid Proxy Measures of Clinical\nBehaviour? A Systematic Review. Implementation Science 4:37,\nPMID19575790, PMC2713194\n\nReferences\n\n163.\n\n164.\n\n165.\n\n166.\n\n167.\n\n168.\n169.\n170.\n\n171.\n\n241\n\nIntegru (2012) Review 6: Aurelia Cristina Nechifor, Ecaterina\nAndronescu (minister of research), 2003 – plagiarism and falsification of\ndata. Online Source, retrieved Feb. 28, 2013 from: http://integru.org/reviews/andronescu-2003\niParadigms LLC (2013) Turnitin Webpage - Content. Online Source,\nretrieved Feb. 28, 2013 from: http://turnitin.com/en_us/products/originalitycheck/content\nJalel A, Soumaya GS, Hamdaoui MH (2009) Dermatology Life Quality\nIndex Scores in Vitiligo: Reliability and Validity of the Tunesian Version.\nIndian Journal of Dermatology 54(4):3–330, doi: 10.4103/00195154.57607, PMID20101332, PMC2807707\nJanssens F, Tran Quoc V, Glänzel W, De Moor B (2006) Integration of\nTextual Content and Link Information for Accurate Clustering of Science\nFields. In: Proceedings of the I International Conference on\nMultidisciplinary Information Sciences &amp; Technologies, pp 615–619\nJanssens F, Zhang L, De Moor B, Glänzel W (2009) Hybrid Clustering\nfor Validation and Improvement of Subject-classification Schemes.\nInformation Processing and Management 45:683–702, doi:\n10.1016/j.ipm.2009.06.003\nJarneving B (2005) A Comparison of Two Bibliometric Methods for\nMapping of the Research Front. Scientometrics 65(2):245–263\nJuola P (2008) Authorship Attribution. Foundations and Trends\nInformation Retrieval 1:233–334, doi: 10.1561/1500000005\nKakkonen T, Mozgovoy M (2010) Hermetic and Web Plagiarism\nDetection Systems for Student Essays — an Evaluation of the State-ofthe-Art. Journal of Educational Computing Research 42(2):135–159, doi:\n10.2190/EC.42.2.a\nKang N, Gelbukh A, Han S (2006) PPChecker: Plagiarism Pattern\nChecker in Document Copy Detection. In: Text, Speech and Dialogue,\nLecture Notes in Computer Science, vol 4188, Springer, pp 661–667, doi:\n10.1007/11846406_83\n\n242\n\n172.\n\n173.\n\n174.\n\n175.\n\n176.\n\n177.\n\n178.\n\n179.\n\n180.\n\nReferences\n\nKasprzak J, Brandejs M (2010) Improving the Reliability of the\nPlagiarism Detection System - Lab Report for PAN at CLEF 2010. In:\nNotebook Papers of CLEF 2010 LABs and Workshops, Padua, Italy\nKasprzak J, Brandejs M, Kripac M (2009) Finding Plagiarism by\nEvaluating Document Similarities. In: Proceedings of the 3rd PAN\nWorkshop. Uncovering Plagiarism, Authorship and Social Software\nMisuse\nKessler MM (1963) An Experimental Study of Bibliographic Coupling\nBetween Technical Papers. IEEE Transactions on Information Theory\n9:49–51\nKhmelev DV, Teahan WJ (2003) A Repetition Based Measure for\nVerification of Text Collections and for Text Categorization. In:\nProceedings of the 26th Annual International ACM SIGIR Conference on\nResearch and Development in Information Retrieval, ACM, pp 104–110,\ndoi: 10.1145/860435.860456\nKidwell LA, Wozniak K, Laurel JP (2003) Student Reports and Faculty\nPerceptions of Academic Dishonesty. Teaching Business Ethics 7:205–\n214, doi: 10.1023/A:1025008818338\nKo P, Aluru S (2003) Space Efficient Linear Time Construction of Suffix\nArrays. Journal of Discrete Algorithms 2676:200–210, doi: 10.1007/3540-44888-8_15\nKoppel M, Schler J, Argamon S (2011) Authorship Attribution in the\nWild. Language Resources and Evaluation 45(1):83–94, doi:\n10.1007/s10579-009-9111-2\nKreider R, Almada A, Antonio J, Broeder C, Earnest C, Greenwood M,\nIncledon T, Kalman D, Kleiner S, Leutholtz B, Lowery L, Mendel R,\nStout J, Willoughby D, Ziegenfuss T (2004) ISSN Exercise &amp; Sport\nNutrition Review: Research &amp; Recommendations. Journal of the\nInternational Society of Sports Nutrition 1(1):1–44, doi: 10.1186/15502783-1-1-1, PMC2129137\nKreider RB, Wilborn CD, Taylor L, Campbell B, Almada AL, Collins R,\nCooke M, Earnest CP, Greenwood M, Kalman DS, Kerksick CM, Kleiner\n\nReferences\n\n181.\n\n182.\n183.\n\n184.\n\n185.\n\n186.\n187.\n\n188.\n\n243\n\nSM, Leutholtz B, Lopez H, Lowery LM, Mendel R, Smith A, Spano M,\nWildman R, Willoughby DS, Ziegenfuss TN, Antonio J (2010) ISSN\nExercise &amp; Sport Nutrition Review: Research &amp; Recommendations.\nJournal of the International Society of Sports Nutrition 7:7,\nPMID20181066, PMC2853497\nKulkarni AP, Agarwal V (2008) Extubation failure in intensive care unit:\nPredictors and management. Indian Journal of Critical Care Medicine\n12(1):1–9,\ndoi:\n10.4103/0972-5229.40942,\nPMID19826583,\nPMC2760915\nKumagi T, Heathcote EJ (2008) Primary Biliary Cirrhosis. Orphanet\nJournal of Rare Diseases 3:1\nKurtz S (1999) Reducing the Space Requirement of Suffix Trees.\nSoftware-Practice\nand\nExperience\n29(13):1149–1171,\ndoi:\n10.1002/(SICI)1097-024X(199911)29:13&lt;1149::AID-SPE274&gt;3.0.CO;2O\nLachlan P (2012) The Sherlock Plagiarism Detector. Online Source,\nretrieved Jul. 11, 2012 from: http://sydney.edu.au/engineering/it/~scilect/sherlock/\nLancaster T (2003) Effective and Efficient Plagiarism Detection. Phd\nthesis, School of Computing, Information Systems and Mathematics,\nSouth Bank University, retrieved on Jul. 9, 2013 from http://academia.edu/168972/Effective_and_Efficient_Plagiarism_Detection\nLane P (2011) Ferret Copy Detection Software. Online Source, retrieved\nOct. 1, 2011 from: http://homepages.feis.herts.ac.uk/~comqpcl/ferret.html\nLarsen B (2004) References and citations in automatic indexing and\nretrieval systems - experiments with the boomerang effect. PhD thesis,\nDepartment of Information Studies, Royal School of Library and\nInformation Science, Copenhagen\nLeBaron B (2005) Agent-based Computational Finance. In: Handbook of\nComputational Economics, International Business School, Brandeis\nUniversity, retrieved May 28, 2013 from: people.brandeis.edu/~blebaron/wps/hbook.pdf\n\n244\n\n189.\n\n190.\n\n191.\n\n192.\n\n193.\n\n194.\n\n195.\n\n196.\n\nReferences\n\nLeucht S, Kissling W, Davis JM (2009) How to Read and Understand and\nUse Systematic Reviews and Meta-analyses. Acta Psychiatrica\nScandinavica 119(6):443–450, doi: 10.1111/j.1600-0447.2009.01388.x\nLeung CH, Chan YY (2007) A Natural Language Processing Approach to\nAutomatic Plagiarism Detection. In: Proceedings of the 8th ACM SIGITE\nConference on Information Technology Education, ACM, pp 213–218,\ndoi: 10.1145/1324302.1324348\nLewis J, Ossowski S, Hicks J, Errami M, Garner HR (2006) Text\nSimilarity: an Alternative Way to Search Medline. Bioinformatics\n22(18):2298–2304, doi: 10.1093/bioinformatics/btl388\nLiberati A, Altman DG, Tetzlaff J, Mulrow C, Gøtzsche PC, Ioannidis JP,\nClarke M, Devereaux PJ, Kleijnen J, Moher D (2009) The Prisma\nStatement for Reporting Systematic Reviews and Meta-analyses of\nStudies that Evaluate Healthcare Interventions: Explanation and\nElaboration. BMJ 339:1–27, PMID19189221, PMC2764094\nLiberati A, Altman DG, Tetzlaff J, Mulrow C, Gøtzsche PC, Ioannidis JP,\nClarke M, Devereaux PJ, Kleijnen J, Moher D (2009) The Prisma\nStatement for Reporting Systematic Reviews and Meta-analyses of\nStudies that Evaluate Health Care Interventions: Explanation and\nElaboration.\nPLoS\nMedicine\n6:1–28,\ndoi:\ne1000100.\ndoi:10.1371/journal.pmed.1000100, PMID19192942, PMC2634792\nLim VKG, See SKB (2001) Attitudes toward, and Intentions to Report,\nAcademic Cheating among Students in Singapore. Ethics &amp; Behavior\n11(3):261–274, doi: 10.1207/S15327019EB1103_5\nLipinski M, Yao K, Breitinger C, Beel J, Gipp B (2013) Evaluation of\nHeader Metadata Extraction Approaches and Tools for Scientific PDF\nDocuments. In: Proceedings of the 13th ACM/IEEE-CS Joint Conference\non Digital Libraries (JCDL), ACM, New York, NY, USA, pp 385–386,\ndoi:\n10.1145/2467696.2467753,\nhttp://doi.acm.org/10.1145/2467696.2467753\nLittle J, Higgins JP, Ioannidis JP, Moher D, Gagnon F, von Elm E,\nKhoury MJ, Cohen B, Davey Smith G, Grimshaw J, Scheet P, Gwinn M,\n\nReferences\n\n197.\n\n198.\n\n199.\n200.\n\n201.\n\n202.\n\n245\n\nWilliamson RE, Zou GY, Hutchings K, Johnson CY, Tait V, Wiens M,\nGolding J, van Duijn C, McLaughlin J, Paterson A, Wells G, Fortier I,\nFreedman M, Zecevic M, King R, Infante Rivard C, Stewart A, Birkett N\n(2009) Strengthening the Reporting of Genetic Association Studies\n(STREGA): an Extension of the STROBE Statement. PLoS Med 6:1–13,\ndoi: 10.1371/journal.pmed.1000022, PMID19192942, PMC2634792\nLittle J, Higgins JP, Ioannidis JP, Moher D, Gagnon F, von Elm E,\nKhoury MJ, Cohen B, Davey Smith G, Grimshaw J, Scheet P, Gwinn M,\nWilliamson RE, Zou GY, Hutchings K, Johnson CY, Tait V, Wiens M,\nGolding J, van Duijn C, McLaughlin J, Paterson A, Wells G, Fortier I,\nFreedman M, Zecevic M, King R, Infante Rivard C, Stewart A, Birkett N\n(2009) Strengthening the Reporting of Genetic Association Studies\n(STREGA): an Extension of the STROBE Statement. Eur J Epidemiol\n24:37–55, PMID19189221, PMC2764094\nLiu S, Chen C (2011) The Effects of Co-citation Proximity on Co-citation\nAnalysis. In: Proceedings of the Conference of the International Society\nfor Scientometrics and Informetrics\nLiu S, Chen C (2012) The Proximity of Co-Citation. Scientometrics\n91(2):495–511, doi: 10.1007/s11192-011-0575-7\nLiu X, Yu S, Moreau Y, De Moor B, Glänzel W, Janssens FAL (2009)\nHybrid Clustering of Text Mining and Bibliometrics Applied to Journal\nSets. In: Proceedings of the SIAM International Conference on Data\nMining, Sparks, NV, USA, pp 49–60\nLiu X, Yu S, Janssens FAL, Glänzel W, Moreau Y, De Moor B (2010)\nWeighted Hybrid Clustering by Combining Text Mining and\nBibliometrics on a Large-Scale Journal Database. Journal of the\nAmerican Society for Information Science and Technology 61(6):1105–\n1119, doi: 10.1002/asi.21312\nLong TC, Errami M, George AC, Sun Z, Garner HR (2009) Responding\nto Possible Plagiarism. Science 323(5919):1293–1294, doi:\n10.1126/science.1167408,\nhttp://www.sciencemag.org/content/323/5919/1293.full.pdf\n\n246\n\n203.\n\n204.\n\n205.\n\n206.\n\nReferences\n\nLyon C, Malcolm J, Dickerson B (2001) Detecting Short Passages of\nSimilar Text in Large Document Collections. In: Proceedings of the\nConference on Empirical Methods in Natural Language Processing, pp\n118–125\nLyon C, Barrett R, Malcolm J (2003) Experiments in Electronic\nPlagiarism Detection Computer Science Department. Tech. Rep. TR 388,\nSchool of Computer Science, University of Hertfordshire\nMacPherson H, Altman DG, Hammerschlag R, Li Y, Wu T, White A,\nMoher D, Altman DG, Moher D, MacPherson H, Hammerschlag R, Li Y,\nWu T, Birch S, Boutron I, Bovey M, Fei Y, Gagnier J, Hopewell S,\nHopwood V, Jena S, Linde K, Liu J, Trinh K, Veitch E, White A,\nYamashita H (2010) Revised Standards for Reporting Interventions in\nClinical Trials of Acupuncture (STRICTA): Extending the CONSORT\nStatement. Acupunct Med 28:83–93, PMID20615861, PMC3002761\nMacPherson H, Altman DG, Hammerschlag R, Youping L, Taixiang W,\nWhite A, Moher D, Burton A, Hopton A, Jenna S, Prady S, Stuardi T,\nAltman D, Moher D, MacPherson H, Hammerschlag R, Youping L,\nTaixiang W, Bovey M, Hopwood V, White A, Anastasi J, Birch S, Bosco\nJ, Citkovitz C, Coeytaux R, Cohen M, Colbert A, Elden H, Filho RdeC,\nForbes A, Foster N, Gagnier J, Goldby M, Gronlund M, Harris R, Irnich\nD, Langevin H, Lixing L, Lee A, Hyangsook L, Myeongsoo L, Sanghoon\nL, Lewith G, Linde K, Liu J, Milley R, Mist S, Melchart D, Molsberger\nA, Napadow V, Niemtzow R, Jongbae P, Saghaei M, Saputra K, Schnyer\nR, Shang C, Sherman K, Byung Cheul S, Smith C, Stener Victorin E,\nTrinh K, Vas J, Vickers A, White P, Witt C, Yamashita H, Zaslawski C,\nBirch S, Boutron I, Bovey M, Yutong F, Gagnier J, Hopewell S,\nHopwood V, Jena S, Linde K, Jianping L, Trinh K, Veitch E, White A,\nYamashita H (2010) Revised Standards for Reporting Interventions in\nClinical Trials of Acupuncture (STRICTA): Extending the CONSORT\nStatement. PLoS Medicine 7:1–11, doi: 10.1371/journal.pmed.1000261,\nPMID20543992, PMC2882429\n\nReferences\n\n207.\n208.\n\n209.\n\n210.\n\n211.\n\n212.\n\n213.\n\n214.\n\n215.\n216.\n217.\n\n247\n\nMalthan D (2011) PlagAware. Online Source, retrieved Oct. 1, 2011\nfrom: http://www.plagaware.com\nManber U (1994) Finding Similar Files in a Large File System. In:\nProceedings of the USENIX Winter Technical Conference, USENIX\nAssociation, Berkeley, CA, USA, pp 2–11\nManning CD, Raghavan P, Schütze H (2009) An Introduction to\nInformation Retrieval, online edition edn. Cambridge University Press,\nCambridge, England\nMarkram H, Rinaldi T, Markram K (2007) The Intense World Syndrome\n- an Alternative Hypothesis for Autism. Frontiers in Neuroscience 1:77–\n96\nMarkram K, Markram H (2010) The Intense World Theory - a Unifying\nTheory of the Neurobiology of Autism. Frontiers in Human Neuroscience\n4:224, PMID21191475, PMC3010743\nMarsden H, Carroll M, Neill JT (2005) Who Cheats At University? a\nSelf-report Study of Dishonest Academic Behaviours in a Sample of\nAustralian University Students. Australian Journal of Psychology\n57(1):1–10, doi: 10.1080/00049530412331283426\nMarshakova-Shaikevich I (1973) System of Document Connections\nBased on References. Scientific and Technical Information Serial of\nVINITI 6(2):3–8\nMartin B (2007) Obstacles to Academic Integrity. In: Proceedings of the\n3rd Asia-Pacific Conference on Educational Integrity, University of South\nAustralia, Adelaide, pp 21–26\nMartinson BC, Anderson MS (2005) Scientists Behaving Badly. Nature\n435(7043):737–738, doi: 10.1038/435737a\nMartyn J (1964) Bibliographic coupling. Journal of Documentation\n20(4):236, doi: 10.1108/eb026352\nMathers C, Murray C (2003) Introduction of article-processing charges\nfor Population Health Metrics. Population Health Metrics 1(1:8), doi:\n10.1186/1478-7954-1-8, PMID14613521, PMC272941\n\n248\n\n218.\n\n219.\n\n220.\n\n221.\n\n222.\n\n223.\n\n224.\n\n225.\n\n226.\n\n227.\n\nReferences\n\nMaurer H, Zaka B (2007) Plagiarism - a Problem and How to Fight It. In:\nProceedings of World Conference on Educational Multimedia,\nHypermedia and Telecommunications, AACE, Vancouver, Canada, pp\n4451–4458\nMaurer H, Kappe F, Zaka B (2006) Plagiarism - a Survey. Journal of\nUniversal Computer Science 12(8):1050–1084, doi: 10.3217/jucs-012-081050\nMcCabe DL (2005) Cheating among College and University Students: A\nNorth American Perspective. International Journal for Academic Integrity\n1(1):1–11\nMcCabe DL, Trevino LK (1993) Academic Dishonesty: Honor Codes and\nOther Contextual Influences. The Journal of Higher Education 64(5):522–\n538\nMcCabe DL, Trevino LK (1996) What We Know about Cheating in\nCollege: Longitudinal Trends and Recent Developments. Change\n28(1):28–33\nMcCabe DL, Butterfield KD, Trevino LK (2006) Academic Dishonesty in\nGraduate Business Programs: Prevalence, Causes, and Proposed Action.\nAcademy of Management Learning and Education 5(3):294\nMcnamee P, Mayfield J (2004) Character N-Gram Tokenization for\nEuropean Language Text Retrieval. Information Retrieval 7:73–97, doi:\n10.1023/B:INRT.0000009441.78971.be\nMeho L, Yang K (2007) Impact of data sources on citation counts and\nrankings of LIS faculty: Web of Science vs. Scopus and Google Scholar.\nJournal of the American Society for Information Science and Technology\n58(13):2105–25\nKoch Mehrin S (2001) Historische Währungsunion zwischen Wirtschaft\nund Politik : die Lateinische Münzunion 1865 - 1927. Dissertation,\nFaculty of Philosophy, University of Heidelberg, retracted as plagiarism\nby the University of Heidelberg on Jun. 15, 2011.\nMerton RK (1968) The Matthew Effect in Science. Science\n159(3810):56–63, doi: 10.1126/science.159.3810.56\n\nReferences\n\n228.\n229.\n\n230.\n\n231.\n232.\n\n233.\n\n234.\n\n235.\n\n236.\n\n237.\n\n249\n\nMeuschke N, Gipp B (2013) State of the Art in Detecting Academic\nPlagiarism. International Journal for Educational Integrity 9(1):50–71\nMeuschke N, Gipp B, Breitinger C (2012) CitePlag: A Citation-based\nPlagiarism Detection System Prototype. In: Proceedings of the 5th\nInternational Plagiarism Conference, Newcastle upon Tyne, UK\nMicol D, Ferrández Ó, Llopis F, Muñoz R (2010) A Textual-Based\nSimilarity Approach for Efficient and Scalable External Plagiarism\nAnalysis - Lab Report for PAN at CLEF 2010. In: CLEF (Notebook\nPapers/LABs/Workshops)\nMiller G, Charles W (1991) Contextual correlates of semantic similarity.\nLanguage and cognitive processes 6(1):1–28\nMonostori K, Zaslavsky A, Schmidt H (2000) Document Overlap\nDetection System for Distributed Digital Libraries. In: Proceedings of the\n5th ACM Conference on Digital Libraries, ACM, pp 226–227, doi:\n10.1145/336597.336667\nMonostori K, Zaslavsky A, Bia A (2001) Using the MatchDetectReveal\nSystem for Comparative Analysis of Texts. In: Proceedings of the 6th\nAustralasian Document Computing Symposium, Coffs Harbour,\nAustralia, pp 51–58\nMonostori K, Zaslavsky A, Schmidt H (2001) Efficiency of Data\nStructures for Detecting Overlaps in Digital Documents. Australian\nComputer Science Communications 23:140–147\nMonostori K, Finkel R, Zaslavsky A, Hodász G, Pataki M (2002)\nComparison of Overlap Detection Techniques. In: Proceedings of the\nInternational Conference on Computational Science, Springer,\nAmsterdam, Netherlands, Lecture Notes in Computer Science, vol 2329,\npp 51–60\nMonostori K, Zaslavsky A, Schmidt H (2002) Suffix Vector: Space- and\nTime-efficient Alternative to Suffix Trees. Australian Computer Science\nCommunications 24(1):157–165, doi: 10.1145/563857.563820\nGarnacho Montero J, Amaya Villar R (2006) A validated clinical\napproach for the management of aspergillosis in critically ill patients:\n\n250\n\n238.\n\n239.\n\n240.\n\n241.\n\n242.\n\n243.\n\n244.\n\n245.\n\nReferences\n\nready, steady, go! Critical Care 10(2):132–133, doi: 10.1186/cc4860,\nPMID16584528, PMC1550917\nMuhr M, Zechner R Mario Kern, Granitzer M (2009) External and\nIntrinsic Plagiarism Detection Using Vector Space Models. In:\nProceedings of the 3rd PAN Workshop. Uncovering Plagiarism,\nAuthorship and Social Software Misuse, pp 47–55\nMuhr M, Kern R, Zechner M, Granitzer M (2010) External and Intrinsic\nPlagiarism Detection Using a Cross-Lingual Retrieval and Segmentation\nSystem - Lab Report for PAN at CLEF 2010. In: Notebook Papers of\nCLEF 2010 LABs and Workshops, Padua, Italy\nNeville LM, O’Hara B, Milat AJ (2009) Computer-tailored Dietary\nBehaviour Change Interventions: A Systematic Review. Health Education\nResearch 24:699–720, PMID19286893, PMC2706490\nNeville LM, O’Hara B, Milat AJ (2009) Computer-tailored Physical\nActivity Behavior Change Interventions Targeting Adults: a Systematic\nReview. The International Journal of Behavioral Nutrition and Physical\nActivity 6:30, PMID19490649, PMC2700068\nNikolaou C, Althammer S, Beato M, Guigo R (2010) Structural\nConstraints Revealed in Consistent Nucleosome Positions in the Genome\nof S. Cerevisiae. Epigenetics Chromatin 3:20, PMID21073701,\nPMC2994855\nNorwegian Board of Health Supervision (2007) Case involving scientific\nfraud 2005-2006. Press Release, retrieved Oct. 31, 2012 from: http://www.helsetilsynet.no/no/Norwegian-Board-of-Health-Supervision/Decisions-in-individual-cases/Case-involving-scientific-fraud-2005-2006/\nNoyons E, van Raan A (1994) Bibliometric Cartography of Scientific and\nTechnological Developments of an R &amp; D Field. Scientometrics 30:157–\n173, doi: 10.1007/BF02017220\nOberreuter G, L’Huillier G, Ríos SA, Velásquez JD (2010) FastDocode:\nFinding Approximated Segments of N-Grams for Document Copy\nDetection. In: Notebook Papers of CLEF 2010 LABs and Workshops,\nPadua, Italy\n\nReferences\n\n246.\n\n247.\n\n248.\n\n249.\n\n250.\n\n251.\n\n252.\n\n253.\n254.\n\n255.\n\n251\n\nOberreuter G, L’Huillier G, Ríos SA, Velásquez JD (2011) Approaches\nfor Intrinsic and External Plagiarism Detection. In: Notebook Papers of\nCLEF 2011 LABs and Workshops, Amsterdam, Netherlands\nO’Shea J, Bandar Z, Crockett K, McLean D (2008) A Comparative Study\nof Two Short Text Semantic Similarity Measures. In: Proceedings of the\n2nd KES International Conference on Agent and Multi-agent Systems,\nSpringer, pp 172–181\nPalkovskii Y (2009) &quot;Counter Plagiarism Detection Software” and\n“Counter Counter Plagiarism Detection” Methods. In: Proceedings of the\n3rd Workshop on Uncovering Plagiarism, Authorship and Social\nSoftware Misuse and 1st International Competition on Plagiarism\nDetection\nPapadakis MA, Wofsy D (2010) Plagiarism on Personal Statements: a\nDisturbing Symptom of a Broader Trend. Annals of Internal Medicine\n153(2):128–129\nPark C (2003) In Other Peoples Words: Plagiarism by University\nStudents – Literature and Lessons. Assessment Evaluation in Higher\nEducation 28(5):471–488, doi: 10.1080/02602930301677\nPawelzik B (2005) Algorithmen zur Plagiaterkennung. Student research\nproject,\nTechnische\nUniversität\nBraunschweig\nInstitut\nfür\nBetriebssysteme und Rechnerverbund\nPera MS, Ng YK (2011) SimPaD: a Word-Similarity Sentence-Based\nPlagiarism Detection Tool on Web Documents. Web Intelligence and\nAgent Systems 9(1):24–41, doi: 10.3233/WIA-2011-0203\nPereira ARJ, Ziviani N (2004) Retrieving Similar Documents from the\nWeb. Journal of Web Engineering 2(4):247–261\nPertsemlidis A, Garner H (2004) Engineering in Genomics: Text\nComparison Based on Dynamic Programming. IEEE Engineering in\nMedicine\nand\nBiology\nMagazine\n23(6):66–71,\ndoi:\n10.1109/MEMB.2004.1378640\nPhelan T (1999) A Compendium of Issues for Citation Analysis.\nScientometrics 45:117–136, doi: 10.1007/BF02458472\n\n252\n\n256.\n\n257.\n\n258.\n\n259.\n\n260.\n\n261.\n\n262.\n\n263.\n\n264.\n\nReferences\n\nPiao S, Tsuruoka Y (2008) A Highly Accurate Sentence and Paragraph\nBreaker. Online Source, retrieved Jan. 28, 2011 from: http://text0.mib.man.ac.uk:8080/scottpiao/sent_detector\nPinto D, Civera J, Barrón Cedeño A, Juan A, Rosso P (2009) A Statistical\nApproach to Crosslingual Natural Language Tasks. Journal of Algorithms\n64(1):51–60, doi: 10.1016/j.jalgor.2009.02.005\nPotsdamer Neuste Nachrichten Online (2012) Plagiatsstreit an der BTU\num Vattenfall-Chef. Online Source, retrieved Aug. 2, 2012 from http://www.pnn.de/brandenburg-berlin/663296/\nPotthast M, Stein B, Anderka M (2008) A Wikipedia-based Multilingual\nRetrieval Model. In: Proceedings of the 30th European Conference on\nAdvances in Information Retrieval, Springer, pp 522–530\nPotthast M, Stein B, Eiselt A, Barrón Cedeño A, Rosso P (2009)\nOverview of the 1st International Competition on Plagiarism Detection.\nIn: Proceedings of the 3rd Workshop on Uncovering Plagiarism,\nAuthorship and Social Software Misuse and 1st International Competition\non Plagiarism Detection, vol 502, pp 1–9\nPotthast M, Barrón Cedeño A, Eiselt A, Stein B, Rosso P (2010)\nOverview of the 2nd International Competition on Plagiarism Detection.\nIn: Notebook Papers of CLEF 2010 LABs and Workshops, Padua, Italy\nPotthast M, Stein B, Barrón Cedeño A, Rosso P (2010) An Evaluation\nFramework for Plagiarism Detection. In: Proceedings of the 23rd\nInternational Conference on Computational Linguistics, Association for\nComputational Linguistics, Beijing, China, pp 997–1005\nPotthast M, Barrón Cedeño A, Stein B, Rosso P (2011) Cross-language\nPlagiarism Detection. Language Resources and Evaluation 45(1):45–62,\ndoi: 10.1007/s10579-009-9114-z\nPotthast M, Eiselt A, Barrón-Cedeño A, Stein B, Rosso P (2011)\nOverview of the 3rd International Competition on Plagiarism Detection.\nIn: Notebook Papers of CLEF 2011 LABs and Workshops, Amsterdam,\nNetherlands\n\nReferences\n\n265.\n\n266.\n\n267.\n\n268.\n\n269.\n\n270.\n271.\n272.\n273.\n274.\n\n253\n\nPotthast M, Gollub T, Hagen M, Kiesel J, Michel M, Oberländer A,\nTippmann M, Barrón Cedeño A, Gupta P, Rosso P, Stein B (2012)\nOverview of the 4th International Competition on Plagiarism Detection.\nIn: CLEF 2012 Evaluation Labs and Workshop - Working Notes Papers,\nhttp://www.uni-weimar.de/medien/webis/research/events/pan-12/pan12web/index.html\nPouliquen B, Steinberger R, Ignat C (2003) Automatic Identification of\nDocument Translations in Large Multilingual Document Collections. In:\nProceedings of the International Conference Recent Advances in Natural\nLanguage Processing, pp 401–408\nPrechelt L, Philippsen M, Malpohl G (2000) JPlag: Finding Plagiarisms\namong a Set of Programs. Technical Report 2000-1, Universität\nKarlsruhe, Fakultät für Informatik, Germany\nOxford University Press (2009) A Dictionary of Psychology [electronic\nresource]. Oxford Reference Online, Oxford University Press, http://www.oxfordreference.com/\nPrice AR (2006) Cases of Plagiarism Handled by the United States Office\nof Research Integrity 1992-2005. Plagiary: Cross-Disciplinary Studies in\nPlagiarism, Fabrication, and Falsification 1:46–56\nSolla Price DJd (1965) Networks of Scientific Papers. Science\n149(3683):510–515, doi: 10.1126/science.149.3683.510\nPrioInfo AB (2011) URKUND. Online Source, retrieved Oct. 1, 2011\nfrom: http://www.urkund.com\nProject SAX (2004) Simple API for XML (SAX). Online Source,\nretrieved May 29, 2012 from: http://www.saxproject.org/\nRakovski CC, Levy ES (2007) Academic Dishonesty: Perceptions of\nBusiness Students. College Student Journal 41(2):466\nRan EY, Mordechai N (2007) Optimal Single-Class Classification\nStrategies. In: Proceedings of the 20th Annual Conference on Neural\nInformation Processing Systems, MIT Press, Vancouver, Canada, pp\n377–384\n\n254\n\n275.\n\n276.\n\n277.\n\n278.\n\n279.\n\n280.\n\n281.\n\n282.\n\nReferences\n\nRazera D, Verhagen H, Cerratto Pargman T, Ramberg R (2010)\nPlagiarism Awareness, Perception, and Attitudes among Students and\nTeachers in Swedish Higher Education – A Case Study. In: Proceedings\nof the 4th International Plagiarism Conference, Newcastle upon Tyne, UK\nResnik P (1999) Semantic Similarity in a Taxonomy: An InformationBased Measure and its Application to Problems of Ambiguity in Natural\nLanguage. Journal of Artificial Intelligence Research 11:95–130\nRoberts P, Anderson J, Yanish P (1997) Academic Misconduct: Where\nDo We Start? Paper presented at the Annual Conference of the Northern\nRocky Mountain Educational Research Association, retrieved Oct. 25,\n2010\nfrom:\nhttp://www.eric.ed.gov/ERICWebPortal/search/permalinkPopup.jsp?accno=ED415781\nRossaint R, Bouillon B, Cerny V, Coats TJ, Duranteau J, Fernandez\nMondejar E, Hunt BJ, Komadina R, Nardi G, Neugebauer E, Ozier Y,\nRiddez L, Schultz A, Stahel PF, Vincent JL, Spahn DR (2010)\nManagement of bleeding following major trauma: an updated European\nguideline. Critical Care 14:R52, PMID20370902, PMC2887168\nRudman J (1997) The State of Authorship Attribution Studies: Some\nProblems and Solutions. Computers and the Humanities 31:351–365, doi:\n10.1023/A:1001018624850\nSaß V (2009) Regulierung im Mobilfunk. Dissertation, Department of\nLaw, University of Konstanz, http://d-nb.info/99505147X, retracted as\nplagiarism by the University of Konstanz on May 11, 2011.\nSarkar S, Bhattacharya P, Kumar I, Mandal K (2009) Changes of\nsplanchnic perfusion after applying positive end expiratory pressure in\npatients with acute respiratory distress syndrome. Indian Journal of\nCritical Care Medicine 13(1):12–16, doi: 10.4103/0972-5229.53109,\nPMID19881173, PMC2772258\nScaife B (2007) IT Consultancy Plagiarism Detection Software Report for\nJISC Plagiarism Advisory Service. Tech. rep., Joint Information System\nCommittee\n\nReferences\n\n283.\n284.\n\n285.\n\n286.\n\n287.\n\n288.\n\n289.\n\n290.\n\n291.\n292.\n\n293.\n\n255\n\nScanlon PM, Neumann DR (2002) Internet Plagiarism among College\nStudents. Journal of College Student Development 43(3):374–385\nScheers NJ, Dayton CM (1987) Improved Estimation of Academic\nCheating Behavior Using the Randomized Response Technique. Research\nin Higher Education 26:61–69, doi: 10.1007/BF00991933\nScherbinin V, Butakov S (2009) Using Microsoft SQL Server Platform\nfor Plagiarism Detection. In: Proceedings of the 3rd PAN Workshop.\nUncovering Plagiarism, Authorship and Social Software Misuse\nSchleimer S, Wilkerson DS, Aiken A (2003) Winnowing: Local\nAlgorithms for Document Fingerprinting. In: Proceedings of the ACM\nSIGMOD International Conference on Management of Data, ACM, pp\n76–85, doi: 10.1145/872757.872770\nScott D, Palmer R (2003) The Influence of Tobacco Smoking on\nAdhesion Molecule Profiles. Tobacco Induced Diseases 1:7–25,\nPMID19570245, PMC2669563\nScott D, Palmer R (2003) The Influence of Tobacco Smoking on\nAdhesion Molecule Profiles. Tobacco Induced Diseases 1:7–25,\nPMID19570245, PMC2671531\nScott JE (2004) The Pulmonary Surfactant: Impact of Tobacco Smoke\nand Related Compounds on Surfactant and Lung Development. Tobacco\nInduced Diseases 2:3–25, PMID19570267, PMC2669453\nScott JE (2004) The Pulmonary Surfactant: Impact of Tobacco Smoke\nand Related Compounds on Surfactant and Lung Development. Tobacco\nInduced Diseases 2(1):3–25, PMID19570267, PMC2671518\nSeglen PO (1997) Why the Impact Factor of Journals Should Not Be\nUsed for Evaluating Research. BMJ 314(7079):497\nSemmelweis University of Budapest (2012) University Senate Revokes\nPál Schmitt’s Doctoral (Dr. Univ.) Title. Press Release, retrieved Mar. 30,\n2012\nfrom:\nhttp://www.semmelweis-univ.hu/news/2556/universitysenate-revokes-pal-schmitt%E2%80%99s-doctoral-dr-univ-title/\nShen Y, Li SC, Tian CG, Cheng M (2009) Research on Anti-Plagiarism\nSystem and the Law of Plagiarism. In: Proceedings of the 1st\n\n256\n\n294.\n\n295.\n\n296.\n\n297.\n\n298.\n\n299.\n\n300.\n301.\n\nReferences\n\nInternational Workshop on Education Technology and Computer Science,\npp 296–300, doi: 10.1109/ETCS.2009.327\nSher IH, Garfield E (1966) New Tools for Improving and Evaluating the\nEffectiveness of Science. In: Proceedings of the Conference on Research\nProgram Effectiveness, Gordon and Breach, Washington, D.C., USA, pp\n135–146\nShibata N, Kajikawa Y, Takeda Y, Matsushima K (2009) Comparative\nStudy on Methods of Detecting Research Fronts Using Different Types of\nCitation. Journal of the American Society for Information Science and\nTechnology 60:571–580, doi: 10.1002/asi.v60:3\nShidham VB, Pitman MB, Demay RM, Atkinson BF (2008)\nCytoJournal’s move to the new platform: More on financial model to the\nsupport open-access charter in cytopathology, publication quality\nindicators, and other issues. Cytojournal 5(15), doi: 10.4103/17426413.44572, PMID19495401, PMC2669682\nShivakumar N, Garcia Molina H (1995) SCAM a Copy Detection\nMechanism for Digital Documents. In: Proceedings of the 2nd Annual\nConference on the Theory and Practice of Digital Libraries, Austin, TX,\nUSA\nShivakumar N, Garcia Molina H (1996) Building a Scalable and Accurate\nCopy Detection Mechanism. In: Proceedings of the 1st ACM\nInternational Conference on Digital Libraries, ACM, pp 160–168, doi:\n10.1145/226931.226961\nSi A, Leong V Hong, Lau RWH (1997) CHECK: a Document Plagiarism\nDetection System. In: Proceedings of the ACM Symposium on Applied\nComputing, ACM, pp 70–77, doi: 10.1145/331697.335176\nSkyLine Inc (2011) Plagiarism Detector. Online Source, retrieved Oct. 1,\n2011 from: http://www.plagiarism-detector.com\nSmall H (1973) Co-citation in the Scientific Literature: A New Measure\nof the Relationship Between Two Documents. Journal of the American\nSociety for Information Science 24:265–269\n\nReferences\n\n302.\n303.\n\n304.\n305.\n306.\n\n307.\n\n308.\n\n309.\n\n310.\n\n311.\n\n312.\n\n257\n\nSmall H, Griffith BC (1974) The Structure of Scientific Literatures I:\nIdentifying and Graphing Specialties. Science Studies 4(1):17–40\nSmith H, Ridgway J (2008) Why Students Cheat (In Their Own Words as\nWell as those of Others). In: Proceedings of the 3rd International\nPlagiarism Conference, Newcastle upon Tyne, UK\nSmith LC (1981) Citation Analysis. Library Trends 30(1):83–106\nSmyth B (2003) Computing Patterns in Strings. Pearson Addison-Wesley,\nHarlow, England; New York\nSnapper JW (1999) On the Web, Plagiarism Matters More Than\nCopyright Piracy. Ethics and Information Technology 1:127–135, doi:\n10.1023/A:1010083703905\nSorokina D, Gehrke J, Warner S, Ginsparg P (2006) Plagiarism Detection\nin arXiv. Technical report computer science, Cornell University, TR20062046\nSpahn DR, Cerny V, Coats TJ, Duranteau J, Fernandez Mondejar E,\nGordini G, Stahel PF, Hunt BJ, Komadina R, Neugebauer E, Ozier Y,\nRiddez L, Schultz A, Vincent JL, Rossaint R (2007) Management of\nBleeding Following Major Trauma: a European Guideline. Critical Care\n11:R17, PMID17298665, PMC2151863\nSpiegel Online (2013) Titelentzug vor Gericht: Schavan hat Klage\neingereicht. Online Source, retrieved Feb. 21, 2013 from: http://www.spiegel.de/unispiegel/studium/schavan-reichte-klage-gegen-entzugdes-doktortitels-ein-a-884435.html\nStamatatos E (2009) A Survey of Modern Authorship Attribution\nMethods. Journal of the American Society for Information Science and\nTechnology 60(3):538–556, doi: 10.1002/asi.21001\nStamatatos E (2009) Intrinsic Plagiarism Detection Using Character ngram Profiles. In: Proceedings of the 3rd PAN Workshop. Uncovering\nPlagiarism, Authorship and Social Software Misuse\nStamatatos E (2011) Plagiarism Detection Using Stopword N-grams.\nJournal of the American Society for Information Science and Technology\n62(12):2512–2527, doi: 10.1002/asi.21630\n\n258\n\n313.\n314.\n\n315.\n\n316.\n\n317.\n\n318.\n\n319.\n\n320.\n\n321.\n\nReferences\n\nStandler RB (2001) Plagiarism in Colleges in USA. Online Source,\nretrieved Oct. 27, 2011 from: http://www.rbs2.com/plag.htm\nStanford Natural Language Processing Group (2010) Stanford CoreNLP a Suite of Core NLP Tools. Online Source, retrieved May 29, 2011 from:\nhttp://nlp.stanford.edu/software/corenlp.shtml\nSteen RG (2011) Retractions in the Medical Literature: How Many\nPatients are Put at Risk by Flawed Research? Journal of Medical Ethics\n37:688–692, doi: 10.1136/jme.2011.043133\nStein B, Meyer zu Eissen S (2006) Near Similarity Search and Plagiarism\nAnalysis. In: Proceedings of the 29th Annual Conference of the\nGesellschaft für Klassifikation e.V., Springer, Magdeburg, pp 430–437,\ndoi: 10.1007/3-540-31314-1_52\nStein B, Meyer zu Eissen S, Potthast M (2007) Strategies for Retrieving\nPlagiarized Documents. In: Proceedings of the 30th Annual International\nACM\nSIGIR\nConference,\nACM,\npp\n825–826,\ndoi:\n10.1145/1277741.1277928\nStein B, Koppel M, Stamatatos E (eds) (2007) Plagiarism Analysis\nAuthorship Identification, and Near Duplicate Detection, CEUR\nWorkshop Proceedings, vol 276, CEUR-WS.org, in Proceedings of the\nSIGIR 2007 International Workshop, held in conjunction with the 30th\nAnnual International ACM SIGIR Conference, Amsterdam, Netherlands\nStein B, Lipka N, Prettenhofer P (2011) Intrinsic Plagiarism Analysis.\nLanguage Resources and Evaluation 45(1):63–82, doi: 10.1007/s10579010-9115-y\nSteinberger R, Pouliquen B, Hagman J (2002) Document Similarity\nCalculation Using the Multilingual Thesaurus EUROVOC. In:\nProceedings of the 3rd International Conference on Computational\nLinguistics and Intelligent Text Processing, Springer, London, UK, pp\n415–424\nSun Z, Errami M, Long T, Renard C, Choradia N, Garner H (2010)\nSystematic Characterizations of Text Similarity in Full Text Biomedical\n\nReferences\n\n322.\n\n323.\n\n324.\n\n325.\n\n326.\n\n327.\n\n328.\n\n329.\n\n330.\n\n259\n\nPublications.\nPLoS\nONE\n5(9):e12,704,\ndoi:\n10.1371/journal.pone.0012704\nSuárez P, González JC, Villena Román J (2010) A Plagiarism Detector\nfor Intrinsic Plagiarism. In: Notebook Papers of CLEF 2010 LABs and\nWorkshops, Padua, Italy\nSutherland-Smith W (2005) Pandora’s Box: Academic Perceptions of\nStudent Plagiarism in Writing. Journal of English for Academic Purposes\n4(1):83–95, doi: 10.1016/j.jeap.2004.07.007\nSwazey JP, Anderson MS, Louis KS (1993) Ethical Problems in\nAcademic Research a Survey of Doctoral Candidates and Faculty Raises\nImportant Questions About the Ethical Environment of Graduate\nEducation and Research. American Scientist 81:542–553\nSymvoulakis EK, Klinis S, Peteinarakis I, Kounalakis D, Antonakis N,\nTsafantakis E, Lionis C (2008) Diagnosing a popliteal venous aneurysm\nin a primary care setting: A case report. Journal of Medical Case Reports\n2, doi: 10.1186/1752-1947-2-307, PMID18808663, PMC2556343\nTan Z (2009) Erratum: Neural Protection by Naturopathic Compounds-an\nExample of Tetramethylpyrazine From Retina to Brain. Journal of Ocular\nBiology, Diseases, and Informatics 2:137–144, PMID20046848,\nPMC2798986\nTan Z (2009) Neural Protection by Naturopathic Compounds-an Example\nof Tetramethylpyrazine From Retina to Brain. Journal of Ocular Biology,\nDiseases, and Informatics 2:57–64, PMID19672463, PMC2723671\nTashiro T, Ueda T, Hori T, Hirate Y, Yamana H (2007) EPCI: Extracting\nPotentially Copyright Infringement Texts from the Web. In: Proceedings\nof the 16th International Conference on World Wide Web, ACM, pp\n1151–1152, doi: 10.1145/1242572.1242740\nThornton DE (2010) Detect, Deter, and Disappear: the Plagiarism\nPrevention Project at Bilkent University, Turkey. In: Proceedings of the\n4th International Plagiarism Conference, Newcastle upon Tyne, UK\nTran N, Alves P, Ma S, Krauthammer Michael (2009) Enriching PubMed\nRelated Article Search with Sentence Level Co-citations. In: Proceedings\n\n260\n\n331.\n\n332.\n\n333.\n\n334.\n\n335.\n\n336.\n\n337.\n338.\n\n339.\n\nReferences\n\nof the Annyual AMIA Symposium, pp 650–654, http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2815371/\nTrof RJ, Beishuizen A, Debets Ossenkopp YJ, Girbes ARJ, Groeneveld\nABJ (2007) Management of invasive pulmonary aspergillosis in nonneutropenic critically ill patients. Intensive Care Medicine 33(10):1694–\n1703, doi: 10.1007/s00134-007-0791-z, PMID17646966, PMC2039828\nTrost K (2009) Psst, Have You Ever Cheated? A Study of Academic\nDishonesty in Sweden. Assessment &amp; Evaluation in Higher Education\n34(4):367–376, doi: 10.1080/02602930801956067\nTsatsaronis G, Varlamis I, Giannakoulopoulos A, Kanellopoulos N\n(2010) Identifying Free Text Plagiarism Based on Semantic Similarity.\nIn: Proceedings of the 4th International Plagiarism Conference, Newcastle\nupon Tyne, UK\nTsatsaronis G, Varlamis I, Vazirgiannis M (2010) Text Relatedness Based\non a Word Thesaurus. Journal of Artificial Intelligence Research 37(1):1–\n40\nU S National Library of Medicine (2011) Medline® Bibliographic\nDatabase. Online Source, retrieved Sep. 29, 2011 from: http://www.nlm.nih.gov/pubs/factsheets/medline.html\nUkkonen E (1992) Constructing Suffix Trees On-Line in Linear Time. In:\nProceedings of the IFIP 12th World Computer Congress on Algorithms,\nSoftware, Architecture - Information Processing, North-Holland\nPublishing Co., Amsterdam, Netherlands, vol 1, pp 484–492\nUnser M (1999) Behavioral Finance am Aktienmarkt. Uhlenbruch\nUS National Center for Biotechnology Information (2011) PubMed\nCentral. Online Source, retrieved Sep. 27, 2011 from: http://www.ncbi.nlm.nih.gov/pmc/\nUzuner Ö, Katz B, Nahnsen T (2005) Using Syntactic Information to\nIdentify Plagiarism. In: Proceedings of the 2nd Workshop on Building\nEducational Applications Using Natural Language Processing, Ann\nArbor, MI, USA\n\nReferences\n\n340.\n\n341.\n\n342.\n\n343.\n\n344.\n\n345.\n346.\n\n347.\n348.\n\n349.\n\n350.\n\n261\n\nVeldhuis JD, Bowers CY (2010) Integrating GHS into the Ghrelin\nSystem. International Journal of Peptides 2010(Article ID 879503), doi:\n10.1155/2010/879503, PMID20798846, PMC2925380\nVentura LM (2009) Erratum: Psychoneuroimmunology: Application to\nOcular Diseases. Journal of Ocular Biology, Diseases, and Informatics\n2:109–118, PMID20046843, PMC2798981\nVentura LM (2009) Psychoneuroimmunology: Application to Ocular\nDiseases. Journal of Ocular Biology, Diseases, and Informatics 2:84–93,\nPMID19672468, PMC2723676\nVerma AS, Singh UP, Dwivedi PD, Singh A (2010) Contribution of CNS\nCells in Neuroaids. Journal of Pharmacy And Bioallied Sciences 2:300–\n306, PMID21180461, PMC2996080\nVile JR (1991) American Views of the Constitutional Amending Process:\nAn Intellectual History of Article V. The American Journal of Legal\nHistory 35(1):44–69, http://www.jstor.org/stable/845582\nVirk MS, Lieberman JR (2007) Tumor Metastasis to Bone. Arthritis\nResearch and Therapy 9 Suppl. 1:S5, PMID17634144, PMC1924520\nVladutz J G &amp; Cook (1984) Bibliographic coupling and subject\nrelatedness. Proceedings of the American Society for Information Science\n21:204–207\nVohra A, Vohra D (2006) Pro XML Development with Java Technology.\nApress, Berkeley, CA, USA\nVolk D (2003) Die Begrenzung kriegerischer Konflikte durch das\nmoderne Völkerrecht. Dissertation, Faculty of Law, University of\nWürzburg\nvon Elm E, Poglia G, Walder B, Tramèr MR (2004) Different Patterns of\nDuplicate Publication: an Analysis of Articles Used in Systematic\nReviews. JAMA: The Journal of the American Medical Association\n291(8):974–980, doi: 10.1001/jama.291.8.974\nVroniPlag Wiki (2012) VroniPlag - Collaborative Documentation of\nPlagiarism. Online Source, retrieved May 9, 2012 from: http://de.vroniplag.wikia.com\n\n262\n\n351.\n\n352.\n\n353.\n\n354.\n\n355.\n356.\n\n357.\n\n358.\n\n359.\n\n360.\n\nReferences\n\nKevin W Boyack, Henry Small, Richard Klavans (2012) Improving the\nAccuracy of Co-citation Clustering Using Full Text. In: Proceedings of\n17th International Conference on Science and Technology Indicators\nWang Y, Kitsuregawa M (2002) Evaluating Contents-link Coupled Web\nPage Clustering for Web Search Results. In: Proceedings of the 11th\nInternational Conference on Information and Knowledge Management,\nACM, pp 499–506, doi: 10.1145/584792.584875\nWeber-Wulff D (2004) Portal Plagiat - Softwaretest 2004. Online Source,\nretrieved May 29, 2012 from: http://plagiat.htw-berlin.de/ff-alt/05hilfen/programme.html\nWeber-Wulff D (2008) On the Utility of Plagiarism Detection Software.\nIn: Proceedings of the 3rd International Plagiarism Conference,\nNewcastle upon Tyne, UK\nWeber-Wulff D (2008) Portal Plagiat - Softwaretest 2008. Online Source,\nretrieved May 29, 2012 from: http://plagiat.htw-berlin.de/software/2008/\nWeber-Wulff D (2010) Portal Plagiat - Softwaretest 2010. Online Source,\nretrieved May 29, 2012 from: http://plagiat.htw-berlin.de/software/20102/\nWeber-Wulff D (2010) Test Cases for Plagiarism Detection Software. In:\nProceedings of the 4th International Plagiarism Conference, Newcastle\nupon Tyne, UK\nWeber-Wulff D (2011) Copy, Shake, and Paste - a Blog about Plagiarism\nwritten by a Professor for Media and Computing at the HTW. Online\nSource, retrieved Oct. 28, 2011 from: http://copy-shakepaste.blogspot.com\nWeber-Wulff D (2012) Cottbus Refuses to Rescind Doctorate. Online\nSource,\nretrieved\nJul.\n27,\n2012\nfrom\nhttp://copy-shakepaste.blogspot.com/2012/06/cottbus-refuses-to-rescind-doctorate.html\nWeber-Wulff D (2012) Portal Plagiat - Softwaretest Report 2012. Online\nSource, retrieved Nov. 27, 2012 from: http://plagiat.htw-berlin.de/collusion-test-2012/\n\nReferences\n\n361.\n\n362.\n\n363.\n364.\n\n365.\n366.\n367.\n\n368.\n\n369.\n\n370.\n\n263\n\nWeber-Wulff D, Köhler K (2011) Kopienjäger - Cloud-Software vs.\nmenschliche Crowd in der Plagiaterkennung. iX Magazin für\nProfessionelle Informationstechnik 6:78\nWeber-Wulff D, Wohnsdorf G (2006) Strategien der Plagiatsbekämpfung.\nInformation: Wissenschaft &amp; Praxis 57:90–98, doi: ISSN 1434-4653,\nhttps://www.uni-hohenheim.de/fileadmin/einrichtungen/agrar/Studium/Plagiate/strategien_plagiate.pdf\nWeinberg BH (1974) Bibliographic Coupling: a Review. Information\nStorage and Retrieval 10:189–196\nWhitley BE (1998) Factors Associated with Cheating among College\nStudents: A Review. Research in Higher Education 39:235–274, doi:\n10.1023/A:1018724900565\nWikipedia (2011) Suffix Tree. Online Source, retrieved Aug. 30, 2011\nfrom: http://en.wikipedia.org/wiki/Suffix_tree\nWilliams D (2010) Academic Integrity: Pots and Kettles? In: Proceedings\nof the 4th International Plagiarism Conference, Newcastle upon Tyne, UK\nWise MJ (1993) String Similarity via Greedy String Tiling and Running\nKarp-Rabin Matching. Online Preprint, retrieved May 29, 2012 from:\nhttp://vernix.org/marcel/share/RKR_GST.ps.\nYoon SH, Kim SW, Park S (2010) A Link-based Similarity Measure for\nScientific Literature. In: Proceedings of the 19th International Conference\non\nWorld\nWide\nWeb,\nACM,\npp\n1213–1214,\ndoi:\n10.1145/1772690.1772880\nYoon SH, Kim SW, Park S (2011) C-Rank: a Link-based Similarity\nMeasure for Scientific Literature Databases. arXivorg Computing\nResearch Repository abs/1109.1059:1–11\nZhan S, Byung Ryul A, Ki Yol E, Min Koo K, Jin Pyung K, Moon Kyun\nK (2008) Plagiarism Detection Using the Levenshtein Distance and\nSmith-Waterman Algorithm. In: Proceedings of the 3rd International\nConference on Innovative Computing Information and Control, pp 569–\n569, doi: 10.1109/ICICIC.2008.422\n\n264\n\n371.\n\n372.\n\nReferences\n\nZou D, Long WJ, Ling Z (2010) A Cluster-Based Plagiarism Detection\nMethod. In: Notebook Papers of CLEF 2010 LABs and Workshops, 2223 September, Padua, Italy\nZujewski J, Vaughn Cooke A, Flanders KC, Eckhaus MA, Lubet RA,\nWakefield LM (2001) Transforming Growth Factors-beta Are Not Good\nBiomarkers of Chemopreventive Efficacy in a Preclinical Breast Cancer\nModel System. Breast Cancer Research 3:66–75, PMID11250748,\nPMC13902\n\nAppendix\nThe Appendix includes a list of related publications, the preliminary corpus\nanalysis, the CPA/CbPD patent application, material related to the prototype, and\nother resources.\nA Preliminary PMC OAS Corpus Analysis .................................................... 266\nA.1 Bibliographic Coupling ....................................................................... 266\nA.2 Longest Common Citation Sequence .................................................. 273\nA.3 Greedy Citation Tiling ........................................................................ 278\nA.4 Citation Chunking ............................................................................... 286\nA.5 Character-based PDS Sherlock ........................................................... 293\nA.6 Character-based PDS Encoplot ........................................................... 294\nB Technical Details of the CitePlag Prototype ................................................ 296\nB.1 Sentence-Word-Tagger (SW-Tagger) ................................................. 296\nB.2 Data Parser .......................................................................................... 300\nB.3 Consolidation of Reference Identifiers ............................................... 302\nB.4 Database Documentation .................................................................... 304\nC Data and Source-code Downloads ............................................................... 311\nD Related Publications .................................................................................... 313\nE Patent Application ....................................................................................... 318\nF User Study Feedback ................................................................................... 329\nG Reactions of Contacted Authors .................................................................. 331\nH Empirical Studies on Plagiarism Frequencies ............................................. 336\nI\n\nStudies on Citation-based Similarity Measures ........................................... 339\n\nJ\n\nOverview of Selected PDS .......................................................................... 343\n\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8, © Springer Fachmedien Wiesbaden 2014\n\nA\n\nPreliminary PMC OAS Corpus Analysis\n\nThis chapter70 describes the preliminary analysis of the PMC OAS collection.\nThis analysis served to provide an insight into the characteristics and capabilities\nfor each of the detection algorithms before applying them to detect suspicious\ndocument similarities.\n\nA.1 Bibliographic Coupling\nWe analyzed Bibliographic Coupling (BC), both the number (absolute\nBibliographic Coupling strength, ‫ݏ‬஻஼ ) or fraction (relative Bibliographic\nCoupling strength, ‫ݎ‬஻஼ ) of references that two documents have in common for\ntwo reasons. First, we expected ‫ݏ‬஻஼ and ‫ݎ‬஻஼ to be valuable criteria for\nconstraining the scope of the CbPD analysis to document pairs more likely to\nshare a significant citation-based similarity. Additionally, such a reduction of\ncollection size increases computing speed. Second, we wished to test the extent\nto which BC strength can point to suspicious document similarities. To\ninvestigate these two questions, we analyzed the distribution of bibliographically\ncoupled document pairs in the PMC OAS.\nFigure 57 plots the cumulated number of document pairs (vertical axis) with\nan absolute Bibliographic Coupling strength that is greater or equal to the value\non the horizontal axis. The average absolute BC strength was ߤ(‫ݏ‬஻஼ ) = 1.21\nwith a standard deviation of ߪ(‫ݏ‬஻஼ ) = 0.95. The distribution was strongly\nskewed toward lower values. A clear majority, 84 %, of the bibliographically\ncoupled document pairs had a ‫ݏ‬஻஼ = 1.\n\n70\n\nThis chapter was written in collaboration with Norman Meuschke.\n\nA Preliminary PMC OAS Corpus Analysis\n\n267\n\n67.108.864\n33.554.432\n16.777.216\n8.388.608\n4.194.304\n2.097.152\n1.048.576\n524.288\n262.144\n131.072\n65.536\n32.768\n16.384\n8.192\n4.096\n2.048\n1.024\n512\n256\n128\n64\n32\n16\n8\n4\n2\n1\n\nReversed cumulated frequency of document pairs\n\n45.000.000\n40.000.000\n35.000.000\n30.000.000\n25.000.000\n20.000.000\n15.000.000\n10.000.000\n5.000.000\n0\n1\n\n2\n\nߤ = 1.21\n\n4\n8\n16\n32\n64\nBibliographic Coupling strength\n\nߪ = 0.95\n\nܲଶହ =1\n\n128\n\n256\n\n512\n\nܲହ଴ =1 ܲ଻ହ =1\n\nFigure 57: Bibliographic Coupling Strength among Documents in PMC OAS\n\nThe goal of the subsequent CbPD evaluation was to identify highly\nuncommon citation-based document similarities. To test the extent to which high\nBC strengths reflect highly uncommon citation-based document similarities, we\nchose to preliminarily analyze the approximately 3 % of document pairs with the\nhighest ‫ݏ‬஻஼ . We performed the selection of the respective document pairs by\nstetting ‫ݏ‬஻஼ ൒ 4 as a minimum threshold for inclusion. This threshold retained\n972,919 distinct document pairs (2.5 % of the bibliographically coupled\ndocument pairs) for analysis.\nSetting a required minimum ‫ݏ‬஻஼ potentially excluded documents containing\nfew references. This is problematic, because even documents with few total\nreferences may have a substantial relative BC strength (‫ݎ‬஻஼ ). Having a large\nfraction of references in common represents a significant citation-based\ndocument similarity although ‫ݏ‬஻஼ = 4 may be undercut. Therefore, we also\nchose to include documents with ‫ݏ‬஻஼ &lt; 4 if ‫ݎ‬஻஼ is high. To determine the\nthreshold above which ‫ݎ‬஻஼ should be uncommonly high, we analyzed the\n\n268\n\nAppendix\n\ndistribution of ‫ݎ‬஻஼ over all bibliographically coupled document pairs (see Figure\n58).\nOn average, the fraction of references a document has in common with\nanother document (‫ݎ‬஻஼ ) makes up a minor share, ‫׽‬3 %, of a document’s overall\nreferences. We chose to select the ‫׽‬5 % of bibliographically coupled document\npairs with the highest ‫ݎ‬஻஼ . To do so, we set ‫ݎ‬஻஼ = 9 % as a minimum threshold.\nIn other words, we included document pairs with ‫ݏ‬஻஼ &lt; 4, if they had 9 % or\nmore of their references in common.\n90.000.000\n\n67.108.864\n\nRev. cum. freq. of documents\n\n80.000.000\n\n16.777.216\n4.194.304\n\n70.000.000\n\n1.048.576\n\n60.000.000\n\n262.144\n65.536\n\n50.000.000\n\n16.384\n\n40.000.000\n\n4.096\n1.024\n\n30.000.000\n\n256\n\n20.000.000\n\n64\n16\n\n10.000.000\n\n4\n\n0\n\n1\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\n60\n\n70\n\n80\n\n90\n\n100\n\nFraction of shared references\n\nߤ = 3.08%\n\nߪ = 2.11%\n\nܲଶହ = 1.69%\n\nܲହ଴ = 2.38%\n\nܲ଻ହ = 3.70%\n\nFigure 58: Distribution of Relative Bibliographic Coupling Strength (rBC )\n\nIn addition to using Bibliographic Coupling to limit the scope of the analysis,\nwe also wanted to evaluate its usefulness in detecting suspiciously similar,\npotentially plagiarized documents. Since we compare all documents against all\nothers in a n:n comparison, the number of detected similarities requires finding a\nreasonable confinement of documents for manual inspection. To achieve this, we\nconsidered the following two criteria.\n\nA Preliminary PMC OAS Corpus Analysis\n\n269\n\nFirst, we selected the top 10,000 document pairs with the highest ‫ݏ‬஻஼ . To rely\nnot only on absolute counts, we consolidated these documents with the 10,000\ndocument pairs that had the highest ‫ݎ‬஻஼ . In total, 13,911 document pairs fulfilled\none or both criteria. We plotted the selected document pairs according to their\nabsolute and relative BC strength as shown in the scatter plot in Figure 59.\nSelecting the top 10,000 documents for both criteria causes the clear breakup in\nthe data points in both dimensions of the plot.\n‫ݏ‬஻஼ ൒ 25 ᦬ ‫ݎ‬௦ ൒ 65 %\n\n100\n\nFraction of shared references rS in %\n\n90\n80\n70\n60\n50\n40\n30\n20\n10\n\n‫ݏ‬஻஼ ൒ 55\n\n0\n1\n\n4\n\n16\n\n64\n\n256\n\nBibliographic Coupling strength sBC\n\nFigure 59: Document Pairs with High Absolute and Relative BC Strength\n\nExamining the left upper plot area, we can conclude that in an n:n detection\nscenario, an isolated examination of ‫ݎ‬஻஼ is not a valuable similarity indicator for\n‫ݏ‬஻஼ ‫ د‬20. For almost any ‫ݏ‬஻஼ ‫ د‬20 a substantial number of documents exist that\nshare between 60 % and 80 % of their references with other documents.\nFor ‫ݏ‬஻஼ ൑ 8, even 100 % shared references are common. Samples indicated that\ndocuments with ‫ݏ‬஻஼ ൑ 8, but a large ‫ݎ‬஻஼ are typically very short. These short\ndocuments have most of their references in common with much longer\n\n270\n\nAppendix\n\ndocuments. The scatter plot suggests that in the given n:n detection scenario,\nhigh thresholds must be set for ‫ݏ‬஻஼ and ‫ݎ‬஻஼ to limit the document space to a\nnumber that allows manual inspection. We defined three heuristic criteria to\nselect and examine the most similar documents, i.e. the documents lying to the\nupper right of the thresholds, indicated by straight lines in Figure 59. We chose\ndocument pairs with ‫ݏ‬஻஼ ൒ 55 and consolidated them with documents with\nlower absolute BC strengths (‫ݏ‬஻஼ ൒ 25), but higher relative BC strengths\n‫ݎ‬஻஼ ൒ 65.\n322 document pairs matched the selection criteria and were analyzed. We\ndifferentiated between bibliographically coupled documents with authors in\ncommon (277 document pairs) and no authors in common (45 document pairs) to\nidentify potential plagiarism as opposed to duplicate publications. We examined\n10 document pairs that had no authors in common and 30 document pairs with\nauthors in common. The examined samples showed that strongly coupled\ndocuments with authors in common typically fall into these categories:\n-\n\nIdentical text published in different journals, e.g., [192] and [193],\n[196] and [197], or [7] and [8]\n\n-\n\nDuplicates, i.e. the same journal article appeared in PMC multiple\ntimes, e.g., [289] and [290], [287] and [288], or [61] and [62]\n\n-\n\nErrata including a complete new version of a previously published\ntext, e.g., [326] and [327], or [341] and [342]\n\n-\n\nUpdates on prior research using many of the same references, e.g.,\n[180] and [179], [278] and [308], or [211] and [210]\n\nErrata and multiple copies, which are likely erroneous submissions of the\nsame text to PMC®, are clearly unsuspicious. The appropriateness of\nsimultaneous publication of the same article in different journals is casedependent. Duplicate publication can be justified if the goal is reaching a broader\naudience or increasing the dissemination of key findings. If the publication\nmainly serves interests of the author without contributing to the scientific\ncommunity and without acknowledging prior publications in other venues,\n\nA Preliminary PMC OAS Corpus Analysis\n\n271\n\nduplicate publication represents undue behavior. As far as we can judge, the\nlisted examples of updates seem to provide new information, and hence are\nlegitimate examples of highly similar texts.\nMost examined documents that shared no common authors were review\narticles on related or identical topics that shared a significant number of\nreferences. We found no blatant copy &amp; paste plagiarism. Bibliographic\nCoupling does not provide clues as to which of these documents might contain\nsuspiciously similar content. Overall, Bibliographic Coupling provides a rough\nmeasure of document similarity in the given n:n detection setting, in which we\nregard all documents as potentially suspicious and compare them against all\nothers. Bibliographic Coupling can identify identical and highly related\ndocuments that contain a large number of common references.\nWe assume that ‫ݏ‬஻஼ and ‫ݎ‬஻஼ can be more valuable for indicating suspicious\ndocument similarities in a 1:n detection scenario, in which one potentially\nsuspicious document is compared against a genuine reference collection. To\nsubstantiate this assumption, we analyzed the distribution of documents with\n‫ݎ‬஻஼ ൒ 9 %, which we set as a threshold for suspicion, depending on the number\nof documents the respective fraction of references is shared with (see Figure 60).\n\n272\n\nAppendix\n\nRev. cum. frequency of documents\n\n160.000\n140.000\n120.000\n100.000\n80.000\n60.000\n40.000\n20.000\n0\n1\n\n2\n\n4\n\n8\n\n16\n\n32\n\n64\n\n262144\n131072\n65536\n32768\n16384\n8192\n4096\n2048\n1024\n512\n256\n128\n64\n32\n16\n8\n4\n2\n1\n128 256 512 1024 2048 4096 8192\n\nEƵŵďĞƌ\u0003ŽĨ\u0003ĚŽĐ͘\u0003ǁŝƚŚ\u0003ǁŚŝĐŚ\u0003ŝŶĚŝǀ͘\u0003ĚŽĐ͘\u0003ƐŚĂƌĞ\u0003dž\u0003ш\u0003ε\u0003й\u0003ŽĨ\u0003ƚŚĞŝƌ\u0003ƌĞĨĞƌĞŶĐĞƐ\n\nߤ = 19.85 ߪ = 112.03\n\nܲଶହ = 1\n\nܲହ଴ =4\n\nܲ଻ହ =12\n\nFigure 60: Distribution of Documents Sharing ‫ ݎ‬൒ 9 % of References\n\nThe median of the distribution is four; the upper quartile is 12. This means\nthat 50 % of all ‫׽‬168,000 bibliographically coupled documents share 9 % or\nmore of their references with a maximum of four other documents and 75 % do\nso with a maximum of 12 documents. We find it realistic to assume that\nexaminers would be willing and able to manually check four to 12 documents\nwhen told that the amount of reference overlap is uncommon and may point to\nsuspicious similarity. Thus, we assume that in a majority of cases in a 1:n\ndetection setting, ‫ݎ‬஻஼ is a valuable criterion to identify potentially similar\ndocuments in preparation for a manual inspection.\nSimilarly, the number of documents for which an &quot;unusually&quot; high ‫ݏ‬஻஼ exists\nis a more restrictive and thus a more valuable selector in a 1:n detection setting.\nAs previously mentioned, we derived ‫ݏ‬஻஼ = 4 as the threshold for potential\nsuspicion. Figure 61 shows the distribution of documents that are\nbibliographically coupled to other documents with ‫ݏ‬஻஼ ൒ 4. The median is 3, the\nupper quartile 10. In other words, 75 % of bibliographically coupled documents\n\nA Preliminary PMC OAS Corpus Analysis\n\n273\n\nare &quot;strongly&quot; coupled to a maximum of 10 other documents. Again, in a 1:n\ndetection setting, this generally appears to be a reasonable number for manual\ninspection.\n\nRev. cum. frequency of documents\n\n140.000\n120.000\n100.000\n80.000\n60.000\n40.000\n20.000\n0\n1\n\n2\n\n4\n\n8\n\n16\n\n32\n\n64\n\n128\n\n256\n\n512\n\n1024\n\nEƵŵďĞƌ\u0003ŽĨ\u0003ĚŽĐ͘\u0003ƚŽ\u0003ǁŚŝĐŚ\u0003ŝŶĚŝǀ͘\u0003ĚŽĐ͘\u0003ĂƌĞ\u0003ďŝďůŝŽŐƌĂƉŚŝĐĂůůLJ\u0003ĐŽƵƉůĞĚ\u0003ǁŝƚŚ\u0003Ɛ\u0011\u0012\u0003ш\u0003κ\n\nߤ = 11.25 ߪ = 20.95\n\nܲଶହ = 0\n\nܲହ଴ =3\n\nܲ଻ହ =10\n\nFigure 61: Distribution of Documents with BC Strength ൒ 4\n\nA.2 Longest Common Citation Sequence\nThe Longest Common Citation Sequence (LCCS), as described in Section 4.4.2,\nis a detection algorithm, which allows slight transpositions in matching citations\nor skipping over gaps of non-matching citations. The LCCS measures global\ndocument similarity in the form of a single value. To test the detection\ncapabilities of the LCCS approach and to understand the influence of continuity\nand rarity of matching citations in terms of the CF-Score and Cont.-Score, we\nused both scores as the dimensions of a scatter plot.\nCF-Score and Cont.-Score both depend on the pattern length, i.e. the number\nof matching citations, which makes them additive scores. Documents that differ\nfrom the majority of documents with comparable numbers of matching citations\n\n274\n\nAppendix\n\nrepresent notable outliers in one or both dimensions. To prevent scores of\ndocuments with many references from masking outliers obtained from shorter\ndocuments, separately analyzing documents with similar numbers of references\nis a reasonable approach. For the evaluation presented here, however, we did not\nperform this separation, but considered documents with the highest CF-Scores\nand Cont.-Scores, regardless of their number of references.\nTo limit the scope of analysis for evaluating the Longest Common Citation\nSequence, we used a graph-based approach similar to the one employed in the\ncase of Bibliographic Coupling. We selected the 10,000 document pairs with the\nhighest cumulative CF-Scores calculated for citations that are part of the LCCS.\nWe consolidated these document pairs with the 10,000 document pairs scoring\nhighest when considering the maximum of the LCCS length and the associated\nCont.-Score. 15,392 distinct document pairs matched the selection criteria.\nFigure 62 plots these pairs according to the dimensions CF-Score and the\nmaximum of either pattern length or Cont.-Score.\nUsing the scatter plot, we chose thresholds for both dimensions that separated\nthe most dominant outliers. We selected document pairs with CF-Score ൒ 480\nand/or a maximum length or Cont.-Score ൒ 310. We excluded document pairs\nalready examined as part of the Bibliographic Coupling analysis. We retained six\ndocument pairs with authors in common and 49 document pairs with no authors\nin common.\n\nA Preliminary PMC OAS Corpus Analysis\n\n275\n\n2000\n1800\n1600\n\nCF-Score\n\n1400\n1200\n1000\n800\n600\n400\n200\n0\n1\n\n4\n\n16\n\n64\n\n256\n\n1024\n\n4096\n\n16384\n\nMax (length, Cont.-Score)\n\nFigure 62: Document Pairs with High Similarity Scores in the LCCS Assessment\n\nExamining a sample of 15 document pairs from the group with authors in\ncommon yielded:\n-\n\nSix duplicate submissions of the respective journal to PMC.\n\n-\n\nSix updates on prior research. The updates featured Longest\nCommon Citation Sequence scores of 286, 283, 198, 135, 91 and\n88 citations. However, as far as we were able to judge the articles,\nthey presented new findings.\n\n-\n\nThree document pairs appeared to be slightly reworded reports on\nidentical literature reviews submitted to different journals. The\nthree documents pairs [76] and [75], [241] and [240], [90] and\n[162] respectively featured longest common citation sequences of\n218, 178 and 129, a majority of sequences in direct succession\n(without gaps of non-matching citations). Two pairs were\nsubmitted to the respective journals within one month, and another\n\n276\n\nAppendix\n\npair within three months. None of the later documents indicated a\nrelation to the earlier published documents. The appropriateness of\nsuch publications must be judged in context and by expert\nexaminers.\nAmong the six document pairs with no common authors, one document pair\nwas an annually updated medical standard, which mentioned no authors and had\na LCCS of 364. The remaining five document pairs had LCCS lengths ranging\nfrom 26 to 48. The articles were related, but did not show indications of\nplagiarism.\nTo analyze how the number of shared references influences LCCS-based\nsimilarity, we examined the relation of absolute Bibliographic Coupling strength\nto LCCS length. We selected the 10,000 document pairs with the highest LCCS\nand consolidated them with the 10,000 document pairs with the highest ‫ݏ‬஻஼ . We\nomitted documents we had checked as part of prior analysis and created a scatter\nplot with the dimensions absolute Bibliographic Coupling strength and LCCS\nlength (see Figure 63). By visually examining the most prominent outliers, we\ndefined heuristic thresholds for including document pairs in a manual check. We\nselected document pairs if their LCCS had a length of ݈ &gt; 64. We also included\ndocument pairs with shorter LCCS (݈ &gt; 39) if their absolute Bibliographic\nCoupling strength was comparably low (‫ݏ‬஻஼ &lt; 16). 96 documents matched the\nselection criteria, of which 18 had no authors in common, while 68 had authors\nin common.\n\nA Preliminary PMC OAS Corpus Analysis\n\n277\n\nFigure 63: LCCS Length Dependent on Bibliographic Coupling Strength\n\nThe results from checking documents with authors in common were in line\nwith earlier findings. LCCS lengths ranged from 40 to 108. Among the highestscoring document pairs, we identified one duplicate submission to PMC, which\nwas probably erroneous. Furthermore, we found one identical text published in\ntwo journals [206] and [205]. The duplicate publication appeared to be\nsanctioned because it presented a standardized reporting scheme. We also found\nsimilar, yet non-identical, reviews published in different journals, e.g., [10] and\n[9]. The two articles had a LCCS of length ݈ = 91 in this class of articles.\nOf the 18 article pairs with no authors in common, eight were review articles\n(see for example [159] and [182]). The pattern of highly related periodic review\narticles was dominant. The remaining article pairs were highly related research\npapers in very specific areas of research. One example of such a document pair is\n[242] and [115], which both discuss nucleotide distributions in the DNA of\nspecific cell cultures and have a LCCS of 50. We did not find indications for\nplagiarism in these articles.\n\n278\n\nAppendix\n\nWe conclude that analyzing the LCCS is a reliable approach for limiting the\nretrieval space of potential candidate documents, especially in cases where\ndomain experts perform a 1:n analysis. Further research into the correlations\nbetween Bibliographic Coupling strength and Longest Common Citation\nSequences seems beneficial before setting a specific suspiciousness threshold for\nthe number of references in common. Once established, such thresholds are a\nstrong similarity indicator, especially in a 1:n detection scenario. Both\nBibliographic Coupling and the LCCS yielded recurring patterns for articles with\nauthors in common. Such articles tended to be highly related updates on prior\nresearch or publications of identical or similar texts in different journals. Both\napproaches are able to identify high levels of global document similarity\naccurately, especially in a 1:n detection scenario. In our subsequent\ninvestigations, we focused on local document similarity and considered only\ndocuments sharing no common authors.\n\nA.3 Greedy Citation Tiling\nGreedy Citation Tiling (GCT) , as described in Section 4.4.3, identifies all\nlongest substrings of matching citations, so-called citation tiles, within the\ncitation sequences of two documents. Citation tiles are composed solely of\nmatching citations in identical order. To gain an understanding of the document\nsimilarities that lead to high scores in a GCT analysis, we reduced the number of\ndocuments to the ones most similar. To achieve this reduction, we analyzed the\ndistribution of citation tile lengths in order to set a suitable threshold. Given the\ndistribution (see Figure 64), we disregarded all documents that did not contain at\nleast one citation tile of length three.\nWe also wished to estimate the selective power of the chosen similarity\nthreshold in a 1:n detection setting. For this purpose, we analyzed the\ndistribution of documents sharing citation tiles of length three or more with other\ndocuments depending on the number of documents the tiles were shared with\n(see Figure 65). The upper quartile of the distribution is two. In other words,\n75 % of documents that share a citation tile of length three or more do so with a\nmaximum of two other documents. Therefore, we assume that citation tiles of\n\nA Preliminary PMC OAS Corpus Analysis\n\n279\n\n4.194.304\n\nNumber of document pairs\n\n1.048.576\n262.144\n65.536\n16.384\n4.096\n1.024\n256\n64\n16\n4\n1\n0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50\n\nMaximum tile length in document\n\nߤ = 1.23 ߪ = 0.55\n\nܲଶହ = 1\n\nܲହ଴ =1\n\nܲ଻ହ =1\n\nRev. cum. freq. of doc. contaiing citation tiles\nwith length lш\u00033\n\nFigure 64: Distribution of Maximum Citation Tile Lengths\n30.000\n25.000\n20.000\n15.000\n10.000\n5.000\n0\n1\n\n2\n\n4\n\n8\n\n16\n\n32\n\nNo. of documents sharing a citation tile of length l ш\u00033\n\nߤ = 2.39 ߪ = 3.69\n\nܲଶହ = 1\n\nܲହ଴ =1\n\nܲ଻ହ =2\n\nFigure 65: Distribution of Documents with Citation Tiles of Length ݈ ൒ 3\n\n64\n\n280\n\nAppendix\n\nlength three or more might be a good indicator of potentially suspicious\ndocument similarity in a 1:n detection setting.\n\nSum of CF-Scores for tiles in a document\n\n4.096\n2.048\n\n‫ܨܥ‬оܵܿ‫ ݁ݎ݋‬൒ 815\n\n1.024\n512\n256\n128\n64\n32\n16\n8\n\n݈ ൒ 40\n\n4\n2\n1\n1\n\n2\n\n4\n\n8\n\n16\n\n32\n\n64\n\n128\n\n256\n\n512\n\n6XP\u0003RI\u0003WLOH\u0003OHQJWKV\u000f\u0003O\u000f\u0003IRU\u0003WLOHV\u0003ZLWK\u0003O\u0014\n\nFigure 66: Document Pairs with Highest Similarity Scores in GCT Assessment\n\nTo select the most suspicious documents for manual inspection, we followed\na similar scatter plot approach as in the case of the other approaches analyzed\nearlier. We plotted the sum of citation tile lengths and the cumulative CF-Score\nfor all tiles in the 10,000 documents that contained at least one tile of length\nthree and scored highest in either of the two dimensions (see Figure 66). To\navoid intrinsically replicating a de-facto Bibliographic Coupling assessment, we\nonly included tiles with a length of ݈ &gt; 1 in the cumulated length score. As\nreported earlier, the average tile length is 1.23 (see Figure 64), thus excluding\ntiles with ݈ ൑ 1 from the cumulated length score increases the selective power of\nthe score. Using heuristic visual outlier detection, we set a summed CF-Score ൒\n815 and/or a summed tile length ݈ ൒ 40 as thresholds. After removing\npreviously analyzed documents, 153 distinct documents remained, of which\neight document pairs had no authors in common.\n\nA Preliminary PMC OAS Corpus Analysis\n\n281\n\nSix of these article pairs were reviews, one article pair was a periodically\nrepublished medical standard and another was a related research paper. All\narticles listed consecutive prior studies. The following table shows a typical\nexample of a text excerpt with long citation tiles taken from two review articles\nwritten by different authors. The publishing dates of both articles are apart by ‫׽‬4\nyears. The references 111 to 119 in [121] and 64 to 72 in [343] refer to the same\nsources in identical order. We were able to identify similar examples using the\nLCCS and to a lesser extent using Bibliographic Coupling.\n\n282\n\nAppendix\nTable 25: In-text Citation Tile (Example 1)\nText excerpt from [121]\n\nText excerpt from [343]\n\n“Following entry to the brain,\nmonocytes, lymphocytes, activated\nmacrophage, microglia and astrocytes\nrelease cytokines, reactive oxygen\nspecies, and other neurotoxins that\ndisrupt normal cellular functioning,\nmodify neurotransmitter action, and may\nlead to leukoencephalopathy and\nultimately neuronal apoptosis [111,112].\nSome of these neurotoxins include\nTNF-α, arachidonic acid, platelet\nactivating factors (PAF), nitric oxide\n(NO), and quinolinic acid (QUIN). NO\nis synthesized by endothelial cells,\nmacrophages and neurons and might be\nassociated with the NMDA type\nglutamate associated neurotoxicity. A\nhigh level of inducible NO synthase has\nbeen found in the brain of HAD patients\n[113]. In HIV-1 patients who also\nare/were drug addicted (e.g. cocaine,\nheroine), a 40-fold increase in\nexpression of NO synthase in neurons of\ntemporal lobes was reported [114].\nTNF-α is released by HIV-1 infected\nmacrophage microglia and particularly\naffects oligodendrocytes [115]. It has\nbeen shown that TNF-α mRNA level in\nthe subcortical regions of HAD patients&#x27;\nCNS are higher than in AIDS patients\nwithout neurological symptoms [116]. In\naddition, TNF-α can damage the BBB,\n\n“This may cause alterations in\nneurotransmitter action and causes\nleukoencephalopathy\nresulting\nin\nneuronal\napoptosis.[64,65]\nTNF-α,\nplatelet activating factor (PAF), nitric\noxide (NO), and quinolinic acid (QUIN)\nalso behave like neurotoxicant and cause\nneurotoxicity. NO is produced by\nmicrovascular\nendothelial\ncells,\nmacrophages, and neurons which may\nresult in N-methyl-D-aspartate (NMDA)\ntype glutamate-associated neurotoxicity.\nElevated levels of NO synthase has been\nreported in the brain of HAD patients,\nwhile a 40-fold increase in expression of\nNO synthase in neurons of drug addict\nHIV patients.[66,67] TNF-α is produced\nby macrophages and microglia and it\nmainly affects oligodendrocytes.[68] An\nelevated level of TNF-α mRNA has been\nreported in HIV patients with\nneurological complications.[69] TNF-α\ncauses damage to BBB and facilitates\nentry of peripheral blood cells.[70]\nPro-inflammatory cytokines like TNF-α,\nIL-1, and IFN-α are found to be present\nin\nelevated\nlevel\nin\nAIDS\npatients.[71,72]”\n\nA Preliminary PMC OAS Corpus Analysis\n\n283\n\nas shown in an in-vivo model, which\ncould facilitate entry into the brain of\nHIV-1 protein(s) and cytokines secreted\nin the periphery [117]. Not only the level\nof pro-inflammatory cytokines, such as\nTNF-Į\u000f\u0003\n,/-1\nand\nIFN-Ȗ\u000f\u0003\nanti-inflammatory cytokines including\nTGF-ȕ\u0003 DQG\u0003 ,/-6, and soluble cytokine\nreceptors is elevated in AIDS patients,\nbut the cytokine production is correlated\nwith the gravity of the neuropathology\n[118,119].”\n\nWe also found empirical examples that citation tiles of length three or more\nhave a high predictive value for local document similarity. We randomly selected\nthe following two text excerpts from article pairs that shared exactly one citation\ntile of length three (and potentially additional citations, but for the given\nselection, no other matching pattern was allowed to be longer than two).\n\n284\n\nAppendix\nTable 26: In-text Citation Tile (Example 2)\nText excerpt from ([138], p.1)\n\nText excerpt from ([37], p. 90)\n\n“In RA, RF is detected in 70-80 % of\npatients with established disease, and is\nan integral part of the definition of this\ndisorder. AKA, APF, AFA, and anti-Sa\nhave all been shown to be associated\nwith RA, and appear to be more specific\n\n“Vincent et al. [48] could detect AFA in\n41 % of RA sera with 99 % specificity.\nWhen combining the AFA immunoblot\nassay with AKA testing, a much higher\nsensitivity (64 %), without loss of\nspecificity, could be achieved [48].\nHowever, the sensitivity of the assay\nappears to be dependent on the method\nfor purification of the filaggrin. Slack et\nal. calculated sensitivities of 12 and\n16 for\ntwo\ndifferent\nfilaggrin preparations, while only one of\nfive positive sera reacted with\nboth preparations [49]. The AFA-ELISA\nis somewhat more sensitive (47–54 %)\nthan the immunoblot assay [50,51] ...”\n\nthan\nRF\nfor\n[1,2,3,4,5,6,7,8,9].”\n\nthis\n\ndisease\n\nIn [138] and [37] the citations 3–5 and 48–50 represent references to identical\nsources in matching order. Aside from this tile of length three, the articles share\n20 other single citations. Both paragraphs and the articles as a whole discuss\nauto-antibodies related to rheumatic diseases. The articles are clearly not a\nplagiarism, but are semantically highly related. The article [37] shares a citation\ntile of length three only with the article [138]. The article [138] shares citation\ntiles of length three with two other documents.\n\nA Preliminary PMC OAS Corpus Analysis\n\n285\n\nTable 27: In-text Citation Tile (Example 3)\nText excerpt from\n([372], p. 216)\n\nText excerpt from\n([47], p. 73)\n\n“In RA, RF is detected in 70–80 % of\npatients with established disease, and is\nan integral part of the definition of this\ndisorder. AKA, APF, AFA, and anti-Sa\nhave all been shown to be associated\nwith RA, and appear to be more specific\nthan\nRF\nfor\nthis\ndisease\n[1,2,3,4,5,6,7,8,9].” “In contrast to the\ngrowth inhibitory effects of TGF β1 in\nthe early stages of carcinogenesis, TGF\nβ1 can also act as a promoter of tumor\ncell invasion and metastasis in the later\nstages of tumorigenesis [5,6]. Increased\nproduction of TGF β1 is observed in\nepidermal [35], gastric [36], renal [37],\nbreast [38 41], and prostate carcinomas\n[42] when compared with normal\ntissues.”\n\n“There is considerable evidence to\nsuggest that, at late stages in\ntumorigenesis, TGF βs can actually\npromote the tumorigenic process,\nparticularly if the epithelial cells have\nlost responsiveness to the growth\nregulatory effects of TGF β by this time\n[9,39,40,41]. Thus, advanced human\ntumors show increased levels of TGF β\nexpression [42,43,44], and TGF βs are\nknown\nto\nsuppress\nthe\nimmunosurveillance system, to enhance\nangiogenesis, invasion and metastasis,\nand to increase drug resistance\n[45,46,47,48].”\n\nIn [372] and [47] the citations 39 to 41 and 42 to 44 represent references to\nidentical sources in matching order. Aside from the tile of length three, the\ndocuments share two other single citations. None of the documents shares a tile\nof length three or more with any other articles. The paragraphs of both articles\ndescribe the effect of a tumor growth factor in early and later stages of cancer.\nBoth articles are not a plagiarism, but the relatedness of the paragraph is evident.\nThese examples show that citation tiles of length three or more are highly\npredictive indicators for legitimate or potentially illegitimate local content\nsimilarity. Identifying legitimate, yet highly similar text segments can, for\nexample, be used to improve academic literature recommender systems. Thus,\n\n286\n\nAppendix\n\nthe GCT approach can be valuable to improve general information retrieval and\nparticular plagiarism detection systems. As the empirical examples show, GCT\ncan identify highly related text segments that differ significantly in wording.\nHowever, due to its exact matching approach, GCT fails when shared citations\nare scaled or their order is transposed.\n\nA.4 Citation Chunking\nFor a first test of Citation Chunking (Cit-Chunk), we evaluated the variation of\nCitation Chunking that splits up both documents into chunks and includes\ncitations in chunks dependent on the previous shared citations (see Section 4.4.4\nfor details). The algorithm adds a shared citation to a chunk if n non-matching\ncitations, where ݊ ൑ 1 or 1 &gt; ݊ ൑ ‫ݏ‬, separate it from the last preceding\nmatching citation. The variable s equals the number of citations in the chunk\nunder construction. Once the algorithm has chunked both documents, it\ncompares each chunk of one document to each chunk of the other document\nregardless of the order of citations.\nAs in the case of the other similarity measures in our experiments, we had to\nlimit the large number of documents with matching citation chunks to allow for a\nmore detailed analysis. To define a suitable exclusion threshold for documents,\nwe analyzed the distribution of maximum chunk lengths (see Figure 67).\n\nA Preliminary PMC OAS Corpus Analysis\n\n287\n\n1.048.576\n\nNumber of document pairs\n\n262.144\n65.536\n16.384\n4.096\n1.024\n256\n64\n16\n4\n1\n1\n\n2\n\n4\n\n8\n\n16\n\n32\n\n64\n\n128\n\n256\n\n512\n\n1024\n\nMaximum chunk length in document\n\nߤ = 2.08 ߪ = 3.20\n\nܲଶହ = 1\n\nܲହ଴ =1\n\nܲ଻ହ = 2\n\nFigure 67: Distribution of Maximum Chunk Lengths\n\nThe distribution shows that Citation Chunking, on average, yielded longer\nmaximum patterns than Greedy Citation Tiling (see the distribution of maximum\ncitation tile lengths in Figure 64, page 279, for a comparison). In addition, the\nnumber of document pairs that shared a maximum pattern of specified length\ndecreased more slowly in the case of Citation Chunking than in the case of GCT.\nFurthermore, the overall number of identified citation chunks, ‫׽‬3.5 million, was\nlower than the number of identified citation tiles, ‫׽‬12.4 million. These\ncharacteristics indicate that Citation Chunking includes more matching citations\ninto patterns than the GCT approach, which represents the expected behavior.\nThe results also support the assumption that the number of text segments\ncontaining matching citations in close proximity, yet not necessarily in the same\norder, is significantly higher than that of text segments with perfectly matching\ncitation tiles.\nFigure 67 shows that the number of documents with long citation chunks was\nsignificantly higher than the number of documents with long citation tiles, which\n\n288\n\nAppendix\n\nindicates a negative characteristic of Citation Chunking. The tested chunking\nalgorithm allows an increasing number of non-matching citations to be included\nin the pattern if a higher number of matching citations is already included in the\nchunk under construction. This characteristic negatively affects documents that\nshare many references and citations, because in such a case the chunking\nalgorithm tends to form a small number of very long chunks. Approximately 10\nmillion document pairs in the PMC OAS shared ‫ ݎ‬൒ 64 references, refer to\nBibliographic Coupling in A.1. Thus, the effect likely afflicts a large portion of\nthe corpus. The effect was especially strong for review articles, because they\noften share up to several hundred references with other articles.\nGiven the distribution of documents in Figure 67, we excluded document\npairs from the assessment that did not share at least one citation chunk of length\nfour or greater. This limited the number of documents to approximately 143,000.\nWe also examined the usefulness of this threshold in regard to an &quot;average case&quot;\n1:n detection scenario. For this purpose, we analyzed the distribution of\ndocuments sharing citation chunks of length ݈ ൒ 4 depending on the number of\ndocuments that shared the respective patterns. Figure 68 shows the\ncorresponding plot, which indicates that a citation chunk of length four is not as\nselective as a citation tile of length three (compare this to the distribution of\ncitation tiles in Figure 65, page 279).\n\nA Preliminary PMC OAS Corpus Analysis\n\n289\n\nRev. cum. freq. of doc. containing citation chunks\nof length lш4\n\n80.000\n70.000\n60.000\n50.000\n40.000\n30.000\n20.000\n10.000\n0\n1\n\n2\n\n4\n\n8\n\n16\n\n32\n\n64\n\n128\n\n256\n\nNo. of doc. a citation chunk of length lш4 is shared with\n\nߤ = 4.95 ߪ = 9.32\n\nܲଶହ = 1\n\nܲହ଴ =2\n\nܲ଻ହ =5\n\nFigure 68: Distribution of Documents sharing a Cit. Chunk Length of l &gt;= 4\n\nNonetheless, setting the minimum chunk length to four caused the upper\nquartile of the distribution in Figure 68 to equal five. Thus, 75 % of documents\nin the corpus that shared citation chunks of length four or more did so with a\nmaximum of five other documents. To further confine the sub-collection to be\nanalyzed, we employed a similar graph-based approach as for the other similarity\nmeasures. We used the sum of CF-Scores and the maximum of the Cont.-Score\nor chunk length as the dimensions of a scatter plot. To avoid replicating a\nde-facto Bibliographic Coupling analysis (the majority of citation chunks have a\nlength of one) we only considered the Cont.-Score or the length of chunks with\nlength ݈ &gt; 1 for inclusion in the graph. We selected the 10,000 documents that\nmet the selection criteria and featured the highest scores in either of the two\ndimensions. Figure 69 shows the resulting scatter plot.\n\n290\n\nAppendix\n\nFigure 69: Document Pairs Yielding High Similarity Scores Using Cit-Chunk\n\nConsistent with the evaluations of the similarity functions presented earlier,\nwe visually selected outliers as indicated in Figure 69. The analysis of maximum\nchunk length had already indicated that Citation Chunking is prone to degenerate\ninto a de-facto global similarity measure for documents sharing many references.\nManually inspecting the highest scoring documents verified this expected result.\nA total of 128 document pairs matched the selection criteria, of which 47 had no\nauthors in common. The large majority of these documents were review articles,\nwhich we already covered in the description of prior similarity functions. While\nCitation Chunking is able to identify such highly related documents, the measure\ndid not provide a significant benefit over the LCCS approach.\nFor documents with many shared references, citation chunks tend to become\nso large that a majority of a document’s citations are included in a chunk. For\ninstance, the highest scoring document in the assessment yielded a citation chunk\nlength of 139. We assume that such high similarities would also be detected\nusing the Bibliographic Coupling or LCCS approach.\n\nA Preliminary PMC OAS Corpus Analysis\n\n291\n\nThe strength of Citation Chunking lies in its ability to pinpoint specific local\nsimilarities. To illustrate this capacity, we analyzed the portion of selected\ndocuments with the shortest lengths (l &lt; 16 as indicated in Figure 69), but a high\nCF-Score. Consider the following example from the group of documents with\nshorter citation chunks, but a high CF-Score. The two documents [141] and\n[345] share a single citation chunk of length four, consisting of four citations of\ntwo distinct references that are repeated to outline various facts. Because the\nmatching citations are transposed, we state alphanumeric keys formed of first\nauthor name and publication year in bold type in addition to the original numeric\ncitations given in the texts. The two texts were not cases of plagiarism, but\nclearly related. As mentioned previously, the average specificity of citation\nchunks is not as high as that of citation tiles. For instance, the article [141]\nshared citation chunks of length four or more with eight additional documents,\nwhile the article [345] shared citations with the indicated document only.\n\n292\n\nAppendix\nTable 28: In-text Citation Chunk Example\nText excerpt from ([141], p. 228)\n\n“[...] recent findings that challenge the\ndogma that metastases arise from\na relatively small population of cells\nwithin a tumor that have a particularly\nhigh metastatic potential. Rather,\nmicroarray\nstudies\ncomparing\nmetastatic\nand\nnon-metastatic adenocarcinomas\nidentified a molecular signature\ncorrelating with metastasis, and\nsuggested that the bulk of cells within\nthe tumor share this signature, and thus\nthe metastatic potential is encoded\nwithin the bulk of the primary tumor\n[13 |Ramaswarmy03|]. This signature,\ndefined as 17 differentially regulated\ngenes, correlated with metastatic\npotential in solid tumors from a variety\nof organs, supporting the concept of a\ncommon pathway towards metastasis,\n\nText excerpt from ([345], p. 1)\n“According to the traditional model of\nmetastasis, the potential to metastasize\nresides in a small subset of tumor cells that\nhave acquired this property through a set of\nmutations that occur during the later stages\nof tumor progression [11]. An emerging\nconcept has recently challenged this existing\nmodel of metastasis by demonstrating that\nthe potential to metastasize is encoded in the\nbulk of the tumor and is present early in\ntumor\npathogenesis\n[11,\n12 |van’tVeer02| 13 |Ramaswarmy03|,\n14].”\n\nand suggesting the existence of\ncommon therapeutic targets in\ndifferent cancers. Gene-expression\nprofiling has also been reported to be\nuseful for predicting the clinical\noutcome of breast cancer [14\n|van’tVeer02|]”.\n\nIn summary, we found that a chunk length of three to four is sufficient in\nmost cases to predict local text similarity with high accuracy. Citation Chunking\nis most valuable for texts that share smaller or average numbers of citations. The\n\nA Preliminary PMC OAS Corpus Analysis\n\n293\n\napproach is also capable of highlighting highly related texts with numerous\ncitations in very close proximity, which is common in review articles. However,\nif documents share many references overall, the algorithm begins to lose its most\nvaluable feature of highlighting the specific areas of highest similarity. The\nalgorithm treats citation chunks like a bucket. Once this bucket gets too large,\nand potentially contains many non-matching citations, a manual analysis\nbecomes cumbersome.\n\nA.5 Character-based PDS Sherlock\nTo compare the CbPD detection performance to a character-based PDS, we also\nanalyzed parts of the PMC OAS with the plagiarism detector Sherlock developed\nat the University of Sydney [184]. We chose Sherlock as a baseline approach for\nthe following reasons:\n-\n\nSherlock offers a fingerprinting detection approach, which is\nrepresentative for most currently available PDS. Sherlock employs\nword-based text chunking and a probabilistic selection strategy for\ncomputing each document’s fingerprint.\n\n-\n\nSherlock allows customizing the length of chunks and the probability\nof retaining chunks during the selection step. By default, Sherlock\npartitions the input texts into chunks of three words, selects on\naverage one out of 16 chunks formed and discards the rest. For our\nexperiment, we increased the probability of retaining chunks to one\nout of eight on average to perform a finer-grained comparison.\nSherlock reports the document similarities identified as a percentage\ncalculated as: ‫= ݉݅ݏ‬\n\nଵ଴଴௟ೞ\n௟ವభ ା ௟ವమ ି ௟ೞ\n\nwhere ݈௦ is the length of passages\n\nidentified as similar in both documents and ݈஽ଵ and ݈஽ଶ denote the\noverall length of the two documents.\n-\n\nSherlock is a lightweight open source C program, which we could\neasily adapt to the requirements of the evaluation. While most other\navailable PDS are closed source or limit the number of analyzable\n\n294\n\nAppendix\n\ndocuments, Sherlock does not enforce a limit on analyzable\ndocuments.\nThe required computational effort prohibited the use of Sherlock to analyze\nthe entire test collection derived from the PMC OAS (185,170 documents) in an\nn:n\n\nanalysis\n\n(17,143,871,865\n\ncomparisons).\n\nRefer\n\nto\n\nComparison of Computational Efficiency, page 176, for more details.\n\nA.6 Character-based PDS Encoplot\nTo compare the detection performance of CbPD to more than one\ncharacter-based PDS, we additionally analyzed documents from the PMC OAS\nwith Encoplot, a PDS developed by Grozea et al. [143]. We chose Encoplot as a\nbaseline approach for the following reasons:\n-\n\nThe system is a state-of-the-art research prototype. Encoplot won the\nPAN comparison of PDS in 2009 and constantly ranged among the\nbest-performing PDS in subsequent PAN comparisons [260, 261,\n264].\n\n-\n\nEncoplot employs elaborate n-gram string matching for an n:n\ncomparison of documents, i.e. the system compares each document to\nevery other document in the collection. During each comparison of a\ndocument pair, the system matches all unique character n-gram pairs\nin the two documents. This approach guarantees high detection\naccuracy for literal text matches. The system extracts all character ngrams of length 16 from two documents under comparison into two\nseparate lists, sorts the lists of n-grams, and uses a modified merge\nsort algorithm to identify matching n-grams. A limitation of\nEncoplot’s detection algorithm is that it matches the first occurrence\nof an n-gram in one document to the first occurrence of that n-gram in\nthe second document, the second occurrence to the second and so on.\nIf the number of n-gram occurrences in the documents is different,\nEncoplot does not identify all possible matches. For example, if\nDocument 1 contains the n-gram &quot;abc&quot; twice and Document 2\n\nA Preliminary PMC OAS Corpus Analysis\n\n295\n\ncontains &quot;abc&quot; four times, Encoplot only matches the first two\noccurrences of “abc” in Document 2 to the two occurrences of &quot;abc&quot;\nin Document 1.\n-\n\nEncoplot is optimized for speed and offers a worst case performance\nof O(n).\n\nDespite Encoplot’s efficiency, an n:n comparison of the 185,170 documents\nin the PMC OAS test collection would still require 17,143,871,865 comparisons,\nas in the case of Sherlock. The processing time required by Encoplot to perform\nthese comparisons is just as infeasible as an n:n comparison using Sherlock.\nRefer to Comparison of Computational Efficiency, page 176, for details.\n\nB\n\nTechnical Details of the CitePlag Prototype\n\nSection B.1 describes the implementation of the sentence-word-tagger and\nSection B.2 describes the data parser, two subcomponents of the CitePlag\nprototype. Section B.3 presents the procedure for the consolidation of reference\nidentifiers in the PMC OAS.\n\nB.1 Sentence-Word-Tagger (SW-Tagger)\nThe SW-Tagger identifies individual sentences and words in NXML texts and\nmarks them with delimiters that do not impair the validity of the original XML\nmarkup. Identifying parts of speech (POS) is a common task in the field of\nNatural Language Processing (NLP). The ambiguity of natural language makes\naccurately identifying POS challenging. One example of a highly ambiguous\ngrapheme in natural language is the period. Aside from indicating the conclusion\nof a sentence, a period can also be a decimal point, or a delimiter within an email\naddress.\nThe peculiarities of life science texts pose additional challenges to POS\nidentification and force researchers to adjust POS taggers specifically for this\nfield to achieve good POS detection performance. Articles in the life sciences\nfrequently refer to chemical substances, abbreviations, or other domain-specific\nentities that are difficult to match to ordinary sentence structures. Due to the\nchallenges of identifying POS in life science texts, we incorporated an existing\nPOS tagger into the CitePlag document parser to detect sentence boundaries.\nExisting and potentially suitable POS taggers for the life sciences include\nOpenNLP, dTagger, SPToolkit and Stanford Core NLP [52, 91, 256, 314]. We\nevaluated OpenNLP [14] in combination with the extensions for POS tagging in\nlife sciences proposed by Buyko et al. [52], Stanford CoreNLP [314], and\nSPToolkit [256] on their suitability for integration into the CitePlag document\nparser. For each of the three tools, we manually inspected five annotated\ndocuments. Although the test was too small to be statistically significant, the\nresults of all tools were in line with results reported in earlier studies [52, 256].\n\nB Technical Details of the CitePlag Prototype\n\n297\n\nAll three tools achieved precision and recall values of ‫׽‬99 % for word and\nsentence boundary detection.\nIn terms of processing time per document, SPToolkit, which required ‫׽‬30ms,\nwas superior to OpenNLP and Stanford CoreNLP, which both required ‫׽‬1.5s.\nWe attribute this difference in runtime to the complexity of the different\ndetection approaches the systems employ. SPToolkit relies on comparably less\ncomplicated heuristic rule sets, while OpenNLP and Stanford CoreNLP use\nsophisticated machine-learning procedures.\nAnother advantage of SPToolkit over OpenNLP and Stanford CoreNLP is\nthat the output format of SPToolkit’s sentence detector is easier to integrate with\nthe other sub-components of the document parser than that of OpenNLP or\nStanford CoreNLP. SPToolkit provides its output as a plain Java string object\nthat is universally usable. OpenNLP or Stanford CoreNLP discard the original\nXML markup and create individually formatted output files. This tagging\nbehavior would require changes to the tools’ source codes to produce an output\nthat includes sentence and word markup in addition to the original XML tags.\nGiven the test results, we incorporated SPToolkit into the CitePlag document\nparser. All three of the tools tested showed nearly identical precision and recall\nin sentence detection, yet SPToolkit offered both better runtime performance and\na favorable output format. By default, SPToolkit is not able to process XML\ntexts. Therefore, the SW-Tagger substitutes all XML tags in the original\ndocuments with unique placeholder strings of the form Z\\*§running no./§ and\nstores the tag content in an index for later reinsertion. After the substitution, the\nSW-Tagger runs the sentence detection procedures of SPToolkit.\nSPToolkit does not feature word boundary detection. To avoid using a\nruntime-intensive POS tagger based on machine learning, we adapted and\nincorporated word markup heuristics commonly found in similar POS tools into\nthe SW-Tagger. The SW-Tagger marks up word boundaries with plain text\nannotations similar to the ones employed for tagging sentences. These\nannotations do not interfere with the original XML markup. The SW-Tagger\nrestores the original markup after the detection of sentences and words by re-\n\n298\n\nAppendix\n\nsubstituting the inserted placeholder strings with the original tag content from the\nstored index.\nThe algorithm uses regular expressions in JavaTM and was designed for use\nafter a separate tagger, in our case SentParDetector [256], has identified sentence\nboundaries. The output of the sentence tagger has to list each sentence in a\nseparate line and mark the beginning of a sentence with a specific character\nsequence. In the given case, the SW-Tagger replaces the XML style markups\nproduced by SentParDetector and all original XML markups with the following\ncharacter sequences prior to the word boundary detection:\n*§S/§ denotes the beginning of a sentence.\n_Z*§000/§ denotes an individual XML tag, which the SW-Tagger replaced\nwith this placeholder string. The numbering 000 corresponds to an individual\nunique ascending number for each tag in the document. This way, the SWTagger can reinsert the original tags after the sentence and word markup process\nto retain the original document structure information.\nThe SW-Tagger uses the following regular expression, which includes\nalternative tests for two main patterns. We list the entire expression in multiple\nsub-expressions to comment on the sub-patterns these sub-expressions match.\nThe first main pattern, which the regular expression searches for, represents\nwords separated by one or multiple whitespaces.\nTo identify such patterns, the SW-Tagger uses the following sub-expression\nto search for the last alphanumeric character in a character sequence that is not\npart of a markup substitution mentioned above:\n“(?:(?:[a-zA-Z0-9](?!\\\\w|/§|([\\\\.,]?[0-9]+?)))”+\nNote that the SW-Tagger treats numeric expressions or abbreviations as words.\nWhile we consider this behavior reasonable for CbPD, it might not be desirable\nfor other applications.\nThe following sub-expression allows any non-alphanumeric character, except\nfor white spaces or characters that are part of a markup substitution, to follow the\nfirst sub-pattern of pattern 1.\n\nB Technical Details of the CitePlag Prototype\n\n299\n\n“(?:[^\\\\w\\\\s]|(?:[S0-9]+(?=/§)))*”+\nThis sub-expression causes the SW-Tagger to ignore, e.g., punctuation marks or\nbrackets between words. The next sub-expression tests for a white-space\ncharacter, which is mandatory in order to match pattern 1.\n“(?:\\\\s)”+\nAny non-alphanumeric character, except for whitespaces and characters that are\npart of a markup substitution, can follow the whitespace. This sub-expression\nallows additional punctuation marks, brackets and similar characters before the\nnext word starts.\n“(?:[^\\\\w]|(?:S/§)|(?:[0-9]+(?=/§)))*”+\nThe last sub-expression belonging to the test for pattern 1 searches for an\nalphanumeric character that is not part of a markup substitution. If the SWTagger finds such a character, it assumes the beginning of a new word.\n“(?:[a-zA-Z0-9](?!/§)))”+\nIf the SW-Tagger fails to match the first main pattern, it checks for a second one,\nwhich represents words that are separated by an XML tag, but no whitespaces.\n“|”+\nThe SW-Tagger attempts to match the second pattern by looking for the last\nalphanumeric character in a sequence (word or numeric expression) that is not\npart of a markup substitution, but directly followed by a markup substitution.\n“(?:(?:[a-zA-Z0-9](?!(?:\\\\w)|(?:/§)|(?:[\\\\.,]?\n[0-9]+?))[,\\\\.;\\\\?!\\&quot;&#x27;\\\\=/:&amp;+\\\\-\\\\$%°]*(?=\\\\*§[0-9]+/§\n))” +\nNon-alphanumeric characters, markup substitutions or a sentence markup can\nfollow the first sub-pattern of pattern 2.\n“(?:[^\\\\w]|(?:S/§)|(?:[0-9]+(?=/§)))*”+\nThis sub-expression causes the SW-Tagger to ignore punctuation marks,\nbrackets or sentence boundaries between words. The end of the second main\n\n300\n\nAppendix\n\npattern must be an alphanumeric character that is not part of a markup\nsubstitution.\n“(?:[a-zA-Z0-9](?!(?:/§))))”\nTo check the quality of the SW-Tagger’s markup procedure, we randomly\nsampled four documents from four journals and inspected the markup for three\nparagraphs in each document. For words, we found 2,092 correctly identified\ninstances, six incorrect separations and no misses. Five of the six errors\noriginated from one document that states the names of places and tribes in native\nAfrican languages. These words contained unusual combinations of diacritics\nand hyphens that caused the word split-up heuristics to fail. The SW-Tagger’s\nword markup procedure achieved a precision of 99 % and a recall of 100 %. The\ndetection for sentences was error-free in the sample. Overall, we are confident\nthat the SW-Tagger’s markup procedure is highly accurate.\n\nB.2 Data Parser\nThe data parser extracts all information necessary for a CbPD analysis from\nNXML texts. This task requires evaluating the original XML markup and the\nplain text markup for sentences and words that the SW-Tagger introduced to the\ndocuments during the pre-processing step. We implemented the data parser\naccording to the Simple API for XML (SAX) [272]. SAX allows easy extraction\nof citation positions compared to other APIs for XML parsing and offers high\nprocessing speed ([347], p. 36).\nSAX follows a push approach for accessing data in XML documents. This\nmeans a parser implementing the SAX API reads and triggers (i.e. &quot;pushes&quot;) a\nnotification when it detects one of five predefined events. Encountering the start\nor end tag of the whole document or arbitrary elements represents one event\neach, thus totaling four events. The fifth event is the encountering of literal\ncharacter data. Only the application that invokes the SAX parser defines\nreactions for events that the SAX parser reports. For this purpose, the invoking\napplication must provide callback handlers to the SAX parser. These handlers\ncontain and execute programming logic dependent on the event they receive\nfrom the SAX parser.\n\nB Technical Details of the CitePlag Prototype\n\n301\n\nThe content handler is the callback handler of the data parser that extracts\ndocument metadata, citations, and references. For most data elements, such as\ndocument IDs, author names, and references, this extraction is straightforward.\nLikewise, citations are easy to parse when the respective NXML text contains\nindividual tags for every citation.\nHowever, some texts state several citations in an abbreviated fashion, for\nexample, “[3 – 8]” without offering XML markup for all citations in the range.\nTo recognize these notations, we implemented an additional check to see if\ncitations occur within a range of 13 or less characters. We chose thirteen\ncharacters by assuming that a notation similar to this: “[110] – [115]” is the\nlikely maximum length of an abbreviated citation range. If citations occur within\nthe 13-character-interval, the content handler uses regular expressions to check\nwhether the literal character data between the citation tags actually represents a\ncitation range.\nTo keep track of sentence and word counts, we adapted the method of the\ncallback handler that reacts to event notifications for literal character data. We\nuse regular expressions to recognize the sentence and word markup introduced in\nthe pre-processing step. After gathering all data for an element, for example a\ncitation, the content handler submits the element to the database.\nIn order to analyze research papers, while ignoring additional content in\nPMC, including editorial letters, book reviews, etc., we selected only those\ndocuments in the PMC OAS of the following types: &quot;research-article&quot;, &quot;reviewarticle&quot;, &quot;case-report&quot;, &quot;brief-report&quot;, &quot;report&quot; and &quot;other&quot;. We also excluded\ndocuments containing more than one text body or no text body. Samples\nindicated that documents without a text body are mostly scanned versions of\nolder articles that express only metadata in NXML. Documents with multiple\ntext body parts were usually conference reviews that list summaries of\nproceeding articles. Both of these document types are not relevant for a\nplagiarism analysis. The exclusions affected ‫׽‬13,000 documents. In total, we\nimported 221,220 documents to the CitePlag database.\n\n302\n\nAppendix\n\nB.3 Consolidation of Reference Identifiers\nWe consolidated available document identifiers after importing the data into the\nCitePlag database. When possible, we assigned all identifiers available for a\ndocument to all references that likely point to that document and corrected\nreference records in the database that had incorrect identifiers assigned to them.\nTo achieve this, we identified all likely valid relationships between identifiers\nand documents by applying the following procedure:\nFirst, we selected all PMIDs, MEDIDs, DOIs, RefTitKeys, and RefAuthKeys\nand took each of these identifiers as a seed to build all combinations with other\nidentifiers. For example, taking PMIDs as the seed, we selected all pairwise\ncombinations of PMID-DOI, PMID-MEDID, PMID-RefAuthKey, and\nPMID-RefTitKey. To improve accuracy, we only considered identifier\ncombinations that were identical in at least two documents. During this process,\nwe recognized that RefAuthKey is too error-prone for use as a seed, because we\ndo not disambiguate author names. If we encountered non-unique combinations\nof identifiers, we chose the combination used by the majority of authors and\nignored the other combinations. Assuming that the most frequently used\ncombination of, for example, a given PMID and DOI, is likely the correct\nmapping, we consolidated all ambiguous pairwise mappings of document\nidentifiers.\nSecond, we joined the consolidated pairwise-unique mappings of document\nidentifiers using the respective seed identifier in the mappings as the join\ncriterion. This step yielded the following four combined mappings for the\nrespective seed identifiers:\n1. PMID-DOI-MEDID-RefAuthKey-RefTitKey\n2. DOI-PMID-MEDID-RefAuthKey-RefTitKey\n3. MEDID-PMID-DOI-RefAuthKey-RefTitKey\n4. RefTitKey-PMID-DOI MEDID-RefAuthKey\n\nB Technical Details of the CitePlag Prototype\n\n303\n\nThird, we joined the mappings 1 through 4 consecutively to the table of all\nreferences using the respective seed identifier of the mappings as the join\ncriterion. If reference records matched one of the mappings in at least one\nadditional identifier aside from the seed identifier, we updated all data fields of\nthe reference record to equal the mapping. Mapping 4, which uses the artificially\ncomputed RefTitKey as the seed identifier, is more error-prone than the other\nmappings. Therefore, we used mapping 4 only to alter records that offered no\nother document identifier.\nTable 29: Consolidation of Reference Identifiers\nBefore Consolidation\nNo. of Ref.\n\nDocument Identifier\n\nTotal\nPMID\nno PMID, DOI\nno PMID, no\nDOI, MEDID\nNo identifiers,\nauthors, title\nNo title and/or\nauthors\n\nAfter Consolidation\n\nNo. of dist.\nIDs\n\nNo. of Ref.\n\nNo. of dist.\nIDs\n\n6,921,249\n5,470,266\n\n2,367,554\n\n5,572,531\n\n2,364,433\n\n195,359\n\n158,652\n\n192,705\n\n141,357\n\n84\n\n81\n\n82\n\n79\n\n831,899\n\n655,841\n\n733,183\n\n597,220\n\n423,641\n\n-\n\n422,748\n\n-\n\nTable 29 displays the availability of document identifiers for references\nbefore and after the consolidation. The table states the number of references for\nwhich the respective type of document identifier is available. Authors most often\nstated PMIDs when citing sources. DOIs and MEDIDs were the second and third\nmost frequent choice. The table shows the quantities of available document\nidentifiers according to the most commonly used document identifier for an\nindividual reference. For example, if the string for a reference included a PMID\n\n304\n\nAppendix\n\nand a DOI, we counted it for the PMID category only. The table also lists the\ntotals for distinct document identifiers before and after consolidation.\nDuring the consolidation, we assigned PMIDs to ‫׽‬100,000 references that\nhad no assigned PMIDs before consolidation. We were able to reduce the\nnumber of references without numeric identifiers by ‫׽‬58,000. Additionally, we\nreduced the number of distinct PMIDs by ‫׽‬3,000 and the number of distinct\nDOIs by ‫׽‬17,000. This reduction in distinct identifiers suggests that we\nsignificantly reduced the numbers of non-unique identifiers.\n\nB.4 Database Documentation\nThis section presents more details on the database structure of the CitePlag\nprototype briefly introduced in Section 5.2. A database dump (530 GB) is\navailable upon request from the author.\n\nFigure 70: ER Data Model for the CitePlag Database\n\nThe following list explains the attributes of all tables in the CitePlag\ndatabase.\n\nB Technical Details of the CitePlag Prototype\n\nciteplag_document_data\n-\n\ndocument_id ĺ\u0003 the database-internal ID assigned to documents\nfor which the full text is available in the database and to\n&quot;placeholder&quot; documents representing documents referenced\nwithin full texts.\n\n-\n\ntype ĺ\u0003a flag that identifies the type of additional data stored for\ndocuments, e.g., title or external document identifiers (PubMed\nIDs, PMCIDs, DOIs). The ENUM type provides the possibility to\nadd further types, which are not yet considered, in the future.\n\n-\n\nvalue ĺ\u0003an attribute holding the actual data of a certain type, e.g.,\ntitle.\n\nciteplag_document_text\n-\n\ndocument_id ĺ\u0003 the database-internal ID of the document for\nwhich the full text is stored.\n\n-\n\nfulltext ĺ\u0003the full text of the document.\n\nciteplag_author\n-\n\nauthor_id ĺ\u0003the database-internal ID for all authors.\n\n-\n\ndocument_id ĺ\u0003 the ID of the document in which the author\nappeared. Currently, authors are not disambiguated, i.e. if an\nauthor appears in multiple documents, there will be multiple\nrecords with the same name in citePlag_authors.\n\n-\n\nlast_name, first_name ĺ\u0003the author name.\n\n305\n\n306\n\nAppendix\n\nciteplag_citation\n-\n\ndb_citation_id ĺ\u0003the database-internal ID for all citations.\n\n-\n\ndocument_id ĺ\u0003 the database-internal ID of the document that\ncontains the citation.\n\n-\n\ndoc_reference_id ĺ\u0003the ID for references in NXML-documents. It\nis unique only within the NXML-document. In-text citations\nwithin a NXML-document specify the ID of their corresponding\nreference.\n\n-\n\ndb_reference_id ĺ\u0003the unique database-internal ID for references.\n\n-\n\ncount ĺ\u0003a sequential number of a citation within a document’s full\ntext.\n\n-\n\ncharacter, word, sentence, paragraph, section ĺ\u0003 the positional\ninformation of a citation within a document’s full text.\n\nciteplag_reference\n-\n\ndb_reference_id ĺ\u0003the database-internal ID for references.\n\n-\n\ncont_document_id ĺ\u0003 the document_id of the document that\ncontains the reference.\n\n-\n\ndoc_reference_id ĺ\u0003 an ID for references used in NXMLdocuments; is unique only within the NXML-document.\n\n-\n\nref_document_id ĺ\u0003 the document_id of the document that is\nreferenced. The referenced document is not necessarily part of the\nPMC OAS. Therefore, many &quot;placeholder documents&quot; for which\nno full text is available are contained in the database.\n\nB Technical Details of the CitePlag Prototype\n\nciteplag_pattern\n-\n\npattern_id → the database-internal ID for all patterns.\n\n-\n\ndocument_id1, document_id2 → the document_ids of the two\ndocuments for which the matching pattern has been identified.\n\n-\n\nprocedure → the ID that denominates the detection algorithm,\nwhich was used to identify the pattern, see Table 30 for a short\ndescription and an overview of IDs for the detection approaches.\n\n-\n\npattern_score → similarity score of the identified pattern. For\ncitation patterns, the score equals the length of the pattern, for\ncharacter-based patterns see table above.\n\n307\n\n308\n\nAppendix\nTable 30: Overview of Detection Algorithms and their Database-internal IDs\nClass\nLCCS\n\nGCT\n\nCitation\nChunking\n\nDetection Algorithm\n\nID\n\nLCCS\n\n1\n\nLCCS distinct\n\n11\n\nshared citations only\n\n2\n\nall citations\n\n21\n\nall citations, matches all shared citations once a match\nhas been found\n\n22\n\none document chunked, only adjacent citations\nconsidered, no merge performed\n\n30\n\none document chunked, only adjacent citations\nconsidered, merge\n\n31\n\none document chunked dependent on predecessor, no\nmerge\n\n32\n\none document chunked dependent on predecessor,\nmerge\n\n33\n\none document chunked dependent on textual proximity,\nno merge\n\n34\n\none document chunked dependent on textual proximity,\nno merge\n\n35\n\nboth documents chunked, only adjacent citations\nconsidered, no merge\n\n40\n\nboth documents chunked, only adjacent citations\nconsidered, merge\n\n41\n\nboth documents chunked dependent on predecessor, no\nmerge\n\n42\n\nboth documents chunked dependent on predecessor,\n\n43\n\nB Technical Details of the CitePlag Prototype\n\n309\n\nmerge\nboth documents chunked dependent on textual\nproximity, no merge\n\n44\n\nboth documents chunked dependent textual proximity,\nno merge\n\n45\n\nEncoplot (global score of document = percentage of\nsimilarity)\n\n50\n\nEncoplot (scores of multiple patterns per document,\ndetails on patterns in textpattern_member table)\n\n51\n\nBasic CPA\n\n60\n\nBibliographic Coupling (score = coupling strength of\nboth documents, no pattern_members)\n\n70\n\nBibliographic Coupling / Coupling units (score = total\ncitations of a shared reference, pattern_members:\ncitations that form the coupling)\n\n71\n\nCo-Citation\n\nCo-Citation = number of documents that cite the two\ndocuments together\n\n80\n\nLucene\n\nLucene MoreLikeThis measure computed on the full\ntext\n\n90\n\nEncoplot\nSimilarity\n\nCPA\nBibliographic\nCoupling\n\nciteplag_citationpattern_member\n-\n\npattern_member_id\n→\ncitation_pattern_members\n\n-\n\npattern_id → database-internal ID of the pattern formed by the\ncitation_pattern_members\n\ndatabase-internal\n\nID\n\nfor\n\nall\n\n310\n\nAppendix\n\n-\n\ndocument_id → document_ID of the document that contains the\ncitations. Storing this ID here is redundant, because the citation\nidentified by db_citation_id contains the same information.\nHowever, in practice the redundancy saves a join of\nciteplag_citationpattern_member to citeplag_citation, which\nsignificantly improves performance, because citeplag_citationpattern_member is a very large table (approximately 1.4 billion\nrecords).\n\n-\n\ncount → sequential position of the pattern member within the\npattern\n\n-\n\ngap → number of non-matching citations between two matching\ncitations in a citation pattern\n\n-\n\ndb_citation_id → ID of the citation that represents the pattern\nmember\n\nciteplag_textpattern_member\n-\n\npattern_member_id\n→\ntext_pattern_members\n\n-\n\npattern_id → database-internal ID of the pattern formed by the\ntext_pattern_members\n\n-\n\ndocument_id → document_ID of the document that features the\ntext similarity\n\n-\n\nstart_character, end_character → character count at the start- and\nending position of the identified text overlap\n\ndatabase-internal\n\nID\n\nfor\n\nall\n\nC\n\nData and Source-code Downloads\n\nVarious files are publicly available for download on the thesis website:\nhttp://citeplag.org/thesis/\n-\n\nThis doctoral thesis (PDF)\n\n-\n\nIntroductory video to CbPD\n\n-\n\nSource code: CitePlag prototype (zip file)\n\n-\n\nRelated publications (PDF)\n\n-\n\nThe figures and tables used in the thesis (zip file)\n\n-\n\nGuttenPlag Wiki evaluation, from Section 6.3 (Excel file)\n\n-\n\nVroniPlag Wiki evaluation data, from Section 6.3 (Excel file)\n\n-\n\nHeun plagiarism examination, from Section 6.3.3 (Excel file)\n\nCbPD Evaluation Findings (password required)\nTo access the non-publically accessible password-protected data, including the\nuser study suspiciousness-ratings for the scientific publications of the PMC OAS\nthat have not yet been retracted, please contact the author71.\nThe following non-public downloads are available:\n\n71\n\n-\n\nPMC OAS database dump with description (SQL file, 530 GB)\n\n-\n\nPMC OAS findings of suspicious publications, as discussed in\nExamples of CbPD-identified Cases on page 188 (Excel file)\n\nbela@gipp.com\n\n312\n\nAppendix\n\nInvolved Organizations\n-\n\nDKE – Data &amp; Knowledge Engineering Group, Otto-von-Guericke\nUniversity, Germany\n\n-\n\nHTW – Hochschule für Technik und Wirtschaft, Germany\n\n-\n\nUC Berkeley – University of California, Berkeley, CA, USA\n\n-\n\nVLBA Lab – SAP / Very Large Business Applications Lab\n(VLBA), Germany\n\nD\n\nRelated Publications\n\nContent included in this dissertation has been published with co-authors at\nconferences and in journals. These publications and their respective locations in\nthe doctoral thesis are listed here.\nJCDL / TPDL Doctoral consortium [125]: See Chapter 7 and Section 7.3\nB. Gipp. Identifying Related Work and Plagiarism by Citation Analysis.\nIEEE-TCDL Bulletin, 7, 2011.\nCbPD Algorithms [129]: See Chapter 4\nB. Gipp and N. Meuschke. Citation Pattern Matching Algorithms for\nCitation-based Plagiarism Detection: Greedy Citation Tiling, Citation\nChunking and Longest Common Citation Sequence. In Proceedings of\nthe 11th ACM Symposium on Document Engineering, pages 249–258,\nMountain\nView,\nCA,\nUSA,\n2011.\nACM.\ndoi:\n10.1145/2034691.2034741\nCPA concept publication [126]: See Section 3.2.5\nB. Gipp and J. Beel. Citation Proximity Analysis (CPA) - A new\napproach for identifying related work based on Co-Citation Analysis. In\nB. Larsen and J. Leta, editors, Proceedings of the 12th International\nConference on Scientometrics and Informetrics (ISSI’09), volume 2,\npages 571–575, Rio de Janeiro (Brazil), July 2009. International Society\nfor Scientometrics and Informetrics. ISSN 2175-1935.\nCbPD concept [127]: See Chapter 4\nB. Gipp and J. Beel. Citation Based Plagiarism Detection - a New\nApproach to Identify Plagiarized Work Language Independently. In\nProceedings of the 21st ACM Conference on Hypertext and\nHypermedia,\npages\n273–274.\nACM,\n2010.\ndoi:\n10.1145/1810617.1810671\n\n314\n\nAppendix\n\nCbPD Prototype [133, 229]: See Chapter 5\nB. Gipp, N. Meuschke, C. Breitinger, M. Lipinski, and A. Nürnberger.\nDemonstration of the First Citation-based Plagiarism Detection\nPrototype. In The 36th International ACM SIGIR conference on\nresearch and development in Information Retrieval, 2013. doi:\n10.1145/2484028.2484214\nN. Meuschke, B. Gipp, and C. Breitinger. CitePlag: A Citation-based\nPlagiarism Detection System Prototype. In Proceedings of the 5th\nInternational Plagiarism Conference, Newcastle upon Tyne, UK, 2012.\nCbPD Evaluation using GuttenPlag [132]: See Chapter 6\nB. Gipp, N. Meuschke, and J. Beel. Comparative Evaluation of Textand Citation-based Plagiarism Detection Approaches using GuttenPlag.\nIn Proceedings of 11th ACM/IEEE-CS Joint Conference on Digital\nLibraries (JCDL’11), pages 255–258, Ottawa, Canada, 2011. ACM.\ndoi: 10.1145/1998076.1998124\nState-of-the-Art in Detecting Academic Plagiarism [228]: See Chapter 2\nN. Meuschke and B. Gipp. State of the Art in Detecting Academic\nPlagiarism. International Journal for Educational Integrity, 9 (1): 50–\n71, June 2013.\nMeasuring Document Relatedness by Citation Proximity Analysis and\nCitation Order Analysis [124]: See Chapter 4\nB. Gipp. Measuring Document Relatedness by Citation Proximity\nAnalysis and Citation Order Analysis. In M. Lalmas, J. Jose, A. Rauber,\nF. Sebastiani, and I. Frommholz, editors, Proceedings of the 14th\nEuropean Conference on Digital Libraries (ECDL’10): Research and\nAdvanced Technology for Digital Libraries, volume 6273 of Lecture\nNotes of Computer Science (LNCS). Springer, September 2010.\n\nD Related Publications\n\n315\n\nScienstein [130]: See Section 3.2.5\nB. Gipp, J. Beel, and C. Hentschel. Scienstein: A Research Paper\nRecommender System. In Proceedings of the International Conference\non Emerging Trends in Computing (ICETiC’09), pages 309–315,\nVirudhunagar (India), 2009. Kamaraj College of Engineering and\nTechnology India, IEEE.\nCPA / CbPD Approach [123]: See Section 3.2.5 and Chapter 4\nB. Gipp. Very Large Business Applications (VLBA): Systemlandschaften\nder Zukunft, chapter Entwicklung neuer Verfahren zur Bestimmung von\nDokumentenaehnlichkeiten mittels Referenz- und Zitationsanalyse,\npages 163–173. 3. Workshop des Centers for Very Large Business\nApplications (CVLBA). Shaker Verlag, Magdeburg, October 2009.\nLink-Proximity Analysis [131]: See Chapter 7.3\nB. Gipp, A. Taylor, and J. Beel. Link Proximity Analysis - Clustering\nWebsites by Examining Link Proximity. In M. Lalmas, J. Jose,\nA. Rauber, F. Sebastiani, and I. Frommholz, editors, Proceedings of the\n14th European Conference on Digital Libraries (ECDL’10): Research\nand Advanced Technology for Digital Libraries, volume 6273 of\nLecture Notes of Computer Science (LNCS). Springer, September 2010.\n\n316\n\nAppendix\n\nPatent applications:\nB. Gipp and J. Beel. Method and system for detecting a similarity of\ndocuments.\nPatent Application, 10 2011. URL\nhttp://www.patentlens.net/patentlens/patent/US_2011_0264672_A1/en/. US\n2011/0264672 A1.\nIndirectly Related Publications:\nCitRec [134]: See Chapter 7.3\nB. Gipp, N. Meuschke, M. Lipinski, and A. Nürnberger. CITREC: An\nEvaluation Framework for Citation-Based Similarity Measures based on\nTREC Genomics and PMC. To be published.\nSciPlore Xtract: Extracting Titles from Scientific PDF Documents by\nAnalyzing Style Information [29]: See Chapter 7.3\nJ. Beel, B. Gipp, A. Shaker, and N. Friedrich. SciPlore Xtract:\nExtracting Titles from Scientific PDF Documents by Analyzing Style\nInformation (Font Size). In M. Lalmas, J. Jose, A. Rauber, F. Sebastiani,\nand I. Frommholz, editors, Research and Advanced Technology for\nDigital Libraries, Proceedings of the 14th European Conference on\nDigital Libraries (ECDL’10), volume 6273 of Lecture Notes of\nComputer Science (LNCS), pages 413–416, Glasgow (UK), Sept. 2010.\nSpringer.\nMrDLib [31]: See Chapter 7.3\nJ. Beel, B. Gipp, S. Langer, M. Genzmehr, E. Wilde, A. Nürnberger,\nand J. Pitman. Introducing Mr. DLib, a Machine-readable Digital\nLibrary. In Proceedings of the 11th ACM/IEEE Joint Conference on\nDigital Libraries (JCDL‘11), 2011.\n\nD Related Publications\n\n317\n\nImpact of Citations in Google Scholar [25, 27, 30]: See Chapter 7.3\nJ. Beel and B. Gipp. Google Scholar’s Ranking Algorithm: An\nIntroductory Overview. In B. Larsen and J. Leta, editors, Proceedings of\nthe 12th International Conference on Scientometrics and Informetrics\n(ISSI’09), volume 1, pages 230–241, Rio de Janeiro (Brazil), July 2009.\nInternational Society for Scientometrics and Informetrics.\nJ. Beel and B. Gipp. Academic search engine spam and Google\nScholar’s resilience against it. Journal of Electronic Publishing, 13 (3),\nDec. 2010. doi: 10.3998/3336451.0013.305.\nJ. Beel, B. Gipp, and E. Wilde. Academic Search Engine Optimization\n(ASEO): Optimizing Scholarly Literature for Google Scholar and Co.\nJournal of Scholarly Publishing, 41 (2): 176–190, Jan. 2010. doi:\n10.3138/jsp.41.2.176. University of Toronto Press.\nEvaluation of Header Metadata Extraction Approaches and Tools for\nScientific PDF Documents [195]: See Section 5.1 and 7.3.1\nM. Lipinski, K. Yao, C. Breitinger, J. Beel, and B. Gipp. Evaluation of\nHeader Metadata Extraction Approaches and Tools for Scientific PDF\nDocuments. In Proceedings of the 13th ACM/IEEE-CS joint conference\non Digital Libraries (JCDL), JCDL ’13, New York, NY, USA, 2013.\nACM. doi: 10.1145/2467696.2467753.\n\nE\n\nPatent Application\n\nThe author filed three patent applications in Europe and the USA related to the\nideas and research presented in this thesis [28, 32, 128]. The following text is a\ncopy of the US-Patent application for Co-citation Proximity Analysis [128]. For\nadditional information please visit:\nhttp://www.patentstorm.us/applications/20110264672/description.html\nThe following patent is included in this appendix:\n\nMETHOD AND SYSTEM FOR DETECTING A SIMILARITY\nOF DOCUMENTS\nCross Reference to Related Applications\nThe present application is a continuation of International Application Number\nPCT/DE2009/000017 filed on January 8, 2009, the entire contents of which are\nincorporated herein by reference.\nField of the Invention\nThe present invention relates to a method and a system for detecting a similarity\nof documents. The invention particularly relates to a method and a system for\ndetecting a similarity of documents, wherein similar documents are detected and\npossibly provided based on a predetermined document.\n\nE Patent Application\n\n319\n\n320\n\nAppendix\n\nE Patent Application\n\n321\n\n322\n\nAppendix\n\nE Patent Application\n\n323\n\n324\n\nAppendix\n\nE Patent Application\n\n325\n\n326\n\nAppendix\n\nE Patent Application\n\n327\n\n328\n\nAppendix\n\nF\n\nUser Study Feedback\n\nAs part of the user study, participants had the opportunity to submit comments\nand suggestions on their perceived usefulness of the citation-based approach.\nTable 31 shows excerpts of responses collected in the user study.\nTable 31: User Comments on CbPD\n“[CbPD shows]... a similarity which I find valuable to see.“\n“[The citation pattern visualization] helped me come to a quicker\nconclusion. Sometimes [CbPD] helped either strengthen or weaken my\nopinion on similarity. For example, if shake &amp; paste plagiarism also\nclearly shared citation patterns, I arrived at a conclusion more\nquickly72.”\n“...when many key words overlapped, but the citation patterns around\nshared words were unique, CbPD helps to show legitimate similarity.”\n“...[CbPD adds a]... new level of document similarity that I was\nunaware of before.”\n“Judging plagiarism is quick when two documents have text overlaps,\nbut when the text is adjusted or rearranged, it is much more difficult to\nassess documents and to find any overlap in their content. It requires a\ndeep background knowledge on the topic and also the cited works. The\ncitation visualization really helps to better assess the content similarity\nwhen the text does not overlap. This makes it faster and easier,\nespecially for an examiner who is not familiar with a particular topic!”\n\nSome users expressed uncertainty regarding the value of citations. They felt\ncitation-based similarity allowed them no quick way of knowing what similarity\nshould still be considered &quot;normal&quot;. However, the threshold problem for\n&quot;acceptable&quot; similarity also exists for character-based measures. The reality is\n72\n\nTranslated from German. Comment submitted by a General Medical Practitioner.\n\n330\n\nAppendix\n\nthat no quick or easy fix exists to categorize a given similarity among documents\nas clearly suspicious.\nOne of the experts commented that for documents with high semantic\nsimilarity with no notable text similarity, the addition of very fine-grained text\nsimilarity visualization, i.e. ten or less matching characters was helpful for\ndiscerning if the patterns of medical key words, especially surrounding shared\ncitations were suspiciously similar.\n\nG Reactions of Contacted Authors\nOf the top-40 document pairs rated as most suspicious by user study participant,\ntwo publications had already been retracted. One publication [281] was retracted\nas a result of a previous email exchange we had with the earlier authors, while\nthe other case [165] had already been retracted at the time of detection by the\nCbPD algorithms. We emailed73 the authors of the remaining 38 earlier\npublished articles asking them if they:\n-\n\nwere aware of the later published article?\n\n-\n\nknew of any reasons which may explain the similarity of the later\narticle?\n\n-\n\nsaw any indications for plagiarism?\n\nThe authors of 20 articles replied74.\nThe authors of six articles confirmed the presence of plagiarism, one\nadditional author confirmed plagiarism, but wished to take no action75, and the\nauthors of nine papers acknowledged similarities, but did not consider them as\ncrucial enough to initiate a retraction process. The authors of two papers simply\nreplied a “thank you” refusing to comment on plagiarism, and the authors of the\nfinal two publications replied they were not technically versed enough to utilize\nor make sense of the prototype visualization.\nMany authors expressed gratitude for being made aware of the plagiarism of\ntheir work. Table 32 lists some of the email responses from the authors we\ncontacted.\n\n73\n74\n75\n\nAll authors were contacted 2013-05-06, unless specified otherwise.\nAs of 2013-05-31.\nRefer to the comment beginning “I don&#x27;t know if...” on page 334 for an explanation.\n\n332\n\nAppendix\nTable 32: Original Author Comments on CbPD\n“To be honest I am quite shocked. The resemblance is indeed more than\nstriking. [...] your tool seems to be very efficacious indeed.”\n...the degree of overlap seems to me to be most consistent with over-reliance\non our paper for language and structure by the authors of the later paper.”\n“I was not aware of this later paper and I do not know of any reasons which\nmay explain the similarity of the later article to ours.\n“The results which you have shown are mind boggling.. I simply don&#x27;t know\nhow to respond...I find no reasons for both the manuscripts to be so similar.\nIntroductions can be similar to some extent, but almost the entire discussion\nseems to be copied as it is. Their images do not show any evidence of skin\ngraft being used, where discussion mentions of skin grafts!!!\n...I see every indication for plagiarism in this particular article. It\nis definitely more than just coincidence. Unfortunately, our article has not\neven been cited by the manuscript.”\n“...your approach is reasonable, and I applaud the success of your program”\n“Your program is very nice and surprising!\nWe have not been aware of the existence of the later article.”\n“Your work raises the question of reviewing. Why wasn&#x27;t this detected by the\nreviewers?”\n“I looked at your analysis and I am amazed.\nWe were definitely plagiarized and I was not aware of this article. [...] The\nbest evidence is the results of your algorithm.”\n“I&#x27;m quite surprised... I did not know that paper and I do not know its authors.\nIt seems that they just copied and pasted most of the discussion section and\nthe bibliography of my paper without changing even a single word.\nI think this is a clear example of plagiarism”\n“I was not aware of this later published article.\nI find no reason for the similarity (identity) of the articles. I am completely\nsure it is a case of plagiarism76.”\n\n76\n\nExcerpt from an email exchange on 2012-09-03.\n\nG Reactions of Contacted Authors\n\n333\n\nTo guarantee anonymity to the individual authors quoted here, we do not\ndisclose their names. Disclosure of full names is available only upon request77.\nThe gamut of responses we received were in line with the types of responses\ncollected in similar investigations of potential plagiarism. For a study examining\nprecisely the responses of all involved parties that result from investigating\nplagiarism, refer to [202].\nThe responses we received from the original authors, who rejected the\npresence of plagiarism, showed that the opinions on what constitutes plagiarism\ncontinue to differ. A first case in which authors felt that high similarity was\nacceptable was in introductory or overview sections. According to one set of\nauthors, introductory phrases ‘set the stage’ of a paper and may be copied in\npublications, given that they serve to point out the scientific niche the paper will\noccupy. As one set of authors78 argues, generic ‘stage-setting’ statements were\nnot part of the author’s unique contribution and thus should not be viewed as\nplagiarism:\n“the [...] sentences [...] are indeed similar. [They] ‘set the stage’\nby pointing out how health care can be unsafe. They are not a part\nof the authors’ unique contributions.” T.A., B.G., L.S.\nA second case in which citation pattern similarity was viewed as justified by\nauthors was for case reports and review studies. Such reports tend to follow\nstandardized forms, often using boilerplate text, as pointed out by the following\nauthor:\n“Both papers are study design papers of Dutch studies. The recent\nstudy was modeled using elements of the first study. Record review\nstudies are highly standardized. This clarifies the similarities.”\nM.B.\n77\n\n78\n\nWe also decided against using author initials, since the identity of the publications’\noriginal authors can easily be revealed once the retracted cases are made public. This\nwould jeopardize the anonymity of authors who communicated confidentially with us\nby email.\nExcerpt from an email exchange on 2012-10-10.\n\n334\n\nAppendix\n\nA third example of author-approved citation pattern similarity affected\nreview articles:\n“the similarity [...] is normal because we wrote about the same\ntopic and it is normal to use the same references because both\npapers are reviews and the field is so small (I mean the people\nworking in the field are not so many so obviously we are all going\nto use the same references and same words).”\nA final – albeit a most controversial example of similarity considered\n“legitimate” – was pointed out by an author, who argued that the different\ndefinition on &quot;acceptable borrowing&quot; of text in developing countries should not\nbe ignored:\n“I don&#x27;t know if there are technical criteria for declaring a\ndocument to have been plagiarized....My lenient reaction is no\ndoubt colored by having trained many scientists from developing\ncountries whose first language is not English. Not only must they\nrely on published English-language work to help them formulate\nwording for their own work, but the cultural norms for what is\nconsidered acceptable &quot;borrowing&quot; of language tend to be more\npermissive in developing countries than in the U.S.”\nWe were also reminded of the fear of consequences authors face for accusing\nothers of plagiarism. The authors of one paper were not willing to approach the\njournal and expose the plagiarists themselves:\n“We are not willing to do this job ourselves because this will lead\nto great conflict with the author of the second paper who is living\nin the same country, even though we do not know him personally.”\n\nG Reactions of Contacted Authors\n\n335\n\nIt was common for authors to express their disbelief and surprise of the\nplagiarism having gone undetected for so long. Many expressed their concern\nregarding the quality of peer review and the ability of current detection\napproaches to identify strongly disguised plagiarism forms beyond copy &amp; paste.\nOne author was of the opinion that automated plagiarism detection presented an\nimportant area of research, in which CbPD was:\n“a useful step in development of more sophisticated methods.”\n\nH Empirical Studies on Plagiarism\nFrequencies\nTable 33: Studies Pertaining to North American Colleges\nSource\n\nSample size, place\nand time of collection\n\nMethod\n\nResults\n\n[277]\n\n447 undergraduates at\none U.S. campus\nSpring term 1997\n\nself-report\nsurvey\n\n50 % copied from fellow students\nwith their consent, 24.3 % without\n35.6 % committed partial\nplagiarism\n\n[45]\n\n71 students at one U.S.\ncampus\nSpring term 1998\n\nself-report\nsurvey\n\n67.2 % committed partial\nplagiarism\n26.8 submitted a paper from an\nexternal source\n\n[283]\n\n698 students at nine\nU.S. campuses\nAcademic year\n1999/2000\n\nself-report\nsurvey\n\n19.0 % committed partial\nplagiarism “sometimes”\n5.4 % submitted a paper from an\nexternal source “sometimes”\n\n[176]\n\nUnknown number of\nundergraduates at one\nU.S. campus\npublication date: Aug.\n2003\n\nself-report\nsurvey\n\n[220]\n\n60,691 students at 67\nU.S. institutions\n21,649 students at 16\nCanadian institutions\nAcademic years\n2002/2003, 2004/2005\n\nself-report\nsurvey\n\n38 % undergrad., 25 % grad.\ncommitted partial plagiarism\n8 % undergrad., 4 % grad. copied\nfrom another source\n(within 12 months prior to the\nsurvey)\n\n[46]\n\n91 students at one U.S.\ncampus\nFall term 2004\n\nself-report\nsurvey\n\n53.2 % committed partial\nplagiarism\n31.2 % submitted a paper from an\nexternal source\n\n[223]\n\n5,331 graduate\nstudents at 32\ncampuses in the USA\n\nself-report\nsurvey\n\n53 % of business majors, 43 % of\nother students cheated on written\nwork\n\n47.1 % committed plagiarism\n\nH Empirical Studies on Plagiarism Frequencies\nand Canada\n\n[273]\n\n337\n\nAcademic years\n2003/2004, 2004/2005\n\n33 % of business majors, 22 %\nother students literally copied\nfrom the internet (within 12\nmonths prior to the survey)\n\n1,225 students at one\nU.S. campus\nObservation period\nunspecified,\npublication date: Jun.\n2007\n\n62.6 % copied homework from\nfellow students\n44.5 % plagiarized from internet\n17.9 % copied term papers or\nprojects from fellow students\n\nself-report\nsurvey\n\nTable 34: Studies Pertaining to Colleges Outside of North America\nSource\n\nSample size, place,\ntime of collection\n\nMethod\n\nResults\n\n[194]\n\n518 students\nfrom three institutions\nin Singapore;\nObservation period\nunspecified;\nPublication date: July\n2001\n\nself-report\nsurvey\n\n89.8 % plagiarized by\nparaphrasing\n85.1 % copied literally from\nbooks, articles etc.\n56.5 % copied papers from fellow\nstudents with or without their\nconsent\n\n[212]\n\n954 students\nfrom four Australian\nuniversities;\nObservation period\nunspecified;\nPublication date: May\n2005\n\nself-report\nsurvey\n\n81 % committed plagiarism\n\n[83]\n\n2002/2003: 145\nundergraduates\n2003/2004: 207\nundergraduates from\n\nAssignments\nchecked\nwith\n\n79\n\n‫׽‬40 % of students had\nNOS&gt;=20 % in both academic\nyears analyzed79\n\nNon-Originality Score (NOS); documents scoring NOS&gt;10 % are typically regarded\nas suspicious and likely to contain plagiarism.\n\n338\n\nAppendix\none institution in the\nUK\n\n[23]\n\n[303]\n\n182 graduate students\nfrom one institution in\nthe UK\nObservation period\nunspecified;\nPublication date: 2006\n\n159 students\nfrom one institution in\nthe UK;\nObservation period\nunspecified;\nPublication date: June\n2008\n\nOrCheck\nAssignments\nchecked\nwith\nTurnitin;\nSuspicious\ndocuments\ninspected\nmanually\n\nTurnitin flagged 40.6 % of all\ndocuments as suspicious\nManual inspection revealed 26 %\nof all documents contained actual\nplagiarism\n\nself-report\nsurvey\n\n68.6 % plagiarized by\nparaphrasing (23.9 % frequently)\n59.7 % copied material literally\nfrom books, articles etc. (24.5 %\nfrequently)\n21.4 % copied from fellow\nstudents (5.7 % frequently)\n17.5 % submitted a paper from an\nexternal source, (3.7 %\nfrequently)\n\n[332]\n\n322 undergraduates\nFrom three Swedish\nuniversities\n\nself-report\nsurvey\n\n61 % copied material literally\nfrom books, articles etc.\n55 % copied from fellow students\nwith their consent, 9 % without\n31 % submitted a paper from an\nexternal source\n\n[329]\n\n‫׽‬1,300 MA and PhD\nthesis\nat one Turkish\nuniversity\nSubmissions between\n2001 and 2010\n\nAssignments\nchecked\nwith\nTurnitin\n\n22.3 % of thesis had\n21 %&lt;=x&lt;=30 % NOS\n(NOS&gt;15 % was considered\nsuspicious by this study [85] )\n\nI\n\nStudies on Citation-based Similarity\nMeasures\n\nThe following three tables summarize studies, which assessed the applicability of\ncitation-based similarity measures for different retrieval tasks. Studies commonly\nanalyzed the suitability of different measures for creating topic-centered clusters\nof research articles [4, 38, 39, 166, 167, 200, 244] or web pages [53, 54, 79, 86,\n352].\nTable 35 lists studies exclusively analyzing citation-based measures, while\nTable 36 outlines studies that compared character-based and citation-based\nsimilarity measures side-by-side.\nTable 37 highlights studies that also evaluated hybrid measures, which\ncombined both approaches.\n\n340\n\nAppendix\nTable 35: Studies Evaluating Citation-based Similarity Measures\nObjective of\nStudy\n\nSimilarity\nMeasures\n\nGold Standard\n\nTest collection\n\n[86]: Find relevant\nweb pages for\ngiven input URLs\n\nCo-citation\n(CoCit),\nCompanion\n\n18 expert\njudgments\n\n59 input URLs\nselected by\nexperts, top-10\nrecommendations\nof each approach\n\n[4]: Subject\nclassification for\nresearch articles\n\nBibCoup, Abstract\nkeywords\n\n1 expert judgments\n\n43 IR articles\n\n[295]: Perf. of\nsimilarity measures\nto identify research\nfront\n\nBibCoup, CoCit,\nDirect Citation\n\nTopological\nclustering (defined\ncriteria)\n\nArticles retrieved\nby keyword search\nfrom SCI\n\n[369]: Identify\ntopically similar\npapers\n\nBibCoup, CoCit,\nAmsler, Inter\nConn.\n\nPrediction of\nreference papers\ngiven in textbook\nchapters\n\nDBLP and\nreference\ninformation\ncrawled from MS\nAcademic Search\n\nI Studies on Citation-based Similarity Measures\n\n341\n\nTable 36: Studies Primarily Evaluating Citation-based Similarity Measures\nStudy,\nObjective\n\nSimilarity\nMeasure\n\nGold Standard\n\nTest collection\n\nComparison of\nsimilarity measures\nfor topical\nsimilarity (our own\nstudy [134])\n\nBibCoup, CoCit,\nAmsler,\nCo-citation\nProximity\nAnalysis, CoCit,\nLucene\n\nInformation\ncontent analysis\nderived from\nMeSH thesaurus\n\n‫׽‬260,000\ndocuments from\nthe PubMed\nCentral Open\nAccess Subset\n\n[39]: Subject\nclustering, creation\nof topic maps for\nresearch articles\n\nCoCit,\nVector Space\nModel (VSM)\n\n1 expert interview\nper analyzed\ndomain\n\n‫׽‬3,400 and\n‫׽‬1,300 articles\nfrom two research\nfields\n\n[352]: Web page\nclustering\n\nBibCoup, CoCit,\nanchor texts\n\nRelevance\njudgment by the\nauthors\n\n200 web pages for\neach of 8 topics\n\n[168]: Evaluate\nsuitability of\nsimilarity measures\nto identify research\nfront\n\nBibCoup and\nCoCit combined\nwith title keyword\nclustering\n\nNone;\nclustering derived\nfrom assumptions\nmade\n\n‫׽‬73,000\nenvironmental\nresearch articles\nfrom SCI\n\n342\n\nAppendix\nTable 37: Studies Evaluating Hybrid Measures\nStudy,\nObjective\n\nSimilarity\nMeasures\n\n[166]: Subject\nclustering, creation\nof topic maps for\nresearch articles\n\nBibCoup, VSM of\ntitles and abstracts,\nchi-square\ncombination of\nboth\n\nMeSH\n\n5,188 papers\nretrieved by\njournal selection,\nkeyword search\netc.\n\n[53, 54, 79, 80]:\nSubject\nclassification for\nweb pages\n\nBibCoup,CoCit,\nAmsler, Compan.,\nkNN with tf/idf\nVSM, SVM, Naïve\nBayes classifier\n\nExpert\nclassifications\n\n2 sets of manually\npre-classified web\npages;\nin [79] further\n‫׽‬6,600 articles\nfrom ACM DL\n\n[3]: Subject\nclassification for\nresearch articles\n\nBibCoup, termbased approach,\ncombination of\nboth\n\nOne expert\nclustering\n\n43 IR articles\n\n[167]: Subject\nclustering, creation\nof topic maps for\narticles\n\nVarious citationbased,\ntf/idf VSM,\nlinear\ncombinations\n\nExternal:\nThomson Reuters\nEssential Science\nIndicators\n\n‫׽‬6 million papers,\n‫׽‬8,000 journals\nfrom Web of\nScience\n\n[200, 201]:\nClustering of\nresearch articles\n\ncharacter-based,\nvarious citationbased\nLSI of binary\narticle\ncross-citation,\ncombination of\ntext- and\ncitation-based\nmeasures\n\nGold Standard\n\nInternal:\nMean Silhouette\nValue, Modularity\n\nTest collection\n\nJ\n\nOverview of Selected PDS\n\nGiven the fast-paced changes in the software landscape for plagiarism detection,\nthis section presents some established systems that are well-maintained and find\nwidespread use for the comparison of academic documents.\nTable 38 presents PDS that focus on collusion detection by employing a\nuser-defined corpus. PDS that compare documents to external collections are\ntypically web-based. Major vendors, including Ephorus, SafeAssign, Turnitin,\nand Urkund, maintain large indices of the web and exclusive non-publicly\navailable content, including journal articles, books, and prior works submitted\nfor inspection. Turnitin calls itself the global leader in PD and claims to\ncontinuously index ‫׽‬24 billion web pages, ‫׽‬250 million student papers, and\n‫׽‬100 million books and periodicals [164]. The comparison algorithms of all\ncommercial PDS are trade secrets. However, given the size of the reference\ncollection, we conclude that the systems must apply approaches requiring low\ncomputational effort, which suggests commercial PDS most likely use\nfingerprinting.\nTable 39 summarizes systems that check documents against an external\ncollection. The last columns in both tables list publications that offer details on\ndetection procedures and system performance. Information on the exact\nalgorithms used in commercial tools is not publicly available.\n\n344\n\nAppendix\nTable 38: PDS for Document Comparisons within a User-Defined Corpus\nSystem/\nManufacturer\n\nDetection\nApproach\n\nLicense/Costs\n\nAntiPlagiarist\n[2]\n\nclient software:\nlocal installation\nprocedure:\nword-based string\nmatching\n\nCommercial\n$34.95\n\nCopyCatch\n[60]\n\nclient software:\nlocal installation\nprocedure:\nstring matching\n\nCommercial\nindividual price\n\nEncoplot\n[143]\n\nclient software:\nlocal installation\nprocedure:\nfingerprinting\nusing 16-charactergrams\n\nFreeware;\nOpen source\n\nSource\n[355]\n\n[50, 89, 353]\n\n[142, 143]\n\nFerret\n[186]\n\nclient software:\nlocal installation\nprocedure:\nword-3-gram\nfingerprinting\n\n[22, 203, 204]\n\nSherlock\n[184]\n\nclient software:\nlocal installation\nprocedure:\nword-n-gram\nfingerprinting\n\nFreeware;\nOpen source\n\n[184]\n\nWCopyFind\n[35]\n\nclient software:\nlocal installation\nprocedure:\nword-based string\nmatching\n\nFreeware;\nOpen source\n\n[94, 282, 355]\n\nFreeware\n\nJ Overview of Selected PDS\n\n345\n\nPDS that compare documents to external collections are typically web-based.\nMajor vendors, including Ephorus, SafeAssign, Turnitin, and Urkund, maintain\nlarge indices of the web and exclusive non-publicly available content, including\njournal articles, books, and prior works submitted for inspection. Turnitin calls\nitself the global leader in PD and claims to continuously index ‫׽‬24 billion web\npages, ‫׽‬250 million student papers, and ‫׽‬100 million books and periodicals\n[164]. The comparison algorithms of all commercial PDS are trade secrets.\nHowever, given the size of the reference collection, we conclude that the systems\nmust apply detection approaches with low computational effort, which suggests\ncommercial PDS most likely use fingerprinting.\nTable 39: PDS for Document Comparisons with an External Collection\nSystem/\nManufacturer\nCopyscape\n[60]\n\nDetection Approach\n\nLicense/Costs\n\nclient software:\nweb-based system\ninput: URL or plain text (max.\n2,000 words)\nprocedure: chunking and\nselection strategy unknown,\nchunks searched with Google\n\nCommercial\n$0.05 per scan\n\nSource\n[282, 353,\n356]\n\n346\n\nAppendix\nDocoloc\n[93]\n\nclient software: web-based\nsystem\ninput: single or multiple\ndocuments\nprocedure: selection of\n(5-9)-word-grams, which the\nsystem searches with Google\n\nCommercial\n€264 p.a.\nmax 5,000\npages\n\n[145, 251,\n282, 355, 356]\n\nEphorus\n[100]\n\nclient software: web-based\nsystem\ninput: single or multiple\ndocuments\nprocedure: chunking and\nselection strategy unknown,\ncomparison to indexed www\nand repository of prior\nsubmissions\n\nCommercial\nindividual\nprice\n\n[282, 355,\n356]\n\nPlagAware\n[207]\n\nclient software: web-based\nsystem\ninput: single document\nprocedure: chunking and\nselection strategy unknown,\nweb search for chunks, string\nmatching on retrieved results\n\nCommercial\n€0.01–0.03\nper 250 words\n\n[355, 356]\n\nPlagiarism\nDetector\n[300]\n\nclient software: local\ninstallation\ninput: single or multiple\ndocuments\nprocedure: chunking and\nselection strategy unknown,\nchunks searched with Google,\nAlta Vista and Yahoo\n\nCommercial\n$49.99–79.99\n\n[260, 355,\n356]\n\nSafeAssign\n[34]\n\nclient software: web-based\nsystem\ninput: single or multiple\ndocuments\nprocedure: chunking and\nselection strategy unknown,\ncomparison to www, exclusive\ncontent, and repositories of\nprior submissions\n\nCommercial\nindividual\nprice\n\n[282, 353,\n354, 356]\n\nTurnitin\n[164]\nUrkund\n[271]\n\n[50, 84, 89,\n157, 282, 353,\n354, 356]\n[282, 355,\n356]\n\nIndex\nacademic plagiarism\nAmsler Measure\nApplication Programming Interface (API)\nauthor inspiration trail\nAuthorship Attribution (AA)\nBibliographic Coupling (BC)\nconcept\ndefinition\nstrength\nCF-Score\nconcept\ndefinition\nCitation Chunking\nconcept\ndefinition\ncitation composition plagiarism\nCitation Proximity Index (CPI)\nCitation-based Plagiarism Detection (CbPD)\nalgorithms\nconcept\ndefinition\nprototype\ncitations\nas markers\ncharacteristics considered\ncitation graph\ndefinition\nmotivations for citing\nCitePlag\nfrontend\nCo-citation\nCo-citation Proximity Analysis (CPA)\nalgorithms\nconcept\ndefinition\nrelevance for PD\ncollusion\nContinuity-Score\nconcept\nB. Gipp, Citation-based Plagiarism Detection,\nDOI 10.1007/978-3-658-06394-8, © Springer Fachmedien Wiesbaden 2014\n\nSee plagiarism\n52\nXVII\n216\n30\n47, 48, 54\n69\n64\n83, 273\nXVII\n73, 88\nXVII\n212\n53\n68\n58, 87\nXVII, 57\nSee CitePlag\n59\n64\n47\n44\n62\n89, 188, 204\n96\n50, 55\n54\n52\nXVIII\n55\n10\n85, 273\n\n348\n\ndefinition\ncopy &amp; paste (c&amp;p)\nCross-Language Information Retrieval (CLIR)\nCross-Language Plagiarism Detection (CLPD)\nDigital Object Identifier (DOI)\ndTagger\nEntity-Relationship Model (ERM)\nfalse positives\nfingerprinting\nFleiss&#x27; Kappa\nglobal similarity\nGoogle Scholar\nGoogle Translate\nGreedy Citation Tiling (GCT)\nconcept\ndefinition\nGreedy String Tiling (GST)\nground truth\nGuttenPlag Wiki\ninformation need\nInformation Retrieval (IR)\ndefinition\nfor plagiarism detection\nintercitation\nJaccard coefficient\nK.-T. zu Guttenberg\nLatent Semantic Indexing (LSI)\nlocal similarity\nLongest Common Citation Sequence (LCCS)\nconcept\ndefinition\nMatch Detect Reveal (MDR)\nMatthew effect\nMechanical Turk\nMedical Subject Headings (MeSH)\nMEDLINE\nNatural Language Processing (NLP)\nNXML\noDesk\nOpenNLP\nPAN-PC\n\nIndex\n\nXVIII\nXVII, 11, 152\nXVIII, 33\n32\nXVIII\n296\nXVIII\n148, 179, 214\n22\n158\n20\n64, 179\n36, 104\n70\nXVIII, 278\n69, 70\n101, 104\n108, 116, 311\n102, 168\nXIX\n17, 102\n47\n26\nXXIII, 1, 108\nXIX, 59\n20\n70, 273\nXIX\nXIX, 27\n64\n105, 198\nXIX\n15\n296\nXIX, 176, 300\n105\n296\n34, 42\n\nIndex\n\n349\n\nparaphrase\nParsCit\nparts of speech (POS)\nplagdet score\nplagiarism\ndefinition\nforms\nprevalence\nPlagiarism Detection (PD)\napproaches\nfingerprinting\nstring matching\nstylometry\nVector Space Models\n\nexternal detection\nintrinsic detection\noverview\nPlagiarism Detection Systems (PDS)\napproaches\navailable systems\n\n11, 152\n105\nXX, 296\n35\n9, 10\n11\n1, 13, 336\n19\n22\n26\n30\n28\n\n17, 33\n17, 31, 33\n9\n17\n33, 38\n\nAntiPlagiarist\nCopyCatch\nCopyscape\nDocoloc\nEncoplot\nEphorus\nFerret\niThenticate\nPlagAware\nPlagiarism Detector\nPlagScan\nSafeAssign\nSherlock\nTurnitin\nUrkund\nWCopyFind\n\n344\n344\n345\n346\n143, 160, 166, 176, 186, 344\n116, 120, 343, 345, 346\n116, 344\n120\n346\n346\n120\n343, 345, 346\n143, 160, 166, 176, 185, 293, 344\n338, 343, 345, 346\n343, 345, 346\n116, 344\n\ndefinition\nevaluation of systems\nlimitations of\nprototypes\nPMCID\npooling\nprecision and recall\n\nXX, 102\n34\n3, 39, 40\n34\nXX\n147\n106, 169, 170, 297\n\n350\n\nIndex\n\nPubMed Central (PMC)\n15, 111\nPubMed Central Open Access Subset (PMC OAS)\n111, 136, 139, 142, 195\nRefAuthKey\nXX, 94\nRefTitKey\nXX, 94\nrelatedness\nSee similarity\nrelative recall\n169\nrelevance judgment\n102\nSAX\nXX, 300\nself-plagiarism\n13, 15, 149\nSequential Pattern Analysis\n59, 217\nshake &amp; paste (s&amp;p)\nXX, 11, 152\nsimilarity\ncitation-based\n43, 47\ndefinition\n45\nlexical\n46, 58\nlocal vs. global\n20\nsemantic\n46, 58\nstructural\n46\nSPToolkit\n296\nStanford CoreNLP\n296\nstring matching\n26\nstructural &amp; idea plagiarism\n12, 152\nstylometry\n30, 31\nSW-Tagger\nXXI, 296\nsynonymizer\n1\ntechnical disguise\n11, 39, 42\nTerm Frequency–Inverse Document Frequency (TF-IDF)\nXXI, 29\nterm occurrence analysis\n26\ntranslated plagiarism\n11\ntranspositions\n67\nU.S. National Library of Medicine (NLM)\nXIX, 111, 142\nUML\nXXI, 95\nuser utility\n171\nVector Space Model (VSM)\nXXI, 28\nVroniPlag Wiki\n109, 121\nXML\nXXI\n\n","pages":{"startPosition":[0,5000,9995,15000,19990,25000,30001,34997,39998,45000,50000,54999,60000,65000,69998,74994,79999,85000,89997,94990,99999,104993,109994,114999,119991,124998,130001,134999,140000,145000,149994,154997,159998,164995,170000,174994,179997,184990,189998,195001,199999,204998,209996,215000,219999,224986,230000,235000,239998,244997,249998,254996,260000,265000,269998,274997,279983,284990,289997,294998,300001,304999,309996,315001,319997,325000,329999,334995,339991,344998,349991,354995,359998,365000,370000,375001,379988,384997,389999,394998,399996,405000,410001,414997,420001,424999,430001,435000,439996,444993,449984,454988,460000,464993,469996,474993,479996,485001,490000,494993,500000,504992,509999,515001,519998,524999,529998,534996,539999,544996,549999,554989,560000,564996,570000,574997,580000,584997,589997,594996]}},"html":{"comparison":{"identical":{"groupId":[0,1,1,1,2,3,4,5,6,7,8,9,10,11,12,13,14],"source":{"chars":{"starts":[11666,11694,11808,11838,12650,12727,21995,34369,34484,34500,56818,65943,66103,70537,70644,73383,77146],"lengths":[10,6,26,42,76,9,78,105,3,3,107,80,45,73,5,55,76]},"words":{"starts":[256,259,259,259,304,317,705,1306,1320,1322,2499,2657,2673,2750,2761,2805,2876],"lengths":[0,10,10,10,12,0,9,12,0,0,12,11,5,8,0,7,10]}},"suspected":{"chars":{"starts":[72287,72308,72308,72308,72517,72602,81668,118531,118642,118659,466701,427533,427640,460528,460622,421187,421490],"lengths":[10,74,74,74,76,9,78,105,3,3,107,80,45,73,5,55,76]},"words":{"starts":[8610,8613,8613,8613,8642,8656,9956,15376,15390,15392,66212,60970,60985,65392,65402,60102,60143],"lengths":[0,10,10,10,12,0,9,12,0,0,12,11,5,8,0,7,10]}}},"minorChanges":{"groupId":[15,16,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,34,34,34,35,36,37,38,39,40,41,41,41,41,42,43,43,44,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61],"source":{"chars":{"starts":[11687,22074,22265,34488,65757,65770,66024,66094,66149,70357,70374,70386,70435,70611,76921,76935,76971,77018,77223,77280,77716,77723,77827,77852,83201,83217,83221,83237,83326,83683,84117,84124,84228,84253,87741,87755,87904,88090,88104,88116,93755,93819,93857,94157,96442,96504,98462,98618,98948,101112,101209,101504,104227,113345,121441,121519],"lengths":[6,45,4,11,7,7,12,8,10,7,5,19,4,18,5,6,13,11,4,3,3,1,21,1,8,3,7,13,16,3,3,1,21,1,7,8,10,10,1,8,16,11,15,10,9,2,16,10,11,19,12,9,9,10,2,4]},"words":{"starts":[258,715,715,1321,2654,2656,2669,2672,2679,2737,2739,2741,2749,2759,2863,2865,2869,2875,2887,2890,2894,2894,2894,2894,2971,2973,2974,2976,2990,3009,3013,3013,3013,3013,3052,3054,3054,3074,3074,3076,3155,3164,3168,3178,3223,3226,3239,3257,3266,3285,3295,3305,3347,3491,3630,3640],"lengths":[0,6,6,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0]}},"suspected":{"chars":{"starts":[72305,81747,81747,118646,427517,427526,427614,427634,427686,460456,460466,460473,460520,460602,421397,421405,421430,421475,421567,421578,421595,421595,421595,421595,449548,449556,449560,449567,449654,449799,449816,449816,449816,449816,431689,431698,431698,431844,431844,431855,438484,438547,438582,438657,440458,440491,438922,439077,439141,439957,440053,440139,418143,430762,430242,430321],"lengths":[2,52,52,12,6,6,13,5,9,6,4,17,3,19,4,5,11,10,5,2,21,21,21,21,7,3,6,11,15,2,21,21,21,21,6,16,16,10,10,9,15,8,14,11,10,2,15,9,12,18,11,10,10,9,3,5]},"words":{"starts":[8612,9966,9966,15391,60967,60969,60982,60984,60991,65378,65380,65382,65390,65401,60128,60130,60135,60141,60154,60156,60159,60159,60159,60159,63845,63846,63847,63848,63862,63881,63884,63884,63884,63884,61556,61558,61558,61577,61577,61578,62438,62447,62451,62462,62702,62706,62492,62510,62520,62639,62649,62660,59677,61421,61348,61358],"lengths":[0,6,6,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,2,0,0,0,0,0,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0]}}},"relatedMeaning":{"groupId":[62,63,64,65,65,65,66,66,67,68,69,70,71,72,73,74,75,75,76,77,78,79,79,80,80,81,81,82,83,83],"source":{"chars":{"starts":[11677,11887,12642,34504,34719,34734,56959,56971,65765,66083,70365,70380,73326,76927,76942,76964,77261,77273,77377,83780,87749,94209,94221,96485,96497,99006,99018,99020,101547,101559],"lengths":[9,2,7,77,11,12,5,1,4,10,8,5,10,7,21,6,5,1,9,9,5,5,1,5,6,5,1,8,5,1]},"words":{"starts":[257,271,303,1323,1323,1323,2512,2512,2655,2671,2738,2740,2803,2864,2866,2868,2888,2888,2892,3011,3053,3180,3180,3224,3224,3268,3268,3269,3306,3306],"lengths":[0,0,0,12,12,12,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,1,0,0]}},"suspected":{"chars":{"starts":[72298,72383,72504,118663,118663,118663,466819,466819,427524,427628,460463,460471,421178,421402,421411,421421,421573,421573,421590,449811,431696,438674,438674,440469,440469,439154,439154,439159,440150,440150],"lengths":[6,6,8,107,107,107,3,3,1,5,2,1,8,2,9,6,4,4,4,4,1,2,2,21,21,4,4,18,4,4]},"words":{"starts":[8611,8624,8640,15393,15393,15393,66226,66226,60968,60983,65379,65381,60101,60129,60131,60133,60155,60155,60158,63883,61557,62464,62464,62703,62703,62521,62521,62522,62661,62661],"lengths":[0,0,0,14,14,14,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,2,2,0,0,2,0,0]}}}}},"version":3}